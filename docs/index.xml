<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>To Be Decided </title>
    <link>https://www.kaitoy.xyz/</link>
    <language>en-us</language>
    <author>Kaito Yamada</author>
    <rights>(C) 2018</rights>
    <updated>2018-11-07 23:41:30 &#43;0900 JST</updated>

    
      
        <item>
          <title>React &#43; Reduxアプリケーションプロジェクトのテンプレートを作る ― その10: Code Splitting、Flow、Jest、Enzyme</title>
          <link>https://www.kaitoy.xyz/2018/11/07/creating-react-redux-app-from-scratch-10/</link>
          <pubDate>Wed, 07 Nov 2018 23:41:30 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/11/07/creating-react-redux-app-from-scratch-10/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt;と&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;を学ぶために、開発環境というかプロジェクトテンプレートをスクラッチから作っている。
(最終的な成果は&lt;a href=&#34;https://github.com/kaitoy/react-redux-scaffold&#34;&gt;GitHub&lt;/a&gt;に置いた。)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/11/02/creating-react-redux-app-from-scratch-09/&#34;&gt;前回&lt;/a&gt;は&lt;a href=&#34;https://reacttraining.com/react-router/&#34;&gt;React Router&lt;/a&gt;をセットアップした。&lt;/p&gt;

&lt;p&gt;今回は残りの要素をまとめてかたづける。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;code-splitting&#34;&gt;Code Splitting&lt;/h1&gt;

&lt;p&gt;webpackでリソースをバンドルすると、一回の通信でアプリの要素全てをロードできるので効率いいような気がするけど、アプリの規模が大きくなってくるとバンドルサイズが大きくなって、初期ロード時間が長くなり、つまり初期画面の表示に時間がかかるようになってしまう。
そもそも、いつもアプリの全画面をみるとは限らないので、いつもアプリの全要素をロードするのは無駄。&lt;/p&gt;

&lt;p&gt;そんな問題に対応する技術が&lt;a href=&#34;https://webpack.js.org/guides/code-splitting/&#34;&gt;Code Splitting&lt;/a&gt;。
バンドルを分割し、(理想的には)必要な時に必要な分だけロードする技術。&lt;/p&gt;

&lt;p&gt;Code Splittingのやりかたはいくつかあるが、webpackのディレクティブを使った&lt;a href=&#34;https://webpack.js.org/guides/code-splitting/#prefetching-preloading-modules&#34;&gt;プリフェッチ&lt;/a&gt;を、フォントモジュールに適用してみる。&lt;/p&gt;

&lt;p&gt;src/index.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
 import ReactDOM from &#39;react-dom&#39;;
 import { Provider } from &#39;react-redux&#39;;
 import { ConnectedRouter } from &#39;connected-react-router&#39;;
 import App from &#39;./components/App&#39;;
 import configureStore from &#39;./configureStore&#39;;
 import configureStore, { history } from &#39;./configureStore&#39;;
-import &#39;./fonts.css&#39;;
+import(/* webpackPrefetch: true */ &#39;./fonts&#39;);

 const store = configureStore();
 const root = document.getElementById(&#39;root&#39;);

 if (root) {
   ReactDOM.render(
     &amp;lt;Provider store={store}&amp;gt;
       &amp;lt;ConnectedRouter history={history}&amp;gt;
         &amp;lt;App /&amp;gt;
       &amp;lt;/ConnectedRouter&amp;gt;
     &amp;lt;/Provider&amp;gt;,
     root,
   );
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コード変更はこれだけ。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;import()&lt;/code&gt;は&lt;a href=&#34;https://github.com/tc39/proposal-dynamic-import&#34;&gt;ダイナミックインポート&lt;/a&gt;という、ECMAScriptで現在策定中の機能。
これを使えるようにするためには、Babelのプラグインを追加する必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D babel-plugin-syntax-dynamic-import
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.babelrc&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; {
   &amp;quot;presets&amp;quot;: [&amp;quot;env&amp;quot;, &amp;quot;react&amp;quot;],
-  &amp;quot;plugins&amp;quot;: [&amp;quot;styled-components&amp;quot;]
+  &amp;quot;plugins&amp;quot;: [&amp;quot;styled-components&amp;quot;, &amp;quot;syntax-dynamic-import&amp;quot;]
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ダイナミックインポートの設定も完了。
これでフォントモジュールはメインのバンドルとは別ファイルになり、初期画面の表示時にはロードされず、ブラウザの空き時間に非同期にロードされるようになる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Code Splittingは&lt;a href=&#34;https://reactjs.org/docs/code-splitting.html&#34;&gt;Reactのドキュメント&lt;/a&gt;でも紹介されていて、そこにはReact特有のやり方も載っている。
&lt;a href=&#34;https://reactjs.org/docs/code-splitting.html#reactlazy&#34;&gt;React.lazy&lt;/a&gt;と&lt;a href=&#34;https://reactjs.org/docs/code-splitting.html#suspense&#34;&gt;Suspense&lt;/a&gt;を使うものがかなりナウい。&lt;/p&gt;

&lt;h1 id=&#34;flow&#34;&gt;Flow&lt;/h1&gt;

&lt;p&gt;Reactに限らない話だけど、JavaScriptは動的型付け言語なので、特に規模が大き目なアプリを開発するとなると保守性が悪くなりがちで辛い。
ので、できれば静的型付けでやりたい。&lt;/p&gt;

&lt;p&gt;JavaScriptを静的型付けにするには、&lt;a href=&#34;https://www.typescriptlang.org/&#34;&gt;TypeScript&lt;/a&gt;と&lt;a href=&#34;https://flow.org/&#34;&gt;Flow&lt;/a&gt;という二つの選択肢がある。
今回、FlowがReactと同じくFacebook製なので、Reactと相性がいいかと思ってFlowを選択したけど、人気やエコシステムの充実度から見るとTypeScriptのほうがよかった気がする。
ので、Flowについてはさらっと書く。&lt;/p&gt;

&lt;h2 id=&#34;flow導入&#34;&gt;Flow導入&lt;/h2&gt;

&lt;p&gt;Flowは、ソースに型情報を付けて静的型チェック可能にしつつ、実行時には型情報を取り去って普通のJavaScriptとして実行できるようにする仕組み。&lt;/p&gt;

&lt;p&gt;型チェックするツールは&lt;a href=&#34;https://www.npmjs.com/package/flow-bin&#34;&gt;flow-bin&lt;/a&gt;パッケージで配布されていて、型情報の除去は&lt;a href=&#34;https://www.npmjs.com/package/babel-preset-flow&#34;&gt;babel-preset-flow&lt;/a&gt;を使ってBabelでできる。
babel-preset-flowは、すでにインストールしたbabel-preset-reactに含まれてるので、敢えて入れる必要はない。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D flow-bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで、&lt;code&gt;yarn flow&lt;/code&gt;でFlowを実行できるようになった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ yarn flow version
yarn run v1.7.0
$ C:\Users\kaitoy\Desktop\bin\pleiades\workspace\react-redux-scaffold\node_modules\.bin\flow version
Flow, a static type checker for JavaScript, version 0.77.0
Done in 0.38s.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、&lt;code&gt;yarn flow init&lt;/code&gt;でFlowの設定ファイル&lt;code&gt;.flowconfig&lt;/code&gt;を生成して、型チェックしたいファイルの頭に&lt;code&gt;// @flow&lt;/code&gt;と書けばとりあえず機能する。&lt;/p&gt;

&lt;h2 id=&#34;flowの型アノテーション&#34;&gt;Flowの型アノテーション&lt;/h2&gt;

&lt;p&gt;それだけでもだいぶ型推論してくれてチェックが利くけど、&lt;a href=&#34;https://flow.org/en/docs/types/&#34;&gt;型アノテーション&lt;/a&gt;を書いていくとよりいい。
ただ、アノテートするとESLintとけんかするので、それ対策として&lt;a href=&#34;https://github.com/gajus/eslint-plugin-flowtype&#34;&gt;eslint-plugin-flowtype&lt;/a&gt;を入れる必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D babel-eslint eslint-plugin-flowtype
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;.eslintrc.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; module.exports = {
   env: {
     browser: true,
   },
+  parser: &#39;babel-eslint&#39;,
-  extends: [&#39;airbnb&#39;, &#39;prettier&#39;],
+  extends: [&#39;airbnb&#39;, &#39;plugin:flowtype/recommended&#39;, &#39;prettier&#39;],
+  plugins: [&#39;flowtype&#39;],
 };
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;例として、Reactコンポーネントのpropsに型を付けてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;// @flow

import React from &#39;react&#39;;
import Dialog from &#39;@material-ui/core/Dialog&#39;;
import DialogTitle from &#39;@material-ui/core/DialogTitle&#39;;
import PropTypes from &#39;prop-types&#39;;

// Propsという型の定義
// text(string型)とopen(boolean型)というプロパティを持つオブジェクト
type Props = {
  text: string,
  open: boolean,
};

// Props型を受け取る関数
const MyDialog = ({ text, open }: Props) =&amp;gt; (
  &amp;lt;Dialog open={open}&amp;gt;
    &amp;lt;DialogTitle&amp;gt;{text}&amp;lt;/DialogTitle&amp;gt;
  &amp;lt;/Dialog&amp;gt;
);

MyDialog.propTypes = {
  text: PropTypes.string.isRequired,
  open: PropTypes.bool.isRequired,
};

export default MyDialog;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じで型を付けておくと、MyDialogに渡すpropsを間違った場合にFlowがエラーにしてくれる。
prop-typesによる型定義と冗長な感じに見えるけど、Flowは静的に型チェックするのに対し、prop-typesはアプリの動作中に型チェックしてくれるので、両方書いておくのがよさそう。
(Flowの型定義からprop-typesの定義を生成してくれる&lt;a href=&#34;https://github.com/atlassian/babel-plugin-react-flow-props-to-prop-types&#34;&gt;babel-plugin-react-flow-props-to-prop-types&lt;/a&gt;というのがあるけど、サポートされていない型があるし、メンテされていないし、微妙。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;上のコードで、&lt;code&gt;type&lt;/code&gt;というキーワードで型を定義しているんだけど、Reactとかの3rdパーティライブラリの型情報(&lt;a href=&#34;https://flow.org/en/docs/libdefs/&#34;&gt;libdef&lt;/a&gt;と呼ばれるもの)は、ライブラリ開発者などが作ったものが公開されていて、インストールして利用できる。&lt;/p&gt;

&lt;p&gt;libdefはそれようの&lt;a href=&#34;https://github.com/flow-typed/flow-typed/tree/master/definitions&#34;&gt;リポジトリ&lt;/a&gt;で管理されていて、&lt;a href=&#34;https://github.com/flow-typed/flow-typed/blob/master/README.md&#34;&gt;flow-typed&lt;/a&gt;で引っ張れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D flow-typed
yarn flow-typed --ignoreDeps dev install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで、package.jsonに書かれている依存(devDependenciesを除く)を見て、必要なlibdefをダウンロードしてきて、プロジェクトルートの&lt;code&gt;flow-typed&lt;/code&gt;というディレクトリにインストールしてくれる。&lt;/p&gt;

&lt;p&gt;例えばさっきのReactコンポーネントのコードに、ReactのAPIの型の一つである&lt;code&gt;Node&lt;/code&gt;を書くと以下のようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; // @flow

 import React from &#39;react&#39;;
+import type { Node } from &#39;react&#39;;
 import Dialog from &#39;@material-ui/core/Dialog&#39;;
 import DialogTitle from &#39;@material-ui/core/DialogTitle&#39;;
 import PropTypes from &#39;prop-types&#39;;

 // Propsという型の定義
 // text(string型)とopen(boolean型)というプロパティを持つオブジェクト
 type Props = {
   text: string,
   open: boolean,
 };

 // Props型を受け取る関数
-const MyDialog = ({ text, open }: Props) =&amp;gt; (
+const MyDialog = ({ text, open }: Props): Node =&amp;gt; (
   &amp;lt;Dialog open={open}&amp;gt;
     &amp;lt;DialogTitle&amp;gt;{text}&amp;lt;/DialogTitle&amp;gt;
   &amp;lt;/Dialog&amp;gt;
 );

 MyDialog.propTypes = {
   text: PropTypes.string.isRequired,
   open: PropTypes.bool.isRequired,
 };

 export default MyDialog;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因みに&lt;code&gt;flow-typed&lt;/code&gt;ディレクトリの中身はコミットすることが推奨されている。
なんか違和感あるんだけど…&lt;/p&gt;

&lt;h1 id=&#34;jest&#34;&gt;Jest&lt;/h1&gt;

&lt;p&gt;Reactプロジェクトでユニットテストを書くなら、&lt;a href=&#34;https://jestjs.io/ja/&#34;&gt;Jest&lt;/a&gt;一択でいいっぽい。
JestもReactと開発元が同じFacebookで、Reactと相性がいいはずだし、Reactプロジェクト以外でもJestは人気。&lt;/p&gt;

&lt;p&gt;ゼロ設定で使えるように作られていて、導入の敷居が低いのが特徴。
また多機能で、アサーション、モック、カバレージ測定辺りは組み込まれていてすぐ使える。&lt;/p&gt;

&lt;p&gt;もともとは(今も?)&lt;a href=&#34;https://jasmine.github.io/&#34;&gt;Jasmine&lt;/a&gt;ベースで、APIが似た感じなので、Jasmineとか&lt;a href=&#34;https://mochajs.org/&#34;&gt;Mocha&lt;/a&gt;に慣れた人には特に使いやすい。&lt;/p&gt;

&lt;h2 id=&#34;jestインストール&#34;&gt;Jestインストール&lt;/h2&gt;

&lt;p&gt;ReactプロジェクトでJestを使うには以下のパッケージを入れる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.npmjs.com/package/jest&#34;&gt;jest&lt;/a&gt;: 本体&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.npmjs.com/package/babel-jest&#34;&gt;babel-jest&lt;/a&gt;: BabelでトランスパイルするコードをJestでテストするためのBabelプラグイン&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.npmjs.com/package/react-test-renderer&#34;&gt;react-test-renderer&lt;/a&gt;: ReactコンポーネントをピュアなJavaScriptオブジェクトにレンダリングするライブラリ。&lt;a href=&#34;https://jestjs.io/docs/en/snapshot-testing&#34;&gt;スナップショットテスト&lt;/a&gt;などに使う。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D jest babel-jest react-test-renderer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Jestはv23.4.2が入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;npm scriptにjestを追加しておくといい。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;package.json&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; (前略)
   &amp;quot;scripts&amp;quot;: {
     &amp;quot;format&amp;quot;: &amp;quot;prettier --write **/*.jsx **/*.js **/*.css&amp;quot;,
     &amp;quot;build&amp;quot;: &amp;quot;webpack --config webpack.prod.js&amp;quot;,
+    &amp;quot;test&amp;quot;: &amp;quot;jest&amp;quot;,
     &amp;quot;start&amp;quot;: &amp;quot;webpack-dev-server --hot --config webpack.dev.js&amp;quot;
   },
 (後略)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;jestセットアップ&#34;&gt;Jestセットアップ&lt;/h2&gt;

&lt;p&gt;Jestの設定ファイルである&lt;a href=&#34;https://jestjs.io/docs/en/configuration&#34;&gt;jest.config.js&lt;/a&gt;をプロジェクトルートに生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn test --init
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;プロンプトでいくつかのことを聞かれるが、「Choose the test environment that will be used for testing」に&lt;code&gt;jsdom&lt;/code&gt;で答えるのがポイント。ブラウザで動かすアプリなので。&lt;/p&gt;

&lt;p&gt;設定ファイルはとりあえずおおむね生成されたままでいいけど、一点、v23.4.2時点では、テスト実行時に「SecurityError: localStorage is not available for opaque origins」というエラーが出る&lt;a href=&#34;https://github.com/facebook/jest/issues/6769#issuecomment-408352345&#34;&gt;問題がある&lt;/a&gt;ので、testURLを「&lt;code&gt;http://localhost/&lt;/code&gt;」に設定しておく必要がある。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;jest.config.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;// For a detailed explanation regarding each configuration property, visit:
// https://jestjs.io/docs/en/configuration.html

module.exports = {
  // All imported modules in your tests should be mocked automatically
  // automock: false,

  // Stop running tests after the first failure
  // bail: false,

  // Respect &amp;quot;browser&amp;quot; field in package.json when resolving modules
  // browser: false,

  // The directory where Jest should store its cached dependency information
  // cacheDirectory: &amp;quot;C:\\Users\\kaitoy\\AppData\\Local\\Temp\\jest&amp;quot;,

  // Automatically clear mock calls and instances between every test
  // clearMocks: false,

  // Indicates whether the coverage information should be collected while executing the test
  // collectCoverage: false,

  // An array of glob patterns indicating a set of files for which coverage information should be collected
  // collectCoverageFrom: null,

  // The directory where Jest should output its coverage files
  coverageDirectory: &#39;coverage&#39;,

  // An array of regexp pattern strings used to skip coverage collection
  // coveragePathIgnorePatterns: [
  //   &amp;quot;\\\\node_modules\\\\&amp;quot;
  // ],

  // A list of reporter names that Jest uses when writing coverage reports
  // coverageReporters: [
  //   &amp;quot;json&amp;quot;,
  //   &amp;quot;text&amp;quot;,
  //   &amp;quot;lcov&amp;quot;,
  //   &amp;quot;clover&amp;quot;
  // ],

  // An object that configures minimum threshold enforcement for coverage results
  // coverageThreshold: null,

  // Make calling deprecated APIs throw helpful error messages
  // errorOnDeprecated: false,

  // Force coverage collection from ignored files usin a array of glob patterns
  // forceCoverageMatch: [],

  // A path to a module which exports an async function that is triggered once before all test suites
  // globalSetup: null,

  // A path to a module which exports an async function that is triggered once after all test suites
  // globalTeardown: null,

  // A set of global variables that need to be available in all test environments
  // globals: {},

  // An array of directory names to be searched recursively up from the requiring module&#39;s location
  // moduleDirectories: [
  //   &amp;quot;node_modules&amp;quot;
  // ],

  // An array of file extensions your modules use
  // moduleFileExtensions: [
  //   &amp;quot;js&amp;quot;,
  //   &amp;quot;json&amp;quot;,
  //   &amp;quot;jsx&amp;quot;,
  //   &amp;quot;node&amp;quot;
  // ],

  // A map from regular expressions to module names that allow to stub out resources with a single module
  // moduleNameMapper: {},

  // An array of regexp pattern strings, matched against all module paths before considered &#39;visible&#39; to the module loader
  // modulePathIgnorePatterns: [],

  // Activates notifications for test results
  // notify: false,

  // An enum that specifies notification mode. Requires { notify: true }
  // notifyMode: &amp;quot;always&amp;quot;,

  // A preset that is used as a base for Jest&#39;s configuration
  // preset: null,

  // Run tests from one or more projects
  // projects: null,

  // Use this configuration option to add custom reporters to Jest
  // reporters: undefined,

  // Automatically reset mock state between every test
  // resetMocks: false,

  // Reset the module registry before running each individual test
  // resetModules: false,

  // A path to a custom resolver
  // resolver: null,

  // Automatically restore mock state between every test
  // restoreMocks: false,

  // The root directory that Jest should scan for tests and modules within
  // rootDir: null,

  // A list of paths to directories that Jest should use to search for files in
  // roots: [
  //   &amp;quot;&amp;lt;rootDir&amp;gt;&amp;quot;
  // ],

  // Allows you to use a custom runner instead of Jest&#39;s default test runner
  // runner: &amp;quot;jest-runner&amp;quot;,

  // The paths to modules that run some code to configure or set up the testing environment before each test
  // setupFiles: [],

  // The path to a module that runs some code to configure or set up the testing framework before each test
  // setupTestFrameworkScriptFile: null,

  // A list of paths to snapshot serializer modules Jest should use for snapshot testing
  // snapshotSerializers: [],

  // The test environment that will be used for testing
  // testEnvironment: &amp;quot;jest-environment-jsdom&amp;quot;,

  // Options that will be passed to the testEnvironment
  // testEnvironmentOptions: {},

  // Adds a location field to test results
  // testLocationInResults: false,

  // The glob patterns Jest uses to detect test files
  // testMatch: [
  //   &amp;quot;**/__tests__/**/*.js?(x)&amp;quot;,
  //   &amp;quot;**/?(*.)+(spec|test).js?(x)&amp;quot;
  // ],

  // An array of regexp pattern strings that are matched against all test paths, matched tests are skipped
  // testPathIgnorePatterns: [
  //   &amp;quot;\\\\node_modules\\\\&amp;quot;
  // ],

  // The regexp pattern Jest uses to detect test files
  // testRegex: &amp;quot;&amp;quot;,

  // This option allows the use of a custom results processor
  // testResultsProcessor: null,

  // This option allows use of a custom test runner
  // testRunner: &amp;quot;jasmine2&amp;quot;,

  // This option sets the URL for the jsdom environment. It is reflected in properties such as location.href
  testURL: &#39;http://localhost/&#39;,

  // Setting this value to &amp;quot;fake&amp;quot; allows the use of fake timers for functions such as &amp;quot;setTimeout&amp;quot;
  // timers: &amp;quot;real&amp;quot;,

  // A map from regular expressions to paths to transformers
  // transform: null,

  // An array of regexp pattern strings that are matched against all source file paths, matched files will skip transformation
  // transformIgnorePatterns: [
  //   &amp;quot;\\\\node_modules\\\\&amp;quot;
  // ],

  // An array of regexp pattern strings that are matched against all modules before the module loader will automatically return a mock for them
  // unmockedModulePathPatterns: undefined,

  // Indicates whether each individual test should be reported during the run
  // verbose: null,

  // An array of regexp patterns that are matched against all source file paths before re-running tests in watch mode
  // watchPathIgnorePatterns: [],

  // Whether to use watchman for file crawling
  // watchman: true,
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;また、例によって、(主にJestのグローバル変数のために、)JestのテストコードとESLintがけんかするので、ESLintをなだめるために&lt;a href=&#34;https://www.npmjs.com/package/eslint-plugin-jest&#34;&gt;eslint-plugin-jest&lt;/a&gt;を入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D eslint-plugin-jest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;.eslintrc.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; module.exports = {
   env: {
     browser: true,
+    &#39;jest/globals&#39;: true,
   },
   parser: &#39;babel-eslint&#39;,
   extends: [&#39;airbnb&#39;, &#39;plugin:flowtype/recommended&#39;, &#39;prettier&#39;],
-  plugins: [&#39;flowtype&#39;],
+  plugins: [&#39;flowtype&#39;, &#39;jest&#39;],
 };
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;jestのテスト作成&#34;&gt;Jestのテスト作成&lt;/h2&gt;

&lt;p&gt;Jestのテストは、&lt;code&gt;jest.config.js&lt;/code&gt;の&lt;code&gt;testMatch&lt;/code&gt;にマッチするJavaScriptファイルに書く。
デフォルトでは&lt;code&gt;__test__&lt;/code&gt;ディレクトリ以下に置けばいい。&lt;/p&gt;

&lt;p&gt;テストコードはよくある感じの&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%93%E3%83%98%E3%82%A4%E3%83%93%E3%82%A2%E9%A7%86%E5%8B%95%E9%96%8B%E7%99%BA&#34;&gt;BDD&lt;/a&gt;風に書けばいいと思う。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/__tests__/reducers/reducers.test.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { hoge } from &#39;../../reducers/reducers&#39;;
import { hogeButtonClicked } from &#39;../../actions/actions&#39;;

const initialState = {
  clicked: false,
};

describe(&#39;reducers&#39;, () =&amp;gt; {
  describe(&#39;hoge()&#39;, () =&amp;gt; {
    test(&#39;returns a state with clicked:true when the action is HOGE_BUTTON_CLICKED&#39;, () =&amp;gt; {
      const state = hogeButtonClicked(initialState, hogeButtonClicked({}));
      expect(state.clicked).toBe(true);
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;スナップショットテスト&#34;&gt;スナップショットテスト&lt;/h2&gt;

&lt;p&gt;Jestの目玉のひとつは&lt;a href=&#34;https://jestjs.io/docs/ja/snapshot-testing&#34;&gt;スナップショットテスト&lt;/a&gt;。
Reactコンポーネントのレンダリング結果が以前と変わってないかをテストできる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/__tests__/components/HogeButton.test.jsx&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import React from &#39;react&#39;;
import renderer from &#39;react-test-renderer&#39;;
import HogeButton from &#39;../../components/HogeButton&#39;;

describe(&#39;components&#39;, () =&amp;gt; {
  describe(&#39;HogeButton&#39;, () =&amp;gt; {
    test(&#39;renders correctly&#39;, () =&amp;gt; {
      const tree = renderer.create(
        &amp;lt;HogeButton variant=&amp;quot;contained&amp;quot; onClick={() =&amp;gt; {}}&amp;gt;
          HOGE
        &amp;lt;/HogeButton&amp;gt;
      ).toJSON();
      expect(tree).toMatchSnapshot();
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このテストの初回実行時には、&lt;code&gt;src/__tests__/components/__snapshots__/HogeButton.test.jsx.snap&lt;/code&gt;というスナップショットファイルが生成される。
これはテキスト形式で、以下のような人が読み解ける内容。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/__tests__/components/__snapshots__/HogeButton.test.jsx.snap&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`components HogeButton renders correctly 1`] = `
&amp;lt;button
  className=&amp;quot;MuiButtonBase-root-25 MuiButton-root-1 MuiButton-contained-10 MuiButton-raised-13&amp;quot;
  disabled={false}
  onBlur={[Function]}
  onClick={[Function]}
  onFocus={[Function]}
  onKeyDown={[Function]}
  onKeyUp={[Function]}
  onMouseDown={[Function]}
  onMouseLeave={[Function]}
  onMouseUp={[Function]}
  onTouchEnd={[Function]}
  onTouchMove={[Function]}
  onTouchStart={[Function]}
  tabIndex=&amp;quot;0&amp;quot;
  type=&amp;quot;button&amp;quot;
&amp;gt;
  &amp;lt;span
    className=&amp;quot;MuiButton-label-2&amp;quot;
  &amp;gt;
    HOGE
  &amp;lt;/span&amp;gt;
  &amp;lt;span
    className=&amp;quot;MuiTouchRipple-root-28&amp;quot;
  /&amp;gt;
&amp;lt;/button&amp;gt;
`;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;スナップショットファイルはコミットしてバージョン管理して、変更があったときには差分を確認する。&lt;/p&gt;

&lt;h1 id=&#34;enzyme&#34;&gt;Enzyme&lt;/h1&gt;

&lt;p&gt;Reactのユニットテストをよりいい感じに書けるようにしてくれるユーティリティライブラリが&lt;a href=&#34;https://airbnb.io/enzyme/&#34;&gt;Enzyme&lt;/a&gt;。
Airbnb製。
Reactコンポーネントをレンダリングして、jQueryみたいなAPIで&lt;a href=&#34;https://airbnb.io/enzyme/docs/api/selector.html&#34;&gt;セレクタ&lt;/a&gt;を指定したりしてエレメントを取得し、アサートするようなテストが書ける。&lt;/p&gt;

&lt;p&gt;Enzymeによるレンダリングには以下の3種類があり、テスト内容によって使い分ける。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://airbnb.io/enzyme/docs/api/shallow.html&#34;&gt;Shallow Rendering&lt;/a&gt;: 浅くレンダリングして、子コンポーネントに影響を受けないテストができる。Reactの&lt;a href=&#34;https://reactjs.org/docs/state-and-lifecycle.html&#34;&gt;ライフサイクルメソッド&lt;/a&gt;も呼んでくれる。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://airbnb.io/enzyme/docs/api/mount.html&#34;&gt;Full Rendering&lt;/a&gt;: &lt;a href=&#34;https://github.com/jsdom/jsdom&#34;&gt;jsdom&lt;/a&gt;などを使って完全なDOMツリーとしてレンダリングする。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://airbnb.io/enzyme/docs/api/render.html&#34;&gt;Static Rendering&lt;/a&gt;: 静的なHTMLに出力して、それをパースする。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Enzymeはv3から本体とアダプタという構成になっていて、Reactのバージョンによってアダプタを使い分ける。
(&lt;a href=&#34;https://preactjs.com/&#34;&gt;preact&lt;/a&gt;とか&lt;a href=&#34;https://infernojs.org/&#34;&gt;Inferno&lt;/a&gt;のアダプタもある。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D enzyme enzyme-adapter-react-16
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Enzymeはv3.3.0が入った。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/FormidableLabs/enzyme-matchers/tree/master/packages/jest-enzyme&#34;&gt;jest-enzyme&lt;/a&gt;も入れるとアサーションがいい感じに書けてよりいいかもしれない。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Full Renderingをやってみる。&lt;/p&gt;

&lt;p&gt;ContainedButtonがクリックされたとき、&lt;code&gt;onClick&lt;/code&gt;に指定した関数が呼ばれることを確認するテストは以下のように書ける。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/__tests__/components/HogeButton.test.jsx&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
 import renderer from &#39;react-test-renderer&#39;;
+import Enzyme, { mount } from &#39;enzyme&#39;;
+import Adapter from &#39;enzyme-adapter-react-16&#39;;
 import HogeButton from &#39;../../components/HogeButton&#39;;

+beforeAll(() =&amp;gt; {
+  Enzyme.configure({ adapter: new Adapter() });
+});

 describe(&#39;components&#39;, () =&amp;gt; {
   describe(&#39;HogeButton&#39;, () =&amp;gt; {
     test(&#39;renders correctly&#39;, () =&amp;gt; {
       const tree = renderer.create(
         &amp;lt;HogeButton variant=&amp;quot;contained&amp;quot; onClick={() =&amp;gt; {}}&amp;gt;
           HOGE
         &amp;lt;/HogeButton&amp;gt;
       ).toJSON();
       expect(tree).toMatchSnapshot();
     });
+
+    test(&amp;quot;calls the passed handler when it&#39;s clicked&amp;quot;, () =&amp;gt; {
+      const handler = jest.fn();
+      const wrapper = mount(&amp;lt;HogeButton onClick={handler} /&amp;gt;);
+      wrapper.find(&#39;button&#39;).simulate(&#39;click&#39;);
+      expect(handler).toHaveBeenCalledTimes(1);
+    });
   });
 });
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;mount&lt;/code&gt;がFull RenderingのAPIで、内部で&lt;code&gt;react-test-renderer&lt;/code&gt;を使っているみたいなんだけど、&lt;code&gt;mount&lt;/code&gt;のために&lt;code&gt;react-test-renderer&lt;/code&gt;をimportする必要はない。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上で全10回に渡るReact―Redux環境のセットアップ体験記が完結。&lt;/p&gt;

&lt;p&gt;だらだら書いてるうちに、&lt;a href=&#34;https://babeljs.io/blog/2018/08/27/7.0.0&#34;&gt;Babelの7が出たり&lt;/a&gt;、&lt;a href=&#34;https://reactjs.org/docs/hooks-overview.html&#34;&gt;React Hooks&lt;/a&gt;とか&lt;a href=&#34;https://logmi.jp/tech/articles/302611&#34;&gt;React Suspense&lt;/a&gt;とかが出てきてて、また大きく変わってきそう…&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>React &#43; Reduxアプリケーションプロジェクトのテンプレートを作る ― その9: React Router</title>
          <link>https://www.kaitoy.xyz/2018/11/02/creating-react-redux-app-from-scratch-09/</link>
          <pubDate>Fri, 02 Nov 2018 13:45:56 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/11/02/creating-react-redux-app-from-scratch-09/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt;と&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;を学ぶために、開発環境というかプロジェクトテンプレートをスクラッチから作っている。
(最終的な成果は&lt;a href=&#34;https://github.com/kaitoy/react-redux-scaffold&#34;&gt;GitHub&lt;/a&gt;に置いた。)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/10/07/creating-react-redux-app-from-scratch-08/&#34;&gt;前回&lt;/a&gt;は&lt;a href=&#34;https://redux-saga.js.org/&#34;&gt;Redux Saga&lt;/a&gt;をセットアップした。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;フロントエンドのルーティング&#34;&gt;フロントエンドのルーティング&lt;/h1&gt;

&lt;p&gt;Webアプリケーションにおけるルーティングとは、クライアントがリクエストしたURLに対して、返すべきリソースを選択する処理。
昔はバックエンド(i.e. サーバサイド)でやってたけど、バックエンドでリソースを返すということは、ページ遷移が発生するということなので、ネイティブアプリケーションに比べてUXが落ちてしまう。&lt;/p&gt;

&lt;p&gt;一方、ページ遷移を発生させないようにAjaxでサーバとやりとりしつつ、ちまちまDOMをいじるのは大変。
DOMをごっそり書き換えて、ページ遷移なしに画面を切り替えることはできるけど、ナイーブにやると以下のような問題がある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;URLと画面の紐づけがなく、URLを指定して直接開けない&lt;/li&gt;
&lt;li&gt;ブラウザの進む、戻るが使えない&lt;/li&gt;
&lt;li&gt;宣言的に書けない&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;こういった問題に対応するため、フロントエンドでのルーティング技術が生まれた。&lt;/p&gt;

&lt;p&gt;フロントエンドのルーティングでは、URLが変わってもリクエストはサーバに飛ばない。
代わりに、フロントエンドフレームワークがそのURLを見て、適切な画面を選んでレンダリングする。&lt;/p&gt;

&lt;h2 id=&#34;ハッシュベースのルーティング&#34;&gt;ハッシュベースのルーティング&lt;/h2&gt;

&lt;p&gt;URLが変わってもリクエストがサーバに飛ばないとは何事か。&lt;/p&gt;

&lt;p&gt;それを実現するやりかたは2通りある。
古くはハッシュ(#、&lt;a href=&#34;https://en.wikipedia.org/wiki/Fragment_identifier&#34;&gt;フラグメント識別子&lt;/a&gt;)をつかったやり方。&lt;/p&gt;

&lt;p&gt;例えば、&lt;code&gt;http://example.com/&lt;/code&gt;でUIをサーブしているとすると、&lt;code&gt;http://example.com/#foo&lt;/code&gt;とか、&lt;code&gt;http://example.com/#bar&lt;/code&gt;で別々のページの状態を表現する。
ハッシュ以降が変わってもブラウザがサーバにリクエストを投げることはないので、クライアント側でハンドリングできる。
(因みに、ハッシュを含んだURLをブラウザのアドレスバーに入れても、ハッシュを除いたURLでリクエストが送られる。この挙動の根拠となる規格はRFCなどを調べても見つからなかったけど…)&lt;/p&gt;

&lt;p&gt;ハッシュの書き換えは、JavaScriptで以下のようにしてできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;location.hash = newHash;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こういう処理を、例えばWeb UIのボタンをクリックしたときなんかに実行してURLを変えて、その上で画面を更新してやればいい。&lt;/p&gt;

&lt;p&gt;そのあと、ブラウザの戻るボタンなんかを押されると書き換える前のURLにもどるわけだけど、これを検知するために&lt;code&gt;setInterval()&lt;/code&gt;とかで定期的に&lt;code&gt;location.hash&lt;/code&gt;を監視してたりした。&lt;/p&gt;

&lt;h2 id=&#34;history-apiによるルーティング&#34;&gt;History APIによるルーティング&lt;/h2&gt;

&lt;p&gt;ハッシュベースのルーティングは見るからにしょぼい。
URLのハッシュ以降しか使えないのもしょぼいし、内部の処理も泥臭い。&lt;/p&gt;

&lt;p&gt;これが、HTML 5で&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/History&#34;&gt;History API&lt;/a&gt;がでて変わった。
History APIはJavaScriptのAPIで、ブラウザの履歴を操作できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const state = { hoge: &amp;quot;hogeee&amp;quot; };
history.pushState(state, &amp;quot;&amp;quot;, &amp;quot;/foo/bar&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じのを実行すると、URLが&lt;code&gt;/foo/bar&lt;/code&gt;に変わる。(が、もちろんサーバにはリクエストは飛ばない。)
で、ブラウザの戻るボタンを押すと、&lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/Events/popstate&#34;&gt;popstate&lt;/a&gt;イベントが発生するので、それにイベントハンドラを登録しておけば、もとのURLに戻った時にも適時画面を書き換えられる。
popstateイベントからは、&lt;code&gt;pushState()&lt;/code&gt;に渡したstateオブジェクトを取得できる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ところで、ブラウザのアドレスバーに&lt;code&gt;/foo/bar&lt;/code&gt;を直打ちするとどうなるかというと、普通にWebサーバを設定しておくと、&lt;code&gt;/foo/bar/index.html&lt;/code&gt;を返そうとして、無いので404エラーになっちゃう。
ので、サーバ設定では、どのURLも同じリソース(e.g. &lt;code&gt;/index.html&lt;/code&gt;)をしといて、そこからJavaScriptを呼んで、URLを読み取って、画面を描いてやればいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;HTML 5が普及するにつれ、このようなHistory APIを使ったフロントエンドルーティングをするフレームワークやライブラリが色々出てきた。んだろうと思う。&lt;/p&gt;

&lt;h1 id=&#34;react-router&#34;&gt;React Router&lt;/h1&gt;

&lt;p&gt;Reactのエコシステムとしては、&lt;a href=&#34;https://reacttraining.com/react-router/&#34;&gt;React Router&lt;/a&gt;がフロントエンドルーティングを実現してくれる。&lt;/p&gt;

&lt;p&gt;React Routerは、宣言的にフロントエンドルーティングを実現できるReactコンポーネントのライブラリ。&lt;/p&gt;

&lt;p&gt;Reduxとともに使う場合は、&lt;a href=&#34;https://github.com/supasate/connected-react-router&#34;&gt;Connected React Router&lt;/a&gt;を使う。
Connected React Routerには&lt;a href=&#34;https://www.npmjs.com/package/history&#34;&gt;history&lt;/a&gt;が必要。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add react-router-dom connected-react-router history
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;React Routerはv4.3.1、Connected React Routerはv4.3.0が入った。&lt;/p&gt;

&lt;h1 id=&#34;connected-react-router導入&#34;&gt;Connected React Router導入&lt;/h1&gt;

&lt;p&gt;まずはConnected React Routerの&lt;a href=&#34;https://github.com/supasate/connected-react-router#usage&#34;&gt;Usage&lt;/a&gt;を参考に、ReduxのMiddlewareを追加して、historyのインスタンスをStoreとつなぐ。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/configureStore.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import { createStore, applyMiddleware } from &#39;redux&#39;;
 import createSagaMiddleware from &#39;redux-saga&#39;;
+import { createBrowserHistory } from &#39;history&#39;;
+import { connectRouter, routerMiddleware } from &#39;connected-react-router&#39;;
 import { logger } from &#39;redux-logger&#39;;
 import rootSaga from &#39;./sagas/rootSaga&#39;;
 import rootReducer from &#39;./reducers/rootReducer&#39;;

 const sagaMiddleware = createSagaMiddleware();
+export const history = createBrowserHistory();

 export default function configureStore(initialState = {}) {
   const middlewares = [];
   if (process.env.NODE_ENV === `development`) {
     middlewares.push(logger);
   }
+  middlewares.push(routerMiddleware(history));
   middlewares.push(sagaMiddleware);

   const store = createStore(
-    rootReducer,
+    connectRouter(history)(rootReducer),
     initialState,
     applyMiddleware(...middlewares),
   );
   sagaMiddleware.run(rootSaga);
   return store;
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、Connected React RouterのConnectedRouterコンポーネントを&lt;a href=&#34;https://www.kaitoy.xyz/2018/10/01/creating-react-redux-app-from-scratch-07/#provider&#34;&gt;React ReduxのProvider&lt;/a&gt;の下に追加する。&lt;/p&gt;

&lt;p&gt;src/index.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
 import ReactDOM from &#39;react-dom&#39;;
 import { Provider } from &#39;react-redux&#39;;
+import { ConnectedRouter } from &#39;connected-react-router&#39;;
 import App from &#39;./components/App&#39;;
-import configureStore from &#39;./configureStore&#39;;
+import configureStore, { history } from &#39;./configureStore&#39;;
 import &#39;./fonts.css&#39;;

 const store = configureStore();
 const root = document.getElementById(&#39;root&#39;);

 if (root) {
   ReactDOM.render(
-    &amp;lt;Provider store={store}&amp;gt;
-      &amp;lt;App /&amp;gt;
-    &amp;lt;/Provider&amp;gt;,
+    &amp;lt;Provider store={store}&amp;gt;
+      &amp;lt;ConnectedRouter history={history}&amp;gt;
+        &amp;lt;App /&amp;gt;
+      &amp;lt;/ConnectedRouter&amp;gt;
+    &amp;lt;/Provider&amp;gt;,
     root,
   );
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これだけ。
これで、Appコンポーネント以下でReact Routerのコンポーネントを使えるようになった。&lt;/p&gt;

&lt;h1 id=&#34;react-router導入&#34;&gt;React Router導入&lt;/h1&gt;

&lt;p&gt;React Routerの&lt;a href=&#34;https://reacttraining.com/react-router/core/api/Redirect&#34;&gt;Redirect&lt;/a&gt;コンポーネントと&lt;a href=&#34;https://reacttraining.com/react-router/core/api/Route&#34;&gt;Route&lt;/a&gt;コンポーネントを使って、&lt;code&gt;/&lt;/code&gt;にアクセスしたら&lt;code&gt;/home&lt;/code&gt;にリダイレクトして、&lt;code&gt;/home&lt;/code&gt;で今までと同じ画面をレンダリングするようにする。&lt;/p&gt;

&lt;p&gt;まず、App.jsxをHome.jsxにリネームして、Homeコンポーネントに変える。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;components/Home.jsx&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
 import styled from &#39;styled-components&#39;;
 import HogeButton from &#39;../containers/HogeButton&#39;;

 const Wrapper = styled.div`
   font-size: 5rem;
 `;

-const App = () =&amp;gt; (
+const Home = () =&amp;gt; (
   &amp;lt;Wrapper&amp;gt;
     &amp;lt;HogeButton variant=&amp;quot;contained&amp;quot;&amp;gt;
       HOGE
     &amp;lt;/HogeButton&amp;gt;
   &amp;lt;/Wrapper&amp;gt;
 );

-export default App;
+export default Home;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、App.jsxはルーティングを定義するコンポーネントとして作り直す。&lt;/p&gt;

&lt;p&gt;components/App.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import React from &#39;react&#39;;
import { Route, Redirect } from &#39;react-router-dom&#39;;
import Home from &#39;./Home&#39;;

const App = (): Node =&amp;gt; (
  &amp;lt;div&amp;gt;
    &amp;lt;Route exact path=&amp;quot;/&amp;quot; render={() =&amp;gt; &amp;lt;Redirect to=&amp;quot;/home&amp;quot; /&amp;gt;} /&amp;gt;
    &amp;lt;Route exact path=&amp;quot;/home&amp;quot; component={Home} /&amp;gt;
  &amp;lt;/div&amp;gt;
);

export default App;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じ。&lt;/p&gt;

&lt;h1 id=&#34;webpack-dev-serverのhistory-api-fallback&#34;&gt;webpack-dev-serverのHistory API Fallback&lt;/h1&gt;

&lt;p&gt;あとは、上に書いたような404エラーを防ぐために、webpack-dev-serverの&lt;a href=&#34;https://webpack.js.org/configuration/dev-server/#devserver-historyapifallback&#34;&gt;History API Fallback&lt;/a&gt;を有効にしてやる。&lt;/p&gt;

&lt;p&gt;webpack.dev.js&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; const path = require(&#39;path&#39;);
 const webpackMerge = require(&#39;webpack-merge&#39;);
 const webpackCommon = require(&#39;./webpack.common.js&#39;);

 module.exports = webpackMerge(webpackCommon, {
   mode: &#39;development&#39;,
   devServer: {
     contentBase: path.join(__dirname, &#39;public&#39;),
     compress: true,
     hot: true,
     port: 3000,
     publicPath: &#39;http://localhost:3000/&#39;,
+    historyApiFallback: true,
   },
 });
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こうしておくと、&lt;code&gt;/index.html&lt;/code&gt;以外にリクエストが来た場合、404エラーを返す代わりに&lt;code&gt;/index.html&lt;/code&gt;を返してくれるようになる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/11/07/creating-react-redux-app-from-scratch-10/&#34;&gt;次回&lt;/a&gt;はラストで、&lt;a href=&#34;https://webpack.js.org/guides/code-splitting/&#34;&gt;Code Splitting&lt;/a&gt;と&lt;a href=&#34;https://flow.org/&#34;&gt;Flow&lt;/a&gt;と&lt;a href=&#34;https://jestjs.io/ja/&#34;&gt;Jest&lt;/a&gt;と&lt;a href=&#34;https://airbnb.io/enzyme/&#34;&gt;Enzyme&lt;/a&gt;。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>React &#43; Reduxアプリケーションプロジェクトのテンプレートを作る ― その8: Redux-Saga</title>
          <link>https://www.kaitoy.xyz/2018/10/07/creating-react-redux-app-from-scratch-08/</link>
          <pubDate>Sun, 07 Oct 2018 13:26:22 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/10/07/creating-react-redux-app-from-scratch-08/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt;と&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;を学ぶために、開発環境というかプロジェクトテンプレートをスクラッチから作っている。
(最終的な成果は&lt;a href=&#34;https://github.com/kaitoy/react-redux-scaffold&#34;&gt;GitHub&lt;/a&gt;に置いた。)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/10/01/creating-react-redux-app-from-scratch-07/&#34;&gt;前回&lt;/a&gt;は&lt;a href=&#34;https://redux.js.org/basics/usagewithreact&#34;&gt;React Redux&lt;/a&gt;をセットアップした。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;reduxのmiddleware&#34;&gt;ReduxのMiddleware&lt;/h1&gt;

&lt;p&gt;Redux単体では同期的なデータフローしか実装できない。
つまり、Actionを発生させたら、即座にディスパッチされ、stateが更新される。
一方、非同期なフローとは、REST APIを呼んでその結果でstateを更新するような処理。
REST API呼び出しが非同期なわけだが、これをReduxのピュアなフローのどこで実行するのかというと、&lt;a href=&#34;https://redux.js.org/advanced/middleware&#34;&gt;Middleware&lt;/a&gt;で実行する。&lt;/p&gt;

&lt;p&gt;MiddlewareはStoreの&lt;code&gt;dispatch()&lt;/code&gt;をラップして、Actionをトラップして副作用を含む任意の処理をするための機能。
Middlewareの仕組みについては&lt;a href=&#34;https://qiita.com/pirosikick/items/d7f9e5e197a2e8aad62f&#34;&gt;この記事&lt;/a&gt;が分かりやすい。&lt;/p&gt;

&lt;p&gt;Middlewareには例えば、発生したActionの内容と、それによるstateの変化をログに出力する&lt;a href=&#34;https://github.com/evgenyrodionov/redux-logger&#34;&gt;redux-logger&lt;/a&gt;がある。
デバッグに有用そうなので入れておく。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add redux-logger
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;v3.0.6が入った。&lt;/p&gt;

&lt;p&gt;Middlewareは、Reduxの&lt;code&gt;applyMiddleware()&lt;/code&gt;というAPIを使って、&lt;code&gt;createStore()&lt;/code&gt;実行時に適用できる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/configureStore.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;-import { createStore } from &#39;redux&#39;;
+import { createStore, applyMiddleware } from &#39;redux&#39;;
+import { logger } from &#39;redux-logger&#39;;
 import rootReducer from &#39;./reducers/rootReducer&#39;;

 export default function configureStore(initialState = {}) {
+  const middlewares = [];
+  if (process.env.NODE_ENV === `development`) {
+    middlewares.push(logger);
+  }
+
   const store = createStore(
     rootReducer,
     initialState,
+    applyMiddleware(...middlewares),
   );
   return store;
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これだけ。
これで、HOGEボタンをクリックしたときにコンソールに以下のようなログが出るようになる。
(ログは&lt;code&gt;yarn start&lt;/code&gt;とかの開発モードの時だけでる。)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;action HOGE_BUTTON_CLICKED @ 23:19:35.190
 prev state Object { hoge: {…} }
 action Object { type: &amp;quot;HOGE_BUTTON_CLICKED&amp;quot;, payload: undefined }
 next state Object { hoge: {…} }
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;非同期処理&#34;&gt;非同期処理&lt;/h1&gt;

&lt;p&gt;非同期処理をするためのMiddlewareには&lt;a href=&#34;https://github.com/reduxjs/redux-thunk&#34;&gt;redux-thunk&lt;/a&gt;とか&lt;a href=&#34;https://github.com/redux-utilities/redux-promise&#34;&gt;redux-promise&lt;/a&gt;とかがあるけど、なかでもGitHubのスター数が一番多い&lt;a href=&#34;https://redux-saga.js.org/&#34;&gt;Redux Saga&lt;/a&gt;を使うことにする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add redux-saga
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;v0.16.0が入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;因みに次にスター数が多いのがredux-thunkで、これはActionをfunctionオブジェクトで書けるようにするMiddleware。
そのfunctionの中で非同期処理をすることで、非同期なReduxフローを実現できる。
redux-sagaはredux-thunkに比べて以下の特長を持つ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;コールバック地獄に悩まされることが無い&lt;/li&gt;
&lt;li&gt;Actionをプレーン且つピュアに保てるのでテストしやすい&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;redux-sagaの使い方&#34;&gt;Redux Sagaの使い方&lt;/h1&gt;

&lt;p&gt;Redux Sagaでは、非同期処理はSagaというコンポーネントに書く。
Sagaでは、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;ディスパッチされるActionをWatcherが監視し、&lt;/li&gt;
&lt;li&gt;特定のActionが来たらWorkerを起動し、&lt;/li&gt;
&lt;li&gt;Workerが非同期処理などのTaskを実行し、&lt;/li&gt;
&lt;li&gt;その結果を通知するActionをディスパッチする、&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;といった処理を実行する。&lt;/p&gt;

&lt;p&gt;これらの処理は、Saga Middlewareから呼ばれる&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Global_Objects/Generator&#34;&gt;ジェネレータ関数&lt;/a&gt;のなかで、EffectというオブジェクトをSaga Middlewareに返すことで、Saga Middlewareに指示して実行させる。
このEffectを生成する&lt;a href=&#34;https://redux-saga.js.org/docs/api/&#34;&gt;API&lt;/a&gt;がRedux Sagaからいろいろ提供されている。&lt;/p&gt;

&lt;p&gt;上記処理の1~4はそれぞれ以下のAPIで実装できる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;take(pattern)&lt;/code&gt;: ディスパッチされるActionを監視して、&lt;code&gt;pattern&lt;/code&gt;にマッチしたら取得するEffectを生成する。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fork(fn, ...args)&lt;/code&gt;: 渡された関数&lt;code&gt;fn&lt;/code&gt;をノンブロッキングで呼び出すEffectを生成する。&lt;code&gt;fn&lt;/code&gt;はジェネレータか&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Global_Objects/Promise&#34;&gt;Promise&lt;/a&gt;を返す関数。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;call(fn, ...args)&lt;/code&gt;: 渡された関数&lt;code&gt;fn&lt;/code&gt;を同期的に呼び出すEffectを生成する。&lt;code&gt;fn&lt;/code&gt;はジェネレータか&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Global_Objects/Promise&#34;&gt;Promise&lt;/a&gt;を返す関数。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;put(action)&lt;/code&gt;: Actionオブジェクトの&lt;code&gt;action&lt;/code&gt;をディスパッチするEffectを生成する。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;rest-api呼び出し&#34;&gt;REST API呼び出し&lt;/h1&gt;

&lt;p&gt;非同期実行で最もよくあるのがREST API呼び出しであろう。
REST API呼び出し処理は&lt;code&gt;call()&lt;/code&gt;で実行するわけだけど、&lt;code&gt;call()&lt;/code&gt;にはPromiseを返す必要があるので、使うライブラリはそこを考慮しないといけない。&lt;/p&gt;

&lt;p&gt;ざっと調べたところ、&lt;a href=&#34;https://www.npmjs.com/package/axios&#34;&gt;axios&lt;/a&gt;、&lt;a href=&#34;https://www.npmjs.com/package/superagent&#34;&gt;SuperAgent&lt;/a&gt;、&lt;a href=&#34;https://www.npmjs.com/package/r2&#34;&gt;r2&lt;/a&gt;あたりが選択肢。
最も人気のあるaxiosを使うことにする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add axios
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;v0.18.0が入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;REST API呼び出しのコードは&lt;code&gt;src/services/&lt;/code&gt;に置く。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/services/api.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import axios from &#39;axios&#39;;

export const HOGE_URL = &#39;https://httpbin.org/get&#39;;

export function getHoge() {
  return axios.get(HOGE_URL);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;getHoge()&lt;/code&gt;はGETリクエストを送ってPromiseオブジェクトを返す。
このPromiseオブジェクトはレスポンスボディやステータスコードを保持する&lt;a href=&#34;https://github.com/axios/axios#response-schema&#34;&gt;Response&lt;/a&gt;オブジェクトに解決される。&lt;/p&gt;

&lt;h1 id=&#34;rest-api呼び出しを表現するaction&#34;&gt;REST API呼び出しを表現するAction&lt;/h1&gt;

&lt;p&gt;REST API呼び出しをする場合、呼び出し開始、呼び出し成功、呼び出し失敗の3種類のActionで表現するのが一つの&lt;a href=&#34;https://redux.js.org/advanced/asyncactions&#34;&gt;プラクティス&lt;/a&gt;。
これら3種類を、同一のtypeのActionのプロパティ値を変えて表現するやりかたもあるけど、ここでは別々のtypeのアクションとする。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/actions/actionTypes.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; export const HOGE_BUTTON_CLICKED = &#39;HOGE_BUTTON_CLICKED&#39;;
+export const HOGE_FETCH_SUCCEEDED = &#39;HOGE_FETCH_SUCCEEDED&#39;;
+export const HOGE_FETCH_FAILED = &#39;HOGE_FETCH_FAILED&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;src/actions/actions.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import {
   HOGE_BUTTON_CLICKED,
+  HOGE_FETCH_SUCCEEDED,
+  HOGE_FETCH_FAILED,
 } from &#39;./actionTypes&#39;;

 export function hogeButtonClicked(payload) {
   return {
     type: HOGE_BUTTON_CLICKED,
     payload,
   };
 }
+
+export function hogeFetchSucceeded(payload, meta) {
+  return {
+    type: HOGE_FETCH_SUCCEEDED,
+    payload,
+    meta,
+  };
+}
+
+export function hogeFetchFailed(payload) {
+  return {
+    type: HOGE_FETCH_FAILED,
+    error: true,
+    payload,
+  };
+}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;sagaの実装&#34;&gt;Sagaの実装&lt;/h1&gt;

&lt;p&gt;Sagaのソースは&lt;code&gt;src/sagas/&lt;/code&gt;に置く。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;HOGE_BUTTON_CLICKED&lt;/code&gt;が来たら&lt;code&gt;getHoge()&lt;/code&gt;を実行するSagaは以下のような感じ。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/sagas/hoge.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { call, fork, put, take } from &#39;redux-saga/effects&#39;;
import { getHoge } from &#39;../services/apis&#39;;
import { HOGE_BUTTON_CLICKED } from &#39;../actions/actionTypes&#39;;
import { hogeFetchSucceeded, hogeFetchFailed } from &#39;../actions/actions&#39;;

// Task
function* fetchHoge() {
  try {
    const response = yield call(getHoge);
    const payload = response.data;
    const meta = { statusCode: response.status, statusText: response.statusText };
    yield put(hogeFetchSucceeded(payload, meta));
  } catch (ex) {
    yield put(hogeFetchFailed(ex));
  }
}

// Watcher
export function* watchHogeButtonClicked(): Generator&amp;lt;any, void, Object&amp;gt; {
  while (true) {
    const action = yield take(HOGE_BUTTON_CLICKED);
    yield fork(fetchHoge, action); // actionはfetchHogeの引数に渡される。使ってないけど…
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Watcherは&lt;code&gt;take&lt;/code&gt;して&lt;code&gt;fork&lt;/code&gt;するのを無限ループで回すのが常なので、これをもうちょっときれいに書けるAPIが用意されていて、以下のように書ける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { takeEvery } from &#39;redux-saga/effects&#39;

// Watcher
export function* watchHogeButtonClicked(): Generator&amp;lt;any, void, Object&amp;gt; {
  yield takeEvery(HOGE_BUTTON_CLICKED, fetchHoge)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この場合、&lt;code&gt;fetchHoge()&lt;/code&gt;の最後の引数に&lt;code&gt;take&lt;/code&gt;したActionオブジェクトが渡される。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、今後Watcherはモジュールを分けていくつも書いていくことになるので、それらをまとめて起動するためのモジュール&lt;code&gt;rootSaga.js&lt;/code&gt;を作って、そこで各Watcherを&lt;code&gt;import&lt;/code&gt;して&lt;code&gt;call()&lt;/code&gt;したい。
&lt;code&gt;call()&lt;/code&gt;はブロッキングなAPIなので、パラレルに実行するために&lt;code&gt;all()&lt;/code&gt;を使う。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/sagas/rootSaga.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { call, all } from &#39;redux-saga/effects&#39;;
import { watchHogeButtonClicked } from &#39;./hoge&#39;;

export default function* rootSaga() {
  yield all([
    call(watchHogeButtonClicked),
    // call(watchAnotherAction),
    // call(watchYetAnotherAction),
  ]);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そもそもブロッキングな&lt;code&gt;call()&lt;/code&gt;を使うのがだめなので、代わりに&lt;code&gt;fork()&lt;/code&gt;を使ってもいい。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/sagas/rootSaga.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { fork } from &#39;redux-saga/effects&#39;;
import { watchHogeButtonClicked } from &#39;./hoge&#39;;

export default function* rootSaga() {
  yield fork(watchHogeButtonClicked);
  // yield fork(watchAnotherAction);
  // yield fork(watchYetAnotherAction);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;どっちがいいんだろう。&lt;/p&gt;

&lt;h1 id=&#34;saga-middlewareの追加と起動&#34;&gt;Saga Middlewareの追加と起動&lt;/h1&gt;

&lt;p&gt;Saga Middlewareは以下のように追加して起動する。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/configureStore.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import { createStore, applyMiddleware } from &#39;redux&#39;;
+import createSagaMiddleware from &#39;redux-saga&#39;;
 import { logger } from &#39;redux-logger&#39;;
+import rootSaga from &#39;./sagas/rootSaga&#39;;
 import rootReducer from &#39;./reducers/rootReducer&#39;;

+const sagaMiddleware = createSagaMiddleware();

 export default function configureStore(initialState = {}) {
   const middlewares = [];
   if (process.env.NODE_ENV === `development`) {
     middlewares.push(logger);
   }
+  middlewares.push(sagaMiddleware);

   const store = createStore(
     rootReducer,
     initialState,
     applyMiddleware(...middlewares),
   );
+  sagaMiddleware.run(rootSaga);
   return store;
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/11/02/creating-react-redux-app-from-scratch-09/&#34;&gt;次回&lt;/a&gt;は&lt;a href=&#34;https://reacttraining.com/react-router/&#34;&gt;React Router&lt;/a&gt;。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>React &#43; Reduxアプリケーションプロジェクトのテンプレートを作る ― その7: React Redux</title>
          <link>https://www.kaitoy.xyz/2018/10/01/creating-react-redux-app-from-scratch-07/</link>
          <pubDate>Mon, 01 Oct 2018 07:54:53 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/10/01/creating-react-redux-app-from-scratch-07/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt;と&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;を学ぶために、開発環境というかプロジェクトテンプレートをスクラッチから作っている。
(最終的な成果は&lt;a href=&#34;https://github.com/kaitoy/react-redux-scaffold&#34;&gt;GitHub&lt;/a&gt;に置いた。)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/09/26/creating-react-redux-app-from-scratch-06/&#34;&gt;前回&lt;/a&gt;はReduxをセットアップした。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;react-redux&#34;&gt;React Redux&lt;/h1&gt;

&lt;p&gt;前回はReduxをセットアップして、ActionをStoreにディスパッチしてstateを更新できるようになった。
今回はこれをReactにつなぐ。&lt;/p&gt;

&lt;p&gt;使うのは&lt;a href=&#34;https://redux.js.org/basics/usagewithreact&#34;&gt;React Redux&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add react-redux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;v5.0.7が入った。&lt;/p&gt;

&lt;h1 id=&#34;presentational-components-と-container-components&#34;&gt;Presentational Components と Container Components&lt;/h1&gt;

&lt;p&gt;React Reduxの使い方を理解するには、&lt;a href=&#34;https://medium.com/@dan_abramov/smart-and-dumb-components-7ca2f9a7c7d0&#34;&gt;Presentational Components と Container Components&lt;/a&gt; という概念を知らないといけない。
これはReactコンポーネントを役割別に分ける考え方で、それぞれ以下のような特徴をもつ。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Presentational Components&lt;/th&gt;
&lt;th&gt;Container Components&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;主な役割&lt;/td&gt;
&lt;td&gt;DOMをレンダリングする&lt;/td&gt;
&lt;td&gt;データを取得したりstateを更新したりする(Reduxとつなぐ)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Reduxとの関連&lt;/td&gt;
&lt;td&gt;無し&lt;/td&gt;
&lt;td&gt;有り&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;データの読み込み&lt;/td&gt;
&lt;td&gt;propsから読む&lt;/td&gt;
&lt;td&gt;Reduxのstateオブジェクトから読む&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;データの更新&lt;/td&gt;
&lt;td&gt;propsで渡されたコールバックを呼ぶ&lt;/td&gt;
&lt;td&gt;ReduxのActionをディスパッチする&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;作り方&lt;/td&gt;
&lt;td&gt;自前で書く&lt;/td&gt;
&lt;td&gt;React Reduxで生成する&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;要するに、普通にReactで作ったUIコンポーネントを、React Reduxで生成するContainer ComponentでラップしてやることでReduxのStoreとつなぐことができる。&lt;/p&gt;

&lt;h1 id=&#34;connect&#34;&gt;connect()&lt;/h1&gt;

&lt;p&gt;Container Componentの生成にはReact Reduxの&lt;a href=&#34;https://github.com/reduxjs/react-redux/blob/master/docs/api.md#connectmapstatetoprops-mapdispatchtoprops-mergeprops-options&#34;&gt;connect()&lt;/a&gt;というAPIを使う。&lt;/p&gt;

&lt;p&gt;React Reduxを使う場合、Reduxのstateの更新に応じてReactコンポーネントに新しいpropsを渡して再レンダリングすることになるが、この新しいpropsを作ってコンポーネントに渡す処理を定義するのが&lt;code&gt;connect()&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;connect()&lt;/code&gt;の第一引数には、ReduxのstateのプロパティとReactコンポーネントのpropsのプロパティとのマッピングをする関数である&lt;code&gt;mapStateToProps()&lt;/code&gt;を渡す。
&lt;code&gt;mapStateToProps()&lt;/code&gt;はstateの更新に応じて呼び出され、引数にstate(と現在のprops)が渡される。
&lt;code&gt;mapStateToProps()&lt;/code&gt;が返すオブジェクトはReactコンポーネントに渡されるpropsにマージされる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;connect()&lt;/code&gt;の第二引数には、Storeの&lt;code&gt;dispatch()&lt;/code&gt;を呼び出す処理とReactコンポーネントのpropsのプロパティとのマッピングをする関数である&lt;code&gt;mapDispatchToProps()&lt;/code&gt;を渡す。
&lt;code&gt;mapDispatchToProps()&lt;/code&gt;の引数には&lt;code&gt;dispatch()&lt;/code&gt;が渡される。
&lt;code&gt;mapDispatchToProps()&lt;/code&gt;が返すオブジェクトはReactコンポーネントに渡されるpropsにマージされる。&lt;/p&gt;

&lt;p&gt;(&lt;code&gt;mapDispatchToProps()&lt;/code&gt;は第二引数に&lt;code&gt;props&lt;/code&gt;を受け取ることもできて、この場合、propsの更新に反応して呼び出されるコールバックになる。)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;connect()&lt;/code&gt;を実行すると関数が返ってくる。
この関数にReactコンポーネント(Presentational Component)を渡して実行すると、Storeに接続されたReactコンポーネント(Container Component)が返ってくる。&lt;/p&gt;

&lt;h2 id=&#34;connect-の使い方&#34;&gt;connect()の使い方&lt;/h2&gt;

&lt;p&gt;前回作ったStoreをHOGEボタン(これはPresentational Component)につなげるContainer Componentを書いてみる。
Container Componentのソースは&lt;code&gt;src/containers/&lt;/code&gt;に入れる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/containers/HogeButton.jsx&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import React from &#39;react&#39;;
import Button from &#39;@material-ui/core/Button&#39;;
import { connect } from &#39;react-redux&#39;;
import { hogeButtonClicked } from &#39;../actions/actions&#39;;

function mapStateToProps(state) {
  return {
    clicked: state.hoge.clicked
  };
}

function mapDispatchToProps(dispatch) {
  return {
    onClick: function() {
      dispatch(hogeButtonClicked());
    }
  };
}

const HogeButton = connect(
  mapStateToProps,
  mapDispatchToProps,
)(Button);

export default HogeButton;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じ。&lt;/p&gt;

&lt;p&gt;HOGEボタンをクリックすると、以下の流れで状態が遷移する。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;hogeButtonClicked()&lt;/code&gt;が呼ばれて&lt;code&gt;HOGE_BUTTON_CLICKED&lt;/code&gt;アクションが生成されてdispatchされる。&lt;/li&gt;
&lt;li&gt;Storeの中で&lt;code&gt;state.hoge.clicked&lt;/code&gt;が更新される。&lt;/li&gt;
&lt;li&gt;stateの更新に反応して&lt;code&gt;mapStateToProps()&lt;/code&gt;が呼び出され、その戻り値がpropsにマージされる。&lt;/li&gt;
&lt;li&gt;新しいpropsを使って、新たにHOGEボタンがレンダリングされる。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;connect-のシンプルな書き方&#34;&gt;connect()のシンプルな書き方&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;mapDispatchToProps&lt;/code&gt;は実はプレーンオブジェクトでもいい。
この場合、オブジェクトのキーと値はそれぞれ、propsのプロパティ名とAction Creatorにする。
(Action Creatorは&lt;code&gt;connect()&lt;/code&gt;が&lt;code&gt;dispatch()&lt;/code&gt;でラップしてくれる。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const mapDispatchToProps ⁼ {
  onClick: hogeButtonClicked,
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;また、&lt;code&gt;mapStateToProps&lt;/code&gt;と&lt;code&gt;mapDispatchToProps&lt;/code&gt;はexportするわけでも再利用するわけでもないので、&lt;code&gt;connect()&lt;/code&gt;の中に直接書いてしまってもいい。
この場合、&lt;code&gt;mapStateToProps&lt;/code&gt;はアロー関数で書いて、&lt;code&gt;return&lt;/code&gt;は省略してしまうのがいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const HogeButton = connect(
  (state) =&amp;gt; ({
    clicked: state.hoge.clicked
  }),
  {
    onClick: hogeButtonClicked,
  },
)(Button);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;さらに、&lt;code&gt;mapStateToProps&lt;/code&gt;が受け取る&lt;code&gt;state&lt;/code&gt;は、&lt;code&gt;hoge&lt;/code&gt;プロパティしか興味ないので、オブジェクト分割代入をするのがいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const HogeButton = connect(
  ({hoge}) =&amp;gt; ({
    clicked: hoge.clicked
  }),
  {
    onClick: hogeButtonClicked,
  },
)(Button);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;まとめると、以下のように書けるということ。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/containers/HogeButton.jsx&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import React from &#39;react&#39;;
import Button from &#39;@material-ui/core/Button&#39;;
import { connect } from &#39;react-redux&#39;;
import { hogeButtonClicked } from &#39;../actions/actions&#39;;

const HogeButton = connect(
  ({hoge}) =&amp;gt; ({
    clicked: hoge.clicked
  }),
  {
    onClick: hogeButtonClicked,
  },
)(Button);

export default HogeButton;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;参考: &lt;a href=&#34;https://qiita.com/taneba/items/4d45d1075137a7dae10e&#34;&gt;シンプルなreact-reduxのconnectの書き方&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;reselect&#34;&gt;reselect&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;mapStateToProps&lt;/code&gt;はstateが更新されるたびに呼ばれるので、中で複雑な計算してたりするとアプリ全体のパフォーマンスに影響を与える。&lt;/p&gt;

&lt;p&gt;このような問題に対応するため、stateの特定のサブツリーが更新された時だけ&lt;code&gt;mapStateToProps&lt;/code&gt;の先の計算を実行できるようにするライブラリがある。
それが&lt;a href=&#34;https://github.com/reduxjs/reselect&#34;&gt;relesect&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;reselectは重要なライブラリだとは思うけど、とりあえずほって先に進む。&lt;/p&gt;

&lt;h1 id=&#34;hogebuttonのアプリへの組み込み&#34;&gt;HogeButtonのアプリへの組み込み&lt;/h1&gt;

&lt;p&gt;作ったHogeButtonは、普通のコンポーネントと同じように使える。&lt;/p&gt;

&lt;p&gt;components/App.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
 import styled from &#39;styled-components&#39;;
-import Button from &#39;@material-ui/core/Button&#39;;
+import HogeButton from &#39;../containers/HogeButton&#39;;

 const Wrapper = styled.div`
   font-size: 5rem;
 `;

 const App = () =&amp;gt; (
   &amp;lt;Wrapper&amp;gt;
-    &amp;lt;Button variant=&amp;quot;contained&amp;quot;&amp;gt;
+    &amp;lt;HogeButton variant=&amp;quot;contained&amp;quot;&amp;gt;
       HOGE
-    &amp;lt;/Button&amp;gt;
+    &amp;lt;/HogeButton&amp;gt;
   &amp;lt;/Wrapper&amp;gt;
 );

 export default App;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;provider&#34;&gt;Provider&lt;/h1&gt;

&lt;p&gt;全てのContainer ComponentsがReduxのStoreの変更をサブスクライブする必要があるので、それらに&lt;a href=&#34;https://redux.js.org/basics/usagewithreact#passing-the-store&#34;&gt;Storeを渡してやらないといけない&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;Storeをpropsに渡して、子コンポーネントにバケツリレーさせたりして行きわたらせることも可能だけど面倒すぎる。
ので、React Reduxがもっと簡単にやる仕組みを提供してくれている。
それが&lt;a href=&#34;https://github.com/reduxjs/react-redux/blob/master/docs/api.md#provider&#34;&gt;Provider&lt;/a&gt;というコンポーネント。&lt;/p&gt;

&lt;p&gt;Providerの子コンポーネントはStoreにアクセスして&lt;code&gt;connect()&lt;/code&gt;を使えるようになる。
ざっくり全体をProviderで囲ってやるのがいい。&lt;/p&gt;

&lt;p&gt;src/index.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
 import ReactDOM from &#39;react-dom&#39;;
+import { Provider } from &#39;react-redux&#39;;
 import App from &#39;./components/App&#39;;
+import configureStore from &#39;./configureStore&#39;;
 import &#39;./fonts.css&#39;;

+const store = configureStore();
 const root = document.getElementById(&#39;root&#39;);

 if (root) {
   ReactDOM.render(
-    &amp;lt;App /&amp;gt;,
+    &amp;lt;Provider store={store}&amp;gt;
+      &amp;lt;App /&amp;gt;
+    &amp;lt;/Provider&amp;gt;,
     root,
   );
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/10/07/creating-react-redux-app-from-scratch-08/&#34;&gt;次回&lt;/a&gt;は、ReduxにMiddlewareを追加して、非同期処理を実装する。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>React &#43; Reduxアプリケーションプロジェクトのテンプレートを作る ― その6: Redux</title>
          <link>https://www.kaitoy.xyz/2018/09/26/creating-react-redux-app-from-scratch-06/</link>
          <pubDate>Wed, 26 Sep 2018 23:03:04 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/09/26/creating-react-redux-app-from-scratch-06/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt;と&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;を学ぶために、開発環境というかプロジェクトテンプレートをスクラッチから作っている。
(最終的な成果は&lt;a href=&#34;https://github.com/kaitoy/react-redux-scaffold&#34;&gt;GitHub&lt;/a&gt;に置いた。)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/09/06/creating-react-redux-app-from-scratch-05/&#34;&gt;前回&lt;/a&gt;はMaterial-UIをセットアップした。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;reactの状態管理&#34;&gt;Reactの状態管理&lt;/h1&gt;

&lt;p&gt;Reactによるプログラミングをするとき、小さいUIコンポーネントをたくさん作って、それらを組み合わせてVirtual DOMツリーを作っておいて、そこにpropsをほうりこんでレンダリングする、という感じになる。
また、レンダリングした後はコンポーネントのstateをいじって状態を変化させる。&lt;/p&gt;

&lt;p&gt;このpropsやstateの扱いをReactの状態管理という。
propsやstateを適当にアドホックに設定してると、結局jQuery使ってるのとそんなに変わらなくなって辛くなるので、Reactの開発元であるFacebookは&lt;a href=&#34;https://facebook.github.io/flux/&#34;&gt;Flux&lt;/a&gt;というアーキテクチャを提案している。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/facebook/flux/raw/master/docs/img/flux-diagram-white-background.png&#34; alt=&#34;Flux&#34; title=&#34;Flux&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Fluxでは、単一の(またはドメイン毎くらいの単位の)オブジェクトでアプリケーション全体の状態(state)を表し、これをStoreに保持する。
ReactはStoreが保持するstateを受け取り、それをもとにViewをレンダリングする。
Viewに対するユーザの操作(など)はActionというオブジェクトで表現され、Dispatcherに渡され、Dispatcherに登録されたcallbackを通してstateを変化させる。&lt;/p&gt;

&lt;p&gt;データが常に一方向に流れて見通しがよく、各コンポーネントの独立性が高いのが特徴。
各コンポーネントは、受け取ったデータをピュアに処理すればよく、リアクティブにファンクショナルに実装できる。&lt;/p&gt;

&lt;h1 id=&#34;redux&#34;&gt;Redux&lt;/h1&gt;

&lt;p&gt;Fluxの実装、というか発展形がRedux。&lt;/p&gt;

&lt;p&gt;ReduxではFluxのDispatcher辺りがReducerに置き換わっている。
ReducerはActionと現在のstateから次のstateを計算する純粋関数。&lt;/p&gt;

&lt;p&gt;また、ReduxからはViewが切り離されていて、Actionによってstateを更新する状態管理ライブラリの役割に徹している。
ReactコンポーネントのイベントハンドラからActionオブジェクトを生成したり、更新したstateをReactに渡したりするつなぎ目は、別途&lt;a href=&#34;https://github.com/reduxjs/react-redux&#34;&gt;React Redux&lt;/a&gt;というライブラリが担当する。&lt;/p&gt;

&lt;p&gt;ReduxとReact Reduxについては、Qiitaの「&lt;a href=&#34;https://qiita.com/mpyw/items/a816c6380219b1d5a3bf&#34;&gt;たぶんこれが一番分かりやすいと思います React + Redux のフロー図解&lt;/a&gt;」という記事が分かりやすい。&lt;/p&gt;

&lt;p&gt;今回はReduxを導入する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add redux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Redux v4.0.0が入った。&lt;/p&gt;

&lt;p&gt;以降、現時点で唯一のUIコンポーネントであるHOGEボタンの状態管理を実装してみる。&lt;/p&gt;

&lt;h2 id=&#34;action&#34;&gt;Action&lt;/h2&gt;

&lt;p&gt;まず&lt;a href=&#34;https://redux.js.org/basics/actions&#34;&gt;Action&lt;/a&gt;を実装する。&lt;/p&gt;

&lt;p&gt;Actionオブジェクトはどんな形式でもいいけど、普通は&lt;a href=&#34;https://github.com/redux-utilities/flux-standard-action&#34;&gt;Flux Standard Action&lt;/a&gt;(FSA)にする。
FSAは以下のプロパティを持つプレーンオブジェクト。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;type: Action種別を示す文字列定数。必須。&lt;/li&gt;
&lt;li&gt;payload: Actionの情報を示す任意の型の値。任意。&lt;/li&gt;
&lt;li&gt;error: Actionがエラーを表すものかを示す boolean プロパティ。エラーなら true にして、payload にエラーオブジェクトをセットする。任意。&lt;/li&gt;
&lt;li&gt;meta: その他の情報を入れる任意の型の値。任意。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Actionのコードは、Actionのtypeに入れる値を定義する&lt;code&gt;actionTypes.js&lt;/code&gt;と、Action Creator(i.e. Actionオブジェクトを生成する関数)を定義する&lt;code&gt;actions.js&lt;/code&gt;からなり、ともに&lt;code&gt;src/actions/&lt;/code&gt;に置く。&lt;/p&gt;

&lt;p&gt;HOGEボタンをクリックしたときのAction、&lt;code&gt;HOGE_BUTTON_CLICKED&lt;/code&gt;を定義してみる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/actions/actionTypes.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;export const HOGE_BUTTON_CLICKED = &#39;HOGE_BUTTON_CLICKED&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;src/actions/actions.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import {
  HOGE_BUTTON_CLICKED,
} from &#39;./actionTypes&#39;;

export function hogeButtonClicked(payload) {
  return {
    type: HOGE_BUTTON_CLICKED,
    payload,
  };
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じ。&lt;/p&gt;

&lt;h2 id=&#34;reducer&#34;&gt;Reducer&lt;/h2&gt;

&lt;p&gt;次は&lt;a href=&#34;https://redux.js.org/basics/reducers&#34;&gt;Reducer&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;Reducerは、上記Action Creatorが生成するActionオブジェクトに対応して起動し、Store(後述)から現在のstateオブジェクトを受け取って、Actionオブジェクトのpayloadの値(など)に応じて新しいstateオブジェクトを作る。&lt;/p&gt;

&lt;p&gt;Reducerを書く前に、stateオブジェクトの構造を設計しておくことが推奨されている。
UIコンポーネント毎にプロパティを分けて、コンポーネント構造と同様の階層構造にしておけばだいたいよさそう。&lt;/p&gt;

&lt;p&gt;HOGEボタンに一つ、クリックしたかどうかの状態(&lt;code&gt;clicked&lt;/code&gt;)を持たせるとすると、stateオブジェクトは以下のようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;{
  hoge: {
    clicked: false,
  },
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Reducerはピュアじゃないといけないので、内部で&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E5%89%AF%E4%BD%9C%E7%94%A8_(%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0&#34;&gt;副作用&lt;/a&gt;を起こしてはいけない。
副作用とは、具体的には以下のようなもの。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;引数で与えられたオブジェクトを変更する。&lt;/li&gt;
&lt;li&gt;REST APIへのリクエストを送る。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(ログの出力も厳密には副作用なんだろうけど、それは許されてる気がする。)&lt;/p&gt;

&lt;p&gt;また、ピュアであるためには&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E5%8F%82%E7%85%A7%E9%80%8F%E9%81%8E%E6%80%A7&#34;&gt;参照透過性&lt;/a&gt;を持たないといけなくて、つまり同じ引数に対しては同じ戻り値を返さないといけないので、内部で&lt;code&gt;Date.now()&lt;/code&gt;とか&lt;code&gt;Math.random()&lt;/code&gt;とかを呼ぶのもダメ。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Reducerのコードは&lt;code&gt;src/reducers/&lt;/code&gt;に置く。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;HOGE_BUTTON_CLICKED&lt;/code&gt;が発生したら、&lt;code&gt;hoge&lt;/code&gt;の&lt;code&gt;clicked&lt;/code&gt;を&lt;code&gt;true&lt;/code&gt;にするReducer(&lt;code&gt;hoge()&lt;/code&gt;)は以下の感じに書ける。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/reducers/reducers.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { HOGE_BUTTON_CLICKED } from &#39;../actions/actionTypes&#39;;

const initialState = {
  hoge: {
    clicked: false,
  },
};

export function hoge(state = initialState, action) {
  switch (action.type) {
    case HOGE_BUTTON_CLICKED:
      const newHoge = {
        hoge: {
          clicked: true,
        },
      };
      return Object.assign({}, state, newHoge);
    default:
      return state;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;hoge()&lt;/code&gt;のポイントはたくさんある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;state&lt;/code&gt;と&lt;code&gt;action&lt;/code&gt;を引数に取る。前者が現在の状態を表すstateオブジェクトで、後者がActionオブジェクト。&lt;/li&gt;
&lt;li&gt;戻り値は新しい状態を表すstateオブジェクト。&lt;/li&gt;
&lt;li&gt;actionオブジェクトはどのActionを表すものかは分からないので、&lt;code&gt;action.type&lt;/code&gt;を見て&lt;code&gt;HOGE_BUTTON_CLICKED&lt;/code&gt;だけを処理するようにする。

&lt;ul&gt;
&lt;li&gt;知らないActionだったら(i.e. &lt;code&gt;default&lt;/code&gt;句のなかに来たら)、受け取ったstateオブジェクトをそのまま返す。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;アプリケーションの初期化時には&lt;code&gt;state&lt;/code&gt;に&lt;code&gt;undefined&lt;/code&gt;が渡されるので、それに備え、初期状態である&lt;code&gt;initialState&lt;/code&gt;をデフォルト引数に設定する。&lt;/li&gt;
&lt;li&gt;渡されたstateオブジェクトを変更してはいけないので、&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Global_Objects/Object/assign&#34;&gt;Object.assgin()&lt;/a&gt;に空オブジェクト&lt;code&gt;{}&lt;/code&gt;とともに&lt;code&gt;state&lt;/code&gt;を渡してコピーする。

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Object.assgin()&lt;/code&gt;の代わりに&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment#%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E3%81%AE%E5%88%86%E5%89%B2%E4%BB%A3%E5%85%A5&#34;&gt;オブジェクト分割代入&lt;/a&gt;を使う方法も&lt;a href=&#34;https://redux.js.org/recipes/usingobjectspreadoperator&#34;&gt;ある&lt;/a&gt;。この場合&lt;a href=&#34;https://babeljs.io/docs/en/babel-plugin-transform-object-rest-spread&#34;&gt;babel-plugin-transform-object-rest-spread&lt;/a&gt;が必要。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Object.assign()&lt;/code&gt;の第三引数に&lt;code&gt;newHoge&lt;/code&gt;で上書きするようにしている。

&lt;ul&gt;
&lt;li&gt;今はstateオブジェクトのプロパティが&lt;code&gt;hoge&lt;/code&gt;一つだけなので単に&lt;code&gt;newHoge&lt;/code&gt;をreturnしても結果は一緒。なので無駄なことをしてるようにも見えるけど、stateオブジェクトのプロパティが増えた場合に&lt;code&gt;hoge&lt;/code&gt;以外に影響を与えないための計らい。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これはこれでいい感じに見えるけど、&lt;code&gt;hoge()&lt;/code&gt;が&lt;code&gt;hoge&lt;/code&gt;プロパティしか扱わないのに、stateオブジェクト全体を渡しているのがイケていない。
(まあ今はstateオブジェクトには&lt;code&gt;hoge&lt;/code&gt;プロパティしかないんだけど、他のプロパティが色々増えてくるとイケてない感が高まる。)
&lt;code&gt;hoge&lt;/code&gt;プロパティがstateオブジェクト構造のどこにあるかを&lt;code&gt;hoge()&lt;/code&gt;が気にしないといけないのもイケてない。
&lt;code&gt;hoge()&lt;/code&gt;には&lt;code&gt;hoge&lt;/code&gt;プロパティだけを見てほしい。&lt;/p&gt;

&lt;p&gt;ということで、普通はReducerは分割して書いて、それぞれのReducerにstateオブジェクトを分割して渡してやる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/reducers/reducers.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import { HOGE_BUTTON_CLICKED } from &#39;../actions/actionTypes&#39;;

-const initialState = {
-  hoge: {
-    clicked: false,
-  },
-};

-export function hoge(state = initialState, action) {
+export function hoge(state = { clicked: false }, action) {
   switch (action.type) {
     case HOGE_BUTTON_CLICKED:
       const newHoge = {
-        hoge: {
-          clicked: true,
-        },
+        clicked: true,
       };
       return Object.assign({}, state, newHoge);
     default:
       return state;
   }
 }

+export function rootReducer(state = {}, action) {
+  return {
+    hoge: hoge(state.hoge, action),
+  }
+}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じで、&lt;code&gt;rootReducer()&lt;/code&gt;がstateオブジェクトを分割して子Reducerを呼び出す。
孫Reducerとか曾孫Reducerとかがあってもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;rootReducer()&lt;/code&gt;は別のファイルに書くと見やすくなるし、Reduxの&lt;a href=&#34;https://redux.js.org/api/combinereducers&#34;&gt;combineReducers()&lt;/a&gt;というヘルパー関数を使うともっと楽に書ける。
上記&lt;code&gt;reducers.js&lt;/code&gt;からは&lt;code&gt;rootReducer()&lt;/code&gt;を削除して、&lt;code&gt;rootReducer.js&lt;/code&gt;に以下のように書く。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/reducers/rootReducer.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { combineReducers } from &#39;redux&#39;;
import hoge from &#39;./reducers&#39;;

const rootReducer = combineReducers({
  hoge,
});
export default rootReducer;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このように&lt;code&gt;combineReducers()&lt;/code&gt;で作った&lt;code&gt;rootReducer&lt;/code&gt;は、上で自前で書いた&lt;code&gt;rootReducer&lt;/code&gt;と全く同じ動きをする。&lt;/p&gt;

&lt;p&gt;さらに簡単に、以下のようにも書ける。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/reducers/rootReducer.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { combineReducers } from &#39;redux&#39;;
import * as reducers from &#39;./reducers&#39;;

const rootReducer = combineReducers(reducers);
export default rootReducer;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こうしておけば、Reducerの追加は&lt;code&gt;reducers.js&lt;/code&gt;に関数を追加するだけでよくなる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/redux-utilities/redux-actions&#34;&gt;redux-actions&lt;/a&gt;を使うとさらに記述を簡略化できるみたいだけど、逆に何が何だか分からなくなりそうだったので、慣れるまでは使わないでおく。&lt;/p&gt;

&lt;h2 id=&#34;store&#34;&gt;Store&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://redux.js.org/basics/store&#34;&gt;Store&lt;/a&gt;は以下のような特徴を持つオブジェクト。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;getState()&lt;/code&gt;でstateオブジェクトを返す。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dispatch(action)&lt;/code&gt;でActionをディスパッチできる。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;subscribe(listener)&lt;/code&gt;でActionのディスパッチをサブスクライブできる。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;StoreはrootReducerを&lt;a href=&#34;https://redux.js.org/api/createstore&#34;&gt;createStore()&lt;/a&gt;に渡すことで作れる。
&lt;code&gt;createStore()&lt;/code&gt;を呼ぶコードはモジュールにしておくのがいい。
後で膨らんでくるので。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/configureStore.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { createStore } from &#39;redux&#39;;
import rootReducer from &#39;./reducers/rootReducer&#39;;

export default function configureStore(initialState = {}) {
  const store = createStore(
    rootReducer,
    initialState,
  );
  return store;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これだけ。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でReduxのコンポーネントが一通りそろって、状態管理システムができた。
試しに動かしてみる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/try.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { hogeButtonClicked } from &#39;./actions/actions&#39;;
import configureStore from &#39;./configureStore&#39;;

const store = configureStore();
console.log(store.getState()); // =&amp;gt; { hoge: {clicked: false} }

store.subscribe(() =&amp;gt; {
  console.log(store.getState());
});

store.dispatch(hogeButtonClicked()); // =&amp;gt; { hoge: {clicked: true} }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;store.dispatch()&lt;/code&gt;するとReducer(&lt;code&gt;hoge()&lt;/code&gt;)が実行され、stateオブジェクトが更新されることが分かる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/10/01/creating-react-redux-app-from-scratch-07/&#34;&gt;次回&lt;/a&gt;は、今回作ったStoreをReactコンポーネントにつなぐ。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>React &#43; Reduxアプリケーションプロジェクトのテンプレートを作る ― その5: Material-UIとWebフォント</title>
          <link>https://www.kaitoy.xyz/2018/09/06/creating-react-redux-app-from-scratch-05/</link>
          <pubDate>Thu, 06 Sep 2018 23:33:31 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/09/06/creating-react-redux-app-from-scratch-05/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt;と&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;を学ぶために、開発環境というかプロジェクトテンプレートをスクラッチから作っている。
(最終的な成果は&lt;a href=&#34;https://github.com/kaitoy/react-redux-scaffold&#34;&gt;GitHub&lt;/a&gt;に置いた。)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/29/creating-react-redux-app-from-scratch-04/&#34;&gt;前回&lt;/a&gt;はCSS周りの処理系をセットアップした。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;既成reactコンポーネント&#34;&gt;既成Reactコンポーネント&lt;/h1&gt;

&lt;p&gt;前回まででHTMLもCSSもReactコンポーネント単位で書けるようになったんだけど、実際、自分で1からコンポーネントを書くのは、特にデザインセンスがない人にとっては辛い。
かっこいいUIコンポーネントを作りたいならデザイナーの協力が必要だけど、個人の開発などそれができない状況も多い。&lt;/p&gt;

&lt;p&gt;という問題を抱えた人たち向けなのかはわからないが、既成のReactコンポーネントセットが色々OSSで提供されている。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://material-ui.com/&#34;&gt;Material-UI&lt;/a&gt;: Googleの&lt;a href=&#34;https://material.io/design/&#34;&gt;マテリアルデザイン&lt;/a&gt;のReact実装。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://react.semantic-ui.com/&#34;&gt;Semantic UI React&lt;/a&gt;: &lt;a href=&#34;https://semantic-ui.com/&#34;&gt;Semantic UI&lt;/a&gt;のReactバインディング。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ant.design/docs/react/introduce&#34;&gt;antd&lt;/a&gt;: &lt;a href=&#34;https://ant.design/&#34;&gt;Ant Design&lt;/a&gt;のReact実装。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blueprintjs.com/&#34;&gt;Blueprint&lt;/a&gt;: 複雑でデータ量の多いUI向けに作られたReact UIツールキット。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://react-bootstrap.github.io/&#34;&gt;React-Bootstrap&lt;/a&gt;: &lt;a href=&#34;https://getbootstrap.com/&#34;&gt;Bootstrap&lt;/a&gt;のReactバインディング。現時点ではv4未対応。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://grommet.io/&#34;&gt;Grommet&lt;/a&gt;: HPEによるエンタープライズレディなデザインシステム。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/fabric#/components&#34;&gt;Office UI Fabric React&lt;/a&gt;: OfficeなどのMicrosoft製品に使われているReactコンポーネントセット。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今回はこの中でも圧倒的に人気なMaterial-UIを導入する。&lt;/p&gt;

&lt;h1 id=&#34;material-ui&#34;&gt;Material-UI&lt;/h1&gt;

&lt;p&gt;Material-UIは簡単に使える。
とりあえずコアパッケージをインストールする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add @material-ui/core
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;v1.4.1が入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あとはパッケージに入っている色々なコンポーネントをMaterial-UIのドキュメント見ながら使えばいいだけ。&lt;/p&gt;

&lt;p&gt;components/App.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
 import styled from &#39;styled-components&#39;;
+import Button from &#39;@material-ui/core/Button&#39;;

 const Wrapper = styled.div`
   font-size: 5rem;
 `;

 const App = () =&amp;gt; (
   &amp;lt;Wrapper&amp;gt;
-    HOGE
+    &amp;lt;Button variant=&amp;quot;contained&amp;quot;&amp;gt;
+      HOGE
+    &amp;lt;/Button&amp;gt;
   &amp;lt;/Wrapper&amp;gt;
 );

 export default App;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これでただのテキストがボタンになった。&lt;/p&gt;

&lt;h1 id=&#34;css-web-fonts&#34;&gt;CSS Web Fonts&lt;/h1&gt;

&lt;p&gt;前節でいちおうMaterial-UI使えたけど、フォントをケアしてやるともう少しかっこよくなる。
Material-UIは&lt;a href=&#34;https://fonts.google.com/specimen/Roboto&#34;&gt;Robotoフォント&lt;/a&gt;を想定して作られているが、これはブラウザにデフォルトで入ってはいないので、そのままだとArialとかにフォールバックされちゃう。
のでRobotoフォントを導入する。&lt;/p&gt;

&lt;p&gt;フォントは&lt;a href=&#34;https://www.w3schools.com/css/css3_fonts.asp&#34;&gt;CSS Web Fonts&lt;/a&gt;の機能である&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/@font-face&#34;&gt;@font-face&lt;/a&gt;で、フォントファイルをブラウザにロードさせることで導入できる。
&lt;code&gt;@font-face&lt;/code&gt;で読み込むフォントファイル(i.e. &lt;code&gt;url()&lt;/code&gt;関数で指定するファイル)はwebpackでバンドルできる。&lt;/p&gt;

&lt;p&gt;Robotoフォントのフォントファイルはnpmで配布されていて、Yarnでプロジェクトにインストールできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add typeface-roboto
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;フォントファイルの種類は、OTFとかTTFとかWOFFとかWOFF2とかいろいろあるけど、&lt;a href=&#34;https://www.6666666.jp/design/20160218/&#34;&gt;この記事&lt;/a&gt;などをみるに、WOFFだけ使えばよさげ。&lt;/p&gt;

&lt;p&gt;フォントファイルのバンドルは&lt;a href=&#34;https://github.com/webpack-contrib/url-loader&#34;&gt;url-loader&lt;/a&gt;を使う方法と&lt;a href=&#34;https://github.com/webpack-contrib/file-loader&#34;&gt;file-loader&lt;/a&gt;を使う方法とがある。&lt;/p&gt;

&lt;h2 id=&#34;url-loaderを使う方法&#34;&gt;url-loaderを使う方法&lt;/h2&gt;

&lt;p&gt;url-loaderを使う場合は、url-loaderとフォールバック用のfile-loaderをインストールする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;yarn add -D url-loader file-loader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;webpackのローダ設定は以下のようなのを追加すればいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;(前略)
   module: {
     rules: [
(中略)
-      }
+      },
+      {
+        test: /\.(png|woff|woff2|eot|ttf|svg)$/,
+        include: [path.resolve(__dirname, &#39;node_modules/typeface-roboto&#39;)],
+        loader: &#39;url-loader&#39;,
+        options: {
+          limit: 100000,
+        },
+      },
     ],
   },
(後略)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あとは、typeface-robotoパッケージ内のフォントファイルを指すようにCSSに@font-faceを書けばいい。
例えば、weightが300のWOFFファイルを読むなら以下のような感じ。&lt;/p&gt;

&lt;p&gt;src/fonts.css:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;@font-face {
  font-family: &#39;Roboto&#39;;
  font-style: normal;
  font-display: swap;
  font-weight: 300;
  src: local(&#39;Roboto Light &#39;), local(&#39;Roboto-Light&#39;),
    url(&#39;../node_modules/typeface-roboto/files/roboto-latin-300.woff&#39;) format(&#39;woff&#39;);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これをどこかのJavaScriptでインポートしてやればいい。&lt;/p&gt;

&lt;p&gt;src/index.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
 import ReactDOM from &#39;react-dom&#39;;
 import App from &#39;./components/App&#39;;
+import &#39;./fonts.css&#39;;

 const root = document.getElementById(&#39;root&#39;);

 if (root) {
   ReactDOM.render(
     &amp;lt;App /&amp;gt;,
     root,
   );
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;けど、styled-componentsを使っている場合はurl-loaderは使えないみたいで、代わりにfile-loaderを使う必要がある。&lt;/p&gt;

&lt;h2 id=&#34;file-loaderを使う方法-styled-components&#34;&gt;file-loaderを使う方法 (styled-components)&lt;/h2&gt;

&lt;p&gt;file-loaderを使う場合は、file-loaderだけインストールすればいい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;yarn add -D file-loader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;webpackのローダ設定は以下のようなのを追加すればいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;(前略)
   module: {
     rules: [
(中略)
-      }
+      },
+      {
+        test: /\.(png|woff|woff2|eot|ttf|svg)$/,
+        include: [path.resolve(__dirname, &#39;node_modules&#39;)],
+        loader: &#39;file-loader&#39;,
+      },
     ],
   },
(後略)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、&lt;a href=&#34;https://github.com/styled-components/styled-components/issues/233&#34;&gt;ここ&lt;/a&gt;にある通り、styled-componentsの&lt;a href=&#34;https://www.styled-components.com/docs/api#injectglobal&#34;&gt;injectGlobal&lt;/a&gt;というAPIを使って、以下のようにフォントファイルを読み込む。&lt;/p&gt;

&lt;p&gt;src/font.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { injectGlobal } from &#39;styled-components&#39;;
import roboto300 from &#39;../node_modules/typeface-roboto/files/roboto-latin-300.woff&#39;;

injectGlobal`
  /* roboto-300normal - latin */
  @font-face {
    font-family: &#39;Roboto&#39;;
    font-style: normal;
    font-display: swap;
    font-weight: 300;
    src:
      local(&#39;Roboto Light &#39;),
      local(&#39;Roboto-Light&#39;),
      url(&#39;${roboto300}&#39;) format(&#39;woff&#39;);
  }
`;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あとはこれをどこかのJavaScriptでインポートしてやればいい。&lt;/p&gt;

&lt;p&gt;src/index.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
 import ReactDOM from &#39;react-dom&#39;;
 import App from &#39;./components/App&#39;;
+import &#39;./fonts&#39;;

 const root = document.getElementById(&#39;root&#39;);

 if (root) {
   ReactDOM.render(
     &amp;lt;App /&amp;gt;,
     root,
   );
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/09/26/creating-react-redux-app-from-scratch-06/&#34;&gt;次回&lt;/a&gt;はようやくReduxを導入する。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>React &#43; Reduxアプリケーションプロジェクトのテンプレートを作る ― その4: CSS ModulesとPostCSSとstylelintとstyled-components</title>
          <link>https://www.kaitoy.xyz/2018/08/29/creating-react-redux-app-from-scratch-04/</link>
          <pubDate>Wed, 29 Aug 2018 23:50:53 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/08/29/creating-react-redux-app-from-scratch-04/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt;と&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;を学ぶために、開発環境というかプロジェクトテンプレートをスクラッチから作っている。
(最終的な成果は&lt;a href=&#34;https://github.com/kaitoy/react-redux-scaffold&#34;&gt;GitHub&lt;/a&gt;に置いた。)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/23/creating-react-redux-app-from-scratch-03/&#34;&gt;前回&lt;/a&gt;はPrettierとESLintをセットアップした。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;css&#34;&gt;CSS&lt;/h1&gt;

&lt;p&gt;前回までで作った環境で、Reactを使ってHTMLのDOMツリーを構築することができるようになったが、これは基本的にUIに表示する情報の構造しか定義しない。
UIの見た目(スタイル)を決めるのはCSSなので、それをアプリに組み込むことを考えないといけない。&lt;/p&gt;

&lt;p&gt;組み込み方には現時点で大きく3通りある。&lt;/p&gt;

&lt;h2 id=&#34;cssを別途設計する&#34;&gt;CSSを別途設計する&lt;/h2&gt;

&lt;p&gt;一つ目はCSSを別途設計する方法。&lt;/p&gt;

&lt;p&gt;Reactコンポーネントからレンダリングされる要素にclassが付くようにしておいて、設計したCSSをbundle.jsとは別途読み込んでスタイルを適用することにはる。&lt;/p&gt;

&lt;p&gt;この場合、CSSのスタイル定義はすべてグローバルなので、設計効率やメンテナンス効率を維持しつつ、各コンポーネントに意図したスタイルが適用されるようにするため、テクニックを凝らしてCSSクラスを設計する必要がある。
例えば&lt;a href=&#34;https://en.bem.info/&#34;&gt;BEM&lt;/a&gt; (2009年3月誕生)、&lt;a href=&#34;http://oocss.org/&#34;&gt;OOCSS&lt;/a&gt; (2009年3月誕生)、&lt;a href=&#34;https://smacss.com/ja&#34;&gt;SMACSS&lt;/a&gt; (2011年9月誕生)、&lt;a href=&#34;https://github.com/hiloki/flocss&#34;&gt;FLOCSS&lt;/a&gt; (2014年4月誕生)など。&lt;/p&gt;

&lt;p&gt;CSS自体は、素のCSSを書くことはあまりなく、普通は&lt;a href=&#34;https://sass-lang.com/&#34;&gt;Sass&lt;/a&gt;などのAltCSSや&lt;a href=&#34;https://postcss.org/&#34;&gt;PostCSS&lt;/a&gt;を使って書く。&lt;/p&gt;

&lt;p&gt;さらに、&lt;a href=&#34;https://github.com/stylelint/stylelint&#34;&gt;stylelint&lt;/a&gt;でリンティングすることで、CSSの品質を上げられる。
リンティングルールは、stylelintプロジェクトから提供されている&lt;a href=&#34;https://github.com/stylelint/stylelint-config-recommended&#34;&gt;stylelint-config-recommended&lt;/a&gt;か&lt;a href=&#34;https://github.com/stylelint/stylelint-config-standard&#34;&gt;stylelint-config-standard&lt;/a&gt;を使えば十分。
後者がGoogleやAirbnbのCSSスタイルガイドを反映していていい感じ。&lt;/p&gt;

&lt;p&gt;書いたCSSは、webpackの&lt;a href=&#34;https://github.com/webpack-contrib/css-loader&#34;&gt;css-loader&lt;/a&gt;で読み込める。
webpackはJavaScriptの&lt;code&gt;import &#39;./App.css&#39;;&lt;/code&gt;みたいなコードを見つけると、css-loaderに処理を渡す。
css-loaderは、&lt;code&gt;import&lt;/code&gt;文で指定されたCSSファイルだけでなく、&lt;code&gt;@import&lt;/code&gt;や&lt;code&gt;url()&lt;/code&gt;で定義される依存関係をたどって関連するCSSを一通り読み込む。&lt;/p&gt;

&lt;p&gt;読み込んだCSSは、webpackの&lt;a href=&#34;https://github.com/webpack-contrib/style-loader&#34;&gt;style-loader&lt;/a&gt;を使ってDOMに適用できる。
style-loaderは、読み込んだCSSを&lt;code&gt;&amp;lt;style&amp;gt;&lt;/code&gt;タグで囲ってHTMLのヘッダに挿入してくれる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;CSSの処理にはPostCSSを使うとして、プロジェクトに以下のパッケージを追加する。
(PostCSSについては&lt;a href=&#34;https://qiita.com/morishitter/items/4a04eb144abf49f41d7d&#34;&gt;Qiitaの記事&lt;/a&gt;が参考になった。)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;css-loader: CSSを読み込むためのwebpackのローダ。&lt;/li&gt;
&lt;li&gt;style-loader: CSSをDOMに追加するためのwebpackのローダ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/postcss/postcss-loader&#34;&gt;postcss-loader&lt;/a&gt;: PostCSSを実行するためのwebpackのローダ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://preset-env.cssdb.org/&#34;&gt;postcss-preset-env&lt;/a&gt;: CSSのエッジな機能を使うためのPostCSSプラグイン。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/postcss/autoprefixer&#34;&gt;autoprefixer&lt;/a&gt;: CSSプロパティにベンダプレフィックスを追加してくれるPostCSSプラグイン。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/luisrudge/postcss-flexbugs-fixes&#34;&gt;postcss-flexbugs-fixes&lt;/a&gt;: &lt;a href=&#34;https://www.w3schools.com/css/css3_flexbox.asp&#34;&gt;Flexbox&lt;/a&gt;のバグを修正してくれるPostCSSプラグイン。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cssnano/cssnano&#34;&gt;cssnano&lt;/a&gt;: CSSをミニファイしてくれるPostCSSプラグイン。&lt;/li&gt;
&lt;li&gt;stylelint: CSSのリンタ。&lt;/li&gt;
&lt;li&gt;stylelint-config-standard: stylelintのルール設定集。&lt;/li&gt;
&lt;li&gt;stylelint-config-prettier: &lt;a href=&#34;https://prettier.io/&#34;&gt;Prettier&lt;/a&gt;が施すコード整形とコンフリクトするルールを無効にするstylelintルール設定集。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D css-loader style-loader postcss-loader postcss-preset-env autoprefixer postcss-flexbugs-fixes cssnano stylelint stylelint-config-standard stylelint-config-prettier
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;PostCSSとstylelintの設定は、それぞれpostcss.config.jsとstylelint.config.jsを書いてプロジェクトルートに置けばいい。&lt;/p&gt;

&lt;p&gt;postcss.config.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;module.exports = {
  plugins: {
    stylelint: {},
    &#39;postcss-preset-env&#39;: {},
    autoprefixer: {},
    &#39;postcss-flexbugs-fixes&#39;: {},
    cssnano: {},
  },
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;stylelint.config.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;module.exports = {
  extends: [&#39;stylelint-config-standard&#39;, &#39;stylelint-config-prettier&#39;],
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;stylelintはPostCSSのプラグインとしてPostCSSから実行する構成。&lt;/p&gt;

&lt;p&gt;stylelint.config.jsで、stylelint-config-prettierはextendsの最後に書く必要があることに注意。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;webpackにもローダの設定を追加する。&lt;/p&gt;

&lt;p&gt;webpack.common.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; (前略)
       {
         test: /\.(js|jsx)$/,
         include: [path.resolve(__dirname, &#39;src&#39;)],
         loader: &#39;babel-loader&#39;,
       },
+      {
+        test: /\.css$/,
+        include: [path.resolve(__dirname, &#39;src&#39;)],
+        use: [
+          &#39;style-loader&#39;,
+          {
+            loader: &#39;css-loader&#39;,
+            options: {
+              importLoaders: 1,
+            },
+          },
+          &#39;postcss-loader&#39;,
+        ],
+      },
     ],
   },
 (後略)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここで追加した設定は、&lt;code&gt;&amp;lt;プロジェクトルート&amp;gt;/src&lt;/code&gt;ディレクトリ内の&lt;code&gt;.css&lt;/code&gt;ファイルが&lt;code&gt;import&lt;/code&gt;されたら、postcss-loader、css-loader、style-loaderの順にそのファイルを処理する、というもの。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;実際のCSSは普通に書いて、JavaScriptからimportしてやればいい。&lt;/p&gt;

&lt;p&gt;components/App.css:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.normal {
  font-size: 5rem;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;components/App.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
+import &#39;./App.css&#39;

 const App = () =&amp;gt; (
-  &amp;lt;div&amp;gt;
+  &amp;lt;div className=&amp;quot;normal&amp;quot;&amp;gt;
     HOGE
   &amp;lt;/div&amp;gt;
 );

 export default App;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;JSXでHTML要素にclass属性を付けるには、classNameプロパティを使うことに注意。&lt;/p&gt;

&lt;p&gt;これでHOGEに&lt;code&gt;font-size: 5rem&lt;/code&gt;が適用され、文字が大きくなる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でCSSを適用できた。&lt;/p&gt;

&lt;p&gt;これはこれで十分で柔軟なやりかただけど、BEMなどでCSSクラスの設計を頑張る手間がある。
UIコンポーネントの構造とスタイルの構造を1対1対応させるなら、もっと楽な方法がある。&lt;/p&gt;

&lt;h2 id=&#34;css-modules&#34;&gt;CSS Modules&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/css-modules/css-modules&#34;&gt;CSS Modules&lt;/a&gt;は2015年9月に&lt;a href=&#34;https://postd.cc/css-modules/&#34;&gt;発表&lt;/a&gt;された技術で、一つのCSSファイルを一つのモジュールと考え、モジュールごとにCSSクラス名の名前空間を自動生成し、スタイルの影響範囲をモジュールに閉じ込めてくれるもの。
(実際には、子要素に継承されるプロパティもあるので完全に閉じ込められるわけではない。)&lt;/p&gt;

&lt;p&gt;ReactによるUIコンポーネントごとにCSSモジュールを作り、コンポーネント単位でスタイリングすることを意図した技術であり、コンポーネント内で閉じたCSSクラス設計をすればいいだけになり、BEMとかを考えなくてよくなる。&lt;/p&gt;

&lt;p&gt;CSS Modulesを使うには、&lt;a href=&#34;https://github.com/gajus/babel-plugin-react-css-modules&#34;&gt;babel-plugin-react-css-modules&lt;/a&gt;というBabelのプラグインをセットアップすればいい。
まずはそれをプロジェクトにインストールする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D babel-plugin-react-css-modules
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Babelの設定を修正してインストールしたbabel-plugin-react-css-modulesを使うようにする。&lt;/p&gt;

&lt;p&gt;.babelrc&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; {
-  &amp;quot;presets&amp;quot;: [&amp;quot;env&amp;quot;, &amp;quot;react&amp;quot;]
+  &amp;quot;presets&amp;quot;: [&amp;quot;env&amp;quot;, &amp;quot;react&amp;quot;],
+  &amp;quot;plugins&amp;quot;: [&amp;quot;react-css-modules&amp;quot;]
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;webpackのcss-loaderのオプションを追加して、CSS Modulesを有効にする。&lt;/p&gt;

&lt;p&gt;webpack.common.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; (前略)
       {
         test: /\.css$/,
         include: [path.resolve(__dirname, &#39;src&#39;)],
         use: [
           &#39;style-loader&#39;,
           {
             loader: &#39;css-loader&#39;,
             options: {
               importLoaders: 1,
+              modules: true,
+              localIdentName: &#39;[path]___[name]__[local]___[hash:base64:5]&#39;,
             },
           },
           &#39;postcss-loader&#39;,
         ],
       },
 (後略)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;modules&lt;/code&gt;がCSS Modulesを有効化するスイッチ。
&lt;code&gt;localIdentName&lt;/code&gt;はモジュール化したCSSクラスの命名規則で、babel-plugin-react-css-modulesの設定と合っている必要がある。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あとは、コンポーネントの方で&lt;code&gt;className&lt;/code&gt;プロパティを&lt;code&gt;styleName&lt;/code&gt;プロパティに変えればいい。&lt;/p&gt;

&lt;p&gt;components/App.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
 import &#39;./App.css&#39;

 const App = () =&amp;gt; (
-  &amp;lt;div className=&amp;quot;normal&amp;quot;&amp;gt;
+  &amp;lt;div styleName=&amp;quot;normal&amp;quot;&amp;gt;
     HOGE
   &amp;lt;/div&amp;gt;
 );

 export default App;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でCSS Modulesの設定は完了。
App.cssに書いたクラス名はcss-loaderによって変換され、App.jsxに書いたstyleNameはbabel-plugin-react-css-modulesによって変換され、どちらも&lt;code&gt;src-components-___App__normal___1fxGx&lt;/code&gt;になるようになる。&lt;/p&gt;

&lt;h2 id=&#34;css-in-js&#34;&gt;CSS in JS&lt;/h2&gt;

&lt;p&gt;3つめはCSS in JS。&lt;/p&gt;

&lt;p&gt;これは2014年11月に&lt;a href=&#34;https://speakerdeck.com/vjeux/react-css-in-js&#34;&gt;提唱された&lt;/a&gt;技術で、UIコンポーネントとそのスタイルを両方一つのJavaScriptファイルに書いて、完全に一体化させるというもの。&lt;/p&gt;

&lt;p&gt;CSS in JSはCSS Modulesの陰でしばらく目立たなかったが、2016年に&lt;a href=&#34;https://www.styled-components.com/&#34;&gt;styled-components&lt;/a&gt;という実装がリリースされて注目され、その後いくつかの実装が生まれた。
styled-componentsは2017年ころからCSS Modulesに代わって人気になり、&lt;a href=&#34;https://postd.cc/stop-using-css-in-javascript-for-web-development-fa/&#34;&gt;CSS Modules陣営からの反撃&lt;/a&gt;もあったものの、今日まで支持を増やしている模様。
SassやPostCSSなど既存のCSSエコシステムを切り捨てているのと、React限定なのが気になるところではあるが、時流に乗って使ってみることにする。&lt;/p&gt;

&lt;p&gt;なお、CSS in JSはCSS Modulesとセットアップ方法がかなり異なるので、本稿前節までの変更はいったん全部破棄する。&lt;/p&gt;

&lt;p&gt;styled-componentsを使う場合、プロジェクトに追加する必要があるのは二つだけ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;styled-components: styled-components本体。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/styled-components/babel-plugin-styled-components&#34;&gt;babel-plugin-styled-components&lt;/a&gt;: styled-componentsのサポートを強化するBabelプラグイン。実際には必須ではないけど、バンドルサイズを削減出来たり、SSRしやすくなったりする。ベンダプレフィックスの付与とかミニファイもしてくれる。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add styled-components
yarn add -D babel-plugin-styled-components
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;styled-componentsはv3.4.4が入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Babelの設定は以下のように修正する。&lt;/p&gt;

&lt;p&gt;.babelrc&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; {
-  &amp;quot;presets&amp;quot;: [&amp;quot;env&amp;quot;, &amp;quot;react&amp;quot;]
+  &amp;quot;presets&amp;quot;: [&amp;quot;env&amp;quot;, &amp;quot;react&amp;quot;],
+  &amp;quot;plugins&amp;quot;: [&amp;quot;styled-components&amp;quot;]
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;App.jsxは、styled-componentsのstyledというAPIを使ってWrapperコンポーネント(スタイル付きdiv)を定義し、これをdivと置き換える。&lt;/p&gt;

&lt;p&gt;components/App.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
+import styled from &#39;styled-components&#39;;

+const Wrapper = styled.div`
+  font-size: 5rem;
+`;

 const App = () =&amp;gt; (
-  &amp;lt;div&amp;gt;
+  &amp;lt;Wrapper&amp;gt;
     HOGE
-  &amp;lt;/div&amp;gt;
+  &amp;lt;/Wrapper&amp;gt;
 );

 export default App;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これだけ。CSS Modulesに比べて大分シンプル。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;styled.div&lt;/code&gt;でスタイルを記述している部分は見慣れない構文だけど、ECMAScript 2015で追加されたタグ付きテンプレートリテラルという構文で、テンプレート文字列の一種。
ここに書くスタイルの構文はCSSと全く一緒。
JavaScriptの構文としては単なる文字列なので、変数を使ったり、if文とかで動的に変えたり、数値を計算したり、自由に書ける。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ややややこしいが、&lt;a href=&#34;https://www.styled-components.com/docs/tooling#stylelint&#34;&gt;stylelintによるリンティング&lt;/a&gt;もできる。
以下のパッケージをプロジェクトに追加する。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;stylelint: CSSのリンタ。(既出)&lt;/li&gt;
&lt;li&gt;stylelint-config-standard: stylelintのルール設定集。(既出)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/styled-components/stylelint-processor-styled-components&#34;&gt;stylelint-processor-styled-components&lt;/a&gt;: スタイル付きコンポーネントからスタイル定義を抽出するstylelintのカスタムプロセッサ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/styled-components/stylelint-config-styled-components&#34;&gt;stylelint-config-styled-components&lt;/a&gt;: stylelint-processor-styled-componentsを使うのに必要なstylelint設定集。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/emilgoldsmith/stylelint-custom-processor-loader&#34;&gt;stylelint-custom-processor-loader&lt;/a&gt;: stylelintでカスタムプロセッサを使う場合に必要なwebpackのローダ。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D stylelint stylelint-config-standard stylelint-processor-styled-components stylelint-config-styled-components stylelint-custom-processor-loader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;stylelintの設定は以下。&lt;/p&gt;

&lt;p&gt;stylelint.config.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;module.exports = {
  processors: [&#39;stylelint-processor-styled-components&#39;],
  extends: [&#39;stylelint-config-standard&#39;, &#39;stylelint-config-styled-components&#39;],
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;webpackの設定にstylelint-custom-processor-loaderの設定を追加する。&lt;/p&gt;

&lt;p&gt;webpack.common.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; (前略)
       {
         test: /\.(js|jsx)$/,
         include: [path.resolve(__dirname, &#39;src&#39;)],
         loader: &#39;babel-loader&#39;,
       },
+      {
+        test: /\.(js|jsx)$/,
+        include: [path.resolve(__dirname, &#39;src&#39;)],
+        enforce: &#39;pre&#39;,
+        loader: &#39;stylelint-custom-processor-loader&#39;,
+      },
     ],
   },
 (後略)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これでstyled-componentsにstylelintを適用できた。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/09/06/creating-react-redux-app-from-scratch-05/&#34;&gt;次回&lt;/a&gt;は&lt;a href=&#34;https://material-ui.com/&#34;&gt;Material-UI&lt;/a&gt;を導入する。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>React &#43; Reduxアプリケーションプロジェクトのテンプレートを作る ― その3: PrettierとESLint</title>
          <link>https://www.kaitoy.xyz/2018/08/23/creating-react-redux-app-from-scratch-03/</link>
          <pubDate>Thu, 23 Aug 2018 00:19:09 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/08/23/creating-react-redux-app-from-scratch-03/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt;と&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;を学ぶために、開発環境というかプロジェクトテンプレートをスクラッチから作っている。
(最終的な成果は&lt;a href=&#34;https://github.com/kaitoy/react-redux-scaffold&#34;&gt;GitHub&lt;/a&gt;に置いた。)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/22/creating-react-redux-app-from-scratch-02/&#34;&gt;前回&lt;/a&gt;はReactをセットアップした。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;フォーマッタとリンタ&#34;&gt;フォーマッタとリンタ&lt;/h1&gt;

&lt;p&gt;プロジェクトにフォーマッタとリンタを導入する。&lt;/p&gt;

&lt;p&gt;フォーマッタはソースの体裁を整えるツール。
フォーマッタを使うことで体裁が統一され、ソースが読みやすくなり、品質向上につながる。&lt;/p&gt;

&lt;p&gt;リンタはソースを静的解析して、潜在的なバグ、構造的な問題、体裁の問題を検出して警告してくれるツール。
フォーマッタは体裁だけ整えるのに対し、リンタは論理構造にも制約を課せるので、コーディングスタイルがより統一できたり、ミスをしやすい論理構造が無くなったりして、品質向上につながる。&lt;/p&gt;

&lt;p&gt;JavaScriptのような動的型付け言語では、実行時まで顕在化しないバグを作りこみやすく、また実行時エラーの原因解析が静的型付け言語に比べて難しいので、フォーマッタとリンタでプログラム実行前に問題をできるだけ取り除いておくのが重要。
またチーム開発では、コードレビューでコーディンスタイルを見る必要がなくなり、効率化につながる。&lt;/p&gt;

&lt;h2 id=&#34;prettier&#34;&gt;Prettier&lt;/h2&gt;

&lt;p&gt;フォーマッタには&lt;a href=&#34;https://prettier.io/&#34;&gt;Prettier&lt;/a&gt;を使う。&lt;/p&gt;

&lt;p&gt;Prettierは&lt;a href=&#34;https://jlongster.com/A-Prettier-Formatter&#34;&gt;2017年1月&lt;/a&gt;にリリースされた新しいツール。
構文解析をして&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E6%8A%BD%E8%B1%A1%E6%A7%8B%E6%96%87%E6%9C%A8&#34;&gt;AST&lt;/a&gt;を構築し、そこからフォーマット済みコードを出力するので、従来のツールよりも厳密な整形(e.g. 行の最大長を考慮した整形)ができる。&lt;/p&gt;

&lt;p&gt;また、opinionated(独断的)であることも特徴で、Prettierプロジェクトが推奨するフォーマットをほぼ強制し、設定がほとんどない。
このため導入が簡単だけど、かゆいところに手が届かないこともある。&lt;/p&gt;

&lt;p&gt;JavaScriptの他、JSX、CSS、Markdown、GraphQLのフォーマットにも対応している。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;まずプロジェクトにインストールする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D prettier
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;v1.14.0が入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://prettier.io/docs/en/options.html&#34;&gt;設定&lt;/a&gt;は&lt;code&gt;prettier.config.js&lt;/code&gt;という&lt;a href=&#34;https://prettier.io/docs/en/configuration.html&#34;&gt;ファイル&lt;/a&gt;を書いてプロジェクトルートに置けばいい。&lt;/p&gt;

&lt;p&gt;prettier.config.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;module.exports = {
  printWidth: 100, // 行の最大長
  tabWidth: 2, // インデント長
  singleQuote: true, // 文字列をシングルクオートで囲う
  trailingComma: &#39;all&#39;, // オブジェクトのプロパティとか関数の引数を複数行で書いたときに、全行の末尾にカンマをつける
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;また、フォーマット対象外のファイルを指定するファイルである&lt;code&gt;.prettierignore&lt;/code&gt;をプロジェクトルートに置く。&lt;/p&gt;

&lt;p&gt;.prettierignore:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;node_modules/
dist/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;node_modulesはnpmパッケージが入るディレクトリ。
実際はnode_modulesはデフォルトで無視されるから書かなくていいんだけど。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://prettier.io/docs/en/ignore.html&#34;&gt;prettier-ignoreコメント&lt;/a&gt;を書くことで、ソースを部分的にフォーマット対象外とすることもできる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;最後に、npmスクリプトを書く。&lt;/p&gt;

&lt;p&gt;package.json:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; (前略)
   &amp;quot;scripts&amp;quot;: {
+    &amp;quot;format&amp;quot;: &amp;quot;prettier --write **/*.jsx **/*.js **/*.css&amp;quot;,
     &amp;quot;build&amp;quot;: &amp;quot;webpack --config webpack.prod.js&amp;quot;,
     &amp;quot;start&amp;quot;: &amp;quot;webpack-dev-server --hot --config webpack.dev.js&amp;quot;
   },
 (後略)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで、&lt;code&gt;yarn format&lt;/code&gt;を実行するとプロジェクト内ソースを一通りフォーマットできる。&lt;/p&gt;

&lt;h2 id=&#34;eslint&#34;&gt;ESLint&lt;/h2&gt;

&lt;p&gt;リンタにはデファクトスタンダードの&lt;a href=&#34;https://eslint.org/&#34;&gt;ESLint&lt;/a&gt;を使う。&lt;/p&gt;

&lt;p&gt;ESLintは2013年6月にリリースされたそこそこ歴史のあるツール。
リンティングルールがプラガブルで、豊富なルールを細かく制御できるのが特徴。
フォーマッタとしての機能もあるけど、そこはPrettierにまかせることにする。&lt;/p&gt;

&lt;p&gt;JavaScriptもJSXもリンティングできる。&lt;/p&gt;

&lt;p&gt;リンティングルールはAirbnbによる&lt;a href=&#34;https://github.com/airbnb/javascript/tree/master/packages/eslint-config-airbnb&#34;&gt;eslint-config-airbnb&lt;/a&gt;が有名なのでこれを使う。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ESLintを導入するために、以下のパッケージをプロジェクトにインストールする。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;eslint: ESLint本体。&lt;/li&gt;
&lt;li&gt;eslint-loader: webpackからESLintを実行するやつ。&lt;/li&gt;
&lt;li&gt;eslint-config-airbnb: ESLintルール設定集。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/benmosher/eslint-plugin-import&#34;&gt;eslint-plugin-import&lt;/a&gt;: eslint-config-airbnbのピア依存。import文を処理するためのESLintプラグイン。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/evcohen/eslint-plugin-jsx-a11y&#34;&gt;eslint-plugin-jsx-a11y&lt;/a&gt;: eslint-config-airbnbのピア依存。JSXを処理するためのESLintプラグイン。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/yannickcr/eslint-plugin-react&#34;&gt;eslint-plugin-react&lt;/a&gt;: eslint-config-airbnbのピア依存。React特有のリンティングルールを追加するESLintプラグイン。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/prettier/eslint-config-prettier&#34;&gt;eslint-config-prettier&lt;/a&gt;: Prettierが施すコード整形とコンフリクトするルールを無効にするESLintルール設定集。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ピア依存をインストールするのにはちょっとコツがいるので、&lt;a href=&#34;https://github.com/airbnb/javascript/tree/master/packages/eslint-config-airbnb#eslint-config-airbnb-1&#34;&gt;eslint-config-airbnbのドキュメント&lt;/a&gt;を参照すべし。&lt;/p&gt;

&lt;p&gt;今回は以下のコマンドでインストールした。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D &amp;quot;eslint@&amp;gt;=1.6.0 &amp;lt;5.0.0&amp;quot; eslint-loader eslint-config-airbnb &amp;quot;eslint-plugin-import@^2.12.0&amp;quot; &amp;quot;eslint-plugin-jsx-a11y@^6.0.3&amp;quot; &amp;quot;eslint-plugin-react@^7.9.1&amp;quot; eslint-config-prettier
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ESlintはv4.19.1が入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://eslint.org/docs/user-guide/configuring&#34;&gt;ESlintの設定&lt;/a&gt;は、設定ファイルである&lt;code&gt;.eslintrc.js&lt;/code&gt;をプロジェクトルートに置けばいい。&lt;/p&gt;

&lt;p&gt;.eslintrc.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;module.exports = {
  env: {
    browser: true,
  },
  extends: [&#39;airbnb&#39;, &#39;prettier&#39;],
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;アプリの実行環境はブラウザなので&lt;code&gt;env.browser&lt;/code&gt;をtrueにしている。
これにより、ブラウザ環境でデフォルトで使えるグローバル変数(e.g. &lt;code&gt;document&lt;/code&gt;)を使うときにESLintに怒られないようになる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;extends&lt;/code&gt;は&lt;code&gt;eslint-config-airbnb&lt;/code&gt;と&lt;code&gt;eslint-config-prettier&lt;/code&gt;のルール設定を取り込むように書いている。
&lt;code&gt;prettier&lt;/code&gt;が最後でなければいけないことに注意。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;また、&lt;a href=&#34;https://eslint.org/docs/user-guide/configuring#ignoring-files-and-directories&#34;&gt;リンティング対象外のファイルを指定するファイル&lt;/a&gt;をプロジェクトルートに置く。&lt;/p&gt;

&lt;p&gt;.eslintignore:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;node_modules/*
dist/*
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;node_modulesはnpmパッケージが入るディレクトリ。
実際はnode_modulesはデフォルトで無視されるから書かなくていいんだけど。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://eslint.org/docs/user-guide/configuring#disabling-rules-with-inline-comments&#34;&gt;eslint-disableコメント&lt;/a&gt;を書くことで、ソースを部分的にリンティング対象外としたり、特定のルールを無効化することもできる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;webpackからESLintを実行し、エラーがなくならない限りビルド成功できないようにする。&lt;/p&gt;

&lt;p&gt;webpack.common.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; (前略)
   module: {
     rules: [
+      {
+        test: /\.(js|jsx)$/,
+        include: [path.resolve(__dirname, &#39;src&#39;)],
+        enforce: &#39;pre&#39;,
+        loader: &#39;eslint-loader&#39;,
+        options: {
+          configFile: &#39;./.eslintrc.js&#39;,
+          failOnError: true,
+        },
       },
       {
         test: /\.(js|jsx)$/,
         include: [path.resolve(__dirname, &#39;src&#39;)],
         loader: &#39;babel-loader&#39;,
       },
     ],
   },
 (後略)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あとはnpmスクリプト書くだけ。&lt;/p&gt;

&lt;p&gt;package.json:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; (前略)
   &amp;quot;scripts&amp;quot;: {
     &amp;quot;format&amp;quot;: &amp;quot;prettier --write **/*.jsx **/*.js **/*.css&amp;quot;,
+    &amp;quot;lint&amp;quot;: &amp;quot;eslint **/*.jsx **/*.js&amp;quot;,
     &amp;quot;build&amp;quot;: &amp;quot;webpack --config webpack.prod.js&amp;quot;,
     &amp;quot;start&amp;quot;: &amp;quot;webpack-dev-server --hot --config webpack.dev.js&amp;quot;
   },
 (後略)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで、&lt;code&gt;yarn lint&lt;/code&gt;を実行するとプロジェクト内ソースを一通りリンティングできる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上で、フォーマッタとリンタを導入できた。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/29/creating-react-redux-app-from-scratch-04/&#34;&gt;次回&lt;/a&gt;はCSS周りの処理系を追加する。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>React &#43; Reduxアプリケーションプロジェクトのテンプレートを作る ― その2: React</title>
          <link>https://www.kaitoy.xyz/2018/08/22/creating-react-redux-app-from-scratch-02/</link>
          <pubDate>Wed, 22 Aug 2018 08:21:28 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/08/22/creating-react-redux-app-from-scratch-02/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt;と&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;を学ぶために、開発環境というかプロジェクトテンプレートをスクラッチから作っている。
(最終的な成果は&lt;a href=&#34;https://github.com/kaitoy/react-redux-scaffold&#34;&gt;GitHub&lt;/a&gt;に置いた。)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/19/creating-react-redux-app-from-scratch-01/&#34;&gt;前回&lt;/a&gt;はNode.jsとYarnとBabelとwebpackをセットアップした。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;reactとは&#34;&gt;Reactとは&lt;/h1&gt;

&lt;p&gt;以前にも同じような事を書いたけど、改めてReactについて書く。
ちょっとコーディングの詳細にも触れながら。&lt;/p&gt;

&lt;p&gt;ReactはViewを記述するためのライブラリで、特徴は&lt;a href=&#34;https://reactjs.org/docs/faq-internals.html&#34;&gt;Virtual DOM&lt;/a&gt;と&lt;a href=&#34;https://reactjs.org/docs/introducing-jsx.html&#34;&gt;JSX&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;virtual-dom&#34;&gt;Virtual DOM&lt;/h2&gt;

&lt;p&gt;Virtual DOMはDOMを仮想化するもので、JavaScriptからVirtual DOMでUIを記述してやると、それが実DOMに効率的に反映されるようになっている。&lt;/p&gt;

&lt;h2 id=&#34;jsx&#34;&gt;JSX&lt;/h2&gt;

&lt;p&gt;Virtual DOMはJSXというHTMLみたいな言語で記述できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import React from &#39;react&#39;;
import ReactDOM from &#39;react-dom&#39;;

ReactDOM.render(
  &amp;lt;h1&amp;gt;Hello, world!&amp;lt;/h1&amp;gt;,
  document.getElementById(&#39;root&#39;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな風に書くと、idが&lt;code&gt;root&lt;/code&gt;であるHTML要素の中に、&lt;code&gt;&amp;lt;h1&amp;gt;Hello, world!&amp;lt;/h1&amp;gt;&lt;/code&gt;がレンダリングされる。
上記コードの&lt;code&gt;&amp;lt;h1&amp;gt;Hello, world!&amp;lt;/h1&amp;gt;&lt;/code&gt;の部分がJSX。&lt;/p&gt;

&lt;h2 id=&#34;コンポーネント&#34;&gt;コンポーネント&lt;/h2&gt;

&lt;p&gt;JSXではコンポーネントを定義して新たなタグとして使うことができるので、再利用できるコンポーネントを作って、それらを組み合わせてUIを構築することで、効率的な開発ができる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import React from &#39;react&#39;;
import ReactDOM from &#39;react-dom&#39;;

// Welcomeコンポーネントの定義
function Welcome() {
  return &amp;lt;h1&amp;gt;Hello, World&amp;lt;/h1&amp;gt;;
}

// Welcomeコンポーネントのレンダリング
ReactDOM.render(
  &amp;lt;Welcome /&amp;gt;,
  document.getElementById(&#39;root&#39;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上記コードではコンポーネントをfunctionで定義しているが、アロー関数で書いても全く一緒。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const Welcome = () =&amp;gt; (
  &amp;lt;h1&amp;gt;Hello, World&amp;lt;/h1&amp;gt;;
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;関数の代わりにclassで定義することもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;class Welcome extends React.Component {
  render() {
    return &amp;lt;h1&amp;gt;Hello, World&amp;lt;/h1&amp;gt;;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;関数による定義とclassによる定義はおおむね変わらないが、&lt;a href=&#34;https://reactjs.org/docs/state-and-lifecycle.html&#34;&gt;stateとライフサイクルメソッド&lt;/a&gt;を使いたいときはclassにする必要がある。&lt;/p&gt;

&lt;h2 id=&#34;props&#34;&gt;props&lt;/h2&gt;

&lt;p&gt;コンポーネントはレンダリングの際に&lt;code&gt;props&lt;/code&gt;というパラメータを受け取って使うことができるので、上手く設計すれば汎用的なコンポーネントが書ける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import React from &#39;react&#39;;
import ReactDOM from &#39;react-dom&#39;;

// Welcomeコンポーネントの定義 (props付き)
function Welcome(props) {
  return &amp;lt;h1&amp;gt;Hello, {props.name}&amp;lt;/h1&amp;gt;;
}

// Welcomeコンポーネントのレンダリング (props付き)
ReactDOM.render(
  &amp;lt;Welcome name=&amp;quot;Kaitoy&amp;quot; /&amp;gt;,
  document.getElementById(&#39;root&#39;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;props&lt;/code&gt;はイミュータブルにしてコンポーネント内で変更しない(i.e. コンポーネントをpureにする)のが定石。&lt;/p&gt;

&lt;h2 id=&#34;prop-types&#34;&gt;prop-types&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/facebook/prop-types&#34;&gt;prop-types&lt;/a&gt;を使うと、コンポーネントに渡される&lt;code&gt;props&lt;/code&gt;に期待する型を定義することができる。&lt;/p&gt;

&lt;p&gt;前節で作ったWelcomeコンポーネントの&lt;code&gt;props&lt;/code&gt;の&lt;code&gt;name&lt;/code&gt;はStringオブジェクトを受け取ることを期待するので、prop-typesを以下のように定義する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;function Welcome(props) {
  return &amp;lt;h1&amp;gt;Hello, {props.name}&amp;lt;/h1&amp;gt;;
}

Welcome.propTypes = {
  name: PropTypes.string.isRequired,
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こうしておくと、実行時に型チェックが走り、型が合わないとコンソールに警告がでるようになる。&lt;/p&gt;

&lt;h1 id=&#34;reactのインストール&#34;&gt;Reactのインストール&lt;/h1&gt;

&lt;p&gt;上記のコードを実行するためのライブラリを一通りプロジェクトに追加する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add react react-dom prop-types
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Reactはv16.4.1が入った。&lt;/p&gt;

&lt;h1 id=&#34;ソース構成&#34;&gt;ソース構成&lt;/h1&gt;

&lt;p&gt;ソースを入れる&lt;code&gt;src&lt;/code&gt;ディレクトリの構成は、&lt;a href=&#34;https://qiita.com/numanomanu/items/af97312f34cf1388cee6#%E5%AE%9F%E9%9A%9B%E3%81%AE%E3%83%97%E3%83%AD%E3%83%80%E3%82%AF%E3%83%88%E3%81%AE%E3%83%95%E3%82%A9%E3%83%AB%E3%83%80%E6%A7%8B%E6%88%90&#34;&gt;Qiitaの記事&lt;/a&gt;を参考に以下のようにする。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;react-redux-scaffold/

&lt;ul&gt;
&lt;li&gt;src/

&lt;ul&gt;
&lt;li&gt;actions/&lt;/li&gt;
&lt;li&gt;components/&lt;/li&gt;
&lt;li&gt;containers/&lt;/li&gt;
&lt;li&gt;reducers/&lt;/li&gt;
&lt;li&gt;sagas/&lt;/li&gt;
&lt;li&gt;services/&lt;/li&gt;
&lt;li&gt;index.jsx&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今のところ使うのは&lt;code&gt;index.jsx&lt;/code&gt;と&lt;code&gt;components&lt;/code&gt;だけ。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;index.jsx&lt;/code&gt;は&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/19/creating-react-redux-app-from-scratch-01/#webpack%E8%A8%AD%E5%AE%9A%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB&#34;&gt;前回&lt;/a&gt;書いた通り、webpackが初めにロードするファイル。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;components&lt;/code&gt;にはReactのコンポーネントを入れる。&lt;/p&gt;

&lt;p&gt;その他のディレクトリについては追って説明する。&lt;/p&gt;

&lt;h1 id=&#34;reactコンポーネント作成&#34;&gt;Reactコンポーネント作成&lt;/h1&gt;

&lt;p&gt;最初のReactコンポーネントとして、適当なものを作る。&lt;/p&gt;

&lt;p&gt;components/App.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import React from &#39;react&#39;;

const App = () =&amp;gt; (
  &amp;lt;div&amp;gt;
    HOGE
  &amp;lt;/div&amp;gt;
);

export default App;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、これを&lt;code&gt;index.jsx&lt;/code&gt;でインポートしてレンダリングしてやる。&lt;/p&gt;

&lt;p&gt;src/index.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import React from &#39;react&#39;;
import ReactDOM from &#39;react-dom&#39;;
import App from &#39;./components/App&#39;;

const root = document.getElementById(&#39;root&#39;);

if (root) {
  ReactDOM.render(
    &amp;lt;App /&amp;gt;,
    root,
  );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで&lt;code&gt;yarn build&lt;/code&gt;すると&lt;code&gt;dist/bundle.js&lt;/code&gt;が生成される。&lt;/p&gt;

&lt;p&gt;実践的なコンポーネント構成の考え方については、公式の&lt;a href=&#34;https://reactjs.org/docs/thinking-in-react.html&#34;&gt;Thinking in React&lt;/a&gt;が参考になる。&lt;/p&gt;

&lt;h1 id=&#34;htmlファイル作成&#34;&gt;HTMLファイル作成&lt;/h1&gt;

&lt;p&gt;bundle.jsを読み込むHTMLファイルを作る。&lt;/p&gt;

&lt;p&gt;HTMLファイルを書くときは、「&lt;a href=&#34;https://hail2u.net/documents/html-best-practices.html&#34;&gt;普通のHTMLの書き方&lt;/a&gt;」の1～3章とか、「&lt;a href=&#34;https://qiita.com/miya0001/items/8fff46c201bf9eaeba4a&#34;&gt;フロントエンドチェックリスト&lt;/a&gt;」のHead、HTML辺りが参考になる。
まあ開発時にしか使わないだろうから実際は適当でいいし、なんなら&lt;a href=&#34;https://webpack.js.org/plugins/html-webpack-plugin/&#34;&gt;HtmlWebpackPlugin&lt;/a&gt;で自動生成してもいい。&lt;/p&gt;

&lt;p&gt;作るファイルは、&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/19/creating-react-redux-app-from-scratch-01/#webpack-dev-server%E8%A8%AD%E5%AE%9A&#34;&gt;webpackの設定に書いた&lt;/a&gt;通り、&lt;code&gt;public/index.html&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;内容は以下。&lt;/p&gt;

&lt;p&gt;public/index.html:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;!doctype html&amp;gt;
&amp;lt;html lang=&amp;quot;en&amp;quot;&amp;gt;
  &amp;lt;head&amp;gt;
    &amp;lt;meta charset=&amp;quot;utf-8&amp;quot; /&amp;gt;
    &amp;lt;meta http-equiv=&amp;quot;x-ua-compatible&amp;quot; content=&amp;quot;ie=edge&amp;quot;&amp;gt;
    &amp;lt;meta name=&amp;quot;viewport&amp;quot; content=&amp;quot;width=device-width, initial-scale=1&amp;quot;&amp;gt;
    &amp;lt;title&amp;gt;React Redux&amp;lt;/title&amp;gt;
    &amp;lt;meta name=&amp;quot;description&amp;quot; content=&amp;quot;React Redux Scaffold&amp;quot;&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
    &amp;lt;div id=&amp;quot;root&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
    &amp;lt;noscript&amp;gt;
      You need to enable JavaScript to run this app.
    &amp;lt;/noscript&amp;gt;
    &amp;lt;script src=&amp;quot;./bundle.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
  &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ポイントは2点。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;&amp;lt;body&amp;gt;&lt;/code&gt;の最初に&lt;code&gt;id=root&lt;/code&gt;の&lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt;を書く&lt;/p&gt;

&lt;p&gt;上で書いた&lt;code&gt;index.jsx&lt;/code&gt;で、&lt;code&gt;id&lt;/code&gt;が&lt;code&gt;root&lt;/code&gt;の要素を取得して&lt;code&gt;ReactDOM.render()&lt;/code&gt;に渡しているので、この&lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt;要素のなかに全てのWeb UIがレンダリングされることになる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;&amp;lt;body&amp;gt;&lt;/code&gt;の最後に&lt;code&gt;&amp;lt;script src=&amp;quot;./bundle.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;&lt;/code&gt;を書く&lt;/p&gt;

&lt;p&gt;この&lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;要素により、bundle.jsがWebサーバからダウンロードされて実行される。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でReactは一通り。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;yarn start&lt;/code&gt;してブラウザで&lt;code&gt;http://localhost:3000&lt;/code&gt;にアクセスするとHOGEと表示されるはず。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/23/creating-react-redux-app-from-scratch-03/&#34;&gt;次回&lt;/a&gt;はフォーマッタとリンタを導入する。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>React &#43; Reduxアプリケーションプロジェクトのテンプレートを作る ― その1: Node.jsとYarnとBabelとwebpack</title>
          <link>https://www.kaitoy.xyz/2018/08/19/creating-react-redux-app-from-scratch-01/</link>
          <pubDate>Sun, 19 Aug 2018 15:27:19 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/08/19/creating-react-redux-app-from-scratch-01/</guid>
          <description>

&lt;p&gt;昔、&lt;a href=&#34;https://dojotoolkit.org/&#34;&gt;Dojo Toolkit&lt;/a&gt;を使ってFlashなUIをJavaScriptに書き換えた時以来、仕事でWeb UIを触ることはなかったんだけど、最近になってWeb UIを書かなければいけなくなるような気がして再学習を始めた。&lt;/p&gt;

&lt;p&gt;題材は&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt; (と&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;)。
今一番人気のフロントエンドフレームワークで、&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/21/hello-react/&#34;&gt;昔触ったこともある&lt;/a&gt;ので。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/16/chronicle-of-frontend-2018/&#34;&gt;前回の記事でReactが生まれた経緯を学んだ&lt;/a&gt;ので、今回から実習に入る。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;プロジェクト作成&#34;&gt;プロジェクト作成&lt;/h1&gt;

&lt;p&gt;ちょっと&lt;a href=&#34;https://github.com/facebook/create-react-app&#34;&gt;Create React App&lt;/a&gt;を触ってみたけど使わないことにした。
すぐ開発始められるのはよかったんだけど、裏でなにが起こっているかわからな過ぎて肌に合わないし、使うライブラリが結構固定されちゃいそうだったし、トラブルシュート(特にライブラリのバグを踏んだ時)が大変そうだったので。&lt;/p&gt;

&lt;p&gt;代わりに、&lt;a href=&#34;https://reactjs.org/docs/create-a-new-react-app.html#creating-a-toolchain-from-scratch&#34;&gt;公式&lt;/a&gt;で紹介されているブログ記事である&lt;a href=&#34;https://blog.usejournal.com/creating-a-react-app-from-scratch-f3c693b84658&#34;&gt;Creating a React App… From Scratch.&lt;/a&gt;を見ながら、スクラッチからプロジェクトを作ることにした。&lt;/p&gt;

&lt;p&gt;環境はWindows 10 Home。&lt;/p&gt;

&lt;p&gt;最終的な成果は&lt;a href=&#34;https://github.com/kaitoy/react-redux-scaffold&#34;&gt;GitHub&lt;/a&gt;に置いた。&lt;/p&gt;

&lt;h2 id=&#34;node-jsインストール&#34;&gt;Node.jsインストール&lt;/h2&gt;

&lt;p&gt;なにはともあれ&lt;a href=&#34;https://nodejs.org/ja/&#34;&gt;Node.js&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;Node.jsのバージョン管理には以前は&lt;a href=&#34;https://github.com/marcelklehr/nodist&#34;&gt;nodist&lt;/a&gt;使っていたんだけど、こいつは2年ほど前に開発が止まっているので、代わりに&lt;a href=&#34;https://github.com/coreybutler/nvm-windows&#34;&gt;nvm for Windows&lt;/a&gt;を入れた。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;nvm install&lt;/code&gt;で任意のバージョンのNode.jsをインストール出来て、&lt;code&gt;nvm use&lt;/code&gt;で使うNode.jsのバージョンを切り替えられる。&lt;/p&gt;

&lt;p&gt;今回使うNode.jsのバージョンは、現時点でLTS版の最新である8.11.4にする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\&amp;gt;nvm install 8.11.4
Downloading node.js version 8.11.4 (64-bit)...
Complete
Creating C:\Users\kaitoy\AppData\Roaming\nvm\temp

Downloading npm version 5.6.0... Complete
Installing npm v5.6.0...

Installation complete. If you want to use this version, type

nvm use 8.11.4

C:\&amp;gt;nvm use 8.11.4
Now using node v8.11.4 (64-bit)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;yarnインストール&#34;&gt;Yarnインストール&lt;/h2&gt;

&lt;p&gt;パッケージマネージャには&lt;a href=&#34;https://yarnpkg.com/lang/ja/&#34;&gt;Yarn&lt;/a&gt;を使う。&lt;/p&gt;

&lt;p&gt;Yarnちょっとバギーだとか、npm 5がlockファイルをサポートしてYarnの優位性が減ったとか、&lt;a href=&#34;https://github.com/mixmaxhq/deyarn&#34;&gt;Yarnからnpmに戻るためのツール&lt;/a&gt;が出てきたりしてるけど、現時点では深く考えずにYarnでいいと思う。&lt;/p&gt;

&lt;p&gt;YarnはWindows環境ではMSIファイルを&lt;a href=&#34;https://yarnpkg.com/ja/docs/install#windows-stable&#34;&gt;ダウンロード&lt;/a&gt;して実行すればインストールできる。&lt;/p&gt;

&lt;p&gt;(npmでもインストールできるけど邪道。)&lt;/p&gt;

&lt;p&gt;Yarnはv1.7.0を使う。&lt;/p&gt;

&lt;h2 id=&#34;package-json生成&#34;&gt;package.json生成&lt;/h2&gt;

&lt;p&gt;プロジェクトの構成情報を記述するファイルであるpackage.jsonをYarnで生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\&amp;gt;mkdir react-redux-scaffold

C:\&amp;gt;cd react-redux-scaffold

C:\react-redux-scaffold&amp;gt;yarn init
yarn init v1.7.0
question name (react-redux-scaffold):
question version (1.0.0):
question description: React Redux Scaffold
question entry point (index.js): src/index.jsx
question repository url: https://github.com/kaitoy/react-redux-scaffold.git
question author: kaitoy
question license (MIT):
question private:
success Saved package.json
Done in 40.38s.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できたのがこれ。&lt;/p&gt;

&lt;p&gt;package.json:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;react-redux-scaffold&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;1.0.0&amp;quot;,
  &amp;quot;description&amp;quot;: &amp;quot;React Redux Scaffold&amp;quot;,
  &amp;quot;main&amp;quot;: &amp;quot;src/index.jsx&amp;quot;,
  &amp;quot;repository&amp;quot;: &amp;quot;https://github.com/kaitoy/react-redux-scaffold.git&amp;quot;,
  &amp;quot;author&amp;quot;: &amp;quot;kaitoy&amp;quot;,
  &amp;quot;license&amp;quot;: &amp;quot;MIT&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以降、カレントディレクトリは&lt;code&gt;C:\react-redux-scaffold&lt;/code&gt;として、プロンプト表示は省略する。&lt;/p&gt;

&lt;h1 id=&#34;ビルド環境セットアップ&#34;&gt;ビルド環境セットアップ&lt;/h1&gt;

&lt;p&gt;ビルド環境としてトランスパイラとかモジュールバンドラとかをセットアップする。&lt;/p&gt;

&lt;h2 id=&#34;babel&#34;&gt;Babel&lt;/h2&gt;

&lt;p&gt;トランスパイラはデファクトスタンダードの&lt;a href=&#34;https://babeljs.io/&#34;&gt;Babel&lt;/a&gt;を使う。&lt;/p&gt;

&lt;p&gt;Babelのプラグインはとりあえず最低限入れるとして、以下のnpmパッケージをプロジェクトにインストールする。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://babeljs.io/docs/en/babel-core&#34;&gt;babel-core&lt;/a&gt;: Babel本体。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://babeljs.io/docs/en/babel-preset-react&#34;&gt;babel-preset-react&lt;/a&gt;: Reactの&lt;a href=&#34;https://reactjs.org/docs/introducing-jsx.html&#34;&gt;JSX&lt;/a&gt;とか&lt;a href=&#34;https://flow.org/&#34;&gt;Flow&lt;/a&gt;とかを処理するプラグイン集。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://babeljs.io/docs/en/babel-preset-env&#34;&gt;babel-preset-env&lt;/a&gt;: ES 2015+をES 5にトランスパイルするプラグイン集。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;これらのパッケージは実行時には要らないので&lt;code&gt;yarn add -D&lt;/code&gt;コマンドで開発時依存としてインストールする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D babel-core babel-preset-react babel-preset-env
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Babelは6.26.3が入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、Babelの&lt;a href=&#34;https://babeljs.io/docs/en/babelrc&#34;&gt;設定ファイル&lt;/a&gt;を書いてプロジェクトルートに置いておく。&lt;/p&gt;

&lt;p&gt;.babelrc:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;presets&amp;quot;: [&amp;quot;env&amp;quot;, &amp;quot;react&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;polyfill&#34;&gt;Polyfill&lt;/h2&gt;

&lt;p&gt;BabelはES 2015+で追加された構文の変換はしてくれるけど、追加されたグローバルオブジェクト(e.g. &lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Global_Objects/Promise&#34;&gt;Promise&lt;/a&gt;)とかメソッド(e.g. Object.assignとかArray.prototype.includes)とかを補完してくれるわけではない。
そこを補完してくれるのが&lt;a href=&#34;https://en.wikipedia.org/wiki/Polyfill_%28programming%29&#34;&gt;Polyfill&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;少なくとも後で導入する&lt;a href=&#34;https://redux-saga.js.org/&#34;&gt;redux-saga&lt;/a&gt;が使う&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Statements/function*&#34;&gt;ジェネレータ&lt;/a&gt;がPolyfillを必要とする(ないと&lt;code&gt;ReferenceError: regeneratorRuntime is not defined&lt;/code&gt;というエラーが出る)ので、今の時点で入れておくことにする。&lt;/p&gt;

&lt;p&gt;Polyfillの実装はいくつかあるけど、定番っぽい&lt;a href=&#34;https://babeljs.io/docs/en/babel-polyfill/&#34;&gt;babel-polyfill&lt;/a&gt;を使う。
こちらは実行時依存としてインストールする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add babel-polyfill
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;webpack&#34;&gt;webpack&lt;/h2&gt;

&lt;p&gt;モジュールバンドラは現時点で一番人気の&lt;a href=&#34;https://webpack.js.org/&#34;&gt;webpack&lt;/a&gt;を使う。
(&lt;a href=&#34;https://parceljs.org/&#34;&gt;Parcel&lt;/a&gt;の方がナウいはナウいけど。)&lt;/p&gt;

&lt;p&gt;webpackは、タスクランナーの機能も備えたモジュールバンドラみたいな感じで、バンドルしたいファイルの形式とか実行したいタスクに応じた&lt;a href=&#34;https://webpack.js.org/loaders/&#34;&gt;ローダー&lt;/a&gt;を設定することでプロジェクトのビルドを定義できる。&lt;/p&gt;

&lt;p&gt;ちょっと古いけど&lt;a href=&#34;https://qiita.com/chuck0523/items/caacbf4137642cb175ec&#34;&gt;この記事&lt;/a&gt;を読むとwebpackの理解が深まる。&lt;/p&gt;

&lt;p&gt;こちらもとりあえず最低限のローダーをセットアップするとして、以下のnpmパッケージをプロジェクトにインストールする。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;webpack: webpack本体。&lt;/li&gt;
&lt;li&gt;webpack-cli: webpackのコマンドラインインターフェース。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/webpack/webpack-dev-server&#34;&gt;webpack-dev-server&lt;/a&gt;: webpackから起動できる開発用 HTTP サーバ。ライブリロードしてくれる。(&lt;a href=&#34;https://github.com/webpack-contrib/webpack-serve&#34;&gt;webpack-serve&lt;/a&gt;の方がモダンではある。)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://webpack.js.org/loaders/babel-loader/&#34;&gt;babel-loader&lt;/a&gt;: Babelを実行してくれるやつ。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D webpack webpack-cli webpack-dev-server babel-loader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;webpackはv4.16.0が入った。&lt;/p&gt;

&lt;h3 id=&#34;webpack設定ファイル&#34;&gt;webpack設定ファイル&lt;/h3&gt;

&lt;p&gt;webpackの設定は&lt;a href=&#34;https://webpack.js.org/configuration/&#34;&gt;設定ファイル&lt;/a&gt;を書いてプロジェクトルートに置けばいい。
設定は結構複雑だけど、v1の時よりかは若干書きやすくなったし、公式のマニュアルとかローダーのマニュアル見てれば書くのは難しくない。
&lt;a href=&#34;https://generatewebpackconfig.netlify.com/&#34;&gt;設定ファイルを生成してくれるサイト&lt;/a&gt;もある。&lt;/p&gt;

&lt;p&gt;とりあえず適当に書くとこんな感じ。&lt;/p&gt;

&lt;p&gt;webpack.config.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const path = require(&#39;path&#39;);
const packageJson = require(&#39;./package.json&#39;);

module.exports = {
  mode: &#39;development&#39;,
  entry: [&#39;babel-polyfill&#39;, `./${packageJson.main}`],
  output: {
    path: path.resolve(__dirname, &#39;dist&#39;),
    filename: &#39;bundle.js&#39;,
  },
  module: {
    rules: [
      {
        test: /\.(js|jsx)$/,
        include: [path.resolve(__dirname, &#39;src&#39;)],
        loader: &#39;babel-loader&#39;,
      },
    ],
  },
  resolve: {
    extensions: [&#39;*&#39;, &#39;.js&#39;, &#39;.jsx&#39;],
    modules: [&#39;node_modules&#39;],
  },
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この設定の意味は、&lt;code&gt;./src/index.jsx&lt;/code&gt;を読んで、&lt;code&gt;.js&lt;/code&gt;か&lt;code&gt;.jsx&lt;/code&gt;を拡張子としたファイルとかモジュールをロードするコードがあったら、babel-loaderでBabelを呼んでトランスパイルして、バンドルした結果は&lt;code&gt;&amp;lt;プロジェクトルート&amp;gt;/dist/bundle.js&lt;/code&gt;に吐き出す。
というだけ。
(&lt;a href=&#34;https://nodejs.org/docs/latest/api/modules.html#modules_dirname&#34;&gt;__dirname&lt;/a&gt;はNode.jsが値を入れてくれる変数で、webpack.config.jsのあるディレクトリの絶対パスが入ってる。)&lt;/p&gt;

&lt;p&gt;ファイルをロードするコードというのは、&lt;code&gt;import App from &#39;./components/App&#39;;&lt;/code&gt;みたいなやつ。
webpackはこのコードを読んだら、&lt;code&gt;./components&lt;/code&gt;ディレクトリのなかを見て、&lt;code&gt;App&lt;/code&gt;か&lt;code&gt;App.js&lt;/code&gt;か&lt;code&gt;App.jsx&lt;/code&gt;というファイルを探してロードする。
また、モジュールをロードするコードというのは&lt;code&gt;import React from &#39;react&#39;;&lt;/code&gt;みたいなやつで、webpackはこのコードを読んだら、プロジェクトの&lt;code&gt;node_modules/react/package.json&lt;/code&gt;の&lt;code&gt;main&lt;/code&gt;プロパティの値に書いてあるファイルをロードする。
という挙動が上記webpack.config.jsの&lt;code&gt;resolve&lt;/code&gt;に書いてあって、その詳細は&lt;a href=&#34;https://webpack.js.org/concepts/module-resolution/&#34;&gt;公式のドキュメントのModule Resolution&lt;/a&gt;に書いてある。&lt;/p&gt;

&lt;p&gt;webpack.config.jsの&lt;code&gt;entry&lt;/code&gt;には、最初に&lt;code&gt;babel-polyfill&lt;/code&gt;を書いておいて、bundle.jsの最初に一度だけPolyfillがロードされるようにしている。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;mode&lt;/code&gt;は後述。&lt;/p&gt;

&lt;h3 id=&#34;webpack-dev-server設定&#34;&gt;webpack-dev-server設定&lt;/h3&gt;

&lt;p&gt;webpack-dev-serverの設定もwebpack.config.jsに書く。&lt;/p&gt;

&lt;p&gt;以下を&lt;code&gt;resolve&lt;/code&gt;の次辺りに書き足せばいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;  devServer: {
    contentBase: path.join(__dirname, &#39;public&#39;),
    compress: true,
    hot: true,
    port: 3000,
    publicPath: &#39;http://localhost:3000/&#39;,
  },
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;この設定でwebpack-dev-serverを実行すると、&lt;code&gt;http://localhost:3000/&lt;/code&gt;へのアクセスに&lt;code&gt;public/index.html&lt;/code&gt;を返すWebサーバを起動できる。
Webサーバが起動するときにプロジェクトがインメモリでビルドされ、メモリからbundle.jsがサーブされる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;hot&lt;/code&gt;をtrueにしておくと&lt;a href=&#34;https://webpack.js.org/concepts/hot-module-replacement/&#34;&gt;Hot Module Replacement&lt;/a&gt;が有効になる。
これによって、webpack-dev-serverの起動中にソースを編集すると、自動で再ビルドし、動的にモジュール単位でロードし、ブラウザをリロードしてくれるようになる。
Hot Module Replacementを有効にするときは&lt;code&gt;publicPath&lt;/code&gt;をフルURLで書かないといけない。&lt;/p&gt;

&lt;p&gt;webpack-dev-serverの他の設定については&lt;a href=&#34;https://webpack.js.org/configuration/dev-server/&#34;&gt;公式のマニュアルのDevServer&lt;/a&gt;を見るべし。&lt;/p&gt;

&lt;h3 id=&#34;webpackのmode&#34;&gt;webpackのmode&lt;/h3&gt;

&lt;p&gt;webpackにはビルドの&lt;a href=&#34;https://webpack.js.org/concepts/#mode&#34;&gt;mode&lt;/a&gt;という概念があり、modeを切り替えることで適切な最適化を適用してくれる。&lt;/p&gt;

&lt;p&gt;modeにはdevelopmentとproduction(とnone)があり、productionにしておくと、&lt;a href=&#34;https://webpack.js.org/plugins/uglifyjs-webpack-plugin/&#34;&gt;UglifyJsPlugin&lt;/a&gt;とかを適用して、出力するバンドルファイルのサイズを小さくしてくれたりする。
(v1のころはUglifyJsPluginとかは全部自分でwebpack.config.jsに指定していた記憶があるので、楽になった。)&lt;/p&gt;

&lt;h3 id=&#34;webpack-config-jsの分割&#34;&gt;webpack.config.jsの分割&lt;/h3&gt;

&lt;p&gt;modeを切り替えるのにwebpack.config.jsを書き換えるのはイケてないので、developmentとproductionでファイルを分割して使い分けるようにする。&lt;/p&gt;

&lt;p&gt;developmentとproductionはほとんどが共通の設定なので、共通部分をwebpack.common.jsに書いて、developmentとproductionに固有な設定だけをそれぞれwebpack.dev.jsとwebpack.prod.jsに書く。
webpack.common.jsは、&lt;a href=&#34;https://github.com/survivejs/webpack-merge&#34;&gt;webpack-merge&lt;/a&gt;でwebpack.dev.jsとwebpack.prod.jsにマージする。
というのが&lt;a href=&#34;https://webpack.js.org/guides/production/&#34;&gt;公式&lt;/a&gt;で紹介されているプラクティス。&lt;/p&gt;

&lt;p&gt;まずwebpack-mergeをプロジェクトにインストール。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D webpack-merge
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;分割したファイルは以下の感じ。全部プロジェクトルートに置いておく。&lt;/p&gt;

&lt;p&gt;webpack.common.js&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const path = require(&#39;path&#39;);
const packageJson = require(&#39;./package.json&#39;);

module.exports = {
  entry: [&#39;babel-polyfill&#39;, `./${packageJson.main}`],
  output: {
    path: path.resolve(__dirname, &#39;dist&#39;),
    filename: &#39;bundle.js&#39;,
  },
  module: {
    rules: [
      {
        test: /\.(js|jsx)$/,
        include: [path.resolve(__dirname, &#39;src&#39;)],
        loader: &#39;babel-loader&#39;,
      },
    ],
  },
  resolve: {
    extensions: [&#39;*&#39;, &#39;.js&#39;, &#39;.jsx&#39;],
    modules: [&#39;node_modules&#39;],
  },
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;webpack.dev.js&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const path = require(&#39;path&#39;);
const webpackMerge = require(&#39;webpack-merge&#39;);
const webpackCommon = require(&#39;./webpack.common.js&#39;);

module.exports = webpackMerge(webpackCommon, {
  mode: &#39;development&#39;,
  devServer: {
    contentBase: path.join(__dirname, &#39;public&#39;),
    compress: true,
    hot: true,
    port: 3000,
    publicPath: &#39;http://localhost:3000/&#39;,
  },
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;webpack.prod.js&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const webpackMerge = require(&#39;webpack-merge&#39;);
const webpackCommon = require(&#39;./webpack.common.js&#39;);

module.exports = webpackMerge(webpackCommon, {
  mode: &#39;production&#39;,
});
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;npmスクリプト&#34;&gt;npmスクリプト&lt;/h3&gt;

&lt;p&gt;webpackによるビルドは次のコマンドで実行できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;node_modules\.bin\webpack --config webpack.prod.js
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、webpack-dev-serverは次のコマンドで起動できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;node_modules\.bin\webpack-dev-server --hot --config webpack.dev.js
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--hot&lt;/code&gt;はHot Module Replacementに必要なオプション。&lt;/p&gt;

&lt;p&gt;コマンドが長くて面倒なのは、&lt;a href=&#34;https://docs.npmjs.com/misc/scripts&#34;&gt;npmスクリプト&lt;/a&gt;で楽にできる。
package.jsonの&lt;code&gt;main&lt;/code&gt;の次辺りに以下を書き足せばいい。
(npmスクリプトは実行時に&lt;code&gt;node_modules\.bin&lt;/code&gt;にPATHを通してくれるので、それを省略できる。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;  &amp;quot;scripts&amp;quot;: {
    &amp;quot;build&amp;quot;: &amp;quot;webpack --config webpack.prod.js&amp;quot;,
    &amp;quot;start&amp;quot;: &amp;quot;webpack-dev-server --hot --config webpack.dev.js&amp;quot;
  },
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こうしておくと、&lt;code&gt;yarn build&lt;/code&gt;でビルド、&lt;code&gt;yarn start&lt;/code&gt;でwebpack-dev-server起動できる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でビルド環境セットアップはいったん完了とする。
&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/22/creating-react-redux-app-from-scratch-02/&#34;&gt;次回&lt;/a&gt;はReactが動くところらへんまで。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Webアプリケーションフロントエンド年代記 - 2018年夏編</title>
          <link>https://www.kaitoy.xyz/2018/08/16/chronicle-of-frontend-2018/</link>
          <pubDate>Thu, 16 Aug 2018 23:44:39 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/08/16/chronicle-of-frontend-2018/</guid>
          <description>

&lt;p&gt;Webアプリケーションの、主にフロントエンド周りに関連する歴史をまとめた。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;静的サイト&#34;&gt;静的サイト&lt;/h1&gt;

&lt;p&gt;まずは原初の話から。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1990年代前半&lt;/strong&gt;、まだWebアプリケーションという言葉が無かった時代。
静的にHTMLファイルを配信するだけのWebサイト(静的サイト)だけがあった。
静的サイトでは、HTTPサーバーに複数のHTMLファイルを置いておいて、クライアントのHTTPリクエストのURLのパスによって配信するHTMLファイルを変える。&lt;/p&gt;

&lt;p&gt;例えば、HTTPサーバーを&lt;a href=&#34;https://httpd.apache.org/&#34;&gt;httpd&lt;/a&gt;で立てて、ドキュメントルートを&lt;code&gt;/var/www/html&lt;/code&gt;に設定して、以下のようにファイルを配置したとする。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;/var/www/html/
    |
    +-- index.html
    |
    +-- sub/
          |
          +-- hoge.html
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;この場合、ブラウザで&lt;code&gt;http://&amp;lt;HTTPサーバアドレス&amp;gt;/index.html&lt;/code&gt;にアクセスすれば&lt;code&gt;/var/www/html/index.html&lt;/code&gt;が配信されてレンダリングされて表示される。
&lt;code&gt;http://&amp;lt;HTTPサーバアドレス&amp;gt;/sub/hoge.html&lt;/code&gt;にアクセスすれば&lt;code&gt;/var/www/html/sub/hoge.html&lt;/code&gt;が配信される。&lt;/p&gt;

&lt;p&gt;古のWebサイトは、こんな感じにコンテンツごとにHTMLファイルを書いてサーバに置いておいて、その間にリンクを張って辿れるようにすることで構成されていた。&lt;/p&gt;

&lt;p&gt;まあ今も大体そんな感じだけど。&lt;/p&gt;

&lt;h1 id=&#34;動的html生成-プログラムでhtmlを書き出す&#34;&gt;動的HTML生成 (プログラムでHTMLを書き出す)&lt;/h1&gt;

&lt;p&gt;静的サイトだと表現できることが非常に限られるので、クライアントからのリクエストの内容をサーバが解釈し、DBの情報やなんかをもとにサーバ側でHTMLドキュメントを動的に生成し、クライアントに返す、ということをするようになった。&lt;/p&gt;

&lt;p&gt;原始的(&lt;strong&gt;1990年代中盤から後半&lt;/strong&gt;)には、プログラム中で一連のHTMLドキュメントを出力する方法がとられた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void doGet(
  HttpServletRequest request, HttpServletResponse response
) throws IOException, ServletException {

  response.setContentType(&amp;quot;text/html;&amp;quot;);
  PrintWriter out = response.getWriter();

  out.println(&amp;quot;&amp;lt;html&amp;gt;&amp;quot;);
  out.println(&amp;quot;  &amp;lt;head&amp;gt;&amp;quot;);
  out.println(&amp;quot;    &amp;lt;title&amp;gt;Hoge&amp;lt;/title&amp;gt;&amp;quot;);
  out.println(&amp;quot;  &amp;lt;/head&amp;gt;&amp;quot;);
  out.println(&amp;quot;  &amp;lt;body&amp;gt;&amp;quot;);
  out.println(new java.util.Date());
  out.println(&amp;quot;  &amp;lt;/body&amp;gt;&amp;quot;);
  out.println(&amp;quot;&amp;lt;/html&amp;gt;&amp;quot;);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使われた技術は、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Common_Gateway_Interface&#34;&gt;CGI&lt;/a&gt; (Perl)とか、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Java_Servlet&#34;&gt;Java Servlet&lt;/a&gt;とか。
&lt;a href=&#34;http://jakarta.apache.org/ecs/index.html&#34;&gt;Jakarta ECS&lt;/a&gt;なんてのもあった。&lt;/p&gt;

&lt;h1 id=&#34;動的html生成-htmlにプログラムを埋め込む&#34;&gt;動的HTML生成 (HTMLにプログラムを埋め込む)&lt;/h1&gt;

&lt;p&gt;プログラムでHTMLを書き出すことにより、かなり動的な感じにはなったが、書き出す処理を書くのがめんどくさすぎるし、読みにくい。
そのため、&lt;strong&gt;1990年代後半から2000年代初頭&lt;/strong&gt; にかけ、HTMLを主体にして、そのなかの動的な部分だけにプログラムを埋め込む技術がいくつも生まれた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-jsp&#34;&gt;&amp;lt;%@ page contentType=&amp;quot;text/html %&amp;gt;

&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
    &amp;lt;title&amp;gt;Hoge&amp;lt;/title&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
    &amp;lt;%
    out.println(new java.util.Date());
    %&amp;gt;
  &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;HTMLドキュメントのひな型を作っておいて、その中にプログラムの処理結果を埋め込んでクライアントに返すため、テンプレートエンジンとか、テンプレートシステムとか呼ばれる。&lt;/p&gt;

&lt;p&gt;該当する技術は、&lt;a href=&#34;http://www.php.net/&#34;&gt;PHP&lt;/a&gt;とか、&lt;a href=&#34;https://ja.wikipedia.org/wiki/JavaServer_Pages&#34;&gt;JSP&lt;/a&gt;とか、&lt;a href=&#34;http://velocity.apache.org/&#34;&gt;Velocity&lt;/a&gt;とか、&lt;a href=&#34;https://ja.wikipedia.org/wiki/ERuby&#34;&gt;eRuby&lt;/a&gt;とか。&lt;/p&gt;

&lt;h1 id=&#34;dhtml&#34;&gt;DHTML&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;1990年代後半&lt;/strong&gt;、クライアントサイドのJavaScriptでHTMLドキュメントをいじって、多少の動的感・インタラクティブ感をだす技術は既に一応あって、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%80%E3%82%A4%E3%83%8A%E3%83%9F%E3%83%83%E3%82%AFHTML&#34;&gt;DHTML&lt;/a&gt;と呼ばれていた。&lt;/p&gt;

&lt;p&gt;DHTMLの肝はJavaScriptの&lt;a href=&#34;https://ja.wikipedia.org/wiki/Document_Object_Model&#34;&gt;DOM&lt;/a&gt; APIだ。
このAPIでは、HTML文書が各要素(タグなど)をノードとするツリー構造(DOMツリー)で表され、任意の要素を検索して取得したり、属性などを書き換えたり、要素の追加・削除ができる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;&amp;lt;!DOCTYPE HTML PUBLIC &amp;quot;-//W3C//DTD HTML 4.01 Transitional//EN&amp;quot; &amp;quot;http://www.w3.org/TR/html4/loose.dtd&amp;quot;&amp;gt;
&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
    &amp;lt;div id=&amp;quot;hogehoge&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
    &amp;lt;script type=&amp;quot;text/javascript&amp;quot;&amp;gt;
      // idがhogehogeの要素の子要素として「&amp;lt;p&amp;gt;HOGEEEEEEE&amp;lt;/p&amp;gt;」を追加。
      document.getElementById(&amp;quot;hogehoge&amp;quot;).innerHTML = &amp;quot;&amp;lt;p&amp;gt;HOGEEEEEEE&amp;lt;/p&amp;gt;&amp;quot;
    &amp;lt;/script&amp;gt;
  &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;しかし、このころのJavaScriptは、仕様・機能が貧弱だった上、ブラウザ間で挙動に差があったり、標準メソッドがブラウザ固有のメソッドで代替されていたりして開発体験が最悪だったためか、今日のようにWeb UIの中心的役割を果たすことはなく、補助的・装飾的機能の実装に使われることが多かったように思う。&lt;/p&gt;

&lt;p&gt;アクセスした日付を表示したり、背景に雪を降らせたり、マウスカーソルを目玉に追いかけさせたり。&lt;/p&gt;

&lt;h1 id=&#34;mvcアーキテクチャ&#34;&gt;MVCアーキテクチャ&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;2000年初頭&lt;/strong&gt;、&lt;a href=&#34;http://struts.apache.org/&#34;&gt;Struts&lt;/a&gt; (Struts1)というJavaのWebアプリケーションフレームワークが流行り、Controller (Java Servlet)がクライアントからリクエストを受け取り、Model (JavaBeans)がそれを処理して、View (JSP)がHTMLをレンダリングしてクライアントに返す、という、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Model_View_Controller&#34;&gt;MVCアーキテクチャ&lt;/a&gt;が流行った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/MVC-Process.svg/500px-MVC-Process.svg.png&#34; alt=&#34;MVC&#34; title=&#34;MVC&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Strutsに続いて&lt;a href=&#34;https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html&#34;&gt;Spring MVC&lt;/a&gt;、&lt;a href=&#34;https://rubyonrails.org/&#34;&gt;Ruby on Rails&lt;/a&gt;、&lt;a href=&#34;https://cakephp.org/jp&#34;&gt;CakePHP&lt;/a&gt;といったフレームワークが出てきて、MVCアーキテクチャによる開発効率や開発体験は洗練されていった。&lt;/p&gt;

&lt;h1 id=&#34;ajax&#34;&gt;Ajax&lt;/h1&gt;

&lt;p&gt;Strutsが全盛期の&lt;strong&gt;2005年&lt;/strong&gt;ころ、JavaScriptで非同期にサーバからデータを取得し、それをもとにクライアントサイドでHTMLを動的に編集するような技術に、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Ajax&#34;&gt;Ajax&lt;/a&gt;という名前が付いた。&lt;/p&gt;

&lt;p&gt;Ajaxは「Asynchronous JavaScript + XML」の略で、&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/XMLHttpRequest&#34;&gt;XMLHttpRequest&lt;/a&gt; (略してXHR)というJavaScriptのAPIで
、サーバにHTTPリクエストを送り、そのレスポンスを非同期に処理する技術。
レスポンスは、当時XMLが流行っていたので、その形式で送ることが想定されていたが、実際にはどんな形式でもいい。はず。
最近はJSONで送られることがほとんど。&lt;/p&gt;

&lt;p&gt;JavaScriptはシングルスレッドで動くわけだけど、XMLHttpRequestはレスポンスを非同期に処理するため、リクエスト送信からレスポンス受信までの間、クライアントがスタックせずに済む。
また、通常のHTTPリクエストは、完全なHTMLドキュメントを受信して画面全体をレンダリングしなおす(i.e. 画面遷移する)のに対して、Ajaxは受信したデータをもとに画面の一部だけを更新するので、ネイティブアプリケーションに近めなユーザエクスペリエンスを実現できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var xhr = new XMLHttpRequest();
xhr.open(&#39;GET&#39;, &#39;https://httpbin.org/get&#39;, true);
xhr.onreadystatechange = function() {
  if (xhr.readyState === 4 &amp;amp;&amp;amp; xhr.status === 200) {
    console.log(xhr.responseText);
    // DOMをいじる処理
    // …
  }
};
xhr.send(null);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ajaxは、GoogleがGoogle Mapsで活用して一気に注目を集めた。
地図データをサーバから非同期に先読みするなどして、マウスのドラッグによって地図を滑らかにスクロールして見せるそのUIは当時画期的で、それまでの、画面遷移中心のUIからの飛躍を感じさせた。&lt;/p&gt;

&lt;h1 id=&#34;prototypeとjquery&#34;&gt;PrototypeとjQuery&lt;/h1&gt;

&lt;p&gt;Ajaxの普及を後押ししたのが、&lt;a href=&#34;http://prototypejs.org/&#34;&gt;Prototype&lt;/a&gt;と&lt;a href=&#34;https://jquery.com/&#34;&gt;jQuery&lt;/a&gt;というJavaScriptライブラリの登場だった。&lt;/p&gt;

&lt;p&gt;PrototypeはRubyにインスパイアされて開発され、Ruby on Railsに採用されたことで&lt;strong&gt;2005年&lt;/strong&gt;ころから普及したライブラリで、JavaScriptの標準グローバルオブジェクトであるArrayとかElementに便利メソッドを生やしたり、独自のグローバルユーティリティオブジェクトを追加したりして、Ajax処理をしやすくしたり、JavaScriptの機能を拡張してくれたりする。&lt;/p&gt;

&lt;p&gt;特に、当時のプロトタイプベースで使いにくかったJavaScriptのオブジェクト指向を扱いやすくしてくれる&lt;a href=&#34;http://prototypejs.org/learn/class-inheritance&#34;&gt;Class&lt;/a&gt;や、配列の処理に便利なeachとかmapとかincludeとかのメソッドを追加する&lt;a href=&#34;http://api.prototypejs.org/language/Enumerable/&#34;&gt;Enumerable&lt;/a&gt;なんかが熱かったように思う。&lt;/p&gt;

&lt;p&gt;一方jQueryは、ファーストバージョンが&lt;strong&gt;2006年8月&lt;/strong&gt;にリリースされ、ブラウザ間の非互換性をほとんど気にすることなく、簡潔なコードでDOM操作やAjax通信ができるAPIを提供した。
Prototypeと比べて、標準オブジェクトやグローバル名前空間を汚さない点がよかったのか、&lt;strong&gt;2007年&lt;/strong&gt; ころにはPrototypeを抜いて猛烈に普及した。&lt;/p&gt;

&lt;p&gt;この頃からWebアプリケーションは、UIはクライアントサイドのJavaScriptでインタラクティブな感じに書いて、サーバサイドはXMLHttpRequestに対してJSONデータを返すAPIサーバとして働く、という感じのものが増えていったように思う。
またこの頃から、クライアントサイドの開発が量質ともに上がったために独立した仕事になり、サーバサイドと対比して、前者をフロントエンド、後者をバックエンドと呼ぶようになってきた。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;因みに、PrototypeやjQueryと同様というかもう少し高機能な&lt;a href=&#34;https://dojotoolkit.org/&#34;&gt;Dojo Toolkit&lt;/a&gt;というライブラリが&lt;strong&gt;2004年&lt;/strong&gt;ころからあったんだけど、あまり流行らなかった。
カスタムビルドという、モジュールを結合してminifyする&lt;a href=&#34;https://webpack.js.org/&#34;&gt;webpack&lt;/a&gt;みたいな機能を、&lt;a href=&#34;https://nodejs.org/ja/&#34;&gt;Node.js&lt;/a&gt;もない時代に実現していた先進的なライブラリだったんだけど、時代がついてこれなかったのかもしれない。&lt;/p&gt;

&lt;h1 id=&#34;ria-flashとか&#34;&gt;RIA (Flashとか)&lt;/h1&gt;

&lt;p&gt;WebアプリケーションにはAjaxと別の世界線もあった。&lt;/p&gt;

&lt;p&gt;そこでは&lt;strong&gt;1997年&lt;/strong&gt;ころに&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%AA%E3%83%83%E3%83%81%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%BC%E3%83%8D%E3%83%83%E3%83%88%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3&#34;&gt;RIA (Rich Internet Application)&lt;/a&gt;という言葉が生まれた。
これは、クライアントサイドの技術を駆使した、表現力やユーザビリティが高いWebアプリケーションのこと。&lt;/p&gt;

&lt;p&gt;(実際にはAjaxなアプリもこのくくりに入るが、ここでは非Web標準なクライアントサイド技術を使ったものの話を書く。)&lt;/p&gt;

&lt;p&gt;RIA技術の代表格である&lt;a href=&#34;https://ja.wikipedia.org/wiki/Adobe_Flash&#34;&gt;Flash&lt;/a&gt;は&lt;strong&gt;1996年&lt;/strong&gt;に生まれた。
このころはShockwave FlashとかMacromedia Flashとか呼ばれたが、開発元が&lt;strong&gt;2005年&lt;/strong&gt;にAdobeに買収されてAdobe Flashになり、そのあたりから&lt;strong&gt;2010年代前半&lt;/strong&gt;辺りまで最先端のWeb UI技術として甚だしく流行った。&lt;/p&gt;

&lt;p&gt;Flashは、&lt;a href=&#34;https://www.adobe.com/jp/products/flex.html&#34;&gt;Flex&lt;/a&gt;というフレームワーク(ツール?)のもと、&lt;a href=&#34;https://ja.wikipedia.org/wiki/ActionScript&#34;&gt;ActionScript&lt;/a&gt;というJavaScriptっぽいプログラミング言語と、&lt;a href=&#34;https://ja.wikipedia.org/wiki/MXML&#34;&gt;MXML&lt;/a&gt;というXMLなUI記述言語を駆使してWeb UIを開発できる技術。
WebブラウザにAdobe Flash PlayerとかAdobe AIRのプラグインを入れると表示できる。&lt;/p&gt;

&lt;p&gt;Flashの人気に触発されたのか、Microsoftが&lt;strong&gt;2007年&lt;/strong&gt;に&lt;a href=&#34;https://www.microsoft.com/silverlight/&#34;&gt;Silverlight&lt;/a&gt;というのをリリースした。
これは、&lt;a href=&#34;https://ja.wikipedia.org/wiki/.NET_Framework&#34;&gt;.NET Framework&lt;/a&gt;な言語(&lt;a href=&#34;https://docs.microsoft.com/ja-jp/dotnet/csharp/&#34;&gt;C#&lt;/a&gt;とか&lt;a href=&#34;https://msdn.microsoft.com/ja-jp/library/cc427807.aspx&#34;&gt;JScript&lt;/a&gt;とか)と、&lt;a href=&#34;https://docs.microsoft.com/ja-jp/dotnet/framework/wpf/advanced/xaml-overview-wpf&#34;&gt;XAML&lt;/a&gt;というHTMLっぽいUI記述言語を駆使してWeb UIを開発できる技術。
WebブラウザにMicrosoft Silverlightプラグインを入れると表示できる。&lt;/p&gt;

&lt;p&gt;また、Flashの誕生とほぼ同時期に、JavaでWebアプリケーションのUIを書く&lt;a href=&#34;https://ja.wikipedia.org/wiki/Java%E3%82%A2%E3%83%97%E3%83%AC%E3%83%83%E3%83%88&#34;&gt;Java Applet&lt;/a&gt;というのも生まれていた。が、初期のバージョンでロードに時間がかかったり動作が重かったりする問題があり、嫌厭されてFlashほど流行らなかった。
WebブラウザにJavaプラグインを入れると表示できる。
なぜか最近になって、&lt;strong&gt;2017年&lt;/strong&gt; 公開のマイナンバーのポータルサイトで採用されて話題になった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;こうした非Web標準技術を使ったRIAは、Ajaxに比べてリッチな表現ができたり、ブラウザ間の非互換性に悩まされないところに優位性があったが、以下のような問題があった。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;プロプライエタリな技術をベースにしていて、実装がブラックボックスだったり、仕様の方向性がベンダの都合に左右されたり、ベンダロックインされやすかったりする。&lt;/li&gt;
&lt;li&gt;ユーザがブラウザにプラグインをいれてないと表示されない。&lt;/li&gt;
&lt;li&gt;セキュリティ問題が見つかった場合、オープンな技術のものに比べて対策が遅い傾向があるし、ベンダによる実装しかないので替えが利かない。&lt;/li&gt;
&lt;li&gt;他ベンダの技術や標準技術との親和性が無かったり、連携が弱かったりする。&lt;/li&gt;
&lt;li&gt;ブラウザ内で文字列検索ができなかったり、検索エンジンにまともにクローリングしてもらえない。&lt;/li&gt;
&lt;li&gt;動作が重い。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;このような問題のためか、Web標準周辺技術の発展に伴い、一時期は隆盛を誇ったFlashなども次第に廃れていった。&lt;/p&gt;

&lt;p&gt;Flashは&lt;strong&gt;2020年&lt;/strong&gt;に、Silverlightは&lt;strong&gt;2021年&lt;/strong&gt;にサポート終了になり、Java Appletは&lt;strong&gt;2018年9月&lt;/strong&gt;に出るJava 11で廃止されることが決まっている。&lt;/p&gt;

&lt;h1 id=&#34;html-5とcss-3とecmascript-5&#34;&gt;HTML 5とCSS 3とECMAScript 5&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;2000年代中盤&lt;/strong&gt; から非Web標準なRIAが流行ったのは、そもそもWeb標準技術であるHTML、CSS、JavaScript(というかその標準仕様を定める&lt;a href=&#34;https://ja.wikipedia.org/wiki/ECMAScript&#34;&gt;ECMAScript&lt;/a&gt;)が、アプリケーションのUIを作るという目的で設計されているわけではなく、それらを使ってWeb UIを作ることに限界があったのが一因だったと思う。&lt;/p&gt;

&lt;p&gt;RIAの流行を受け、Web標準業界に危機感が募ったのか、&lt;strong&gt;2000年代後半&lt;/strong&gt; くらいからWeb標準技術にWeb UIを意識したバージョンアップの動きが始まった。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.w3schools.com/html/html5_intro.asp&#34;&gt;HTML 5&lt;/a&gt;の勧告 (&lt;strong&gt;2014年&lt;/strong&gt;)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;それまでの標準であるHTML 4.01の勧告が&lt;strong&gt;1999年&lt;/strong&gt;だったので、&lt;strong&gt;15年&lt;/strong&gt; ぶり。&lt;/li&gt;
&lt;li&gt;文書構造を表すタグの追加: &lt;code&gt;&amp;lt;header&amp;gt;&lt;/code&gt;とか&lt;code&gt;&amp;lt;footer&amp;gt;&lt;/code&gt;とか。&lt;/li&gt;
&lt;li&gt;図を表現するためのタグの追加: &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt;と&lt;code&gt;&amp;lt;canvas&amp;gt;&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;inputタイプの追加: &lt;code&gt;date&lt;/code&gt;、&lt;code&gt;range&lt;/code&gt;、&lt;code&gt;email&lt;/code&gt;とか。&lt;/li&gt;
&lt;li&gt;inputタグの属性の追加: &lt;code&gt;autocomplete&lt;/code&gt;、&lt;code&gt;pattern&lt;/code&gt;、&lt;code&gt;placeholder&lt;/code&gt;、&lt;code&gt;required&lt;/code&gt;とか。&lt;/li&gt;
&lt;li&gt;マルチメディアのためのタグの追加:&lt;code&gt;&amp;lt;audio&amp;gt;&lt;/code&gt;と&lt;code&gt;&amp;lt;video&amp;gt;&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;Webアプリケーション向けAPI追加: Drag and Drop、Local Storage、Web Workerとか。&lt;/li&gt;
&lt;li&gt;冗長だったり見た目に関するタグ・属性の削除: &lt;code&gt;&amp;lt;center&amp;gt;&lt;/code&gt;とか&lt;code&gt;&amp;lt;font&amp;gt;&lt;/code&gt;とか&lt;code&gt;border&lt;/code&gt;とか&lt;code&gt;color&lt;/code&gt;とか。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;data-*&lt;/code&gt;属性のサポート。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/CSS3&#34;&gt;CSS 3&lt;/a&gt;の勧告 (&lt;strong&gt;2011年&lt;/strong&gt;)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;それまでの標準であるCSS 2の勧告が&lt;strong&gt;1998年&lt;/strong&gt;だったので、&lt;strong&gt;13年&lt;/strong&gt; ぶり。&lt;/li&gt;
&lt;li&gt;角丸、シャドウ、グラデーションのサポート。&lt;/li&gt;
&lt;li&gt;セレクタの機能追加: 属性値の部分マッチ、nth-childなど。&lt;/li&gt;
&lt;li&gt;メディアクエリ。&lt;/li&gt;
&lt;li&gt;Flexboxレイアウト、Gridレイアウト。&lt;/li&gt;
&lt;li&gt;Webフォント。&lt;/li&gt;
&lt;li&gt;トランジション、トランスフォーム、アニメーション。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.w3schools.com/js/js_es5.asp&#34;&gt;ECMAScript 5&lt;/a&gt;の発行 (&lt;strong&gt;2009年&lt;/strong&gt;)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;それまでの標準であるECMAScript 3の勧告が&lt;strong&gt;1999年&lt;/strong&gt;だったので、&lt;strong&gt;10年&lt;/strong&gt; ぶり。&lt;/li&gt;
&lt;li&gt;strictモード。&lt;/li&gt;
&lt;li&gt;Arrayのメソッド追加: forEach、map、filterなど。&lt;/li&gt;
&lt;li&gt;Objectのメソッド追加: keys、freezeなど。&lt;/li&gt;
&lt;li&gt;グローバルオブジェクトにJSONが追加。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;javascriptフロントエンドフレームワーク-第1世代&#34;&gt;JavaScriptフロントエンドフレームワーク (第1世代)&lt;/h1&gt;

&lt;p&gt;Web標準技術が進化して表現力が上がり、ECMAScript 5やjQueryによってロジックを書きやすくなり、人々がWeb UIをバリバリ書けるようになり、RIAの影響もあってUIの複雑化が進んだ。&lt;/p&gt;

&lt;p&gt;UIが複雑化すると、ユーザ入力の処理、Ajaxによるサーバとのデータ通信、UIの状態の取得、DOMの操作なんかを、何の秩序も構造化もレイヤー分けもなくナイーブにコーディングするのが辛くなってきた。&lt;/p&gt;

&lt;p&gt;この辛みに対処すべく誕生してきたのが数多のJavaScriptフロントエンドフレームワーク。
&lt;strong&gt;2018年現在&lt;/strong&gt; まで続くフロントエンドフレームワーク戦国時代の幕開けである。&lt;/p&gt;

&lt;p&gt;フロントエンドフレームワークは大抵以下のような機能を提供してくれる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;UI(View)の記述を楽にする何か。テンプレートエンジンとか。&lt;/li&gt;
&lt;li&gt;Viewに表示しているデータとJavaScriptプログラムで保持しているデータを紐づける仕組み。(i.e. &lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%87%E3%83%BC%E3%82%BF%E3%83%90%E3%82%A4%E3%83%B3%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0&#34;&gt;データバインディング&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Ajaxユーティリティ。&lt;/li&gt;
&lt;li&gt;URLをViewやロジックと紐づける仕組み。(i.e. URLルーティング)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;フロントエンドフレームワーク戦国時代初期に生まれた主要なフロントエンドフレームワークを列挙する。&lt;/p&gt;

&lt;p&gt;(この記事では便宜上第1世代と呼ぶ。)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://knockoutjs.com/&#34;&gt;Knockout&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2010年&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/Model_View_ViewModel&#34;&gt;MVVMアーキテクチャ&lt;/a&gt;。

&lt;ul&gt;
&lt;li&gt;ModelがUIと独立してデータ(Ajaxでサーバから取ったものなど)を保持する。&lt;/li&gt;
&lt;li&gt;ViewModelがUIに紐づくデータとその操作を表現する。&lt;/li&gt;
&lt;li&gt;ViewはDOMツリー。ViewModelへの変更は自動でViewに反映されるし、その逆もしかり。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://backbonejs.org/&#34;&gt;Backbone.js&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2010年&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;主にModelとViewからなるMVC的アーキテクチャ。

&lt;ul&gt;
&lt;li&gt;Modelはデータとビジネスロジックを表現する。

&lt;ul&gt;
&lt;li&gt;サーバから取ってきたデータを保持。&lt;/li&gt;
&lt;li&gt;ビジネスロジックによってデータが変わると、イベントを生成。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ViewがModelをDOMに反映する。

&lt;ul&gt;
&lt;li&gt;ModelからのイベントをlistenしてDOMに反映。&lt;/li&gt;
&lt;li&gt;ユーザからの入力を取得して、Modelに渡す。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.emberjs.com/&#34;&gt;Ember.js&lt;/a&gt; v1&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2011年&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;MVVMアーキテクチャ。&lt;/li&gt;
&lt;li&gt;URLルーティングをコアとするコンセプトが特徴的。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://angularjs.org/&#34;&gt;AngularJS&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2012年&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;Google製。&lt;/li&gt;
&lt;li&gt;MVVMアーキテクチャ。&lt;/li&gt;
&lt;li&gt;DIやテストなどのサポートまであるフルスタックフレームワーク。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;第1世代は、フロントエンドの世界にMVCアーキテクチャ(とその派生)をもたらした。&lt;/p&gt;

&lt;p&gt;このMVCは、Struts時代のMVCとは違い、完全にクライアントサイドに閉じたアーキテクチャだ。
サーバ側はエントリーポイントとしてHTML(とCSSとJavaScript)をサーブするほかは、JSONを返すAPIサーバとしての役割に徹する。
このようなWebアプリケーションは、ページ遷移が発生せず、単一ページだけでUIが構成されるので、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%B7%E3%83%B3%E3%82%B0%E3%83%AB%E3%83%9A%E3%83%BC%E3%82%B8%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3&#34;&gt;Single Page Application (SPA)&lt;/a&gt;と呼ばれる。&lt;/p&gt;

&lt;p&gt;ModelとViewとの間でのデータの同期の仕方には以下のように2方向がある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;M⇒V: Modelを更新すると対応するViewが自動で更新される。&lt;/li&gt;
&lt;li&gt;V⇒M: Viewがユーザ入力などによって変更されるとModelが自動で更新される。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;前者だけをするのが1-wayバインディングで、両方するのが2-wayバインディング。
上に挙げた中では、Backbone.js以外が2-wayバインディング推しで、このころは2-wayバインディングが正義だったっぽい。&lt;/p&gt;

&lt;h1 id=&#34;commonjs-node-js-パッケージマネージャ-モジュールバンドラ-altjs-altcss-トランスパイラ-タスクランナー&#34;&gt;CommonJS、Node.js、パッケージマネージャ、モジュールバンドラ、AltJS、AltCSS、トランスパイラ、タスクランナー&lt;/h1&gt;

&lt;p&gt;第1世代のフロントエンドフレームワークが出始めたころ、JavaScriptの言語周りの環境にも大きな変化があった。
正直書くの辛くなってきたので、一気に片付ける。&lt;/p&gt;

&lt;h3 id=&#34;commonjs&#34;&gt;CommonJS&lt;/h3&gt;

&lt;p&gt;クライアントサイドでJavaScriptが盛り上がっているのを見て、もっとJavaScriptいろんなところで活用できるんじゃね?
となって、ブラウザの外でも普通のプログラミング言語としてJavaScriptを使うためには、どんな機能を追加すべきか、みたいな議論をするプロジェクトが&lt;strong&gt;2009年&lt;/strong&gt;に立ち上がった。
&lt;a href=&#34;http://www.commonjs.org/&#34;&gt;CommonJS&lt;/a&gt;である。&lt;/p&gt;

&lt;p&gt;CommonJSの最大の功績は多分、モジュールシステムを言語仕様でちゃんとサポートしよう、と言ったこと。
モジュールシステムは、Cでいうincludeとか、JavaやPythonのimportとか、そういう機能。
JavaScriptにはもともとそういうのが無くて、単にファイルを分割して個別にロードしていただけだったので、名前空間がコンフリクトしたりしなかったりしてた。&lt;/p&gt;

&lt;p&gt;因みに、JavaScriptのモジュールシステムには、CommonJSのやつ以外にも&lt;a href=&#34;https://en.wikipedia.org/wiki/Asynchronous_module_definition&#34;&gt;AMD&lt;/a&gt;というのがあったけど、そっちは盛り上がらなかった。&lt;/p&gt;

&lt;h3 id=&#34;node-js&#34;&gt;Node.js&lt;/h3&gt;

&lt;p&gt;CommonJSの流れを汲んで、サーバサイドのJavaScriptランタイムとして&lt;a href=&#34;https://nodejs.org/en/&#34;&gt;Node.js&lt;/a&gt;が&lt;strong&gt;2009年&lt;/strong&gt;にリリースされた。
これにより、ブラウザ外でJavaScriptを実行できるようになり、以降のJavaScript開発体験の劇的な改善につながった。&lt;/p&gt;

&lt;h3 id=&#34;パッケージマネージャ&#34;&gt;パッケージマネージャ&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;2010年&lt;/strong&gt; には、Node.jsにパッケージマネージャとして&lt;a href=&#34;https://www.npmjs.com/&#34;&gt;npm&lt;/a&gt;が同梱されるようになった。
これにより、モジュールを公開してシェアして再利用する文化が定着し、JavaScriptプログラムの開発効率や品質がかなり向上したはず。&lt;/p&gt;

&lt;p&gt;パッケージマネージャとしてはもうひとつ、&lt;a href=&#34;https://bower.io/&#34;&gt;Bower&lt;/a&gt;というのが&lt;strong&gt;2012年&lt;/strong&gt;に出た。
npmはサーバサイドのパッケージ、Bowerはクライアントサイドのパッケージ、みたいな住みわけが当初はあったが、最近は全部npmになってBower使ってるプロジェクトは見なくなった。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2016年10月&lt;/strong&gt; には、Facebookが&lt;a href=&#34;https://yarnpkg.com/lang/ja/&#34;&gt;Yarn&lt;/a&gt;というnpmを代替するツールを&lt;a href=&#34;https://code.fb.com/web/yarn-a-new-package-manager-for-javascript/&#34;&gt;発表&lt;/a&gt;。
パッケージバージョンのロック、&lt;a href=&#34;https://twitter.com/madbyk/status/988795520805203969?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E988795520805203969&amp;amp;ref_url=https%3A%2F%2Fblog.risingstack.com%2Fyarn-vs-npm-node-js-package-managers%2F&#34;&gt;CDN (CloudFlare)&lt;/a&gt;・キャッシュ・並列処理によるパッケージダウンロードの高速化、パッケージ間のバージョンの不整合解消(フラットモード)、といった機能により、発表直後から急速にシェアを伸ばした。&lt;/p&gt;

&lt;h3 id=&#34;モジュールバンドラ&#34;&gt;モジュールバンドラ&lt;/h3&gt;

&lt;p&gt;サーバサイドでモジュールシステムができたのはよかったけど、その仕様がブラウザでサポートされることは終ぞなかった。
ので、モジュールバンドラというものが生まれた。
これは、ソース中のモジュールインポート(requireとかimport)をたどって、モジュール分割されたソースをブラウザが読めるように一つに結合してくれるツール。&lt;/p&gt;

&lt;p&gt;モジュールバンドラのパイオニアが、&lt;strong&gt;2011年&lt;/strong&gt; にリリースされた&lt;a href=&#34;http://browserify.org/&#34;&gt;Browserify&lt;/a&gt;。
Browserifyは、モジュールの結合だけでなく、Node.js特有のAPIをある程度ブラウザでも動くようにしてくれるなど、魔法のようなツールだった。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2012年&lt;/strong&gt; には&lt;a href=&#34;https://webpack.js.org/&#34;&gt;webpack&lt;/a&gt;というモジュールバンドラが出て、後述のトランスパイラと上手く連携したり、JavaScriptだけでなくCSSもHTMLもフォントも画像ファイルもなんでもバンドルできる高機能により、Browserifyを食った。&lt;/p&gt;

&lt;p&gt;モジュールバンドルすると、ファイルサイズが大きくなって、ブラウザでロードするのに時間がかかって、初期画面の表示が遅くなる問題があった。
&lt;strong&gt;2015年&lt;/strong&gt;、その問題を軽減すべく、&lt;a href=&#34;https://rollupjs.org/guide/en&#34;&gt;Rollup&lt;/a&gt;というのが出てきた。
Rollupは、&lt;a href=&#34;https://rollupjs.org/guide/en#tree-shaking&#34;&gt;Tree-shaking&lt;/a&gt;という機能で、バンドル時に不要なコードを削除することでファイルサイズを小さくできることを売りにした。
が、webpackがバージョン2でTree-shakingをサポートしたため、使う理由がなくなった。&lt;/p&gt;

&lt;p&gt;webpackは機能的には最高にクールだったが、設定が複雑で設定ファイルが肥大化するという問題があった。
この問題を解消すべく、&lt;strong&gt;2017年末&lt;/strong&gt; に&lt;a href=&#34;https://parceljs.org/&#34;&gt;Parcel&lt;/a&gt;というモジュールバンドラがリリースされ、ゼロ設定で使えるということで人気を集めてきている。
今の時点でプロダクションレディなレベルなのかは疑問。&lt;/p&gt;

&lt;h3 id=&#34;altjs&#34;&gt;AltJS&lt;/h3&gt;

&lt;p&gt;上に書いた通り、&lt;strong&gt;2009年&lt;/strong&gt; にECMAScript 5が発行されて、JavaScriptは若干改善されたわけだけど、はっきり言ってまだまだ貧弱な言語だった。
そこに&lt;a href=&#34;https://coffeescript.org/&#34;&gt;CoffeeScript&lt;/a&gt;が登場。
&lt;strong&gt;2009年末&lt;/strong&gt; のことだった。&lt;/p&gt;

&lt;p&gt;CoffeeScriptは、RubyやPythonみたいな簡潔で機能的な構文を備えた生産性の高い言語で、JavaScriptにコンパイルできる。
クラス構文とか、アロー関数とか、配列内包表記とか、インデントによるブロック構造とかを実現してて書き心地がかなりよかったのと、Ruby on Railsに採用されたというのもあって、&lt;strong&gt;2010年代中盤&lt;/strong&gt; くらいまで結構流行った。&lt;/p&gt;

&lt;p&gt;CoffeeScriptのように、JavaScriptの代替として使い、JavaScriptに変換して実行するのを主なユースケースとする言語を、AltJS (Alternative JavaScript)と呼ぶ。
CoffeeScriptの最大の功績は、このAltJSという分野を切り開き、JavaScriptフロントエンドにコンパイルという概念を持ち込んだことだったと思う。&lt;/p&gt;

&lt;p&gt;CoffeeScript自体はその後、&lt;strong&gt;2015年&lt;/strong&gt; に発行されたECMAScript 2015がその仕様を取り込んだことで役目を終えた。
&lt;strong&gt;2017年9月&lt;/strong&gt; に&lt;a href=&#34;https://coffeescript.org/announcing-coffeescript-2/&#34;&gt;バージョン2をアナウンス&lt;/a&gt;して再起を図ったが、そのころすでに他に有力なAltJSが出てたし、ECMAScriptも結構成熟してきてたし、あまり注目されなかった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;AltJSには他に以下のようなものがあるが、ほぼTypeScriptしか使われてなさそう。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.typescriptlang.org/&#34;&gt;TypeScript&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2012年10月&lt;/strong&gt; 初版リリース。&lt;/li&gt;
&lt;li&gt;Microsoft製。&lt;/li&gt;
&lt;li&gt;静的型付けが最大の特徴で、他にもクラスやアロー関数やレキシカル変数などをサポート。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.purescript.org/&#34;&gt;PureScript&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2014年4月&lt;/strong&gt; 初版リリース。&lt;/li&gt;
&lt;li&gt;強い静的型付けの関数型言語。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.dartlang.org/&#34;&gt;Dart&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2011年10月&lt;/strong&gt; 初版リリース。&lt;/li&gt;
&lt;li&gt;Google製。&lt;/li&gt;
&lt;li&gt;全く流行らなかったし、Google自身も社内標準プログラミング言語にTypeScriptを採用したので、だれも使ってなくてよくわからない。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2018年8月&lt;/strong&gt; にバージョン2がリリースされ、再起を図ってはいる。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jsx.github.io/&#34;&gt;JSX&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;DeNA製。&lt;/li&gt;
&lt;li&gt;名前がReactの&lt;a href=&#34;https://reactjs.org/docs/introducing-jsx.html&#34;&gt;JSX&lt;/a&gt;と紛らわしい。&lt;/li&gt;
&lt;li&gt;誰も使ってないし、&lt;strong&gt;2014年&lt;/strong&gt; くらいから開発止まってる。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;altcss&#34;&gt;AltCSS&lt;/h3&gt;

&lt;p&gt;CSSにもalternativesがある。
というかAltJSよりも歴史が古い。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://sass-lang.com/&#34;&gt;Sass&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2006年&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;SASS記法とSCSS記法がある。&lt;/li&gt;
&lt;li&gt;AltCSSでは1番人気っぽい。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://lesscss.org/&#34;&gt;Less&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2009年&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;Sassに感銘を受けたけど、そのSASS記法がCSSと違いすぎてちょっと、と思った人がCSSに寄せて作った。けどSassもCSSに寄せたSCSS記法をサポートしたため食われた。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://stylus-lang.com/&#34;&gt;Stylus&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2010年&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://postcss.org/&#34;&gt;PostCSS&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2013年&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;正確にはAltCSSではなく、CSSを処理するツールをJavaScriptで開発できるフレームワーク。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://preset-env.cssdb.org/&#34;&gt;PostCSS Preset Env&lt;/a&gt;というプラグインとともに使うと、CSSのエッジな機能を使えるようになる。つまりどちらかといえば後述のトランスパイラに近い。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;トランスパイラ&#34;&gt;トランスパイラ&lt;/h3&gt;

&lt;p&gt;CoffeeScriptの流行などを受けて、ECMAScriptに再び改善の圧力がかかったのか、&lt;strong&gt;2011年後半&lt;/strong&gt; ころから次期ECMAScriptの議論が活発化した。
&lt;strong&gt;2015年&lt;/strong&gt; に満を持してECMAScript 6改めECMAScript 2015が発行された。&lt;/p&gt;

&lt;p&gt;ECMAScript 2015は、クラス構文、アロー関数、レキシカル変数、定数、関数のデフォルト引数、ジェネレータ、テンプレート文字列、モジュールシステムなどをサポートし、一気にまともなプログラミング言語になった。&lt;/p&gt;

&lt;p&gt;しかし、それらの新しい機能をアプリケーションに使うには、各社のブラウザのJavaScriptエンジンが実装して、さらにその実装したバージョンのブラウザがユーザに十分に行きわたるのを待たないといけない。
ECMAScriptの新機能は、正式に発行される前から仕様が公開され、ブラウザが先行して実装してはいくものの、&lt;a href=&#34;http://threevirtues.com/&#34;&gt;プログラマは短気&lt;/a&gt;なのでそんなの待ってられない。&lt;/p&gt;

&lt;p&gt;といった状況のなか、&lt;strong&gt;2014年10月&lt;/strong&gt; に&lt;a href=&#34;https://www.npmjs.com/package/6to5&#34;&gt;6to5&lt;/a&gt;というツールがnpmで公開された。
ECMAScript 6で書かれたコードをECMAScript 5なコードに変換してくれる、トランスパイラというツールだった。&lt;/p&gt;

&lt;p&gt;(実はトランスパイラとしては&lt;strong&gt;2013年3月&lt;/strong&gt;に公開されたGoogle製の&lt;a href=&#34;https://github.com/google/traceur-compiler&#34;&gt;Traceur&lt;/a&gt;とか、&lt;strong&gt;2014年4月&lt;/strong&gt; に公開されたEmber.jsチーム製の&lt;a href=&#34;https://esnext.github.io/esnext/&#34;&gt;esnext&lt;/a&gt;のほうが先駆けだったんだけど、6to5の開発スピードがとんでもなく早く、&lt;strong&gt;2015年1Q&lt;/strong&gt; には機能面で両者を抜いてしまったらしい。)&lt;/p&gt;

&lt;p&gt;6to5は&lt;strong&gt;2015年2月&lt;/strong&gt;に名前を&lt;a href=&#34;https://babeljs.io/&#34;&gt;Babel&lt;/a&gt;に&lt;a href=&#34;https://babeljs.io/blog/2015/02/15/not-born-to-die&#34;&gt;変えて&lt;/a&gt;、単に6to5という名前が示す機能だけでなく、JavaScript周りの様々なツールを開発・統合するためのプラットフォームとなった。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2018年現在&lt;/strong&gt;、Babel無しでフロントエンド開発をすることはほぼ無さそうな感じになってる。&lt;/p&gt;

&lt;h3 id=&#34;タスクランナー&#34;&gt;タスクランナー&lt;/h3&gt;

&lt;p&gt;モジュールバンドラやら、AltJSやら、AltCSSやらで、フロントエンドにコンパイルとかビルドとかいう作業が必要になって来たため、この業界にも必然的にタスクランナーが登場してきた。&lt;/p&gt;

&lt;p&gt;タスクランナーというのは、他業界ではビルドツールなどとも呼ばれているもので、Cとかで使われる&lt;a href=&#34;https://ja.wikipedia.org/wiki/Make&#34;&gt;Make&lt;/a&gt;とか、Javaの&lt;a href=&#34;https://ant.apache.org/&#34;&gt;Ant&lt;/a&gt;とか&lt;a href=&#34;https://maven.apache.org/&#34;&gt;Maven&lt;/a&gt;とか&lt;a href=&#34;https://gradle.org/&#34;&gt;Gradle&lt;/a&gt;とか、Googleの&lt;a href=&#34;https://bazel.build/&#34;&gt;Bazel&lt;/a&gt;とかと同様のもの。&lt;/p&gt;

&lt;p&gt;まず、&lt;strong&gt;2012年1月&lt;/strong&gt; に&lt;a href=&#34;https://gruntjs.com/&#34;&gt;Grunt&lt;/a&gt;がリリースされて人気を博した。
が、当時のGruntの設定ファイルがJSONで&lt;a href=&#34;http://monmon.hatenablog.com/entry/2013/12/20/151321&#34;&gt;書きにくい&lt;/a&gt;とか、処理がシーケンシャルで遅いとかいう不満が潜在的に溜まっていった。&lt;/p&gt;

&lt;p&gt;で、それらの問題を払拭する&lt;a href=&#34;https://gulpjs.com/&#34;&gt;gulp&lt;/a&gt;が&lt;strong&gt;2013年7月&lt;/strong&gt;に出て、Gruntを食った。&lt;/p&gt;

&lt;p&gt;けど結局、Gruntもgulpも、タスクの処理をどこかの馬の骨が作ったプラグインに頼っていて不安定で、またビルドツールというレイヤが増えたせいでビルドエラーのデバッグがし辛くなるという&lt;a href=&#34;https://qiita.com/chuck0523/items/dafdbd19c12efd40e2de&#34;&gt;根本的な問題が顕在化&lt;/a&gt;し、&lt;a href=&#34;https://docs.npmjs.com/misc/scripts&#34;&gt;npm-scripts&lt;/a&gt;でいいじゃん、ってなった。&lt;/p&gt;

&lt;p&gt;シンプルイズベスト。&lt;/p&gt;

&lt;h1 id=&#34;javascriptフロントエンドフレームワーク-第2世代&#34;&gt;JavaScriptフロントエンドフレームワーク (第2世代)&lt;/h1&gt;

&lt;p&gt;前章で書いたフロントエンド界の変容の後あたりに、当時の先端技術を取り入れて誕生したフロントエンドフレームワークを、この記事では第2世代と呼ぶ。&lt;/p&gt;

&lt;p&gt;第2世代は第1世代から正統な進化を遂げた感じで、あいかわらずMVW (i.e. MV*)だった。
主要なのは以下。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://vuejs.org/&#34;&gt;Vue.js&lt;/a&gt; v1&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2013年12月&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;Googleのエンジニア(個人)製。&lt;/li&gt;
&lt;li&gt;MVVMアーキテクチャ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mizchi.hatenablog.com/entry/2014/02/13/153742&#34;&gt;軽量AngularJS&lt;/a&gt;な感じらしい。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://aurelia.io/&#34;&gt;Aurelia&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2015年11月&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;AngularJSっぽいフルスタックフレームワークで、EcmaScript 2015+とかWeb Componentsとかの先端技術を取り入れていることが売り。&lt;/li&gt;
&lt;li&gt;2-wayバインディング推しで、あまり流行らなかった。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://riot.js.org/&#34;&gt;Riot&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2014年6月&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;AngularJSもReactも複雑すぎ。フロントエンド開発に必要十分なコンパクトな機能を提供するぜ、というフレームワーク。&lt;/li&gt;
&lt;li&gt;Aureliaよりかは使われていそう。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://angular.io/&#34;&gt;Angular&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2016年9月&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;AngularJSの後継。AngularJSとの互換性をばっさり切り捨てる代わりに、アーキテクチャを刷新し、性能面と機能面の&lt;a href=&#34;https://medium.com/@mnemon1ck/why-you-should-not-use-angularjs-1df5ddf6fc99&#34;&gt;色々な問題&lt;/a&gt;を克服したらしい。&lt;/li&gt;
&lt;li&gt;が、Reactが画期的過ぎてAngularJSの栄光は取り戻せなかった。&lt;/li&gt;
&lt;li&gt;最初2-wayバインディングまで切り捨てたが、あとで復活させた。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;react-virtual-dom&#34;&gt;React (Virtual DOM)&lt;/h1&gt;

&lt;p&gt;第1世代から流行っていた2-wayバインディングがちょっと&lt;a href=&#34;https://stackoverflow.com/questions/35379515/why-is-two-way-databinding-in-angularjs-an-antipattern&#34;&gt;辛みを帯びてきた&lt;/a&gt;。
というか、2-wayバインディングしかできないAngularJSが辛くなってきたということだったのかもしれない。&lt;/p&gt;

&lt;p&gt;2-wayバインディングには以下のような問題があった。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;変更をwatchするオブジェクトが増えて、性能が悪くなる。&lt;/li&gt;
&lt;li&gt;ModelとViewとの間の依存やデータの流れが複雑になって、コーディングやデバッグが難しくなる。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;これに異を唱えて登場してきたのがFacebookによる&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt;。
&lt;strong&gt;2013年3月&lt;/strong&gt; のことであった。&lt;/p&gt;

&lt;p&gt;2-wayバインディングもMVCもテンプレートも要らんとして、代わりにReactが突きつけてきた&lt;a href=&#34;https://reactjs.org/docs/faq-internals.html&#34;&gt;Virtual DOM&lt;/a&gt;という解は、世界中の人々の&lt;a href=&#34;https://qiita.com/mizchi/items/4d25bc26def1719d52e6&#34;&gt;魂を震えさせた&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;Virtual DOMは、その名の通りDOMの仮想化であり、JavaScriptからReactのAPIを通してDOMのようなものを更新すると、Reactがいい感じに実DOMを更新してくれるというもの。
開発者は深く考えずに、イベントが発生するごとに、ページ全体を表すDOMツリーがどうなっているべきかをReactに教えるだけでいい。
あとはReactが、現在の実DOMとの差分を計算し、差分だけを性能よく更新してくれる。
これによって開発者は、DOMの状態やイベントの種類をみてアドホックに実DOMやModelの更新処理を書くという苦行から解放され、宣言的に&lt;a href=&#34;http://blog.neleid.com/2016/04/05/%E5%AF%8C%E8%B1%AA%E7%9A%84%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%E3%81%AF%E6%AD%BB%E8%AA%9E%E3%81%8B/&#34;&gt;富豪的に&lt;/a&gt;フロントエンドプログラミングができるようになった。&lt;/p&gt;

&lt;p&gt;さらに&lt;strong&gt;2014年5月&lt;/strong&gt;、Reactにベストマッチするアプリケーションアーキテクチャとして&lt;a href=&#34;https://facebook.github.io/flux/&#34;&gt;Flux&lt;/a&gt;が発表された。
これは単方向のデータフローが特徴のアーキテクチャで、斬新でかっこよくて未来だった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/facebook/flux/raw/master/docs/img/flux-diagram-white-background.png&#34; alt=&#34;Flux&#34; title=&#34;Flux&#34; /&gt;
&lt;/p&gt;

&lt;h1 id=&#34;javascriptフロントエンドフレームワーク-第3世代&#34;&gt;JavaScriptフロントエンドフレームワーク (第3世代)&lt;/h1&gt;

&lt;p&gt;React後、Virtual DOMの実装がいくつも出てきた。
&lt;a href=&#34;https://github.com/Matt-Esch/virtual-dom&#34;&gt;virtual-dom&lt;/a&gt;とか&lt;a href=&#34;https://maquettejs.org/&#34;&gt;Maquette&lt;/a&gt;とか&lt;a href=&#34;https://preactjs.com/&#34;&gt;Preact&lt;/a&gt;とか&lt;a href=&#34;https://infernojs.org/&#34;&gt;Inferno&lt;/a&gt;とか。&lt;/p&gt;

&lt;p&gt;Fluxの実装も、Facebook自身による&lt;a href=&#34;https://github.com/facebook/flux&#34;&gt;Flux&lt;/a&gt;のほか、&lt;a href=&#34;http://fluxxor.com/&#34;&gt;Fluxxor&lt;/a&gt;とか&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;とか&lt;a href=&#34;https://mobx.js.org/&#34;&gt;MobX&lt;/a&gt;とか沢山出た。&lt;/p&gt;

&lt;p&gt;で、React+Reduxがいい感じってなって、&lt;a href=&#34;https://medium.com/@TechMagic/reactjs-vs-angular5-vs-vue-js-what-to-choose-in-2018-b91e028fa91d&#34;&gt;世界の8割近くの人がReactで書くようになって&lt;/a&gt;、猫も杓子もVirtual DOMってなった辺りのフロントエンドフレームワークを第3世代と呼ぶことにする。&lt;/p&gt;

&lt;p&gt;第3世代としては以下が挙げられる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://grommet.io/&#34;&gt;Grommet&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2015年6月&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;HPE製。&lt;/li&gt;
&lt;li&gt;Reactと&lt;a href=&#34;https://github.com/inuitcss/inuitcss&#34;&gt;inuitcss&lt;/a&gt;によるフレームワーク。&lt;/li&gt;
&lt;li&gt;全然流行ってないけど&lt;a href=&#34;http://grommet.io/docs/components&#34;&gt;コンポーネント&lt;/a&gt;の取り揃えがよくて結構いいような気がする。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://emberjs.com/blog/2015/08/13/ember-2-0-released.html&#34;&gt;Ember.js v2&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2015年8月&lt;/strong&gt; リリース。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://glimmerjs.com/&#34;&gt;Glimmer&lt;/a&gt;というレンダリングエンジンを搭載。

&lt;ul&gt;
&lt;li&gt;Glimmerは、テンプレートをGlimmer VM上で動くバイトコードにコンパイルして、実DOMを速くレンダリングしてくれるもの。&lt;/li&gt;
&lt;li&gt;Virtual DOMとは違う感じだけど、実DOMの更新を開発者の代わりにやってくれるあたり、目指しているものは同じ。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://jp.vuejs.org/2016/10/01/here-2.0/&#34;&gt;Vue.js v2&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2016年10月&lt;/strong&gt; リリース。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/snabbdom/snabbdom&#34;&gt;snabbdom&lt;/a&gt;ベースのVirtual DOM実装を搭載。&lt;/li&gt;
&lt;li&gt;2017年頭位からかなりの勢いで流行ってきている。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://hyperapp.js.org/&#34;&gt;Hyperapp&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2017年1月&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://qiita.com/&#34;&gt;Qiita&lt;/a&gt;で働いてるエンジニアが趣味で作ったフレームワークで、Qiitaに採用された。&lt;/li&gt;
&lt;li&gt;超軽量(1KB!)で、シンプルが売り。&lt;/li&gt;
&lt;li&gt;独自のVirtual DOM実装であるPicodom(現&lt;a href=&#34;https://github.com/jorgebucaran/superfine&#34;&gt;superfine&lt;/a&gt;)を搭載。&lt;/li&gt;
&lt;li&gt;JSXにも対応。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://dojo.io/&#34;&gt;Dojo&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2018年5月&lt;/strong&gt; 正式版リリース。&lt;/li&gt;
&lt;li&gt;Dojo Toolkitの後継。&lt;/li&gt;
&lt;li&gt;Virtual DomでTypeScriptでリアクティブでフルスタック。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;終わりに&#34;&gt;終わりに&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;2018年8月現在&lt;/strong&gt; では、React vs Vue.js vs Angularといった感じで、激動の時代が過ぎてやや落ち着いて来ている感があるが、油断はできない。
実際、最近&lt;a href=&#34;http://elm-lang.org/&#34;&gt;Elm&lt;/a&gt;という関数型AltJS兼Frontendフレームワークがじわじわ盛り上がってきている感じがあり、一波乱あるかもしれない。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;いろいろ書いたけど、&lt;a href=&#34;https://electronjs.org/&#34;&gt;Electron&lt;/a&gt;とか&lt;a href=&#34;https://facebook.github.io/react-native/&#34;&gt;React Native&lt;/a&gt;とか&lt;a href=&#34;https://nextjs.org&#34;&gt;Next.js&lt;/a&gt;とかの&lt;a href=&#34;https://jp.vuejs.org/v2/guide/ssr.html&#34;&gt;SSR&lt;/a&gt;とか&lt;a href=&#34;https://www.gatsbyjs.org/&#34;&gt;Gatsby.js&lt;/a&gt;とか&lt;a href=&#34;https://graphql.org/learn/&#34;&gt;GraphQL&lt;/a&gt;とか&lt;a href=&#34;https://developers.google.com/web/fundamentals/codelabs/your-first-pwapp/?hl=ja&#34;&gt;PWA&lt;/a&gt;とか&lt;a href=&#34;https://webassembly.org/&#34;&gt;WebAssembly&lt;/a&gt;とか&lt;a href=&#34;https://aws.amazon.com/jp/getting-started/serverless-web-app/&#34;&gt;サーバーレス&lt;/a&gt;とか&lt;a href=&#34;https://kuroeveryday.blogspot.com/2017/03/css-structure-and-rules.html&#34;&gt;CSS設計手法&lt;/a&gt;とかCSSフレームワークとかいろいろ書き漏れた。&lt;/p&gt;

&lt;p&gt;フロントエンドのユニットテストとかE2Eテストとかもいろいろあって面白い。
(E2Eテストは&lt;a href=&#34;https://www.kaitoy.xyz/2017/08/04/browser-test-framework/&#34;&gt;前に書いた&lt;/a&gt;。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;年表も気が向いたら追加したい。&lt;/p&gt;

&lt;p&gt;しかし&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/19/creating-react-redux-app-from-scratch-01/&#34;&gt;React+Reduxに再入門したよ、っていう記事&lt;/a&gt;の前座として書くつもりだったのに、ずいぶん長編になってしまった…&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>PackerでESXiにVMを自動構築</title>
          <link>https://www.kaitoy.xyz/2018/06/30/packer-esxi/</link>
          <pubDate>Sat, 30 Jun 2018 16:56:34 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/06/30/packer-esxi/</guid>
          <description>

&lt;p&gt;前回「&lt;a href=&#34;https://www.kaitoy.xyz/2018/06/17/packer-k8s/&#34;&gt;Packer + Ansible on Windows 10でKubernetes 1.10のクラスタ on VirtualBoxを全自動構築&lt;/a&gt;」で、やったことをESXiでやっただけ。&lt;/p&gt;

&lt;p&gt;書いたコードは&lt;a href=&#34;https://github.com/kaitoy/packer-k8s&#34;&gt;GitHub&lt;/a&gt;に置いてある。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;前回との違い&#34;&gt;前回との違い&lt;/h2&gt;

&lt;p&gt;VirtualBoxとESXiとで変えないといけない部分は、主にPackerのbuilderの定義。
前回はvirtualbox-isoだったけど、今回は&lt;a href=&#34;https://www.packer.io/docs/builders/vmware-iso.html&#34;&gt;vmware-iso&lt;/a&gt;を使う。
それに伴ってパラメータが結構違ってくる。&lt;/p&gt;

&lt;p&gt;いっこトリッキーだったのが、&lt;code&gt;cdrom_adapter_type&lt;/code&gt;に&lt;code&gt;ide&lt;/code&gt;を明示的に指定しておかないと、CDロムドライブがSCSIになって、OSのインストールメディアのマウントか読み取り辺りでエラーになってしまったところ。
環境によっては指定しないでいいかも。&lt;/p&gt;

&lt;p&gt;また、&lt;code&gt;&amp;quot;vnc_disable_password&amp;quot;: &amp;quot;true&amp;quot;&lt;/code&gt;をbuilderに指定しておかないと、Packerが「Error handshaking with VNC: no suitable auth schemes found. server supported: []byte{0x1}」という&lt;a href=&#34;https://github.com/hashicorp/packer/issues/5939&#34;&gt;エラーを出す&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;あとは、Nested Virtualizationでやった(下記)ので、すごく遅くて、色々タイムアウトを伸ばしたりしてやる必要があった。&lt;/p&gt;

&lt;h2 id=&#34;esxi環境&#34;&gt;ESXi環境&lt;/h2&gt;

&lt;p&gt;ESXi(というかVMware vSphere Hypervisor)は、現時点での最新の6.7を使用。
自前のWindows 10 HomeのノートPC上で動くVMware Player 12で作ったVMにESXiをインストールして環境を作った。&lt;/p&gt;

&lt;p&gt;(因みにVirtualBoxにもインストールしてみたESXi上ではVM作成できなかった。VirtualBoxは今の時点でNested Virtualization未サポートで、サポートする予定もない模様。)&lt;/p&gt;

&lt;p&gt;Packerから操作するには、以下の設定をする必要がある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;静的IPアドレスを設定。Packerからの接続先に指定するので。&lt;/li&gt;
&lt;li&gt;SSH有効化。PackerがSSHで接続するので。

&lt;ul&gt;
&lt;li&gt;因みにSSHクライアントでESXiにつなぐときは、チャレンジ/レスポンス認証になる。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.packer.io/docs/builders/vmware-iso.html#building-on-a-remote-vsphere-hypervisor&#34;&gt;GuestIPHack の有効化&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;ESXiにSSHでログインして「&lt;code&gt;esxcli system settings advanced set -o /Net/GuestIPHack -i 1&lt;/code&gt;」&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ファイアウォール設定でVNCポート(TCP5900番台)を開ける。
これをしないとPackerが「Starting HTTP server on port xxxx」でハングする。
けどこれが一筋縄ではいかない。&lt;a href=&#34;https://kb.vmware.com/s/article/2008226?lang=ja&#34;&gt;この記事&lt;/a&gt;にあるように、&lt;code&gt;/etc/vmware/firewall/service.xml&lt;/code&gt;に設定を追加して「&lt;code&gt;esxcli network firewall refresh&lt;/code&gt;」してもいいんだけど、再起動するともとに戻ってしまう。&lt;/p&gt;

&lt;p&gt;ので、&lt;a href=&#34;https://kb.vmware.com/s/article/2043564&#34;&gt;この記事&lt;/a&gt;などを参考に、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;VNCポートの設定ファイルをデータストアに作成。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/vmfs/volumes/datastore1/svc/packer.xml&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;ConfigRoot&amp;gt;
  &amp;lt;service id=&amp;quot;1000&amp;quot;&amp;gt;
    &amp;lt;id&amp;gt;packer-vnc&amp;lt;/id&amp;gt;
    &amp;lt;rule id=&amp;quot;0000&amp;quot;&amp;gt;
      &amp;lt;direction&amp;gt;inbound&amp;lt;/direction&amp;gt;
      &amp;lt;protocol&amp;gt;tcp&amp;lt;/protocol&amp;gt;
      &amp;lt;porttype&amp;gt;dst&amp;lt;/porttype&amp;gt;
      &amp;lt;port&amp;gt;
        &amp;lt;begin&amp;gt;5900&amp;lt;/begin&amp;gt;
        &amp;lt;end&amp;gt;6000&amp;lt;/end&amp;gt;
      &amp;lt;/port&amp;gt;
    &amp;lt;/rule&amp;gt;
    &amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt;
    &amp;lt;required&amp;gt;true&amp;lt;/required&amp;gt;
  &amp;lt;/service&amp;gt;
&amp;lt;/ConfigRoot&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;設定ファイルをESXi起動時に読み込むスクリプトを記述。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/etc/rc.local.d/local.sh&lt;/code&gt;に以下を追記:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cp /vmfs/volumes/datastore1/svc/packer.xml /etc/vmware/firewall/
esxcli network firewall refresh
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;packer実行&#34;&gt;Packer実行&lt;/h2&gt;

&lt;p&gt;設定ファイルが出来てESXi環境が用意できれば、Packer実行は前回と一緒。&lt;/p&gt;

&lt;p&gt;ただ結局、環境が激遅なせいでところどころでタイムアウトしたり、OSインストール中にランダムにパニックになったり、PackerのBoot Commandの入力がランダムに失敗したりして、最後までビルド成功させる前に心折れた。
まあAnsibleのプロビジョニングの途中までは動いたので、だいたいよしとする。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Packer &#43; Ansible on Windows 10でKubernetes 1.10のクラスタ on VirtualBoxを全自動構築</title>
          <link>https://www.kaitoy.xyz/2018/06/17/packer-k8s/</link>
          <pubDate>Sun, 17 Jun 2018 23:22:33 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/06/17/packer-k8s/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2018/06/03/build-k8s-cluster-by-ansible/&#34;&gt;Kubernetes 1.10のクラスタを全手動で構築するのをAnsibleで全自動化した&lt;/a&gt;」の続きで、さらに&lt;a href=&#34;https://www.packer.io/&#34;&gt;Packer&lt;/a&gt;を組み合わせて、VM作成まで自動化した話。&lt;/p&gt;

&lt;p&gt;AnsibleをWindows(&lt;a href=&#34;https://www.msys2.org/&#34;&gt;MSYS2&lt;/a&gt;)で動かした話でもある。&lt;/p&gt;

&lt;p&gt;書いたPackerテンプレートは&lt;a href=&#34;https://github.com/kaitoy/packer-k8s&#34;&gt;GitHub&lt;/a&gt;に置いた。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;packerとは&#34;&gt;Packerとは&lt;/h2&gt;

&lt;p&gt;Packerは、様々な種類のVMを構築できるツール。
VagrantとかTerraformとかを開発している&lt;a href=&#34;https://www.hashicorp.com/&#34;&gt;HashiCorp&lt;/a&gt;が開発している。&lt;/p&gt;

&lt;p&gt;テンプレートと呼ばれるビルド定義をJSONファイルに書いて、ビルド、プロビジョニング、ポストプロセスを実行して、アーティファクトと呼ばれるビルドの成果物を生成する。&lt;/p&gt;

&lt;p&gt;ビルドのステップでは、VMを作成して、ハードウェア構成を設定したり、OSをインストールしたりする。&lt;/p&gt;

&lt;p&gt;以下のような環境でVMを作れる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;VirtualBox&lt;/li&gt;
&lt;li&gt;Hyper-V&lt;/li&gt;
&lt;li&gt;VMware Workstation&lt;/li&gt;
&lt;li&gt;VMware vSphere Hypervisor&lt;/li&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;li&gt;AWS EC2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;プロビジョニングのステップでは、ビルドで作ったVMのOS上で指定された操作を実行し、ソフトウェアのインストールなどのセットアップ処理をする。&lt;/p&gt;

&lt;p&gt;プロビジョニングには以下のようなツールを使える。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Shell&lt;/li&gt;
&lt;li&gt;PowerShell&lt;/li&gt;
&lt;li&gt;Ansible&lt;/li&gt;
&lt;li&gt;Chef&lt;/li&gt;
&lt;li&gt;Puppet&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;プロビジョニングが終わるとアーティファクト(VMイメージファイルや、AWS EC2のAMI IDとか)が出力される。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ポストプロセスのステップでは、アーティファクトを入力として何らかの処理をして、最終的なアーティファクトを生成する。&lt;/p&gt;

&lt;p&gt;ポストプロセスでは以下のような処理を実行できる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;アーカイブ&lt;/li&gt;
&lt;li&gt;VagrantBox生成&lt;/li&gt;
&lt;li&gt;AWS EC2へのインポート&lt;/li&gt;
&lt;li&gt;Docker push&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;PackerはGoで書かれていてビルド済みのバイナリが配布されているので、&lt;a href=&#34;https://www.packer.io/downloads.html&#34;&gt;ダウンロードページ&lt;/a&gt;から落として PATHの通ったところに置くだけでインストールできる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今回はPacker 1.2.4のWindows版をインストールした。&lt;/p&gt;

&lt;h2 id=&#34;packerの-テンプレート-https-www-packer-io-docs-templates-index-html-概要&#34;&gt;Packerの&lt;a href=&#34;https://www.packer.io/docs/templates/index.html&#34;&gt;テンプレート&lt;/a&gt;概要&lt;/h2&gt;

&lt;p&gt;Packerのテンプレートにはビルド、プロビジョニング、ポストプロセスの定義を複数かけて、複数環境のVM生成を1ファイルで定義できる。&lt;/p&gt;

&lt;p&gt;テンプレートには以下のプロパティを書く。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.packer.io/docs/templates/builders.html&#34;&gt;builders&lt;/a&gt;: ビルドの定義のリスト。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;description&lt;/code&gt;: テンプレートの説明。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;min_packer_version&lt;/code&gt;: Packer の最低バージョン指定。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.packer.io/docs/templates/post-processors.html&#34;&gt;post-processors&lt;/a&gt;: ポストプロセスの定義のリスト。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.packer.io/docs/templates/provisioners.html&#34;&gt;provisioners&lt;/a&gt;: プロビジョニングの定義のリスト。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.packer.io/docs/templates/user-variables.html&#34;&gt;variables&lt;/a&gt;: テンプレート内で使う変数の定義。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;_comment&lt;/code&gt;: コメントなどを書くためのプロパティ。実際はアンダースコアで始まればなんでもいい。JSON オブジェクトのルートレベルのみで使える。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;これらのうち、必須なのはbuildersだけ。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;一つのビルド定義には一つの&lt;a href=&#34;https://www.packer.io/docs/templates/communicator.html&#34;&gt;communicator&lt;/a&gt;を紐づける。
communicatorはビルド時にVMにつなぐための設定。
基本は&lt;a href=&#34;https://www.packer.io/docs/templates/communicator.html#ssh-communicator&#34;&gt;SSH&lt;/a&gt;だけど、WinRMとかもある。&lt;/p&gt;

&lt;h2 id=&#34;やりたいこと&#34;&gt;やりたいこと&lt;/h2&gt;

&lt;p&gt;Windows 10上でPackerとAnsibleを動かして、VirtualBoxのVMをOracle Linux 7.4で作って、Kubernetes 1.10をインストールしたい。
Windowsでやりたいのは、単にベアメタルのLinuxの環境が無いからってのもあるし、いずれHyper-VのVMも作りたいからってのもある。&lt;/p&gt;

&lt;p&gt;PackerはGo製で普通にWindowsで動くからいいけど、問題はAnsibleがPython製のくせにWindowsのPythonでは動かないこと。
AnsibleはWSLでは動くけど、VirtualBoxとかHyper-VはWindows上で動くから、PackerはWindows上で動かさないといけないはずで、そうなるとPackerから呼ばれるAnsibleもWindows上で動かさないといけない気がする。
のでWSLではだめな気がするし、そもそも実はWindows 7でも同じことやりたいのでWSLは無し。&lt;/p&gt;

&lt;p&gt;要はWindows上でLinuxのPythonを使ってAnsibleを動かしたい。
ならばCygwinかMSYS2+MinGW-w64かGit Bashか。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://superuser.com/questions/1255634/install-ansible-in-windows-using-git-bash&#34;&gt;ここ&lt;/a&gt;にAnsibleはCygwinでもGit Bashでも動かすの難しいと書いてあって、逆に&lt;a href=&#34;http://itsp0.blogspot.com/2017/03/ansible-msys2-ansible.html&#34;&gt;MSYS2でAnsible動かした記事&lt;/a&gt;はあったので、安直にMSYS2でやることにした。&lt;/p&gt;

&lt;h2 id=&#34;msys2インストール&#34;&gt;MSYS2インストール&lt;/h2&gt;

&lt;p&gt;MSYS2は、&lt;a href=&#34;http://www.msys2.org/&#34;&gt;公式サイト&lt;/a&gt;からx86_64のインストーラ(msys2-x86_64-20180531.exe)をダウンロードして実行して普通にインストールしただけ。&lt;/p&gt;

&lt;h2 id=&#34;ansibleインストール&#34;&gt;Ansibleインストール&lt;/h2&gt;

&lt;p&gt;MSYS2でのパッケージ管理にはpacmanを使う。&lt;/p&gt;

&lt;p&gt;何はともあれPythonを入れる。3系でいい。
&lt;code&gt;MSYS2 MSYS&lt;/code&gt;のショートカット(&lt;code&gt;MSYS2 MinGW 64-bit&lt;/code&gt;じゃだめ)からターミナルを開いて、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ pacman -S python
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、Python 3.6.2が入った。&lt;/p&gt;

&lt;p&gt;次に、Ansible(の依存)のビルドに必要なパッケージを入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ pacman -S gcc
$ pacman -S make
$ pacman -S libffi-devel
$ pacman -S openssl-devel
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;さらに、AnsibleからのSSH接続で(鍵ではなくて)パスワードを使う場合に必要なパッケージも入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ pacman -S sshpass
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;sshpassの依存としてopensshも入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Ansibleはpipでインストールするんだけど、pacmanで入れたPython 3にはpipが付いてなかったので、&lt;a href=&#34;https://pip.pypa.io/en/stable/installing/&#34;&gt;別途入れる&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ curl https://bootstrap.pypa.io/get-pip.py -LO
$ python get-pip.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(ちょっと古いけどpipは&lt;code&gt;pacman python3-pip&lt;/code&gt;でも入る。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、ようやくAnsibleインストール。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ export CFLAGS=-I/usr/lib/libffi-3.2.1/include
$ pip install ansible
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;依存するPyNaClのビルドに20分くらいかかるのでゆっくり待つと、インストール完了するはず。&lt;/p&gt;

&lt;p&gt;今回はAnsible 2.5.4がインストールされた。&lt;/p&gt;

&lt;p&gt;AnsibleでJinja2のipaddrフィルターを使うために、もう一つPyPiパッケージ入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ pip install netaddr
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;packerテンプレート作成&#34;&gt;Packerテンプレート作成&lt;/h2&gt;

&lt;p&gt;ビルドは、OSインストールメディアのISOファイルを使うVirtualBoxのビルダである&lt;a href=&#34;https://www.packer.io/docs/builders/virtualbox-iso.html&#34;&gt;virtualbox-iso&lt;/a&gt;を指定して書いた。&lt;/p&gt;

&lt;p&gt;OSのインストールは、&lt;a href=&#34;https://www.packer.io/docs/builders/virtualbox-iso.html#boot-command&#34;&gt;Boot Command&lt;/a&gt;をテンプレートに書くことで、インストーラのGUIを操作してやることもできるけど、RHEL系なら&lt;a href=&#34;https://access.redhat.com/documentation/ja-jp/red_hat_enterprise_linux/7/html/installation_guide/chap-kickstart-installations&#34;&gt;Kickstart&lt;/a&gt;を使うのが楽。&lt;/p&gt;

&lt;p&gt;Kickstartの定義ファイルは、普通に手動でOSをインストールした後、&lt;code&gt;/root/anaconda-ks.cfg&lt;/code&gt;を採取して、必要に応じて編集して作る。
今回作ったのは&lt;a href=&#34;https://github.com/kaitoy/packer-k8s/blob/fc530d94a04c15c97986e73d2c190e659ee0ddc0/http/ks.cfg&#34;&gt;これ&lt;/a&gt;で、&lt;a href=&#34;https://www.centos.org/forums/viewtopic.php?t=47262&#34;&gt;このスレ&lt;/a&gt;を参考に、Minimalインストールから、Wifiのファームウェアとか要らないのを抜いてる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;プロビジョニングは、「&lt;a href=&#34;https://www.kaitoy.xyz/2018/06/03/build-k8s-cluster-by-ansible/&#34;&gt;Kubernetes 1.10のクラスタを全手動で構築するのをAnsibleで全自動化した&lt;/a&gt;」ときのPlaybookを実行するやつを&lt;a href=&#34;https://www.packer.io/docs/provisioners/ansible.html&#34;&gt;公式マニュアル&lt;/a&gt;見ながら適当に書いて、ポストプロセスも適当に書いて、できたのが&lt;a href=&#34;https://github.com/kaitoy/packer-k8s/blob/fc530d94a04c15c97986e73d2c190e659ee0ddc0/k8s_single_node_cluster-vb.json&#34;&gt;これ&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ansible_env_vars&lt;/code&gt;で&lt;code&gt;ANSIBLE_SSH_ARGS&lt;/code&gt;に&lt;code&gt;-o ControlMaster=no&lt;/code&gt;を入れているのは、&lt;a href=&#34;https://github.com/geerlingguy/JJG-Ansible-Windows/issues/6&#34;&gt;この問題&lt;/a&gt;に対応するため。&lt;/p&gt;

&lt;h2 id=&#34;ビルド実行&#34;&gt;ビルド実行&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;MSYS2 MSYS&lt;/code&gt;のショートカットからターミナルを開いて、Packerを実行してみたら以下のエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ packer build -var-file=variables.json k8s_single_node_cluster-vb.json
bash: packer: コマンドが見つかりません
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;WindowsのPathが通ったところにPackerバイナリを置いておいてもMSYS2からは見えない。
のでpackerバイナリのフルパス(今回は&lt;code&gt;C:\Users\kaitoy\Desktop\bin\&lt;/code&gt;にインストールしてたのでそのパス)を指定してやる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ /c/Users/kaitoy/Desktop/bin/packer.exe build -var-file=variables.json k8s_single_node_cluster-vb.json
k8s-single-node-cluster output will be in this color.

1 error(s) occurred:

* Error running &amp;quot;ansible-playbook --version&amp;quot;: exec: &amp;quot;ansible-playbook&amp;quot;: executable file not found in %PATH%
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;と、今度は、ansible-playbookが無いと言われる。
ansible-playbookはansibleパッケージに入っていて/usr/bin/にインストールされているんだけど、Windows界で動いているPackerからはLinuxのPATHが見えないので、見つけられない。&lt;/p&gt;

&lt;p&gt;さらに、AnsibleのPlaybookのパスなど、Packerが妙な気を利かせてWindowsのフルパスにしてansible-playbookに渡してくれちゃうので、それをLinuxなパスに変換してやる必要がある。&lt;/p&gt;

&lt;p&gt;ということで、以下のようなラッパスクリプトを書いて、カレントディレクトリに置くことにした。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bat&#34;&gt;@echo off
setlocal enabledelayedexpansion

for %%f in (%*) do (
  if !key_file! == 1 (
    rem The value of ansible_ssh_private_key_file is the path to
    rem a key file in Windows TMP directory from MSYS2 point of view.
    set arg=/%tmp:\=/%
    set arg=!arg::=!
    set args=!args!=!arg!/%%~nxf
    set key_file=0
  ) else if %%~xf == .yml (
    rem Convert the passed Playbook path to relative one.
    set arg=%%f
    set arg=!arg:%CD%=!
    set arg=!arg:\=/!
    set args=!args! !arg:~1!
  ) else (
    rem Add other args as they are
    set args=!args! %%f
  )
  if %%f == ansible_ssh_private_key_file (
    rem The next arg will be the value of ansible_ssh_private_key_file
    set key_file=1
  )
)

echo args: %args%
C:\msys64\usr\bin\python C:\msys64\usr\bin\ansible-playbook -v %args%
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でちゃんと実行できるようになった。&lt;/p&gt;

&lt;p&gt;まとめると、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Windows 10に、&lt;/li&gt;
&lt;li&gt;VirtualBox 5.1.28をインストールして、&lt;/li&gt;
&lt;li&gt;Packer 1.2.4のWindows版をインストールして、&lt;/li&gt;
&lt;li&gt;MSYS2をインストールして、&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MSYS2 MSYS&lt;/code&gt;のターミナルでPython 3.6.2とAnsible 2.5.4とか(とGit)をインストールして、&lt;/li&gt;

&lt;li&gt;&lt;p&gt;以下を実行すればいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ git clone --recursive https://github.com/kaitoy/packer-k8s.git
$ cd packer-k8s
$ /c/Users/kaitoy/Desktop/bin/packer.exe build -var-file=variables.json k8s_single_node_cluster-vb.json
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code&gt;packer.exe build&lt;/code&gt;に&lt;code&gt;-debug&lt;/code&gt;を渡すと、内部の処理ステップごとに停止するようになり、デバッグしやすい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;一回実行したらゴミができて、次回実行時にエラーになるので、以下でクリーンアップする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ rm -rf /tmp/ansible
$ rm -f ~/.ssh/known_hosts
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因みに、上記known_hostsを消し忘れると以下のようなエラーになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; k8s-single-node-cluster: fatal: [k8s_master]: UNREACHABLE! =&amp;gt; {&amp;quot;changed&amp;quot;: false, &amp;quot;msg&amp;quot;: &amp;quot;Failed to connect to the host via ssh: @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\r\n@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @\r\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\r\nIT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\r\nSomeone could be eavesdropping on you right now (man-in-the-middle attack)!\r\nIt is also possible that a host key has just been changed.\r\nThe fingerprint for the ECDSA key sent by the remote host is\nSHA256:JNs/ZY38VpIuBE3QEzLHyLFGYe+Qg+bEWi8BOzgSNc0.\r\nPlease contact your system administrator.\r\nAdd correct host key in /home/kaitoy/.ssh/known_hosts to get rid of this message.\r\nOffending ECDSA key in /home/kaitoy/.ssh/known_hosts:1\r\nPassword authentication is disabled to avoid man-in-the-middle attacks.\r\nKeyboard-interactive authentication is disabled to avoid man-in-the-middle attacks.\r\nroot@127.0.0.1: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\r\n&amp;quot;, &amp;quot;unreachable&amp;quot;: true}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetes 1.10のクラスタを全手動で構築するのをAnsibleで全自動化した</title>
          <link>https://www.kaitoy.xyz/2018/06/03/build-k8s-cluster-by-ansible/</link>
          <pubDate>Sun, 03 Jun 2018 17:14:07 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/06/03/build-k8s-cluster-by-ansible/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/&#34;&gt;Kubernetes 1.10をスクラッチから全手動で構築&lt;/a&gt;」、「&lt;a href=&#34;https://www.kaitoy.xyz/2018/05/04/kubernetes-with-weave-net/&#34;&gt;Kubernetes 1.10のクラスタにWeave Netをデプロイする&lt;/a&gt;」、「&lt;a href=&#34;https://www.kaitoy.xyz/2018/05/05/kubernetes-kubelet-config-and-pod-sec-policy/&#34;&gt;Kubernetes 1.10のkubeletの起動オプションをKubelet ConfigファイルとPodSecurityPolicyで置き換える&lt;/a&gt;」のまとめとして、Kubernetes 1.10のクラスタを構築するAnsible Playbookを書いた。&lt;/p&gt;

&lt;p&gt;書いたものは&lt;a href=&#34;https://github.com/kaitoy/ansible-k8s&#34;&gt;GitHub&lt;/a&gt;に置いた。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;ansibleとは&#34;&gt;Ansibleとは&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.ansible.com/&#34;&gt;Ansible&lt;/a&gt;は、Ansible社が開発したOSSのIT自動化ツール。
Ansible社は2015年10月にRedHatが買収したので、現在はRedHatが開発している。
似たようなツールに&lt;a href=&#34;https://puppet.com/&#34;&gt;Puppet&lt;/a&gt;や&lt;a href=&#34;https://www.chef.io/&#34;&gt;Chef&lt;/a&gt;があるが、最近はAnsibleが最も支持されている気がする。&lt;/p&gt;

&lt;p&gt;構成管理ツールと紹介されることが多い気がするが、2014年末位からはIT自動化ツールを自称していて、構成管理は実現するユースケースの一つという位置づけになっているので、そろそろ認識を改めてあげたい。&lt;/p&gt;

&lt;p&gt;ユースケースは以下のようなもの。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ansible.com/use-cases/provisioning&#34;&gt;プロビジョニング&lt;/a&gt; (ベアメタル、VM、クラウドインスタンス)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ansible.com/use-cases/configuration-management&#34;&gt;構成管理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ansible.com/use-cases/application-deployment&#34;&gt;アプリケーションデプロイメント&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ansible.com/use-cases/continuous-delivery&#34;&gt;CI/CD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ansible.com/use-cases/security-and-compliance&#34;&gt;セキュリティ・コンプライアンス管理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ansible.com/use-cases/orchestration&#34;&gt;オーケストレーション&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以下のような特徴を持つ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Python(とPowerShell)で作られてる。

&lt;ul&gt;
&lt;li&gt;昔はPython 2じゃないと動かなかったけど、2.2から&lt;a href=&#34;https://docs.ansible.com/ansible/2.3/python_3_support.html&#34;&gt;Python 3でも動くようになった&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;YAMLで書いた定義(Playbook)に従って処理を実行する。&lt;/li&gt;
&lt;li&gt;シンプルで簡便であることを売りにしている。

&lt;ul&gt;
&lt;li&gt;多数のモジュールがビルトインされていて、様々な操作を簡潔な定義で宣言的に実行できる。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;エージェントレスで、SSH(等)で対象のサーバにつないで処理を実行する。&lt;/li&gt;
&lt;li&gt;処理を冪等にできるような仕組みが備わっていて、特にビルトインモジュールを活用すると簡単に冪等性を持たせられる。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Pythonで書かれているのでどこでも動くかと思いきや、&lt;a href=&#34;https://docs.python.jp/3/library/fcntl.html&#34;&gt;fcntl&lt;/a&gt;とか&lt;a href=&#34;https://docs.python.jp/3/library/grp.html&#34;&gt;grp&lt;/a&gt;やらUnix特有のモジュールを使っているため、WindowsのPythonでは動かない。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://kzlog.picoaccel.com/post-935/&#34;&gt;MSYS2&lt;/a&gt;とか&lt;a href=&#34;https://qiita.com/comefigo/items/f2b42c22e903f43e136e&#34;&gt;WSL&lt;/a&gt;では動く模様。
(&lt;a href=&#34;https://superuser.com/questions/1255634/install-ansible-in-windows-using-git-bash&#34;&gt;Git Bashでは動かない…&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今回使ったのは最新版の2.5.3。&lt;/p&gt;

&lt;h2 id=&#34;ansibleインストール&#34;&gt;Ansibleインストール&lt;/h2&gt;

&lt;p&gt;AnsibleはYUMとかpipとかでインストールできる。&lt;/p&gt;

&lt;p&gt;今回はOracle Linux 7.4で動かすため、以下のようにインストールした。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;AnsibleのYUMリポジトリ追加&lt;/p&gt;

&lt;p&gt;以下の内容を&lt;code&gt;/etc/yum.repos.d/&lt;/code&gt;の適当な&lt;code&gt;.repo&lt;/code&gt;ファイルに書く。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;[ansible]
name=Ansible
baseurl=http://releases.ansible.com/ansible/rpm/release/epel-7-x86_64/
gpgcheck=0
enabled=1
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;依存するPythonパッケージのYUMリポジトリを有効化&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/etc/yum.repos.d/public-yum-ol7.repo&lt;/code&gt;を編集して、&lt;code&gt;ol7_openstack30&lt;/code&gt;セクションの&lt;code&gt;enabled&lt;/code&gt;を1にする。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;インストール&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# yum install -y ansible
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;playbookの書き方&#34;&gt;Playbookの書き方&lt;/h2&gt;

&lt;p&gt;Playbookの書き方は他にたくさん情報があるし、どうせすぐに陳腐化するのでここには書かない。&lt;/p&gt;

&lt;p&gt;以下を参照して書いた。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.ansible.com/ansible/latest/user_guide/playbooks_best_practices.html#how-to-differentiate-staging-vs-production&#34;&gt;公式のBest Practices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.ansible.com/ansible/latest/modules/modules_by_category.html&#34;&gt;公式マニュアルのモジュール編&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html&#34;&gt;公式マニュアルの変数編&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.ansible.com/ansible/latest/user_guide/playbooks_loops.html&#34;&gt;公式マニュアルのループ編&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://jinja.pocoo.org/docs/2.10/&#34;&gt;Jinja2のマニュアル&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://openedx.atlassian.net/wiki/spaces/OpenOPS/pages/26837527/Ansible+Code+Conventions&#34;&gt;edXのAnsibleコーディング規約&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;一つ他にあまりなかった情報を書く:&lt;/p&gt;

&lt;p&gt;タスクをループするとき、&lt;code&gt;with_items&lt;/code&gt;プロパティを書くのはもう古くて、バージョン2.5以降では&lt;code&gt;loop&lt;/code&gt;プロパティを使う。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;書いたPlaybookで構築できるのは以下のようなKubernetesクラスタ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Kubernetes: バージョン1.10.1

&lt;ul&gt;
&lt;li&gt;単一ノード&lt;/li&gt;
&lt;li&gt;全コンポーネント(kubelet、kube-proxy、kube-apiserver、kube-controller-manager、kube-scheduler、etcd)をsystemdで起動 (i.e. 非コンテナ)

&lt;ul&gt;
&lt;li&gt;kubeletとkube-proxy以外は非rootユーザ&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;コンポーネント間通信とkubectlの通信をTLSで暗号化&lt;/li&gt;
&lt;li&gt;コンポーネント間通信とkubectlの通信の認証は&lt;a href=&#34;https://kubernetes.io/docs/admin/authentication/#x509-client-certs&#34;&gt;x509クライアント証明書&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TLS Bootstrapping

&lt;ul&gt;
&lt;li&gt;Bootstrap token使用&lt;/li&gt;
&lt;li&gt;CSR自動承認&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tls/certificate-rotation/&#34;&gt;Certificate Rotation&lt;/a&gt;有効&lt;/li&gt;
&lt;li&gt;etcd 3.1.12&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.weave.works/oss/net/&#34;&gt;Weave Net&lt;/a&gt; 2.3.0&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/coredns/coredns&#34;&gt;CoreDNS&lt;/a&gt; 1.1.3&lt;/li&gt;
&lt;li&gt;SERVICE_CLUSTER_IP_RANGE (Serviceに割り当てるIPの範囲) は10.0.0.0/16&lt;/li&gt;
&lt;li&gt;CLUSTER_CIDR (Podに割り当てるIPの範囲) は10.32.0.0/16&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies&#34;&gt;Proxyモード&lt;/a&gt;はiptables。&lt;/li&gt;
&lt;li&gt;PodSecurityPolicy有効。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/&#34;&gt;KubeletConfiguration&lt;/a&gt;、&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/apis/kubeproxyconfig/v1alpha1/types.go&#34;&gt;KubeProxyConfiguration&lt;/a&gt;、&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/master/pkg/apis/componentconfig/v1alpha1/types.go&#34;&gt;KubeSchedulerConfiguration&lt;/a&gt;を使用。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;開発ツール付き

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/c-bata/kube-prompt&#34;&gt;kube-prompt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/moncho/dry&#34;&gt;dry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ansibleの変数をいじればある程度違う構成もできる。
複数ノードや、マスターコンポーネントの冗長化や、etcdが別サーバの構成もできそうな感じにはRoleを分けて書いたけど、試してはいない。&lt;/p&gt;

&lt;h2 id=&#34;kubespray&#34;&gt;kubespray&lt;/h2&gt;

&lt;p&gt;一通り作った後で、&lt;a href=&#34;https://github.com/kubernetes-incubator/kubespray&#34;&gt;kubespray&lt;/a&gt;というものを知った。
これ使うと、Ansibleでマルチノードのk8sクラスタ作れて、ネットワークプロバイダ切り替えたり、&lt;a href=&#34;https://istio.io/&#34;&gt;istio&lt;/a&gt;とか&lt;a href=&#34;https://helm.sh/&#34;&gt;Helm&lt;/a&gt;とかDocker Registryとか簡単にデプロイできたり、AWSやAzureにクラスタ作れたり、すごい。&lt;/p&gt;

&lt;p&gt;あ、いや、けどこれOracle Linuxサポートしてないし…&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetes 1.10のkubeletの起動オプションをKubelet ConfigファイルとPodSecurityPolicyで置き換える</title>
          <link>https://www.kaitoy.xyz/2018/05/05/kubernetes-kubelet-config-and-pod-sec-policy/</link>
          <pubDate>Sat, 05 May 2018 21:54:30 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/05/05/kubernetes-kubelet-config-and-pod-sec-policy/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/&#34;&gt;Kubernetes 1.10をスクラッチから全手動で構築&lt;/a&gt;」、「&lt;a href=&#34;https://www.kaitoy.xyz/2018/05/04/kubernetes-with-weave-net/&#34;&gt;Kubernetes 1.10のクラスタにWeave Netをデプロイする&lt;/a&gt;」の続き。&lt;/p&gt;

&lt;p&gt;kubeletの起動オプションの代わりに、Kubelet ConfigファイルとPodSecurityPolicyを使うように変更した話。&lt;/p&gt;

&lt;p&gt;ついでにkube-proxyとkube-schedulerもConfigファイルを使うようにした。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;kubelet-configファイル&#34;&gt;Kubelet Configファイル&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;journalctl -u kubelet&lt;/code&gt;すると、以下の警告が出ている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Apr 28 15:31:39 k8s-master kubelet[1370]: Flag --address has been deprecated, This parameter should be set via the config file specified by the Kubelet&#39;s -
-config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 28 15:31:40 k8s-master kubelet[1370]: Flag --pod-manifest-path has been deprecated, This parameter should be set via the config file specified by the K
ubelet&#39;s --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 28 15:31:40 k8s-master kubelet[1370]: Flag --cluster-dns has been deprecated, This parameter should be set via the config file specified by the Kubelet
&#39;s --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 28 15:31:40 k8s-master kubelet[1370]: Flag --cluster-domain has been deprecated, This parameter should be set via the config file specified by the Kube
let&#39;s --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 28 15:31:40 k8s-master kubelet[1370]: Flag --authorization-mode has been deprecated, This parameter should be set via the config file specified by the
Kubelet&#39;s --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 28 15:31:40 k8s-master kubelet[1370]: Flag --client-ca-file has been deprecated, This parameter should be set via the config file specified by the Kube
let&#39;s --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 28 15:31:40 k8s-master kubelet[1370]: Flag --cgroup-driver has been deprecated, This parameter should be set via the config file specified by the Kubel
et&#39;s --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 28 15:31:40 k8s-master kubelet[1370]: Flag --tls-min-version has been deprecated, This parameter should be set via the config file specified by the Kubelet&#39;s --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 28 15:31:40 k8s-master kubelet[1370]: Flag --allow-privileged has been deprecated, will be removed in a future version
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;kubeletのいくつかのオプションは、&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/&#34;&gt;https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/&lt;/a&gt; を参照してKubelet Configファイルのほうに書けとある。&lt;/p&gt;

&lt;p&gt;参照先のマニュアルには現時点でほぼ何も書いてないし、ググっても情報が無いので、&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/release-1.10/pkg/kubelet/apis/kubeletconfig/v1beta1/types.go&#34;&gt;ソース&lt;/a&gt;を見てそれっぽく書いてみた。&lt;/p&gt;

&lt;p&gt;将来的に調整しそうなパラメータは、Kubelet Configファイルにデフォルト値とともにコメントとして書き出している。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# DNS_SERVER_IP=10.0.0.10
# DNS_DOMAIN=&amp;quot;cluster.local&amp;quot;
# cat &amp;gt; /etc/kubernetes/kubelet.conf &amp;lt;&amp;lt; EOF
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
featureGates:
  RotateKubeletServerCertificate: true
address: &amp;quot;0.0.0.0&amp;quot;
staticPodPath: &amp;quot;/etc/kubernetes/manifests&amp;quot;
clusterDNS: [&amp;quot;${DNS_SERVER_IP}&amp;quot;]
clusterDomain: &amp;quot;${DNS_DOMAIN}&amp;quot;
authorization:
  mode: Webhook
  webhook:
    cacheAuthorizedTTL: &amp;quot;5m0s&amp;quot;
    cacheUnauthorizedTTL: &amp;quot;30s&amp;quot;
authentication:
  x509:
    clientCAFile: &amp;quot;/etc/kubernetes/pki/ca.crt&amp;quot;
  webhook:
    enabled: false
    cacheTTL: &amp;quot;0s&amp;quot;
  anonymous:
    enabled: false
cgroupDriver: &amp;quot;cgroupfs&amp;quot;
tlsMinVersion: &amp;quot;VersionTLS12&amp;quot;
tlsCipherSuites:
- &amp;quot;TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256&amp;quot;
- &amp;quot;TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384&amp;quot;
- &amp;quot;TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256&amp;quot;
- &amp;quot;TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384&amp;quot;
readOnlyPort: 0
# port: 10250
# containerLogMaxSize: &amp;quot;10Mi&amp;quot;
# containerLogMaxFiles: 5
# evictionHard:
#   imagefs.available: &amp;quot;15%&amp;quot;
#   memory.available: &amp;quot;100Mi&amp;quot;
#   nodefs.available: &amp;quot;10%&amp;quot;
#   nodefs.inodesFree: &amp;quot;5%&amp;quot;
# evictionMaxPodGracePeriod: 0
# evictionPressureTransitionPeriod: &amp;quot;5m0s&amp;quot;
# fileCheckFrequency: &amp;quot;20s&amp;quot;
# imageGCHighThresholdPercent: 85
# imageGCLowThresholdPercent: 80
# maxOpenFiles: 1000000
# maxPods: 110
# imageMinimumGCAge: &amp;quot;2m0s&amp;quot;
# nodeStatusUpdateFrequency: &amp;quot;10s&amp;quot;
# runtimeRequestTimeout: &amp;quot;2m0s&amp;quot;
# streamingConnectionIdleTimeout: &amp;quot;4h0m0s&amp;quot;
# syncFrequency: &amp;quot;1m0s&amp;quot;
# volumeStatsAggPeriod: &amp;quot;1m0s&amp;quot;
EOF
# PAUSE_IMAGE=k8s.gcr.io/pause-amd64:3.1
# cat &amp;gt; /etc/systemd/system/kubelet.service &amp;lt;&amp;lt; EOF
[Unit]
Description=Kubernetes Kubelet
Documentation=https://github.com/kubernetes/kubernetes
After=docker.service
Requires=docker.service

[Service]
User=root
Group=root
ExecStart=/usr/bin/kubelet \\
  --allow-privileged=true \\
  --config=/etc/kubernetes/kubelet.conf \\
  --bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \\
  --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \\
  --network-plugin=cni \\
  --cni-conf-dir=/etc/cni/net.d \\
  --cni-bin-dir=/opt/cni/bin \\
  --cert-dir=/etc/kubernetes/pki \\
  --rotate-certificates=true \\
  --v=2 \\
  --pod-infra-container-image=${PAUSE_IMAGE}
Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl restart kubelet
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--allow-privileged&lt;/code&gt;だけは、警告が出てるけどKubelet Configファイルで設定できない。&lt;/p&gt;

&lt;h2 id=&#34;podsecuritypolicy&#34;&gt;PodSecurityPolicy&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;--allow-privileged&lt;/code&gt;は非推奨。
どうも代わりに&lt;a href=&#34;https://kubernetes.io/docs/concepts/policy/pod-security-policy/&#34;&gt;PodSecurityPolicy&lt;/a&gt;で制御しろということのようだ。&lt;/p&gt;

&lt;p&gt;PodSecurityPolicyを使うにはまず、kube-apiserverの起動オプションの&lt;code&gt;--enable-admission-plugins&lt;/code&gt;に&lt;code&gt;PodSecurityPolicy&lt;/code&gt;を追加する必要がある。&lt;/p&gt;

&lt;p&gt;で、privilegedななんでもできるPodSecurityPolicyと、それを使うロールを作成する。
因みにPodSecurityPolicyは名前空間に属さない。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl create -f- &amp;lt;&amp;lt;EOF
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: privileged
spec:
  privileged: true
  hostIPC: true
  hostPID: true
  hostNetwork: true
  hostPorts:
  - min: 0
    max: 65535
  volumes:
  - &amp;quot;*&amp;quot;
  fsGroup:
    rule: &amp;quot;RunAsAny&amp;quot;
  runAsUser:
    rule: &amp;quot;RunAsAny&amp;quot;
  supplementalGroups:
    rule: &amp;quot;RunAsAny&amp;quot;
  allowPrivilegeEscalation: true
  allowedCapabilities:
  - &amp;quot;*&amp;quot;
  seLinux:
    rule: &amp;quot;RunAsAny&amp;quot;
EOF
# kubectl -n kube-system create role psp:privileged --verb=use --resource=podsecuritypolicy --resource-name=privileged
# kubectl -n weave create role psp:privileged --verb=use --resource=podsecuritypolicy --resource-name=privileged
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今のところ、privilegedなPodSecurityPolicyが必要なService AccountはWeave Netのkube-system:weave-netと、Weave Scopeのweave:weave-scopeとweave:default。
こいつらに上記ロールをバインドする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl -n kube-system create rolebinding weave-net:psp:privileged --role=psp:privileged --serviceaccount=kube-system:weave-net
# kubectl -n weave create rolebinding weave-scope:psp:privileged --role=psp:privileged --serviceaccount=weave:weave-scope
# kubectl -n weave create rolebinding weave-default:psp:privileged --role=psp:privileged --serviceaccount=weave:default
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あと、CoreDNS用のPodSecurityPolicyとロールを作ってバインドする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl apply -f- &amp;lt;&amp;lt;EOF
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: coredns
spec:
  privileged: false
  hostIPC: false
  hostPID: false
  hostNetwork: false
  hostPorts:
  - min: 0
    max: 65535
  volumes:
  - &amp;quot;configMap&amp;quot;
  - &amp;quot;secret&amp;quot;
  fsGroup:
    rule: &amp;quot;RunAsAny&amp;quot;
  runAsUser:
    rule: &amp;quot;RunAsAny&amp;quot;
  supplementalGroups:
    rule: &amp;quot;RunAsAny&amp;quot;
  allowPrivilegeEscalation: true
  seLinux:
    rule: &amp;quot;RunAsAny&amp;quot;
EOF
# kubectl -n kube-system create role psp:coredns --verb=use --resource=podsecuritypolicy --resource-name=coredns
# kubectl -n kube-system create rolebinding coredns:psp:coredns --role=psp:coredns --serviceaccount=kube-system:coredns
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで晴れてkubeletから&lt;code&gt;--allow-privileged&lt;/code&gt;を外せる、と思ったら、外したら動かなかった。
どうも現時点では&lt;a href=&#34;https://github.com/kubernetes/kubernetes/issues/58010&#34;&gt;kubeletとPodSecurityPolicyが連携できていない&lt;/a&gt;らしく、&lt;code&gt;--allow-privileged&lt;/code&gt;は付けとかないといけないようだ。
付けといても、PodSecurityPolicyでprivilegedをtrueにしないとprivilegedが許可されないので、動きとしては問題ない。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--allow-privileged&lt;/code&gt;はKubernetes 1.12で廃止される予定なので、それまでにはなんとかなるだろう。&lt;/p&gt;

&lt;h2 id=&#34;kube-proxy-configファイル&#34;&gt;Kube Proxy Configファイル&lt;/h2&gt;

&lt;p&gt;kube-proxyも&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/apis/config/types.go&#34;&gt;Kube Proxy Config&lt;/a&gt;というのがある。
&lt;a href=&#34;https://github.com/kubernetes/kubernetes/issues/50041&#34;&gt;ドキュメントには載ってない&lt;/a&gt;けど、使わないと警告が出るので適当に書いてみた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# CLUSTER_CIDR=&amp;quot;10.32.0.0/16&amp;quot;
# cat &amp;gt; /etc/kubernetes/kube-proxy.conf &amp;lt;&amp;lt; EOF
kind: KubeProxyConfiguration
apiVersion: kubeproxy.config.k8s.io/v1alpha1
featureGates:
  RotateKubeletServerCertificate: true
bindAddress: &amp;quot;0.0.0.0&amp;quot;
clientConnection:
  kubeconfig: &amp;quot;/etc/kubernetes/kube-proxy.kubeconfig&amp;quot;
clusterCIDR: &amp;quot;${CLUSTER_CIDR}&amp;quot;
EOF
# cat &amp;gt; /etc/systemd/system/kube-proxy.service &amp;lt;&amp;lt; EOF
[Unit]
Description=Kubernetes Kube Proxy
Documentation=https://github.com/kubernetes/kubernetes
After=network.target

[Service]
User=root
Group=root
ExecStart=/usr/bin/kube-proxy \\
  --config=/etc/kubernetes/kube-proxy.conf \\
  --v=2
Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl restart kube-proxy
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;kube-scheduler-confファイル&#34;&gt;Kube Scheduler Confファイル&lt;/h2&gt;

&lt;p&gt;kube-schedulerも&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/master/pkg/apis/componentconfig/v1alpha1/types.go&#34;&gt;Kube Scheduler Conf&lt;/a&gt;というのがある。
例によってドキュメントには載ってないけど、使わないと警告が出るので適当に書いてみた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# cat &amp;gt; /etc/kubernetes/kube-scheduler.conf &amp;lt;&amp;lt; EOF
kind: KubeSchedulerConfiguration
apiVersion: componentconfig/v1alpha1
featureGates:
  RotateKubeletServerCertificate: true
healthzBindAddress: &amp;quot;0.0.0.0&amp;quot;
clientConnection:
  kubeconfig: &amp;quot;/etc/kubernetes/kube-scheduler.kubeconfig&amp;quot;
EOF
# cat &amp;gt; /etc/systemd/system/kube-scheduler.service &amp;lt;&amp;lt; EOF
[Unit]
Description=Kubernetes Scheduler
Documentation=https://github.com/kubernetes/kubernetes
After=network.target

[Service]
User=kubernetes
Group=kubernetes
ExecStart=/usr/bin/kube-scheduler \\
  --config=/etc/kubernetes/kube-scheduler.conf \\
  --v=2
Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl restart kube-scheduler
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetes 1.10のクラスタにWeave Netをデプロイする</title>
          <link>https://www.kaitoy.xyz/2018/05/04/kubernetes-with-weave-net/</link>
          <pubDate>Fri, 04 May 2018 11:14:33 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/05/04/kubernetes-with-weave-net/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/&#34;&gt;Kubernetes 1.10をスクラッチから全手動で構築&lt;/a&gt;」で、Kubernetes 1.10のクラスタに、ネットワークプロバイダとして&lt;a href=&#34;https://github.com/coreos/flannel&#34;&gt;flannel&lt;/a&gt;をデプロイしたけど、flannelは&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/network-policies/&#34;&gt;Network Policy&lt;/a&gt;をサポートしていないので、代わりに&lt;a href=&#34;https://www.weave.works/oss/net/&#34;&gt;Weave Net&lt;/a&gt;をデプロイしてみた話。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;weave-netにした理由&#34;&gt;Weave Netにした理由&lt;/h1&gt;

&lt;p&gt;Network Policyをサポートしているネットワークプロバイダには現時点で以下のものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.projectcalico.org/&#34;&gt;Calico&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cilium/cilium&#34;&gt;Cilium&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kube-router.io/&#34;&gt;Kube-router&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/romana/romana&#34;&gt;Romana&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Weave Net&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;このなかで、よく名前を聞くのがCalicoとWeave Net。
GitHubのスター数が圧倒的に多いのがWeave Net。
&lt;a href=&#34;https://engineering.skybettingandgaming.com/2017/02/03/overlay-network-performance-testing/&#34;&gt;性能が比較的いい&lt;/a&gt;のがWeave Net。&lt;/p&gt;

&lt;p&gt;ということでWeave Netにした。&lt;/p&gt;

&lt;h1 id=&#34;weave-netデプロイ&#34;&gt;Weave Netデプロイ&lt;/h1&gt;

&lt;p&gt;以下を参考に設定してデプロイする。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.weave.works/docs/net/latest/kubernetes/kube-addon/&#34;&gt;https://www.weave.works/docs/net/latest/kubernetes/kube-addon/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.weave.works/docs/net/latest/install/installing-weave/&#34;&gt;https://www.weave.works/docs/net/latest/install/installing-weave/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/weaveworks/weave/blob/master/prog/weave-kube/launch.sh&#34;&gt;https://github.com/weaveworks/weave/blob/master/prog/weave-kube/launch.sh&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;kubernetesマニフェスト&#34;&gt;Kubernetesマニフェスト&lt;/h2&gt;

&lt;p&gt;Weave NetをKubernetesクラスタにデプロイするためのマニフェストは、&lt;a href=&#34;https://github.com/weaveworks/weave/releases&#34;&gt;GitHub Releases&lt;/a&gt;か&lt;code&gt;https://cloud.weave.works&lt;/code&gt;からダウンロードできる。
今回は後者にする。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;https://cloud.weave.works&lt;/code&gt;を使う場合、Kubernetesのバージョンなどのパラメータは&lt;a href=&#34;https://www.weave.works/docs/net/latest/kubernetes/kube-addon/#-changing-configuration-options&#34;&gt;クエリストリングで指定できる&lt;/a&gt;。
主なパラメータは以下。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;k8s-version: Kubernetesのバージョン。指定しないとlatest。&lt;/li&gt;
&lt;li&gt;password-secret: ノード間の&lt;a href=&#34;https://www.weave.works/docs/net/latest/concepts/encryption/&#34;&gt;Weave Net通信の暗号化&lt;/a&gt;に使うパスワードを保持するSecret名。指定しないと平文。(参考: &lt;a href=&#34;https://www.weave.works/docs/net/latest/tasks/manage/security-untrusted-networks/&#34;&gt;https://www.weave.works/docs/net/latest/tasks/manage/security-untrusted-networks/&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;IPALLOC_RANGE: Podに割り当てるIPアドレスの範囲。指定しないと10.32.0.0/12。&lt;/li&gt;
&lt;li&gt;CHECKPOINT_DISABLE: Weave Netのアップデートを&lt;a href=&#34;https://www.weave.works/docs/net/latest/install/installing-weave/#checkpoint&#34;&gt;定期的にチェック&lt;/a&gt;する機能の無効化オプション。&lt;/li&gt;
&lt;li&gt;WEAVE_MTU: MTUを指定するオプション。&lt;a href=&#34;https://www.weave.works/docs/net/latest/tasks/manage/fastdp/#packet-size-mtu&#34;&gt;デフォルトで1376バイト&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;WEAVE_MTUはとりあえずデフォルトにしておいて、IPALLOC_RANGEもデフォルトにして、通信暗号化して、CHECKPOINT_DISABLEをtrueにするとすると、マニフェストは以下のようにダウンロードできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# curl -fsSLo weave-daemonset.yaml &amp;quot;https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d &#39;\n&#39;)&amp;amp;env.CHECKPOINT_DISABLE=1&amp;amp;password-secret=weave-passwd&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(通信暗号化は単一ノードなら不要だと思うけどとりあえず設定しておく。)&lt;/p&gt;

&lt;h2 id=&#34;kubernetesコンポーネントの起動オプション&#34;&gt;Kubernetesコンポーネントの起動オプション&lt;/h2&gt;

&lt;p&gt;kube-controller-managerの起動オプションの&lt;code&gt;--cluster-cidr&lt;/code&gt;はIPALLOC_RANGEと同じにする必要がある。
今回は10.32.0.0/12を指定する。&lt;/p&gt;

&lt;p&gt;また、kube-proxyの起動オプションの&lt;a href=&#34;https://www.weave.works/docs/net/latest/kubernetes/kube-addon/#-things-to-watch-out-for&#34;&gt;要件&lt;/a&gt;は以下。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--masquerade-all&lt;/code&gt;を指定してはいけない。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--cluster-cidr&lt;/code&gt;を指定する場合、IPALLOC_RANGEと同じにする必要がある。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;また、kube-apiserverとkube-controller-managerの起動オプションに&lt;code&gt;--allow-privileged&lt;/code&gt;を付ける必要があるはず。&lt;/p&gt;

&lt;h2 id=&#34;secret作成&#34;&gt;Secret作成&lt;/h2&gt;

&lt;p&gt;password-secretに渡すSecretは以下のように作成できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# WEAVE_PASSWORD=$(echo -n &#39;your_secure_password&#39; | base64)
# cat &amp;lt;&amp;lt;EOF | kubectl create -f -
apiVersion: v1
kind: Secret
metadata:
  namespace: kube-system
  name: weave-passwd
type: Opaque
data:
  weave-passwd: ${WEAVE_PASSWORD}
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで準備完了。&lt;/p&gt;

&lt;h2 id=&#34;マニフェスト適用&#34;&gt;マニフェスト適用&lt;/h2&gt;

&lt;p&gt;以下のコマンドでマニフェストを適用し、Weave Netをデプロイできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl apply -f weave-daemonset.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;weaveworks/weave-kube:2.3.0&lt;/code&gt;と&lt;code&gt;weaveworks/weave-npc:2.3.0&lt;/code&gt;がpullされる。
前者が本体で、後者がNetwork Policy Controller。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;マスタノード上で以下のコマンドを実行すると、Weave NetのAPIを叩いて状態を確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# curl http://localhost:6784/status
        Version: 2.3.0 (version check update disabled)

        Service: router
       Protocol: weave 1..2
           Name: 92:44:35:3d:f8:d8(k8s-master)
     Encryption: enabled
  PeerDiscovery: enabled
        Targets: 1
    Connections: 1 (1 failed)
          Peers: 1
 TrustedSubnets: none

        Service: ipam
         Status: ready
          Range: 10.32.0.0/12
  DefaultSubnet: 10.32.0.0/12
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetes 1.10をスクラッチから全手動で構築</title>
          <link>https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/</link>
          <pubDate>Tue, 17 Apr 2018 00:31:48 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/</guid>
          <description>

&lt;p&gt;Oracle Linux 7.4.0のVMでKubernetes1.10.0のクラスタをスクラッチから全手動で作った。
参考にしたのは主に以下。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://nixaid.com/deploying-kubernetes-cluster-from-scratch/&#34;&gt;https://nixaid.com/deploying-kubernetes-cluster-from-scratch/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.10.md&#34;&gt;https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.10.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/getting-started-guides/scratch/&#34;&gt;https://kubernetes.io/docs/getting-started-guides/scratch/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/reference/setup-tools/kubeadm/implementation-details/&#34;&gt;https://kubernetes.io/docs/reference/setup-tools/kubeadm/implementation-details/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ulam.io/blog/kubernetes-scratch/&#34;&gt;https://ulam.io/blog/kubernetes-scratch/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/virtualization/windowscontainers/kubernetes/creating-a-linux-master&#34;&gt;https://docs.microsoft.com/en-us/virtualization/windowscontainers/kubernetes/creating-a-linux-master&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;構成&#34;&gt;構成&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;マシン: Windows 10 Homeのラップトップの上のVMware PlayerのVM

&lt;ul&gt;
&lt;li&gt;CPU: 2コア&lt;/li&gt;
&lt;li&gt;メモリ: 4GB&lt;/li&gt;
&lt;li&gt;NIF: NATのを一つ&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;OS: Oracle Linux 7.4.0

&lt;ul&gt;
&lt;li&gt;Minimalインストール&lt;/li&gt;
&lt;li&gt;IPアドレス: 192.168.171.200、静的割り当て&lt;/li&gt;
&lt;li&gt;ホスト名: k8s-master (hostsで解決)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Docker: Oracle Container Runtime for Docker (docker-engine) 17.06.2&lt;/li&gt;
&lt;li&gt;Kubernetes: バージョン1.10.0

&lt;ul&gt;
&lt;li&gt;単一ノード&lt;/li&gt;
&lt;li&gt;全コンポーネント(kubelet、kube-proxy、kube-apiserver、kube-controller-manager、kube-scheduler、etcd)をsystemdで起動 (i.e. 非コンテナ)

&lt;ul&gt;
&lt;li&gt;kubeletとkube-proxy以外は非rootユーザ&lt;/li&gt;
&lt;li&gt;kubeletは&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.10.2/cmd/kubelet/app/server.go#L388&#34;&gt;現時点でrootで動かす必要がある&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;kube-proxyはiptableいじったりする都合上rootで動かす必要があるっぽい。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;コンポーネント間通信とkubectlの通信をTLSで暗号化

&lt;ul&gt;
&lt;li&gt;TLS 1.2&lt;/li&gt;
&lt;li&gt;セキュアなCipher Suites&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;コンポーネント間通信とkubectlの通信の認証は&lt;a href=&#34;https://kubernetes.io/docs/admin/authentication/#x509-client-certs&#34;&gt;x509クライアント証明書&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TLS Bootstrapping

&lt;ul&gt;
&lt;li&gt;Bootstrap token使用&lt;/li&gt;
&lt;li&gt;CSR自動承認&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tls/certificate-rotation/&#34;&gt;Certificate Rotation&lt;/a&gt;有効&lt;/li&gt;
&lt;li&gt;etcd 3.1.12&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/coreos/flannel&#34;&gt;flannel&lt;/a&gt; 0.10.0&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/coredns/coredns&#34;&gt;CoreDNS&lt;/a&gt; 1.1.1&lt;/li&gt;
&lt;li&gt;SERVICE_CLUSTER_IP_RANGE (Serviceに割り当てるIPの範囲) は10.0.0.0/16

&lt;ul&gt;
&lt;li&gt;kube-apiserverのIPはこの範囲の最初のIP(i.e. 10.0.0.1)になる。&lt;/li&gt;
&lt;li&gt;ホストネットワークや、CLUSTER_CIDRと範囲が被らないようにする必要がある。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;CLUSTER_CIDR (Podに割り当てるIPの範囲) は10.244.0.0/16

&lt;ul&gt;
&lt;li&gt;flannelの要件に合わせている。&lt;/li&gt;
&lt;li&gt;ホストネットワークや、SERVICE_CLUSTER_IP_RANGEと範囲が被らないようにする必要がある。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies&#34;&gt;Proxyモード&lt;/a&gt;はiptables。

&lt;ul&gt;
&lt;li&gt;ipvsのほうが速いけど、flannelとかがサポートしているかよくわからないので。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;kubeletの動作条件にあるので、swapをoffにする。
Oracle Linuxにログインして、&lt;code&gt;/etc/fstab&lt;/code&gt;のswapの行を削除して、以下のコマンドを実行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# swapoff -a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;SELinuxはちゃんと設定すればKubernetes動かせるはずだけど、面倒なのでとりあえず無効にする。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/etc/selinux/config&lt;/code&gt;を編集して、&lt;code&gt;SELINUX&lt;/code&gt;を&lt;code&gt;permissive&lt;/code&gt;にして、以下のコマンドを実行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# setenforce 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ファイアウォールもちゃんと設定すればいいんだけど面倒なのでとりあえず無効にする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# systemctl stop firewalld
# systemctl disable firewalld
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで準備完了。&lt;/p&gt;

&lt;h2 id=&#34;クラスタ構築手順&#34;&gt;クラスタ構築手順&lt;/h2&gt;

&lt;p&gt;おおむね、k8sコンポーネント間の通信の暗号化に使う鍵と証明書の生成、各コンポーネント用kubeconfigの生成、etcdのデプロイ、k8sコンポーネントのデプロイ、fannelデプロイ、CoreDNSデプロイ、という流れ。
ついでに最後に&lt;a href=&#34;https://github.com/weaveworks/scope&#34;&gt;Weave Scope&lt;/a&gt;をデプロイしてみる。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Bridge netfilterとIP forwardingを設定&lt;/p&gt;

&lt;p&gt;まず、Bridge netfilterモジュールをロードする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# modprobe br_netfilter
# echo &amp;quot;br_netfilter&amp;quot; &amp;gt; /etc/modules-load.d/br_netfilter.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Bridge netfilterとIP forwardingを有効化する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# cat &amp;gt; /etc/sysctl.d/kubernetes.conf &amp;lt;&amp;lt; EOF
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward = 1
EOF
# sysctl -p /etc/sysctl.d/kubernetes.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;設定確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# lsmod |grep br_netfilter
# sysctl -a | grep -E &amp;quot;net.bridge.bridge-nf-call-|net.ipv4.ip_forward&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;x509証明書生成&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;opensslの設定作成&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# mkdir -p /etc/kubernetes/pki
# HOSTNAME=k8s-master
# K8S_SERVICE_IP=10.0.0.1
# MASTER_IP=192.168.171.200
# cat &amp;gt; /etc/kubernetes/pki/openssl.cnf &amp;lt;&amp;lt; EOF
[ req ]
distinguished_name = req_distinguished_name
[req_distinguished_name]
[ v3_ca ]
basicConstraints = critical, CA:TRUE
keyUsage = critical, digitalSignature, keyEncipherment, keyCertSign
[ v3_req_client ]
basicConstraints = CA:FALSE
keyUsage = critical, digitalSignature, keyEncipherment
extendedKeyUsage = clientAuth
[ v3_req_apiserver ]
basicConstraints = CA:FALSE
keyUsage = critical, digitalSignature, keyEncipherment
extendedKeyUsage = serverAuth
subjectAltName = @alt_names_cluster
[ v3_req_etcd ]
basicConstraints = CA:FALSE
keyUsage = critical, digitalSignature, keyEncipherment
extendedKeyUsage = serverAuth
subjectAltName = @alt_names_etcd
[ alt_names_cluster ]
DNS.1 = kubernetes
DNS.2 = kubernetes.default
DNS.3 = kubernetes.default.svc
DNS.4 = kubernetes.default.svc.cluster.local
DNS.5 = ${HOSTNAME}
IP.1 = ${MASTER_IP}
IP.2 = ${K8S_SERVICE_IP}
[ alt_names_etcd ]
DNS.1 = ${HOSTNAME}
IP.1 = ${MASTER_IP}
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kubernetes CA証明書生成&lt;/p&gt;

&lt;p&gt;以降で生成する証明書に署名するための証明書。
後述のTLS Bootstrappingでの証明書生成にも使う。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# groupadd -r kubernetes
# adduser -r -g kubernetes -M -s /sbin/nologin kubernetes
# CA_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/ca.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/ca.key
# chmod 0600 /etc/kubernetes/pki/ca.key
# openssl req -x509 -new -sha256 -nodes -key /etc/kubernetes/pki/ca.key -days $CA_DAYS -out /etc/kubernetes/pki/ca.crt -subj &amp;quot;/CN=kubernetes-ca&amp;quot;  -extensions v3_ca -config /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kube-apiserver証明書生成&lt;/p&gt;

&lt;p&gt;kube-apiserverのサーバ証明書。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# APISERVER_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/kube-apiserver.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/kube-apiserver.key
# chmod 0600 /etc/kubernetes/pki/kube-apiserver.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/kube-apiserver.key -subj &amp;quot;/CN=kube-apiserver&amp;quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/kube-apiserver.crt -days $APISERVER_DAYS -extensions v3_req_apiserver -extfile /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kube-apiserver-kubelet証明書生成&lt;/p&gt;

&lt;p&gt;kube-apiserverが&lt;a href=&#34;https://kubernetes.io/docs/concepts/architecture/master-node-communication/#apiserver-kubelet&#34;&gt;kubeletのAPIにアクセス&lt;/a&gt;するときのクライアント証明書。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# APISERVER_KUBELET_CLIENT_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/apiserver-kubelet-client.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/apiserver-kubelet-client.key
# chmod 0600 /etc/kubernetes/pki/apiserver-kubelet-client.key
# openssl req -new -key /etc/kubernetes/pki/apiserver-kubelet-client.key -subj &amp;quot;/CN=kube-apiserver-kubelet-client/O=system:masters&amp;quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/apiserver-kubelet-client.crt -days $APISERVER_KUBELET_CLIENT_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;adminクライアント証明書生成&lt;/p&gt;

&lt;p&gt;kubectlがkube-apiserverのAPIにアクセスするときのクライアント証明書。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# groupadd -r kube-admin
# adduser -r -g kube-admin -M -s /sbin/nologin kube-admin
# ADMIN_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/admin.key
# chown kube-admin:kube-admin /etc/kubernetes/pki/admin.key
# chmod 0600 /etc/kubernetes/pki/admin.key
# openssl req -new -key /etc/kubernetes/pki/admin.key -subj &amp;quot;/CN=kubernetes-admin/O=system:masters&amp;quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/admin.crt -days $ADMIN_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kube-controller-managerのクライアント証明書生成&lt;/p&gt;

&lt;p&gt;kube-controller-managerがkube-apiserverに接続するときのクライアント証明書。
この証明書に対応する秘密鍵と公開鍵はそれぞれ、kube-controller-managerがService Accountトークンに署名するとき、kube-apiserverがトークンの署名を確認するときにも使う。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# CONTROLLER_MANAGER_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/kube-controller-manager.key
# openssl ec -in /etc/kubernetes/pki/kube-controller-manager.key -outform PEM -pubout -out /etc/kubernetes/pki/kube-controller-manager.pub
# chown kubernetes:kubernetes /etc/kubernetes/pki/kube-controller-manager.key
# chmod 0600 /etc/kubernetes/pki/kube-controller-manager.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/kube-controller-manager.key -subj &amp;quot;/CN=system:kube-controller-manager&amp;quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/kube-controller-manager.crt -days $CONTROLLER_MANAGER_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kube-schedulerクライアント証明書生成&lt;/p&gt;

&lt;p&gt;kube-schedulerがkube-apiserverにリクエストするときに使うクライアント証明書。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# SCHEDULER_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/kube-scheduler.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/kube-scheduler.key
# chmod 0600 /etc/kubernetes/pki/kube-scheduler.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/kube-scheduler.key -subj &amp;quot;/CN=system:kube-scheduler&amp;quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/kube-scheduler.crt -days $SCHEDULER_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kube-proxyクライアント証明書生成&lt;/p&gt;

&lt;p&gt;kube-proxyがkube-apiserverにリクエストするときに使うクライアント証明書。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# PROXY_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/kube-proxy.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/kube-proxy.key
# chmod 0600 /etc/kubernetes/pki/kube-proxy.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/kube-proxy.key -subj &amp;quot;/CN=system:kube-proxy&amp;quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/kube-proxy.crt -days $PROXY_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;front proxy CA証明書生成&lt;/p&gt;

&lt;p&gt;front proxyの証明書に署名するのにつかう証明書。
front proxyは&lt;a href=&#34;https://github.com/kubernetes/community/blob/master/contributors/design-proposals/api-machinery/aggregated-api-servers.md&#34;&gt;API Aggregation&lt;/a&gt;のためのもの。
API Aggregationは、kube-apiserverを変更することなく、別途作られた&lt;a href=&#34;https://kubernetes.io/docs/tasks/access-kubernetes-api/setup-extension-api-server/&#34;&gt;Extension API Server&lt;/a&gt;でKubernetesのAPIを拡張できるようにする機能。
API Aggregationは現時点では&lt;a href=&#34;https://kubernetes.io/docs/concepts/api-extension/apiserver-aggregation/#overview&#34;&gt;kube-apiserverの一機能として実装されていて&lt;/a&gt;、将来的には&lt;a href=&#34;https://github.com/kubernetes/kube-aggregator&#34;&gt;kubernetes-aggregator&lt;/a&gt;という別のコンポーネントで実現される。&lt;/p&gt;

&lt;p&gt;API AggregationしないならこのCA証明書と次のクライアント証明書はいらないはず。
今回はしないけど、とりあえず作って設定したおく。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# FRONT_PROXY_CA_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/front-proxy-ca.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/front-proxy-ca.key
# chmod 0600 /etc/kubernetes/pki/front-proxy-ca.key
# openssl req -x509 -new -sha256 -nodes -key /etc/kubernetes/pki/front-proxy-ca.key -days $FRONT_PROXY_CA_DAYS -out /etc/kubernetes/pki/front-proxy-ca.crt -subj &amp;quot;/CN=front-proxy-ca&amp;quot; -extensions v3_ca -config /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;front proxyクライアント証明書&lt;/p&gt;

&lt;p&gt;Extension API ServerのAPIへのリクエストは、いったんkube-apiserverが受け取ってExtension API Serverに転送される。(多分。)
この転送の暗号化と認証にTLSが使われていて、ここではそのクライアント証明書を生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# FRONT_PROXY_CLIENT_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/front-proxy-client.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/front-proxy-client.key
# chmod 0600 /etc/kubernetes/pki/front-proxy-client.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/front-proxy-client.key -subj &amp;quot;/CN=front-proxy-client&amp;quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/front-proxy-ca.crt -CAkey /etc/kubernetes/pki/front-proxy-ca.key -CAcreateserial -out /etc/kubernetes/pki/front-proxy-client.crt -days $FRONT_PROXY_CLIENT_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;etcd CA証明書&lt;/p&gt;

&lt;p&gt;以降で生成するetcdの証明書に署名するための証明書。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# groupadd -r etcd
# adduser -r -g etcd -M -s /sbin/nologin etcd
# ETCD_CA_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/etcd-ca.key
# chown etcd:etcd /etc/kubernetes/pki/etcd-ca.key
# chmod 0600 /etc/kubernetes/pki/etcd-ca.key
# openssl req -x509 -new -sha256 -nodes -key /etc/kubernetes/pki/etcd-ca.key -days $ETCD_CA_DAYS -out /etc/kubernetes/pki/etcd-ca.crt -subj &amp;quot;/CN=etcd-ca&amp;quot; -extensions v3_ca -config /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;etcd証明書&lt;/p&gt;

&lt;p&gt;etcdのサーバ証明書。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# ETCD_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/etcd.key
# chown etcd:etcd /etc/kubernetes/pki/etcd.key
# chmod 0600 /etc/kubernetes/pki/etcd.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/etcd.key -subj &amp;quot;/CN=etcd&amp;quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/etcd-ca.crt -CAkey /etc/kubernetes/pki/etcd-ca.key -CAcreateserial -out /etc/kubernetes/pki/etcd.crt -days $ETCD_DAYS -extensions v3_req_etcd -extfile /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;etcdクライアント証明書&lt;/p&gt;

&lt;p&gt;etcdのクライアント証明書。
kube-apiserverだけがetcdと話すので、kube-apiserverだけが使う。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# ETCD_CLIENT_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/etcd-client.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/etcd-client.key
# chmod 0600 /etc/kubernetes/pki/etcd-client.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/etcd-client.key -subj &amp;quot;/CN=kube-apiserver&amp;quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/etcd-ca.crt -CAkey /etc/kubernetes/pki/etcd-ca.key -CAcreateserial -out /etc/kubernetes/pki/etcd-client.crt -days $ETCD_CLIENT_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;etcd peer証明書&lt;/p&gt;

&lt;p&gt;etcdサーバが冗長構成のとき、サーバ間の通信の暗号化に使う証明書。
マスタが一つなら要らないはずだけど、今回とりあえず作って設定しておく。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# ETCD_PEER_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/etcd-peer.key
# chown etcd:etcd /etc/kubernetes/pki/etcd-peer.key
# chmod 0600 /etc/kubernetes/pki/etcd-peer.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/etcd-peer.key -subj &amp;quot;/CN=etcd-peer&amp;quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/etcd-ca.crt -CAkey /etc/kubernetes/pki/etcd-ca.key -CAcreateserial -out /etc/kubernetes/pki/etcd-peer.crt -days $ETCD_PEER_DAYS -extensions v3_req_etcd -extfile /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;確認&lt;/p&gt;

&lt;p&gt;以上で生成した証明書の内容を確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# for i in /etc/kubernetes/pki/*crt; do
  echo $i:;
  openssl x509 -subject -issuer -noout -in $i;
  echo;
done
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kubernetesバイナリインストール&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/getting-started-guides/scratch/#selecting-images&#34;&gt;公式ドキュメント&lt;/a&gt;によると、Docker、kubelet、kube-proxyはコンテナ外で動かして、etcd、kube-apiserver、kube-controller-manager、kube-schedulerはコンテナで動かすのが推奨されている。
けど、とりあえずは簡単に全部コンテナ外でやる。&lt;/p&gt;

&lt;p&gt;(Oracle Linux用には、各コンポのコンテナイメージ詰め合わせがOracle Container Services for use with Kubernetesという名前で配布されているけど、現時点で1.9までしかないので使わない。)&lt;/p&gt;

&lt;p&gt;バイナリは以下URLからダウンロードできる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;全部入り: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/kubernetes-server-linux-amd64.tar.gz&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/kubernetes-server-linux-amd64.tar.gz&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;kube-apiserver

&lt;ul&gt;
&lt;li&gt;バイナリ: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-apiserver&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-apiserver&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;コンテナ: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-apiserver.tar&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-apiserver.tar&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;kube-controller-manager

&lt;ul&gt;
&lt;li&gt;バイナリ: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-controller-manager&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-controller-manager&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;コンテナ: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-controller-manager.tar&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-controller-manager.tar&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;kube-scheduler

&lt;ul&gt;
&lt;li&gt;バイナリ: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-scheduler&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-scheduler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;コンテナ: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-scheduler.tar&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-scheduler.tar&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;kube-proxy

&lt;ul&gt;
&lt;li&gt;バイナリ: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-proxy&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-proxy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;コンテナ: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-proxy.tar&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-proxy.tar&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;kubelet: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubelet&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubelet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;kubectl: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubectl&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubectl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;kubeadm: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubeadm&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubeadm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;hyperkube: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/hyperkube&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/hyperkube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最後のhyperkubeは、各種Kubernetesバイナリのごった煮。
ファイル名によって動作が変わる。
簡単のためこれを使うけど、個別のバイナリ使ったほうがメモリ使用量などで有利そう。&lt;/p&gt;

&lt;p&gt;hyperkubeとkubeadmのバイナリを&lt;code&gt;/usr/bin/&lt;/code&gt;において、以下のコマンドを実行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# ln -s /usr/bin/hyperkube /usr/bin/kube-apiserver
# ln -s /usr/bin/hyperkube /usr/bin/kube-controller-manager
# ln -s /usr/bin/hyperkube /usr/bin/kube-scheduler
# ln -s /usr/bin/hyperkube /usr/bin/kube-proxy
# ln -s /usr/bin/hyperkube /usr/bin/kubelet
# ln -s /usr/bin/hyperkube /usr/bin/kubectl
# chmod +x /usr/bin/kube*
# mkdir -p /var/lib/{kubelet,kube-proxy}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kubeconfigファイル生成&lt;/p&gt;

&lt;p&gt;kubectlとマスタコンポーネントがkube-apiserverと話すときに使うkubeconfigファイルを生成する。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;kube-controller-managerのkubeconfig&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# MASTER_IP=192.168.171.200
# KUBERNETES_PUBLIC_ADDRESS=$MASTER_IP
# CLUSTER_NAME=&amp;quot;k8s&amp;quot;
# KCONFIG=/etc/kubernetes/kube-controller-manager.kubeconfig
# KUSER=&amp;quot;system:kube-controller-manager&amp;quot;
# kubectl config set-cluster ${CLUSTER_NAME} --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 --kubeconfig=${KCONFIG}
# kubectl config set-credentials ${KUSER} --client-certificate=/etc/kubernetes/pki/kube-controller-manager.crt --client-key=/etc/kubernetes/pki/kube-controller-manager.key --embed-certs=true --kubeconfig=${KCONFIG}
# kubectl config set-context ${KUSER}@${CLUSTER_NAME} --cluster=${CLUSTER_NAME} --user=${KUSER} --kubeconfig=${KCONFIG}
# kubectl config use-context ${KUSER}@${CLUSTER_NAME} --kubeconfig=${KCONFIG}
# chown kubernetes:kubernetes ${KCONFIG}
# chmod 0600 ${KCONFIG}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;設定確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl config view --kubeconfig=${KCONFIG}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kube-schedulerのkubeconfig&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# MASTER_IP=192.168.171.200
# KUBERNETES_PUBLIC_ADDRESS=$MASTER_IP
# CLUSTER_NAME=&amp;quot;k8s&amp;quot;
# KCONFIG=/etc/kubernetes/kube-scheduler.kubeconfig
# KUSER=&amp;quot;system:kube-scheduler&amp;quot;
# kubectl config set-cluster ${CLUSTER_NAME} --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 --kubeconfig=${KCONFIG}
# kubectl config set-credentials ${KUSER} --client-certificate=/etc/kubernetes/pki/kube-scheduler.crt --client-key=/etc/kubernetes/pki/kube-scheduler.key --embed-certs=true --kubeconfig=${KCONFIG}
# kubectl config set-context ${KUSER}@${CLUSTER_NAME} --cluster=${CLUSTER_NAME} --user=${KUSER} --kubeconfig=${KCONFIG}
# kubectl config use-context ${KUSER}@${CLUSTER_NAME} --kubeconfig=${KCONFIG}
# chown kubernetes:kubernetes ${KCONFIG}
# chmod 0600 ${KCONFIG}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;設定確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl config view --kubeconfig=${KCONFIG}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;adminのkubeconfig&lt;/p&gt;

&lt;p&gt;kubectl用。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# MASTER_IP=192.168.171.200
# KUBERNETES_PUBLIC_ADDRESS=$MASTER_IP
# CLUSTER_NAME=&amp;quot;k8s&amp;quot;
# KCONFIG=/etc/kubernetes/admin.kubeconfig
# KUSER=&amp;quot;kubernetes-admin&amp;quot;
# kubectl config set-cluster ${CLUSTER_NAME} --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 --kubeconfig=${KCONFIG}
# kubectl config set-credentials ${KUSER} --client-certificate=/etc/kubernetes/pki/admin.crt --client-key=/etc/kubernetes/pki/admin.key --embed-certs=true --kubeconfig=${KCONFIG}
# kubectl config set-context ${KUSER}@${CLUSTER_NAME} --cluster=${CLUSTER_NAME} --user=${KUSER} --kubeconfig=${KCONFIG}
# kubectl config use-context ${KUSER}@${CLUSTER_NAME} --kubeconfig=${KCONFIG}
# chown kube-admin:kube-admin ${KCONFIG}
# chmod 0600 ${KCONFIG}
# ln -s ${KCONFIG} ~/.kube/config
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;設定確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl config view --kubeconfig=${KCONFIG}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;etcdデプロイ&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/coreos/etcd/releases/download/v3.1.12/etcd-v3.1.12-linux-amd64.tar.gz&#34;&gt;https://github.com/coreos/etcd/releases/download/v3.1.12/etcd-v3.1.12-linux-amd64.tar.gz&lt;/a&gt;
からアーカイブをダウンロードして、中のetcdとetcdctlを&lt;code&gt;/usr/bin/&lt;/code&gt;にいれて、以下のコマンドを実行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# chown root:root /usr/bin/etcd*
# chmod 0755 /usr/bin/etcd*
# mkdir -p /var/lib/etcd
# chown etcd:etcd /var/lib/etcd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、systemdのユニットファイルを書いてサービス化。&lt;/p&gt;

&lt;p&gt;(参考: &lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/&#34;&gt;Kubernetesドキュメント&lt;/a&gt;、&lt;a href=&#34;https://github.com/coreos/etcd/blob/master/Documentation/op-guide/security.md&#34;&gt;etcdドキュメント&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# MASTER_IP=192.168.171.200
# ETCD_MEMBER_NAME=etcd1
# CLUSTER_NAME=&amp;quot;k8s&amp;quot;
# ETCD_TOKEN=$(openssl rand -hex 5)
# ETCD_CLUSTER_TOKEN=$CLUSTER_NAME-$ETCD_TOKEN
# cat &amp;gt; /etc/systemd/system/etcd.service &amp;lt;&amp;lt; EOF
[Unit]
Description=etcd
Documentation=https://coreos.com/etcd/docs/latest/
After=network.target


[Service]
Type=notify
NotifyAccess=all
User=etcd
Group=etcd
ExecStart=/usr/bin/etcd \\
  --name ${ETCD_MEMBER_NAME} \\
  --listen-client-urls https://${MASTER_IP}:2379 \\
  --advertise-client-urls https://${MASTER_IP}:2379 \\
  --data-dir=/var/lib/etcd \\
  --cert-file=/etc/kubernetes/pki/etcd.crt \\
  --key-file=/etc/kubernetes/pki/etcd.key \\
  --peer-cert-file=/etc/kubernetes/pki/etcd-peer.crt \\
  --peer-key-file=/etc/kubernetes/pki/etcd-peer.key \\
  --trusted-ca-file=/etc/kubernetes/pki/etcd-ca.crt \\
  --peer-trusted-ca-file=/etc/kubernetes/pki/etcd-ca.crt \\
  --peer-client-cert-auth \\
  --client-cert-auth \\
  --initial-advertise-peer-urls https://${MASTER_IP}:2380 \\
  --listen-peer-urls https://${MASTER_IP}:2380 \\
  --initial-cluster-token ${ETCD_CLUSTER_TOKEN} \\
  --initial-cluster ${ETCD_MEMBER_NAME}=https://${MASTER_IP}:2380 \\
  --initial-cluster-state new
Restart=always
RestartSec=10s


[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable etcd
# systemctl start etcd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# systemctl status etcd -l
# MASTER_IP=192.168.171.200
# etcdctl --endpoints https://${MASTER_IP}:2379 --ca-file=/etc/kubernetes/pki/etcd-ca.crt --cert-file=/etc/kubernetes/pki/etcd-client.crt --key-file=/etc/kubernetes/pki/etcd-client.key cluster-health
# etcdctl --endpoints https://${MASTER_IP}:2379 --ca-file=/etc/kubernetes/pki/etcd-ca.crt --cert-file=/etc/kubernetes/pki/etcd-client.crt --key-file=/etc/kubernetes/pki/etcd-client.key member list
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;マスタコンポーネントデプロイ。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;kube-apiserver&lt;/p&gt;

&lt;p&gt;systemdのユニットファイルを書いてサービス化。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;d&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# mkdir -p /var/log/kubernetes
# chown kubernetes:kubernetes /var/log/kubernetes
# chmod 0700 /var/log/kubernetes
# MASTER_IP=192.168.171.200
# SERVICE_CLUSTER_IP_RANGE=&amp;quot;10.0.0.0/16&amp;quot;
# SECRET_ENC_KEY=$(echo -n &#39;your_32_bytes_secure_private_key&#39; | base64)
# cat &amp;gt; /etc/kubernetes/encryption.conf &amp;lt;&amp;lt; EOF
kind: EncryptionConfig
apiVersion: v1
resources:
  - resources:
    - secrets
    providers:
    - aescbc:
        keys:
        - name: key1
          secret: ${SECRET_ENC_KEY}
    - identity: {}
EOF
# cat &amp;gt; /etc/kubernetes/audit-policy.conf &amp;lt;&amp;lt; EOF
apiVersion: audit.k8s.io/v1beta1
kind: Policy
# Don&#39;t generate audit events for all requests in RequestReceived stage.
omitStages:
  - &amp;quot;RequestReceived&amp;quot;
rules:
  # Log pod changes at RequestResponse level
  - level: RequestResponse
    resources:
    - group: &amp;quot;&amp;quot;
      # Resource &amp;quot;pods&amp;quot; doesn&#39;t match requests to any subresource of pods,
      # which is consistent with the RBAC policy.
      resources: [&amp;quot;pods&amp;quot;]
  # Log &amp;quot;pods/log&amp;quot;, &amp;quot;pods/status&amp;quot; at Metadata level
  - level: Metadata
    resources:
    - group: &amp;quot;&amp;quot;
      resources: [&amp;quot;pods/log&amp;quot;, &amp;quot;pods/status&amp;quot;]


  # Don&#39;t log requests to a configmap called &amp;quot;controller-leader&amp;quot;
  - level: None
    resources:
    - group: &amp;quot;&amp;quot;
      resources: [&amp;quot;configmaps&amp;quot;]
      resourceNames: [&amp;quot;controller-leader&amp;quot;]


  # Don&#39;t log watch requests by the &amp;quot;system:kube-proxy&amp;quot; on endpoints or services
  - level: None
    users: [&amp;quot;system:kube-proxy&amp;quot;]
    verbs: [&amp;quot;watch&amp;quot;]
    resources:
    - group: &amp;quot;&amp;quot; # core API group
      resources: [&amp;quot;endpoints&amp;quot;, &amp;quot;services&amp;quot;]


  # Don&#39;t log authenticated requests to certain non-resource URL paths.
  - level: None
    userGroups: [&amp;quot;system:authenticated&amp;quot;]
    nonResourceURLs:
    - &amp;quot;/api*&amp;quot; # Wildcard matching.
    - &amp;quot;/version&amp;quot;


  # Log the request body of configmap changes in kube-system.
  - level: Request
    resources:
    - group: &amp;quot;&amp;quot; # core API group
      resources: [&amp;quot;configmaps&amp;quot;]
    # This rule only applies to resources in the &amp;quot;kube-system&amp;quot; namespace.
    # The empty string &amp;quot;&amp;quot; can be used to select non-namespaced resources.
    namespaces: [&amp;quot;kube-system&amp;quot;]


  # Log configmap and secret changes in all other namespaces at the Metadata level.
  - level: Metadata
    resources:
    - group: &amp;quot;&amp;quot; # core API group
      resources: [&amp;quot;secrets&amp;quot;, &amp;quot;configmaps&amp;quot;]


  # Log all other resources in core and extensions at the Request level.
  - level: Request
    resources:
    - group: &amp;quot;&amp;quot; # core API group
    - group: &amp;quot;extensions&amp;quot; # Version of group should NOT be included.


  # A catch-all rule to log all other requests at the Metadata level.
  - level: Metadata
    # Long-running requests like watches that fall under this rule will not
    # generate an audit event in RequestReceived.
    omitStages:
      - &amp;quot;RequestReceived&amp;quot;
EOF
# cat &amp;gt; /etc/systemd/system/kube-apiserver.service &amp;lt;&amp;lt; EOF
[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/kubernetes/kubernetes
After=network.target


[Service]
User=kubernetes
Group=kubernetes
ExecStart=/usr/bin/kube-apiserver \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --apiserver-count=1 \\
  --allow-privileged=true \\
  --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,NodeRestriction,DenyEscalatingExec,StorageObjectInUseProtection \\
  --authorization-mode=Node,RBAC \\
  --bind-address=0.0.0.0 \\
  --advertise-address=${MASTER_IP} \\
  --client-ca-file=/etc/kubernetes/pki/ca.crt \\
  --etcd-cafile=/etc/kubernetes/pki/etcd-ca.crt \\
  --etcd-certfile=/etc/kubernetes/pki/etcd-client.crt \\
  --etcd-keyfile=/etc/kubernetes/pki/etcd-client.key \\
  --etcd-servers=https://${MASTER_IP}:2379 \\
  --service-account-key-file=/etc/kubernetes/pki/kube-controller-manager.pub \\
  --service-cluster-ip-range=${SERVICE_CLUSTER_IP_RANGE} \\
  --tls-cert-file=/etc/kubernetes/pki/kube-apiserver.crt \\
  --tls-private-key-file=/etc/kubernetes/pki/kube-apiserver.key \\
  --kubelet-certificate-authority=/etc/kubernetes/pki/ca.crt \\
  --enable-bootstrap-token-auth=true \\
  --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt \\
  --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key \\
  --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname \\
  --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt \\
  --requestheader-username-headers=X-Remote-User \\
  --requestheader-group-headers=X-Remote-Group \\
  --requestheader-allowed-names=front-proxy-client \\
  --requestheader-extra-headers-prefix=X-Remote-Extra- \\
  --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt \\
  --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key \\
  --experimental-encryption-provider-config=/etc/kubernetes/encryption.conf \\
  --v=2 \\
  --tls-min-version=VersionTLS12 \\
  --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 \\
  --anonymous-auth=false \\
  --audit-log-format=json \\
  --audit-log-maxage=30 \\
  --audit-log-maxbackup=3 \\
  --audit-log-maxsize=100 \\
  --audit-log-path=/var/log/kubernetes/kube-audit.log \\
  --audit-policy-file=/etc/kubernetes/audit-policy.conf
Restart=always
RestartSec=10s


[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable kube-apiserver
# systemctl start kube-apiserver
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--allow-privileged&lt;/code&gt;はflannelなどに必要。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--enable-admission-plugins&lt;/code&gt;には&lt;a href=&#34;https://kubernetes.io/docs/admin/admission-controllers/#is-there-a-recommended-set-of-admission-controllers-to-use&#34;&gt;公式推奨のプラグイン&lt;/a&gt;に加えて、後述のTLS BootstrappingのためのNodeRestrictionを指定。
また、&lt;code&gt;--allow-privileged&lt;/code&gt;の効果を軽減するため、DenyEscalatingExecも追加で指定。
また、使われているPersistent VolumeやPersistent Volume Claimが誤って消されることを防ぐ&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/#storage-object-in-use-protection&#34;&gt;StorageObjectInUseProtection&lt;/a&gt;も追加で指定。
因みに、プラグインを指定する順番はKubernetes 1.10からは気にしなくてよくなった。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--authorization-mode&lt;/code&gt;にはRBACを指定するのが標準。
後述のTLS Bootstrappingをするなら、Nodeも要る。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--experimental-encryption-provider-config&lt;/code&gt;は&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/&#34;&gt;Secretを暗号化する&lt;/a&gt;ための設定。
暗号化のキーをローテーションすることもできるけど、それはやってない。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--tls-min-version&lt;/code&gt;と&lt;code&gt;--tls-cipher-suites&lt;/code&gt;は&lt;a href=&#34;https://www.lambdanote.com/blogs/news/openssl-cookbook&#34;&gt;OpenSSLクックブック&lt;/a&gt;と&lt;a href=&#34;https://golang.org/pkg/crypto/tls/#pkg-constants&#34;&gt;Goのtlsパッケージドキュメント&lt;/a&gt;を参考に設定。
RSA鍵交換はNG、RC4と3DESもNG、AESの鍵長は128ビット以上、SHA1はNG。&lt;/p&gt;

&lt;p&gt;また、(&amp;ndash;tls-min-versionをVersionTLS12にする場合?)TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256が必須で、CBCモードがNG。(参照: &lt;a href=&#34;https://github.com/golang/go/blob/release-branch.go1.9/src/net/http/h2_bundle.go&#34;&gt;https://github.com/golang/go/blob/release-branch.go1.9/src/net/http/h2_bundle.go&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--anonymous-auth=false&lt;/code&gt;はセキュリティのため設定。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--requestheader-*&lt;/code&gt;と&lt;code&gt;--proxy-client-*&lt;/code&gt;は上記API Aggregationのための設定。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--audit-*&lt;/code&gt;は監査ログ設定。
100MB3面のログを30日間保持する。
ログポリシーは&lt;a href=&#34;https://kubernetes.io/docs/tasks/debug-application-cluster/audit/&#34;&gt;公式のサンプル&lt;/a&gt;そのまま。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--feature-gates&lt;/code&gt;でRotateKubeletServerCertificateを有効にして、kubeletのサーバ証明書を自動更新するようにしている。
因みに、クライアント証明書を自動更新するRotateKubeletClientCertificateはデフォルトで有効。
これらがCertificate Rotationと呼ばれる機能。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--feature-gates&lt;/code&gt;は全Kubernetesコンポーネントで同じ値を指定するのがよさそう。&lt;/p&gt;

&lt;p&gt;確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# systemctl status kube-apiserver -l
# journalctl -u kube-apiserver
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kube-controller-manager&lt;/p&gt;

&lt;p&gt;systemdのユニットファイルを書いてサービス化。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# CLUSTER_CIDR=&amp;quot;10.244.0.0/16&amp;quot;
# SERVICE_CLUSTER_IP_RANGE=&amp;quot;10.0.0.0/16&amp;quot;
# CLUSTER_NAME=&amp;quot;k8s&amp;quot;
# cat &amp;gt; /etc/systemd/system/kube-controller-manager.service &amp;lt;&amp;lt; EOF
[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/kubernetes/kubernetes
After=network.target


[Service]
User=kubernetes
Group=kubernetes
ExecStart=/usr/bin/kube-controller-manager \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig \\
  --bind-address=0.0.0.0 \\
  --controllers=*,bootstrapsigner,tokencleaner \\
  --service-account-private-key-file=/etc/kubernetes/pki/kube-controller-manager.key \\
  --allocate-node-cidrs=true \\
  --cluster-cidr=${CLUSTER_CIDR} \\
  --node-cidr-mask-size=24 \\
  --cluster-name=${CLUSTER_NAME} \\
  --service-cluster-ip-range=${SERVICE_CLUSTER_IP_RANGE} \\
  --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt \\
  --cluster-signing-key-file=/etc/kubernetes/pki/ca.key \\
  --root-ca-file=/etc/kubernetes/pki/ca.crt \\
  --use-service-account-credentials=true \\
  --v=2 \\
  --experimental-cluster-signing-duration=8760h0m0s
Restart=always
RestartSec=10s


[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable kube-controller-manager
# systemctl start kube-controller-manager
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;期限の切れたBootstrap token(後述)を消すためにtokencleanerを有効にしている。&lt;/p&gt;

&lt;p&gt;bootstrapsignerは後述のcluster-infoにBootstrap tokenで署名するためのコントローラ。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/#approval-controller&#34;&gt;csrapproving&lt;/a&gt;というコントローラがデフォルトで有効になっていて、後述のTLS BootstrapppingやCertificate Rotationの時に作られるCSRを自動で承認する。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--cluster-cidr&lt;/code&gt;で指定するネットワークは、後述のネットワークプロバイダの設定と合っている必要がある。
&lt;code&gt;--allocate-node-cidrs&lt;/code&gt;は&lt;code&gt;--cluster-cidr&lt;/code&gt;の前提。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--node-cidr-mask-size&lt;/code&gt;は、ノードに使うネットワークのサイズを指定するオプションで、&lt;code&gt;--cluster-cidr&lt;/code&gt;で指定したネットワークの一部になるようにする。
&lt;code&gt;--cluster-cidr&lt;/code&gt;で&lt;code&gt;/16&lt;/code&gt;を指定した場合、半分の&lt;code&gt;/24&lt;/code&gt;にするのが普通。
つまり256ノードまで作れて、それぞれ254個のPodをホストできるような構成。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--experimental-cluster-signing-duration&lt;/code&gt;は、Certificate Rotationのための設定で、自動発行する証明書の期限を1年に指定している。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--use-service-account-credentials&lt;/code&gt;をつけると、&lt;a href=&#34;https://kubernetes.io/docs/admin/authorization/rbac/#controller-roles&#34;&gt;各コントローラが別々のService Accountで動く&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--secure-port&lt;/code&gt;や&lt;code&gt;--tls-*&lt;/code&gt;は、ヘルスチェックAPIをHTTPSにするだけで意味が無いし、設定すると&lt;code&gt;kubectl get componentstatuses&lt;/code&gt;でエラーが出るようになるので、設定しないほうがいい。&lt;/p&gt;

&lt;p&gt;確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# systemctl status kube-controller-manager -l
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kube-scheduler&lt;/p&gt;

&lt;p&gt;systemdのユニットファイルを書いてサービス化。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# cat &amp;gt; /etc/systemd/system/kube-scheduler.service &amp;lt;&amp;lt; EOF
[Unit]
Description=Kubernetes Scheduler
Documentation=https://github.com/kubernetes/kubernetes
After=network.target


[Service]
User=kubernetes
Group=kubernetes
ExecStart=/usr/bin/kube-scheduler \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --kubeconfig=/etc/kubernetes/kube-scheduler.kubeconfig \\
  --address=0.0.0.0 \\
  --v=2
Restart=always
RestartSec=10s


[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable kube-scheduler
# systemctl start kube-scheduler
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# systemctl status kube-scheduler -l
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;マスタコンポーネント状態確認&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl version
# kubectl get componentstatuses
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/&#34;&gt;TLS Bootstrapping&lt;/a&gt;の設定&lt;/p&gt;

&lt;p&gt;TLS Bootstrappingは、Kubernetesクラスタのコンポーネント間の通信がTLSで暗号化されている環境で、ノードが新たにクラスタに参加するとき、自動的にセキュアに&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E8%A8%BC%E6%98%8E%E6%9B%B8%E7%BD%B2%E5%90%8D%E8%A6%81%E6%B1%82&#34;&gt;CSR&lt;/a&gt;を処理する仕組み。&lt;/p&gt;

&lt;p&gt;TLS Bootstrappingでは、kubeletは起動時にBootstrap kubeconfigを読んで、kubeletとノード用のCSRを生成し、それらがkube-controller-managerに承認されると、kubelet用のクライアント証明書と秘密鍵を生成する。
その証明書と鍵を使ってkubeconfigを生成し、以降のクラスタへの接続に使う。&lt;/p&gt;

&lt;p&gt;Bootstrap時の認証には&lt;a href=&#34;https://kubernetes.io/docs/admin/bootstrap-tokens/&#34;&gt;Bootstrap Tokens&lt;/a&gt;か&lt;a href=&#34;https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/#token-authentication-file&#34;&gt;Token authentication file&lt;/a&gt;を使うことが推奨されていて、今回は前者を使う。&lt;/p&gt;

&lt;p&gt;(後者については&lt;a href=&#34;https://medium.com/@toddrosner/kubernetes-tls-bootstrapping-cf203776abc7&#34;&gt;この記事&lt;/a&gt;に詳しい。)&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Bootstrap TokenのSecret生成&lt;/p&gt;

&lt;p&gt;以下のように生成できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# TOKEN_PUB=$(openssl rand -hex 3)
# TOKEN_SECRET=$(openssl rand -hex 8)
# BOOTSTRAP_TOKEN=&amp;quot;${TOKEN_PUB}.${TOKEN_SECRET}&amp;quot;
# kubectl -n kube-system create secret generic bootstrap-token-${TOKEN_PUB} --type &#39;bootstrap.kubernetes.io/token&#39; --from-literal description=&amp;quot;cluster bootstrap token&amp;quot; --from-literal token-id=${TOKEN_PUB} --from-literal token-secret=${TOKEN_SECRET} --from-literal usage-bootstrap-authentication=true --from-literal usage-bootstrap-signing=true --from-literal auth-extra-groups=system:bootstrappers:worker,system:bootstrappers:ingress
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;けど、&lt;a href=&#34;https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-token/#cmd-token-generate&#34;&gt;kubeadm&lt;/a&gt;でも生成出来てこっちのほうが楽なので、それで。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# BOOTSTRAP_TOKEN=$(kubeadm token create --kubeconfig /etc/kubernetes/admin.kubeconfig)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;BOOTSTRAP_TOKENの値はあとで使う。&lt;/p&gt;

&lt;p&gt;expirationは指定できなくて、1日で期限切れになっちゃうけど、クラスタにノードを追加するときに有効であればいいのでまあいい。&lt;/p&gt;

&lt;p&gt;確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# TOKEN_PUB=$(echo $BOOTSTRAP_TOKEN | sed -e s/\\..*//)
# kubectl -n kube-system get secret/bootstrap-token-${TOKEN_PUB} -o yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Bootstrap kubeconfig作成&lt;/p&gt;

&lt;p&gt;Bootstrap時は&lt;code&gt;kubelet-bootstrap&lt;/code&gt;というユーザでkube-apiserverに接続する。
&lt;code&gt;kubelet-bootstrap&lt;/code&gt;は&lt;code&gt;system:node-bootstrapper&lt;/code&gt;ロールを持って&lt;code&gt;system:bootstrappers&lt;/code&gt;に属しているユーザとして認証される必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# mkdir -p /etc/kubernetes/manifests
# MASTER_IP=192.168.171.200
# KUBERNETES_PUBLIC_ADDRESS=$MASTER_IP
# CLUSTER_NAME=&amp;quot;k8s&amp;quot;
# KCONFIG=&amp;quot;/etc/kubernetes/bootstrap.kubeconfig&amp;quot;
# KUSER=&amp;quot;kubelet-bootstrap&amp;quot;
# kubectl config set-cluster ${CLUSTER_NAME} --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 --kubeconfig=${KCONFIG}
# kubectl config set-context ${KUSER}@${CLUSTER_NAME} --cluster=${CLUSTER_NAME} --user=${KUSER} --kubeconfig=${KCONFIG}
# kubectl config use-context ${KUSER}@${CLUSTER_NAME} --kubeconfig=${KCONFIG}
# chown kubernetes:kubernetes ${KCONFIG}
# chmod 0600 ${KCONFIG}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl config view --kubeconfig=${KCONFIG}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;CA証明書とbootstrap kubeconfigをConfigMap(cluster-info)で公開&lt;/p&gt;

&lt;p&gt;kubeletはこのConfigMapを見てクラスタに参加する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl -n kube-public create configmap cluster-info --from-file /etc/kubernetes/pki/ca.crt --from-file /etc/kubernetes/bootstrap.kubeconfig
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;anonymousユーザにcluster-infoへのアクセスを許可する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl -n kube-public create role system:bootstrap-signer-clusterinfo --verb get --resource configmaps
# kubectl -n kube-public create rolebinding kubeadm:bootstrap-signer-clusterinfo --role system:bootstrap-signer-clusterinfo --user system:anonymous
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;system:bootstrappersグループにsystem:node-bootstrapperロールを紐づける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl create clusterrolebinding kubeadm:kubelet-bootstrap --clusterrole system:node-bootstrapper --group system:bootstrappers
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;bootstrap.kubeconfigにトークンを追記&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl config set-credentials kubelet-bootstrap --token=${BOOTSTRAP_TOKEN} --kubeconfig=/etc/kubernetes/bootstrap.kubeconfig
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Docker、CNI、kubeletインストール&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Docker&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/install/linux/docker-ce/centos/#set-up-the-repository&#34;&gt;https://docs.docker.com/install/linux/docker-ce/centos/#set-up-the-repository&lt;/a&gt;
に従ってDocker CEをインストール。
ストレージドライバにはoverlay2をつかうので、device-mapper-persistent-dataとlvm2は入れない。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# yum install -y yum-utils
# yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
# yum install -y docker-ce
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;18.03.0-ceが入った。&lt;/p&gt;

&lt;p&gt;が、よくみたらDocker CEはOracle Linuxをサポートしていないので、Docker CEはアンインストールして、代わりに&lt;a href=&#34;https://docs.oracle.com/cd/E77565_01/E87205/html/section_install_upgrade_yum_docker.html&#34;&gt;Oracle Container Runtime for Docker&lt;/a&gt; (aka docker-engine)を入れる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/etc/yum.repos.d/public-yum-ol7.repo&lt;/code&gt;の&lt;code&gt;ol7_addons&lt;/code&gt;の&lt;code&gt;enabled&lt;/code&gt;を1にして、以下のコマンドでdocker-engineをインストール。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# yum install -y docker-engine
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;docker-engine 17.06.2が入った。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/etc/sysconfig/docker&lt;/code&gt;に以下を追記して、 Dockerがオープンできる最大ファイル数を増やす。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DOCKER_NOFILE=1000000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kubernetes環境ではiptablesはkube-proxyが操作するので、Dockerには操作させないようにするため、&lt;code&gt;/etc/sysconfig/docker&lt;/code&gt;の&lt;code&gt;OPTIONS&lt;/code&gt;に&lt;code&gt;--iptables=false&lt;/code&gt;を追加。
(これをすると、&lt;code&gt;--icc=false&lt;/code&gt;は設定できなくなる(不要になる)。)&lt;/p&gt;

&lt;p&gt;また、Podの&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/security-context/&#34;&gt;allowPrivilegeEscalation&lt;/a&gt;をfalseにできない&lt;a href=&#34;https://github.com/coreos/bugs/issues/1796&#34;&gt;問題&lt;/a&gt;に対処するため、&lt;code&gt;/etc/sysconfig/docker&lt;/code&gt;の&lt;code&gt;OPTIONS&lt;/code&gt;から&lt;code&gt;--selinux-enabled&lt;/code&gt;を消す。&lt;/p&gt;

&lt;p&gt;で、起動。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# systemctl daemon-reload
# systemctl enable docker
# systemctl start docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# cat /proc/$(pidof dockerd)/environ
# systemctl status docker -l
# docker version
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;CNI&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# mkdir -p /etc/cni/net.d /opt/cni/bin/
# cd /tmp
# curl -OL https://github.com/containernetworking/cni/releases/download/v0.6.0/cni-amd64-v0.6.0.tgz
# curl -OL https://github.com/containernetworking/plugins/releases/download/v0.7.1/cni-plugins-amd64-v0.7.1.tgz
# cd /opt/cni/bin
# tar zxf /tmp/cni-amd64-v0.6.0.tgz
# tar zxf /tmp/cni-plugins-amd64-v0.7.1.tgz
# chmod +x /opt/cni/bin/*
# cat &amp;gt;/etc/cni/net.d/99-loopback.conf &amp;lt;&amp;lt;EOF
{
  &amp;quot;type&amp;quot;: &amp;quot;loopback&amp;quot;
}
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kubelet&lt;/p&gt;

&lt;p&gt;前提コマンド(conntrack)インストール。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# yum -y install conntrack-tools
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;systemdのユニットファイルを書いてサービス化。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# DNS_SERVER_IP=10.0.0.10
# PAUSE_IMAGE=k8s.gcr.io/pause-amd64:3.1
# DNS_DOMAIN=&amp;quot;cluster.local&amp;quot;
# cat &amp;gt; /etc/systemd/system/kubelet.service &amp;lt;&amp;lt; EOF
[Unit]
Description=Kubernetes Kubelet
Documentation=https://github.com/kubernetes/kubernetes
After=docker.service
Requires=docker.service


[Service]
User=root
Group=root
ExecStart=/usr/bin/kubelet \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --address=0.0.0.0 \\
  --bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \\
  --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \\
  --pod-manifest-path=/etc/kubernetes/manifests \\
  --network-plugin=cni \\
  --cni-conf-dir=/etc/cni/net.d \\
  --cni-bin-dir=/opt/cni/bin \\
  --cluster-dns=${DNS_SERVER_IP} \\
  --cluster-domain=${DNS_DOMAIN} \\
  --authorization-mode=Webhook \\
  --client-ca-file=/etc/kubernetes/pki/ca.crt \\
  --cert-dir=/etc/kubernetes/pki \\
  --rotate-certificates=true \\
  --v=2 \\
  --cgroup-driver=cgroupfs \\
  --pod-infra-container-image=${PAUSE_IMAGE} \\
  --tls-min-version=VersionTLS12 \\
  --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 \\
  --allow-privileged=true \\
  --anonymous-auth=false
Restart=always
RestartSec=10s


[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable kubelet
# systemctl start kubelet
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(実際は、systemctl start kubeletするまえに、後述のNode CSR自動承認設定をすべし。)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--allow-privileged&lt;/code&gt;はflannelなどに必要。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--pod-infra-container-image&lt;/code&gt;では&lt;a href=&#34;https://github.com/kubernetes/kubernetes/tree/master/build/pause&#34;&gt;pause&lt;/a&gt;コンテナイメージを指定する。
このコンテナはPod毎に起動され、Podネットワークの名前空間を保持するために使われるらしい。
今回使った&lt;code&gt;k8s.gcr.io/pause-amd64:3.1&lt;/code&gt;はKubernetesチームが配布しているものだけど、Oracleが配布しているものもあり、そちらを使うには、Oracle Linux 7.4のダウンロード媒体リストに含まれるOracle Container Services for use with Kubernetes 1.1.9.1に入っているpause-amd64.tarを&lt;code&gt;docker load&lt;/code&gt;しておいて、そのイメージ名を&lt;code&gt;--pod-infra-container-image&lt;/code&gt;に渡せばいい。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--bootstrap-kubeconfig&lt;/code&gt;で指定したkubeconfigでTLS Bootstrapして、&lt;code&gt;--cert-dir&lt;/code&gt;で指定したディレクトリに証明書と鍵を生成して、&lt;code&gt;--kubeconfig&lt;/code&gt;で指定したパスに以降使うkubeconfigを生成する。
この証明書を自動更新(i.e. Certificate Rotation)するオプションが&lt;code&gt;--rotate-certificates&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--pod-manifest-path&lt;/code&gt;で指定したディレクトリはkubeletに定期的にスキャンされ、そこに置いたKubernetesマニフェスト(ドットで始まるもの以外)が読まれる。
(参照: &lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/static-pod/&#34;&gt;Static Pods&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--pod-cidr&lt;/code&gt;は指定しない。
これはkube-controller-managerに渡した&lt;code&gt;--cluster-cidr&lt;/code&gt;と&lt;code&gt;--node-cidr-mask-size&lt;/code&gt;から計算されるので。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--anonymous-auth=false&lt;/code&gt;は&lt;a href=&#34;https://kubernetes.io/docs/admin/kubelet-authentication-authorization/&#34;&gt;セキュリティのために推奨されたオプション&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--authorization-mode=Webhook&lt;/code&gt;も&lt;a href=&#34;https://kubernetes.io/docs/admin/kubelet-authentication-authorization/&#34;&gt;セキュリティのために推奨されたオプション&lt;/a&gt;で、認可処理をkube-apiserverに移譲する設定。&lt;/p&gt;

&lt;p&gt;本当は&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/&#34;&gt;Kubelet Configファイル&lt;/a&gt;を使ったほうがいいみたいなので、いずれそれに対応する。
(対応した: 「&lt;a href=&#34;https://www.kaitoy.xyz/2018/05/05/kubernetes-kubelet-config-and-pod-sec-policy/&#34;&gt;Kubernetes 1.10のkubeletの起動オプションをKubelet ConfigファイルとPodSecurityPolicyで置き換える&lt;/a&gt;」)&lt;/p&gt;

&lt;p&gt;起動確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# systemctl status kubelet -l
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Node CSR手動承認&lt;/p&gt;

&lt;p&gt;TLS Bootstrappingで生成されたCSRを手動で承認する。&lt;/p&gt;

&lt;p&gt;CSRは以下のコマンドで見れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl get csr
NAME                                                   AGE       REQUESTOR                 CONDITION
csr-cf9hm                                              24m       system:node:k8s-master  Pending
node-csr-Vcw_4HioW1CI96eDH29RMKPrOchEN133053wm6DCXUk   24m       system:bootstrap:itacbw   Pending
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;node-csr-…&lt;/code&gt;がクライアント証明書のためのCSRで、&lt;code&gt;csr-…&lt;/code&gt;がサーバ証明書の。
これらを承認する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl certificate approve node-csr-Vcw_4HioW1CI96eDH29RMKPrOchEN133053wm6DCXUk
# kubectl certificate approve csr-cf9hm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(因みに否認するときは&lt;code&gt;kubectl certificate deny&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;これでクラスタにノードが追加されたはず。
確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl get node
NAME         STATUS    ROLES     AGE       VERSION
k8s-master   Ready     &amp;lt;none&amp;gt;    36s       v1.10.0
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Node CSR自動承認設定&lt;/p&gt;

&lt;p&gt;前節でやった手動承認はcsrapprovingが自動でやってくれる。&lt;/p&gt;

&lt;p&gt;新規ノード参加時のCSRを承認するClusterRoleとして&lt;code&gt;system:certificates.k8s.io:certificatesigningrequests:nodeclient&lt;/code&gt;が自動生成されているので、これを&lt;code&gt;system:bootstrappers&lt;/code&gt;グループにバインドしてやると、自動承認が有効になる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;s&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# cat &amp;lt;&amp;lt;EOF | kubectl create -f -
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: auto-approve-csrs-for-group
subjects:
- kind: Group
  name: system:bootstrappers
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: system:certificates.k8s.io:certificatesigningrequests:nodeclient
  apiGroup: rbac.authorization.k8s.io
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、kubeletのクライアント証明書を自動更新(i.e. RotateKubeletClientCertificate)するときのCSRを承認するClusterRoleとして&lt;code&gt;system:certificates.k8s.io:certificatesigningrequests:selfnodeclient&lt;/code&gt;が自動生成されていて、これをノード毎のユーザにバインドしてやると、自動承認が有効になる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# HOSTNAME=k8s-master
# cat &amp;lt;&amp;lt;EOF | kubectl create -f -
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: ${HOSTNAME}-node-client-cert-renewal
subjects:
- kind: User
  name: system:node:${HOSTNAME}
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient
  apiGroup: rbac.authorization.k8s.io
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;kubeletのサーバ証明書を自動更新(i.e. RotateKubeletServerCertificate)するときのCSRを承認するClusterRoleは現時点で自動生成されないので、自分で作ってノード毎のユーザにバインドして、自動承認を有効にする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# cat &amp;lt;&amp;lt;EOF | kubectl create -f -
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: approve-node-server-renewal-csr
rules:
- apiGroups: [&amp;quot;certificates.k8s.io&amp;quot;]
  resources: [&amp;quot;certificatesigningrequests/selfnodeserver&amp;quot;]
  verbs: [&amp;quot;create&amp;quot;]
EOF
# HOSTNAME=k8s-master
# cat &amp;lt;&amp;lt;EOF | kubectl create -f -
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: ${HOSTNAME}-server-client-cert-renewal
subjects:
- kind: User
  name: system:node:${HOSTNAME}
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: approve-node-server-renewal-csr
  apiGroup: rbac.authorization.k8s.io
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kube-proxy、オーバレイネットワーク、DNSのデプロイ&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;kube-proxy&lt;/p&gt;

&lt;p&gt;kube-proxyのkubeconfigを作成。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# MASTER_IP=192.168.171.200
# KUBERNETES_PUBLIC_ADDRESS=$MASTER_IP
# CLUSTER_NAME=&amp;quot;k8s&amp;quot;
# KCONFIG=&amp;quot;/etc/kubernetes/kube-proxy.kubeconfig&amp;quot;
# KUSER=&amp;quot;system:kube-proxy&amp;quot;
# kubectl config set-cluster ${CLUSTER_NAME} --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 --kubeconfig=${KCONFIG}
# kubectl config set-credentials ${KUSER} --client-certificate=/etc/kubernetes/pki/kube-proxy.crt --client-key=/etc/kubernetes/pki/kube-proxy.key --embed-certs=true --kubeconfig=${KCONFIG}
# kubectl config set-context ${KUSER}@${CLUSTER_NAME} --cluster=${CLUSTER_NAME} --user=${KUSER} --kubeconfig=${KCONFIG}
# kubectl config use-context ${KUSER}@${CLUSTER_NAME} --kubeconfig=${KCONFIG}
# chown kubernetes:kubernetes ${KCONFIG}
# chmod 0600 ${KCONFIG}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl config view --kubeconfig=${KCONFIG}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Service Accountのkube-proxyに&lt;code&gt;system:node-proxier&lt;/code&gt;というClusterRoleを付ける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl create clusterrolebinding kubeadm:node-proxier --clusterrole system:node-proxier --serviceaccount kube-system:kube-proxy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;systemdのユニットファイルを書いてサービス化。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# CLUSTER_CIDR=&amp;quot;10.244.0.0/16&amp;quot;
# cat &amp;gt; /etc/systemd/system/kube-proxy.service &amp;lt;&amp;lt; EOF
[Unit]
Description=Kubernetes Kube Proxy
Documentation=https://github.com/kubernetes/kubernetes
After=network.target


[Service]
User=root
Group=root
ExecStart=/usr/bin/kube-proxy \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --bind-address 0.0.0.0 \\
  --cluster-cidr=${CLUSTER_CIDR} \\
  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig \\
  --v=2
Restart=always
RestartSec=10s


[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable kube-proxy
# systemctl start kube-proxy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# systemctl status kube-proxy -l
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ネットワークプロバイダ (flannel)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/coreos/flannel/blob/master/Documentation/kubernetes.md&#34;&gt;flannelのドキュメント&lt;/a&gt;を参考に。&lt;/p&gt;

&lt;p&gt;flannelをデプロイするには、kube-apiserverとkube-controller-managerの起動オプションに&lt;code&gt;--allow-privileged&lt;/code&gt;を付ける必要がある。&lt;/p&gt;

&lt;p&gt;また、公式が配布しているKubernetesマニフェストを使う場合、kube-controller-managerの起動オプションの&lt;code&gt;--cluster-cidr&lt;/code&gt;で&lt;code&gt;10.244.0.0/16&lt;/code&gt;を指定する必要がある。&lt;/p&gt;

&lt;p&gt;デプロイ自体は以下のコマンドを実行するだけ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このKubernetesマニフェストでは、quay.ioから&lt;code&gt;quay.io/coreos/flannel:v0.10.0-amd64&lt;/code&gt;というコンテナイメージがpullされる。&lt;/p&gt;

&lt;p&gt;Oracleもflannelのコンテナイメージを配布していて、そちらを使うには、Oracle Linux 7.4のダウンロード媒体リストに含まれるOracle Container Services for use with Kubernetes 1.1.9.1に入っているflannel.tarを&lt;code&gt;docker load&lt;/code&gt;しておいて、そのイメージを使うようにマニフェストを書きかえればいい。&lt;/p&gt;

&lt;p&gt;起動確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl -n kube-system get po
NAME                    READY     STATUS    RESTARTS   AGE
kube-flannel-ds-gkcqd   1/1       Running   0          1m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;flannelは&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/network-policies/&#34;&gt;Network Policy&lt;/a&gt;をサポートしていないので、&lt;a href=&#34;https://www.projectcalico.org/&#34;&gt;Calico&lt;/a&gt;か&lt;a href=&#34;https://www.weave.works/oss/net/&#34;&gt;Weave Net&lt;/a&gt;あたりにすればよかったかも。
(やった: 「&lt;a href=&#34;https://www.kaitoy.xyz/2018/05/04/kubernetes-with-weave-net/&#34;&gt;Kubernetes 1.10のクラスタにWeave Netをデプロイする&lt;/a&gt;」)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;CoreDNS&lt;/p&gt;

&lt;p&gt;Kubernetes 1.10からは、サービスディスカバリに(kube-dnsの代わりに)CoreDNSを使うのが標準になった。&lt;/p&gt;

&lt;p&gt;以下を参考にCoreDNSをデプロイする:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/coredns/&#34;&gt;https://kubernetes.io/docs/tasks/administer-cluster/coredns/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://coredns.io/2018/01/29/deploying-kubernetes-with-coredns-using-kubeadm/&#34;&gt;https://coredns.io/2018/01/29/deploying-kubernetes-with-coredns-using-kubeadm/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/coredns/deployment/tree/master/kubernetes&#34;&gt;https://github.com/coredns/deployment/tree/master/kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# cd /tmp
# curl -LO https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/coredns.yaml.sed
# curl -LO https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/deploy.sh
# chmod +x deploy.sh
# DNS_SERVER_IP=&amp;quot;10.0.0.10&amp;quot;
# SERVICE_CLUSTER_IP_RANGE=&amp;quot;10.0.0.0/16&amp;quot;
# DNS_DOMAIN=&amp;quot;cluster.local&amp;quot;
# ./deploy.sh -r $SERVICE_CLUSTER_IP_RANGE -i $DNS_SERVER_IP -d $DNS_DOMAIN &amp;gt; coredns.yaml
# kubectl apply -f coredns.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このKubernetesマニフェストではDocker Hubから&lt;code&gt;coredns/coredns:1.1.1&lt;/code&gt;というイメージがpullされる。&lt;/p&gt;

&lt;p&gt;起動確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl -n kube-system get pods -o wide | grep coredns
coredns-8459d9f654-b585f   1/1       Running   0          48s       10.244.0.3        k8s-master
coredns-8459d9f654-x7drc   1/1       Running   0          48s       10.244.0.2        k8s-master
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;起動確認時にCoreDNSのIPアドレスを確認して、動作確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# dig @10.244.0.3 kubernetes.default.svc.cluster.local +noall +answer


; &amp;lt;&amp;lt;&amp;gt;&amp;gt; DiG 9.9.4-RedHat-9.9.4-61.el7 &amp;lt;&amp;lt;&amp;gt;&amp;gt; @10.244.0.3 kubernetes.default.svc.cluster.local +noall +answer
; (1 server found)
;; global options: +cmd
kubernetes.default.svc.cluster.local. 5 IN A    10.0.0.1
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kubernetesアプリデプロイ&lt;/p&gt;

&lt;p&gt;前節まででKubernetesクラスタの構築は完了。
試しにKubernetesアプリをひとつデプロイしてみる。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/weaveworks/scope&#34;&gt;Weave Scope&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.weave.works/docs/scope/latest/installing/#k8s&#34;&gt;ドキュメント&lt;/a&gt;を参考に。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# cd /tmp
# curl -sSL -o scope.yaml https://cloud.weave.works/k8s/scope.yaml?k8s-service-type=NodePort
# kubectl apply -f scope.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このKubernetesマニフェストではDocker Hubから&lt;code&gt;weaveworks/scope:1.8.0&lt;/code&gt;というイメージがpullされる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl -n weave get svc/weave-scope-app&lt;/code&gt;でポート調べて、&lt;code&gt;http://k8s-master:&amp;lt;ポート&amp;gt;/&lt;/code&gt;をブラウザ開くとWeave ScopeのGUIが見れる。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Skaffoldを触ってみた</title>
          <link>https://www.kaitoy.xyz/2018/04/01/hello-skaffold/</link>
          <pubDate>Sun, 01 Apr 2018 09:59:43 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/04/01/hello-skaffold/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/skaffold#run-a-deployment-pipeline-once&#34;&gt;Skaffold&lt;/a&gt;を試してみた話。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;skaffoldとは&#34;&gt;Skaffoldとは&lt;/h2&gt;

&lt;p&gt;Googleが開発している、Kubernetesアプリケーションを快適に開発するためのツール。
アプリケーションのソースを監視し、変更が入ると、自動的にコンテナイメージをビルドしてKubernetesクラスタにデプロイしてくれる。&lt;/p&gt;

&lt;p&gt;2018/3/16に&lt;a href=&#34;https://cloudplatform.googleblog.com/2018/03/introducing-Skaffold-Easy-and-repeatable-Kubernetes-development.html&#34;&gt;発表&lt;/a&gt;された新しいツールで、触った感じではまだこれからといった感じだった。&lt;/p&gt;

&lt;p&gt;Goで書かれていて、Linux、OS X、Windows用のバイナリが提供されている。&lt;/p&gt;

&lt;p&gt;似たツールにはMicrosoftの&lt;a href=&#34;https://draft.sh/&#34;&gt;Draft&lt;/a&gt;がある。&lt;/p&gt;

&lt;p&gt;また、Gitのコミットを自動デプロイしてくれるものに、&lt;a href=&#34;https://gitkube.sh/&#34;&gt;Gitkube&lt;/a&gt;、&lt;a href=&#34;http://jenkins-x.io/&#34;&gt;Jenkins X (エックス)&lt;/a&gt;がある。&lt;/p&gt;

&lt;h2 id=&#34;windows版を試す&#34;&gt;Windows版を試す&lt;/h2&gt;

&lt;p&gt;自PCがWindowsなのでWindows版を試す。
会社で使ってるのもWindowsだし。&lt;/p&gt;

&lt;p&gt;Skaffoldを使うには、Skaffoldの実行バイナリ、Kubernetesクラスタ、そのクラスタをコンテクストに設定したkubectl、Dockerが必要。&lt;/p&gt;

&lt;p&gt;まずWindows版Skaffoldをインストールする。
&lt;a href=&#34;https://github.com/GoogleCloudPlatform/skaffold/releases&#34;&gt;GitHubのリリースページ&lt;/a&gt;からWindowsバイナリをダウンロードして、skaffold.exeにリネームしてPATHの通ったところに置くだけ。
Skaffoldのバージョンは0.3.0。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Kubernetesクラスタは、Windows 10 Home上にminikube 0.22.2で作ったKubernetes 1.7.0のクラスタ。
minikubeは&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/&#34;&gt;以前&lt;/a&gt;インストールしたものを使う。&lt;/p&gt;

&lt;p&gt;minikubeを起動。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;&amp;gt; minikube start --kubernetes-version v1.7.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;kubectlもminikubeと一緒にインストール済み。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Dockerについては、デーモンはminikube上のを使えばいいとして、クライアント(Docker Client)はskaffoldコマンドから実行するのでWindows上にないとだめはなず。&lt;/p&gt;

&lt;p&gt;WindowsでDockerと言えば今なら&lt;a href=&#34;https://www.docker.com/docker-windows&#34;&gt;Docker for Windows&lt;/a&gt;だけど、これはWindows 10 Proじゃないと使えなかったはずなので、&lt;a href=&#34;https://docs.docker.com/toolbox/&#34;&gt;Docker Toolbox&lt;/a&gt;でクライアントをいれた。&lt;/p&gt;

&lt;p&gt;このクライアントはデフォルトではローカルのデーモンを見てるので、minikubeのデーモンを見させる。
そのための設定はminikubeのコマンドで分かるようになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;&amp;gt; minikube docker-env
SET DOCKER_TLS_VERIFY=1
SET DOCKER_HOST=tcp://192.168.99.100:2376
SET DOCKER_CERT_PATH=C:\Users\kaitoy\.minikube\certs
SET DOCKER_API_VERSION=1.23
REM Run this command to configure your shell:
REM @FOR /f &amp;quot;tokens=*&amp;quot; %i IN (&#39;minikube docker-env&#39;) DO @%i
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これに従って以下のコマンドを実行するとクライアントの設定完了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;&amp;gt; @FOR /f &amp;quot;tokens=*&amp;quot; %i IN (&#39;minikube docker-env&#39;) DO @%i
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで準備完了。&lt;/p&gt;

&lt;p&gt;Skaffoldの&lt;a href=&#34;https://github.com/GoogleCloudPlatform/skaffold/tree/10d56cf0fd3c253b0716a084419b5833e53d9870#getting-started-with-local-tooling&#34;&gt;Getting Started&lt;/a&gt;をやってみる。&lt;/p&gt;

&lt;p&gt;Skaffoldのリポジトリをcloneして、コマンドプロンプト開いて、&lt;code&gt;examples/getting-started&lt;/code&gt;にcdして、以下のコマンドを実行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;&amp;gt; skaffold dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;エラーで終わった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[31mERRO[0m[0047] run: running skaffold steps: starting watch on file C:\Users\kaitoy\Desktop\skaffold\examples\getting-started\Dockerfile: adding watch for C:\Users\kaitoy\Desktop\skaffold\examples\getting-started\Dockerfile: The parameter is incorrect.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;MinGW(Git Bash)でやっても同じ結果。
&lt;a href=&#34;https://github.com/GoogleCloudPlatform/skaffold/issues/287&#34;&gt;Issuesに登録されているやつ&lt;/a&gt;と同じ問題っぽい。&lt;/p&gt;

&lt;p&gt;対応を待つしかない。&lt;/p&gt;

&lt;h2 id=&#34;linux版を試す&#34;&gt;Linux版を試す&lt;/h2&gt;

&lt;p&gt;Linux版も試してみる。
minikubeのVMがLinux(Boot2Docker)なので、そこで動かす。
&lt;a href=&#34;https://ja.wikipedia.org/wiki/Windows_Subsystem_for_Linux&#34;&gt;WSL&lt;/a&gt;は試さない。
会社のPCがWindows 7で使えないので。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;SkaffoldのLinux版バイナリをダウンロードしてskaffoldにリネームして、minikubeのBoot2DockerにSSHでログインして、PATHの通ったところに置く。
因みにminikubeのBoot2Dockerは、ユーザdockerパスワードtcuserでログインできる。&lt;/p&gt;

&lt;p&gt;kubectlのLinux版バイナリもダウンロードしてPATHに入れたら準備完了。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;examples/getting-started&lt;/code&gt;にcdして&lt;code&gt;skaffold dev&lt;/code&gt;したらエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ERRO[0001] run: getting skaffold config: getting k8s client: Error creating kubeConfig: invalid configuration: no configuration has been provided
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちょっと調べたら、kubectlのコンテクストが設定されていないのがだめっぽい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl config current-context
error: current-context is not set
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Windows上のkubectlに設定されたコンテクストを参考に、以下の内容を&lt;code&gt;~/.kube/config&lt;/code&gt;に。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
clusters:
- cluster:
    certificate-authority: /c/Users/kaitoy/.minikube/ca.crt
    server: https://localhost:8443
  name: minikube
contexts:
- context:
    cluster: minikube
    user: minikube
  name: minikube
current-context: minikube
kind: Config
preferences: {}
users:
- name: minikube
  user:
    client-certificate: /c/Users/kaitoy/.minikube/client.crt
    client-key: /c/Users/kaitoy/.minikube/client.key
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;再度&lt;code&gt;skaffold dev&lt;/code&gt;したら違うエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;WARN[0002] run: build: build step: running build: read auth configs: docker config: opening docker config: open /home/docker/.docker/config.json: no such file or directory
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;.docker/config.json&lt;/code&gt;は&lt;code&gt;docker login&lt;/code&gt;すると生成されるものらしい。
SkaffoldのREADME.mdにはminikube使うならDocker image registry要らないって書いてあるんだけど…&lt;/p&gt;

&lt;p&gt;色々あって、ファイルがあればいいだけっぽいので、以下で良し。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# echo {} &amp;gt; ~/.docker/config.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;再度&lt;code&gt;skaffold dev&lt;/code&gt;したら動いた。
Dockerビルドが走り、minikubeにPodがデプロイされた。&lt;/p&gt;

&lt;p&gt;Getting Startedのサンプルは、一秒ごとに「[getting-started] Hello world!」というメッセージをコンソールに表示する。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;examples/getting-started/main.go&lt;/code&gt;の&lt;code&gt;fmt.Println(&amp;quot;Hello world!&amp;quot;)&lt;/code&gt;のとこをいじってメッセージを変えたら、自動で再Dockerビルドしてデプロイされて、新しいメッセージを表示し始めた。
便利。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;examples/getting-started/skaffold.yaml&lt;/code&gt;がSkaffoldの設定ファイルで、ここに定義されたKubernetesマニフェストをデプロイしてくれるっぽい。
watchするファイルはどう決めているんだろうか。
Dockerfileとmain.goはwatchしてるけど、新しいファイルを作ってもDockerビルド走らなかった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ひとつ問題は、Linuxファイルシステム上で編集しないと変更を検知してくれない。&lt;/p&gt;

&lt;p&gt;minikubeのVMには&lt;code&gt;C:\Users&lt;/code&gt;がマウントされてるので、最初はWindows上にcloneしたサンプルをSkaffoldで実行しつつ、Windows上でmain.goを編集してみたんだけど、それだとダメだった。&lt;/p&gt;

&lt;p&gt;やはりWindows版Skaffoldの修正が待たれる。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>機械学習のHello World: MNISTの分類モデルをKerasで作ってみた</title>
          <link>https://www.kaitoy.xyz/2018/03/25/hello-world-to-ml-with-keras/</link>
          <pubDate>Sun, 25 Mar 2018 22:43:27 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/03/25/hello-world-to-ml-with-keras/</guid>
          <description>

&lt;p&gt;機械学習のHello Worldとしてよくやられる&lt;a href=&#34;http://yann.lecun.com/exdb/mnist/&#34;&gt;MNIST&lt;/a&gt;の分類モデルを&lt;a href=&#34;https://keras.io/ja/&#34;&gt;Keras&lt;/a&gt; on &lt;a href=&#34;https://www.tensorflow.org/&#34;&gt;TensorFlow&lt;/a&gt;で作ってみた話。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;mnistとは&#34;&gt;MNISTとは&lt;/h2&gt;

&lt;p&gt;手書き数字画像のラベル付きデータセット。
6万個の訓練データと1万個のテストデータからなる。
&lt;a href=&#34;https://creativecommons.org/licenses/by-sa/3.0/&#34;&gt;CC BY-SA 3.0&lt;/a&gt;で&lt;a href=&#34;http://www.pymvpa.org/datadb/mnist.html&#34;&gt;配布されているっぽい&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;一つの画像は28×28ピクセルの白黒画像で、0から9のアラビア数字が書かれている。&lt;/p&gt;

&lt;p&gt;画像とラベルがそれぞれ独特な形式でアーカイブされていて、画像一つ、ラベル一つ取り出すのも一苦労する。&lt;/p&gt;

&lt;h2 id=&#34;kerasとは&#34;&gt;Kerasとは&lt;/h2&gt;

&lt;p&gt;Pythonのニューラルネットワークライブラリ。
バックエンドとしてTensorFlowかCNTKかTheanoを使う。
今回はTensorFlowを使った。&lt;/p&gt;

&lt;h2 id=&#34;やったこと&#34;&gt;やったこと&lt;/h2&gt;

&lt;p&gt;KerasのMNISTの&lt;a href=&#34;https://keras.io/ja/datasets/#mnist&#34;&gt;API&lt;/a&gt;とか&lt;a href=&#34;https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py&#34;&gt;コードサンプル&lt;/a&gt;とかがあけどこれらはスルー。&lt;/p&gt;

&lt;p&gt;MNISTのサイトにあるデータセットをダウンロードしてきて、サイトに書いてあるデータ形式の説明を見ながらサンプルを取り出すコードを書いた。
で、KerasでVGGっぽいCNNを書いて、学習させてモデルをダンプして、ダンプしたモデルをロードしてテストデータで評価するコードを書いた。
コードは&lt;a href=&#34;https://github.com/kaitoy/ml-mnist&#34;&gt;GitHub&lt;/a&gt;に。&lt;/p&gt;

&lt;h2 id=&#34;ネットワークアーキテクチャ&#34;&gt;ネットワークアーキテクチャ&lt;/h2&gt;

&lt;p&gt;入力画像のサイズに合わせてVGGを小さくした感じのCNNを作った。&lt;/p&gt;

&lt;p&gt;VGGは2014年に発表されたアーキテクチャで、各層に同じフィルタを使い、フィルタ数を線形増加させるシンプルな構造でありながら、性能がよく、今でもよく使われるっぽい。&lt;/p&gt;

&lt;p&gt;VGGを図にすると以下の構造。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/hello-world-to-ml-with-keras/vgg16.png&#34; alt=&#34;vgg16.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;実際はバッチ正規化とかDropoutもやるのかも。
プーリング層は数えないで16層なので、VGG-16とも呼ばれる。
パラメータ数は1億3800万個くらいで、結構深めなアーキテクチャ。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;VGG-16は244×244×3の画像を入力して1000クラスに分類するのに対し、MNISTは28×28×1を入れて10クラスに分類するので、以下のような7層版を作った。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/hello-world-to-ml-with-keras/vgg7.png&#34; alt=&#34;vgg7.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;これでパラメータ数は27万個くらい。
訓練データのサンプル数が6万個なので、パラメータ数が大分多い感じではある。&lt;/p&gt;

&lt;p&gt;コードは以下。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;inputs: Tensor = Input(shape=(IMAGE_NUM_ROWS, IMAGE_NUM_COLS, 1))

x: Tensor = Conv2D(filters=8, kernel_size=(2, 2), padding=&#39;same&#39;, activation=&#39;relu&#39;)(inputs)
x = Conv2D(filters=8, kernel_size=(2, 2), padding=&#39;same&#39;, activation=&#39;relu&#39;)(x)
x = MaxPooling2D(pool_size=(2, 2))(x)

x = Conv2D(filters=16, kernel_size=(2, 2), padding=&#39;same&#39;, activation=&#39;relu&#39;)(x)
x = Conv2D(filters=16, kernel_size=(2, 2), padding=&#39;same&#39;, activation=&#39;relu&#39;)(x)
x = Conv2D(filters=16, kernel_size=(2, 2), padding=&#39;same&#39;, activation=&#39;relu&#39;)(x)
x = MaxPooling2D(pool_size=(2, 2))(x)

x = Flatten()(x)
x = Dense(units=256, activation=&#39;relu&#39;)(x)
x = Dense(units=256, activation=&#39;relu&#39;)(x)
predictions: Tensor = Dense(NUM_CLASSES, activation=&#39;softmax&#39;)(x)

model: Model = Model(inputs=inputs, outputs=predictions)
model.compile(optimizer=&#39;adam&#39;, loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;訓練-評価&#34;&gt;訓練・評価&lt;/h2&gt;

&lt;p&gt;上記モデルを6万個のサンプルでバッチサイズ512で一周(1エポック)学習させると、Intel Core i5-6300HQプロセッサー、メモリ16GBのノートPCで28秒前後かかる。&lt;/p&gt;

&lt;p&gt;とりあえず3エポック学習させてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;(ml-mnist) C:\workspace\ml-mnist&amp;gt;python bin\ml_mnist.py train
Using TensorFlow backend.
Epoch 1/3
60000/60000 [==============================] - 28s 465us/step - loss: 0.7813 - acc: 0.7702
Epoch 2/3
60000/60000 [==============================] - 27s 453us/step - loss: 0.1607 - acc: 0.9496
Epoch 3/3
60000/60000 [==============================] - 27s 448us/step - loss: 0.1041 - acc: 0.9681
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ロスが0.1041で正答率が96.81%という結果になった。&lt;/p&gt;

&lt;p&gt;このモデルをテストデータで評価する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;(ml-mnist) C:\workspace\ml-mnist&amp;gt;python bin\ml_mnist.py eval
Using TensorFlow backend.
10000/10000 [==============================] - 2s 165us/step
loss: 0.08780829641819, acc: 0.9717000002861023
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正答率97.17%。
そんなに良くないけど、過学習はしていない模様。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次に10エポック学習させて評価してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;(ml-mnist) C:\workspace\ml-mnist&amp;gt;python bin\ml_mnist.py train
Using TensorFlow backend.
Epoch 1/10
60000/60000 [==============================] - 29s 486us/step - loss: 0.5814 - acc: 0.8297
Epoch 2/10
60000/60000 [==============================] - 28s 470us/step - loss: 0.1130 - acc: 0.9651
Epoch 3/10
60000/60000 [==============================] - 28s 469us/step - loss: 0.0711 - acc: 0.9777
Epoch 4/10
60000/60000 [==============================] - 28s 468us/step - loss: 0.0561 - acc: 0.9821
Epoch 5/10
60000/60000 [==============================] - 28s 469us/step - loss: 0.0476 - acc: 0.9852
Epoch 6/10
60000/60000 [==============================] - 28s 473us/step - loss: 0.0399 - acc: 0.9879
Epoch 7/10
60000/60000 [==============================] - 28s 467us/step - loss: 0.0338 - acc: 0.9892
Epoch 8/10
60000/60000 [==============================] - 28s 467us/step - loss: 0.0283 - acc: 0.9909
Epoch 9/10
60000/60000 [==============================] - 29s 490us/step - loss: 0.0230 - acc: 0.9925
Epoch 10/10
60000/60000 [==============================] - 28s 471us/step - loss: 0.0223 - acc: 0.9928

(ml-mnist) C:\workspace\ml-mnist&amp;gt;python bin\ml_mnist.py eval
Using TensorFlow backend.
10000/10000 [==============================] - 2s 171us/step
loss: 0.040611953073740006, acc: 0.9866999998092651
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;テストデータでの正答率98.67%。
ちょっと改善した。&lt;/p&gt;

&lt;h2 id=&#34;モデル改善&#34;&gt;モデル改善&lt;/h2&gt;

&lt;p&gt;試しにバッチ正規化層を入れてみる。
ReLUの前に入れるべきという情報があったけど、それだとちょっと修正が面倒なので、単にプーリング層の後に入れてみた。&lt;/p&gt;

&lt;p&gt;3エポックで学習・評価。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;(ml-mnist) C:\workspace\ml-mnist&amp;gt;python bin\ml_mnist.py train
Using TensorFlow backend.
Epoch 1/3
60000/60000 [==============================] - 45s 746us/step - loss: 0.2157 - acc: 0.9336
Epoch 2/3
60000/60000 [==============================] - 44s 737us/step - loss: 0.0513 - acc: 0.9838
Epoch 3/3
60000/60000 [==============================] - 47s 777us/step - loss: 0.0340 - acc: 0.9896

(ml-mnist) C:\workspace\ml-mnist&amp;gt;python bin\ml_mnist.py eval
Using TensorFlow backend.
10000/10000 [==============================] - 2s 246us/step
loss: 0.051704482543468475, acc: 0.9844999995231628
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;98.45%。
1エポックの学習時間は45秒前後に伸びたけど、速く学習できるようにはなった。&lt;/p&gt;

&lt;p&gt;10エポックではどうか。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;(ml-mnist) C:\workspace\ml-mnist&amp;gt;python bin\ml_mnist.py train
Using TensorFlow backend.
Epoch 1/10
60000/60000 [==============================] - 47s 776us/step - loss: 0.2318 - acc: 0.9265
Epoch 2/10
60000/60000 [==============================] - 47s 790us/step - loss: 0.0596 - acc: 0.9811
Epoch 3/10
60000/60000 [==============================] - 47s 778us/step - loss: 0.0370 - acc: 0.9884
Epoch 4/10
60000/60000 [==============================] - 48s 801us/step - loss: 0.0259 - acc: 0.9917
Epoch 5/10
60000/60000 [==============================] - 47s 785us/step - loss: 0.0182 - acc: 0.9942
Epoch 6/10
60000/60000 [==============================] - 48s 794us/step - loss: 0.0132 - acc: 0.9961
Epoch 7/10
60000/60000 [==============================] - 46s 765us/step - loss: 0.0108 - acc: 0.9965
Epoch 8/10
60000/60000 [==============================] - 45s 751us/step - loss: 0.0107 - acc: 0.9965
Epoch 9/10
60000/60000 [==============================] - 45s 749us/step - loss: 0.0055 - acc: 0.9984
Epoch 10/10
60000/60000 [==============================] - 45s 754us/step - loss: 0.0035 - acc: 0.9991

(ml-mnist) C:\workspace\ml-mnist&amp;gt;python bin\ml_mnist.py eval
Using TensorFlow backend.
10000/10000 [==============================] - 2s 243us/step
loss: 0.034382903814315795, acc: 0.9893999994277954
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;98.94%。
バッチ正規化無し版よりも0.27%改善してるけど、誤差の範囲かも。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;MNISTのサイトに載ってるので一番いいのが99.77%。
どうしたらそんなによくなるのか。&lt;/p&gt;

&lt;h2 id=&#34;エラー分析&#34;&gt;エラー分析&lt;/h2&gt;

&lt;p&gt;一番正答率が高かったモデルについて、エラー分析をしてみた。&lt;/p&gt;

&lt;p&gt;まず、エラーが多かった数字を調べる。
数字をエラー数順に並べると、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ラベル: エラー数
9: 18
7: 18
5: 15
4: 14
6: 14
3: 8
8: 8
2: 7
1: 2
0: 2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;9と7が一番分類むずくて、4、5、6がそれらに次いでむずいことがわかる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次にエラーのパターンを見てみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(予測した数字, ラベル): 出現数
(9, 4): 10
(3, 5): 9
(1, 7): 7
(2, 7): 6
(7, 9): 6
(9, 7): 5
(7, 2): 4
(8, 5): 4
(1, 6): 4
(1, 9): 4
(0, 6): 4
(8, 9): 3
(9, 3): 3
(4, 9): 3
(8, 3): 2
(2, 4): 2
(2, 8): 2
(1, 2): 2
(8, 4): 2
(5, 3): 2
(5, 9): 2
(8, 6): 2
(2, 6): 2
(5, 6): 1
(1, 8): 1
(6, 8): 1
(0, 8): 1
(2, 3): 1
(4, 6): 1
(2, 1): 1
(3, 8): 1
(8, 1): 1
(7, 0): 1
(4, 8): 1
(6, 0): 1
(5, 8): 1
(6, 5): 1
(9, 2): 1
(0, 5): 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4を9と、5を3と、7を1か2と、9を7と間違えたパターンが多い。
特に4と7がむずい模様。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次に、実際に間違えた画像を見てみる。
多かったパターンについて見てみる。&lt;/p&gt;

&lt;p&gt;4を9と間違えたパターン:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/hello-world-to-ml-with-keras/9-4.png&#34; alt=&#34;9-4.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;なんだこれは。
これはかなり9にも見える。
ちょっと角ばってるとこと、線が右にはみ出しているとこで判断するのか。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;5を3と間違えたパターン:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/hello-world-to-ml-with-keras/3-5.png&#34; alt=&#34;3-5.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;これはもうちょっとモデルに頑張ってほしい。
これを3としてしまうのは残念。
なにがだめだったのかは分からないけど。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;7を1と間違えたパターン:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/hello-world-to-ml-with-keras/1-7.png&#34; alt=&#34;1-7.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;これは1でもいいような…&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;7を2と間違えたパターン:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/hello-world-to-ml-with-keras/2-7.png&#34; alt=&#34;2-7.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;これはちょっと面白い。
7の真ん中に線をいれるパターンを訓練データに足せば対応できそう。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;9を7と間違えたパターン:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/hello-world-to-ml-with-keras/7-9.png&#34; alt=&#34;7-9.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;これもモデルに頑張ってほしかったパターン。
左上のごみが悪さしたんだろうか。
ごみがあるパターンを訓練データに増やすと対応できるかも。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あと、ちょっと噴いたやつ:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/hello-world-to-ml-with-keras/2-4.png&#34; alt=&#34;2-4.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;これは4。
モデルは2と間違えた。
むずい。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/hello-world-to-ml-with-keras/2-8.png&#34; alt=&#34;2-8.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;これは8。
モデルは2と間違えた。
こんなのテストデータにいれないで…&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>オープンデータメモ</title>
          <link>https://www.kaitoy.xyz/2018/03/04/open-data/</link>
          <pubDate>Sun, 04 Mar 2018 16:22:46 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/03/04/open-data/</guid>
          <description>&lt;p&gt;機械学習の勉強に使えそうなオープンデータのメモ。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;テキスト

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://wordnet.princeton.edu/&#34;&gt;WordNet&lt;/a&gt;: 英語の語彙データベース。名詞、動詞、形容詞、副詞ごとに階層的にグルーピングされたDBが提供されている。ライセンスは&lt;a href=&#34;http://wordnet.princeton.edu/wordnet/license/&#34;&gt;WordNet License&lt;/a&gt;で、著作権表示さえしておけば、目的の制限なく、使用、複製、改変、再配布を無料でできる。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://compling.hss.ntu.edu.sg/wnja/index.ja.html&#34;&gt;日本語ワードネット&lt;/a&gt;: 日本語版WordNet。ライセンスは&lt;a href=&#34;http://compling.hss.ntu.edu.sg/wnja/license.txt&#34;&gt;Japanese WordNetライセンス&lt;/a&gt;で、著作権表示さえしておけば、目的の制限なく、使用、複製、改変、再配布を無料でできる。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;画像

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://image-net.org/index&#34;&gt;ImageNet&lt;/a&gt;: WordNetの名詞の階層構造に従ってラベル付けされた1400万個以上の画像データ。バウンディングボックスも付いてる。画像はFlickrとかに上がっているもので、そこから自分で無料でダウンロードできる。非商用(研究か教育)目的ならImageNetのサイトから画像をダウンロードできる。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/openimages/dataset&#34;&gt;Open Images&lt;/a&gt;: 900万個の画像に数千クラスのラベルとバウンディングボックスを付けたデータ。ライセンスはCreative Commons BY 4.0。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://yann.lecun.com/exdb/mnist/&#34;&gt;MNIST&lt;/a&gt;: 手書き数字のラベル付きデータセット。訓練データとテストデータ合わせて7万個。機械学習のHello Worldに使われる。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;動画

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://research.google.com/youtube8m/&#34;&gt;YouTube-8M&lt;/a&gt;: 800万個のYouTube動画を4800クラスでラベル付けしたデータ。ライセンスはCreative Commons BY 4.0。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://research.google.com/youtube-bb/&#34;&gt;YouTube-Bounding Boxes&lt;/a&gt;: 24万個のYouTube動画に23クラスのラベルと560万個のバウンディングボックスを付けたデータ。ライセンスはCreative Commons BY 4.0。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://research.google.com/ava/&#34;&gt;Atomic Visual Actions(AVA)&lt;/a&gt;: 5.76万個のYouTube動画を、80種の動作についてラベル付けしたデータ。ライセンスはCreative Commons BY 4.0。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;音声

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz&#34;&gt;Speech Commands Datase&lt;/a&gt;: 6.5万個の1秒音声データで、30種の言葉を数千人が発音してる。ライセンスはCreative Commons BY 4.0。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://research.google.com/audioset/&#34;&gt;AudioSet&lt;/a&gt;: 200万個の10秒音声データで、527クラスでラベル付けされてる。ライセンスはCreative Commons BY 4.0。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;データカタログサイト

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.data.go.jp/&#34;&gt;DATA GO JP&lt;/a&gt;: 日本政府が公開してる公共データ集。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://archive.ics.uci.edu/ml/index.php&#34;&gt;UCI Machine Learning Repository&lt;/a&gt;: 現時点で426のデータセットが配布されている。有名なアヤメのデータセットのソースはここ。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;単語ベクトル

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bizreach/ai/tree/master/word2vec&#34;&gt;HR領域の単語ベクトル&lt;/a&gt;: 約9.95億個の日本語のHR系の単語からWord2Vecで学習した単語ベクトル。ベクトル長は100か200。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;学習済みモデル

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://caffe.berkeleyvision.org/model_zoo.html&#34;&gt;Caffe Model Zoo&lt;/a&gt;: Caffe用のモデル集。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/Detectron/blob/master/MODEL_ZOO.md&#34;&gt;Detectron Model Zoo&lt;/a&gt;: Facebookが開発した物体検知モデルの学習済みモデル。Caffe2。ライセンスはCC BY-SA 3.0。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CourseraのDeep Learning SpecializationのSequence Modelsコースを修了した</title>
          <link>https://www.kaitoy.xyz/2018/02/27/coursera-deep-learning-sequence-models/</link>
          <pubDate>Tue, 27 Feb 2018 00:49:05 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/02/27/coursera-deep-learning-sequence-models/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/02/06/coursera-deep-learning-convolutional-neural-networks/&#34;&gt;CourseraのDeep Learning SpecializationのConvolutional Neural Networksコースを修了した&lt;/a&gt;のに続き、&lt;a href=&#34;https://www.coursera.org/learn/nlp-sequence-models&#34;&gt;Sequence Modelsコース&lt;/a&gt;を修了した。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;このコースは、RNNの原理、代表的なアーキテクチャ、自然言語処理などについて学べる3週間のコース。
生成モデルが色々出てきて面白い。
動画は今のところ全部英語。&lt;/p&gt;

&lt;p&gt;2018/2/6に始めて、2/27に完了。
22日間かかった。
修了したらまた&lt;a href=&#34;https://www.coursera.org/account/accomplishments/certificate/NCW69X7UASJ6&#34;&gt;Certifacate&lt;/a&gt;もらえた。&lt;/p&gt;

&lt;p&gt;また、これでDeep Learning Specializationのすべてのコースを修了したので、全部まとめた&lt;a href=&#34;https://www.coursera.org/account/accomplishments/specialization/certificate/4487DSN9ARXN&#34;&gt;Certifacate&lt;/a&gt;ももらえた。
結局2ヶ月ほどかかり、1万円以上課金してしまった…&lt;/p&gt;

&lt;p&gt;以下、3週分の内容をメモ程度に書いておく。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;p&gt;連続データを扱うシーケンス(Sequence)モデルについて学ぶ。
RNN、LSTM、GRU、BRNN。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;再帰型ニューラルネットワーク(Recurrent Neural Network)&lt;/p&gt;

&lt;p&gt;シーケンスモデルにはRNNなどがあって、音声認識(Speech recognition)や自然言語処理(Natural language processing)に使われる。
音楽生成(Music generation)、感情分類(Sentiment classification)、DNA解析(DNA sequence analysis)、動画行動認識(Video Activity Recognition)、固有表現抽出(Named entity recognition)なんてのも。&lt;/p&gt;

&lt;p&gt;入力だけが連続データだったり、出力だけが連続データだったり、両方だったり。&lt;/p&gt;

&lt;p&gt;自然言語処理では、ボキャブラリ(Vocabulary)を使って単語をone hotベクトルにして扱う。
ボキャブラリは普通5万次元くらいのベクトル。
ボキャブラリにない単語はそれ用(unknown)の次元に割り当てる。&lt;/p&gt;

&lt;p&gt;入力や出力の次元がサンプルごとに違うので、普通のNNは使えない。
また、普通のNNだと、文のある個所から学んだ特徴を他の箇所と共有しない。
また、普通のNNだと、入力サイズが大きすぎて、パラメータが多くなりすぎる。
RNNはこうした問題を持たない。&lt;/p&gt;

&lt;p&gt;RNNは、最初の単語xを受け取り、層で計算し、最初の出力yとアクティベーションaを出し、そのaと次のxを同じ層で受け取り、次のyとaをだす、ということを繰り返す。
xにかける重みをWax、aにかける重みをWaa、yにかける重みをWyaと呼ぶ。
あとaとyを計算するときに足すバイアスがあって、それぞれba、by。
あるxの計算をするときに、その前のxも使うので、連続データ処理に向いてる。
けど、後のxを考慮しないところが欠点。
この欠点に対処したのがBRNN(Bidirectional RNN)。&lt;/p&gt;

&lt;p&gt;RNNのaの活性化関数にはtanhがよく使われる。
ReLUもあり。
yには二値分類だったらシグモイドだし、そうでなければソフトマックスとか。&lt;/p&gt;

&lt;p&gt;損失関数は普通に交差エントロピーでいいけど、yがベクトルなので、その各要素について交差エントロピーを計算して、足し合わせたものが損失になる。
ここから逆伝播するんだけど、その際に連続データを過去にさかのぼるので、時をかける逆伝播(BPTT: Backpropagation through time)と呼ばれる。&lt;/p&gt;

&lt;p&gt;上で説明したRNNは、入力と出力が同じ長さだけど、そうでない問題のほうが多い。
感情分類なんかは、任意の長さの文を入力して、5段階評価とかするので、最後のxまで入力した後で一つだけyを出すようにする。
音楽生成なんかは入力が一つで出力が多いので、入力がない部分は前の出力を代わりに入力する。
翻訳みたいに入力と出力の長さが違うときは、前半入力だけして、後半出力だけする。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;言語モデル(Language model)&lt;/p&gt;

&lt;p&gt;ある文のあとに、どんな分が続くかを確率で示してくれるモデル。&lt;/p&gt;

&lt;p&gt;訓練データは、文をトークンに分解してone-hotベクトルにして、最後にEOSトークンを加えて作る。&lt;/p&gt;

&lt;p&gt;モデルは、RNNの出力をボキャブラリと同じサイズのソフトマックスにして、どの単語の確率が高いかを出力させる。
最初に0ベクトルを入力し、その出力を次の入力にして、それを繰り返す。&lt;/p&gt;

&lt;p&gt;単語じゃなくて文字単位でやるモデルもあるけど、あんまり使われない。&lt;/p&gt;

&lt;p&gt;このモデルを使うと、学習した文章に似た雰囲気の分を生成できる。
このとき、出力したベクトルから、各単語の確率にしたがって単語をサンプリングし、それを次の入力にする。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;RNNの勾配消失&lt;/p&gt;

&lt;p&gt;英語の文だと、主語が単数だと動詞の形が変わるんだけど、主語と動詞がすごい離れていることがありうる。
最初のほうの単語である主語は浅い層(初期のステップ)で処理されて、一方動詞は深い層(あとのほうのステップ)で処理されることになる。
すると、勾配消失により、深い層の単語が浅い層から受ける影響が小さくなってしまって、動詞の形をいい感じに学習できない。
これがナイーブなRNNの欠点。&lt;/p&gt;

&lt;p&gt;勾配爆発も起こり得るけど、Gradient clipping、つまり勾配の値を計算した後に値が閾値を超えていたら修正する手法を使えば比較的簡単に回避できるので、勾配消失が深刻。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;GRU(Gated Recurrent Unit)&lt;/p&gt;

&lt;p&gt;RNNにMemory cell&amp;copy;というアイデアを加えたもの。
cは浅い層の情報を深い層に伝える役目をして、勾配消失問題を緩和する。
cの候補は毎回、前回のcとxの線形変換をtanhに入れたものとして生成され、それを、0か1を返すゲートΓu(シグモイドな感じの関数)で実際にcとして使うかを決めて、cを更新していく。
このゲートを更新ゲート(Update gate)という。
cはソフトマックスに入れてyを出力したり、次のステップのaにする。&lt;/p&gt;

&lt;p&gt;実際には、もう一つ関連ゲート(Relevance gate)Γrってのがあって、cの候補を計算するときに前回のcに掛ける。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;LSTM(Long short term memory)&lt;/p&gt;

&lt;p&gt;RNNの勾配消失に対処するまた別のアイデア。
GRUよりパワフル。
けどGRUより古くからあるもので、GRUがそれのシンプル版という関係。&lt;/p&gt;

&lt;p&gt;LSTMの論文はかなりむずい。&lt;/p&gt;

&lt;p&gt;GRUと比べると、まずΓrはない。&lt;/p&gt;

&lt;p&gt;で、GRUはΓuが1だったらcを更新して、0だったら前のを保持するという感じだったけど、LSTMでは忘却ゲート(Forget gate)Γfに前回のcをかけて、捨てるかどうかを決める。&lt;/p&gt;

&lt;p&gt;また、出力ゲート(Output gate)Γoが追加されて、単にcを次のaにするんじゃなくて、&lt;code&gt;Γo*c&lt;/code&gt;をaにする。&lt;/p&gt;

&lt;p&gt;各ゲートは前のaと今回のxの線型結合にバイアスを加えたものをシグモイドして計算する。
ゲートの計算にcもいれることがあって、のぞき穴接続 (Peephole connection)と呼ばれる。&lt;/p&gt;

&lt;p&gt;基本的にはLSTM使えばいいけど、GRUのほうが計算コストが少なくて大きなネットワーク作りやすいから、GRUのほうがいいこともある。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;BRNN(Bidirectional RNN)&lt;/p&gt;

&lt;p&gt;普通にRNNやった後、後ろの入力から順番に逆向きにRNNする。
yは、順向きのaと逆向きのaとバイアスを線形計算して非線形変換したものになる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Deep RNN&lt;/p&gt;

&lt;p&gt;単にyを出力するんじゃなくて、そのyを入力とする別のRNNを積み上げていくとdeepになる。
RNNは時間軸の方向にすでに深いので、出力方向には普通は2、3個だけ積み上げる。&lt;/p&gt;

&lt;p&gt;出力方向にRNNを積み上げる代わりに、出力を普通のNNにいれるってのもある。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;p&gt;3つもある…&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ベーシックRNNとLSTMの順伝播をNumPyで実装&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;恐竜の名前を生成する言語モデルをNumPyで実装&lt;/p&gt;

&lt;p&gt;Gradient clippingとサンプリングを実装して、モデルを訓練しながら、恐竜の名前をいい感じに生成できるようになっていく様を観察する。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;LSTMの音楽生成モデルをKerasで実装&lt;/p&gt;

&lt;p&gt;Jazzの曲の断片を学習させて、それっぽい曲を生成してみる。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;p&gt;自然言語処理。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;単語埋め込み(Word embedding)&lt;/p&gt;

&lt;p&gt;1週目でやったように、単語をone-hotベクトルで表すと、単語同士の積が0になって、単語間の関係(距離)が表せられない。
代わりに、単語を特徴のベクトルにして、各次元に特徴量をもたせる、特徴付き表現(Featurized representation)がある。&lt;/p&gt;

&lt;p&gt;単語の特徴は数百とかにするけど、可視化するために2Dにすることがある。
このための代表的なアルゴリズムがt-SNE。
t-SNEは複雑で非線形な処理をするので、後述の類推には使えないけど、似たような単語のクラスタを観察できる。&lt;/p&gt;

&lt;p&gt;特徴の分布を表すN次元の空間に単語を埋め込むため、単語埋め込みという。
このN次元ベクトルを単語の数だけ結合したものをEで表す。&lt;/p&gt;

&lt;p&gt;この表現形式にすると、大量の適当なテキストデータで学習させたり、学習済みのモデルをダウンロードしたりしたあと、特定のタスクのために転移学習させることができる。&lt;/p&gt;

&lt;p&gt;また、類推(Analogical reasoning)が可能になる。
単語のペアが二つあって、ペア内の単語ベクトル間の差を計算して、ペア間でその値が近ければ、それらのペアは同じような関係の組み合わせだと言える。
例えば、&lt;code&gt;男 - 女&lt;/code&gt;は&lt;code&gt;王 - 女王&lt;/code&gt;に近くなる。
類似度の計算にはコサイン類似度(Cosine similarity)がよく使われる。
ユークリッド距離(Euclidean distance)でもいいけど、コサイン類似度のほうが一般的。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;単語埋め込みの学習&lt;/p&gt;

&lt;p&gt;Eにone-hotベクトルをかけると、そのone-hotベクトルが表す単語の特徴ベクトルが得られる。&lt;/p&gt;

&lt;p&gt;数単語の後に続く単語を予測するニューラル言語モデルを考えると、与えられたそれぞれの単語を表すone-hotベクトルを入力して、Eをかける層があって、その結果を全結合層にいれて、その結果をボキャブラリサイズのベクトルを出力するソフトマックス層にいれる。
ソフトマックス層の出力で、一番大きい値の単語が予測する単語になる。
Eをパラメータにしておくと、このモデルを訓練するとEが学習される。
予測精度自体はそんなによくならなくても問題ない。&lt;/p&gt;

&lt;p&gt;予測する単語の前だけじゃなくて、前後の単語を使って学習させたりも。
1単語だけで予測しても結構いい結果になる。&lt;/p&gt;

&lt;p&gt;上記のモデルはSkip-Gramモデルと呼ばれる。
実際には、文の中からターゲット単語を選び、前後ウィンドウサイズ(5とか)以内のコンテクスト単語を一つ選び、それらをペアにして一つの訓練データを作る。
コンテクスト単語は完全にランダムに選ぶと、aとかtheとかofとかが多くなっちゃうので、ヒューリスティックにバランスよく選ぶ必要がある。&lt;/p&gt;

&lt;p&gt;ソフトマックス層は、ボキャブラリサイズのベクトルを出力するため、計算コストがでかい。
その対策として、階層的ソフトマックス(Hierarchical softmax)ってのがあって、これは木構造で分類を表す手法。
もう一つ負例サンプリング(Negative sampling)という手法があって、こっちのほうがシンプルで効果的。&lt;/p&gt;

&lt;p&gt;Skip-Gramモデルのほか、CBOW(Continuous Bag Of Words)というモデルもある。
これはターゲット単語とその前後数単語を訓練データにするもの。
これらのモデルをWord2Vecモデルといったり、それを使ってEを学習する手法をWord2Vecアルゴリズムといったりする。&lt;/p&gt;

&lt;p&gt;負例サンプリングではまず、コンテクスト単語に対して別の単語を与え、ターゲット単語なら1、違うなら0というラベル付き訓練データを作る。
ターゲット単語とコンテクスト単語の組はSkip-Gramと同様に選んで、0になる単語はランダムに選ぶ。
コンテクスト単語一つに対し、yが1になるデータを一つ、0になるデータをk個(2～20くらい)作る。
kはデータセットが大きいほど少なくする。
で、Skip-Gramモデルのソフトマックス層を、ボキャブラリの数だけの二値分類ノードに変える。
これらのノードは毎回全部計算するんじゃなくて、k+1個だけを計算するので計算コストが小さい。&lt;/p&gt;

&lt;p&gt;単語埋め込みの学習アルゴリズムとして、Word2Vecじゃないものだと、GloVe(Global Vectors)アルゴリズムってのがある。
GloVeでは、単語iと単語jが近くに現れることが何回あるかをxijで表す。
xijをボキャブラリのすべての単語の組み合わせで数えて、それらと何かの二乗誤差にヒューリスティックな重み付けをしたコスト関数を作って最適化して単語埋め込みを学習させる。
細かいことはよくわからなかった…&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;感情分類&lt;/p&gt;

&lt;p&gt;Yelpみたいなサービスで、コメントから星の数を推定する。&lt;/p&gt;

&lt;p&gt;感情分類は、教師データがあまり得られないことが多いのが課題だけど、よく訓練したEがあれば上手く分類できる。&lt;/p&gt;

&lt;p&gt;コメントを単語に分解したら、それぞれのone-hotベクトルをEとかけて単語ベクトルを作って、単語間の平均を計算して、ソフトマックス層に入れて、出力を星の数だけ作る。
というのがシンプルなモデル。
これだと語順を考慮しないので、RNNに単語ごとに入力して、最後の出力をソフトマックスするといい感じになる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;単語埋め込みからのバイアス除去(Debias)&lt;/p&gt;

&lt;p&gt;単語埋め込みに性別とか人種のバイアスがかかってると、いいモデルができない。
例えば、&lt;code&gt;プログラマ - 男 + 女 = 主婦&lt;/code&gt;みたいになってるとまずい。
こういうバイアスは、学習データのテキストのバイアス、つまりそれを書いた人のバイアスからくる。&lt;/p&gt;

&lt;p&gt;単語空間のバイアスの方向を調べるには、例えば性別のバイアスなら、&lt;code&gt;he - she&lt;/code&gt;とか&lt;code&gt;male - female&lt;/code&gt;とかの平均をとる。
するとある1次元のベクトルが得られて、これがバイアスの方向になる。
この上にある値を他の次元の射影に変換することでバイアスを削減(Neutralize)できる。&lt;/p&gt;

&lt;p&gt;実際には、特異値分解(SVD: Singular Value Decomposition)でもっとシステマチックにバイアスを計算する。
バイアスも数次元のベクトルになりうる。&lt;/p&gt;

&lt;p&gt;Neutralizeしたらさらに、バイアスをなくす方向に単語の組の位置をずらす(Equalize pairs)。
例えば、男と女の組を、ベビーシッターからの距離に差がなくなるようにずらす。&lt;/p&gt;

&lt;p&gt;Neutralizeすべき単語は、線形分類で決めることができる(?)。
Equalizeすべき単語は手で選ぶ。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;訓練済みのGloVeの単語埋め込みをロードして、コサイン類似度計算を実装して、類推を実行。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;NeutralizationとEqualizationを実装。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;感情分類(文に自動で絵文字を付ける)の、シンプルな実装と2層LSTMでの実装。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;3週目&lt;/p&gt;

&lt;p&gt;連続データを入力して連続データを出力するRNNアーキテクチャを学ぶ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Sequence to sequence(Seq2Seq)モデル&lt;/p&gt;

&lt;p&gt;翻訳などに使うモデル。
エンコーダ(encoder)ネットワークで元の単語を読み込み、デコーダ(decoder)ネットワークが翻訳を吐き出す。&lt;/p&gt;

&lt;p&gt;画像を読んでその説明文(caption)を吐くのにもつかわれる。
この場合、CNNで画像を読んで、最後の全結合層の出力をRNNに入れる。&lt;/p&gt;

&lt;p&gt;小説を生成するような言語モデルと異なるのは、ランダムに生成してほしいのではなくて、ベストな結果を生成してほしいところ。
デコーダネットワークの部分は言語モデルと一緒。
入力がエンコーダネットワークの出力か0ベクトルかの違いだけ。
このようなのを条件付き言語モデル(Conditional language model)と呼ぶ。&lt;/p&gt;

&lt;p&gt;言語モデルだと、次に出力する単語をランダムで選んでたけど、翻訳ではそうはいかない。
貪欲法(Greedy algorithm)みたいに、毎回一番確率が高いものを選んでもうまくいかない。
最終的に出力する全単語の確率の掛け合わせが最大になるやつを選びたい。&lt;/p&gt;

&lt;p&gt;ビームサーチ(Beam search)を代わりに使う。
ビーム幅(Beamwidth)Bを決めて、最初にBの数だけ単語の候補を確率の高い順に選ぶ。
で、それらを次の入力にしてB個の出力ベクトルを得たら、最初の単語の確立をそれらのベクトルの各要素にかけて、大きい順にまたB個単語を選ぶ。
あとはこれの繰り返し。&lt;/p&gt;

&lt;p&gt;ビームサーチをもう少し改良できる。
その一つが長さ正規化(Length normalization)。
条件付確率を計算するときに、単語が増えてくると1未満の数を何回もかけることになり、アンダーフローや丸め誤差が発生してしまう。
ので、各単語の確率をかけ合わせる代わりに、各確率のlogを足し合わせる。
これだとまだ、確率が1未満なのでlogは常に負の値になり、単語の数が少ない程総和は大きくなるので、翻訳結果に短い文が選ばれがちになっちゃう。
ので単語数で割る。
または単語数をα(0～1)乗したもので割る。
この式(目的関数)をNormalized log probability objectiveとかNormalized log likelihood objectiveとか呼ぶ。&lt;/p&gt;

&lt;p&gt;Bはどう選ぶか。
Bが小さいと計算コストが低く、最適解を見つける可能性が低い。
Bが大きいとその逆。
プロダクション環境では、10～100くらいが一般的。
研究では数千とかも。
試行錯誤していい値を見つけるしかない。&lt;/p&gt;

&lt;p&gt;深さ優先探索(DFS: Depth First Search)、幅優先探索(BFS: Breadth First Search)に比べて、ビームサーチは最適解を見つけられないかもしれないけど、リーズナブル。&lt;/p&gt;

&lt;p&gt;ビームサーチはヒューリスティックなアルゴリズムなので、いつもいい結果を出すとは限らない。
だめだったときはエラー分析をする。
ダメな翻訳が出力されたとき、RNNの訓練が足らないのか、ビームサーチのBが小さすぎるのかを切り分けたい。&lt;/p&gt;

&lt;p&gt;まずは、翻訳中のある単語について、期待する出力とモデルの出力の確率をそれぞれ見てみる。
前者が大きければ、モデルは正しい出力してるけど、ビームサーチが間違ったものを選択している。
逆ならモデルに問題がある。
(長さ正規化してたらその目的関数を比べる。)
これを色んなサンプルで試して、より多くのサンプルでダメだったほうの改善に努めるべし。&lt;/p&gt;

&lt;p&gt;いい感じの訳が複数あったらどうする?
Bleu(BiLingual Evaluation Understudy)スコアで評価する。
Bleuスコアは、生成した訳が期待する訳(リファレンス)のいずれかに近ければ高くなる。&lt;/p&gt;

&lt;p&gt;precisionは、生成した訳の単語のいくつが、リファレンスにも出現するかを示す。
これだと、例えば&lt;code&gt;the the the is the the&lt;/code&gt;みたいな訳で高い値(&lt;code&gt;6/6&lt;/code&gt;)をとれちゃう。
のでmodified precisionを代わりに使う。
modified precisionでは、それぞれの単語について、一つのリファレンスに最大何回出現するかをcreditと定義する。
で、&lt;code&gt;the&lt;/code&gt;のcreditが2、&lt;code&gt;is&lt;/code&gt;のcreditが1なら、上記訳のmodified precisionは&lt;code&gt;3/6&lt;/code&gt;になる。&lt;/p&gt;

&lt;p&gt;Bleuスコアは、Nグラム(N-Gram)についてmodified precisionを計算する。
あるN-Gramについてのmodified precisionをPn、N-Gramの数をNとすると、Bleuスコアは&lt;code&gt;exp((ΣPn)/N) * BP&lt;/code&gt;。
BPはbrevity penaltyで、短い訳で高いスコアを簡単に取れないようにするためのもの。
出力長がリファレンス長より長ければ1で、そうでなければ&lt;code&gt;exp(1 - 出力長 / リファレンス長)&lt;/code&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Attentionモデル&lt;/p&gt;

&lt;p&gt;Seq2Seqを改良したもの。&lt;/p&gt;

&lt;p&gt;長い文の場合でも、Seq2Seqは原文を全部読んで、それをactivationに記憶して、そこから翻訳を出力する。
けど人が翻訳するときは、短い文や節に区切って出力していく。
実際、長い原文を記憶するのは難しく、原文の単語数が増えていくにしたがってSeq2Seqは性能が落ちる。
Attentionモデルは人と同様な翻訳の仕方をするので、原文の単語数が増えても性能を保てる。&lt;/p&gt;

&lt;p&gt;Attentionモデルでは、エンコーダはBRNN。
で、エンコーダはデコーダに対し、t番目の出力に際してどの入力単語に注目すべきかという重みづけαから生成するコンテクストcを入力する。
エンコーダの順方向と逆方向のアクティベーションを結合したものをaとすると、&lt;code&gt;c = Σαa&lt;/code&gt;。
デコーダはそのcと、1ステップ前のアクティベーションsを使って一単語を出力する。
1ステップ前のsとaを小さいシンプルなNNにいれて入力単語ごとに計算したeを、入力単語に渡って足すと1になるようにスケールしたものがα。&lt;/p&gt;

&lt;p&gt;Attentionモデルは、画像を読んで説明文を出力するときにも使われる。
説明文は画像の特定の箇所に注目した説明の集まりなので。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;音声認識(Speech recognition)&lt;/p&gt;

&lt;p&gt;Seq2Seqモデルで、音声データを読んで字幕を出力する。
従来、音声を音素(Phoneme)に分解して処理していたが、深層学習ではその必要が無い。
但し300～100000時間くらいの音声データが要る。&lt;/p&gt;

&lt;p&gt;普通に音声データをエンコーダに時系列に従って入力してデコーダに文字を出力させてもいいけど、それだと、入力データのステップ数は出力ステップ数よりはるかに大きくなっちゃう。
ので、CTC(Connectionist temporal classification)モデルは、RNNに入力と同じだけ出力をさせて、その出力を圧縮して最終的な字幕を生成する。
例えば&lt;code&gt;the&lt;/code&gt;について、&lt;code&gt;ttt_h_eee___&lt;/code&gt;みたいな出力をさせる。
&lt;code&gt;_&lt;/code&gt;はブランクという特殊な出力で、単語の切れ目のスペースとはまた別のもの。&lt;/p&gt;

&lt;p&gt;「OK Google」みたいなトリガーワードを識別するシステムに使うアルゴリズムはまだ発展途上で、これといったものはない。
例えば、トリガーワードを含む音声を入力して、トリガーワードの終わりの部分の出力を1、それ以外を0として学習させる方法がある。
終わりの瞬間だけ1にすると0ばっかりになっちゃうので、終わりから一定時間1にする。
トリガーワードを聞いた瞬間に検知するようにしたいので、BRNNじゃなくて単方向のRNNを使う。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Kerasで日付を特定のフォーマットに変換するAttentionモデルを作る。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;トリガーワード検知システムを作る。&lt;/p&gt;

&lt;p&gt;トリガーワードとそれ以外の言葉とノイズを別々に録音して、合成してラベルを付けて訓練データを作る。
で、Kerasで1D畳み込み層がひとつ、GRUが2層のDeep RNNモデルを作って学習させる。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CourseraのDeep Learning SpecializationのConvolutional Neural Networksコースを修了した</title>
          <link>https://www.kaitoy.xyz/2018/02/06/coursera-deep-learning-convolutional-neural-networks/</link>
          <pubDate>Tue, 06 Feb 2018 00:37:11 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/02/06/coursera-deep-learning-convolutional-neural-networks/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/01/16/coursera-deep-learning-ml-strategy/&#34;&gt;CourseraのDeep Learning SpecializationのStructuring Machine Learning Projectsコースを修了した&lt;/a&gt;のに続き、&lt;a href=&#34;https://www.coursera.org/learn/convolutional-neural-networks&#34;&gt;Convolutional Neural Networksコース&lt;/a&gt;を修了した。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;このコースは、CNNの原理、代表的なアーキテクチャ、応用などについて学べる4週間のコース。
動画は今のところ全部英語。
プログラミング課題は初のKeras。&lt;/p&gt;

&lt;p&gt;このコースは結構難しくて、特に3週目と4週目は理解に苦しんだ。
というか理解しきれなかったような。
けどNST面白かった。&lt;/p&gt;

&lt;p&gt;2018/1/16に始めて、2/6に完了。
22日間かかった。
修了したらまた&lt;a href=&#34;https://www.coursera.org/account/accomplishments/certificate/MVNK5ZA5CDKA&#34;&gt;Certifacate&lt;/a&gt;もらえた。&lt;/p&gt;

&lt;p&gt;以下、4週分の内容をメモ程度に書いておく。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;p&gt;畳み込みニューラルネットワーク(CNN: Convolutional neural network)の基本。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;畳み込み計算&lt;/p&gt;

&lt;p&gt;画像認識でよく使われるNNのアーキテクチャ。&lt;/p&gt;

&lt;p&gt;低層ではエッジを検出し、層が進むにつれて複雑な特徴を学習する。&lt;/p&gt;

&lt;p&gt;画像を特定の行列(普通は奇数の正方行列。3×3が多い。)で畳み込むことで、特定の方向のエッジを検出できる。
この行列をフィルタ(filter)という。カーネルと呼ばれることもある。
例えば縦なら以下。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[[1, 0, -1],
 [1, 0, -1],
 [1, 0, -1]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;縦でもいろいろフィルタはあって、以下はSobelフィルタというもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[[1, 0, -1],
 [2, 0, -2],
 [1, 0, -1]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下はScharrフィルタ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[[ 3, 0,  -3],
 [10, 0, -10],
 [ 3, 0,  -3]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;縦のフィルタを90度回転すると横のフィルタになる。&lt;/p&gt;

&lt;p&gt;深層学習では、フィルタもパラメータとして学習させる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;パディング(Padding)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;n×n&lt;/code&gt;の行列を&lt;code&gt;f×f&lt;/code&gt;のフィルタで畳み込むと&lt;code&gt;n-f+1×n-f+1&lt;/code&gt;の行列になる。
つまり畳み込めば畳み込むほど画像が小さくなってしまう。
また、画像の端のほうはフィルタにかかる割合が小さいので、情報量が小さくなってしまう。
これらを解決するテクニックがパディング(Padding)。
行列の周囲を0でパディングして、サイズを大きくしてから畳み込む。
パディングがないのをValidな畳み込み、出力が入力と同じサイズになるようにパディングするのをSameな畳み込みという。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Strided畳み込み&lt;/p&gt;

&lt;p&gt;畳み込むときにフィルタをずらす幅を1より大きくする。
パディングサイズがpでストライドがsのとき、&lt;code&gt;n×n&lt;/code&gt;の行列を&lt;code&gt;f×f&lt;/code&gt;のフィルタで畳み込むと&lt;code&gt;(n+2p-f)/s+1×(n+2p-f)/s+1&lt;/code&gt;の行列になる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;3次元(カラー画像)の畳み込み&lt;/p&gt;

&lt;p&gt;カラー画像は3次元の行列、つまり&lt;code&gt;n×n×c&lt;/code&gt;の行列で、それを畳み込むのは&lt;code&gt;f×f×c&lt;/code&gt;のフィルタで、出力は&lt;code&gt;n-f+1×n-f+1&lt;/code&gt;の行列になる。
チャネルごとにフィルタを設定して、色ごとにエッジ検出できる。
フィルタごとの出力は全部スタックして、最終的な出力は3次元になる。&lt;/p&gt;

&lt;p&gt;畳み込み層はフィルタの要素数がパラメータ数になる。
入力画像の大きさに依存しないので、パラメータ数が少なくて済み、過学習しにくい。&lt;/p&gt;

&lt;p&gt;入力を複数の畳み込み層に通したら、最終的に3次元の出力をなべてベクトルにして、後ろの層に渡す。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プーリング層(Pooling layer)&lt;/p&gt;

&lt;p&gt;計算量を減らすため、また特徴の抽出のために、畳み込み層のあとに使われる層。
基本Max poolingが使われるけど、Average poolingというのもある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Max pooling: フィルタをかけた部分を畳み込む代わりに、最大値を出力とする。大きな値が特徴が大きく出ているところだから、特徴を凝縮するイメージだけど、経験的にこれで上手くいくことが分かっているだけで、なぜ上手くいくかは判明していない。この層はパラメータを持たない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Average pooling: フィルタをかけた部分を畳み込む代わりに、平均を出力とする。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;プーリング層のフィルタは大抵、サイズが&lt;code&gt;2×2&lt;/code&gt;でパディングが0でストライドは2。&lt;/p&gt;

&lt;p&gt;普通、畳み込み層とプーリング層とセットで1層と数える。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;全結合層(Fully connected layer)&lt;/p&gt;

&lt;p&gt;全ノードがメッシュ状につながった普通の層。
畳み込み層とプーリング層のセットがいくつかあって、その出力をベクトルになべて、全結合層につなぐ。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;一般的なCNN&lt;/p&gt;

&lt;p&gt;畳み込み層は、普通nhとnwを縮め、ncを増やす。
また、全体として、層が浅くなるほど出力が減るのが多い。&lt;/p&gt;

&lt;p&gt;CNNはハイパーパラメータが多すぎるので、アーキテクチャは自分で考えるんではなく、論文呼んで自分の問題に合いそうなのを探すべし。&lt;/p&gt;

&lt;p&gt;畳み込み層は全結合層に比べてパラメータ数がかなり少なくて済むのがいいところ。
これはパラメーター共有(Parameter sharing)という、画像のある個所で上手く動いたフィルタ(e.g. 縦エッジ検出器)は、その画像の他の箇所でも上手く働くという考え方がベース。&lt;/p&gt;

&lt;p&gt;また、層間の接続がまばらなのもパラメータを減らす要因。
つまり出力のあるピクセルは、入力のうちフィルタ分のサイズのピクセルとしか関連していない。&lt;/p&gt;

&lt;p&gt;CNNは空間変化の不変性(Translation invariance)に強い。
つまり画像の中の物体の位置が変わってもよく検出できる。
これは同じフィルタを画像全体に適用するから。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;p&gt;CNNの順伝播をNumPyで実装。&lt;/p&gt;

&lt;p&gt;CNNによる画像の分類をTensorFlowで実装。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ケーススタディ&lt;/p&gt;

&lt;p&gt;畳み込み層とかプーリング層をどう組み合わせるといいかは、事例を見ていくことで雰囲気をつかめる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;古いやつ&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;LeNet-5&lt;/p&gt;

&lt;p&gt;1980年代にできたふるいやつ。
モノクロ画像(32×32)の手書き数字認識。&lt;/p&gt;

&lt;p&gt;当時はソフトマックスもReLUもなかった。
けど、畳み込み層とプーリング層のセットを繰り返して入力をチャネル方向に引き伸ばし、全結合層に流し込むアーキテクチャは、モダンなCNNにも通じる。&lt;/p&gt;

&lt;p&gt;5層(内2層が全結合層)の浅いネットワークで、比較的パラメータが少なく、6万個くらい。
モダンなのだとこの1000倍くらいあるのが普通。&lt;/p&gt;

&lt;p&gt;LeNet-5は、チャネルごとに違うフィルタを使っているが、今日では普通同じのを使う。&lt;/p&gt;

&lt;p&gt;また、プーリング層のあとに活性化関数(シグモイド)かけてるのも特殊。
(モダンなアーキテクチャではプーリング層の前にかける?)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;AlexNet&lt;/p&gt;

&lt;p&gt;227×227×3のカラー画像
8層(内3層が全結合層)でパラメータは6千万個くらい。
活性化関数にReLU。&lt;/p&gt;

&lt;p&gt;Local Response Normalizationという正規化層がある。
昨今ではあまり使われない。&lt;/p&gt;

&lt;p&gt;論文が比較的読みやすい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;VGG-16&lt;/p&gt;

&lt;p&gt;2014年に発表。&lt;/p&gt;

&lt;p&gt;各層に同じフィルタを使い、フィルタ数も線形増加させるシンプルなアーキテクチャ。
16層(内2層が全結合層)で、1億3800万個のパラメータ。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;モダンなやつ&lt;/p&gt;

&lt;p&gt;理論的にはネットワークを深くすると精度が高くなるけど、現実的にそうはいかない。
深いネットワークは勾配消失や勾配爆発で訓練しにくいので。
モダンなアーキテクチャはこの問題に対応。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ResNet(Residual Network)&lt;/p&gt;

&lt;p&gt;残差ブロック(Residual block)を持つ。
このブロックでは、浅い層からの出力を深い層のReLUの入力に足し合わせる。
この深い層からの依存はショートカット(short cut)とかskip connectionとか呼ばれる。&lt;/p&gt;

&lt;p&gt;ショートカットのおかげで深い層の学習が効率的になり、層を152まで深くできた。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Network in Network&lt;/p&gt;

&lt;p&gt;畳み込み層に1×1のフィルタを使う。
1×1畳み込み(one by one convolution)、またはNetwork in Networkと呼ばれる。&lt;/p&gt;

&lt;p&gt;これを使うと、入力のhとwを変えずに、チャネル数を減らして計算量を減らしたり、非線形性を追加することができる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Inception Network (GoogleNet)&lt;/p&gt;

&lt;p&gt;フィルタのサイズや畳み込みかプーリングかを考えるのが難しいので、1層内で複数のフィルタサイズで畳み込みやプーリングして、スタックしたものを出力する手法がある。
これをする部分をInception moduleという。
計算コストが大きくなるので、最初に1×1畳み込みで圧縮してからその後の畳み込みをする。
1×1畳み込みの部分でデータがいったん小さくなるので、そこをボトルネック層(Bottleneck layer)と呼ぶ。&lt;/p&gt;

&lt;p&gt;ボトルネック層によって、精度に影響が出ることはない。&lt;/p&gt;

&lt;p&gt;Inception moduleを組み合わせたネットワークをInception Networkという。
Inception Networkの例の一つがGoogLeNet。
GoogLeNetは中間層から全結合層・ソフトマックス層につなげる支流をもっていて、中間層まででうまく学習できているかを見れて、過学習を防げるようになっている。&lt;/p&gt;

&lt;p&gt;因みにInceptionという名前は映画のInceptionから来ている。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;実践&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;既存の実装の利用&lt;/p&gt;

&lt;p&gt;モダンなCNNは複雑すぎて、エキスパートが論文を読み込んでも再現することが難しい。
が、普通は論文の著者がOSSで実装を公開するのでそれを使ったりベースにしたりすべし。&lt;/p&gt;

&lt;p&gt;学習済みのモデルもあることがあるので、転移学習にも使える。
ソフトマックス層だけ入れ替えて、そこのWだけ学習させて自分の問題に使うなど。
色んな深層学習フレームワークが転移学習をサポートしてる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;データ合成(Data augmentation)&lt;/p&gt;

&lt;p&gt;画像認識の分野では基本的にデータが沢山要るけどデータが手に入りにくい。
ので合成するのが効果的。&lt;/p&gt;

&lt;p&gt;左右判定とか、切り抜きとか、回したり、歪めたりとかは、有効だけどあんまりやられない。
若干編集が複雑なので。&lt;/p&gt;

&lt;p&gt;色相を変える(Color shifting)のがよくやられる。赤味を増やしたり。
色を選ぶときには主成分分析(PCA)が使える。(PCA Color Augmentation)&lt;/p&gt;

&lt;p&gt;一つのCPUスレッドに元画像のロードと合成をやらせて、別のスレッドで並列に学習を処理するのが一般的な実装。&lt;/p&gt;

&lt;p&gt;データ合成するにも、どの程度変化させるかというハイパーパラメータが付きまとうので、既存の実装やアイデアを使うのがいい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;画像認識の現状&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;データ vs hand engineering&lt;/p&gt;

&lt;p&gt;データが沢山ある分野の問題だと、でかいネットワークを適当に組んで学習させれば上手く解ける。
データがあんまりないと、色々工夫(hand engineering)が必要になってくる。
特徴量を選んだり、アーキテクチャを工夫したり。
例えば物体検知は画像認識よりかなりデータが少ない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ベンチマークやコンペで上手くやるコツ&lt;/p&gt;

&lt;p&gt;研究者は、論文を通しやすくするため、ベンチマークやコンペのデータに対して頑張る。
ベンチマークに対して上手くやるコツ:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;アンサンブル(Ensembling)&lt;/p&gt;

&lt;p&gt;複数のNNを独立に訓練して、それらの出力の平均を使う。
1,2%の性能向上が見込める。
けど計算コストが高いので、普通プロダクションでは使わない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Multi-crop at test time&lt;/p&gt;

&lt;p&gt;テスト時にテストデータを色んな感じに切り抜いて、それらに対する予測値を平均する。
10-crop。
アンサンブルに比べ、訓練時の計算コストが少ないし、予測時に1つのモデルを保持すればいいのでメモリ使用量が少ない。
若干の性能向上が見込め、プロダクションでも使われることがある。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;オープンソースコードの利用&lt;/p&gt;

&lt;p&gt;だれかが考えたアーキテクチャを使え。&lt;/p&gt;

&lt;p&gt;OSS実装を使え。&lt;/p&gt;

&lt;p&gt;なんなら訓練済みモデルを使え。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Kerasのチュートリアル&lt;/p&gt;

&lt;p&gt;というほど解説してくれるわけではないけど。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kerasで50層のResNetを実装&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;3週目&lt;/p&gt;

&lt;p&gt;物体認識(Object detection)。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;位置特定(Localization)&lt;/p&gt;

&lt;p&gt;画像を与えられて単にラベルを付けるのは分類。
ラベルの物体の位置を示すのが位置特定。
分類したあとさらに位置特定したい。&lt;/p&gt;

&lt;p&gt;分類する画像は、普通一つの画像の中に一つの物体が大きく映っている。
一方、物体認識は、一つの画像の中に複数の物体があったりする、もう少し複雑な問題。&lt;/p&gt;

&lt;p&gt;位置特定するには、ソフトマックス層に、クラス以外に4つの出力をさせる。
すなわち物体の中心点のx座標、y座標、それと物体を囲む枠の高さ、幅。
それぞれ0～1の値で、画像全体に対する割合を示す。&lt;/p&gt;

&lt;p&gt;また、物体があるかないかという予測値Pcも出力する。
この予測値が0のときは、損失関数でそれいがいの出力を計算に入れない。&lt;/p&gt;

&lt;p&gt;より一般的には、物体の位置を示す任意の数のランドマーク(Landmark)の座標を出力させる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;物体認識&lt;/p&gt;

&lt;p&gt;スライディングウィンドウ認識(Sliding windows detection)する。
すなわち、小さい枠をずらしながら画像の切り抜きをたくさん作って、それぞれ分類する。
ウィンドウサイズを変えてもやる。
計算コストがかかる。&lt;/p&gt;

&lt;p&gt;のでCNNでやる。&lt;/p&gt;

&lt;p&gt;まず、全結合層は、数学的に等価な畳み込み層で置き換えられる。
5×5×16の入力を受け取って、5×5の400個のフィルタで畳み込むと、
1×1×400の出力が得られ、これは400ノードの全結合層と一緒。
最後に1×1の4個のフィルタで畳み込むと、4つの出力をするソフトマックス層みたいになる。
こういう、全部畳み込み層のNNをFCN(Fully Convolutional Networks)という。&lt;/p&gt;

&lt;p&gt;で、入力のサイズ(高さと幅)を広げてやると、中間層と出力もちょっと広がる。
このCNNは、入力の一部を5×5のウィンドウで切り抜いた部分の分類結果が、出力の1ピクセルに対応するようなものになる。
なので一回CNNに通せば、一回の計算でスライディングウィンドウできる。&lt;/p&gt;

&lt;p&gt;けどこれは、物体を囲む枠が正確でないという欠点がある。
実際は長方形であるべきだったりするので。
これを解決するのがYOLO(You Only Look Once)アルゴリズム。&lt;/p&gt;

&lt;p&gt;YOLOでは、まず入力画像をグリッド状に分割して、それぞれについて分類と位置特定する。
複数のセルに物体がまたがっている場合は、物体の中心があるセルだけにあるものとする。
それぞれのセルの出力をスタックして、3次元の出力にする。
つまり、グリッドが3×3なら、3×3×(もとのyベクトルの次元)とする。
(普通はもっと細かいグリッドにする。)
で、CNNをこういう形の出力をするように組む。&lt;/p&gt;

&lt;p&gt;YOLOの論文はかなりむずい。&lt;/p&gt;

&lt;p&gt;位置特定の評価をするのに、IoU(Intersection over Union)という指標がある。
これは、2つの領域の重なり具合を示すもので、2つの領域が重なった部分の面積を、2つの領域全体の面積で割った値。
モデルが特定した枠と期待する枠とで、IoUが0.5以上だとよしとすることが多い。&lt;/p&gt;

&lt;p&gt;YOLOを使うと、複数のセルで同じ物体を認識してしまうことが多い。
これを一つに絞るのがNMS(Non-max suppression)。
ざっくり言うと、それぞれのセルの確度(Pc)を見て、一番でかいの以外を無効化する。&lt;/p&gt;

&lt;p&gt;詳しく言うとまず、Pcがある閾値(e.g.0.6)以下のものを無効化する。
で、残ったものの中から、最大のPcを選び、それとおおきくかぶっている枠(IoUが0.5以上など)を無効化する。
で、また残ったのものの中から最大のPcを選び、同じことを繰り返していく。
クラスが複数あったら、これをクラスごとにやる。&lt;/p&gt;

&lt;p&gt;一つのセルに複数の物体があったらどうか。
境界ボックス(Anchor box)を使う。
事前に複数の形の枠(境界ボックス)を用意しておいて、それぞれについての予測を出力ベクトルに並べる。
で、一番IoUが高い境界ボックスを採用する。&lt;/p&gt;

&lt;p&gt;境界ボックスは手動で作ったり、k平均法で作ったりする。&lt;/p&gt;

&lt;p&gt;スライディングウィンドウは、明らかに何もない部分の計算もしちゃうのでちょっと無駄。
なので、そういう部分はスキップしようというのがR-CNN(Regions with CNN)。
これはRegion proposalsとCNNを組み合わせたもの。
Region proposalsは、セグメンテーション(Segmentation)アルゴリズムで画像をざっくり区分けして、それっぽい部分を処理対象にするもの。&lt;/p&gt;

&lt;p&gt;R-CNNはすごく遅いので、あまり使われていないし、Andrew先生も好んで使わない。
Fast R-CNN、Faster R-CNNってのもあるけど、まだ遅い。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;KerasでYOLOv2モデルを実装。&lt;/p&gt;

&lt;p&gt;CNN部分は訓練済みのモデルを使って、出力をフィルタリングする部分を作る。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;4週目&lt;/p&gt;

&lt;p&gt;顔認識(Face recognition)とNeural style transfer。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;顔認識&lt;/p&gt;

&lt;p&gt;顔認証(Face authentication)には、顔認識と、生きた人間かの判定(Liveness detection)が要るけど、前者を主に学ぶ。&lt;/p&gt;

&lt;p&gt;顔認識は顔検証(Face verification)の難しい版。
後者は顔画像と名前を与えて、正しい組み合わせかを判定する。
前者は顔画像を与えて、DBからその人を探す。&lt;/p&gt;

&lt;p&gt;顔認識は一般的に、One-shot learning問題に対応する必要がある。
つまり一つの訓練データから学習しないといけない。
DBに一人のひとについて何個も画像があるというケースは少ない。&lt;/p&gt;

&lt;p&gt;CNNに顔画像を入力して、ソフトマックス層で分類するのは、訓練データが少なすぎるのでうまくいかない。
代わりに類似関数(Similarity function)を学習する。
つまり、二つの画像を入力として、異なる度合いを出力するもの。
で、その出力が閾値以下だったら同一人物と判定する。
これをDBに入っている画像それぞれについてやる。&lt;/p&gt;

&lt;p&gt;類似関数にはシャム(Siamese)ネットワークをつかう。&lt;/p&gt;

&lt;p&gt;CNNの最後の全結合層の出力ベクトルは、入力画像をエンコードしたものだと考えられる。
二つの画像を、別々に同じCNNにいれて、二つの出力ベクトルを得たら、それらのユークリッド距離の二乗を差として出力する。
これがシャムネットワーク。
二つの画像が同一人物ならユークリッド距離が小さくなるように、違うなら大きくなるように訓練する。&lt;/p&gt;

&lt;p&gt;損失関数にはTriplet loss関数を使う。
同一人物を比較するとき、Anchor画像とPositive画像の比較、違う人物の比較はAnchor画像とNegative画像の比較と呼ぶ。
AnchorとPositiveのユークリッド距離がAnchorとNegativeのユークリッド距離以下になってほしい。
つまり前者マイナス後者がゼロ以下になって欲しい。
ただこれだと、CNNが全ての画像について同じ出力をするように学習してしまうかもしれないので、&lt;code&gt;0-α&lt;/code&gt;以下になるように訓練する。
αはマージンと呼ばれるハイパーパラメータ。&lt;/p&gt;

&lt;p&gt;AnchorとPositiveとNegativeの一組をTripletと呼ぶ。
Negativeをランダムに選ぶと、全然違う顔の組み合わせが多くなって、類似関数があまり学習しない。
ので、似てるひとを組み合わせたTripletを多く作ってやると効率よく学習する。&lt;/p&gt;

&lt;p&gt;シャムネットワークの二つの出力ベクトルをロジスティック回帰ユニットに入れて、同一人物か否かの二値分類する方法もある。
ベクトル間の距離も、ユークリッド距離の他、カイ二乗値(χ square similarity)ってのもある。&lt;/p&gt;

&lt;p&gt;DBには、顔画像そのものよりも、エンコードしたベクトルを入れておくと計算量を省けるし、DBサイズも抑えられる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ニューラル画風変換(NST: Neural style transfer)&lt;/p&gt;

&lt;p&gt;Content画像&amp;copy;とStyle画像(S)から、あらたな画像(G)を生成するCNN。
(CNNは別途訓練済みのものを使うので、転移学習の一種。)&lt;/p&gt;

&lt;p&gt;CNNの可視化ができる。
画像の一部を入力して、ある層の一つのユニットの出力が最大になるものを選んで集めると、そのユニットがどのような特徴を抽出しているかがわかる。
深い層ほど広い範囲を見て、複雑なパターンを学ぶ。&lt;/p&gt;

&lt;p&gt;コスト関数&lt;code&gt;J(G)&lt;/code&gt;を最小化する。
&lt;code&gt;J(G)&lt;/code&gt;はコンテントコスト&lt;code&gt;Jcontent(C, G)×α&lt;/code&gt;とスタイルコスト&lt;code&gt;Jstyle(S, G)×β&lt;/code&gt;の和。
前者はCとGの類似関数で、後者はSとGの類似関数。
αとβはハイパーパラメータ。
Gをランダムに初期化して、最急降下法でGを調整していく。&lt;/p&gt;

&lt;p&gt;訓練済みのCNN(VGGなど)を使って、中間層lを選ぶ。
Cを入力してlから出てきた値と、Gを入力してlから出てきた値が似てたら、CとGを似ているとする。
つまりそれらをベクトルにアンロールしたものの二乗誤差が&lt;code&gt;Jcontent(C, G)&lt;/code&gt;。
lが浅ければ浅いほど、CとGは似たものになる。&lt;/p&gt;

&lt;p&gt;スタイルは、ある層lの出力のx座標とy座標の各点について、チャネル間で値の関連性を見る。
あるチャネルのあるニューロンが縦縞を検出していて、ほかのチャネルのあるニューロンがオレンジ色を検出していたとしたら、画像にオレンジの縦縞がよく現れるなら両者は関連が高く、そうでなければ低い。
SとGとの間でこの関連性が似てれば、スタイルが似ていると言える。&lt;/p&gt;

&lt;p&gt;スタイル行列(Style matrix)で表す。
ある層のスタイル行列は&lt;code&gt;nc×nc&lt;/code&gt;で、チャネル間の関連度を表す。
行列の一つの値は、二つのチャネルの各アクティベーションの掛け合わせものの合計。
関連性が強いとこの掛け合わせは大きくなる。
(対角成分は同じチャネル同士の積になって、そのスタイルがどれだけ全体的に出ているかを示す。)
この行列は代数学ではグラム行列(Gram matrix)と呼ばれる。&lt;/p&gt;

&lt;p&gt;このスタイル行列をSとGで計算して、それらの二乗誤差をl層のスタイルコストとする。
で、これにハイパーパラメータλlをかけたものを層ごとに計算して、足し合わせたものを全体のスタイルコストとする。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2D以外の画像の処理&lt;/p&gt;

&lt;p&gt;心電図のデータとかの1Dデータや、CTスキャンみたいな3Dデータでも、それに合わせた次元のフィルタを使えば畳み込める。
1DデータはRNNでもできるけど、CNNでもできて、それぞれメリットデメリットがある。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;TensorFlowでニューラル画風変換を実装&lt;/p&gt;

&lt;p&gt;VGG-19をImageNetのデータで訓練したものを使う。
ルーブル美術館の写真をContent画像に、モネの絵をStyle画像に使って画像を生成。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kerasで顔認識モデルを実装&lt;/p&gt;

&lt;p&gt;現時点でtriplet_lossの採点にバグがある。
対策はフォーラム参照。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CourseraのDeep Learning SpecializationのStructuring Machine Learning Projectsコースを修了した</title>
          <link>https://www.kaitoy.xyz/2018/01/16/coursera-deep-learning-ml-strategy/</link>
          <pubDate>Tue, 16 Jan 2018 07:56:43 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/01/16/coursera-deep-learning-ml-strategy/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/01/12/coursera-deep-learning-improving-deep-neural-networks/&#34;&gt;CourseraのDeep Learning SpecializationのImproving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimizationコースを修了した&lt;/a&gt;のに続き、&lt;a href=&#34;https://www.coursera.org/learn/machine-learning-projects&#34;&gt;Structuring Machine Learning Projectsコース&lt;/a&gt;を修了した。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;このコースは、深層学習プロジェクトの進め方のコツや問題への対処方法などについて学べる2週間のコース。
今回はプログラミング課題がない。
動画は今のところ全部英語。&lt;/p&gt;

&lt;p&gt;ちょっと動画編集ミスが多かった。
同じことを二回言ったり、無音無絵の時間があったり、マイクテストしてたり。&lt;/p&gt;

&lt;p&gt;2018/1/13に始めて、1/15に完了。
3日間かかった。
修了したらまた&lt;a href=&#34;https://www.coursera.org/account/accomplishments/certificate/7MHFMLHP67C4&#34;&gt;Certifacate&lt;/a&gt;もらえた。&lt;/p&gt;

&lt;p&gt;以下、2週分の内容をメモ程度に書いておく。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;p&gt;モデルの改善をするのに、データを増やしたりハイパーパラメータを変えたり色々な手法がある。
一つを試すのに下手すると数か月とかかかるので、効率よく手法の取捨選択し、モデルを改善していくための戦略について学ぶ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;直交化(Orthogonalization)&lt;/p&gt;

&lt;p&gt;一つの要素で複数の制御をしようとすると難しいので、一つの制御だけするようにする。
具体的には、以下のことを別々に扱う。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;訓練データに目標の精度までフィットさせる。&lt;/li&gt;
&lt;li&gt;devデータに目標の精度までフィットさせる。&lt;/li&gt;
&lt;li&gt;テストデータに目標の精度までフィットさせる。&lt;/li&gt;
&lt;li&gt;現実のデータでうまく動くようにする。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;それぞれの目的について、チューニングすべき要素は別々になる。&lt;/p&gt;

&lt;p&gt;早期終了は直行化の原則に反しているので、ほかの方法があるならそっちをやったほうがいい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;指標(Goal)の設定&lt;/p&gt;

&lt;p&gt;モデルの改善はイテレーティブなプロセスなので、サイクルを速く回したい。
そのため、モデルを評価する単一の数値があるといい。
F1スコアとか。平均とか&lt;/p&gt;

&lt;p&gt;単一の指標にまとめるのがむずいときもある。
精度と速さとか。
そんなときは一つ以外の指標を足切りだけに使う。
ある閾値以上の速さが出てるもののなかで精度をくらべるなど。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;データの分け方&lt;/p&gt;

&lt;p&gt;devデータとテストデータの分布(と評価指標)は同じ感じにしないといけない。
そのために、いったん全データをシャッフルしてから分割する。
訓練データの分布は異なってても問題ない。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;訓練:テスト = 70:30&lt;/code&gt;とか、&lt;code&gt;訓練:dev:テスト = 60:20:20&lt;/code&gt;とかいう比率は、1万くらいのデータなら適当。
けど100万くらいなら、98:1:1くらいが妥当。&lt;/p&gt;

&lt;p&gt;テストデータはモデルの最終評価をするためのものなので、どれだけ評価したいかによってサイズを変える。
0もありがちだけど、非推奨。&lt;/p&gt;

&lt;p&gt;猫の画像のなかにエロ画像が混じっちゃうようなモデルはだめ。
猫判定率が多少下がっても、エロ画像が含まれないほうがまし。
こういう場合は評価指標を変える必要がある。
エロ画像を猫と判定した場合にペナルティを大きくするなど。&lt;/p&gt;

&lt;p&gt;直行化の観点で言うと、指標を決めるのと、その指標に従って最適化するのは、別のタスクとして扱うべき。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;人並性能(Human-level performance)との比較&lt;/p&gt;

&lt;p&gt;人並性能とは、人が手動で達成できる精度。そのエラー率、つまり人並誤差(Human-level error)はベイズ誤差(Bayes optimal error)に近い。&lt;/p&gt;

&lt;p&gt;モデルを改良していくと、人並性能を超え、その後改善速度は鈍化し、人並誤差はベイズ誤差に漸近していく。
鈍化する理由は、人並性能がベイズ誤差に近いのと、人以上の精度に人がチューニングするのが無理があるから。
人手でラベル付きデータを作れないし、エラー分析もできなくなるので。&lt;/p&gt;

&lt;p&gt;人並誤差より訓練データでのエラー率が結構高いなら、高バイアス対策をする。
人並誤差と訓練データでのエラー率が近くて、devデータでのエラー率が結構高いなら、高バリアンス対策をする。
人並誤差と訓練データでのエラー率との差ををAndrew先生は可避バイアス(Avoidable bias)と名付けた。&lt;/p&gt;

&lt;p&gt;人並誤差はベイズ誤差の近似として使える。
人並誤差は、ある判別問題に関して、その道のエキスパート達が議論して解を出すみたいな、人類が全力を尽くしたうえでの誤差とする。
人並誤差が分かれば、訓練データとdevデータのエラー率を見て、高バイアスか高バリアンス化を判別できる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;モデルの性能改善手順&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;訓練データにフィットさせ、可避バイアスを最小化する。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;モデルを大きくする。&lt;/li&gt;
&lt;li&gt;最適化アルゴリズムを高度なものにするか、長く訓練する。&lt;/li&gt;
&lt;li&gt;NNのレイヤを深くしたり隠れ層のノードを増やしたり、CNNとかRNNとかの高度なアーキテクチャにする。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;dev・テストデータで評価し、バリアンスを下げる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;データを増やす。&lt;/li&gt;
&lt;li&gt;正則化する。&lt;/li&gt;
&lt;li&gt;ハイパーパラメータをいじる。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Andrej Karpathyへのインタビュー&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;エラー分析&lt;/p&gt;

&lt;p&gt;エラー率が高いときに、エラーが起きたdevデータのサンプルを見て原因を分析する。
天井分析(Ceiling analysis)も併せてやる。
例えば、猫判定器で、犬を猫と判定したサンプルがあったとして、犬の問題に取り組むかどうかは、全体のエラーサンプル数に対する犬のエラーサンプル数の割合を見て、その取り組みで最大どれだけの効果を得るかを分析する。&lt;/p&gt;

&lt;p&gt;天井分析を複数の問題点に対してやれば、どれに時間をかける価値があるかの指標を得られる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ラベリングミスへの対処&lt;/p&gt;

&lt;p&gt;ディープラーニングは、ランダムエラーに対して堅牢で、訓練データに多少のラベリングミスがあっても問題なく動く。&lt;/p&gt;

&lt;p&gt;devデータにミスがあった場合、エラー分析の際にそれも数えておいて、対処すべきかどうかを判断する。
他の問題によるエラーの割合と比べて、ラベリングミスによるものの割合が大きければ対処すればいいし、そうでなければほっておく。
また、エラー全体に対するラベリングミスの割合が大きくなると、モデルの性能比較に支障が出てくるので、そうなったらラベリングミスに対処する必要が高まってくる。&lt;/p&gt;

&lt;p&gt;devデータのラベリングミスを直すときは、テストデータも同時に直し、分布に違いが出ないようにする。
また、エラーなサンプルだけじゃなく、正答したサンプルも見直すべし。
けど、訓練データは直さなくてもいい。数も多いし、devデータと分布が違っていても問題ないし。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;新しいディープラーニングシステムを作るときのガイドライン&lt;/p&gt;

&lt;p&gt;あまり経験のない分野のシステムを新たに作るなら、早く立ち上げてイテレーションを回すべし。
具体的には、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;dev・テストデータと、指標を用意する。&lt;/li&gt;
&lt;li&gt;さっさとシステムを実装する。&lt;/li&gt;
&lt;li&gt;バイアス/バリアンス分析やエラー分析をして、次のアクションを決める。&lt;/li&gt;
&lt;li&gt;システムを改善する。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;というのを速く回す。
経験が深かったり、確かな研究結果がすでにあったりするなら、最初から凝ったシステムにしてもいい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;訓練データとdev・テストデータの分布のミスマッチ&lt;/p&gt;

&lt;p&gt;ディープラーニングでは訓練データは大抵不足するから、現実的に、訓練データはいろんなデータのかき集めで、dev・テストデータとは分布が異なってくる。&lt;/p&gt;

&lt;p&gt;例えば、実際のデータが10000個で、かき集めのが200000個あったら、全部合わせてシャッフルしてデータ分割するのは、dev・テストデータの質が悪くなるのでダメ。
dev・テストデータには実際のデータだけ使って、かき集めのは全部訓練データに使うべし。&lt;/p&gt;

&lt;p&gt;分布がミスマッチになると、バイアス/バリアンス分析がむずくなる。
devデータでエラーが増えても、単にdevデータのほうが判別が難しいデータなのかもしれない。&lt;/p&gt;

&lt;p&gt;分析をしやすくするため、訓練devデータを作る。
これは、訓練データと同じ分布のデータで訓練に使わないデータ。訓練データのサブセット。&lt;/p&gt;

&lt;p&gt;訓練データと訓練devデータのエラー率の差が大きければオーバーフィット。
訓練データと訓練devデータのエラー率の差が小さくて、devデータのエラー率が高いなら、データミスマッチ問題(Data missmatch problem)。&lt;/p&gt;

&lt;p&gt;あんまり発生しないけど、devデータよりテストデータのエラー率が結構大きいなら、devデータにオーバーフィットしてるので、devデータサイズを増やしたりする必要がある。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;データミスマッチ問題への対応&lt;/p&gt;

&lt;p&gt;データミスマッチ問題が発覚したら、訓練データをdevデータに近づけたり、devデータに近いものを訓練データに加えたりすることを考える。
例えば、車内の音声認識のためのモデルを開発していて、devデータに車の雑音が入っていることが分かったら、訓練データにそういう雑音を合成してやるなど。
ただし、その場合、同じ雑音をすべての訓練データに適用すると、その雑音にモデルがオーバーフィットするリスクがあるので注意。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;転移学習(Transfer learning)&lt;/p&gt;

&lt;p&gt;ある問題に対して作ったモデルを、別の問題に再利用する。
(但し入力は同種のデータ。画像なら画像、音声なら音声。)
その際、NNの、出力層だけのパラメータをランダム初期化したり、層を足したりして、あたらしい訓練データで学習させる。
新たな訓練データが少ない場合は、後ろの1,2層だけを再学習させ、データがたくさんあったら全体を再学習させる。&lt;/p&gt;

&lt;p&gt;最初の学習を事前学習(Pre-training)、新たなデータでの学習をファインチューニング(Fine tuning)という。
画像認識の分野でよく使われる。NNの浅い層のほうが、汎用的な特徴(エッジ検出など)を学習するので再利用できると考えられているが、詳しい原理は判明していない。&lt;/p&gt;

&lt;p&gt;事前学習するデータより、ファインチューニングに使えるデータが少ないときに効果的。
データ量が同じくらいだったり、後者のほうが多い場合は、最初から目的のデータで学習させたほうがいい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;マルチタスク学習(Multi-task learning)&lt;/p&gt;

&lt;p&gt;一度に複数の判別をさせるモデルをつくる。
ソフトマックス層つかった多クラス分類に似てるけど、一つのサンプルから複数のクラスを検出する。
例えば車と歩行者と標識など。
物体検知によく使われる。&lt;/p&gt;

&lt;p&gt;一つ一つのクラスのデータが少なくても低層が学んだ共通特徴を活用できるので、一つのタスクをするNNを複数訓練するより性能が良くなることがある。&lt;/p&gt;

&lt;p&gt;ラベルが歯抜けでも学習できる。&lt;/p&gt;

&lt;p&gt;複数タスクをこなすため、大き目なネットワークにする必要がある。&lt;/p&gt;

&lt;p&gt;それぞれのクラスのデータが十分あるときはあまり使われない手法。
目的のクラスのデータが少ないとき、転移学習のほうがよく使われる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;End-to-end学習&lt;/p&gt;

&lt;p&gt;従来、ある入力から解となる出力を得るのに、パイプラインで複数の処理をしていたが、これを全部一つのNNで処理する手法。
データ量が多いと上手くいく。&lt;/p&gt;

&lt;p&gt;例えば、人の認識をするときパイプラインでは、顔検出して、拡大してクロップしてからNNにかける。
こっちのほうが個々のタスクがシンプルで、それぞれのデータも手に入りやすいので性能を出しやすい。
けどもし、end-to-endのラベル付きデータが十分にあればend-to-end学習でもいける。&lt;/p&gt;

&lt;p&gt;翻訳タスクの場合、現実的に大量のデータが手に入るので、end-to-endで上手くいく。&lt;/p&gt;

&lt;p&gt;データさえたくさんあれば、パイプラインのコンポーネント的なところも勝手に学んでくれるので、ヒトが考え付くよりもいい特徴を学んでくれるかもしれない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Ruslan Salakhutdinovへのインタビュー&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CourseraのDeep Learning SpecializationのImproving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimizationコースを修了した</title>
          <link>https://www.kaitoy.xyz/2018/01/12/coursera-deep-learning-improving-deep-neural-networks/</link>
          <pubDate>Fri, 12 Jan 2018 23:41:57 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/01/12/coursera-deep-learning-improving-deep-neural-networks/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/01/05/coursera-deep-learning-neural-networks-and-deep-learning/&#34;&gt;CourseraのDeep Learning SpecializationのNeural Networks and Deep Learningコースを修了した&lt;/a&gt;のに続き、&lt;a href=&#34;https://www.coursera.org/learn/deep-neural-network&#34;&gt;Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimizationコース&lt;/a&gt;を修了した。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;このコースは、ディープニューラルネットワークのチューニングなどについて学べる3週間のコース。
今のところ全部英語。&lt;/p&gt;

&lt;p&gt;2018/1/5に始めて、1/12に完了。
8日間かかった。
修了したらまた&lt;a href=&#34;https://www.coursera.org/account/accomplishments/certificate/5VS9EJJ6TJ3A&#34;&gt;Certifacate&lt;/a&gt;もらえた。&lt;/p&gt;

&lt;p&gt;以下、3週分の内容をメモ程度に書いておく。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;p&gt;OverfittingやUnderfittingを防ぐテクニックについて。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;データ分割&lt;/p&gt;

&lt;p&gt;深層学習のモデル構築は、検討(Idea)、実装(Code)、検証(Experiment)というサイクルの繰り返し(Iterative process)。
取り組む課題、課題のドメイン、データ量、マシンの構成などにより、ハイパーパラメータは変わるので、経験をもって事前に予測することは無理なので、サイクルをどれだけ速く回せるかが鍵。&lt;/p&gt;

&lt;p&gt;データは、訓練データ(Training set)、Devデータ(Development set))(a.k.a. Cross-validation set)、テストデータ(Test set)に分割する。
訓練データで学習し、Devデータでハイパーパラメータを評価し、テストデータで最終的な評価と性能見積をする。
テストデータは無くてもいい。&lt;/p&gt;

&lt;p&gt;サンプル数が1万くらいだった時代は、6:2:2くらいで分割してたけど、近年は数百万とかのデータを扱い、交差検証データやテストデータの割合はもっと小さくするのがトレンド。
98:1:1など。&lt;/p&gt;

&lt;p&gt;Devデータとテストデータは同じようなものを使うべき。
訓練データは必ずしも同様でなくてもいい。訓練データは沢山要るので、別のデータソースからとることもある。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;バイアス vs バリアンス&lt;/p&gt;

&lt;p&gt;でかいネットワークで正則化して大量データで学習させるのが吉。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;正則化&lt;/p&gt;

&lt;p&gt;過学習(Overfitting)を防ぐため、コスト関数を正則化(Regularization)すべし。&lt;/p&gt;

&lt;p&gt;ロジスティック回帰ではL2ノルム(L2 norm)を使ったL2正則化が一般的。
L1正則化はあまり使われない。
L1正則化をすると、wがスパース行列になってモデルを圧縮できると言われることがあるが、経験上その効果はほとんどない。&lt;/p&gt;

&lt;p&gt;正則化パラメータλはハイパーパラメータで、Devデータで評価する。&lt;/p&gt;

&lt;p&gt;ニューラルネットワークでは正則化項にフロベニウスノルム(Frobenius norm)を使う。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dropout(Inverted Dropout)&lt;/p&gt;

&lt;p&gt;ランダムにノードを無効化しながら学習することで過学習を防ぐ。
画像処理の分野では、特徴量の数が多く学習データが少ない傾向があるので、ほぼ常に使われる。&lt;/p&gt;

&lt;p&gt;コスト関数が計算できなくなるのが欠点。
計算する必要があるときにはDropoutを無効化する。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;データ拡張(Data augmentation)&lt;/p&gt;

&lt;p&gt;データを加工して増やせば、高バリアンス対策になる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;早期終了(Early stopping)&lt;/p&gt;

&lt;p&gt;過学習するまえに学習を止めるテクニック。
訓練データとDevデータについてコストをプロットして、Devデータのものが上がる前に止める。&lt;/p&gt;

&lt;p&gt;これは、直交化(Orthogonalization)の原則、つまり一度に一つのことを考慮すべきという原則に反していて、コストを最小化するという問題と、過学習を避けるという問題に同時に対処することになるので微妙。&lt;/p&gt;

&lt;p&gt;普通は代わりにL2正則化使えばいいけど、λを最適化する手間を省きたいときには選択肢になりうる、というか実現場ではちょくちょく選択肢になる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;訓練データの正規化(Normalization)&lt;/p&gt;

&lt;p&gt;訓練データの各特徴量について平均を0にして分散を1にすると学習が速くなる。&lt;/p&gt;

&lt;p&gt;訓練データを正規化したらテストデータも正規化する。
その際、正規化パラメータは訓練データのものを使う。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;勾配消失(Vanishing gradient)、勾配爆発(Exploding gradient)&lt;/p&gt;

&lt;p&gt;ニューラルネットワークの層が深くなると、層の出力や勾配が指数関数的に大きくなったり小さくなったりして、学習が難しくなる問題。
長年ディープニューラルネットワークの発展を妨げてきた問題。&lt;/p&gt;

&lt;p&gt;パラメータのランダム初期化をすると防げる。
ガウス分布で作ったパラメータに特定の値を掛けてを分散が1/n(ReLUの時は2/n)になるように調整して、活性化関数に入力する値を約1に抑える。
掛ける値は活性化関数ごとにだいたい決まっていて((e.g. Xavier Initialization)、その値をハイパーパラメータとして調整するのはそれほど優先度は高くない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Gradient checking&lt;/p&gt;

&lt;p&gt;順伝播・逆伝播が正確に実装できているかを、数値計算手法で概算した勾配と逆伝播で出した勾配を比べてチェックするテクニック。
計算コストが高くなるので、デバッグ時にのみ使う。&lt;/p&gt;

&lt;p&gt;Dropoutしてるときには使えない。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;初期化&lt;/p&gt;

&lt;p&gt;ゼロ初期化、大きい値でのランダム初期化、He初期化(Xavier初期化っぽいやつ)を実装して性能を比べる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;正則化&lt;/p&gt;

&lt;p&gt;正則化無し、L2正則化、Dropoutの実装と比較。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Gradient checking&lt;/p&gt;

&lt;p&gt;Gradient checkingの実装と、その結果を利用した逆伝播のデバッグ。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Yoshua Bengioへのインタビュー&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;p&gt;学習を速くするテクニックについて。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ミニバッチ勾配降下法(Mini-batch gradient descent)&lt;/p&gt;

&lt;p&gt;普通の勾配降下法(i.e. バッチ勾配降下法)よりかなり速いので、大規模データでよく使われるテクニック。
学習回数に対するコストのプロットはノイジーになる。&lt;/p&gt;

&lt;p&gt;ミニバッチサイズというハイパーパラメータが増える。
ミニバッチサイズがmならバッチ勾配降下法、1なら確率的勾配降下法(Stochastic gradient descent)になる。&lt;/p&gt;

&lt;p&gt;ミニバッチ勾配降下法と確率的勾配降下法は収束しない。&lt;/p&gt;

&lt;p&gt;バッチ勾配降下法は遅すぎる。
確率的勾配降下法はベクトル化の恩恵がなくなるという欠点がある。
ので、適当なミニバッチサイズにするのがよく、それが一番速い。&lt;/p&gt;

&lt;p&gt;2000個くらいのデータならバッチ勾配降下法。
それより多ければ、64～512位のミニバッチサイズがいい。
メモリ効率を考えると2の累乗数がいいし、CPU/GPUメモリサイズに乗るサイズにすべし。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;指数加重移動平均 (EWMA: Exponentially Weighted Moving Average)&lt;/p&gt;

&lt;p&gt;ノイズのあるデータから、よりスムーズなプロットを書く手法。
過去数日の平均をもとにプロットする。&lt;/p&gt;

&lt;p&gt;この手法だと、最初の方のデータが不当に小さくなってしまう。
これが問題になるなら、バイアス補正(Bias correction)をかける。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;モーメンタム(Momentum)付き勾配降下法&lt;/p&gt;

&lt;p&gt;パラメータを更新するときに、勾配そのままではなく、勾配の指数加重移動平均を使う手法。
勾配降下を滑らかに速くできる。
慣性(勢い)をつけて走り抜ける感じ。&lt;/p&gt;

&lt;p&gt;指数加重移動平均を計算するときのβが新たなハイパーパラメータになる。
普通0.9。この場合バイアス補正はそんなに効果ないので普通かけない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;RMSprop&lt;/p&gt;

&lt;p&gt;パラメータを更新するときに、勾配そのままではなく、勾配の二乗平均平方根(RMS: Root Mean Square)を使う手法。
学習率を上げつつ、勾配降下を滑らかに速くできる。&lt;/p&gt;

&lt;p&gt;二乗平均平方根を計算するときのβと、ゼロ除算を防ぐためのεが新たなハイパーパラメータになる。
提唱者は、&lt;code&gt;β=0.999&lt;/code&gt;、&lt;code&gt;ε=10^-8&lt;/code&gt;を推奨しているし、これらをチューニングすることはあまりない。&lt;/p&gt;

&lt;p&gt;Couseraが広めたことで、よく使われるようになった。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Adam(Adaptive Moment Estimation)&lt;/p&gt;

&lt;p&gt;モーメンタムとRMSpropとバイアス補正を組み合わせた最適化アルゴリズム。
これをミニバッチ勾配降下法と一緒に使えばだいたい上手くいく。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;学習率減衰(Learning rate decay)&lt;/p&gt;

&lt;p&gt;ミニバッチ勾配降下を収束させるために、学習率を徐々に小さくする手法。
エポックごとに学習率を下げる。&lt;/p&gt;

&lt;p&gt;学習率αが、α0と 減衰率(Decay rate)とエポック番号から計算されるようになるので、α0と減衰率がハイパーパラメータ。&lt;/p&gt;

&lt;p&gt;学習率の計算方法にはいくつかある。
指数関数的に下げたり、階段状に下げたり。&lt;/p&gt;

&lt;p&gt;Andrew先生はあまり使わない手法。
学習率をよくチューニングすれば十分。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;局所最適解(Local optima)&lt;/p&gt;

&lt;p&gt;かつて、勾配が0になる点は、コストの谷、つまり局所最適解だと考えられていて、そこに嵌ることが問題だった。&lt;/p&gt;

&lt;p&gt;けど、ディープニューラルネットワークでは多くは尾根的なもの。
鞍の上みたいな部分なので鞍点(Saddle point)と呼ばれる。
特徴量が沢山あるので、ちょっと動かすとどれかの勾配は負になる。&lt;/p&gt;

&lt;p&gt;よって局所最適解はあまり恐れなくていい。
代わりに、鞍点の台地みたいな部分では勾配が小さいので学習効率が悪くなる。
ここを勢いよく抜けたいので、モーメンタムやRMSpropやAdamが有効になる。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ミニバッチ勾配降下法実装&lt;/p&gt;

&lt;p&gt;訓練データをシャッフルして、ミニバッチサイズに分割して(余りは余りでミニバッチにする)、forループで回す。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;モーメンタムとAdam実装&lt;/p&gt;

&lt;p&gt;単なるミニバッチ勾配降下法とモーメンタム付きとAdamを比較。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Yuanqing Linへのインタビュー&lt;/p&gt;

&lt;p&gt;中国の国立深層学習研究所のトップ。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;p&gt;ハイパーパラメータのチューニング方法、バッチ正規化、ソフトマックス回帰、TensorFlow。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ハイパーパラメータのチューニング&lt;/p&gt;

&lt;p&gt;一番重要なのは学習率。
次はモーメンタムのβとかミニバッチサイズとか隠れ層のノード数。
その次がレイヤ数とか学習率減衰率。&lt;/p&gt;

&lt;p&gt;チューニングの際は、かつてはグリッドサーチ(Grid search)がよく使われたけど、これはハイパーパラメータが多くなるとつらい。
ランダムサーチ(Randomized search)がより効率的。&lt;/p&gt;

&lt;p&gt;グリッドサーチだとあるパラメータを固定して別のパラメータを変化させるけど、変化させたパラメータがどうでもいいものだった場合、その試行がほとんど無駄になるので。&lt;/p&gt;

&lt;p&gt;粗くランダムサーチして当たりをつけ、範囲を絞って細かいランダムサーチする。&lt;/p&gt;

&lt;p&gt;ランダムといってもいろいろあって、ユニット数なんかは一様にランダムでいいけど、学習率なんかはlogスケールの上でランダムにしたほうがいい。&lt;/p&gt;

&lt;p&gt;実運用では、計算リソースが少ない場合に採るパンダアプローチと、潤沢なリソースで複数のモデルを同時に訓練するキャビアアプローチがある。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;バッチ正規化(Batch normalization)&lt;/p&gt;

&lt;p&gt;深層学習の実用化において最も重要なアルゴリズムの一つ。
ハイパーパラメータの選定を簡単にして、ディープニューラルネットワークの訓練を簡単にする。&lt;/p&gt;

&lt;p&gt;バッチ正規化では、各層の入力を正規化する。
ミニバッチごとに平均を0、分散を1に正規化した後、βとγというパラメータでそれぞれを調整する。
aよりz(i.e. 活性化関数適用前)を正規化するのが普通。&lt;/p&gt;

&lt;p&gt;(ハイパーではない)パラメータとしてβとγが層ごとに増える。
これらもWとともに学習する。
βがbの役割をするので、bはいらなくなる。&lt;/p&gt;

&lt;p&gt;バッチ正規化は共変量シフト(Covariate shift)という問題に対応するもの。
共変量シフトは、訓練した後で入力の分散が変わると、また訓練しなおさないといけないという問題。
ニューラルネットワークの内部では、前のほうの層のWが学習を進めるたびに変わり、その層の出力が変わる。
つまり後のほうの層への入力が変わるので、後のほうの層の学習が進みにくい。
バッチ正規化は、この後のほうの層への入力の分散を一定範囲に抑えることで、後のほうの層の学習を効率化する。&lt;/p&gt;

&lt;p&gt;Dropoutと同様な論理(ノードへの依存が分散される)で正則化の効果もややある。&lt;/p&gt;

&lt;p&gt;訓練が終わったら、最後のミニバッチの平均μと分散σ^2を保存しておいて、予測時に使う。
μとσ^2は訓練データ全体から再計算してもよさそうだけど、普通はやらない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ソフトマックス回帰(Softmax regression)&lt;/p&gt;

&lt;p&gt;ニューラルネットワークで多値分類(Multi-class classification)するアルゴリズム。
出力層(ソフトマックス層)のノード数をクラス数にして、活性化関数にソフトマックス関数を使う。
出力層の各ノードは、サンプルが各クラスに属する確率を出力する。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;TensorFlow&lt;/p&gt;

&lt;p&gt;ディープラーニングフレームワークはいろいろある: Caffe/Caffe2、CNTK、DL2J、Keras、Lasagne、mxnet、PaddlePaddle、TensorFlow、Theano、Torch。
プログラミングしやすいこと、訓練性能がいいこと、オープンであることが重要。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;TensorFlowの基本&lt;/p&gt;

&lt;p&gt;TensorFlowでのプログラムはだいたい以下のような手順で書く。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;テンソル(tensor)をつくる。これはまだ評価されない。&lt;/li&gt;
&lt;li&gt;テンソル間の計算式(計算グラフ)を書く。&lt;/li&gt;
&lt;li&gt;テンソルを初期化する。&lt;/li&gt;
&lt;li&gt;セッションを作る。&lt;/li&gt;
&lt;li&gt;セッションを実行する。ここで計算が実行される。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;後で(セッション実行時に)値を入れたい場合はプレースホルダ(placeholder)を使う。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;TensorFlowでのニューラルネットワーク実装&lt;/p&gt;

&lt;p&gt;画像を読み込んで多クラス分類するNNを作る。
以下、今回使った関数の一部。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;シグモイド関数: &lt;code&gt;tf.sigmoid(x)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;エントロピーコスト: &lt;code&gt;tf.nn.sigmoid_cross_entropy_with_logits(logits, labels)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;One-hotエンコーディング: &lt;code&gt;tf.one_hot(labels, depth, axis)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;最急降下法: &lt;code&gt;tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CourseraのDeep Learning SpecializationのNeural Networks and Deep Learningコースを修了した</title>
          <link>https://www.kaitoy.xyz/2018/01/05/coursera-deep-learning-neural-networks-and-deep-learning/</link>
          <pubDate>Fri, 05 Jan 2018 15:20:23 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/01/05/coursera-deep-learning-neural-networks-and-deep-learning/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2017/12/22/coursera-machine-learning/&#34;&gt;CourseraのMachine Learningコース&lt;/a&gt;に続いて、同じくAndrew先生による&lt;a href=&#34;https://www.coursera.org/specializations/deep-learning&#34;&gt;Deep Learning Specialization&lt;/a&gt;を受講中。&lt;/p&gt;

&lt;p&gt;これは深層学習の基本を学べるもので、以下の5つのコースからなる。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Neural Networks and Deep Learning&lt;/li&gt;
&lt;li&gt;Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization&lt;/li&gt;
&lt;li&gt;Structuring Machine Learning Projects&lt;/li&gt;
&lt;li&gt;Convolutional Neural Networks&lt;/li&gt;
&lt;li&gt;Sequence Models&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;この内、最初のNeural Networks and Deep Learningを修了したので、記念にブログしておく。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;deep-learning-specializationとは&#34;&gt;Deep Learning Specializationとは&lt;/h1&gt;

&lt;p&gt;Deep Learning Specializationは&lt;a href=&#34;https://learner.coursera.help/hc/en-us/articles/208280296&#34;&gt;Coursera Specialization&lt;/a&gt;のひとつ。
Coursera Specializationはサブスクリプションモデルで、つまりあるSpecializationのサブスクリプションを購入すると、受講完了するまで毎月定額の料金を支払うことになる。&lt;/p&gt;

&lt;p&gt;Deep Learning Specializationは月$49で、5コース合わせて16週分の内容。
最初の7日間はトライアルで無料なので、この間に全部終わらせられればタダ。
無理だけど。&lt;/p&gt;

&lt;p&gt;Deep Learning Specializationでは、PythonとTensorFlowでディープニューラルネットワーク、CNN、RNN、LSTM、Adam、Dropout、バッチ正規化、Xavier/He initializationなどを学べる。
Machine Learningコースと同じく、5分～15分くらいの動画による講義と、小テストと、プログラミング課題から構成されている。&lt;/p&gt;

&lt;p&gt;プログラミング課題は、coursera hubという、ホステッドJupyter Notebookで解いて提出できるので楽。&lt;/p&gt;

&lt;h1 id=&#34;neural-networks-and-deep-learningコースとは&#34;&gt;Neural Networks and Deep Learningコースとは&lt;/h1&gt;

&lt;p&gt;ディープニューラルネットワークの仕組みを学んで実装する4週間のコース。
また、深層学習の偉い人へのインタビューを見れる。
Machine Learningコースと被っている内容が少なくなく、かなり楽だったが、結構ペースが速いので、Machine Learningコースをやっていなかったら辛かったと思う。&lt;/p&gt;

&lt;p&gt;動画は大抵日本語字幕が付いている。
日本語字幕が付いていない奴は、英語字幕が機械生成したっぽいもので見辛い。&lt;/p&gt;

&lt;p&gt;2018/1/1に始めて、1/5に完了。
5日間かかった。
修了したら&lt;a href=&#34;https://www.coursera.org/account/accomplishments/certificate/G77XMU9TNEKX&#34;&gt;Certifacate&lt;/a&gt;もらえた。&lt;/p&gt;

&lt;p&gt;以下、4週分の内容をキーワードレベルで書いておく。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;深層学習(Deep Learning)概要&lt;/p&gt;

&lt;p&gt;AIは次世代の電気。産業革命を起こす。
AIで今一番熱い分野が深層学習。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ニューラルネットワーク(Neural Network)。&lt;/li&gt;
&lt;li&gt;畳み込みニューラルネットワーク(CNN: Convolutional Neural Network)。&lt;/li&gt;
&lt;li&gt;再帰型ニューラルネットワーク(RNN: Recurrent Neural Network)。&lt;/li&gt;
&lt;li&gt;深層学習の適用分野・例。&lt;/li&gt;
&lt;li&gt;深層学習が実用化した背景。&lt;/li&gt;
&lt;li&gt;シグモイド関数(Sigmoid function) vs ReLU(Rectified Linear Unit)関数。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;深層学習のゴッドファーザー、Geoffrey Hintonへのインタビュー。&lt;/p&gt;

&lt;p&gt;ニューラルネットワークの黎明期を支え、ReLU関数の有効性を証明したりボルツマンマシンを発明したりした人。
自身が歩んできた深層学習の歴史や今取り組んでいる・注目している理論について、
高尚な話をしていたようだったが、高尚すぎてよくわからなかった。&lt;/p&gt;

&lt;p&gt;今日成果を出しているのは教師あり学習だけど、教師無し学習のほうが重要と考えているとのこと。&lt;/p&gt;

&lt;p&gt;これから機械学習に取り組む人へ、以下のアドバイスをしていた。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;文献を読みすぎるな。&lt;/li&gt;
&lt;li&gt;文献を読んで、間違っていると感じるところをみつけて、それに取り組め。&lt;/li&gt;
&lt;li&gt;人から何を言われても気にせず、自分の信念に従って研究しろ。&lt;/li&gt;
&lt;li&gt;誰かに無意味なことをしていると指摘されたら、むしろ価値のあることをしていると思え。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ニューラルネットワークプログラミングの基礎&lt;/p&gt;

&lt;p&gt;ロジスティック回帰は小さい(1層1ノード)ニューラルネットワーク。
ロジスティック回帰の微分を逆伝播で計算する。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;二値分類(Binary classification)、ロジスティック回帰(Logistic regression)。&lt;/li&gt;
&lt;li&gt;損失関数(Loss function)、交差エントロピー(Cross entropy)、目的関数(Cost function)。&lt;/li&gt;
&lt;li&gt;最急降下法(Gradient descent)。&lt;/li&gt;
&lt;li&gt;微分(Derivatives)。&lt;/li&gt;
&lt;li&gt;逆伝播(Backpropagation)、計算グラフ(Computation graph)、連鎖律(Chain rule)。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Pythonとベクトル化(Vectorization)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;forループ vs ベクトル化。&lt;/li&gt;
&lt;li&gt;Jupyter Notebook、NumPy、ブロードキャスト(Broadcasting)。&lt;/li&gt;
&lt;li&gt;ロジスティック回帰のベクトル化。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ロジスティック回帰で猫の画像の判別。&lt;/li&gt;
&lt;li&gt;NumPy、h5py、Matplotlib、PIL、SciPy。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;深層学習とロボットの研究者、Pieter Abbeelへのインタビュー&lt;/p&gt;

&lt;p&gt;深層強化学習の有名な研究者。DQN。&lt;/p&gt;

&lt;p&gt;かつて、機械学習で成果を出すためには、取り組んでいる課題特有の分野の知識が必要だったが、2012年にGeoffreyが発表したAlexNetがそれを覆した。
Pieterはそのアイデアを深層強化学習に適用し発展させた。&lt;/p&gt;

&lt;p&gt;強化学習は、どこからデータ収集するのか、報酬の分配はどうするかといったところに課題がある。
また、安全性にも課題。学習の過程で失敗を繰り返すので、自動運転などをどう学習させるか、またどう学び続けさせるか。
ネガティブデータを集めるのがむずい。&lt;/p&gt;

&lt;p&gt;短時間の実験でうまくいっても、長時間の稼働でうまくいくとも限らない。&lt;/p&gt;

&lt;p&gt;強化学習は複雑すぎるので、アルゴリズム自体を学習できるようにしたい。
プログラムを自動で変更しながら学習するなど。&lt;/p&gt;

&lt;p&gt;強化学習は、アルゴリズムを変更しなくても様々なことを学べる。
けど、ゼロから学ぶと時間がかかるので、以前学んだことを活かして次の課題に取り組めるようにするのが最先端の研究。&lt;/p&gt;

&lt;p&gt;まずは教師あり学習で人の代わりができるようになり、その後目的を与えて、強化学習で改善していく、っていう感じのことができるとうれしい。&lt;/p&gt;

&lt;p&gt;これから機械学習に取り組む人へ、以下のアドバイスをしていた。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;需要が高まっているので、AIを始めるにはよい時期。&lt;/li&gt;
&lt;li&gt;オンライン講座がたくさんあるので、学びやすい。自分で試したり再現したりしてみることが重要。&lt;/li&gt;
&lt;li&gt;TensorFlow、Chainer、Theano、PyTorchなど、手軽に試せるツールが色々ある。&lt;/li&gt;
&lt;li&gt;専門的な教育を受けなくても、自己学習でトップクラスになれる。&lt;/li&gt;
&lt;li&gt;機械学習を学ぶのに、大学で研究すべきか大企業で仕事を得るべきかについては、どれくらいの指導を受けれるかによる。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;3週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;浅いニューラルネットワーク&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ロジスティック回帰を多重にして2層のニューラルネットワーク化。&lt;/li&gt;
&lt;li&gt;ニューラルネットワークアルゴリズムのベクトル化。&lt;/li&gt;
&lt;li&gt;活性化関数(Activation function)の選択: シグモイド vs tanh vs ReLU vs Leaky ReLU vs 線形活性化関数(Linear activation function)。&lt;/li&gt;
&lt;li&gt;順伝播(Forward propagation)、逆伝播(Backpropagation)。&lt;/li&gt;
&lt;li&gt;ランダム初期化(Random initialization)。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;二値分類するニューラルネットワークを実装。&lt;/li&gt;
&lt;li&gt;scikit-learn。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;GAN(Generative Adversarial Network)の発明者、Ian Goodfellowへのインタビュー&lt;/p&gt;

&lt;p&gt;GANは生成モデル(学習したデータに似たデータを生成するモデル)。
バーで飲んでいるときに思いつき、一晩で実装した。&lt;/p&gt;

&lt;p&gt;GANは今は繊細過ぎるのが課題で、安定性の向上に今取り組んでいる。&lt;/p&gt;

&lt;p&gt;機械学習のセキュリティにも興味がある。モデルをだまして想定外の動作をさせるような攻撃への対策など。&lt;/p&gt;

&lt;p&gt;これから機械学習に取り組む人へ、以下のアドバイスをしていた。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;機械学習のアルゴリズムよりも、線形代数や確率といった数学の基礎を習得することが重要。&lt;/li&gt;
&lt;li&gt;AIの道を進むのに、近年では博士号は必ずしも要らない。コードを書いてGitHubに上げろ。自身も実際に、オープンソース活動をしているひとの貢献を見て興味をもって採用したことがある。&lt;/li&gt;
&lt;li&gt;論文を公開するとよりいいけど、コードのほうが楽。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;4週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;深いニューラルネットワーク&lt;/p&gt;

&lt;p&gt;3層以上のニューラルネットワーク。その実装方法と有効性について。
ハイパーパラメータ(Hyperparameters): 学習率(Learning rate)、学習回数、レイヤ数、ノード数、活性化関数、等。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ディープニューラルネットワークの実装。&lt;/li&gt;
&lt;li&gt;再度猫画像の判別。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CourseraのMachine Learningコースを修了した</title>
          <link>https://www.kaitoy.xyz/2017/12/22/coursera-machine-learning/</link>
          <pubDate>Fri, 22 Dec 2017 10:20:44 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/12/22/coursera-machine-learning/</guid>
          <description>

&lt;p&gt;機械学習の入門教材として有名な&lt;a href=&#34;https://www.coursera.org/learn/machine-learning&#34;&gt;CourseraのMachine Learningコース&lt;/a&gt;を修了した記念日記。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;courseraとは&#34;&gt;Courseraとは&lt;/h2&gt;

&lt;p&gt;Courseraは、2012年にスタンフォード大学のコンピュータ工学科の2人の教授によって設立されたサービスで、世界トップクラスの大学の講座をオンラインで受けることができるもの。
東京大学とも提携している。&lt;/p&gt;

&lt;p&gt;講座の一部は無料で受けることができる。&lt;/p&gt;

&lt;h2 id=&#34;courseraのmachine-learningコースとは&#34;&gt;CourseraのMachine Learningコースとは&lt;/h2&gt;

&lt;p&gt;Machine Learningコースは、Courseraの設立者の一人であるAndrew Ngによる、機械学習の基礎から実践まで浅く広く(?)学べる世界的に有名な講座。
Andrew先生は一時期Googleで働き、&lt;a href=&#34;https://en.wikipedia.org/wiki/Google_Brain&#34;&gt;Google Brain&lt;/a&gt;というDeep Learningのプロジェクトをリードしていたこともある機械学習のエキスパートで、さらにスタンフォードの教授だっただけあって教え方が非常にうまくてわかりやすい。&lt;/p&gt;

&lt;p&gt;この講座は主に、5分～15分くらいの動画による講義と、小テストと、プログラミング課題から構成されている。
1週間分の内容が、1.5時間分くらいの動画と、15分くらいでできる小テストと、2、3時間で終わるプログラミング課題で、全体で11週間分やれば修了できる。
1、10、11週目はプログラミング課題が無くてすぐ終わる一方、3～5週目辺りは結構ハード。&lt;/p&gt;

&lt;p&gt;私は2017/10/30に始めて、2017/12/19に完了したので、ちょうど50日かかったことになる。&lt;/p&gt;

&lt;p&gt;動画は当然英語だが、有志により英語や日本語の字幕が付けられてるので聞き取れなくても問題はあまりない。
ただ、1～4週目くらいまでは、日本語の字幕がずれている動画が少なくなく、それらは英語の字幕でみる必要がある。
1つだけ英語の字幕もダメなものがあって、それだけは字幕なしで見た。&lt;/p&gt;

&lt;p&gt;プログラミング課題は、&lt;a href=&#34;https://www.gnu.org/software/octave/&#34;&gt;Octave&lt;/a&gt;というオープンソースの数値解析言語で解く。
聞いたことない言語だったが、&lt;a href=&#34;https://jp.mathworks.com/programs/trials/trial_request.html?ref=ggl&amp;amp;s_eid=ppc_30300738322&amp;amp;q=matlab&#34;&gt;MATLAB&lt;/a&gt;との互換性維持を重視して開発されている言語なので、まあ覚えておいて損はない。
Octaveグラフ描画APIは、MATLABのグラフ描画APIをまねていて、MATLABのグラフ描画APIは、Pythonでよく使われるグラフ描画ライブラリである&lt;a href=&#34;https://matplotlib.org/&#34;&gt;Matplotlib&lt;/a&gt;がまねていて、つまりOctaveやってるとMatplotlibの勉強にもなる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以下、11週間分の内容を、キーワードレベルで書いておく。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;機械学習の概要&lt;/p&gt;

&lt;p&gt;背景、歴史、活用例。
教師あり学習(Supervised learning) vs 教師なし(Unsupervised learning)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;線形単回帰(Linear regression with one variable)&lt;/p&gt;

&lt;p&gt;仮説関数(Hypothesis)、目的関数(Cost function)、平均二乗誤差(Mean squared error)、最小二乗法(Least squares method)、最急降下法(Gradient descent)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;行列&lt;/p&gt;

&lt;p&gt;行列(Matrix)とベクトル(Vector)。
行列演算。
逆行列(Inverse)、転置行列(Transpose)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;線形重回帰(Linear regression with multiple variables)&lt;/p&gt;

&lt;p&gt;特徴量のスケーリング(Feature scaling)、平均正則化(Mean normalization)。
学習率(Learning rate)。
多項式回帰(Polynomial regression)。
正規方程式(Normal equation)、特異行列(singular matrix)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Octaveチュートリアル&lt;/p&gt;

&lt;p&gt;基本操作、データロード・セーブ、データ計算、描画、制御構文、ベクトル化。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;3週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ロジスティック回帰(Logistic regression)&lt;/p&gt;

&lt;p&gt;二値分類(Binary classification)。
シグモイド関数(Sigmoid function)。
決定境界(Decision boundary)。
共役勾配法(Conjugate gradient)、BFGS、L-BFGS。
多値分類(Multi-class classification)、1対その他(One-vs-all)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;過学習(Overfitting)&lt;/p&gt;

&lt;p&gt;正則化(Regularization)、未学習(Underfitting)。
バイアス(Bias)、バリアンス(Variance)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;4週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ニューラルネットワーク(Neural Network)&lt;/p&gt;

&lt;p&gt;入力層(Input layer)、隠れ層(Hidden layer)、出力層(Output layer)。
ユニット(Unit)、バイアスユニット(Bias unit)、重み(Weight)。
活性化関数(Activation function)。
順伝播(Forward propagation)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;5週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ニューラルネットワーク続き&lt;/p&gt;

&lt;p&gt;逆伝播(Backpropagation)。
Gradient checking。
対称性破壊(Symmetry breaking)、ランダム初期化(Random initialization)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;6週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;機械学習へのアドバイス&lt;/p&gt;

&lt;p&gt;訓練データ(Training set)、テストデータ(Test set)、交差検証データ(Cross-validation set)。
一般化エラー(Generalization error)。
高バイアス(High bias)、高バリアンス(High variance)。
学習曲線(Learning curve)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;機械学習システムの設計&lt;/p&gt;

&lt;p&gt;実装の優先度付け。
スパム分類器(Spam classifier)。
エラー分析(Error analysis)。
歪んだクラス(Skewed classes)。
真陽性(True positive)、偽陽性(False positive)、真陰性(True negative)、偽陰性(False negative)。
適合率(Precision)、再現率(Recall)、F値(F1 score)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;7週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;サポートベクタマシン(SVM: Support Vector Machine)&lt;/p&gt;

&lt;p&gt;マージン(Margin)。
線形カーネル(Linear kernel)、ガウスカーネル(Gaussian kernel)、多項式カーネル(Polynomial kernel)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;8週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;K平均法(K-means algorithm)&lt;/p&gt;

&lt;p&gt;クラスタリング(Clustering)。
ランダム初期化(Random initialization)、局所最適解(Local optima)。
エルボー法(Elbow method)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;主成分分析(PCA: Principal Component Analysis)&lt;/p&gt;

&lt;p&gt;データ圧縮(Data compression)、データ可視化(Data visualization)、次元削減(Dimensionality Reduction)、データ復元(Reconstruction from compressed representation)。
投影誤差(Projection error)、分散(Variance)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;9週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;異常検知(Anomaly detection)&lt;/p&gt;

&lt;p&gt;密度推定(Density estimation)。
ガウス分布(Gaussian distribution)、正規分布(Normal distribution)。
異常検知 vs 教師あり学習。
多変量ガウス分布(Multivariate gaussian distribution)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;レコメンダシステム(Recommender system)&lt;/p&gt;

&lt;p&gt;映画レーティング(Movie rating)。
コンテンツベース(Content-­based recommendation)、協調フィルタリング(Collaborative filtering)。
低ランク行列因子分解(Low-rank matrix factorization)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;10週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;大規模機械学習&lt;/p&gt;

&lt;p&gt;バッチ勾配降下法(Batch gradient descent)、確率的勾配降下法(Stochastic gradient descent)、ミニバッチ勾配降下法(Mini-batch gradient descent)。
オンライン学習(Online learning)。
Map­‐reduce、データ並列性(Data parallelism)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;11週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;写真OCR(Photo OCR)&lt;/p&gt;

&lt;p&gt;写真OCRパイプライン(Photo OCR pipeline)、テキスト検出(Text detection)、文字分割(character segmentation)、文字認識(character recognition)。
スライディングウィンドウ(Sliding window)。
人工データ合成(Artificial data synthesis)、歪曲収差(Distortion)。
天井分析(Ceiling analysis)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次は&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873117584/&#34;&gt;ゼロから作るDeep Learning&lt;/a&gt;かな。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetes 1.8のアクセス制御について。あとDashboard。</title>
          <link>https://www.kaitoy.xyz/2017/10/31/retry-dashboard-on-k8s-cluster-by-kubeadm/</link>
          <pubDate>Tue, 31 Oct 2017 16:57:04 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/10/31/retry-dashboard-on-k8s-cluster-by-kubeadm/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/21/build-kubernetes-cluster-by-kubeadm/&#34;&gt;Kubernetes1.8のクラスタを構築する。kubeadmで。&lt;/a&gt;」で、Dashboardがうまく動かない問題が発生したんだけど、それを解決した話。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;問題の現象&#34;&gt;問題の現象&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/kubeadm/&#34;&gt;kubeadm&lt;/a&gt;でKubernetesクラスタを組んで、自前のアプリ(&lt;a href=&#34;https://www.kaitoy.xyz/2016/12/11/goslings-development-memo0-intro-design/&#34;&gt;Goslings&lt;/a&gt;)のデプロイまではうまくできたんだけど、&lt;a href=&#34;https://github.com/kubernetes/dashboard&#34;&gt;Dashboard&lt;/a&gt;をデプロイしたら動かず、Web UIに&lt;code&gt;kubectl proxy&lt;/code&gt;経由でつないでもタイムアウトしてしまった。&lt;/p&gt;

&lt;h2 id=&#34;対策&#34;&gt;対策&lt;/h2&gt;

&lt;p&gt;なんとなく、クラスタ内部での名前解決には&lt;a href=&#34;https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/dns&#34;&gt;kube-dns&lt;/a&gt;によるDNSサービスが使われているっぽいので、&lt;code&gt;/etc/hosts&lt;/code&gt;に余計な事書いたのがいけなかったと思った。&lt;/p&gt;

&lt;p&gt;ので、&lt;code&gt;/etc/hosts&lt;/code&gt;からk8s-masterとk8s-nodeのエントリを削除してから、&lt;code&gt;kubeadm init&lt;/code&gt;からやり直してみた。&lt;/p&gt;

&lt;h2 id=&#34;結果&#34;&gt;結果&lt;/h2&gt;

&lt;p&gt;したらちゃんと動いた。&lt;/p&gt;

&lt;p&gt;VMのホストで&lt;code&gt;kubectl proxy&lt;/code&gt;して、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop&amp;gt;kubectl proxy
Starting to serve on 127.0.0.1:8001
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/&lt;/code&gt;にブラウザでつないだらサインイン画面が表示された。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/retry-dashboard-on-k8s-cluster-by-kubeadm/dashboard.png&#34; alt=&#34;dashboard&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Dashboardのサインイン処理はKubernetes(というかkube-apiserver)のそれに移譲している。
Dashboardはそこで認証されたユーザでクラスタのリソースにアクセスし、情報を取得して表示する。多分。&lt;/p&gt;

&lt;p&gt;Dashboardへのサインイン方法は&lt;a href=&#34;https://github.com/kubernetes/dashboard/wiki/Access-control&#34;&gt;いくつかある&lt;/a&gt;が、それらを理解するにはKubernetesのアクセス制御について学ぶことを推奨とあったのでちょっと&lt;a href=&#34;https://kubernetes.io/docs/admin/accessing-the-api/&#34;&gt;Kubernetesのドキュメント&lt;/a&gt;を読んだ。&lt;/p&gt;

&lt;h2 id=&#34;kubernetesのアクセス制御&#34;&gt;Kubernetesのアクセス制御&lt;/h2&gt;

&lt;p&gt;Kubernetesクラスタのエンドポイントはkube-apiserverであり、クラスタのリソースへのアクセス制御もkube-apiserverがやる。
クライアントとkube-apiserverとのTLSセッションが確立した後、HTTP層のデータを見てアクセス制御をするんだけど、その処理は&lt;a href=&#34;https://kubernetes.io/docs/admin/authentication/&#34;&gt;Authentication&lt;/a&gt;(認証)、&lt;a href=&#34;https://kubernetes.io/docs/admin/authorization/&#34;&gt;Authorization&lt;/a&gt;(認可)、&lt;a href=&#34;https://kubernetes.io/docs/admin/admission-controllers/&#34;&gt;Admission&lt;/a&gt;(許可)の三段階からなる。&lt;/p&gt;

&lt;h3 id=&#34;authentication&#34;&gt;Authentication&lt;/h3&gt;

&lt;p&gt;第一段階がAuthentication。
ここでは、kube-apiserverに仕込まれたAuthenticatorモジュールがユーザ認証をする。&lt;/p&gt;

&lt;p&gt;Kubernetesが認証するユーザには、Kubernetesが管理するService Accountと、クラスタ外部で管理される通常ユーザの二通りがある。
Service AccountはPodがkube-apiserverと話すためのユーザで、通常ユーザは主に人がkubectlとかでkube-apiserverと話すためのユーザ。(匿名で話すこともできる。)
前者はServiceAccountオブジェクトで定義されるけど、後者用のオブジェクトはない。&lt;/p&gt;

&lt;p&gt;ServiceAccountはNamespaceと関連付き(つまりnamespace毎にユニーク)、Secretに紐づく。
Secretオブジェクトはクレデンシャルのセットを定義し、Podにマウントされる。
ServiceAccountとSecretは、ふつうは自動で作られ、Podに割り当てられる。&lt;/p&gt;

&lt;p&gt;kube-apiserverには一つ以上のAuthenticatorモジュールを設定できて、どれかで認証できれば次の段階に進める。
認証失敗するとHTTPステータスコード401が返る。&lt;/p&gt;

&lt;p&gt;Authenticatorモジュールには以下のようなものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authentication/#x509-client-certs&#34;&gt;クライアント証明書&lt;/a&gt;: X.509のディジタル証明書を使うモジュール。kube-apiserver起動時に&lt;code&gt;--client-ca-file&lt;/code&gt;オプションで証明書ファイルを渡してやると有効になる。証明書のCommon Nameがユーザ名になり、Organizationがグループになる。クライアント側は、その証明書と対応する秘密鍵をクレデンシャルとして指定する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authentication/#putting-a-bearer-token-in-a-request&#34;&gt;Bearer Token&lt;/a&gt;: 無記名トークンを使うモジュール。kube-apiserver起動時に&lt;code&gt;--token-auth-file&lt;/code&gt;オプションでトークン情報を渡してやると有効になる。トークン情報はCSVで、「&lt;code&gt;token,user,uid,&amp;quot;group1,group2,group3&amp;quot;&lt;/code&gt;」という形式で書く。クライアント側は、トークン文字列をクレデンシャルとして指定する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authentication/#static-password-file&#34;&gt;ベーシック認証&lt;/a&gt;: ユーザ名とパスワードで認証するモジュール。kube-apiserver起動時に&lt;code&gt;--basic-auth-file&lt;/code&gt;オプションでユーザ名とパスワードのリストを渡してやると有効になる。このリストはCSVで、「&lt;code&gt;password,user,uid,&amp;quot;group1,group2,group3&amp;quot;&lt;/code&gt;」という形式で書く。クライアント側は、ユーザ名とパスワードをクレデンシャルとして指定する。HTTPクライアントの時はAuthorizationヘッダが使える。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authentication/#service-account-tokens&#34;&gt;Service Account Token&lt;/a&gt;: Service Accountを署名付きBearer Tokenで認証するモジュール。デフォルトで有効になる。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;このあたり、Qiitaの「&lt;a href=&#34;https://qiita.com/hiyosi/items/43465d4fc501c2044d01#x509-client-certs&#34;&gt;kubernetesがサポートする認証方法の全パターンを動かす&lt;/a&gt;」という記事をみると理解が深まる。&lt;/p&gt;

&lt;h3 id=&#34;authorization&#34;&gt;Authorization&lt;/h3&gt;

&lt;p&gt;Authenticationをパスすると、クライアントのユーザ(とグループ)が認証され、第二段階のAuthorizationモジュールの処理に移る。
ここでは、リクエストの内容(操作対象、操作種別(メソッド)等)を見て、それがユーザに許されたものなら認可する。
何を許すかは事前にクラスタにポリシーを定義しておく。&lt;/p&gt;

&lt;p&gt;kube-apiserver起動時に&lt;code&gt;--authorization-mode&lt;/code&gt;オプションで一つ以上のAuthenticatorモジュールを指定できて、どれかで認可されれば次の段階に進める。
さもなくばHTTPステータスコード403が返る。&lt;/p&gt;

&lt;p&gt;Authorizationモジュールには以下のようなものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authorization/node/&#34;&gt;Node&lt;/a&gt;: kubeletからのリクエストを認可する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authorization/abac/&#34;&gt;ABAC Mode&lt;/a&gt;: Attribute-based Access Control。リクエストに含まれる属性とPolicyオブジェクトを比較して、マッチするものがあれば認可。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authorization/rbac/&#34;&gt;RBAC Mode&lt;/a&gt;: Role-Based Access Control。RoleオブジェクトやClusterRoleオブジェクトでロールを作成し、アクセスできるリソースや許可する操作を定義して、RoleBindingオブジェクトやClusterRoleBindingオブジェクトでユーザ名やグループと紐づける。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authorization/webhook/&#34;&gt;Webhook Mode&lt;/a&gt;: リクエストの内容を示すSubjectAccessReviewオブジェクトをシリアライズしたJSONデータをHTTPでPOSTして、そのレスポンスによって認可可否を決める。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;admission-control&#34;&gt;Admission Control&lt;/h3&gt;

&lt;p&gt;Authorizationをパスすると、第三段階のAdmission Controlモジュールの処理に移る。
ここでは、オブジェクトの作成、削除、更新などのリクエストをインターセプトして、オブジェクトの永続化前にそのオブジェクトを確認して、永続化を許可するかを決める。
リクエストされたオブジェクトやそれに関連するオブジェクトを永続化前にいじって、デフォルト値を設定したりもできる。
読み取りリクエストの場合は実行されない。&lt;/p&gt;

&lt;p&gt;kube-apiserver起動時に&lt;code&gt;--admission-control&lt;/code&gt;オプションで複数のAdmission Controlモジュールを指定できて、全てが許可しないとリクエストが却下される。&lt;/p&gt;

&lt;p&gt;Admission Controlモジュールは色々あるんだけど、Kubernetes 1.6以降では&lt;code&gt;--admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,DefaultStorageClass,ResourceQuota,DefaultTolerationSeconds&lt;/code&gt;と指定するのが強く推奨されている。
ここで指定している&lt;a href=&#34;https://kubernetes.io/docs/admin/admission-controllers/#serviceaccount&#34;&gt;ServiceAccountモジュール&lt;/a&gt;は、kube-controller-managerに含まれるServiceAccountControllerとTokenControllerと協調し、Service Account周りの処理を&lt;a href=&#34;https://kubernetes.io/docs/admin/service-accounts-admin/#service-account-automation&#34;&gt;自動化&lt;/a&gt;してくれるもの。&lt;/p&gt;

&lt;p&gt;ServiceAccountControllerは、各Namespaceに&lt;code&gt;default&lt;/code&gt;という名前のService Accountを作る。&lt;/p&gt;

&lt;p&gt;ServiceAccountが作成されるとTokenControllerが動き、対応したSecretとトークンを生成して紐づける。&lt;/p&gt;

&lt;p&gt;ServiceAccountモジュールは、Podの作成や更新時に動き、以下の処理をする。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;PodにServiceAccountが設定されていなければ、&lt;code&gt;default&lt;/code&gt;を設定する。&lt;/li&gt;
&lt;li&gt;Podに設定されたServiceAccountが存在していることを確認し、存在していなければリクエストを却下する。&lt;/li&gt;
&lt;li&gt;PodがImagePullSecretsを含んでいなければ、ServiceAccountのImagePullSecretsをPodに追加する。&lt;/li&gt;
&lt;li&gt;トークンを含んだVolumeをPodに追加する。&lt;/li&gt;
&lt;li&gt;Pod内の各コンテナの&lt;code&gt;/var/run/secrets/kubernetes.io/serviceaccount&lt;/code&gt;にそのVolumeをマウントさせる。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;dashboardへbearer-tokenでサインイン&#34;&gt;DashboardへBearer Tokenでサインイン&lt;/h2&gt;

&lt;p&gt;Dashboardの話に戻る。
とりあえず&lt;a href=&#34;https://github.com/kubernetes/dashboard/wiki/Access-control#bearer-token&#34;&gt;Bearer Tokenでのサインイン&lt;/a&gt;を試す。&lt;/p&gt;

&lt;p&gt;クラスタにはデフォルトで色んなService Accountが作られていて、異なる権限を持っている。
そのいずれかのSecretのTokenを使ってDashboardへサインインできるらしい。&lt;/p&gt;

&lt;p&gt;以下のコマンドで&lt;code&gt;kube-system&lt;/code&gt;というNamespaceのSecretを一覧できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl -n kube-system get secret
NAME                                     TYPE                                  DATA      AGE
attachdetach-controller-token-skzmj      kubernetes.io/service-account-token   3         18m
bootstrap-signer-token-mhqfh             kubernetes.io/service-account-token   3         18m
bootstrap-token-2964e0                   bootstrap.kubernetes.io/token         7         18m
certificate-controller-token-fvrgm       kubernetes.io/service-account-token   3         18m
cronjob-controller-token-hmrdm           kubernetes.io/service-account-token   3         18m
daemon-set-controller-token-vqz85        kubernetes.io/service-account-token   3         18m
default-token-h987g                      kubernetes.io/service-account-token   3         18m
deployment-controller-token-86bp9        kubernetes.io/service-account-token   3         18m
disruption-controller-token-6mskg        kubernetes.io/service-account-token   3         18m
endpoint-controller-token-d4wz6          kubernetes.io/service-account-token   3         18m
generic-garbage-collector-token-smfgq    kubernetes.io/service-account-token   3         18m
horizontal-pod-autoscaler-token-wsbn9    kubernetes.io/service-account-token   3         18m
job-controller-token-fttt2               kubernetes.io/service-account-token   3         18m
kube-dns-token-sn5qq                     kubernetes.io/service-account-token   3         18m
kube-proxy-token-w96xd                   kubernetes.io/service-account-token   3         18m
kubernetes-dashboard-certs               Opaque                                2         7m
kubernetes-dashboard-key-holder          Opaque                                2         6m
kubernetes-dashboard-token-gtppc         kubernetes.io/service-account-token   3         7m
namespace-controller-token-5kksd         kubernetes.io/service-account-token   3         18m
node-controller-token-chpwt              kubernetes.io/service-account-token   3         18m
persistent-volume-binder-token-d5x49     kubernetes.io/service-account-token   3         18m
pod-garbage-collector-token-l8sct        kubernetes.io/service-account-token   3         18m
replicaset-controller-token-njjwr        kubernetes.io/service-account-token   3         18m
replication-controller-token-qrr5h       kubernetes.io/service-account-token   3         18m
resourcequota-controller-token-dznjm     kubernetes.io/service-account-token   3         18m
service-account-controller-token-99nh8   kubernetes.io/service-account-token   3         18m
service-controller-token-9cw7k           kubernetes.io/service-account-token   3         18m
statefulset-controller-token-8z8w9       kubernetes.io/service-account-token   3         18m
token-cleaner-token-cxbkc                kubernetes.io/service-account-token   3         18m
ttl-controller-token-k7gh7               kubernetes.io/service-account-token   3         18m
weave-net-token-lqdgm                    kubernetes.io/service-account-token   3         17m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、適当にそれっぽいSecret、&lt;code&gt;deployment-controller-token-86bp9&lt;/code&gt;を選んで、&lt;code&gt;kubectl describe&lt;/code&gt;したらTokenが見れた。
(Dataセクションの&lt;code&gt;token&lt;/code&gt;のとこ。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl -n kube-system describe secret deployment-controller-token-86bp9
Name:         deployment-controller-token-86bp9
Namespace:    kube-system
Labels:       &amp;lt;none&amp;gt;
Annotations:  kubernetes.io/service-account.name=deployment-controller
              kubernetes.io/service-account.uid=17fc5207-b627-11e7-9867-000c2938deae

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkZXBsb3ltZW50LWNvbnRyb2xsZXItdG9rZW4tODZicDkiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGVwbG95bWVudC1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMTdmYzUyMDctYjYyNy0xMWU3LTk4NjctMDAwYzI5MzhkZWFlIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRlcGxveW1lbnQtY29udHJvbGxlciJ9.ZGV9XDd-GQjAwRuLKpdsWL_dTeF0Mr_2gF117OW4BhEuLwPujnsfOuysAQ-DUtNOp1NHKGitlfxjh6fKo4tFsdwLVJWrRK6i4YH1Mm2No7Sheks7IQn1FnwSmr7yCuvjlHD2e4RpZH0wupOFoY7FHntilhOWbXTJzJzi7TozLX02EKbkVGAsvch3LZ6p8jmUH5hr8DdKc4jbmTRp86SOiFS4_-TJ3RtAHCxiioAuKzXm3-rAWdeGLLcKrM2pAFSAGaBNu8MO5BZlAi6h3Xt4x-8-1ZXs4mudtJiECvjB-XIwiwzhpq8wIPZvvQQ-f1khixOyk1RfIXRJhIE5Gqvi8g
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;サインイン画面でTokenを選択し、
この、&lt;code&gt;eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkZXBsb3ltZW50LWNvbnRyb2xsZXItdG9rZW4tODZicDkiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGVwbG95bWVudC1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMTdmYzUyMDctYjYyNy0xMWU3LTk4NjctMDAwYzI5MzhkZWFlIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRlcGxveW1lbnQtY29udHJvbGxlciJ9.ZGV9XDd-GQjAwRuLKpdsWL_dTeF0Mr_2gF117OW4BhEuLwPujnsfOuysAQ-DUtNOp1NHKGitlfxjh6fKo4tFsdwLVJWrRK6i4YH1Mm2No7Sheks7IQn1FnwSmr7yCuvjlHD2e4RpZH0wupOFoY7FHntilhOWbXTJzJzi7TozLX02EKbkVGAsvch3LZ6p8jmUH5hr8DdKc4jbmTRp86SOiFS4_-TJ3RtAHCxiioAuKzXm3-rAWdeGLLcKrM2pAFSAGaBNu8MO5BZlAi6h3Xt4x-8-1ZXs4mudtJiECvjB-XIwiwzhpq8wIPZvvQQ-f1khixOyk1RfIXRJhIE5Gqvi8g&lt;/code&gt;を入力したらサインインできて、GoslingsのDeploymentの情報が見れた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/retry-dashboard-on-k8s-cluster-by-kubeadm/deploy.png&#34; alt=&#34;deploy&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Podも見れる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/retry-dashboard-on-k8s-cluster-by-kubeadm/pods.png&#34; alt=&#34;pods&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;けどServiceは見れない。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/retry-dashboard-on-k8s-cluster-by-kubeadm/service.png&#34; alt=&#34;service&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;各画面でオレンジ色のワーニングも出ていて、&lt;code&gt;deployment-controller&lt;/code&gt;ユーザで見れる範囲はあまり広くないことが分かる。&lt;/p&gt;

&lt;h2 id=&#34;dashboardへadmin権限でサインイン&#34;&gt;DashboardへAdmin権限でサインイン&lt;/h2&gt;

&lt;p&gt;DashboardのPodのService Accountである&lt;code&gt;kubernetes-dashboard&lt;/code&gt;にAdmin権限を付けてやって、サインイン画面でSKIPを押すとなんでも見れるようになる。セキュリティリスクがあるので本番ではNG設定だけど。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;cluster-admin&lt;/code&gt;というClusterRoleがあって、これを&lt;code&gt;kubernetes-dashboard&lt;/code&gt;にバインドするClusterRoleBindingを作ってやればいい。&lt;/p&gt;

&lt;p&gt;ので、以下のようなYAMLファイルを書いて、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: kubernetes-dashboard
  labels:
    k8s-app: kubernetes-dashboard
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: kubernetes-dashboard
  namespace: kube-system
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;kubectl&lt;/code&gt;で投げる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop&amp;gt;kubectl create -f dashboard-admin.yml
clusterrolebinding &amp;quot;kubernetes-dashboard&amp;quot; created
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;したらServiceも見えるようになった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/retry-dashboard-on-k8s-cluster-by-kubeadm/service-admin.png&#34; alt=&#34;service-admin&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ついでにHWリソース情報も見れた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/retry-dashboard-on-k8s-cluster-by-kubeadm/resources.png&#34; alt=&#34;resources&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;満足した。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetes1.8のクラスタを構築する。kubeadmで。</title>
          <link>https://www.kaitoy.xyz/2017/10/21/build-kubernetes-cluster-by-kubeadm/</link>
          <pubDate>Sat, 21 Oct 2017 10:42:46 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/10/21/build-kubernetes-cluster-by-kubeadm/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/&#34;&gt;Kubernetes 1.8が出たので、Minikubeを触ってみる&lt;/a&gt;」でMinikubeをやったんだけど、もう一歩ステップアップすべく、&lt;a href=&#34;https://kubernetes.io/docs/admin/kubeadm/&#34;&gt;kubeadm&lt;/a&gt;でKubernetesクラスタを組んでみた話。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;kubeadmとは&#34;&gt;kubeadmとは&lt;/h2&gt;

&lt;p&gt;kubeadm(キューブアダム)はKubernetesに含まれるコマンドで、Kubernetesクラスタを簡単に構築するツール。
Kubernetes 1.4で追加され、Kubernetes 1.8の時点でまだベータで、本番環境には使わないでとなっている。
Qiitaの「&lt;a href=&#34;https://qiita.com/helix_kaz/items/9c4a83532f949d8a94ef&#34;&gt;kubeadmが何をやっているのかみてみた&lt;/a&gt;」という記事が、中でどんな動作をしてるかを解説していて参考になる。&lt;/p&gt;

&lt;p&gt;コマンドの使用感からすると、&lt;a href=&#34;https://docs.docker.com/engine/swarm/&#34;&gt;DockerのSwarmモード&lt;/a&gt;でのクラスタ構築の容易さをKubernetesに取り込むことを目指して開発されている気がした。&lt;/p&gt;

&lt;p&gt;ネットで見かけた評判だと、確かに簡単にクラスタ構築できて素晴らしいけど、TLSの証明書生成など、細かく制御できなくて困るところがあって、やはり本番に使えるレベルではないとのこと。&lt;/p&gt;

&lt;p&gt;まあとにかく試してみる価値はあろう。&lt;/p&gt;

&lt;h2 id=&#34;kubeadmインストール&#34;&gt;kubeadmインストール&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/setup/independent/install-kubeadm/&#34;&gt;Kubernetesのドキュメント&lt;/a&gt;に従ってkubeadmをインストールする。
バージョンは最新版の1.8.1。&lt;/p&gt;

&lt;h3 id=&#34;vm作成&#34;&gt;VM作成&lt;/h3&gt;

&lt;p&gt;kubeadmのサポートOSは、Ubuntu 16.04+、Debian 9、CentOS 7、RHEL 7、Fedora 25/26、HypriotOS v1.0.1+となっている。
慣れているCentOS 7を使うことにする。
(HypriotOSってなんだろう?)&lt;/p&gt;

&lt;p&gt;自前のノートPCのWindows 10 x64 Home Edition上のVMware Player 12のVMにCentOS 7を入れた。
メモリは1GB以上が要件なので、味を付けて1.4GBで。
VM間で通信できることって要件があったけど、インターネット接続も必要なはずなので、NICはNATのやつで。&lt;/p&gt;

&lt;p&gt;このVMはMasterになる。&lt;/p&gt;

&lt;h3 id=&#34;os設定&#34;&gt;OS設定&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/setup/independent/install-kubeadm/#check-required-ports&#34;&gt;Kubernetesが使うポート&lt;/a&gt;をいろいろ開けなければいけないんだけど、めんどいのでfirewalldを無効にする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@localhost ~]# systemctl stop firewalld
[root@localhost ~]# systemctl disable firewalld
Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.
Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;なんとなくIPアドレスをDHCPから静的割り当てに。(192.168.171.200)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# nmcli c modify ens33 ipv4.method manual
[root@k8s-master ~]# nmcli c modify ens33 ipv4.addresses 192.168.171.200/24
[root@k8s-master ~]# nmcli c modify ens33 ipv4.dns 192.168.171.2
[root@k8s-master ~]# nmcli c modify ens33 ipv4.gateway 192.168.171.2
[root@k8s-master ~]# systemctl restart network
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ホスト名をlocalhost.localdomainからk8s-masterに変更。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@localhost ~]# hostnamectl set-hostname k8s-master
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ログアウトログインで反映。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/etc/hosts&lt;/code&gt;を編集して、k8s-masterのエントリを追加。
あとで作るもう一つのVM、k8s-nodeのほうもエントリを追加。
(これはだめだったっぽい。詳細は後述。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;クラスタを構成するノードは、一意のMACアドレスとproduct_uuidを持っていないといけない。
Kubernetesがそれらでクラスタ内のノードを区別してるので。&lt;/p&gt;

&lt;p&gt;MACアドレスは&lt;code&gt;ip link&lt;/code&gt;コマンドなどで確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# ip link
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT qlen 1
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: ens33: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT qlen 1000
    link/ether 00:0c:29:38:de:ae brd ff:ff:ff:ff:ff:ff
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;product_uuidは、&lt;a href=&#34;https://ja.wikipedia.org/wiki/SMBIOS&#34;&gt;SMBIOS&lt;/a&gt;という、PC固有のデータを保存・参照するための仕様があって、それに従って保存されたシステムの識別子らしい。
product_uuidは&lt;code&gt;dmidecode&lt;/code&gt;コマンドなどで確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# dmidecode -s system-uuid
58114D56-A744-3610-C3C5-9B15A838DEAE
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;kubeletがちゃんと動くためにはswapを無効にする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# swapoff -a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(このコマンドはよくなかった。詳細は後述。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ebtablesとethtoolを入れる必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# yum install -y ebtables ethtool
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Dockerも入れないと。
v1.12が推奨で、v1.11かv1.13でもいい。
適当に入れたらv1.12.6だった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# yum install -y docker
[root@k8s-master ~]# systemctl enable docker &amp;amp;&amp;amp; systemctl start docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Podネットワークなどが機能する要件として、コンテナがホストファイルシステムにアクセスできる必要があるが、そのためには現状、SELinuxを無効化する必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# setenforce 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(このコマンドもよくなかった。詳細は後述。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;RHEL系の場合、iptablesがバイパスされてトラフィックが変にルーティングされる問題があるため、&lt;code&gt;net.bridge.bridge-nf-call-iptables&lt;/code&gt;を1にセットしておく必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# cat &amp;lt;&amp;lt;EOF &amp;gt;  /etc/sysctl.d/k8s.conf
&amp;gt; net.bridge.bridge-nf-call-ip6tables = 1
&amp;gt; net.bridge.bridge-nf-call-iptables = 1
&amp;gt; EOF
[root@k8s-master ~]# sysctl --system
* Applying /usr/lib/sysctl.d/00-system.conf ...
net.bridge.bridge-nf-call-ip6tables = 0
net.bridge.bridge-nf-call-iptables = 0
net.bridge.bridge-nf-call-arptables = 0
* Applying /usr/lib/sysctl.d/10-default-yama-scope.conf ...
kernel.yama.ptrace_scope = 0
* Applying /usr/lib/sysctl.d/50-default.conf ...
kernel.sysrq = 16
kernel.core_uses_pid = 1
net.ipv4.conf.default.rp_filter = 1
net.ipv4.conf.all.rp_filter = 1
net.ipv4.conf.default.accept_source_route = 0
net.ipv4.conf.all.accept_source_route = 0
net.ipv4.conf.default.promote_secondaries = 1
net.ipv4.conf.all.promote_secondaries = 1
fs.protected_hardlinks = 1
fs.protected_symlinks = 1
* Applying /usr/lib/sysctl.d/99-docker.conf ...
fs.may_detach_mounts = 1
* Applying /etc/sysctl.d/99-sysctl.conf ...
* Applying /etc/sysctl.d/k8s.conf ...
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
* Applying /etc/sysctl.conf ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Cgroup Driverを、Dockerとkubeletとの間で一致させておく必要がある。
以下のようにして確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# cat /etc/systemd/system/kubelet.service.d/10-kubeadm.conf | grep KUBELET_CGROUP_ARGS
Environment=&amp;quot;KUBELET_CGROUP_ARGS=--cgroup-driver=systemd&amp;quot;
ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_SYSTEM_PODS_ARGS $KUBELET_NETWORK_ARGS $KUBELET_DNS_ARGS $KUBELET_AUTHZ_ARGS $KUBELET_CADVISOR_ARGS $KUBELET_CGROUP_ARGS $KUBELET_CERTIFICATE_ARGS $KUBELET_EXTRA_ARGS
[root@k8s-master ~]# docker info |grep -i cgroup
 WARNING: Usage of loopback devices is strongly discouraged for production use. Use `--storage-opt dm.thinpooldev` to specify a custom block storage device.
Cgroup Driver: systemd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;どっちもsystemdだったので問題なし。
(違ってたら&lt;a href=&#34;https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#troubleshooting&#34;&gt;&lt;code&gt;KUBELET_CGROUP_ARGS&lt;/code&gt;を変更する必要がある&lt;/a&gt;。)&lt;/p&gt;

&lt;h3 id=&#34;kubelet-kubeadm-kubectlインストール&#34;&gt;kubelet、kubeadm、kubectlインストール&lt;/h3&gt;

&lt;p&gt;ここでやっとkubeadmのインストール。
kubeletとkubectlも一緒にインストールする。&lt;/p&gt;

&lt;p&gt;まずYUMリポジトリを追加して、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/yum.repos.d/kubernetes.repo
&amp;gt; [kubernetes]
&amp;gt; name=Kubernetes
&amp;gt; baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
&amp;gt; enabled=1
&amp;gt; gpgcheck=1
&amp;gt; repo_gpgcheck=1
&amp;gt; gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
&amp;gt;         https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
&amp;gt; EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;インストール。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# yum install kubelet kubeadm kubectl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、kubeletをサービス登録。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# systemctl enable kubelet &amp;amp;&amp;amp; systemctl start kubelet
Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /etc/systemd/system/kubelet.service.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ここでVMのスナップショットをとっておいて、後でNodeを追加するときに使う。&lt;/p&gt;

&lt;h2 id=&#34;master構築&#34;&gt;Master構築&lt;/h2&gt;

&lt;p&gt;Masterは&lt;code&gt;kubeadm init&lt;/code&gt;で構築できる。
&lt;code&gt;--apiserver-advertise-address&lt;/code&gt;でkube-apiserverがlistenするIPアドレスを指定すべし。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubeadm init --apiserver-advertise-address=192.168.171.200
[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
[init] Using Kubernetes version: v1.8.1
[init] Using Authorization modes: [Node RBAC]
[preflight] Running pre-flight checks
[preflight] WARNING: Running with swap on is not supported. Please disable swap or set kubelet&#39;s --fail-swap-on flag to false.
[kubeadm] WARNING: starting in 1.8, tokens expire after 24 hours by default (if you require a non-expiring token use --token-ttl 0)
[certificates] Generated ca certificate and key.
[certificates] Generated apiserver certificate and key.
[certificates] apiserver serving cert is signed for DNS names [k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.171.200]
[certificates] Generated apiserver-kubelet-client certificate and key.
[certificates] Generated sa key and public key.
[certificates] Generated front-proxy-ca certificate and key.
[certificates] Generated front-proxy-client certificate and key.
[certificates] Valid certificates and keys now exist in &amp;quot;/etc/kubernetes/pki&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;admin.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;kubelet.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;controller-manager.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;scheduler.conf&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-apiserver to &amp;quot;/etc/kubernetes/manifests/kube-apiserver.yaml&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-controller-manager to &amp;quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-scheduler to &amp;quot;/etc/kubernetes/manifests/kube-scheduler.yaml&amp;quot;
[etcd] Wrote Static Pod manifest for a local etcd instance to &amp;quot;/etc/kubernetes/manifests/etcd.yaml&amp;quot;
[init] Waiting for the kubelet to boot up the control plane as Static Pods from directory &amp;quot;/etc/kubernetes/manifests&amp;quot;
[init] This often takes around a minute; or longer if the control plane images have to be pulled.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz&#39; failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz&#39; failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz&#39; failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz/syncloop&#39; failed with error: Get http://localhost:10255/healthz/syncloop: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz/syncloop&#39; failed with error: Get http://localhost:10255/healthz/syncloop: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz/syncloop&#39; failed with error: Get http://localhost:10255/healthz/syncloop: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz&#39; failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz/syncloop&#39; failed with error: Get http://localhost:10255/healthz/syncloop: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz&#39; failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.

Unfortunately, an error has occurred:
        timed out waiting for the condition

This error is likely caused by that:
        - The kubelet is not running
        - The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)
        - There is no internet connection; so the kubelet can&#39;t pull the following control plane images:
                - gcr.io/google_containers/kube-apiserver-amd64:v1.8.1
                - gcr.io/google_containers/kube-controller-manager-amd64:v1.8.1
                - gcr.io/google_containers/kube-scheduler-amd64:v1.8.1

You can troubleshoot this for example with the following commands if you&#39;re on a systemd-powered system:
        - &#39;systemctl status kubelet&#39;
        - &#39;journalctl -xeu kubelet&#39;
couldn&#39;t initialize a Kubernetes cluster
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なんか失敗した。
&lt;code&gt;getsockopt: connection refused.&lt;/code&gt;ってのがたくさん出てる。
ググると、swapがあやしい。
確認してみたら、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# swapon -s
Filename                                Type            Size    Used    Priority
/dev/dm-1                               partition       2097148 0       -1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;無効になってない。
&lt;code&gt;swapoff -a&lt;/code&gt;でswap無効にしても、OS再起動したらもとに戻ってしまうのか。&lt;/p&gt;

&lt;p&gt;永続的に無効にするため、&lt;code&gt;/etc/fstab&lt;/code&gt;を編集して、以下の行を削除した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/dev/mapper/centos-swap swap                    swap    defaults        0 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、OSリブート。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;kubeadm initをやり直す前に、いったん&lt;code&gt;kubeadm reset&lt;/code&gt;して初期化する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubeadm reset
[preflight] Running pre-flight checks
[reset] Stopping the kubelet service
[reset] Unmounting mounted directories in &amp;quot;/var/lib/kubelet&amp;quot;
[reset] Removing kubernetes-managed containers
[reset] Deleting contents of stateful directories: [/var/lib/kubelet /etc/cni/net.d /var/lib/dockershim /var/run/kubernetes /var/lib/etcd]
[reset] Deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki]
[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;2回目の&lt;code&gt;kubeadm init&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubeadm init --apiserver-advertise-address=192.168.171.200
[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
[init] Using Kubernetes version: v1.8.1
[init] Using Authorization modes: [Node RBAC]
[preflight] Running pre-flight checks
[preflight] Starting the kubelet service
[kubeadm] WARNING: starting in 1.8, tokens expire after 24 hours by default (if you require a non-expiring token use --token-ttl 0)
[certificates] Generated ca certificate and key.
[certificates] Generated apiserver certificate and key.
[certificates] apiserver serving cert is signed for DNS names [k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.171.200]
[certificates] Generated apiserver-kubelet-client certificate and key.
[certificates] Generated sa key and public key.
[certificates] Generated front-proxy-ca certificate and key.
[certificates] Generated front-proxy-client certificate and key.
[certificates] Valid certificates and keys now exist in &amp;quot;/etc/kubernetes/pki&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;admin.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;kubelet.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;controller-manager.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;scheduler.conf&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-apiserver to &amp;quot;/etc/kubernetes/manifests/kube-apiserver.yaml&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-controller-manager to &amp;quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-scheduler to &amp;quot;/etc/kubernetes/manifests/kube-scheduler.yaml&amp;quot;
[etcd] Wrote Static Pod manifest for a local etcd instance to &amp;quot;/etc/kubernetes/manifests/etcd.yaml&amp;quot;
[init] Waiting for the kubelet to boot up the control plane as Static Pods from directory &amp;quot;/etc/kubernetes/manifests&amp;quot;
[init] This often takes around a minute; or longer if the control plane images have to be pulled.

Unfortunately, an error has occurred:
        timed out waiting for the condition

This error is likely caused by that:
        - The kubelet is not running
        - The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)
        - There is no internet connection; so the kubelet can&#39;t pull the following control plane images:
                - gcr.io/google_containers/kube-apiserver-amd64:v1.8.1
                - gcr.io/google_containers/kube-controller-manager-amd64:v1.8.1
                - gcr.io/google_containers/kube-scheduler-amd64:v1.8.1

You can troubleshoot this for example with the following commands if you&#39;re on a systemd-powered system:
        - &#39;systemctl status kubelet&#39;
        - &#39;journalctl -xeu kubelet&#39;
couldn&#39;t initialize a Kubernetes cluster
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また違う感じのエラー。
エラーメッセージに従って、&lt;code&gt;journalctl -xeu kubelet&lt;/code&gt;でログを見てみたら、以下のようなエラーが。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Post https://192.168.171.200:6443/api/v1/nodes: dial tcp 192.168.171.200:6443: getsockopt: connection refused
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/kubeadm/issues/228&#34;&gt;kubeadmにIssue&lt;/a&gt;にこのエラーが載っている。
原因はいろいろあるっぽいけど、そのひとつにSELinuxがあったので確認してみたら、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# getenforce
Enforcing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SELinuxが有効になっていた。
&lt;code&gt;setenforce 0&lt;/code&gt;もOS再起動で元に戻ってしまった模様。&lt;/p&gt;

&lt;p&gt;永続的にSELinuxを無効にするため、&lt;code&gt;/etc/selinux/config&lt;/code&gt;を編集して、&lt;code&gt;SELINUX&lt;/code&gt;を&lt;code&gt;disabled&lt;/code&gt;にして、OS再起動した。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、&lt;code&gt;kubeadm reset&lt;/code&gt;したら3回目の&lt;code&gt;kubeadm init&lt;/code&gt;する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubeadm init --apiserver-advertise-address=192.168.171.200
[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
[init] Using Kubernetes version: v1.8.1
[init] Using Authorization modes: [Node RBAC]
[preflight] Running pre-flight checks
[kubeadm] WARNING: starting in 1.8, tokens expire after 24 hours by default (if you require a non-expiring token use --token-ttl 0)
[certificates] Generated ca certificate and key.
[certificates] Generated apiserver certificate and key.
[certificates] apiserver serving cert is signed for DNS names [k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.171.200]
[certificates] Generated apiserver-kubelet-client certificate and key.
[certificates] Generated sa key and public key.
[certificates] Generated front-proxy-ca certificate and key.
[certificates] Generated front-proxy-client certificate and key.
[certificates] Valid certificates and keys now exist in &amp;quot;/etc/kubernetes/pki&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;admin.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;kubelet.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;controller-manager.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;scheduler.conf&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-apiserver to &amp;quot;/etc/kubernetes/manifests/kube-apiserver.yaml&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-controller-manager to &amp;quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-scheduler to &amp;quot;/etc/kubernetes/manifests/kube-scheduler.yaml&amp;quot;
[etcd] Wrote Static Pod manifest for a local etcd instance to &amp;quot;/etc/kubernetes/manifests/etcd.yaml&amp;quot;
[init] Waiting for the kubelet to boot up the control plane as Static Pods from directory &amp;quot;/etc/kubernetes/manifests&amp;quot;
[init] This often takes around a minute; or longer if the control plane images have to be pulled.
[apiclient] All control plane components are healthy after 99.510003 seconds
[uploadconfig]?Storing the configuration used in ConfigMap &amp;quot;kubeadm-config&amp;quot; in the &amp;quot;kube-system&amp;quot; Namespace
[markmaster] Will mark node k8s-master as master by adding a label and a taint
[markmaster] Master k8s-master tainted and labelled with key/value: node-role.kubernetes.io/master=&amp;quot;&amp;quot;
[bootstraptoken] Using token: 957b7b.eaaf0cb656edba7b
[bootstraptoken] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstraptoken] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstraptoken] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstraptoken] Creating the &amp;quot;cluster-info&amp;quot; ConfigMap in the &amp;quot;kube-public&amp;quot; namespace
[addons] Applied essential addon: kube-dns
[addons] Applied essential addon: kube-proxy

Your Kubernetes master has initialized successfully!

To start using your cluster, you need to run (as a regular user):

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run &amp;quot;kubectl apply -f [podnetwork].yaml&amp;quot; with one of the options listed at:
  http://kubernetes.io/docs/admin/addons/

You can now join any number of machines by running the following on each node
as root:

  kubeadm join --token 957b7b.eaaf0cb656edba7b 192.168.171.200:6443 --discovery-token-ca-cert-hash sha256:7d16ade2b651ebac573368b1b4db5c0f1236979584e61833efe90a96ff34ae2e
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できた。
このメッセージの最後に書かれたコマンドを、後でNodeを追加するときに使う。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;kubectlがこのVM上のkube-apiserverと話せるように、コンテキストを設定する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# mkdir -p $HOME/.kube
[root@k8s-master ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
[root@k8s-master ~]# chown $(id -u):$(id -g) $HOME/.kube/config
[root@k8s-master ~]# kubectl get nodes
NAME         STATUS     ROLES     AGE       VERSION
k8s-master   NotReady   master    16m       v1.8.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;podネットワークアドオンインストール&#34;&gt;Podネットワークアドオンインストール&lt;/h3&gt;

&lt;p&gt;Podネットワークはアプリのデプロイの前にセットアップしておく必要がある。&lt;/p&gt;

&lt;p&gt;多くの選択肢があるなか、有名な&lt;a href=&#34;https://github.com/coreos/flannel&#34;&gt;Flannel&lt;/a&gt;にしようと思ったけど、Flannelを使うには
&lt;code&gt;kubeadm init&lt;/code&gt;時に&lt;code&gt;--pod-network-cidr=10.244.0.0/16&lt;/code&gt;を渡さないといけなかった。
やり直すのは面倒なので代わりに&lt;a href=&#34;https://www.weave.works/docs/net/latest/kube-addon/&#34;&gt;Weave Net&lt;/a&gt;にする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# export kubever=$(kubectl version | base64 | tr -d &#39;\n&#39;)
[root@k8s-master ~]# kubectl apply -f &amp;quot;https://cloud.weave.works/k8s/net?k8s-version=$kubever&amp;quot;
serviceaccount &amp;quot;weave-net&amp;quot; created
clusterrole &amp;quot;weave-net&amp;quot; created
clusterrolebinding &amp;quot;weave-net&amp;quot; created
daemonset &amp;quot;weave-net&amp;quot; created
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これでPodネットワークアドオンインストール完了。
しばらくして、&lt;code&gt;kube-dns&lt;/code&gt;のPodが起動していれば(i.e. STATUSがRunningになってれば)OK。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubectl get pods --all-namespaces
NAMESPACE     NAME                                 READY     STATUS    RESTARTS   AGE
kube-system   etcd-k8s-master                      1/1       Running   0          1m
kube-system   kube-apiserver-k8s-master            1/1       Running   0          1m
kube-system   kube-controller-manager-k8s-master   1/1       Running   0          1m
kube-system   kube-dns-545bc4bfd4-xtlnh            3/3       Running   0          6m
kube-system   kube-proxy-922wk                     1/1       Running   0          6m
kube-system   kube-scheduler-k8s-master            1/1       Running   0          1m
kube-system   weave-net-s2kkw                      2/2       Running   0          2m
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;masterにpodをデプロイさせる設定&#34;&gt;MasterにPodをデプロイさせる設定&lt;/h3&gt;

&lt;p&gt;デフォルトでは、セキュリティの都合でMasterコンポーネントが動くNodeにはPodがデプロイされない。
けど、VM2個でPodを分散デプロイしてみたいので、この縛りを外しておく。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubectl taint nodes --all node-role.kubernetes.io/master-
node &amp;quot;k8s-master&amp;quot; untainted
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でMasterのセットアップは完了。&lt;/p&gt;

&lt;h2 id=&#34;node追加&#34;&gt;Node追加&lt;/h2&gt;

&lt;p&gt;次にNodeをひとつ追加する。&lt;/p&gt;

&lt;p&gt;k8s-masterで&lt;code&gt;kubeadm init&lt;/code&gt;するまえに撮ったスナップショットをクローンして、ホスト名とIPアドレスを変更し、これを追加するNodeのマシン(k8s-node)にする。
クローンしたらMACアドレスもproduct_uuidも変わったので、問題なく使えそう。&lt;/p&gt;

&lt;p&gt;k8s-nodeをクラスタに追加するには、このVM上で、&lt;code&gt;kubeadm init&lt;/code&gt;成功時のメッセージの最後に表示されたコマンド(i.e. &lt;code&gt;kubeadm join&lt;/code&gt;)を実行するだけ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-node ~]# kubeadm join --token 957b7b.eaaf0cb656edba7b 192.168.171.200:6443 --discovery-token-ca-cert-hash sha256:7d16ade2b651ebac573368b1b4db5c0f1236979584e61833efe90a96ff34ae2e
[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
[preflight] Running pre-flight checks
[discovery] Trying to connect to API Server &amp;quot;192.168.171.200:6443&amp;quot;
[discovery] Created cluster-info discovery client, requesting info from &amp;quot;https://192.168.171.200:6443&amp;quot;
[discovery] Requesting info from &amp;quot;https://192.168.171.200:6443&amp;quot; again to validate TLS against the pinned public key
[discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server &amp;quot;192.168.171.200:6443&amp;quot;
[discovery] Successfully established connection with API Server &amp;quot;192.168.171.200:6443&amp;quot;
[bootstrap] Detected server version: v1.8.1
[bootstrap] The server supports the Certificates API (certificates.k8s.io/v1beta1)

Node join complete:
* Certificate signing request sent to master and response
  received.
* Kubelet informed of new secure connection details.

Run &#39;kubectl get nodes&#39; on the master to see this machine join.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できた。
k8s-masterでNodeの状態を確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubectl get nodes
NAME         STATUS    ROLES     AGE       VERSION
k8s-master   Ready     master    42m       v1.8.1
k8s-node     Ready     &amp;lt;none&amp;gt;    45s       v1.8.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;k8s-masterもk8s-nodeもReady。&lt;/p&gt;

&lt;h2 id=&#34;vmホストのkubectlの設定&#34;&gt;VMホストのkubectlの設定&lt;/h2&gt;

&lt;p&gt;kubectlはkube-apiserverのWeb APIを呼ぶコマンドなので、接続先さえちゃんと設定すればMasterのマシン上でなくても使える。
VMのホスト(i.e. Windows 10 PC)で使えるようにしたい。&lt;/p&gt;

&lt;p&gt;kubectlの接続先情報は、&lt;code&gt;kubeadm init&lt;/code&gt;時に生成された&lt;code&gt;/etc/kubernetes/admin.conf&lt;/code&gt;に書かれているので、これをホストに持ってきてkubectlに渡してやればいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf get nodes
NAME         STATUS    ROLES     AGE       VERSION
k8s-master   Ready     master    51m       v1.8.1
k8s-node     Ready     &amp;lt;none&amp;gt;    10m       v1.8.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できた。&lt;/p&gt;

&lt;p&gt;admin.confを&lt;code&gt;%UserProfile%\.kube\&lt;/code&gt;の下に&lt;code&gt;config&lt;/code&gt;という名前で置いてやると、&lt;code&gt;--kubeconfig&lt;/code&gt;で指定しなくても読んでくれる。&lt;/p&gt;

&lt;h2 id=&#34;goslingsデプロイ&#34;&gt;Goslingsデプロイ&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/11/goslings-on-kubernetes-cont/#%E7%95%AA%E5%A4%96%E7%B7%A82-%E5%91%BD%E4%BB%A4%E7%9A%84%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E8%A8%AD%E5%AE%9A&#34;&gt;「Kubernetesのチュートリアルをやる」の番外編&lt;/a&gt;で作ったオブジェクト定義ファイルを使って、今回作ったクラスタに&lt;a href=&#34;https://www.kaitoy.xyz/2016/12/11/goslings-development-memo0-intro-design/&#34;&gt;Goslings&lt;/a&gt;をデプロイしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf create -f deploy_goslings.yml
deployment &amp;quot;goslings-sample&amp;quot; created

C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf create -f service_goslings.yml
service &amp;quot;goslings-sample&amp;quot; created

C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf get po -o wide
NAME                              READY     STATUS    RESTARTS   AGE       IP           NODE
goslings-sample-dfd84c69c-4mgh9   1/1       Running   0          12m       10.244.1.3   k8s-node
goslings-sample-dfd84c69c-cd5mm   1/1       Running   0          12m       10.244.0.3   k8s-master
goslings-sample-dfd84c69c-nwwh7   1/1       Running   0          12m       10.244.1.2   k8s-node

C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf get svc
NAME              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
goslings-sample   NodePort    10.109.174.204   &amp;lt;none&amp;gt;        8080:30004/TCP   7m
kubernetes        ClusterIP   10.96.0.1        &amp;lt;none&amp;gt;        443/TCP          1h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;普通にデプロイできた。
レプリカ3つがちゃんと2つのNodeに分散されてる。&lt;/p&gt;

&lt;p&gt;k8s-masterのIPアドレス( &lt;a href=&#34;http://192.168.171.200:30004/&#34;&gt;http://192.168.171.200:30004/&lt;/a&gt; )でもk8s-nodeのIPアドレス( &lt;a href=&#34;http://192.168.171.201:30004/&#34;&gt;http://192.168.171.201:30004/&lt;/a&gt; )でもGoslingsにつなげた。
普通はMasterのIPアドレスを使うらしい。
そりゃそうか。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/build-kubernetes-cluster-by-kubeadm/goslings.png&#34; alt=&#34;goslings&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;試しにk8s-nodeのVMを落としてみる。
k8s-node上のPodがk8s-masterに移動してくれることを期待してたけど、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf get po -o wide
NAME                              READY     STATUS    RESTARTS   AGE       IP           NODE
goslings-sample-dfd84c69c-4mgh9   1/1       Running   0          55m       10.244.1.3   k8s-node
goslings-sample-dfd84c69c-cd5mm   1/1       Running   0          55m       10.244.0.3   k8s-master
goslings-sample-dfd84c69c-nwwh7   1/1       Running   0          55m       10.244.1.2   k8s-node
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なんかk8s-nodeで動き続けていることになってる。&lt;/p&gt;

&lt;p&gt;クラスタうまく動いていないんだろうか…&lt;/p&gt;

&lt;h2 id=&#34;ダッシュボードデプロイ&#34;&gt;ダッシュボードデプロイ&lt;/h2&gt;

&lt;p&gt;Kubernetesクラスタの状態をWeb UIで確認できる、&lt;a href=&#34;https://github.com/kubernetes/dashboard&#34;&gt;Dashboard&lt;/a&gt;をデプロイしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml
secret &amp;quot;kubernetes-dashboard-certs&amp;quot; created
serviceaccount &amp;quot;kubernetes-dashboard&amp;quot; created
role &amp;quot;kubernetes-dashboard-minimal&amp;quot; created
rolebinding &amp;quot;kubernetes-dashboard-minimal&amp;quot; created
deployment &amp;quot;kubernetes-dashboard&amp;quot; created
service &amp;quot;kubernetes-dashboard&amp;quot; created
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できた。&lt;/p&gt;

&lt;p&gt;Dashboardが起動するまでしばらくまってから、&lt;code&gt;kubectl proxy&lt;/code&gt;して、
&lt;code&gt;http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/&lt;/code&gt;にブラウザでつなげばGUIが開くはずなんだけど、タイムアウトしてつながらなかった。&lt;/p&gt;

&lt;p&gt;クラスタうまく動いていないんだろうか…&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;NICがNATなのがだめだったかもと思い、ブリッジにしてみたけど同じ結果だった。
PodのフェールオーバーもしないしDashboardも開けない。&lt;/p&gt;

&lt;p&gt;ちゃんと一つ一つ自分で構築しないとよく分からないな。&lt;/p&gt;

&lt;p&gt;(後日&lt;a href=&#34;https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/&#34;&gt;全手動で構築した&lt;/a&gt;。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あとでふと思い立って、&lt;code&gt;/etd/hosts&lt;/code&gt;をいじったらDashboardは動いた。
それについてはまた&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/31/retry-dashboard-on-k8s-cluster-by-kubeadm/&#34;&gt;別の記事&lt;/a&gt;で。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetesのチュートリアルをやる</title>
          <link>https://www.kaitoy.xyz/2017/10/11/goslings-on-kubernetes-cont/</link>
          <pubDate>Wed, 11 Oct 2017 23:48:40 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/10/11/goslings-on-kubernetes-cont/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/&#34;&gt;Kubernetes 1.8が出たので、Minikubeを触ってみる&lt;/a&gt;」の続き。
Minikubeのセットアップまではできたので、&lt;a href=&#34;https://kubernetes.io/docs/tutorials/kubernetes-basics/&#34;&gt;Kubernetes Basics&lt;/a&gt;というチュートリアルをやりながら、&lt;a href=&#34;https://kaitoy.github.io/goslings/&#34;&gt;Goslings&lt;/a&gt;をデプロイする。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;kubernetes-basics-概要&#34;&gt;Kubernetes Basics - 概要&lt;/h2&gt;

&lt;p&gt;Kubernetes Basicsは、公式のチュートリアルで、Kubernetesクラスタのオーケストレーションの基本を学ぶことができるもの。
以下の6つのモジュールからなる。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Kubernetesクラスタを作る&lt;/li&gt;
&lt;li&gt;アプリをデプロイする&lt;/li&gt;
&lt;li&gt;アプリを調査する&lt;/li&gt;
&lt;li&gt;アプリを公開する&lt;/li&gt;
&lt;li&gt;アプリをスケールする&lt;/li&gt;
&lt;li&gt;アプリをアップデートする&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;チュートリアルで使うのは&lt;a href=&#34;https://github.com/kubernetes/minikube&#34;&gt;Minikube&lt;/a&gt;だけど、自分でセットアップする必要はない。
&lt;a href=&#34;https://www.katacoda.com/&#34;&gt;Katacoda&lt;/a&gt;という、ブラウザ上でIT技術を学べるプラットフォームがあり、Kubernetes Basicsはそれを利用して、ブラウザ上のターミナルからホステッドMinikubeを操作できるようにしている。&lt;/p&gt;

&lt;p&gt;が、&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/&#34;&gt;前回の記事&lt;/a&gt;で自PC上にMinikubeをセットアップしたので、そちらを使うことにする。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;kubernetes-basics-モジュール-1-kubernetesクラスタを作る&#34;&gt;Kubernetes Basics - モジュール 1: Kubernetesクラスタを作る&lt;/h2&gt;

&lt;p&gt;Minikubeを起動してkubectlでクラスタの状態をみるだけのモジュール。&lt;/p&gt;

&lt;p&gt;これは&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/&#34;&gt;前回の記事&lt;/a&gt;でカバーしている。&lt;/p&gt;

&lt;h2 id=&#34;kubernetes-basics-モジュール-2-アプリをデプロイする&#34;&gt;Kubernetes Basics - モジュール 2: アプリをデプロイする&lt;/h2&gt;

&lt;p&gt;アプリ(i.e. コンテナ)をデプロイするにはDeploymentオブジェクトを作る。
MasterはDeploymentのspecに従って各ノードにアプリのインスタンスをスケジューリングする。
Deploymentは、アプリが落ちたら再起動してくれる、つまりself-healingも実現する。&lt;/p&gt;

&lt;p&gt;Deploymentオブジェクトを作るコマンドは&lt;code&gt;kubectl run &amp;lt;オブジェクト名&amp;gt; --image=&amp;lt;Dockerイメージ名&amp;gt;&lt;/code&gt;。
Goslingsをこれでデプロイする。&lt;/p&gt;

&lt;p&gt;Goslingsコンテナは3つの引数を受け取り、指定したポートでWebサーバを起動する。
&lt;code&gt;--port&lt;/code&gt;オプションでそのポートをexposeするようにして、&lt;code&gt;--&lt;/code&gt;の後にコンテナに渡す引数を記述する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl run goslings --image=kaitoy/goslings:latest --port 8080 -- 8080 /tmp https://github.com/kaitoy/
deployment &amp;quot;goslings&amp;quot; created

C:\Users\kaitoy&amp;gt;kubectl get deployment
NAME       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
goslings   1         1         1            1           27s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;デプロイできた。
裏でPodも作られていて、アプリが起動されている。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get pods
NAME                        READY     STATUS              RESTARTS   AGE
goslings-1210510689-6w5tf   0/1       ContainerCreating   0          1m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(&lt;code&gt;kubectl get&lt;/code&gt;に指定するのは、省略形の&lt;code&gt;deploy&lt;/code&gt;とか&lt;code&gt;po&lt;/code&gt;でもいい。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Podは隔離されたネットワークで動くので、そのままではPod同士は通信できるけど、外からはアクセスできない。
kubectlでプロキシを作ってやることで、外からアクセスできるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl proxy
Starting to serve on 127.0.0.1:8001
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで、kube-apiserverへのプロキシがローカルホストで起動した。
この状態で&lt;code&gt;http://localhost:8001&lt;/code&gt;を開くと、kube-apiserverのAPI一覧が見れる。
例えば、&lt;code&gt;http://localhost:8001/version&lt;/code&gt;にアクセスすると、以下のJSONデータが返ってくる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;major&amp;quot;: &amp;quot;1&amp;quot;,
  &amp;quot;minor&amp;quot;: &amp;quot;7&amp;quot;,
  &amp;quot;gitVersion&amp;quot;: &amp;quot;v1.7.0&amp;quot;,
  &amp;quot;gitCommit&amp;quot;: &amp;quot;d3ada0119e776222f11ec7945e6d860061339aad&amp;quot;,
  &amp;quot;gitTreeState&amp;quot;: &amp;quot;dirty&amp;quot;,
  &amp;quot;buildDate&amp;quot;: &amp;quot;2017-10-04T09:25:40Z&amp;quot;,
  &amp;quot;goVersion&amp;quot;: &amp;quot;go1.8.3&amp;quot;,
  &amp;quot;compiler&amp;quot;: &amp;quot;gc&amp;quot;,
  &amp;quot;platform&amp;quot;: &amp;quot;linux/amd64&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;各Podへも以下のURLでアクセスできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://localhost:8001/api/v1/proxy/namespaces/default/pods/&amp;lt;Pod名&amp;gt;/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Pod名の部分は&lt;code&gt;kubectl get&lt;/code&gt;で確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get po
NAME                        READY     STATUS    RESTARTS   AGE
goslings-1210510689-6w5tf   1/1       Running   0          24m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実際に、&lt;code&gt;http://localhost:8001/api/v1/proxy/namespaces/default/pods/goslings-1210510689-6w5tf/&lt;/code&gt;をブラウザで開いたら、GoslingsのGUIが出た。
ヒュー。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-on-kubernetes-cont/goslings-proxy.png&#34; alt=&#34;goslings-proxy&#34; /&gt;
&lt;/p&gt;

&lt;h2 id=&#34;kubernetes-basics-モジュール-3-アプリを調査する&#34;&gt;Kubernetes Basics - モジュール 3: アプリを調査する&lt;/h2&gt;

&lt;p&gt;以下のコマンドで、アプリの状態を調査するモジュール。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;kubectl get: リソースをリスト表示する。&lt;/li&gt;
&lt;li&gt;kubectl describe: リソースの詳細情報を表示する。&lt;/li&gt;
&lt;li&gt;kubectl logs: コンテナのログを表示する。&lt;code&gt;docker logs&lt;/code&gt;的な。&lt;/li&gt;
&lt;li&gt;kubectl exec: コンテナ内でコマンドを実行する。&lt;code&gt;docker exec&lt;/code&gt;的な。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl get&lt;/code&gt;はさんざんやったので飛ばして、&lt;code&gt;kubectl describe&lt;/code&gt;してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl describe po
Name:           goslings-1210510689-6w5tf
Namespace:      default
Node:           minikube/192.168.99.100
Start Time:     Tue, 10 Oct 2017 21:51:48 +0900
Labels:         pod-template-hash=1210510689
                run=goslings
Annotations:    kubernetes.io/created-by={&amp;quot;kind&amp;quot;:&amp;quot;SerializedReference&amp;quot;,&amp;quot;apiVersion&amp;quot;:&amp;quot;v1&amp;quot;,&amp;quot;reference&amp;quot;:{&amp;quot;kind&amp;quot;:&amp;quot;ReplicaSet&amp;quot;,&amp;quot;namespace&amp;quot;:&amp;quot;default&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;goslings-1210510689&amp;quot;,&amp;quot;uid&amp;quot;:&amp;quot;c74b6518-adb9-11e7-88a0-08002798178d...
Status:         Running
IP:             172.17.0.2
Created By:     ReplicaSet/goslings-1210510689
Controlled By:  ReplicaSet/goslings-1210510689
Containers:
  goslings:
    Container ID:       docker://ce90460886c9555f7748bf59e8d9892f05c05020e7841154ee85713d6d9b0c2d
    Image:              kaitoy/goslings:latest
    Image ID:           docker-pullable://kaitoy/goslings@sha256:a587e3c5f202cdaa6d4d5a9c4f6a01ba6f4782e00277c3a18c77dd034daa0109
    Port:               8080/TCP
    Args:
      8080
      C:/Users/kaitoy/AppData/Local/Temp
    State:              Running
      Started:          Tue, 10 Oct 2017 21:55:54 +0900
    Ready:              True
    Restart Count:      0
    Environment:        &amp;lt;none&amp;gt;
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-cqq59 (ro)
Conditions:
  Type          Status
  Initialized   True
  Ready         True
  PodScheduled  True
Volumes:
  default-token-cqq59:
    Type:       Secret (a volume populated by a Secret)
    SecretName: default-token-cqq59
    Optional:   false
QoS Class:      BestEffort
Node-Selectors: &amp;lt;none&amp;gt;
Tolerations:    &amp;lt;none&amp;gt;
Events:
  FirstSeen     LastSeen        Count   From                    SubObjectPath                   Type            Reason
                Message
  ---------     --------        -----   ----                    -------------                   --------        ------
                -------
  45m           45m             1       default-scheduler                                       Normal          Scheduled               Successfully assigned goslings-1210510689-6w5tf to minikube
  45m           45m             1       kubelet, minikube                                       Normal          SuccessfulMountVolume   MountVolume.SetUp succeeded for volume &amp;quot;default-token-cqq59&amp;quot;
  45m           45m             1       kubelet, minikube       spec.containers{goslings}       Normal          Pulling
                pulling image &amp;quot;kaitoy/goslings:latest&amp;quot;
  41m           41m             1       kubelet, minikube       spec.containers{goslings}       Normal          Pulled
                Successfully pulled image &amp;quot;kaitoy/goslings:latest&amp;quot;
  41m           41m             1       kubelet, minikube       spec.containers{goslings}       Normal          Created
                Created container
  41m           41m             1       kubelet, minikube       spec.containers{goslings}       Normal          Started
                Started container
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Podの詳細な情報が出た。
EventsのとこにKubernetesの頑張りが見えて面白い。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次は&lt;code&gt;kubectl logs&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl logs goslings-1210510689-6w5tf

  .   ____          _            __ _ _
 /\\ / ___&#39;_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | &#39;_ | &#39;_| | &#39;_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  &#39;  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v1.4.3.RELEASE)

2017-10-10 12:56:02.498  INFO 6 --- [           main] c.g.kaitoy.goslings.server.Application   : Starting Application on goslings-1210510689-6w5tf with PID 6 (/usr/local/src/goslings/goslings-server/build/libs/goslings-server-0.0.1.jar started by root in /usr/local/src/goslings)
(snip)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Goslingsは&lt;a href=&#34;https://projects.spring.io/spring-boot/&#34;&gt;Spring Boot&lt;/a&gt;でできてるので、そのログが出てる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次は&lt;code&gt;kubectl exec&lt;/code&gt;を試す。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl exec goslings-1210510689-6w5tf env
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=goslings-1210510689-6w5tf
KUBERNETES_PORT_443_TCP=tcp://10.0.0.1:443
KUBERNETES_PORT_443_TCP_PROTO=tcp
KUBERNETES_PORT_443_TCP_PORT=443
KUBERNETES_PORT_443_TCP_ADDR=10.0.0.1
KUBERNETES_SERVICE_HOST=10.0.0.1
KUBERNETES_SERVICE_PORT=443
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBERNETES_PORT=tcp://10.0.0.1:443
LANG=C.UTF-8
JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
JAVA_VERSION=8u111
JAVA_DEBIAN_VERSION=8u111-b14-2~bpo8+1
CA_CERTIFICATES_JAVA_VERSION=20140324
HOME=/root
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;env&lt;/code&gt;コマンドを実行し、コンテナ内の環境変数一覧を出せた。
Kubernetes関係の変数が定義されていることが分かる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker exec&lt;/code&gt;と同様に、&lt;code&gt;-it&lt;/code&gt;オプションを付ければ、コンテナ内に「入る」こともできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl exec -it goslings-1210510689-6w5tf sh
# ls
Dockerfile  _config.yml  build.log     goslings-server  gradle.properties  gradlew.bat
# exit

C:\Users\kaitoy&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;kubernetes-basics-モジュール-4-アプリを公開する&#34;&gt;Kubernetes Basics - モジュール 4: アプリを公開する&lt;/h2&gt;

&lt;p&gt;Serviceオブジェクト扱うモジュール。&lt;/p&gt;

&lt;p&gt;例えば、以下のような状況にあるとする。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;PodがあるNodeで動いていたんだけど、そのNodeが死んだので、Kubernetesが別のNodeにPodを起動しなおしてくれた。&lt;/li&gt;
&lt;li&gt;同じコンテナイメージを3つのPodで動かして、負荷分散させたい。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;こういう場合、KubernetesはPod毎に固有のIPアドレスを割り当てるので、Podにアクセスするユーザはアクセス先が不安定でめんどいことになる。
この問題を解決してくれるのがServiceで、こいつは、Podを抽象化して、安定したIPアドレスを公開してくれる。
しかもそれはクラスタ外からアクセスできる。&lt;/p&gt;

&lt;p&gt;PodとServiceの紐づけには、&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/&#34;&gt;ラベルとセレクタ&lt;/a&gt;というものが使われる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Serviceの情報はDeploymentとかと同様に&lt;code&gt;kubectl get&lt;/code&gt;で見れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get svc
NAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   10.0.0.1     &amp;lt;none&amp;gt;        443/TCP   1d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここで出ているkubernetesというのは、Minikubeがデフォルトで作るService。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Serviceオブジェクトは、&lt;code&gt;kubectl expose&lt;/code&gt;で作ることができる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;goslings&lt;/code&gt;という名のDeploymentに対し、NodePortのServiceを作り、コンテナの8080ポートを公開するコマンドは以下のようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl expose deploy/goslings --type=NodePort --port 8080
service &amp;quot;goslings&amp;quot; exposed

C:\Users\kaitoy&amp;gt;kubectl get services
NAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE
goslings     10.0.0.69    &amp;lt;nodes&amp;gt;       8080:32406/TCP   11s
kubernetes   10.0.0.1     &amp;lt;none&amp;gt;        443/TCP          1d

C:\Users\kaitoy&amp;gt;kubectl describe services/goslings
Name:                   goslings
Namespace:              default
Labels:                 run=goslings
Annotations:            &amp;lt;none&amp;gt;
Selector:               run=goslings
Type:                   NodePort
IP:                     10.0.0.69
Port:                   &amp;lt;unset&amp;gt; 8080/TCP
NodePort:               &amp;lt;unset&amp;gt; 32406/TCP
Endpoints:              172.17.0.2:8080
Session Affinity:       None
Events:                 &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;goslingsという名前のServiceができた。
上記&lt;code&gt;kubectl describe&lt;/code&gt;の出力のNodePortのとこに書いてあるのが外部にさらされたポート。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;minikube ip&lt;/code&gt;を実行すると、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube ip
192.168.99.100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;MinikubeのVMのIPアドレスも分かるので、NodePortのポートと合わせて、&lt;code&gt;http://192.168.99.100:32406&lt;/code&gt;にブラウザでアクセスしたら、GoslingsのGUI見れた。
ヒュー。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-on-kubernetes-cont/goslings-service.png&#34; alt=&#34;goslings-service&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ところで、上記&lt;code&gt;kubectl describe&lt;/code&gt;の出力を見ると、特に指定はしなかったが、Podに&lt;code&gt;run=goslings&lt;/code&gt;というLabelが付いていることが分かる。
Serviceのdescribeを見ると、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl describe svc goslings
Name:                   goslings
Namespace:              default
Labels:                 run=goslings
Annotations:            &amp;lt;none&amp;gt;
Selector:               run=goslings
Type:                   NodePort
IP:                     10.0.0.69
Port:                   &amp;lt;unset&amp;gt; 8080/TCP
NodePort:               &amp;lt;unset&amp;gt; 32406/TCP
Endpoints:              172.17.0.2:8080
Session Affinity:       None
Events:                 &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;run=goslings&lt;/code&gt;というSelectorがServiceに紐づいている。
つまり、ServiceとPodが、&lt;code&gt;run=goslings&lt;/code&gt;で紐づいているというわけだ。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Labelはクエリ時のフィルタとかにも使える。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get po -l run=goslings
NAME                        READY     STATUS    RESTARTS   AGE
goslings-1210510689-6w5tf   1/1       Running   0          1h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;後からラベル付けることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl label pod goslings-1210510689-6w5tf ver=1.2.3
pod &amp;quot;goslings-1210510689-6w5tf&amp;quot; labeled
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;kubernetes-basics-モジュール-5-アプリをスケールする&#34;&gt;Kubernetes Basics - モジュール 5: アプリをスケールする&lt;/h2&gt;

&lt;p&gt;アプリのスケールアウト・スケールインを学ぶモジュール。&lt;/p&gt;

&lt;p&gt;Deploymentの定義でPodのレプリカ数を変えると、その数に合わせてKubernetesがPodを起動したり止めたりしてくれてスケールできる仕組み。
レプリカを作っておくとローリングアップデートできるのも利点。
&lt;a href=&#34;http://kubernetes.io/docs/user-guide/horizontal-pod-autoscaling/&#34;&gt;オートスケール機能&lt;/a&gt;もあるけど、それはチュートリアルでは扱われない。&lt;/p&gt;

&lt;p&gt;複数のPodで負荷分散するということなので、Serviceでロードバランシングするのが前提。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;現在のDeploymentの状態をみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get deploy
NAME       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
goslings   1         1         1            1           1h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Podのレプリカ数は、期待してる(DESIRED)のが1で、今(CURRENT)も1。&lt;/p&gt;

&lt;p&gt;スケールアウトするには、&lt;code&gt;kubectl scale&lt;/code&gt;コマンドでレプリカ数を増やしてやる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl scale deploy/goslings --replicas=3
deployment &amp;quot;goslings&amp;quot; scaled

C:\Users\kaitoy&amp;gt;kubectl get deploy
NAME       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
goslings   3         3         3            3           1h

C:\Users\kaitoy&amp;gt;kubectl get po -o wide
NAME                       READY     STATUS    RESTARTS   AGE       IP           NODE
goslings-442066424-jn1lw   1/1       Running   0          1h        172.17.0.2   minikube
goslings-442066424-rdw4k   1/1       Running   0          1m        172.17.0.3   minikube
goslings-442066424-rwwjw   1/1       Running   0          1m        172.17.0.4   minikube
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;レプリカが3個になった。&lt;/p&gt;

&lt;p&gt;スケールインするには、&lt;code&gt;kubectl scale&lt;/code&gt;コマンドでレプリカ数を減らす。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl scale deploy/goslings --replicas=2
deployment &amp;quot;goslings&amp;quot; scaled

C:\Users\kaitoy&amp;gt;kubectl get po
NAME                       READY     STATUS        RESTARTS   AGE
goslings-442066424-0mv4x   1/1       Terminating   0          1m
goslings-442066424-34h1f   1/1       Running       0          1m
goslings-442066424-kmn3p   1/1       Running       0          17m

C:\Users\kaitoy&amp;gt;kubectl get po
NAME                       READY     STATUS    RESTARTS   AGE
goslings-442066424-34h1f   1/1       Running   0          1m
goslings-442066424-kmn3p   1/1       Running   0          17m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;kubectl scale&lt;/code&gt;直後の&lt;code&gt;kubectl get po&lt;/code&gt;では、一つのPodを停止している最中の様子が見えていて、再度の&lt;code&gt;kubectl get po&lt;/code&gt;ではレプリカが2個になったのが確認できた。&lt;/p&gt;

&lt;p&gt;この状態がKubernetes Basicsで作るクラスタの最終形で、図にすると以下の感じ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-on-kubernetes-cont/objects.png&#34; alt=&#34;objects&#34; /&gt;
&lt;/p&gt;

&lt;h2 id=&#34;kubernetes-basics-モジュール-6-アプリをアップデートする&#34;&gt;Kubernetes Basics - モジュール 6: アプリをアップデートする&lt;/h2&gt;

&lt;p&gt;デプロイしたアプリのアップデート(i.e. コンテナイメージの変更)を学ぶモジュール。&lt;/p&gt;

&lt;p&gt;Deploymentの定義をいじってコンテナイメージを変えてやると、その中のPodを新しいイメージで順次(デフォルトだと一つ一つ)起動しなおしてくれる。&lt;/p&gt;

&lt;p&gt;アプリのアップデートはバージョン管理もされて、ロールバックもできる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;コンテナイメージを変更するには、&lt;code&gt;kubectl set image&lt;/code&gt;コマンドを使う。
&lt;code&gt;goslings&lt;/code&gt;という名のDeployment内の、&lt;code&gt;goslings&lt;/code&gt;という名のContainerのイメージを&lt;code&gt;kaitoy/goslings:hoge&lt;/code&gt;に変更するコマンドは以下。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl set image deploy/goslings goslings=kaitoy/goslings:hoge
deployment &amp;quot;goslings&amp;quot; image updated
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実際には&lt;code&gt;kaitoy/goslings:hoge&lt;/code&gt;というイメージはないので、イメージのPullに失敗したというエラー(ErrImagePull)になる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get po
NAME                       READY     STATUS         RESTARTS   AGE
goslings-274047280-jxmmh   0/1       ErrImagePull   0          9s
goslings-274047280-rgg2v   0/1       ErrImagePull   0          8s
goslings-442066424-34h1f   1/1       Terminating    0          1h
goslings-442066424-kmn3p   1/1       Running        0          1h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;イメージ変更前に戻すには、&lt;code&gt;kubectl rollout undo&lt;/code&gt;する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl rollout undo deploy/goslings
deployment &amp;quot;goslings&amp;quot; rolled back

C:\Users\kaitoy&amp;gt;kubectl rollout status deploy/goslings
deployment &amp;quot;goslings&amp;quot; successfully rolled out

C:\Users\kaitoy&amp;gt;kubectl get po
NAME                       READY     STATUS    RESTARTS   AGE
goslings-442066424-kmn3p   1/1       Running   0          1h
goslings-442066424-m3873   1/1       Running   0          5s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;無事に戻った。&lt;/p&gt;

&lt;h2 id=&#34;番外編1-3つのオブジェクト管理手法&#34;&gt;番外編1 - 3つのオブジェクト管理手法&lt;/h2&gt;

&lt;p&gt;Kubernetesオブジェクトを管理する手法は&lt;a href=&#34;https://kubernetes.io/docs/tutorials/object-management-kubectl/object-management/&#34;&gt;大きく3つある&lt;/a&gt;。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;管理手法&lt;/th&gt;
&lt;th&gt;いじる対象&lt;/th&gt;
&lt;th&gt;難易度&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;命令的コマンド&lt;/td&gt;
&lt;td&gt;生のオブジェクト&lt;/td&gt;
&lt;td&gt;簡単&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;命令的オブジェクト設定&lt;/td&gt;
&lt;td&gt;個々のファイル&lt;/td&gt;
&lt;td&gt;普通&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;宣言的オブジェクト設定&lt;/td&gt;
&lt;td&gt;ディレクトリに入ったファイル群&lt;/td&gt;
&lt;td&gt;難しい&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Kubernetes Basicsでやってた手法は一番上の命令的コマンド。
これは簡単で分かりやすい。
けど、何度も同じようなデプロイするならコマンドを毎回打つのが面倒だし、作成されるオブジェクトは明示的じゃないし、変更管理もできない。
この手法は主に開発中に使う。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;二つ目の手法の命令的オブジェクト設定では、YAML(かJSON)ファイルにオブジェクト定義を書いておいて、kubectlに渡す。
この手法だと、定義ファイルをオブジェクトのテンプレートとして使えるし、Gitとかのリポジトリに入れることでバージョン管理・変更管理できる。
けど、Kubernetesのオブジェクトモデルを理解しないと使えない。
(オブジェクト定義の詳細は&lt;a href=&#34;https://kubernetes.io/docs/api-reference/v1.8/&#34;&gt;APIリファレンス&lt;/a&gt;を参照。)&lt;/p&gt;

&lt;p&gt;命令的オブジェクト設定は以下のような形でやる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ kubectl create -f nginx.yaml
$ kubectl delete -f nginx.yaml -f redis.yaml
$ kubectl replace -f nginx.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;三つ目の手法の宣言的オブジェクト設定では、設定フォルダに定義ファイル群を置く。
ユーザは明示的にcreateとかupdateとか指示する必要が無く、kubectlが勝手に判断してくれる。
生のオブジェクトを直接いじった後、同じオブジェクトの設定を設定ファイルで変更しても、
両者の変更が上手くマージされる。&lt;/p&gt;

&lt;p&gt;なんかすごいけど、上手くいかなかったときのデバッグがむずい。&lt;/p&gt;

&lt;p&gt;宣言的オブジェクト設定は以下のような形でやる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ kubectl apply -R -f configs/
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;番外編2-命令的オブジェクト設定&#34;&gt;番外編2 - 命令的オブジェクト設定&lt;/h2&gt;

&lt;p&gt;3つの手法の内、命令的オブジェクト設定でGoslingsをMinikubeにデプロイしてみる。&lt;/p&gt;

&lt;p&gt;まず、Kubernetes Basicsで作ったオブジェクトを消すため、MinikubeのVMを作り直す。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube stop
Stopping local Kubernetes cluster...
Machine stopped.

C:\Users\kaitoy&amp;gt;minikube delete
Deleting local Kubernetes cluster...
Machine deleted.

C:\Users\kaitoy&amp;gt;minikube start --vm-driver virtualbox --kubernetes-version v1.7.0
Starting local Kubernetes v1.7.0 cluster...
Starting VM...
Getting VM IP address...
Moving files into cluster...
Setting up certs...
Connecting to cluster...
Setting up kubeconfig...
Starting cluster components...
Kubectl is now configured to use the cluster.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次に定義ファイルを書いていく。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://v1-7.docs.kubernetes.io/docs/api-reference/v1.7/#deployment-v1beta1-apps&#34;&gt;APIリファレンスのDeploymentのとこ&lt;/a&gt;をみると、Kubernetes Basicsの最終形と同じようなDeploymentを作る定義は以下のように書ける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: goslings-sample
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: goslings
        ver: latest
    spec:
      containers:
        - name: goslings
          image: kaitoy/goslings:latest
          ports:
            - name: http
              containerPort: 8080
          args:
            - &#39;8080&#39;
            - /tmp
            - https://github.com/kaitoy/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同様に、Serviceは、&lt;a href=&#34;https://v1-7.docs.kubernetes.io/docs/api-reference/v1.7/#service-v1-core&#34;&gt;APIリファレンスのServiceのとこ&lt;/a&gt;みると以下のように書ける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;kind: Service
apiVersion: v1
metadata:
  name: goslings-sample
spec:
  ports:
    - name: http
      port: 8080
      targetPort: 8080
  selector:
    app: goslings
  type: NodePort
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、それぞれのYAMLファイルを&lt;code&gt;kubectl create&lt;/code&gt;に渡してやると、Goslingsデプロイ完了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\kubeTest&amp;gt;kubectl create -f deploy_goslings.yml
deployment &amp;quot;goslings-sample&amp;quot; created

C:\Users\kaitoy\kubeTest&amp;gt;kubectl create -f service_goslings.yml
service &amp;quot;goslings-sample&amp;quot; created
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;オブジェクトの種類もパラメータも大量にあるので、使いこなすのは難しそう。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetes 1.8が出たので、Minikubeを触ってみる</title>
          <link>https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/</link>
          <pubDate>Tue, 10 Oct 2017 00:10:59 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt;1.8のリリースが話題になっていたので、ちょっと触って見たという話。
(1.8を触ったとは言っていない。)&lt;/p&gt;

&lt;p&gt;具体的には、&lt;a href=&#34;https://kubernetes.io/docs/tutorials/kubernetes-basics/&#34;&gt;Kubernetes Basics&lt;/a&gt;というチュートリアルをやりながら、&lt;a href=&#34;https://github.com/kubernetes/minikube&#34;&gt;Minikube&lt;/a&gt;に&lt;a href=&#34;https://kaitoy.github.io/goslings/&#34;&gt;Goslings&lt;/a&gt;をデプロイしたんだけど、この記事ではMinikubeをセットアップしたところまで。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;kubernetesとは&#34;&gt;Kubernetesとは&lt;/h2&gt;

&lt;p&gt;KubernetesはOSSのコンテナオーケストレーションツール。
英語だとクーバネティスみたいに発音する。
Googleが自身のコンテナ技術である&lt;a href=&#34;https://research.google.com/pubs/pub43438.html&#34;&gt;Borg&lt;/a&gt;の運用で培ったノウハウを活かして開発したもの。
2014年ころに開発が始まり、2015年夏にv1がリリースされたということで、かなり新しいツール。
よく比べられるものには&lt;a href=&#34;https://docs.docker.com/engine/swarm/&#34;&gt;DockerのSwarmモード&lt;/a&gt;や&lt;a href=&#34;http://mesos.apache.org/&#34;&gt;Apache Mesos&lt;/a&gt;があるが、何が違うのかは調べてないので知らない。
ただ、Dockerコンテナ管理ツールとしてはKubernetesが一番勢いがある雰囲気を感じる。&lt;/p&gt;

&lt;p&gt;(2017/10/18追記: &lt;a href=&#34;http://www.publickey1.jp/blog/17/dockerkubernetesdockercon_eu_2017.html&#34;&gt;DockerがKubernetesとの統合を発表&lt;/a&gt;した。KubernetesはDockerネイティブなツールになり、Dockerとともにインストールされ、Docker ComposeのConposeファイルでデプロイできるようになったりする。Kubernetesの大勝利っぽい。)&lt;/p&gt;

&lt;p&gt;Kubernetesを使うと、複数の物理マシンからなるHAクラスタ(Kubernetesクラスタ)を構成し、その上にコンテナをデプロイして管理できる。
Kubernetesクラスタは、一組のMasterコンポーネント群(a.k.a. Kubernetes Control Plane、または単にMaster)と一つ以上のNode(昔はMinionと呼ばれてたもの)で構成される。
Nodeは、Masterの管理下でコンテナを実行する機能を備えた、一台のVMや物理マシン。
MasterはNode上で動き、クラスタを管理し、コンテナのスケジューリング、状態管理、スケーリング、アップデートなどを担う。&lt;/p&gt;

&lt;p&gt;Kubernetesの&lt;a href=&#34;https://github.com/kubernetes/community/blob/master/contributors/design-proposals/architecture/architecture.md&#34;&gt;アーキテクチャ&lt;/a&gt;を図にすると以下の感じ。
矢印の向きとかはちょっと間違ってるかも。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-on-kubernetes/architecture.png&#34; alt=&#34;architecture&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;ごちゃごちゃするので省いたけど、図の下部のNode内のコンポーネントは、他のNode内でも動いている。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Masterには&lt;a href=&#34;https://kubernetes.io/docs/admin/kube-apiserver/&#34;&gt;kube-apiserver&lt;/a&gt;が含まれていて、&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/kubernetes-api/&#34;&gt;Kubernetes API&lt;/a&gt;というREST APIを公開する。
このAPIを通して&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/&#34;&gt;Kubernetesオブジェクト&lt;/a&gt;を定義したりすることで、宣言的にコンテナの管理ができる仕組み。
ユーザは普通、&lt;a href=&#34;https://kubernetes.io/docs/user-guide/kubectl/&#34;&gt;kubectl&lt;/a&gt;(キューブシーティーエル)というコマンドでkube-apiserverとやり取りする。&lt;/p&gt;

&lt;p&gt;KubernetesオブジェクトはMasterの&lt;a href=&#34;https://github.com/coreos/etcd&#34;&gt;etcd&lt;/a&gt;によって分散キーバリューストアに永続化され、そのストアを&lt;a href=&#34;https://kubernetes.io/docs/admin/kube-controller-manager/&#34;&gt;kube-controller-manager&lt;/a&gt;と&lt;a href=&#34;https://kubernetes.io/docs/admin/kube-scheduler/&#34;&gt;kube-scheduler&lt;/a&gt;が(kube-apiserver経由で)watchしてて、変更に応じた処理をする。&lt;/p&gt;

&lt;p&gt;kube-controller-managerは、ノードの管理や、オブジェクトのライフサイクルの管理や、コンテナのスケーリングなど、クラスタレベルの機能を実行する。
(よくわからない。)&lt;/p&gt;

&lt;p&gt;kube-schedulerは、コンテナを実行するホストを選出し、コンテナのスケジューリングをする。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;一方、各Nodeでは、&lt;a href=&#34;https://kubernetes.io/docs/admin/kubelet/&#34;&gt;kubelet&lt;/a&gt;(キューブレット)というMasterのエージェントになるプロセスが動く。&lt;/p&gt;

&lt;p&gt;kubeletはkube-apiserverからの指示で、コンテナイメージを取得してコンテナを起動したり監視したり止めたりする。&lt;/p&gt;

&lt;p&gt;kubeletがコンテナを扱うためのコンテナランタイムは、普通は&lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt;だけど、&lt;a href=&#34;https://coreos.com/rkt/&#34;&gt;rkt&lt;/a&gt;とか&lt;a href=&#34;https://github.com/kubernetes-incubator/cri-o&#34;&gt;cri-o&lt;/a&gt;とか&lt;a href=&#34;https://github.com/kubernetes/frakti&#34;&gt;frakti&lt;/a&gt;とかも使える。&lt;a href=&#34;https://github.com/opencontainers/runc&#34;&gt;runc&lt;/a&gt;や&lt;a href=&#34;https://github.com/oracle/railcar&#34;&gt;RailCar&lt;/a&gt;はどうなんだろう。&lt;/p&gt;

&lt;p&gt;コンテナはデフォルトではクラスタ内のプライベートネットワークにつながるので、そこで動いているアプリにユーザからアクセスするには、何らかの形でトラフィックを中継してやる必要がある。
これをするのが&lt;a href=&#34;https://kubernetes.io/docs/admin/kube-proxy/&#34;&gt;kube-proxy&lt;/a&gt;。
ロードバランシングもしてくれる。&lt;/p&gt;

&lt;h2 id=&#34;kubernetesオブジェクトとは&#34;&gt;Kubernetesオブジェクトとは&lt;/h2&gt;

&lt;p&gt;Kubernetesオブジェクトは、Kubernetesクラスタ上で機能する構成要素を表現するもの。
オブジェクトは&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/#object-spec-and-status&#34;&gt;specとstatus&lt;/a&gt;を持ち、オブジェクトに期待する状態やふるまい(spec)を定義しておくと、Kubernetesが実際の状態(status)をそれに合わせてくれる。
宣言的。&lt;/p&gt;

&lt;p&gt;オブジェクトには以下のようなものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/&#34;&gt;Pod&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;デプロイの最小単位。
一つ(またはリソースを共有する複数)のコンテナと、ストレージ、ネットワークなどを内包する。
一つのPodには一つのIPアドレスが付く。&lt;/p&gt;

&lt;p&gt;kubeletはPodの定義に従ってコンテナを起動する。&lt;/p&gt;

&lt;p&gt;因みに、etcd以外のMasterコンポーネントもPodとしてデプロイされる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/&#34;&gt;Service&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Podの論理グループ。
PodのIPアドレスは外部に公開されないので、外とのやり取りをするためにServiceがある。
kube-proxyはこいつの定義に従って働く。&lt;/p&gt;

&lt;p&gt;Serviceには複数のEndpoint(i.e. Pod等)が紐づき、外部からのトラフィックをラウンドロビンでルーティングするので、冗長化やロードバランサ的な働きもする。
ServiceはPodを抽象化するので、Podが死んだり入れ替わったりしても外に影響が見えにくくなる。&lt;/p&gt;

&lt;p&gt;Serviceには以下のtypeがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ClusterIP (デフォルト): Kubernetesクラスタ内からだけアクセスできる内部IPアドレスだけをもつ。&lt;/li&gt;
&lt;li&gt;NodePort: ClusterIPの拡張。内部IPアドレスに加え、クラスタ外からアクセスできるポートを一つ持つ。&lt;/li&gt;
&lt;li&gt;LoadBalancer: NodePortの拡張。外部ロードバランサを作って、固定の外部IPアドレスを付けて、内部IPアドレスへルーティングする。&lt;/li&gt;
&lt;li&gt;ExternalName: 抽象名をもつサービス。Kubernetes DNS serverで名前解決する。&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/&#34;&gt;詳細&lt;/a&gt;は読んでないので知らない。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/volumes/&#34;&gt;Volume&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;永続化やPod内でのファイル共有のためのオブジェクト。
Podとともに作られ、Podとともに破棄される。
実態はファイルシステム上のディレクトリ。
hostPathとか、nfsとか、awsElasticBlockStoreとかの種類があるらしい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/&#34;&gt;Namespace&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;仮想クラスタを表すオブジェクト。
これを定義すると、ひとつの物理クラスタを複数の仮想クラスタに分割できる。
大規模ユーザ・プロジェクト向け機能。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Controller&lt;/p&gt;

&lt;p&gt;Podを管理するオブジェクト。レプリケーションしたり、スケーリングや自動再起動したり。&lt;/p&gt;

&lt;p&gt;以下のようなものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&#34;&gt;Deployment&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Podのデプロイを管理するオブジェクト。
PodとReplicaSetの宣言的な生成・更新を実現する。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/&#34;&gt;ReplicaSet&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;指定した数のPodのレプリカを維持してくれる。
基本はDeploymentから作られて、Podの作成・削除・更新をオーケストレイトする。
&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller/&#34;&gt;ReplicationController&lt;/a&gt;というのもあるけど、今はReplicaSetが推奨。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/&#34;&gt;StatefulSet&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ステートフルなアプリを管理するオブジェクト。
現時点でのKubernetes最新版の1.8でまだベータ。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/&#34;&gt;DaemonSet&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;全てのノードで動くアプリを実現するオブジェクト。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/&#34;&gt;Job&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ジョブを表すオブジェクト。
指定された回数、Podを成功で完了させる。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;オブジェクトには&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/&#34;&gt;ラベル&lt;/a&gt;というキーバリューな属性を付けることができ、PodとServiceの紐づけや、オブジェクト検索時のフィルタとかに使える。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今回Goslingsを動かすのに使ったのは、Pod、Deployment、ReplicaSet、Service (NodePort)。&lt;/p&gt;

&lt;h2 id=&#34;podネットワーク&#34;&gt;Podネットワーク&lt;/h2&gt;

&lt;p&gt;ちょっと細かい話だけど、Pod間の通信はどうなっているかという話についてちょっと調べたのでざっくり書いておく。&lt;/p&gt;

&lt;p&gt;普通の&lt;a href=&#34;https://www.kaitoy.xyz/2015/07/25/how-to-capture-packets-on-a-local-network-with-pcap4j-container/#docker-network&#34;&gt;Dockerネットワーク&lt;/a&gt;だと、コンテナはdocker0という仮想ブリッジ上のプライベートネットワークで動くため、同じホスト上のコンテナ間は通信できるけど、別のホスト上のコンテナ通信させたい場合は、ホストのIPアドレスのポートを割り当ててやらなければいけない。&lt;/p&gt;

&lt;p&gt;これはめんどいので、Kubernetesは、各Podに一意なIPアドレスを与え、Podがどのホストにいるかにかかわらず、NAT無しで相互に通信できる&lt;a href=&#34;https://kubernetes.io/docs/concepts/cluster-administration/networking/&#34;&gt;ネットワーク&lt;/a&gt;を提供する。
これがPodネットワークとか呼ばれ、その仕様は&lt;a href=&#34;https://github.com/containernetworking/cni&#34;&gt;CNI&lt;/a&gt;でオープンに定められていて、以下のような実装がある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.projectcalico.org/v2.6/getting-started/kubernetes/installation/hosted/kubeadm/&#34;&gt;Calico&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/projectcalico/canal/tree/master/k8s-install&#34;&gt;Canal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/coreos/flannel&#34;&gt;Flannel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudnativelabs/kube-router/blob/master/Documentation/kubeadm.md&#34;&gt;Kube-router&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/romana/romana/tree/master/containerize#using-kubeadm&#34;&gt;Romana&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.weave.works/docs/net/latest/kube-addon/&#34;&gt;Weave Net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;minikubeとは&#34;&gt;Minikubeとは&lt;/h2&gt;

&lt;p&gt;Kubernetesクラスタを構築する方法は&lt;a href=&#34;https://kubernetes.io/docs/setup/pick-right-solution/&#34;&gt;いくつかある&lt;/a&gt;が、中でももっとも簡単な方法がMinikube。&lt;/p&gt;

&lt;p&gt;Minikubeは、単一NodeのKubernetesクラスタを詰めたVMをダウンロードして起動して、ローカルのkubectlから使えるようにしてくれるツール。
Linux、Windows、OS Xで動き、開発やテスト用途のKubernetes環境として使われる。&lt;/p&gt;

&lt;p&gt;ちょっと&lt;a href=&#34;https://www.vagrantup.com/&#34;&gt;Vagrant&lt;/a&gt;っぽい感じ。Kubernetes専用の。&lt;/p&gt;

&lt;h2 id=&#34;minikubeインストール&#34;&gt;Minikubeインストール&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-minikube/&#34;&gt;Kubernetesのドキュメント&lt;/a&gt;にしたがって、Minikubeをインストールする。
環境はWindows 10 Home x64。&lt;/p&gt;

&lt;p&gt;まず、MinikubeのVMを動かす仮想化ツールを入れる。
今のところMinikubeがサポートしてるのは、Windowsだと&lt;a href=&#34;https://www.virtualbox.org/&#34;&gt;VirtualBox&lt;/a&gt;か&lt;a href=&#34;https://docs.microsoft.com/ja-jp/virtualization/hyper-v-on-windows/quick-start/enable-hyper-v&#34;&gt;Hyper-V&lt;/a&gt;。
Windows 10 HomeだとHyper-Vが使えないので、VirtualBox一択。
VirtualBoxは、適当にVT-xを有効にして(してあった)、インストーラダウンロードしてインストールしただけ。
バージョンは5.1.28。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次に、minikubeコマンドを入れる。
このコマンドはGoで書かれていて、各プラットフォーム用にビルドされたバイナリがGitHubのプロジェクトページの&lt;a href=&#34;https://github.com/kubernetes/minikube/releases&#34;&gt;Releases&lt;/a&gt;に上がってるので、ダウンロードしてPathの通ったとこに置くだけ。
今回ダウンロードしたのはv0.22.2のminikube-windows-amd64で、これをminikube.exeにリネームして配置した。&lt;/p&gt;

&lt;p&gt;で、minikubeがサポートしているKubernetesのバージョンを調べると、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube get-k8s-versions
The following Kubernetes versions are available:
        - v1.7.5
        - v1.7.4
        - v1.7.3
        - v1.7.2
        - v1.7.0
        (snip)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1.8はまだサポートされていない…&lt;/p&gt;

&lt;p&gt;1.7.5が最新なのでそれでやることにする。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ということで、kubectlの1.7.5をインストールする。
kubectlもGoで書かれているので、以下のアドレスからWindowsバイナリをダウンロードしてPathの通ったところに置くだけ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;https://storage.googleapis.com/kubernetes-release/release/v1.7.5/bin/windows/amd64/kubectl.exe
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でMinikubeの環境ができた。
簡単。&lt;/p&gt;

&lt;h2 id=&#34;minikube起動&#34;&gt;Minikube起動&lt;/h2&gt;

&lt;p&gt;Minikubeは、&lt;code&gt;minikube start&lt;/code&gt;で起動することができ、Minikubeが起動したらすぐにKubernetesをいじれるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube start --vm-driver virtualbox --kubernetes-version v1.7.5
Starting local Kubernetes v1.7.5 cluster...
Starting VM...
Downloading Minikube ISO
 106.37 MB / 106.37 MB [============================================] 100.00% 0s
Getting VM IP address...
Moving files into cluster...
Setting up certs...
Connecting to cluster...
Setting up kubeconfig...
Starting cluster components...
Kubectl is now configured to use the cluster.

C:\Users\kaitoy&amp;gt;minikube status
minikube: Running
cluster: Running
kubectl: Correctly Configured: pointing to minikube-vm at 192.168.99.100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;起動した。
VirtualBoxのGUIを見ると、minikubeというVMが起動しているのが分かる。
この中でKubernetesクラスタが動いているはずだ。&lt;/p&gt;

&lt;p&gt;このVMには、&lt;code&gt;minikube ssh&lt;/code&gt;でログインできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube ssh
                         _             _
            _         _ ( )           ( )
  ___ ___  (_)  ___  (_)| |/&#39;)  _   _ | |_      __
/&#39; _ ` _ `\| |/&#39; _ `\| || , &amp;lt;  ( ) ( )| &#39;_`\  /&#39;__`\
| ( ) ( ) || || ( ) || || |\`\ | (_) || |_) )(  ___/
(_) (_) (_)(_)(_) (_)(_)(_) (_)`\___/&#39;(_,__/&#39;`\____)

$ uname -a
Linux minikube 4.9.13 #1 SMP Fri Sep 15 23:35:16 UTC 2017 x86_64 GNU/Linux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;すごくVagrantっぽい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Minikubeを起動すると、kubectlのコンテキストがminikubeというものに設定され、kubectlコマンドの接続先がMinikubeのKubernetesになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl config current-context
minikube
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、kubectlでクラスタの状態とかを見てみようと思ったら、なんか様子が変。
なしのつぶて。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get nodes
Unable to connect to the server: dial tcp 192.168.99.100:8443: connectex: No connection could be made because the target machine actively refused it.

C:\Users\kaitoy&amp;gt;kubectl cluster-info dump
Unable to connect to the server: dial tcp 192.168.99.100:8443: connectex: No connection could be made because the target machine actively refused it.

C:\Users\kaitoy&amp;gt;minikube dashboard
Could not find finalized endpoint being pointed to by kubernetes-dashboard: Error validating service: Error getting service kubernetes-dashboard: Get https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kubernetes-dashboard: dial tcp 192.168.99.100:8443: connectex: No connection could be made because the target machine actively refused it.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再度&lt;code&gt;minikube status&lt;/code&gt;してみたら、クラスタが落ちていた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube status
minikube: Running
cluster: Stopped
kubectl: Correctly Configured: pointing to minikube-vm at 192.168.99.100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;minikube logs&lt;/code&gt;でログを見てみると、エラーがたくさん出ていた。
以下のようなログが最初のほうに出てたので、認証系がだめで、サービス間でやり取りができなかったんじゃないかという感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Oct 04 23:08:43 minikube localkube[2783]: W1004 23:08:43.599396    2783 authentication.go:368] AnonymousAuth is not allowed with the AllowAll authorizer.  Resetting AnonymousAuth to false. You should use a different authorizer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;エラーの原因はよくわからないので、Kubernetesのバージョンをちょっと古いの(1.7.0)変えてみる。&lt;/p&gt;

&lt;p&gt;kubectlの1.7.0をPathに置いて、Minikubeを1.7.0で再起動する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube stop
Stopping local Kubernetes cluster...
Machine stopped.

C:\Users\kaitoy&amp;gt;minikube start --vm-driver virtualbox --kubernetes-version v1.7.0
Starting local Kubernetes v1.7.0 cluster...
Starting VM...
Getting VM IP address...
Kubernetes version downgrade is not supported. Using version: v1.7.5
Moving files into cluster...
Setting up certs...
Connecting to cluster...
Setting up kubeconfig...
Starting cluster components...
Kubectl is now configured to use the cluster.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kubernetesのダウングレードはサポートされてないと言われた。
ので一回VMを消してからやりなおす。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube stop
Stopping local Kubernetes cluster...
Machine stopped.

C:\Users\kaitoy&amp;gt;minikube delete
Deleting local Kubernetes cluster...
Machine deleted.

C:\Users\kaitoy&amp;gt;minikube start --vm-driver virtualbox --kubernetes-version v1.7.0
Starting local Kubernetes v1.7.0 cluster...
Starting VM...
Getting VM IP address...
Moving files into cluster...
Setting up certs...
Connecting to cluster...
Setting up kubeconfig...
Starting cluster components...
Kubectl is now configured to use the cluster.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1.7.0で動いた。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;様子はどうか。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop\bin\pleiades\workspace\blog&amp;gt;minikube status
minikube: Running
cluster: Running
kubectl: Correctly Configured: pointing to minikube-vm at 192.168.99.100

C:\Users\kaitoy\Desktop\bin\pleiades\workspace\blog&amp;gt;kubectl get nodes
NAME       STATUS    AGE       VERSION
minikube   Ready     22s       v1.7.0

C:\Users\kaitoy\Desktop\bin\pleiades\workspace\blog&amp;gt;kubectl version
Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;7&amp;quot;, GitVersion:&amp;quot;v1.7.0&amp;quot;, GitCommit:&amp;quot;d3ada0119e776222f11ec7945e6d860061339aad&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, BuildDate:&amp;quot;2017-06-29T23:15:59Z&amp;quot;, GoVersion:&amp;quot;go1.8.3&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;windows/amd64&amp;quot;}
Server Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;7&amp;quot;, GitVersion:&amp;quot;v1.7.0&amp;quot;, GitCommit:&amp;quot;d3ada0119e776222f11ec7945e6d860061339aad&amp;quot;, GitTreeState:&amp;quot;dirty&amp;quot;, BuildDate:&amp;quot;2017-10-04T09:25:40Z&amp;quot;, GoVersion:&amp;quot;go1.8.3&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;linux/amd64&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちゃんと動いているっぽい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ダッシュボードだけはなぜか相変わらず開けないけどまあいいか。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube dashboard
Could not find finalized endpoint being pointed to by kubernetes-dashboard: Error validating service: Error getting service kubernetes-dashboard: services &amp;quot;kubernetes-dashboard&amp;quot; not found
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;続きはまた&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/11/goslings-on-kubernetes-cont/&#34;&gt;別の記事&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;因みに、ベーシック認証ありのプロキシ環境でMinikube on Windowsする場合は、まず以下の環境変数を設定:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;NO_PROXY&lt;/code&gt;: 192.168.99.100&lt;/li&gt;
&lt;li&gt;&lt;code&gt;http_proxy&lt;/code&gt;: username:password@domain.com:port&lt;/li&gt;
&lt;li&gt;&lt;code&gt;https_proxy&lt;/code&gt;: username:password@domain.com:port&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;NO_PROXY&lt;/code&gt;の値は&lt;code&gt;minikube ip&lt;/code&gt;の値。
で、&lt;/p&gt;

&lt;p&gt;&lt;code&gt;minikube start --docker-env HTTP_PROXY=http://%http_proxy% --docker-env HTTPS_PROXY=https://%https_proxy% --docker-env NO_PROXY=%NO_PROXY%&lt;/code&gt;みたいにすればできる。&lt;/p&gt;

&lt;p&gt;はず。(参考: &lt;a href=&#34;https://github.com/kubernetes/minikube/issues/530&#34;&gt;https://github.com/kubernetes/minikube/issues/530&lt;/a&gt;)&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>スタートアップはReactを使うべきではない (BSD &#43; patentsライセンスを考慮して) — もし、いつか大企業に買収されたいと望むなら</title>
          <link>https://www.kaitoy.xyz/2017/08/25/if-youre-a-startup-you-should-not-use-react-reflecting-on-the-bsd-patents-license/</link>
          <pubDate>Fri, 25 Aug 2017 00:29:39 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/08/25/if-youre-a-startup-you-should-not-use-react-reflecting-on-the-bsd-patents-license/</guid>
          <description>

&lt;p&gt;このエントリでは、Raúl Kripalaniによる記事、&lt;a href=&#34;https://medium.com/@raulk/if-youre-a-startup-you-should-not-use-react-reflecting-on-the-bsd-patents-license-b049d4a67dd2&#34;&gt;If you’re a startup, you should not use React (reflecting on the BSD + patents license)&lt;/a&gt;を紹介する。
(Raúlから和訳と転載の許可は得た。)
以下はその全文の和訳だが、意訳超訳が混じっているので、もとのニュアンスを知りたければ元記事を読んでもいいし、読まなくてもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;2017/9/23追記: React、Jest、Flow、Immutable.jsが&lt;a href=&#34;https://code.facebook.com/posts/300798627056246/relicensing-react-jest-flow-and-immutable-js/&#34;&gt;MITにリライセンスされる&lt;/a&gt;というアナウンスがFacebookからあった。
コミュニティの大勝利だ。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;現在オープンソースコミュニティで起こっていることには落胆させられる。&lt;/strong&gt;
特に、オープンソースのおかげで多くのスタートアップやビジネスが存在することを認識したときは。
独占的なソフトウェアのために法外なライセンス料を払わなければならないとしたら、それらは存続できない。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;オープンソースとは、より良いソフトウェアをみんなで構築するためのコミュニティをつくることだ。
それを、— Facebookが意図しているような — 人々の権利を交換するための市場として決して使用すべきではない。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Facebookは「BSD + patents」というライセンスモデルを推進している。
広く人気のあるReactを含む、すべてのプロジェクトで。&lt;/p&gt;

&lt;p&gt;基本的に、「BSD + patents」はコードが(誰でも参照し利用できるように)公開されていることを意味するが、しかしそれは常にFacebookの著作物でもある。
そして彼らは、&lt;strong&gt;君がFacebookを特許侵害で訴えないで&lt;/strong&gt; 仲良くやっている限り、君に特許ライセンスを与える。&lt;/p&gt;

&lt;p&gt;Facebookを訴えた瞬間、Reactの他、君の使っているあらゆるFacebookの「オープンソース」技術の特許権は自動的に取り消されてしまう。&lt;/p&gt;

&lt;p&gt;アディオス、バイバイ、どこかへ行ってしまう。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://cdn-images-1.medium.com/max/800/1*crzf_h-aHXU-g3J0W6Ryig.png&#34; alt=&#34;React PATENTS&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;(&lt;a href=&#34;https://github.com/facebook/react/blob/b8ba8c83f318b84e42933f6928f231dc0918f864/PATENTS&#34;&gt;https://github.com/facebook/react/blob/b8ba8c83f318b84e42933f6928f231dc0918f864/PATENTS&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;この問題は、Apache Software Foundationによって&lt;a href=&#34;https://github.com/facebook/react/issues/10191#issuecomment-323486580&#34;&gt;衆目にさらされることとなった&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;この制限は広大で、残忍だ。&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;・・・&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;その知的財産がReactを使用しているドメインと関連しているかどうかは関係ない。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;君がReactを使うなら、Facebookが保持する特許に逆らうことはできない。
いつまでも。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;言い換えれば、代償。&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Facebook、それが君らの考えるオープンソースなのか?&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;・・・&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;fridgebook-inc&#34;&gt;Fridgebook Inc.&lt;/h2&gt;

&lt;p&gt;例として、君の会社「Fridgebook Inc.」はインテリジェントな冷蔵庫を販売しているとしよう。
君の冷蔵庫にはスクリーンが付いていて、独自のアプリケーションを実行していて、そのUIにはReactが使われている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://cdn-images-1.medium.com/max/800/1*vfurq6EY120rZCwkaVtsCg.png&#34; alt=&#34;Fridge&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;突然、Facebookは冷蔵庫業界への進出を決め、新製品「FBfridge」をわずか1週間後に世界中でローンチすると発表した。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;仮に、Facebookがあなたの特許の一部を「FBfridge」で露骨に侵害していた場合、どうすればいい?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;そう、&lt;strong&gt;君は即座に彼らを訴えることはできない。&lt;/strong&gt;
君は顧客が使うアプリにReactを使っている、だろ?&lt;/p&gt;

&lt;p&gt;もし他のもの(&lt;a href=&#34;https://vuejs.org/&#34;&gt;vue.js&lt;/a&gt;とか)に移行せずに訴えたら、Reactのために与えられたライセンスを即座に失い、思いがけず君自身が違反している状態になり、&lt;strong&gt;ソフトウェア不正使用の訴訟を約5000億ドルの会社から起こされる可能性と戦うことになる。&lt;/strong&gt;
君だけで。&lt;/p&gt;

&lt;p&gt;もちろん、君は顧客サービスを中断したくはない。&lt;/p&gt;

&lt;p&gt;だから、もし彼らを訴えたい、もしくは少なくともそれをするための効力を保持したいのであれば、&lt;strong&gt;記録的な期間でReactから移行できる解決策を見つける必要がある&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;それが君の陥るひどい窮地だ。そうだろ?
それはほとんど致命的な状況だ。
&lt;strong&gt;回避策?
最初からReactを使わないことだ。&lt;/strong&gt;
そうすれば権利を主張する自由を維持できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;注: 私は特許に支持も反対もしない。私はこの問題について明確な立場を持っていない。
ここでは私は単にギブアンドテイクのバランスを分析しているだけだ。
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;facebookの釈明&#34;&gt;Facebookの釈明&lt;/h2&gt;

&lt;p&gt;私が最後に見たとき、オープンソースの哲学は、よりよいソフトウェアを構築し、技術をより先に推し進めるために、有能な人々が砂粒に貢献するコミュニティを主要なテーマとしていた。&lt;/p&gt;

&lt;p&gt;それが、Apache Software FoundationやLinux Foundationなどの、&lt;strong&gt;オープンソース界の主要な基準組織の精神だ&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;それで、なぜ特許をオープンソースに持ち込んだのか?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Facebookは&lt;a href=&#34;https://code.facebook.com/posts/112130496157735/explaining-react-s-license/&#34;&gt;正式な釈明&lt;/a&gt;を発表した。
短く要約すると次のようなものだ:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Facebookは、多くのメリットのない特許請求を受けている。
それらに対抗すると多くのリソースを無駄にする。
そこで、(Reactのなどの)オープンソースプロジェクトの成功を利用して、ユーザが理論上メリットのない特許請求を提起するのを阻止するトロイの木馬を導入することに決めた。
彼らはこの制限を交換しない。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;しかしここに重要な部分がある&lt;/strong&gt;。
彼らは、オープンソースソフトウェアをリリースする他のすべての企業が同じことを &lt;em&gt;すべきだと主張している&lt;/em&gt; 。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;残念ながら、これはうまくいかず、以下のような要因により、いずれ再び業界のクローズドソース化を招くだろう：&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;それは市場最大級のプレーヤー間のコンセンサスを必要とする。
&lt;strong&gt;彼らは競合他社に対抗する力として実際の特許兵器(下の画像参照)を保有している。&lt;/strong&gt;
突然、これらの兵器の価値が$0になってしまう。&lt;/li&gt;
&lt;li&gt;そのコンセンサスに達するまず不可能だ。
参加しない悪徳企業が1つでもあれば、残りの企業は「守備/特許兵器」を維持する必要がある。&lt;/li&gt;
&lt;li&gt;すべての巨人達が「BSD + patents」スキームに基づくオープンソースに合意した場合でも、&lt;strong&gt;相互採用はしだいに無くなるだろう。
なぜかって?&lt;/strong&gt;
GoogleがProject Xを「BSD + patents」でリリースし、Amazonがそれを本当に気に入ったら、それを採用してGoogleに特許訴訟をする権利を永久に失うよりは、&lt;strong&gt;それを見限って自分たちで作ってしまうだろう。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;これは、そうした製品の周りにコミュニティが形成されないことを意味する。
コミュニティは、オープンソース製品の燃料でありインセンティブだ。
&lt;strong&gt;コミュニティに着火するチャンスがないならば、オープンソースにする理由はない。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;やがて、上記の状況が何度も繰り返されるにつれ、巨人達は製品をオープンソース化することに価値を見出さなくなり、業界は結局クローズドソースモデルに陥る。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://cdn-images-1.medium.com/max/800/1*VL9qHHrYQ_HMiShoNO4qeg.png&#34; alt=&#34;patent arsenals&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;(2012) &lt;a href=&#34;http://www.droid-life.com/2012/01/24/web-of-tech-patent-lawsuits-infographic/&#34;&gt;http://www.droid-life.com/2012/01/24/web-of-tech-patent-lawsuits-infographic/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;facebookによるオープンソース哲学の非倫理的な利用&#34;&gt;Facebookによるオープンソース哲学の非倫理的な利用&lt;/h2&gt;

&lt;p&gt;特許はアイデアや発明を保護する。
ほとんどの場合特許主張裁判は、白黒が付くのではなく、勝ち負けになる。
&lt;strong&gt;侵害の評価は複雑でコストがかかる。&lt;/strong&gt;
ひとつの訴訟を提起して遂行するのに、何十万か何百万ドルもかかり得る。
FBが君の特許を侵害したという85％の確信を持っていたとしても、それを追求するのに多額の費用がかかるだろう。&lt;/p&gt;

&lt;p&gt;それに加え、まずは別のフロントエンドフレームワークへの移行に投資し、&lt;strong&gt;さらにすべての顧客が新しいバージョンの製品を使用していることを確認する必要がある。&lt;/strong&gt;
(React Nativeを使用していたとするとどうなる? ユーザは一斉にはアプリをアップグレードしてくれないかもしれない!)
そうしなければ、訴訟を起こすことさえできない。
これがオープンソース哲学の誠実で倫理的な利用法だと思うか?&lt;/p&gt;

&lt;p&gt;要点:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;オープンソースは、「代償」取引ではない。
オープンソースは、よりよいソフトウェアを一緒に構築するためのコミュニティをつくることだ。
権利を交換するための市場として使用されるべきではない。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;君はどう思う?&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;・・・&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;なぜスタートアップはreactを避けるべきなのか&#34;&gt;なぜスタートアップはReactを避けるべきなのか&lt;/h2&gt;

&lt;p&gt;君がスタートアップを立ち上げているなら、君と君の投資家は、いつかは百万ドルの価値のある出口に到達することを望んでいるんだろう?&lt;/p&gt;

&lt;p&gt;君は、すべての買収元、特にApple、Microsoft、Google、Amazonなどの大企業に扉を開いておきたい。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;そうした企業は、Facebookに対抗して特許兵器を保有している可能性が高いし、そうでなかったとしても、いざという時にFacebookを訴える権利を放棄したくはない。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;君の製品がReactで構築されている場合、君を買収することはその権利を失うことを意味し、これは恐らく彼らが覚悟できていないことだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;基本的に、もし君を買収することがFacebookの特許侵害を訴える権利を永久に放棄することを意味するなら、
潜在的なバイヤーは10フィートの棒で君を触らない。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;よって、選択肢を残しておきたいのであれば…&lt;/p&gt;

&lt;h2 id=&#34;悪いことは言わない-reactを使うのをやめろ&#34;&gt;悪いことは言わない、Reactを使うのをやめろ&lt;/h2&gt;

&lt;p&gt;私は特に&lt;a href=&#34;https://github.com/developit/preact&#34;&gt;Preact&lt;/a&gt;が好きだが、FacebookにVirtual DOMやReact APIのソフトウェア特許を持っているかは定かではない。&lt;/p&gt;

&lt;p&gt;もし持っていたら、Preactはそれらの特許を侵害しているかもしれないので、&lt;a href=&#34;https://vuejs.org/&#34;&gt;vue.js&lt;/a&gt;や&lt;a href=&#34;https://cycle.js.org/&#34;&gt;cycle.js&lt;/a&gt;も見てみるといい。&lt;/p&gt;

&lt;p&gt;いずれ、知的財産の観点でPreactと&lt;a href=&#34;https://github.com/infernojs/inferno&#34;&gt;Inferno&lt;/a&gt;(もうひとつの軽量なReactの代替品)がどうなのかをコミュニティが明確にできることを願う。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上がRaúlの記事。&lt;/p&gt;

&lt;p&gt;Facebookの「BSD + Patents」への流れは、2015年4月に書かれた&lt;a href=&#34;https://code.facebook.com/posts/1639473982937255/updating-our-open-source-patent-grant/&#34;&gt;Updating Our Open Source Patent Grant&lt;/a&gt;というブログ記事でのアナウンスから始まったようだ。&lt;/p&gt;

&lt;p&gt;Reactのコミットログを見てみると、2014年10月、v16.0.0のアルファ版で「Apache License Version 2.0」から「BSD + Patents」に変わったことが以下のコミットからわかる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/facebook/react/commit/dcf415c2b91ce52fd5d4dd02b70875ba9d33290f&#34;&gt;BSD + PATENTS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;そのPATENTSの部分をより明確にしたのが2015年4月の以下のコミット。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/facebook/react/commit/b8ba8c83f318b84e42933f6928f231dc0918f864&#34;&gt;Update Patent Grant&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;このPATENTSの条項をApache Software Foundationが問題視し、2017年7月に、Apache Software Foundationは自身の全プロジェクトで「BSD + Patents」なOSSの使用を禁止した。
で、Reactのライセンスを「Apache License Version 2.0」に戻せと言ったのをFacebookがごね、ついには、2017/8/19に公式に&lt;a href=&#34;https://code.facebook.com/posts/112130496157735/explaining-react-s-license/&#34;&gt;「BSD + Patents」と心中する&lt;/a&gt;という声明を出して炎上した、というのが今までの流れ。&lt;/p&gt;

&lt;p&gt;Reactのほか、Jest、Flow、Immutable.js、GraphQLなんかもアウト。
うちのプロジェクトでちょっとJestとFlow使いたいと思ってたけど様子見だな。&lt;/p&gt;

&lt;p&gt;Facebookの、みんなもそうすべきだという思惑に反し、今のところはPalantirという企業だけが同様のライセンスを採用しているらしい。&lt;/p&gt;

&lt;p&gt;因みに、たまにBSD + patentsライセンスが&lt;a href=&#34;http://www.opensource.jp/osd/osd-japanese.html&#34;&gt;オープンソースの定義(OSD)&lt;/a&gt;に違反しているので、ReactはOSSですらないという主張があるが、これは間違いであるというのが大方の見方だ。
この主張は、&lt;a href=&#34;https://www.elcaminolegal.com/single-post/2016/10/04/Facebook-Reactjs-License&#34;&gt;Robert Pierceによる記事&lt;/a&gt;が多分発端で、OSDの第一条「再頒布の自由」で、ソフトウェアの再配布に関して報酬(fee)を要求してはいけないとしている部分に、BSD + patentsライセンスが違反しているというもの。
すなわち、Facebookを訴えないという報酬を要求しているという主張だが、この解釈は法律家によって&lt;a href=&#34;http://lu.is/blog/2016/10/31/reacts-license-necessary-and-open/&#34;&gt;否定されている&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;また、OSDの第五条「個人やグループに対する差別の禁止」に違反しているからという主張もあるが、これも微妙。
この主張はつまり、Facebookを訴えていないグループと比較して、訴えたグループを差別しているという主張だろうが、Apache License 2.0、EPL、MPL 2.0といったメジャーなライセンスでも、そのような「差別」をする(i.e. 訴えたら特許使用権を剥奪する)条項がある。
これらのライセンスは、OSDをメンテしている組織であるOSIに&lt;a href=&#34;https://opensource.org/licenses/alphabetical&#34;&gt;承認されている&lt;/a&gt;ので、そうした差別がOSDに決定的に違反することではないことは明らか。
(&lt;a href=&#34;https://lists.opensource.org/pipermail/license-discuss/2016-December/thread.html&#34;&gt;この議論&lt;/a&gt;を見るに、厳密には違反しているけど、原理主義よりも現実主義であるべきなので、受け入れるべきといった雰囲気。)
BSD + patentsライセンスによる「差別」のような条項が、特別なものでも新しいものでもないことは&lt;a href=&#34;https://opensource.org/node/862&#34;&gt;OSI自身も言及している&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;FacebookのBSD + patentsライセンスが特別なのは、その「差別」の範囲が広いことだ。
Apache License 2.0なんかは、訴えた特許を含むソフトウェアだけが使えなくなるが、Facebookのは、Facebookに対するいかなる特許訴訟でもひとたび起こせば、Facebookが提供する広範囲の(全ての?)OSSが使えなくなるというもので、これはあまりにジャイアン的だということで炎上した。&lt;/p&gt;

&lt;p&gt;Facebookはこの炎上をどう収めるつもりなんだろう。
これをきっかけにReactが廃れ、Vue.jsとかに行ってしまうんだろうか。
結局フロントエンドフレームワークは何を学べばいいの?
Angular?&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>WebdriverIOとChromeのヘッドレスモードで自動ブラウザテストするDockerイメージ: webdriverio-chrome</title>
          <link>https://www.kaitoy.xyz/2017/08/14/webdriverio-chrome/</link>
          <pubDate>Mon, 14 Aug 2017 10:53:17 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/08/14/webdriverio-chrome/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/08/04/browser-test-framework/&#34;&gt;2017年夏、ブラウザテストフレームワーク&lt;/a&gt;」の続き。
&lt;a href=&#34;https://www.servicenow.com/ja&#34;&gt;ServiceNow&lt;/a&gt;アプリケーションのブラウザテストをしたくて色々調べている。
前回は、フレームワークに&lt;a href=&#34;http://webdriver.io/&#34;&gt;WebdriverIO&lt;/a&gt;を使うと決めたところまで書いた。&lt;/p&gt;

&lt;p&gt;今回、最終的に、&lt;a href=&#34;http://webdriver.io/&#34;&gt;WebdriverIO&lt;/a&gt;、&lt;a href=&#34;http://webdriver.io/guide/testrunner/gettingstarted.html&#34;&gt;WDIO&lt;/a&gt;、&lt;a href=&#34;https://github.com/vvo/selenium-standalone&#34;&gt;selenium-standalone&lt;/a&gt;、&lt;a href=&#34;https://jasmine.github.io/&#34;&gt;Jasmine&lt;/a&gt;と、Chromeのヘッドレスモードを使って、Dockerコンテナ(&lt;a href=&#34;https://alpinelinux.org/&#34;&gt;Alpine Linux&lt;/a&gt;)上でテストスクリプトを実行して、ServiceNowのログイン画面のスクリーンショットが取れるところまでできた。&lt;/p&gt;

&lt;p&gt;そのコンテナイメージのDockerfileは&lt;a href=&#34;https://github.com/kaitoy/webdriverio-chrome&#34;&gt;GitHubに置いた&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;とりあえずalpine-linux&#34;&gt;とりあえずAlpine Linux&lt;/h2&gt;

&lt;p&gt;テスト環境の作成は自宅でやってるけど、DockerイメージにしてDocker Hubとかに上げておけば、社内でダウンロードしてそのまま再現できる。
ダウンロードに係る社内手続きも、Dockerイメージだけに対してやればいいので、中に何を詰め込んでも、後でライブラリとか追加しても、一回こっきりで済む。&lt;/p&gt;

&lt;p&gt;というわけでWebdriverIO環境をDockerコンテナとしてつくることにする。
とりあえず、自PC(Windows 10 Home x64)に入ってるVMware Workstation Player 12.5.5でCentOS 7 x64のVMを作り、そこにDockerをインストールした。&lt;/p&gt;

&lt;p&gt;次に、そのDockerを使って、WebdriverIO環境のベースにするAlpine Linuxをpullする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ docker pull alpine:edge
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Alpine Linuxは&lt;a href=&#34;https://busybox.net/&#34;&gt;BusyBox&lt;/a&gt;と&lt;a href=&#34;https://www.musl-libc.org/&#34;&gt;musl libc&lt;/a&gt;で構成された軽量な Linuxディストリビューション。
2016年2月に&lt;a href=&#34;https://www.brianchristner.io/docker-is-moving-to-alpine-linux/&#34;&gt;すべてのオフィシャルDockerイメージがAlpine Linuxベースになる&lt;/a&gt;というアナウンスがあったし、他にそれっぽいものもなかったので、これをベースに環境を作ることにした。
&lt;a href=&#34;https://www.gnu.org/software/libc/&#34;&gt;glibc&lt;/a&gt;じゃないのがちょっと気になるけど、まあ問題ないか。&lt;/p&gt;

&lt;p&gt;現在、&lt;a href=&#34;https://pkgs.alpinelinux.org/package/edge/community/x86_64/chromium&#34;&gt;Chrome 59&lt;/a&gt;のAlpine Linuxパッケージはedgeブランチ(i.e. 開発ブランチ)でしか作られていない。
pullするタグをedgeにしたのはそのため。
(因みに現時点でAlpine Linuxのlatestは3.6。)&lt;/p&gt;

&lt;p&gt;で、起動。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ docker run -it alpine:edge sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;chrome-chromium-インストール&#34;&gt;Chrome(Chromium)インストール&lt;/h2&gt;

&lt;p&gt;まずはChrome(がAlpine Linuxパッケージにはないので、実際にはChromium)と、ついでにChromeDriverをインストールする。
Alpine Linux独自のパッケージマネージャーである&lt;a href=&#34;https://wiki.alpinelinux.org/wiki/Alpine_Linux_package_management&#34;&gt;apk&lt;/a&gt;を使う。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/ # apk add --update chromium chromium-chromedriver
/ # chromium-browser -version
Chromium 59.0.3071.115
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;無事インストールできた。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://bufferings.hatenablog.com/entry/2017/05/03/181713&#34;&gt;この記事&lt;/a&gt;を参考にヘッドレスモードで実行してみる。
ヘッドレスモードにするために&lt;code&gt;--headless&lt;/code&gt;を付けて、一時的な制限事項で&lt;code&gt;--disable-gpu&lt;/code&gt;を付ける必要があって、コンテナの権限不足を回避するために&lt;code&gt;--no-sandbox&lt;/code&gt;を付ける。
(コンテナの権限不足回避には他に、&lt;code&gt;docker run&lt;/code&gt;に&lt;code&gt;--privileged&lt;/code&gt;や&lt;code&gt;--cap-add=SYS_ADMIN&lt;/code&gt;付ける&lt;a href=&#34;https://github.com/yukinying/chrome-headless-browser-docker&#34;&gt;方法がある&lt;/a&gt;。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/ # chromium-browser --headless --no-sandbox --disable-gpu https://example.com/
[0811/145902.894023:WARNING:dns_config_service_posix.cc(326)] Failed to read DnsConfig.
[0811/145902.906137:FATAL:udev_loader.cc(38)] Check failed: false.
Received signal 6
  r8: 0000000000000061  r9: 00007fe3fe01c066 r10: 0000000000000008 r11: 0000000000000246
 r12: 00007fe3fe01bed0 r13: 00007fe3fe01be80 r14: 0000000000000000 r15: 0000000000000000
  di: 0000000000000002  si: 00007fe3fe01bda0  bp: 00007fe3fe01bda0  bx: 0000000000000006
  dx: 0000000000000000  ax: 0000000000000000  cx: ffffffffffffffff  sp: 00007fe3fe01bd88
  ip: 00007fe412a2f769 efl: 0000000000000246 cgf: 0000000000000033 erf: 0000000000000000
 trp: 0000000000000000 msk: 0000000000000000 cr2: 0000000000000000
[end of stack trace]
Calling _exit(1). Core file will not be generated.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;エラーになった。&lt;/p&gt;

&lt;p&gt;最初のWARNINGは置いといて、FATALのほうは、udev_loader.ccというのでエラーになってる。&lt;/p&gt;

&lt;p&gt;エラーメッセージでググったら、&lt;a href=&#34;http://qiita.com/dd511805/items/dfe03c5486bf1421875a&#34;&gt;Qiitaに同じエラーを解決している記事&lt;/a&gt;が。
よくわからないが、&lt;a href=&#34;https://pkgs.alpinelinux.org/package/v3.5/main/x86_64/udev&#34;&gt;udev&lt;/a&gt;と&lt;a href=&#34;https://pkgs.alpinelinux.org/package/v3.6/main/x86_64/ttf-freefont&#34;&gt;ttf-freefont&lt;/a&gt;を入れればいいらしい。
深く考えずにそれに従うことにする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/ # apk add udev ttf-freefont
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、再度実行。
(ちゃんと動いてるか分かりやすくするために&lt;code&gt;--dump-dom&lt;/code&gt;も付けた。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/ # chromium-browser --headless --no-sandbox --disable-gpu --dump-dom https://example.com/
[0811/151303.698629:WARNING:dns_config_service_posix.cc(326)] Failed to read DnsConfig.
&amp;lt;body&amp;gt;
&amp;lt;div&amp;gt;
    &amp;lt;h1&amp;gt;Example Domain&amp;lt;/h1&amp;gt;
    &amp;lt;p&amp;gt;This domain is established to be used for illustrative examples in documents. You may use this
    domain in examples without prior coordination or asking for permission.&amp;lt;/p&amp;gt;
    &amp;lt;p&amp;gt;&amp;lt;a href=&amp;quot;http://www.iana.org/domains/example&amp;quot;&amp;gt;More information...&amp;lt;/a&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;


&amp;lt;/body&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;動いた!&lt;/p&gt;

&lt;h2 id=&#34;フォント追加&#34;&gt;フォント追加&lt;/h2&gt;

&lt;p&gt;前節で参考にした&lt;a href=&#34;http://qiita.com/dd511805/items/dfe03c5486bf1421875a&#34;&gt;Qiitaの記事&lt;/a&gt;に、文字化け対策としてフォントを追加する手順も書いてあったのでそれもやる。&lt;/p&gt;

&lt;p&gt;まず試しに、何もしないでスクリーンショットを撮ってみる。
&lt;code&gt;--screenshot&lt;/code&gt;オプションで。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/ # chromium-browser --headless --no-sandbox --disable-gpu --screenshot https://www.google.co.jp/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;するとやはり文字化けしている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/webdriverio-chrome/garblings.png&#34; alt=&#34;garblings.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.google.com/get/noto/&#34;&gt;Google Noto Fonts&lt;/a&gt;を入れて対応する。
(因みにNotoはNo Tofuの略で、文字化けした時に出る、クエスチョンマークが乗った豆腐の撲滅を目指して開発されたフォント。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/ # apk add curl
/ # cd /tmp/
/tmp # curl https://noto-website.storage.googleapis.com/pkgs/NotoSansCJKjp-hinte
/tmp # unzip NotoSansCJKjp-hinted.zip
/tmp # mkdir -p /usr/share/fonts/noto
/tmp # cp *.otf /usr/share/fonts/noto
/tmp # chmod 644 -R /usr/share/fonts/noto/
/tmp # fc-cache -fv
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;後半に実行してるコマンドの詳細はよくわからないが、文字化けは直った。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/webdriverio-chrome/garblings_fixed.png&#34; alt=&#34;garblings_fixed.png&#34; /&gt;
&lt;/p&gt;

&lt;h2 id=&#34;webdriverioインストール&#34;&gt;WebdriverIOインストール&lt;/h2&gt;

&lt;p&gt;次にWebdriverIOをインストールする。
&lt;a href=&#34;https://yarnpkg.com/lang/en/&#34;&gt;Yarn&lt;/a&gt;でインストールして&lt;a href=&#34;https://nodejs.org/ja/&#34;&gt;Node.js&lt;/a&gt;で動かすので、まずそれらをapkで入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/tmp # apk add nodejs yarn
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、プロジェクトを作ってWebdriverIOを追加。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/tmp # mkdir /root/webdriverio-chrome
/tmp # cd /root/webdriverio-chrome
~/webdriverio-chrome # yarn init
~/webdriverio-chrome # yarn add webdriverio --dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;package.jsonのscriptsを編集して、WebdriverIO付属のテストランナであるWDIOを使えるようにする。&lt;/p&gt;

&lt;p&gt;package.json:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;webdriverio-chrome&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.0.1&amp;quot;,
  &amp;quot;description&amp;quot;: &amp;quot;Browser test stack with WebdriverIO and headless Chrome&amp;quot;,
  &amp;quot;scripts&amp;quot;: {
    &amp;quot;test&amp;quot;: &amp;quot;wdio&amp;quot;
  },
  &amp;quot;author&amp;quot;: &amp;quot;Kaito Yamada&amp;quot;,
  &amp;quot;license&amp;quot;: &amp;quot;MIT&amp;quot;,
  &amp;quot;devDependencies&amp;quot;: {
    &amp;quot;webdriverio&amp;quot;: &amp;quot;^4.8.0&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;wdioの設定ファイル生成&#34;&gt;WDIOの設定ファイル生成&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://webdriver.io/guide/testrunner/gettingstarted.html&#34;&gt;WDIOのconfigコマンド&lt;/a&gt;でWDIO Configuration Helperを起動し、設定ファイルwdio.conf.jsをインタラクティブに生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # yarn test -- config
yarn test v0.27.5
$ wdio &amp;quot;config&amp;quot;

=========================
WDIO Configuration Helper
=========================

? Where do you want to execute your tests? On my local machine
? Which framework do you want to use? jasmine
? Shall I install the framework adapter for you? No
? Where are your test specs located? ./test/specs/**/*.js
? Which reporter do you want to use?  spec - https://github.com/webdriverio/wdio-spec-reporter
? Shall I install the reporter library for you? No
? Do you want to add a service to your test setup?  selenium-standalone - https://github.com/webdriverio/wdio-selenium-standalone-service
? Shall I install the services for you? No
? Level of logging verbosity verbose
? In which directory should screenshots gets saved if a command fails? ./errorShots/
? What is the base url? http://localhost

Configuration file was created successfully!
To run your tests, execute:

$ wdio wdio.conf.js

Done in 53.58s.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;WDIO Configuration Helperで、テストフレームワークは&lt;a href=&#34;https://mochajs.org/&#34;&gt;Mocha&lt;/a&gt;か&lt;a href=&#34;https://jasmine.github.io/&#34;&gt;Jasmine&lt;/a&gt;か&lt;a href=&#34;https://cucumber.io/&#34;&gt;Cucumber&lt;/a&gt;から&lt;a href=&#34;http://webdriver.io/guide/testrunner/frameworks.html&#34;&gt;選択できる&lt;/a&gt;。
ServiceNowのテストフレームワーク(ATF)がJasmine使ってるので、一応それに合わせてJasmineにした。
ATFは今のところ使うつもりはないけど。&lt;/p&gt;

&lt;p&gt;レポータ(標準出力へテスト結果を出力するコンポーネント)は妙に色々ある中から、雰囲気で&lt;a href=&#34;http://webdriver.io/guide/reporters/spec.html&#34;&gt;spec&lt;/a&gt;を選択。&lt;/p&gt;

&lt;p&gt;サービス(テスト実行に必要な準備などをしてくれるコンポーネント)には&lt;a href=&#34;http://webdriver.io/guide/services/selenium-standalone.html&#34;&gt;selenium-standalone&lt;/a&gt;を選択。
こいつは、テスト実行前に、npmパッケージの&lt;a href=&#34;https://www.npmjs.com/package/selenium-standalone&#34;&gt;selenium-standalone&lt;/a&gt;を使って&lt;a href=&#34;http://docs.seleniumhq.org/download/&#34;&gt;Selenium Server&lt;/a&gt;をダウンロードして起動したり、WebDriverをセットアップしてくれたりする。&lt;/p&gt;

&lt;p&gt;因みにサービスには他に、&lt;a href=&#34;http://webdriver.io/guide/services/browserstack.html&#34;&gt;browserstack&lt;/a&gt;とか&lt;a href=&#34;http://webdriver.io/guide/services/appium.html&#34;&gt;appium&lt;/a&gt;とか&lt;a href=&#34;http://webdriver.io/guide/services/phantomjs.html&#34;&gt;phantomjs&lt;/a&gt;とかがある。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Shall I install …&lt;/code&gt;という質問には全てnoで回答した。
でないとWDIOがnpm installしようとして、npmが無くて以下のようなエラーになるので。
(apkでは、npmは&lt;a href=&#34;https://pkgs.alpinelinux.org/package/edge/main/x86_64/nodejs&#34;&gt;nodejs&lt;/a&gt;パッケージに入ってなくて、&lt;a href=&#34;https://pkgs.alpinelinux.org/package/edge/main/x86_64/nodejs-npm&#34;&gt;nodejs-npm&lt;/a&gt;に入ってる。)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Installing wdio packages:
/root/webdriverio-chrome/node_modules/webdriverio/build/lib/cli.js:278
                    throw err;
                    ^

Error: Command failed: npm i -D wdio-jasmine-framework
/bin/sh: npm: not found

    at ChildProcess.exithandler (child_process.js:204:12)
    at emitTwo (events.js:106:13)
    at ChildProcess.emit (events.js:191:7)
    at maybeClose (internal/child_process.js:891:16)
    at Socket.&amp;lt;anonymous&amp;gt; (internal/child_process.js:342:11)
    at emitOne (events.js:96:13)
    at Socket.emit (events.js:188:7)
    at Pipe._handle.close [as _onclose] (net.js:497:12)
error Command failed with exit code 1.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;生成された設定ファイルは以下の感じ。(コメントは省略してる。)&lt;/p&gt;

&lt;p&gt;wdio.conf.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;exports.config = {
    specs: [
        &#39;./test/specs/**/*.js&#39;
    ],
    exclude: [
        // &#39;path/to/excluded/files&#39;
    ],
    maxInstances: 10,
    capabilities: [{
        maxInstances: 5,
        browserName: &#39;firefox&#39;,
    }],

    sync: true,
    logLevel: &#39;verbose&#39;,
    coloredLogs: true,
    bail: 0,
    screenshotPath: &#39;./errorShots/&#39;,
    baseUrl: &#39;http://localhost&#39;,
    waitforTimeout: 10000,
    connectionRetryTimeout: 90000,
    connectionRetryCount: 3,

    services: [&#39;selenium-standalone&#39;],

    framework: &#39;jasmine&#39;,
    reporters: [&#39;spec&#39;],
    jasmineNodeOpts: {
        defaultTimeoutInterval: 50000,
        expectationResultHandler: function(passed, assertion) {
            // do something
        }
    },
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;npmパッケージとjava追加&#34;&gt;npmパッケージとJava追加&lt;/h2&gt;

&lt;p&gt;WDIO Configuration Helperの&lt;code&gt;Shall I install …&lt;/code&gt;でnoした分は自分でインストールしておく。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # yarn add wdio-jasmine-framework wdio-spec-reporter wdio-selenium-standalone-service selenium-standalone --dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;したらエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;error /root/webdriverio-chrome/node_modules/fibers: Command failed.
Exit code: 127
Command: sh
Arguments: -c node build.js || nodejs build.js
Directory: /root/webdriverio-chrome/node_modules/fibers
Output:
`linux-x64-48` exists; testing
Problem with the binary; manual build incoming
node-gyp not found! Please ensure node-gyp is in your PATH--
Try running: `sudo npm install -g node-gyp`
sh: nodejs: not found
spawn node-gyp ENOENT
info Visit https://yarnpkg.com/en/docs/cli/add for documentation about this command.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/nodejs/node-gyp&#34;&gt;node-gyp&lt;/a&gt;が無いと。
では追加する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # yarn global add node-gyp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;node-gypのREADME.md読むと、PythonとmakeとC/C++コンパイラが要るとあるので、それも入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # apk add python make gcc g++
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、再度、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # yarn add wdio-jasmine-framework wdio-spec-reporter wdio-selenium-standalone-service selenium-standalone --dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;したら入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あと、Selenium ServerがJavaで動くので、Javaも入れておく。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # apk add openjdk8
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;wdio-conf-jsの修正&#34;&gt;wdio.conf.jsの修正&lt;/h2&gt;

&lt;p&gt;生成されたwdio.conf.jsはFirefoxを使うようになっているなどの問題があるので修正する。
参考にしたのは&lt;a href=&#34;https://stackoverflow.com/questions/42303119/selenium-webdriverio-chrome-headless&#34;&gt;Stack Overflowの回答&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;     capabilities: [{
     maxInstances: 5,
-        browserName: &#39;firefox&#39;
+        browserName: &#39;chrome&#39;,
+        chromeOptions: {
+            binary: &#39;/usr/bin/chromium-browser&#39;,
+            args: [
+                &#39;headless&#39;,
+                &#39;disable-gpu&#39;,
+                &#39;no-sandbox&#39;,
+            ],
+        },
     }],
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;browserName&lt;/code&gt;を&lt;code&gt;firefox&lt;/code&gt;から&lt;code&gt;chrome&lt;/code&gt;に変えて、ヘッドレスモードで動かすためのオプションを指定している。
また、普通のChromeとは実行ファイルの名前が違うので、&lt;code&gt;binary&lt;/code&gt;で指定している。&lt;/p&gt;

&lt;h2 id=&#34;テスト作成と実行&#34;&gt;テスト作成と実行&lt;/h2&gt;

&lt;p&gt;テストはとりあえず&lt;a href=&#34;http://blog.asial.co.jp/1484&#34;&gt;この記事&lt;/a&gt;を参考に以下のようなものを書いた。&lt;/p&gt;

&lt;p&gt;test-sample.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;describe(&#39;Sample&#39;, function() {
    it(&amp;quot;takes a screenshot of www.google.co.jp&amp;quot;, function() {
        browser.url(&#39;https://www.google.co.jp/&#39;);
        browser.saveScreenshot(&#39;./screenshots/google.png&#39;);
    });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを実行すると、&lt;code&gt;https://www.google.co.jp/&lt;/code&gt;をブラウザで開いて、スクリーンショットを撮る。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これを&lt;code&gt;~/webdriverio-chrome/test/specs/&lt;/code&gt;において、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # yarn test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;でテスト実行。
したらエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # yarn test
yarn test v0.27.5
$ wdio
[06:43:04]  COMMAND     POST     &amp;quot;/wd/hub/session&amp;quot;
[06:43:04]  DATA                {&amp;quot;desiredCapabilities&amp;quot;:{&amp;quot;javascriptEnabled&amp;quot;:true,&amp;quot;locationContextEnabled&amp;quot;:true,&amp;quot;handlesAlerts&amp;quot;:true,&amp;quot;rotatable&amp;quot;:true,&amp;quot;maxInstances&amp;quot;:5,&amp;quot;browserName&amp;quot;:&amp;quot;chrome&amp;quot;,&amp;quot;chromeOptions&amp;quot;:{&amp;quot;binary&amp;quot;:&amp;quot;/usr/bin/chromium-browser&amp;quot;,&amp;quot;args&amp;quot;:[&amp;quot;headless&amp;quot;,&amp;quot;disable-gpu&amp;quot;,&amp;quot;no-sandbox&amp;quot;]},&amp;quot;loggingPrefs&amp;quot;:{&amp;quot;browser&amp;quot;:&amp;quot;ALL&amp;quot;,&amp;quot;driver&amp;quot;:&amp;quot;ALL&amp;quot;},&amp;quot;requestOrigins&amp;quot;:{&amp;quot;url&amp;quot;:&amp;quot;http://webdriver.io&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;4.6.2&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;webdriverio&amp;quot;}}}
ERROR: An unknown server-side error occurred while processing the command. (UnknownError:13)
chrome
Error: An unknown server-side error occurred while processing the command. (UnknownError:13)

error Command failed with exit code 1.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;サーバサイドでよくわからないエラーが起きたとのこと。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;試しに手動でSelenium Serverを起動してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # node ./node_modules/.bin/selenium-standalone start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正常に起動する。&lt;/p&gt;

&lt;p&gt;ChromeDriverはどうか。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # /usr/bin/chromedriver
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これも起動する。はて。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/webdriverio/wdio-selenium-standalone-service/blob/v0.0.9/lib/launcher.js&#34;&gt;wdio-selenium-standalone-serviceのソース&lt;/a&gt;を見てみたら、selenium-standaloneの&lt;code&gt;install&lt;/code&gt;を呼んでいた。
これはSelenium ServerとChromeDriverをダウンロードする機能だ。
コンテナ内を確認したら、&lt;code&gt;node_modules/selenium-standalone/.selenium/chromedrive
r/2.31-x64-chromedriver&lt;/code&gt;というのが出来てた。
これがselenium-standaloneがダウンロードしたChromeDriverだろうが、Apline Linux用ではないので、&lt;code&gt;ldd&lt;/code&gt;してやるとたくさんエラーが出る。
selenium-standaloneがこれを実行しようとしたせいでテスト実行がエラーになったんだろう。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.com/@jlchereau/how-to-configure-webdrivier-io-with-selenium-standalone-and-additional-browsers-9369d38bc4d1&#34;&gt;Mediumの記事&lt;/a&gt;などを参考にして、wdio.conf.jsを以下のように修正して、ChromeDriverのバイナリを指定してやったら動いた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;     services: [&#39;selenium-standalone&#39;],
+    seleniumArgs: {
+        javaArgs: [
+            &#39;-Dwebdriver.chrome.driver=/usr/bin/chromedriver&#39;
+        ]
+    },
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;プロキシ対策&#34;&gt;プロキシ対策&lt;/h2&gt;

&lt;p&gt;社内で使うには、ベーシック認証付きのプロキシを突破しないといけない。&lt;/p&gt;

&lt;p&gt;今回作った環境をクールな図にするとこんな↓感じ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/webdriverio-chrome/internet_accesses.png&#34; alt=&#34;internet_accesses.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;なので、二か所あるインターネッツアクセスをプロキシ対応させる必要がある。
図の左のアクセスについては、&lt;a href=&#34;https://github.com/webdriverio/wdio-selenium-standalone-service/blob/master/lib/launcher.js&#34;&gt;wdio-selenium-standalone-serviceのソース&lt;/a&gt;を見たりして、wdio.conf.jsを次のように修正すればいいことが分かった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;     services: [&#39;selenium-standalone&#39;],
     seleniumArgs: {
         javaArgs: [
             &#39;-Dwebdriver.chrome.driver=/usr/bin/chromedriver&#39;,
         ],
     },
+    seleniumInstallArgs: {
+        proxy: &#39;http://userId:password@proxy.com:8080&#39;,
+    },
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;図の右のアクセスについては、プロキシのベーシック認証のクレデンシャルを指定するオプションがChromeにないので、&lt;a href=&#34;https://github.com/sjitech/proxy-login-automator&#34;&gt;proxy-login-automator&lt;/a&gt;を使うことにして、wdio.conf.jsには次のように追記しておく。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;         chromeOptions: {
             binary: &#39;/usr/bin/chromium-browser&#39;,
             args: [
                 &#39;headless&#39;,
                 &#39;disable-gpu&#39;,
                 &#39;no-sandbox&#39;,
+                &#39;proxy-server=localhost:18080&#39;,
             ],
         },
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで、テスト実行前に、以下みたいにproxy-login-automatorを起動しておけばいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # node node_modules/.bin/proxy-login-automator.js -local_port 18080 -remote_host proxy.com -remote_port 8080 -usr userId -pwd password`
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;以上の操作をまとめたDockerfileが以下。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-dockerfile&#34;&gt;From alpine:edge

ADD package.json wdio.conf.js yarn.lock test-sample.js /root/webdriverio-chrome/

RUN apk add --update --no-cache \
            udev \
            ttf-freefont \
            chromium \
            chromium-chromedriver \
            openjdk8 \
            nodejs \
            yarn \
            make gcc g++ python \
            curl &amp;amp;&amp;amp; \
    cd /tmp &amp;amp;&amp;amp; \
    curl https://noto-website.storage.googleapis.com/pkgs/NotoSansCJKjp-hinted.zip -O &amp;amp;&amp;amp; \
    unzip NotoSansCJKjp-hinted.zip &amp;amp;&amp;amp; \
    mkdir -p /usr/share/fonts/noto &amp;amp;&amp;amp; \
    cp *.otf /usr/share/fonts/noto &amp;amp;&amp;amp; \
    chmod 644 -R /usr/share/fonts/noto/ &amp;amp;&amp;amp; \
    fc-cache -fv &amp;amp;&amp;amp; \
    cd /root/webdriverio-chrome/ &amp;amp;&amp;amp; \
    yarn global add node-gyp &amp;amp;&amp;amp; \
    yarn &amp;amp;&amp;amp; \
    mkdir -p test/specs &amp;amp;&amp;amp; \
    mv test-sample.js test/specs/ &amp;amp;&amp;amp; \
    mkdir screenshots &amp;amp;&amp;amp; \
    yarn global remove node-gyp &amp;amp;&amp;amp; \
    rm -rf /root/.node-gyp &amp;amp;&amp;amp; \
    rm -rf /tmp/* &amp;amp;&amp;amp; \
    yarn cache clean &amp;amp;&amp;amp; \
    apk del --purge make gcc g++ python curl

WORKDIR /root/webdriverio-chrome
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できるイメージを小さくするため、レイヤを減らしたり、ビルド用パッケージを消したりしてる。
&lt;a href=&#34;http://qiita.com/minamijoyo/items/711704e85b45ff5d6405&#34;&gt;Multi-Stage build&lt;/a&gt;が&lt;a href=&#34;https://hub.docker.com/&#34;&gt;Docker Hub&lt;/a&gt;のAutomated Buildで&lt;a href=&#34;https://github.com/docker/hub-feedback/issues/1039&#34;&gt;もうすぐサポートされる&lt;/a&gt;ので、そしたらもう少しきれいに書き直せるはず。&lt;/p&gt;

&lt;p&gt;(後日書き直して&lt;a href=&#34;https://github.com/kaitoy/webdriverio-chrome/blob/master/Dockerfile&#34;&gt;きれいになった&lt;/a&gt;。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;最終的なpackage.jsonは&lt;a href=&#34;https://github.com/kaitoy/webdriverio-chrome/blob/v0.0.3/package.json&#34;&gt;これ&lt;/a&gt;。
wdio.conf.jsは&lt;a href=&#34;https://github.com/kaitoy/webdriverio-chrome/blob/v0.0.3/wdio.conf.js&#34;&gt;これ&lt;/a&gt;。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>2017年夏、ブラウザテストフレームワーク</title>
          <link>https://www.kaitoy.xyz/2017/08/04/browser-test-framework/</link>
          <pubDate>Fri, 04 Aug 2017 15:29:37 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/08/04/browser-test-framework/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/07/12/2017-selenium-headless-browsers/&#34;&gt;2017年夏、Selenium、ヘッドレスブラウザ&lt;/a&gt;」の続き。
&lt;a href=&#34;https://www.servicenow.com/ja&#34;&gt;ServiceNow&lt;/a&gt;アプリケーションのブラウザテストをしたくて色々調べている。
前回は、Selenium(WebDriver)とChromeのヘッドレスモードを使うのがよさそうというところまで書いた。&lt;/p&gt;

&lt;p&gt;この記事では、ブラウザテストフレームワークを選ぶ。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;ブラウザ操作ツールとかブラウザテストフレームワークとか&#34;&gt;ブラウザ操作ツールとかブラウザテストフレームワークとか&lt;/h2&gt;

&lt;p&gt;Seleniumを直接使って、&lt;a href=&#34;http://junit.org/junit4/&#34;&gt;JUnit&lt;/a&gt;なんかのテストフレームワークでブラウザテストを書くこともできるけど、それは結構つらい。
Seleniumは低レベルなブラウザ操作APIを提供するので、単純にテスト書き辛いし、動的サイトを扱うときには、かなり気を使ってwait処理を入れていかないとテストが安定しない。
テスト前に、WebDriverの準備をしないといけなかったりするのも面倒。&lt;/p&gt;

&lt;p&gt;なので、昨今はもう少し高級なツールやフレームワークを使うのが普通な模様。
あまり知らなかったので色々記事を読んだ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://qiita.com/cognitom/items/27b7375bea653b414c8f&#34;&gt;Seleniumアレルギーのための処方箋&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://qiita.com/cognitom/items/6cce719b57341769c14d&#34;&gt;ブラウザテストツール総まとめ・2016年夏版&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://postd.cc/a-complete-guide-to-testing-javascript-in-2017/&#34;&gt;2017年JavaScriptのテスト概論&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;結果、ブラウザ操作ツールやブラウザテストフレームワークには以下のようなものがあることが分かった。
(SeleniumやWebDriver系じゃないのも含む。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://nightwatchjs.org/&#34;&gt;Nightwatch.js&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は6835。&lt;/p&gt;

&lt;p&gt;JavaScriptでブラウザテストを書けるフレームワーク。
WebDriverプロトコルに対応していて、Seleniumと異なる独自のクライアントAPIを実装。
つまり使えるブラウザの幅が広い。&lt;/p&gt;

&lt;p&gt;テストフレームワークは独自のもの。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://webdriver.io/&#34;&gt;WebdriverIO&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は3217。&lt;/p&gt;

&lt;p&gt;JavaScriptでブラウザを操作できるツール。
WebDriverプロトコルに対応していて、Seleniumと異なる独自のクライアントAPI(ラッパ?)を実装。
つまり使えるブラウザの幅が広い。&lt;/p&gt;

&lt;p&gt;独自のテストランナである&lt;a href=&#34;http://webdriver.io/guide/testrunner/gettingstarted.html&#34;&gt;WDIO&lt;/a&gt;付きで、テストフレームワークに&lt;a href=&#34;https://mochajs.org/&#34;&gt;Mocha&lt;/a&gt;、&lt;a href=&#34;https://jasmine.github.io/&#34;&gt;Jasmine&lt;/a&gt;、&lt;a href=&#34;https://cucumber.io/&#34;&gt;Cucumber&lt;/a&gt;など、いろいろ利用できる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.protractortest.org/#/&#34;&gt;Protractor&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は6801。&lt;/p&gt;

&lt;p&gt;JavaScriptでブラウザテストを書けるフレームワーク。
WebDriverプロトコルに対応していて、&lt;a href=&#34;https://github.com/SeleniumHQ/selenium/wiki/WebDriverJs&#34;&gt;selenium-webdriver&lt;/a&gt;をラップしたAPIを提供する。
WebDriverなのでブラウザはなんでも。&lt;/p&gt;

&lt;p&gt;テストフレームワークは、Jasmine、Mocha、Cucumberのほか、いろいろ選べる模様。&lt;/p&gt;

&lt;p&gt;AngularとAngularJS向けだけどそれ以外にも使える。
Google製なので信頼感があるし、ドキュメントもコミュニティもしっかりしてる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://casperjs.org/&#34;&gt;Casper.js&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は6337。&lt;/p&gt;

&lt;p&gt;JavaScriptでブラウザテストを書けるフレームワーク。
使えるブラウザは&lt;a href=&#34;http://phantomjs.org/&#34;&gt;PhantomJS&lt;/a&gt;か&lt;a href=&#34;https://slimerjs.org/&#34;&gt;SlimerJS&lt;/a&gt;だけで、多分WebDriver使ってない。&lt;/p&gt;

&lt;p&gt;テストフレームワークは独自のもの。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.nightmarejs.org/&#34;&gt;Nightmare&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は12964。&lt;/p&gt;

&lt;p&gt;JavaScriptでブラウザを操作できるツール。
ブラウザは、昔の1系はPhantomJSを使ってたけど、今の2系は&lt;a href=&#34;https://electron.atom.io/&#34;&gt;Electron&lt;/a&gt;。
WebDriverは使ってないはず。&lt;/p&gt;

&lt;p&gt;テストフレームワーク機能は付いてないけど、同じ作者の&lt;a href=&#34;https://open.segment.com/niffy&#34;&gt;Niffy&lt;/a&gt;というNightmareベースのツールがちょっとそれっぽい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://devexpress.github.io/testcafe/&#34;&gt;TestCafe&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は3029。&lt;/p&gt;

&lt;p&gt;JavaScriptでブラウザテストを書けるフレームワーク。
すごい多機能っぽいし、TypeScriptやasync/awaitをサポートしててなんかモダン。
WebDriverは使ってないっぽいけど、Chrome、Firefox、IE、Edge、Safariなど、一通りのブラウザが使える。
なぜかリモートテストもできる。&lt;/p&gt;

&lt;p&gt;どうもSelenium 1みたいにJavaScriptコードを挿入してテスト実行するらしいんだけど、よくわからない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://zombie.js.org/&#34;&gt;Zombie.js&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は4608。&lt;/p&gt;

&lt;p&gt;JavaScriptでjsdomを操作できるツール。
なぜか妙にアサーション機能に凝っている。&lt;/p&gt;

&lt;p&gt;WebDriverは使ってないはず。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleChrome/puppeteer&#34;&gt;Puppeteer&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は29068。&lt;/p&gt;

&lt;p&gt;Chromeを&lt;a href=&#34;https://chromedevtools.github.io/devtools-protocol/&#34;&gt;DevToolsプロトコル&lt;/a&gt;で操作するJavaScript(Node)ライブラリ。&lt;/p&gt;

&lt;p&gt;Chrome開発チームが開発している。&lt;/p&gt;

&lt;p&gt;WebDriverは使ってない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/OnetapInc/chromy&#34;&gt;Chromy&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は294。&lt;/p&gt;

&lt;p&gt;JavaScriptでChromeを操作できるツール。
&lt;a href=&#34;https://github.com/cyrus-and/chrome-remote-interface&#34;&gt;chrome-remote-interface&lt;/a&gt;をラップして、
NightmareっぽいAPIを提供する。&lt;/p&gt;

&lt;p&gt;WebDriverは使ってない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://codeception.com/&#34;&gt;Codeception&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は2900。&lt;/p&gt;

&lt;p&gt;PHPUnitとSeleniumをラップして、ユーザ視点のブラウザテスト(受入テスト)をPHPで書けるフレームワーク。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://teamcapybara.github.io/capybara/&#34;&gt;Capybara&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は7937。&lt;/p&gt;

&lt;p&gt;Seleniumをラップして、ブラウザテスト(受入テスト)をRubyで書けるフレームワーク。
テストフレームワークはRack::Testを始め、いろいろ選べる模様。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.gebish.org/&#34;&gt;Geb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は759。&lt;/p&gt;

&lt;p&gt;Seleniumをラップして、 JUnitやTestNGと連携して、ブラウザテストをGroovyで書けるフレームワーク。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://selenide.org/&#34;&gt;Selenide&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は555。&lt;/p&gt;

&lt;p&gt;Seleniumをラップして、ブラウザテストをJavaで書けるフレームワーク。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これらよりさらに高級なツールに、&lt;a href=&#34;http://codecept.io/&#34;&gt;CodeceptJS&lt;/a&gt;というのがあって、これはJavaScriptでユーザ視点のブラウザテスト(受入テスト)を書けるフレームワーク。
基本的にはMochaとWebdriverIOをラップして、より抽象的なAPIを提供する。
WebdriverIOをProtractorとかNightmareとか&lt;a href=&#34;http://appium.io/&#34;&gt;Appium&lt;/a&gt;に代えられて、色んな環境のテストが統一的なAPIで書ける。
すごいけどバグを踏んだ時辛そう。&lt;/p&gt;

&lt;p&gt;また、ブラウザテストの文脈でよく名前が出る&lt;a href=&#34;http://karma-runner.github.io/1.0/index.html&#34;&gt;Karma&lt;/a&gt;は、テストフレームワークではなくて、HTTPサーバを起動して、テストを実行するためのHTMLを生成して、ブラウザを起動してそれを読み込んでくれたりするツール(i.e. テストランナ)。
主にユニットテストを色んなブラウザで実行するためのもので、ServiceNowのようなSaaSのテストには使えないはず。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;どれを使うか。&lt;/p&gt;

&lt;p&gt;ServiceNowアプリの開発がJavaScriptなので、テストもJavaScriptで書いてユニバーサルな感じにしたい。
のでCodeceptionとCapybaraとGebとSelenideは無し。&lt;/p&gt;

&lt;p&gt;テストのリモート実行やクロスブラウザテストを見据えてWebDriver使ってたほうがよさそうなので、
NightmareとCasper.jsとZombie.jsとPuppeteerとChromyも無し。&lt;/p&gt;

&lt;p&gt;TestCafeはWebDriverにこだわらなければよさそうだけど、今回はWebDriverで行きたい気分なのでパス。&lt;/p&gt;

&lt;p&gt;Protractorはよさそうだったけど、Angularで開発してるわけではないので、利用するのはちょっと違和感が。&lt;/p&gt;

&lt;p&gt;Nightwatch.jsは、全部メソッドチェーンでつなげる形で書くので、ブラウザ操作とアサーションがごっちゃになるのがちょっと見にくそう。
テストフレームワークは自分の好みで選びたい。&lt;/p&gt;

&lt;p&gt;ということで残ったのがWebdriverIO。
ややドキュメントが少なそうなのと、★が比較的少ないのが懸念。
ProtractorかNightwatch.jsにしとけばよかったってなりそうではある。&lt;/p&gt;

&lt;p&gt;むしろクロスブラウザを捨ててPuppeteerでもよかったかな…&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2017/08/14/webdriverio-chrome/&#34;&gt;WebdriverIOの環境を構築した記事&lt;/a&gt;を書いた。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>2017年夏、Selenium、ヘッドレスブラウザ</title>
          <link>https://www.kaitoy.xyz/2017/07/12/2017-selenium-headless-browsers/</link>
          <pubDate>Wed, 12 Jul 2017 22:36:22 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/07/12/2017-selenium-headless-browsers/</guid>
          <description>

&lt;p&gt;現在仕事で&lt;a href=&#34;https://www.servicenow.com/ja&#34;&gt;ServiceNow&lt;/a&gt;上で動くアプリケーションを開発していて、それのブラウザテストをどうやろうかというのを少し考えたので、書き残しておく。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;servicenowとは&#34;&gt;ServiceNowとは&lt;/h1&gt;

&lt;p&gt;本題とほとんど関係ないけど、一応ServiceNowに簡単に触れる。&lt;/p&gt;

&lt;p&gt;ServiceNowはITサービス管理のSaaS。
世界的にはITサービス管理のデファクトスタンダードとなっているが、日本ではこれから盛り上がりそうといった感じ。&lt;/p&gt;

&lt;p&gt;アプリケーションを開発するプラットフォームとしての側面もあり、JavaScript(ブラウザ側とサーバ側両方)でServiceNowの機能を拡張し、他システムと連携させたり処理を自動化したりできる。&lt;/p&gt;

&lt;p&gt;アプリケーションがServiceNowプラットフォームで動くので、テスト方法が悩ましい。
&lt;a href=&#34;https://docs.servicenow.com/bundle/istanbul-release-notes/page/release-notes/servicenow-platform/automated-test-framework-rn.html&#34;&gt;Automated Test Framework&lt;/a&gt;というテストフレームワークが提供されてはいるが、2017年1月にリリースされたばかりということもあるのか、機能がしょぼく、大したことはできない。
これが自前でブラウザテスト環境を作ろうと思った理由。&lt;/p&gt;

&lt;p&gt;アプリケーションがJavaScriptなので、テストもJavaScriptで書きたい。&lt;/p&gt;

&lt;h1 id=&#34;ブラウザテストとは&#34;&gt;ブラウザテストとは&lt;/h1&gt;

&lt;p&gt;ここでブラウザテストとは、稼働しているWebアプリケーションに、HTTPクライアントで接続して、レンダリングされたWebページを操作して実行する自動E2Eテストのこととする。
HTTPでWebコンテンツを取得して、HTML・CSSをパースしてレンダリングして、JavaScriptを実行するツール、つまりWebブラウザを何にするかというのと、それを自動で操作するのをどうするかというのと、テストどう書くのかということと、書いたテストをどう実行するかということと、テスト結果をどう集計してレポートするかといった辺りを考える必要がある。&lt;/p&gt;

&lt;p&gt;Qiitaの記事「&lt;a href=&#34;http://qiita.com/cognitom/items/6cce719b57341769c14d&#34;&gt;ブラウザテストツール総まとめ・2016年夏版&lt;/a&gt;」にブラウザテストのためのツールが色々載っている。
レイヤや目的が異なるツールがちょっとごっちゃになってる気がするけど。&lt;/p&gt;

&lt;h1 id=&#34;seleniumとかwebdriverとか&#34;&gt;SeleniumとかWebDriverとか&lt;/h1&gt;

&lt;p&gt;ブラウザテストはWebDriver抜きでは語れないので、とりあえずそれについて書く。
それにはまず&lt;a href=&#34;http://www.seleniumhq.org/&#34;&gt;Selenium&lt;/a&gt;について語らなければなるまい。&lt;/p&gt;

&lt;p&gt;ブラウザテスト創世記にはこうある。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;神は「光あれ」と言われた。
するとSeleniumがあった。&lt;/p&gt;

&lt;p&gt;神はその光を見て、良しとされた。
神はその光と闇とを分けられた。&lt;/p&gt;

&lt;p&gt;神は光を&lt;a href=&#34;http://www.seleniumhq.org/projects/remote-control/&#34;&gt;Selenium RC&lt;/a&gt; (aka Selenium 1)と名づけ、
闇 を&lt;a href=&#34;http://www.seleniumhq.org/projects/webdriver/&#34;&gt;Selenium WebDriver&lt;/a&gt; (aka Selenium 2)と名づけられた。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(Seleniumの歴史をもっとちゃんと知りたければ&lt;a href=&#34;http://blog.trident-qa.com/2013/05/so-many-seleniums/&#34;&gt;この記事&lt;/a&gt;を読むべし。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;要は、今ブラウザテストと言ったらSelenium、Seleniumと言ったらSelenium WebDriverというわけだ。&lt;/p&gt;

&lt;p&gt;Selenium WebDriverは、WebDriver APIでブラウザやDOMエレメントを操作するツール。
このAPIを実装したクライアントライブラリが各言語(Java、Ruby、Python、JavaScriptなど)で提供されていて、テストコードから利用できる。&lt;/p&gt;

&lt;p&gt;APIの裏ではドライバなるものが暗躍していて、OSやブラウザのネイティブAPIを使ってブラウザを操作している。
このドライバはブラウザごと(Chrome、Firefox、IEなど)に用意されていて、その実装形式がドライバ毎に割と違っている。
例えばFirefox用のやつ(&lt;a href=&#34;https://github.com/SeleniumHQ/selenium/wiki/FirefoxDriver&#34;&gt;Firefox Driver&lt;/a&gt;)はFirefox のアドオンを使うし、Chrome用のやつ(&lt;a href=&#34;https://github.com/SeleniumHQ/selenium/wiki/ChromeDriver&#34;&gt;ChromeDriver&lt;/a&gt;)は独立したネイティブアプリを介してブラウザを操作する。&lt;/p&gt;

&lt;p&gt;ドライバは(基本的に)ブラウザと同じマシンにある必要があり、実行するテストコードとも(基本的に)同居している必要がある。
テストを実行するマシンとは別のマシンのブラウザでテストしたければ&lt;a href=&#34;http://docs.seleniumhq.org/download/&#34;&gt;Selenium Server&lt;/a&gt; (aka Selenium Standalone Server)を使う。
Selenium Serverはブラウザとドライバと同じマシンで動き、テストコードから送信されたブラウザ操作コマンドを受信してドライバに伝える、プロキシ的な働きをしてくれる。&lt;/p&gt;

&lt;p&gt;Selenium Serverを使えば、クライアントライブラリが対応していないドライバでも利用できるというメリットもある。
Selenium Serverを使うと、オーバーヘッドはあるけどメリットが多いので、とりあえず使うようにしておけば間違いなさそう。&lt;/p&gt;

&lt;p&gt;Selenium Serverが受け取るブラウザ操作コマンドは、HTTPでJSONデータとして送信される。
この辺りの通信は、もともと&lt;a href=&#34;https://github.com/SeleniumHQ/selenium/wiki/JsonWireProtocol&#34;&gt;JsonWireProtocol&lt;/a&gt; (aka WebDriver Wire Protocol)で規定されていた。
JsonWireProtocolを&lt;a href=&#34;https://en.wikipedia.org/wiki/World_Wide_Web_Consortium&#34;&gt;W3C&lt;/a&gt;が国際標準規格化したのが&lt;a href=&#34;https://www.w3.org/TR/webdriver/&#34;&gt;WebDriver&lt;/a&gt;というプロトコル。
このWebDriverプロトコルは、ユーザエージェントとDOMエレメントをリモートコントロールするためのインターフェースを定めている。
現在、JsonWireProtocolは廃止扱いで、Selenium WebDriverはWebDriverプロトコルを実装している。&lt;/p&gt;

&lt;p&gt;この辺り、&lt;a href=&#34;https://app.codegrid.net/entry/selenium-1&#34;&gt;この記事&lt;/a&gt;が図解してて分かりやすい。&lt;/p&gt;

&lt;p&gt;ChromeDriverはWebDriverプロトコルを実装してるので、Selenium Server無しでもリモート実行できるけど、それでもやはりSelenium Serverを介したほうが、ドライバを簡単に切り替えられそうでよさそう。&lt;/p&gt;

&lt;p&gt;Selenium ServerとかChromeDriverのようにWebDriverプロトコルのサーバ機能を実装したものは&lt;a href=&#34;https://github.com/SeleniumHQ/selenium/wiki/RemoteWebDriverServer&#34;&gt;RemoteWebDriverServer&lt;/a&gt;と呼ばれることもある。
それにアクセスするクライアントは&lt;a href=&#34;https://github.com/SeleniumHQ/selenium/wiki/RemoteWebDriver&#34;&gt;RemoteWebDriver&lt;/a&gt;とかRemoteWebDriverクライアントとか呼ばれる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ということで、色々ややこしい(公式も自分でややこしいと言ってる)が、結局WebDriverは何かと言えば、普通は上記ドライバそのものを指す。
ので、以下においても、WebDriverと書いたらそれを指すこととする。&lt;/p&gt;

&lt;h1 id=&#34;ヘッドレス&#34;&gt;ヘッドレス&lt;/h1&gt;

&lt;p&gt;もう一つブラウザテストの文脈で重要なのが、&lt;a href=&#34;https://en.wikipedia.org/wiki/Headless_software&#34;&gt;ヘッドレス&lt;/a&gt;という概念なので、ここでちょっと触れる。&lt;/p&gt;

&lt;p&gt;ヘッドレスとは、ソフトウェアがGUIなしで動く性質とか機能のこと。&lt;/p&gt;

&lt;p&gt;ブラウザテストは、テスト実行時にブラウザを起動するわけだが、ブラウザってのは普通GUIが付いていて、Windowsだったらログインしてないと動かせないし、LinuxだったらXの起動も必要だ。
これだと、テストを定期的に自動実行したり、CIしたりするのが難しい。
また、GUIは動作が遅く、テストに時間がかかる。&lt;/p&gt;

&lt;h3 id=&#34;ヘッドレスブラウザ&#34;&gt;ヘッドレスブラウザ&lt;/h3&gt;

&lt;p&gt;こうした問題を解決するため、ヘッドレスブラウザというものが開発された。
ヘッドレスブラウザには以下のようなものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://phantomjs.org/&#34;&gt;PhantomJS&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;多分一番有名なヘッドレスブラウザ。
JavaScriptとC++などで書かれていて、JavaScriptから操作できる。
2011年にリリースされ、まだ開発が続いている。
レンダリングエンジンはWebKitで、JavaScriptエンジンはWebKitに組み込みの&lt;a href=&#34;https://trac.webkit.org/wiki/JavaScriptCore&#34;&gt;JavaScriptCore&lt;/a&gt;で、
Windows、OS X、Linuxなどで動く。
WebDriver有り。(&lt;a href=&#34;https://github.com/detro/ghostdriver&#34;&gt;Ghost Driver&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://htmlunit.sourceforge.net/&#34;&gt;HtmlUnit&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Chrome、Firefox、IEをシミュレートできるJava製のツールで、
JavaのAPIで操作できる。
2002年にリリースされ、まだ開発が続いている。
レンダリングエンジンは(多分)自前で、JavaScriptエンジンはRhino。
WebDriver有り。(&lt;a href=&#34;https://github.com/SeleniumHQ/htmlunit-driver&#34;&gt;HtmlUnitDriver&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://scrapinghub.com/splash/&#34;&gt;Splash&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Python製。2013年に開発がスタートし、現在も鋭意開発中。
LinuxとOS Xをサポートしてて、Windowsでは(多分)動かない。
HTTP APIにJSONをPOSTして操作するもので、&lt;a href=&#34;https://www.lua.org/&#34;&gt;Lua&lt;/a&gt;のクライアントライブラリが提供されている。
レンダリングエンジンはWebKitで、JavaScriptエンジンはWebKitに組み込みのJavaScriptCore。
WebDriverなさげ。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://triflejs.org/&#34;&gt;TrifleJS&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;JavaScriptとC#(.NET 4.0)で書かれていて、Windowsでしか動かない。
 レンダリングエンジンはTridentで、IEをエミュレートする。
 JavaScriptエンジンはV8。PhantomJSと同じAPIを実装していて、JavaScriptから操作できる。
 2013年に開発がスタートし、ベータ版のまま開発中断してしまった模様。
 WebDriverは、ロードマップにはあるけどまだ実装されてない。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あと、似たようなものに&lt;a href=&#34;https://slimerjs.org/index.html&#34;&gt;SlimerJS&lt;/a&gt;と&lt;a href=&#34;https://electron.atom.io/&#34;&gt;Electron&lt;/a&gt;と&lt;a href=&#34;https://github.com/tmpvar/jsdom&#34;&gt;jsdom&lt;/a&gt;がある。&lt;/p&gt;

&lt;p&gt;SlimerJSは、GeckoとSpiderMonkeyの上に開発された、スクリプトから操作できるテスト用途向けブラウザだけど、ヘッドレスではない。&lt;/p&gt;

&lt;p&gt;ElectronはJavaScriptでデスクトップアプリケーションを開発するためのフレームワーク。
&lt;a href=&#34;https://www.chromium.org/Home&#34;&gt;Chromium&lt;/a&gt;というブラウザを積んでいて、それをElectron APIでプログラマティックに操作できるらしく、ブラウザテストにも使われる。
(&lt;a href=&#34;http://qiita.com/hiroshitoda/items/288706978cd4c6df0f5f&#34;&gt;Seleniumでも操作できる&lt;/a&gt;。)
けどこれもヘッドレスではない。&lt;/p&gt;

&lt;p&gt;jsdomはDOMツリーとそれに対する操作をエミュレートするツールで、そもそもブラウザではないはずなんだけど、HTTPでWebコンテンツダウンロードして解析もできるし、すごくヘッドレスブラウザっぽい。
けどちゃんとブラウザしてるかが怪しく、UIテストには使われてもブラウザテストにはあまり使われないっぽい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ヘッドレスブラウザにも色々あるが結局、テスト用に作られたブラウザであって、実際に多くのエンドユーザに使われて揉まれているGUI有りブラウザに比べて、品質が悪かったり動きが違ったりする(らしい)。
JavaScriptのバージョンのキャッチアップが遅かったりも。&lt;/p&gt;

&lt;h3 id=&#34;xvfb&#34;&gt;Xvfb&lt;/h3&gt;

&lt;p&gt;ヘッドレスブラウザの問題は、実際のブラウザではないということに尽きる。
実際のブラウザをヘッドレスで使えたら万事が上手くいくわけだが、実はこれがLinuxでなら出来る。
&lt;a href=&#34;https://www.x.org/releases/X11R7.7/doc/man/man1/Xvfb.1.xhtml&#34;&gt;Xvfb&lt;/a&gt;というツールを使って。
(Xvfbはあまりメンテされてなくて&lt;a href=&#34;https://xpra.org/trac/wiki/Xdummy&#34;&gt;Xdummy&lt;/a&gt;が代わりに最近熱いみたいだけど。)&lt;/p&gt;

&lt;p&gt;Xvfbはフレームバッファをエミュレートし、ディスプレイが無い環境でも動くヘッドレスXサーバ。
これを使うと、GUIのある普通のブラウザでもヘッドレス環境で動かせる。&lt;/p&gt;

&lt;p&gt;Xvfbについては&lt;a href=&#34;http://blog.amedama.jp/entry/2016/01/03/115602&#34;&gt;この記事&lt;/a&gt;が分かりやすい。&lt;/p&gt;

&lt;h3 id=&#34;chrome-59&#34;&gt;Chrome 59&lt;/h3&gt;

&lt;p&gt;Xvfbを使えば大分幸せになりそうだが、ブラウザ以外のツールを起動しなければいけなかったり、Windowsで使えなかったり、まだちょっと不満が残る。&lt;/p&gt;

&lt;p&gt;そんななか、2017年6月、Chrome 59がリリースされ、ヘッドレスモードを搭載した。
Windowsは現時点で未対応だけど、すぐに対応されるはずだ。
ほかの実ブラウザもこの流れに乗ってヘッドレスモードを実装したら、最高に幸せな世界になるではないか。&lt;/p&gt;

&lt;p&gt;Chromeのヘッドレスモード搭載を受け、&lt;a href=&#34;https://www.infoq.com/jp/news/2017/04/Phantomjs-future-uncertain&#34;&gt;PhantomJSは開発停止&lt;/a&gt;した。
もうヘッドレスブラウザはその役目を終えつつあるということなのだろう。&lt;/p&gt;

&lt;p&gt;Chrome 59のヘッドレスモードの使い方は&lt;a href=&#34;https://developers.google.com/web/updates/2017/04/headless-chrome?hl=ja&#34;&gt;この記事&lt;/a&gt;が分かりやすい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;
&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上のような感じのことが調べて分かって、SeleniumとChromeのヘッドレスモードを使いたいと思ったところで、
続きはまた&lt;a href=&#34;https://www.kaitoy.xyz/2017/08/04/browser-test-framework/&#34;&gt;別の記事&lt;/a&gt;。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>git rebaseを図解する</title>
          <link>https://www.kaitoy.xyz/2017/06/10/git-rebase/</link>
          <pubDate>Sat, 10 Jun 2017 00:00:17 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/06/10/git-rebase/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;この記事&lt;/a&gt;を読んだ、またはGitのオブジェクトモデルを理解していることを前提に、&lt;a href=&#34;https://git-scm.com/&#34;&gt;&lt;strong&gt;Git&lt;/strong&gt;&lt;/a&gt;の &lt;code&gt;git rebase&lt;/code&gt; というコマンドについて説明する。&lt;/p&gt;

&lt;p&gt;このコマンドは、コミット履歴を改変できるGit特有のコマンドで、&lt;a href=&#34;http://qiita.com/kaitoy/items/ed22474837b943eb6d97&#34;&gt;分かり辛いGitコマンド&lt;/a&gt;の中でも最も分かり辛い部類のものだ。
Gitの最後の関門と言えよう。
けど、それだけに使いこなせばとても便利なものでもある。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;git-rebaseがもつたった一つの機能&#34;&gt;git rebaseがもつたった一つの機能&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;git rebase&lt;/code&gt;にはいろんなオプションがあって、ちょっと調べただけだと、コミットを移動する機能とコミットを修正する機能の二つがあるように見えるかもしれないが、実際は単一の機能しかないシンプルなコマンドだ。&lt;/p&gt;

&lt;p&gt;その機能とは、指定した範囲のコミットが含む変更を、別に指定したコミットのコードベースに適用するというもの。&lt;/p&gt;

&lt;p&gt;コマンドの基本形は次のようなものだ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ git rebase --onto master dev bugfix
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このコマンドは、&lt;code&gt;bugfix&lt;/code&gt;から辿れるコミット群から、&lt;code&gt;dev&lt;/code&gt;から辿れるコミット群を除いたコミット群が含む変更を、&lt;code&gt;master&lt;/code&gt;のコードベースに適用する。&lt;/p&gt;

&lt;p&gt;と書いても分からないので図解する。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase/スライド6.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;このスライドを見ると、&lt;code&gt;git rebase&lt;/code&gt;に指定した3つのブランチのそれぞれの使われ方が分かるはず。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git rebase --onto master dev bugfix&lt;/code&gt;が実行する処理をもっと正確に言うと、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;bugfix&lt;/code&gt;を&lt;code&gt;checkout&lt;/code&gt;して(i.e. &lt;code&gt;HEAD&lt;/code&gt;を&lt;code&gt;bugfix&lt;/code&gt;にして)、&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dev..HEAD&lt;/code&gt;のコミット群が含む変更を、それぞれ仮領域にパッチとして保存して、&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git reset --hard master&lt;/code&gt;して、&lt;/li&gt;
&lt;li&gt;仮領域に保存した変更を、&lt;code&gt;HEAD&lt;/code&gt;が指すコミットのコードベースにひとつひとつ順番に適用する。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;上記コマンドで&lt;code&gt;bugfix&lt;/code&gt;のところを省略すると、ステップ1の&lt;code&gt;checkout&lt;/code&gt;が省略される。
言い換えると、上記コマンドは次の二つのコマンドに分解できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ git checkout bugfix
$ git rebase --onto master dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;さらに、&lt;code&gt;--onto master&lt;/code&gt;を省略すると、ステップ3の&lt;code&gt;reset&lt;/code&gt;先が変わり、&lt;code&gt;dev&lt;/code&gt;になる。
このときのコマンドの形は、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ git rebase dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;という見慣れたものになるが、これが最初に挙げた基本形の省略形だと認識しておくと応用が利く。&lt;/p&gt;

&lt;p&gt;以下に&lt;code&gt;git rebase dev&lt;/code&gt;の動きを細かめに図解する。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド6.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド7.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;インタラクティブモード&#34;&gt;インタラクティブモード&lt;/h2&gt;

&lt;p&gt;前節のスライドに書いたパッチの適用をカスタマイズできるのがインタラクティブモードで、これは&lt;code&gt;-i&lt;/code&gt;オプションで有効にできる。
インタラクティブモードを使うと、パッチをスキップしたり、順番を変えたり、まとめたり、分割したり、編集したりでき、またパッチとパッチの間に任意のコマンドを実行でき、例えばパッチごとにユニットテストを実行できたりする。&lt;/p&gt;

&lt;p&gt;インタラクティブモードの使い方についてはググればたくさん出てくるのでここには書かない。
&lt;a href=&#34;http://tkengo.github.io/blog/2013/05/16/git-rebase-reference/&#34;&gt;この記事&lt;/a&gt;辺りがわかりやすい。&lt;/p&gt;

&lt;p&gt;インタラクティブモードのユースケースとしてよく紹介されるのが、&lt;code&gt;git rebase -i HEAD^^&lt;/code&gt;で直近の二つのコミットを変更するといったものだが、これを図解すると以下のようになる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド6.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド7.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド8.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド9.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;このスライドを見ると、&lt;code&gt;git rebase dev&lt;/code&gt;と&lt;code&gt;git rebase -i HEAD^^&lt;/code&gt;は、パッチの適用がインタラクティブかどうか以外は同じ処理をしていることがわかる。
見た目の違いに惑わされないようにしたい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git rebase&lt;/code&gt;はブランチを複数指定したりして分かり辛いコマンドであることは確かだけど、上記の基本形を押さえておけばすんなり理解できるはず。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Elasticsearch、Logstash、Filebeat、elasticsearch-headでログを見てみた</title>
          <link>https://www.kaitoy.xyz/2017/04/04/elasticsearch-in-nnmi-log/</link>
          <pubDate>Tue, 04 Apr 2017 09:24:12 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/04/04/elasticsearch-in-nnmi-log/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://www8.hp.com/jp/ja/software-solutions/network-node-manager-i-network-management-software/&#34;&gt;NNMi&lt;/a&gt;ログを&lt;a href=&#34;https://www.elastic.co/jp/products/beats/filebeat&#34;&gt;Filebeat&lt;/a&gt;で集めて&lt;a href=&#34;https://www.elastic.co/jp/products/logstash&#34;&gt;Logstash&lt;/a&gt;で構造化して&lt;a href=&#34;https://www.elastic.co/jp/products/elasticsearch&#34;&gt;Elasticsearch&lt;/a&gt;に入れて&lt;a href=&#34;https://mobz.github.io/elasticsearch-head/&#34;&gt;elasticsearch-head&lt;/a&gt;で見てみたけど、ログ量が少なかったせいかあんまり恩恵が感じられなかった話。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;elasticsearchとは&#34;&gt;Elasticsearchとは&lt;/h1&gt;

&lt;p&gt;Elasticsearchは&lt;a href=&#34;https://www.elastic.co/&#34;&gt;Elastic社&lt;/a&gt;が開発している&lt;a href=&#34;https://www.elastic.co/products&#34;&gt;Elastic Stack&lt;/a&gt;(旧ELK Stack)というオープンソースなデータ収集分析ツール群のコア製品。
内部で&lt;a href=&#34;https://lucene.apache.org/core/&#34;&gt;Lucene&lt;/a&gt;を使っていて、そのためJava製。
「分散型RESTful検索/分析エンジン」と自称しているが、スキーマレスでNoSQLなドキュメント指向分散データベース管理システムとも見れる。&lt;/p&gt;

&lt;p&gt;Elasticsearchインスタンスはノードと呼ばれ、単一または複数のノードによるシステムはクラスタと呼ばれる。
同一ネットワークに複数のノードを立ち上げると自動で相互検出してクラスタを構成してくれ、そこにデータを入れると自動で冗長化して分散配置してくれるので、堅牢でレジリエントでスケーラブルなシステムが簡単に構築できる。&lt;/p&gt;

&lt;p&gt;Elasticsearchが管理するデータの最小単位はドキュメントと呼ばれ、これはひとつのJSONオブジェクトで、RDBにおける行にあたる。
つまり、JSONオブジェクトの各フィールドがRDBにおける列にあたる。
同種のドキュメントの集まりはインデックスと呼ばれ、これはRDBにおけるテーブルにあたる。
テーブルのスキーマにあたるものはマッピングと呼ばれ、ドキュメントのフィールドの型情報(e.g. string, integer)などを含み、Elasticsearchが自動で生成してくれる。(指定もできる、というかすべきらしい。)
インデックス内ではさらにタイプという属性でドキュメントをカテゴライズできる、が、マニュアルからはタイプはあまり&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/general-recommendations.html#_avoid_types&#34;&gt;使ってほしくない&lt;/a&gt;雰囲気が感じられる。&lt;/p&gt;

&lt;p&gt;(2018/4/25追記: 6.0で、一つのインデックスに複数のタイプを作ることができなくなり、7.0では完全に&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/6.x/removal-of-types.html&#34;&gt;タイプが廃止される&lt;/a&gt;ことになった。)&lt;/p&gt;

&lt;p&gt;因みに、インデックスがRDBのデータベースでタイプがRDBのテーブルと説明されることもあるが、これは古いたとえで、&lt;a href=&#34;https://www.elastic.co/blog/index-vs-type&#34;&gt;公式が間違いだったとしている&lt;/a&gt;ので忘れてあげたい。&lt;/p&gt;

&lt;p&gt;インデックスは分散処理のために分割でき、分割した各部分はシャードと呼ばれる。
シャードを冗長化のためにコピーしたものはレプリカシャードと呼ばれ、レプリカシャードにより成るインデックスはレプリカと呼ばれる。
デフォルトでは、ひとつのインデックスは5つのシャードに分割され、1つのレプリカが作成される。&lt;/p&gt;

&lt;p&gt;インターフェースはREST APIだけ。
REST APIに検索したいドキュメントを投げると、ドキュメントのフィールド毎に自動で形態素解析とかして&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E8%BB%A2%E7%BD%AE%E3%82%A4%E3%83%B3%E3%83%87%E3%83%83%E3%82%AF%E3%82%B9&#34;&gt;転置インデックス&lt;/a&gt;作って保管してくれる。
検索もJSONで表現したクエリをREST APIに投げることで結果をJSONで受け取ることができる。
検索は転置インデックスや分散処理のおかげで速く、また&lt;a href=&#34;http://qiita.com/r4-keisuke/items/d653d26b6fc8b7955c05#%E3%82%B9%E3%82%B3%E3%82%A2%E3%83%AA%E3%83%B3%E3%82%B0&#34;&gt;スコアリング&lt;/a&gt;によってより適切な結果が得られるようになっている。&lt;/p&gt;

&lt;p&gt;今回使ったのはv5.2.1。&lt;/p&gt;

&lt;h1 id=&#34;logstashとは&#34;&gt;Logstashとは&lt;/h1&gt;

&lt;p&gt;LogstashはElastic Stackに含まれる製品で、データ収集エンジンであり、データの受け取り、解析/加工、出力の三つの機能を持つリアルタイムパイプラインを構成する。
この三つの機能はそれぞれ&lt;a href=&#34;https://www.elastic.co/guide/en/logstash/5.2/input-plugins.html&#34;&gt;インプットプラグイン&lt;/a&gt;、&lt;a href=&#34;https://www.elastic.co/guide/en/logstash/5.2/filter-plugins.html&#34;&gt;フィルタプラグイン&lt;/a&gt;、&lt;a href=&#34;https://www.elastic.co/guide/en/logstash/5.2/output-plugins.html&#34;&gt;アウトプットプラグイン&lt;/a&gt;で提供されていて、プラグインの組み合わせにより様々なパイプラインを構成できる。&lt;/p&gt;

&lt;p&gt;インプットプラグインは単位データ(一回分のログなど)を受け取り、タイムスタンプなどのメタデータを付けたりパースしたりしてイベントを生成し、パイプラインに流す。
フィルタプラグインはインプットプラグインからイベントを受け取り、設定されたルールに従って情報を拡充したり変更したり構造化したり秘匿情報を消したりしてアウトプットプラグインに渡す。
アウトプットプラグインは指定されたディスク上のパスやデータベースやアプリやサービスにイベントを書き込んだり送信したりする。&lt;/p&gt;

&lt;p&gt;名前の通りもともとログ収集ツールだったが、今では様々なデータに対応していて、テキストログファイルの他にsyslog、HTTPリクエストやJDBCなんかの入力を受けることもできる。&lt;/p&gt;

&lt;p&gt;Ruby(とJava)で書かれている。&lt;/p&gt;

&lt;p&gt;今回使ったのはv5.2.2で、プラグインは以下を使った。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;インプット: &lt;a href=&#34;https://www.elastic.co/guide/en/logstash/5.2/plugins-inputs-beats.html&#34;&gt;beats&lt;/a&gt; 3.1.12: Beats(後述)からデータを受け取るプラグイン。&lt;a href=&#34;https://github.com/logstash-plugins/logstash-input-beats/blob/v3.1.12/PROTOCOL.md&#34;&gt;Lumberjack&lt;/a&gt;というElastic社が開発しているプロトコルを使い、TCPネットワーク上でデータを受信する。&lt;/li&gt;
&lt;li&gt;フィルタ: &lt;a href=&#34;https://www.elastic.co/guide/en/logstash/5.2/plugins-filters-grok.html&#34;&gt;grok&lt;/a&gt; 3.3.1: 正規表現でパターンマッチして非構造化データを構造化するプラグイン。ログ解析の定番で、例えば、ログからタイムスタンプ、クラス名、ログメッセージを抽出したりする。&lt;a href=&#34;https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns&#34;&gt;組み込みのパターン&lt;/a&gt;が120個くらいあり、&lt;a href=&#34;https://httpd.apache.org/&#34;&gt;Apache HTTP Server&lt;/a&gt;やsyslogのログであれば自分で正規表現を書く必要はない。&lt;/li&gt;
&lt;li&gt;アウトプット: &lt;a href=&#34;https://www.elastic.co/guide/en/logstash/5.2/plugins-outputs-elasticsearch.html&#34;&gt;elasticsearch&lt;/a&gt; 6.2.6: Elasticsearchにイベントをポストするプラグイン。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;beatsとは&#34;&gt;Beatsとは&lt;/h1&gt;

&lt;p&gt;BeatsもElastic Stackに含まれる製品で、データを採取してLogstashやElasticsearchに送信する製品群の総称。
&lt;a href=&#34;https://github.com/elastic/beats/tree/master/libbeat&#34;&gt;libbeat&lt;/a&gt;というGoのライブラリを使って作られていて、以下のようなものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/elastic/beats/tree/master/filebeat&#34;&gt;Filebeat&lt;/a&gt;: ログファイルからログを取得する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/elastic/beats/tree/master/heartbeat&#34;&gt;Heartbeat&lt;/a&gt;: リモートサービスをpingして生死監視する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/elastic/beats/tree/master/metricbeat&#34;&gt;Metricbeat&lt;/a&gt;: OSとその上のサービスやアプリから稼動情報を取得する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/elastic/beats/tree/master/packetbeat&#34;&gt;Packetbeat&lt;/a&gt;: パケットキャプチャしてネットワークのトラフィックを監視する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/elastic/beats/tree/master/winlogbeat&#34;&gt;Winlogbeat&lt;/a&gt;: Windowsのイベントログを取得する。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;今回使ったのはFilebeat 5.2.2。&lt;/p&gt;

&lt;p&gt;Filebeatは指定したログファイルを監視し、変更を検知してリアルタイムにログを送信してくれる。
FilebeatとLogstashが仲良くやってくれて、バッファがあふれるなどすることによるログの損失が起きないようにしてくれるらしい。
Logstashが単位データを受け取るので、ログファイルからひとつひとつのログを切り出すのはFilebeatの責務。
一行一ログなら何も考えなくていいけど、大抵複数行のログがあるのでなんとかする必要がある。&lt;/p&gt;

&lt;h1 id=&#34;elasticsearch-headとは&#34;&gt;elasticsearch-headとは&lt;/h1&gt;

&lt;p&gt;elasticsearch-headは3rdパーティ製(個人製?)のElasticsearchのWeb UI。
ElasticsearchのUIはREST APIしかないのでこういうものを使わないと辛い。&lt;/p&gt;

&lt;p&gt;ElasticsearchのGUIとしてはElastic Stackの&lt;a href=&#34;https://www.elastic.co/jp/products/kibana&#34;&gt;Kibana&lt;/a&gt;が有名だけど、これは大量のログから統計的な情報を見るのに便利そうなものであって、今回やりたかった障害原因調査のためにログを細かく追うのには向いてなさそうだったので使わなかった。&lt;/p&gt;

&lt;h1 id=&#34;実験環境&#34;&gt;実験環境&lt;/h1&gt;

&lt;p&gt;今回は単にログがどんな感じに見えるか試したかっただけなので、全部ローカルで動かして、ローカルに置いた静的なログファイルを読むだけ。
環境はWindows 7のノートPC。&lt;/p&gt;

&lt;p&gt;ログファイルは&lt;code&gt;C:\Users\Kaito\Desktop\logs\&lt;/code&gt;においた&lt;code&gt;nnm-trace.log&lt;/code&gt;と&lt;code&gt;nnm-trace.log.1&lt;/code&gt;。
これらはNNMiのメインログで、&lt;a href=&#34;https://docs.oracle.com/javase/8/docs/api/java/util/logging/package-summary.html&#34;&gt;JUL&lt;/a&gt;で出力されたもの。
NNMiは無料のコミュニティエディションのv10.00をVMのCentOSに適当に入れて採った。&lt;/p&gt;

&lt;p&gt;ログはだいたい以下の様な一行のもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2017-03-15 19:09:55.896 INFO  [com.hp.ov.nms.spi.common.deployment.deployers.ExtensionServicesDeployer] (Thread-2) Deploying arris-device
2017-03-15 19:09:55.923 WARNING [com.hp.ov.nms.topo.spi.server.concurrent.NmsTimerTaskImpl] (NmsWorkManager Scheduler) Skipping task execution because previous execution has not completed: com.hp.ov.nnm.im.NnmIntegrationModule$EnablerTask@3abdac77
2017-03-15 19:09:56.120 INFO  [com.hp.ov.nms.disco.spi.DiscoExtensionNotificationListener] (Thread-2) Disco deployed mapping rules: META-INF/disco/rules/cards/ArrisCard.xml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;たまに複数行のものがある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2017-03-15 19:13:30.872 INFO  [com.hp.ov.nms.trapd.narrowfilter.NarrowTrapAnalysis] (pool-1-thread-18)
***** Hosted Object Trap Rate Report *****
Hosted object trap storm detection and suppression stage started: Wed Mar 15, 2017 19:09:00.746 PM.

***** General Statistics *****
Hosted Object trap rate threshold: 10 traps/sec.
Average trap rate: 0 traps/sec.
Total traps received: 0.
Total traps received without configuration: 0.
Total traps suppressed: 0.
Number of trap configurations: 1.


***** END Hosted object trap storm report END *****
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ログレベルの部分(e.g. INFO、WARNING)はロケールによって日本語になったりする。&lt;/p&gt;

&lt;p&gt;スレッド名の部分(e.g. pool-1-thread-18)は丸括弧で囲われているが、丸括弧を含むことがある。&lt;/p&gt;

&lt;p&gt;クラス名の部分(e.g. com.hp.ov.nms.trapd.narrowfilter.NarrowTrapAnalysis)は、パッケージ名がついていないこともある。デフォルトパッケージってこともないだろうに。&lt;/p&gt;

&lt;h1 id=&#34;elastic-stackのインストールと設定&#34;&gt;Elastic Stackのインストールと設定&lt;/h1&gt;

&lt;p&gt;Elastic Stackの三つはどれも、サイトからアーカイブをダウンロードして展開すればインストール完了。&lt;/p&gt;

&lt;p&gt;Filebeatの設定は、展開したディレクトリのトップにある&lt;code&gt;filebeat.yml&lt;/code&gt;に以下を書いた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;filebeat.prospectors:

- input_type: log
  paths:
    - C:\Users\Kaito\Desktop\logs\*

  multiline.pattern: &#39;^[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9]{3} &#39;
  multiline.negate: true
  multiline.match: after

output.logstash:
  hosts: [&amp;quot;localhost:5043&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;paths&lt;/code&gt;でログファイルを指定して、&lt;code&gt;hosts&lt;/code&gt;でログの送信先を指定している。
また、複数行のログに対応するため、&lt;code&gt;multiline&lt;/code&gt;という設定を書いていて、タイムスタンプで始まらない行は前の行の続きになるようにしている。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Logstashの設定は、展開したディレクトリのトップに&lt;code&gt;pipeline.conf&lt;/code&gt;というファイルを作ってそこに以下を書いた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;input {
    beats {
        port =&amp;gt; &amp;quot;5043&amp;quot;
    }
}
filter {
    grok {
        match =&amp;gt; { &amp;quot;message&amp;quot; =&amp;gt; &amp;quot;%{TIMESTAMP_ISO8601:timestamp} (?&amp;lt;log_level&amp;gt;[^ ]+) +\[(?:%{JAVACLASS:class}|(?&amp;lt;class&amp;gt;[A-Za-z0-9_]+))\] \((?&amp;lt;thread&amp;gt;.+(?=\) ))\) (?&amp;lt;log_message&amp;gt;.*)&amp;quot;}
    }
}
output {
    elasticsearch {
        hosts =&amp;gt; [ &amp;quot;localhost:9200&amp;quot; ]
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;input&lt;/code&gt;と&lt;code&gt;output&lt;/code&gt;の部分は単にbeatsプラグインとelasticsearchプラグイン使うようにして送受信先を指定しているだけ。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;filter&lt;/code&gt;の部分は、grokプラグインを使うようにしつつそのパターンマッチングを指定している。
FilebeatがJSONオブジェクトの&lt;code&gt;message&lt;/code&gt;というフィールドに一回分のログを入れて送ってくるので、そこからタイムスタンプ、ログレベル、クラス、スレッド、ログメッセージを抽出し、それぞれ&lt;code&gt;timestamp&lt;/code&gt;、&lt;code&gt;log_level&lt;/code&gt;、&lt;code&gt;class&lt;/code&gt;、&lt;code&gt;thread&lt;/code&gt;、&lt;code&gt;log_message&lt;/code&gt;というフィールドに入れるように設定。
&lt;code&gt;TIMESTAMP_ISO8601&lt;/code&gt;と&lt;code&gt;JAVACLASS&lt;/code&gt;が組み込みのパターンで、それぞれタイムスタンプとJavaのクラス名にマッチする。
けど&lt;code&gt;JAVACLASS&lt;/code&gt;がパッケージ名の付いてないクラス名にマッチしないのでちょっと細工している。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Elasticsearchの設定は、展開したディレクトリ内の&lt;code&gt;config/elasticsearch.yml&lt;/code&gt;に以下を書いた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;http.cors.enabled: true
http.cors.allow-origin: &amp;quot;*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これは、elasticsearch-headがWebアプリなので、そこからElasticsearchにアクセスできるように&lt;a href=&#34;https://en.wikipedia.org/wiki/Cross-origin_resource_sharing&#34;&gt;CORS&lt;/a&gt;を有効にする設定。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで設定は終わり。&lt;/p&gt;

&lt;h1 id=&#34;各製品の起動&#34;&gt;各製品の起動&lt;/h1&gt;

&lt;p&gt;Filebeatは普通はサービスとして起動するみたいだけど、今回はコマンドラインで起動する。&lt;/p&gt;

&lt;p&gt;展開したディレクトリで以下のコマンドを実行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;filebeat.exe -e -c filebeat.yml -d &amp;quot;publish&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Logstashは展開したディレクトリで以下のコマンド。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;bin\logstash.bat -f pipeline.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Elasticsearchは展開したディレクトリで以下のコマンド。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;bin\elasticsearch.bat
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;しばらく待つと起動完了し、&lt;code&gt;localhost:9200&lt;/code&gt;でHTTPリクエストを待ち始める。
試しにブラウザで&lt;code&gt;http://localhost:9200/_cluster/health&lt;/code&gt;にアクセスすると、以下の様にElasticsearchクラスタのステータスがJSONで返ってきた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{&amp;quot;cluster_name&amp;quot;:&amp;quot;elasticsearch&amp;quot;,&amp;quot;status&amp;quot;:&amp;quot;yellow&amp;quot;,&amp;quot;timed_out&amp;quot;:false,&amp;quot;number_of_nodes&amp;quot;:1,&amp;quot;number_of_data_nodes&amp;quot;:1,&amp;quot;active_primary_shards&amp;quot;:5,&amp;quot;active_shards&amp;quot;:5,&amp;quot;relocating_shards&amp;quot;:0,&amp;quot;initializing_shards&amp;quot;:0,&amp;quot;unassigned_shards&amp;quot;:5,&amp;quot;delayed_unassigned_shards&amp;quot;:0,&amp;quot;number_of_pending_tasks&amp;quot;:0,&amp;quot;number_of_in_flight_fetch&amp;quot;:0,&amp;quot;task_max_waiting_in_queue_millis&amp;quot;:0,&amp;quot;active_shards_percent_as_number&amp;quot;:50.0}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でElastic Stackが起動し、Elasticsearchにログが読み込まれた。&lt;/p&gt;

&lt;h1 id=&#34;elasticsearch-headでログを見る&#34;&gt;elasticsearch-headでログを見る&lt;/h1&gt;

&lt;p&gt;elasticsearch-headは&lt;code&gt;git clone https://github.com/mobz/elasticsearch-head.git&lt;/code&gt;してその中の&lt;code&gt;index.html&lt;/code&gt;をブラウザで開けば動く。組み込みのWebサーバを起動する手順もあるけど。&lt;/p&gt;

&lt;p&gt;開くと&lt;code&gt;http://localhost:9200/&lt;/code&gt;(i.e. Elasticsearch)にアクセスしてGUIに情報を表示してくれる。
Overviewタブには以下の様に、&lt;code&gt;logstash-2017.03.17&lt;/code&gt;というインデックスが作られていて、それに対して5つのシャードとレプリカシャードが作られている様が表示される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/elasticsearch-in-nnmi-log/overview.png&#34; alt=&#34;overview.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Browserタブではざっくりとログの一覧が見れる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/elasticsearch-in-nnmi-log/browser.png&#34; alt=&#34;browser.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Structured Queryタブでは条件を指定してログを表示できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/elasticsearch-in-nnmi-log/query.png&#34; alt=&#34;query.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;ここでは2017/3/15 19:09:50から2017/3/15 19:10:00の間のINFOレベルのDiscoExtensionNotificationListenerクラスのログを10件表示した。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;不要な列を非表示にできないし、ソートもできないし、ログメッセージ見難くくて全く使えない。
もう少しいいGUIがあれば使えるのか、そもそもElasticsearchを使うのが間違っているのか。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Firedrop(プライベートベータ)が全く期待外れだった件</title>
          <link>https://www.kaitoy.xyz/2017/03/05/firedrop-private-beta/</link>
          <pubDate>Sun, 05 Mar 2017 23:28:03 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/03/05/firedrop-private-beta/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://firedrop.ai/&#34;&gt;Firedrop&lt;/a&gt;という現在開発中のサービスがある。
WebサイトのデザインをAIがサポートしてくれるサービスだ。&lt;/p&gt;

&lt;p&gt;2016年夏の&lt;a href=&#34;https://bita.jp/dml/dwango_dennosho2-1&#34;&gt;ニュース&lt;/a&gt;を見たとき、AIがテキストコンテンツを解析してサイトを自動構成してくれ、さらにA/Bテストなどを自動でやってサイトを継続的に改善すると言う衝撃的なふれこみだったので、即座にアーリーアクセスに登録した。&lt;/p&gt;

&lt;p&gt;それからしばらく忘れていたが、3月2日にプライベートベータへの招待メールが来たので早速試してみたら、かなりのスモールスタートをしたようで全く期待外れだった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h1 id=&#34;firedrop-プライベートベータ-の機能&#34;&gt;Firedrop(プライベートベータ)の機能&lt;/h1&gt;

&lt;p&gt;Firedrop(プライベートベータ)では、SachaというAIがWebサイトの構築をサポートしてくれる。
こいつが実のところほとんど知性を感じない単なるチャットボットで、なるほどこれは見事な&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%84%A1%E8%84%B3&#34;&gt;人工無脳&lt;/a&gt;だと感心してしまうほどだ。&lt;/p&gt;

&lt;p&gt;Firedropのアカウントを作るとまず、Sachaとチャットしながらサイトの概要(タイトル、概要、画像など)を教えることになる。
するとSachaがざっくりとシングルページのサイトを作ってくれるので、それをまたSachaとのチャットで調整したりコンテンツ追加したりする。&lt;/p&gt;

&lt;p&gt;チャットと言っても、基本はこちらは5,6個ある選択肢の中からセリフを選ぶサウンドノベル方式で、一応任意の文章も入力できるがあいさつするくらいしか使い道がない。&lt;/p&gt;

&lt;p&gt;追加コンテンツはテキストと画像を渡すと自動でレイアウトしてくれるが、すごくいい感じにしてくれるというわけでもないし、むしろ画像が見切れたりするし、細かい調整はできないので、妥協できるレイアウトになるまでチェンジを繰り返すデリヘル方式を採ることになる。
デリヘルなんて利用したことないけど。&lt;/p&gt;

&lt;p&gt;画像は自分でアップロードもできるけどFiredropが提供しているものもあって、後者のやつはSachaにキーワードを伝えるとそれっぽい画像を探してくれるあたりに唯一知性を感じる。&lt;/p&gt;

&lt;p&gt;デザインができたらSachaに頼むと&lt;code&gt;firedrop.me&lt;/code&gt;ドメインで公開してくれる。&lt;/p&gt;

&lt;p&gt;(FiredropのUIのスクリーンショットを載せようかと思ったけど、プライベートベータの規約を読んだ感じだめそうだったので載せない。)&lt;/p&gt;

&lt;h1 id=&#34;実際に作ってみた&#34;&gt;実際に作ってみた&lt;/h1&gt;

&lt;p&gt;今回実際にFiredropで&lt;a href=&#34;https://www.kaitoy.xyz/2016/12/11/goslings-development-memo0-intro-design/&#34;&gt;Goslings&lt;/a&gt;のサイトを作ってみて、できたのが&lt;a href=&#34;https://quvoi3op.firedrop.me/&#34;&gt;これ&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;ひどい。&lt;/p&gt;

&lt;p&gt;そもそも当初のテキストコンテンツを解析してサイトを自動構成というコンセプトはどこへ行ったのか。
GoslingsのReadmeを入力したらシャレオツなサイトをささっと作ってくれるイメージだったんだけど。&lt;/p&gt;

&lt;p&gt;まだまだ開発中の機能がたくさんあるそうなので、GAまでにはもうちょっとなんとかなるんだろう。
あまり期待はしない。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Hibernateはどのようにして私のキャリアを破滅寸前にしたか</title>
          <link>https://www.kaitoy.xyz/2017/02/23/how-hibernate-ruined-my-career/</link>
          <pubDate>Thu, 23 Feb 2017 00:25:03 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/02/23/how-hibernate-ruined-my-career/</guid>
          <description>

&lt;p&gt;このエントリでは、Grzegorz Gajosによる記事、&lt;a href=&#34;http://ggajos.com/how-hibernate-ruined-my-career/&#34;&gt;How Hibernate Almost Ruined My Career&lt;/a&gt;を紹介する。
(Grzegorzから和訳と転載の許可は得た。)
以下はその全文の和訳だが、意訳超訳が混じっているので、もとのニュアンスを知りたければ元記事を読んでもいいし、読まなくてもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;想像してくれ。
君はJava開発者で、次のビッグプロジェクトを開始しようとしているところだ。
君は、そのプロジェクト全体に影響する根本的な決断をする必要がある。
君の柔軟なデータモデルをオブジェクト指向で抽象化するベストな方法を選択したい。生のSQLを扱いたくはないからね。
どんな種類のデータもサポートしたいし、理想では全種のデータベースをサポートしたい。&lt;/p&gt;

&lt;p&gt;すぐに思いつくのは、単にHibernateを使うという解だ。そうだろ？
Javaディベロッパの90%は君に同意するだろう。
しかし、それって正しい決断になっているだろうか？&lt;/p&gt;

&lt;p&gt;Hibernateが一般に受け入れられているスタンダードだからといって盲目的に採用してしまうと、どんな問題が発生するかを見てみよう。&lt;/p&gt;

&lt;p&gt;モニカというJava開発者がいるとしよう。
モニカは最近出世してアーキテクトの役職に就き、会社の新製品のための技術スタックを選定する責任者になった。
彼女は、Javaの世界にはデータベースとのやり取りを扱うたった一つの適切なツールがあることを知っている。Hibernateだ。
Hibernateは良く知られ支持されているJPAのスタンダードではあるが、プロジェクト開始前に多少のチェックをするのが定跡だ。
幸いにも、同僚のベンが適任者を知っている。&lt;/p&gt;

&lt;h1 id=&#34;4年前-hibernateは銀の弾丸かのように見えた&#34;&gt;4年前、Hibernateは銀の弾丸かのように見えた&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;ベン: やあモニカ。ジョンを紹介させてくれ。彼はHibernateの達人だ。君の助けになるはずだ。&lt;/li&gt;
&lt;li&gt;モニカ: ジョン、時間を取ってくれてありがとう。
今、私たちが次なる目玉製品を開発しようとしてるのは知ってる？
次のFacebookやGoogleになるつもりなの。
忙しくなるわ。巨大なものになる。
本当にすてき！
みんなとても興奮してる！
私はアーキテクトの役に就いたから、とりあえず採用する技術スタックを選定しなければいけないの。
ひとつだけまだ欠けてるのが永続化なんだけど…&lt;/li&gt;
&lt;li&gt;ジョン: Hibernate！&lt;/li&gt;
&lt;li&gt;モニカ: そう！そのとおり！
わたしもそう考えていたの！
それならわたしたちにぴったりで上手く行きそうでしょう。
マーケットと豊富な実績に裏付けられた、真の業務問題のための真の業務ソリューション。
とてもたくさんのポジティブな経験談を聞いたことがあるわ。
けど、一つ問題があって、チームメンバのひとりがそれに絶対反対してるの。
アプリケーションとデータベースの間に別のレイヤを加えるのを気にして。
彼はすごく頭がいいから、これが良い決断だと納得させるには本当にしっかりした根拠が必要なの。
助けてくれる？&lt;/li&gt;
&lt;li&gt;ジョン: もちろん、よろこんで！
Hibernateは、実際、すばらしいツールです。
銀行といった、大きな真の業務ソリューションで広く使われています。
それを使って失敗するということはありえません。
永続化ときたらHibernate。
Javaで書いているならそれが完全に正しい選択ですし、さらには他の言語への移植もあります。
どれだけ多くの職務記述書がそれを要求しているか！&lt;/li&gt;
&lt;li&gt;モニカ: 全く同感！
同じことを感じていたわ。
前のプロジェクトで、ほとんどのところで生のJDBCからSQLを使っていたんだけど、ばかげてた！
そうでしょ！
けど、実は、ほんとに優秀なSQL屋がチームにいて、Hibernateが生成したSQLを見て神経質になってるの。
きたなくて読みにくいって。
これって将来問題になりそう？&lt;/li&gt;
&lt;li&gt;ジョン: 気を付けてください。DBA屋ってのは違ったものの見方をします。
彼らはプロジェクトにおける自分の立場をHibernateに奪われるのではないかと危惧しています。
さらに、データベースには組み込みのクエリ最適化機構があるので、クエリの実際の見た目がどんなかは気にする必要はありません。
データベースが最適化してくれます。
それが高速開発ってものです。
SQLにはまねできません。&lt;/li&gt;
&lt;li&gt;モニカ: ほんとに？
もうSQLを触らなくていいの？
すごい！
この前DBAがクエリの最適化に数週間かけていたわ。
数週間！
あぁ、こんなこと言うのは恥ずかしいんだけど、わたしたちが何を使っていたか分かる？
…ストアドプロシージャ(笑)
もうくちゃくちゃだった。
そのプロジェクト、まだそれ使ってるって信じられる？
そこの人たちほんとに気の毒だわ。
未だにあんな退屈なコードを何度も何度も書かないといけないなんて。
あれってJavaというかもうSQLプロジェクトじゃない？&lt;/li&gt;
&lt;li&gt;ジョン: それはまさにオブジェクト指向とリレーショナルのアプローチの違いです。
いわゆるオブジェクト指向インピーダンスミスマッチですね。
Hibernateはその溝を埋めてくれます。
開発者はビジネスロジックの構築に専念できます。
ステークホルダもマネージメント全体も幸せになれます。
最も重要となることをしましょう。ビジネスです！
ボイラープレートの多くは消え去り、魔法のようで目には見えませんが、ロジックとデータとの間にしっかりとしたコネクションができるのです。&lt;/li&gt;
&lt;li&gt;モニカ: 相互協調。充実したシナジー。
まるでデータベースが最初から言語の一部だったかのよう。
信念の技術的飛躍の指導者になれてとても幸せ。
ソフトウェアという旅路でワープスピードに乗ったみたい。&lt;/li&gt;
&lt;li&gt;ジョン: そう！その調子！&lt;/li&gt;
&lt;li&gt;モニカ: わーい！すごーい！
わくわくしてきた！たーのしー！
ありがとうジョン。
準備万端！&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;3年前-柔軟性のないソリューションとともに大きくなる苦悩&#34;&gt;3年前、柔軟性のないソリューションとともに大きくなる苦悩&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;モニカ: ねえジョン、去年話したプロジェクト覚えてる？&lt;/li&gt;
&lt;li&gt;ジョン: もちろん。調子はどうですか？&lt;/li&gt;
&lt;li&gt;モニカ: もうすぐリリースするわ。
全て順調。だけどいくつか疑問がわいてきたの。&lt;/li&gt;
&lt;li&gt;ジョン: いいですよ。聞いてください。&lt;/li&gt;
&lt;li&gt;モニカ: ええと、もうデータベーススキーマを一から生成することはできないんだけど、データロスのないスキーマ変更をサポートするにはどうするのが一番いい？&lt;/li&gt;
&lt;li&gt;ジョン: えぇ、まず、Hibernateはプロダクション環境での移行ツールとして使われることを想定していません。
FlywayDBやLiquibaseといったものを使うべきです。
結構簡単ですよ。移行スクリプトを書いて、それでエンティティモデルを更新しつつ、Hibernateのマッピングも直して、
実際のデータベース構造と同期するようにしてください。&lt;/li&gt;
&lt;li&gt;モニカ: ふーん、分かった。前のプロジェクトでは単に生のSQLで移行してた。&lt;/li&gt;
&lt;li&gt;ジョン: それでもいいと思います。エンティティモデルとスキーマが同期してさえいれば、好きなやり方でやってください。&lt;/li&gt;
&lt;li&gt;モニカ: そうね。
もう一つ、わたしたちいつも遅延フェッチと即時フェッチの問題と戦ってるの。
ある時、全部を即時でやることに決めたんだけど、それって最適じゃないでしょ？
それに、たまにセッションが残ってないせいかなにかで、フィールドにアクセスできないことがあるの。
それって普通？&lt;/li&gt;
&lt;li&gt;ジョン: もっとHibernateについて学ぶ必要があります。
データベースとのマッピングは単純ではありません。
複数のやりかたがあるのが普通です。
その中から自分に合ったものを選ぶのです。
遅延フェッチはオブジェクトを必要なときにロードできるようにしますが、アクティブなセッションの中で実行しないといけません。&lt;/li&gt;
&lt;li&gt;モニカ: わたしたちはまだ最終的なデプロイでどのデータベースエンジンを使うべきか迷ってるの。
Hibernateってポータブルだと思ってたけど、MS SQLの魔法を使うためにちょっとネイティブクエリを使ってて、実際にはプロダクション環境ではMySQLで行きたいんだけど。&lt;/li&gt;
&lt;li&gt;ジョン: HibernateはdetachedなCriteriaクエリかHQLを使っている限りは柔軟です。
ネイティブクエリを使ったらそのデータベースにソリューションが固定されちゃいますよ。&lt;/li&gt;
&lt;li&gt;モニカ: それならMS SQL専用にしないとダメみたいね。
最後の質問。チームメンバからHQLには「limit」キーワードがないと聞いたわ。
冗談かと思ったけど、わたしも見つけられなかった。
バカな質問で申し訳ないんだけど…&lt;/li&gt;
&lt;li&gt;ジョン: 確かに。HQLには「limit」はありません。
クエリオブジェクトでコントロールすることはできます。
データベースベンダ依存のものなので。&lt;/li&gt;
&lt;li&gt;モニカ: 他の要素は全部HQLにあるのに変ね。
まあ気にしないで。
時間取ってくれてありがとう！&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;2年前-わたしたちは今再びsqlでソリューションをハックしている&#34;&gt;2年前、わたしたちは今再びSQLでソリューションをハックしている&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;モニカ: ジョン、最初わたしたちSQLを触らないつもりだったけど、今はその必要があると感じてる。
要件が大きくなってきていて、それを避ける手立てはないみたいなの。
間違ったことをしているかもしれないけど、またSQLを毎日のように使い始めたわ。&lt;/li&gt;
&lt;li&gt;ジョン: いえ、それは間違っていません。
最初期にはデータベースを気に掛ける必要はありませんでしたが、プロジェクトが進んだ今では、SQLを使ってパフォーマンスの最適化に取り組むのはいいことです。&lt;/li&gt;
&lt;li&gt;モニカ: ときどきエラーを調査するのに数日かかるの。
なぜ期待通りに動かないのか、なぜ思いがけない結果が出力されるのかが全く分からないから、Hibernateが生成したSQLを解析しないといけないみたい。
Hibernateのバグトラッカーに載ってる有名な問題に当たったこともある。
それだけじゃない。エンティティモデルの同期を保ったまま適切な移行処理を書くのは難しいの。
Hibernateの内部をよく調査して、どう動くのかを予測する必要があって、時間を取られてしまう。&lt;/li&gt;
&lt;li&gt;ジョン: 学習曲線というのは常にあります。
たくさんの記述はいりませんが、どう動くかは知っておく必要があります。&lt;/li&gt;
&lt;li&gt;モニカ: 大きなデータセットを扱うのも厄介。
最近データベースに大量のインポートをしたんだけど、あまりにも遅かった。
あとで、速くするにはセッションをクリアする必要があったって分かったんだけど、それでもまだ全然遅い。
だから生のSQLで書き直すことにしたの。
笑ったわ。生のSQLを書くのが実際最速の方法だったから。
だから最後の選択肢としてそうすることに決めたの。&lt;/li&gt;
&lt;li&gt;ジョン: インポートはオブジェクト指向な処理ではないです。
Hibernateはオブジェクト指向設計に焦点を当てています。
ネイティブクエリという選択肢を忘れてはいけません。&lt;/li&gt;
&lt;li&gt;モニカ: Hibernateのキャッシュがどう動くか知りたいんだけど、教えてくれる？
ちょっと分からないの。
一次キャッシュとか二次キャッシュとかあるけど、どういうものなの？&lt;/li&gt;
&lt;li&gt;ジョン: もちろんです。
それはいわゆる永続データのトランザクションレベルキャッシュです。
クラスタやJVMレベルで、クラス毎やコレクション毎のキャッシュを設定できます。
クラスタキャッシュを組み込むことさえできます。
しかし、キャッシュは他のアプリケーションが永続化領域に加えた変更については関知しないことを覚えておいてください。
期限切れのキャッシュデータを定期的に消すように設定することはできますが。&lt;/li&gt;
&lt;li&gt;モニカ: ごめん。気分が悪くなってきた。
もう少し説明してくれる？&lt;/li&gt;
&lt;li&gt;ジョン: はい。
&lt;code&gt;save&lt;/code&gt;とか&lt;code&gt;update&lt;/code&gt;とか&lt;code&gt;saveOrUpdate&lt;/code&gt;にオブジェクトを渡したり、&lt;code&gt;load&lt;/code&gt;、&lt;code&gt;get&lt;/code&gt;、&lt;code&gt;list&lt;/code&gt;、&lt;code&gt;iterate&lt;/code&gt;、&lt;code&gt;scroll&lt;/code&gt;でオブジェクトを取得するときは常に、そのオブジェクトはセッションの内部キャッシュに追加されます。
一次キャッシュからオブジェクトやそのコレクションを削除することもできます。&lt;/li&gt;
&lt;li&gt;モニカ: あぁ…&lt;/li&gt;
&lt;li&gt;ジョン: さらに、キャッシュモードを制御することもできます。
&lt;code&gt;normal&lt;/code&gt;モードでは読み込みと書き込みで二次キャッシュを使います。
&lt;code&gt;get&lt;/code&gt;モードでは二次から読みますがライトバックはできません。
&lt;code&gt;put&lt;/code&gt;は&lt;code&gt;get&lt;/code&gt;と同じですが二次から読むことはできません。
&lt;code&gt;refresh&lt;/code&gt;モードもあります。
これは二次に書き込みますが、そこからは読み込まず、&lt;code&gt;use minimal puts&lt;/code&gt;プロパティを無視し、データベースからの全ての読み込み時に二次キャッシュを強制リフレッシュします。&lt;/li&gt;
&lt;li&gt;モニカ: いいわ。わかった。
ちょっと考えさせて。
もう遅いわ。行かなきゃ。
説明ありがとう！&lt;/li&gt;
&lt;li&gt;ジョン: どういたしまして！&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;2週間前-hibernateをあきらめる&#34;&gt;2週間前、Hibernateをあきらめる&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;モニカ: ジョン、わたしソフトウェア開発の新時代に入ろうとしてるんだと思ってた。
一光年の飛躍をしてるんだと思ってた。
けど、4年たった今も、わたしたちは同じ問題に対応してるみたい。単に違う方向から。
私はHibernateのアーキテクチャ、設定、ロギング、ネーミング戦略、Tuplizer、エンティティ名リゾルバ、拡張IDジェネレータ、IDジェネレータ最適化、ユニオンサブクラス、XDocletマークアップ、インデックス付きコレクションの双方向関連、3項関連、idbag、暗黙的ポリモーフィズムと他の継承マッピングの組み合わせ、二つの異なるデータストア間でのオブジェクトレプリケーション、detachedオブジェクトと自動バージョニング、コネクション開放モード、ステートレスセッションインターフェース、コレクション永続化の分類法、キャッシュレベル、遅延/即時フェッチ、他にもいろんなことを学ばなければならなかった。
わたしの知ってる全てがあっても、ひどい失敗になっていたと思う。
ソフトウェアの出来損ないだわ！
究極の失敗！
大参事！
アルマゲドン！&lt;/li&gt;
&lt;li&gt;ジョン: 待ってください！なにがあったんですか？&lt;/li&gt;
&lt;li&gt;モニカ: わたしたち行き詰ったの。
わたしたちのアプリケーションの性能はばかばかしいほど遅い！
レポートを取得するのに二日も待たないといけない！
二日でやっと顧客にダッシュボードを生成して見せられるの。
つまり毎日計算処理を開始させなければならない上に、ダッシュボードの情報はどんどん遅れてしまう。
うちのDBAエキスパートがクエリ最適化に2か月取り組んでるけど、データベース構造がめちゃくちゃで。
それを手伝ってる開発者もいるけど、困ったことに、DBAはSQLで考えているから、開発者はそれをdetached CriteriaかHQLに翻訳しようと何日も費やしてしまうの。
今となっては性能がかなり重要だから、できるだけネイティブSQLを使おうとしてるわ。
なんにせよ、データベーススキーマがはっきり間違っちゃってるから大したことはできない。
オブジェクト指向な視点ではそれでいいと感じていたけど、リレーショナルな視点では最悪だったみたい。
どうしてこうなっちゃったんだろう？
開発者はエンティティ構造を変えるのはかなりの労力になると言うから、それをする余裕はないし。
前のプロジェクトは乱雑ではあったけど、そんな窮地には陥らなかった。
既存のデータを処理する完全に別のアプリケーションを書くこともできた。
今は、生成されたテーブルを変えるのは危険だわ。
エンティティモデルが完全に正しく動くことを保証するのは本当に難しいもの。
けどこれさえも最悪な点ってわけではないわ！
性能改善するには、データベース問題だけでなく、データベースとアプリケーションの間のレイヤ全体の問題も解決しないといけない。
それが圧倒的！
この新しく加わった人たちはね、コンサルタントなの。
彼らはデータを抽出して、なにか別のストレージに入れて、外側から計算を実行しようとしてる。
どれも時間かかりすぎ！&lt;/li&gt;
&lt;li&gt;ジョン: なんと言っていいか分かりません。&lt;/li&gt;
&lt;li&gt;モニカ: いいのよジョン、あなたを責めはしないわ。
わたしはHibernateを選択して全ての問題を解決しようとしたけど、今ではそれが銀の弾丸ではないと分かる。
もうダメージは負ったし、それをなかったことにはできない。
実は、あなたにお願いしたいことがあるの。
わたしはこの4年間のキャリアをHibernateのあれこれとの戦いに費やしてしまったわ。
もう今の会社でわたしに未来はないみたい。
助けてくれない？&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;今日-学んだ教訓は&#34;&gt;今日、学んだ教訓は？&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;ジョン: やあピーター、モニカを紹介するよ。&lt;/li&gt;
&lt;li&gt;ピーター: やあモニカ！
わたしたちは新しい次なる目玉を開発しようとしてるんだけどね。
巨大なものになりそうだよ！
Uberみたいになりたいんだ！
永続化について何か知って…&lt;/li&gt;
&lt;li&gt;モニカ: Hibernateはダメ！&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;まとめ&#34;&gt;まとめ&lt;/h1&gt;

&lt;p&gt;モニカはHibernateのエキスパートだ。
しかし、この例ではHibernateは間違った選択だった。
彼女のソリューションが以前より大きな問題に変化したと気付いたときには、プロジェクト全体を脅かす最大の脅威になってしまっていた。&lt;/p&gt;

&lt;p&gt;データはアプリケーションの目的の中心で、好むと好まざるにかかわらず、アーキテクチャ全体に影響する。
このストーリーから学んだとおり、アプリケーションがデータベースを使うからとか、&lt;a href=&#34;http://d.hatena.ne.jp/keyword/%A5%BD%A1%BC%A5%B7%A5%E3%A5%EB%A5%D7%A5%EB%A1%BC%A5%D5&#34;&gt;ソーシャルプルーフ&lt;/a&gt;があるからというだけの理由でHibernateを選択してはいけない。
柔軟性をもつソリューションを選ぶべきだ。
堅牢なJDBCラッパには&lt;a href=&#34;http://docs.spring.io/spring/docs/current/javadoc-api/org/springframework/jdbc/core/JdbcTemplate.html&#34;&gt;JdbcTemplate&lt;/a&gt;や&lt;a href=&#34;http://jdbc.jcabi.com/&#34;&gt;Fluent JDBC Wrapper&lt;/a&gt;といった多くの選択肢がある。
あるいは他にも、&lt;a href=&#34;http://www.jooq.org/&#34;&gt;jOOQ&lt;/a&gt;といった強力なソリューションがある。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上がGrzegorzの記事。&lt;/p&gt;

&lt;p&gt;ジョンにそそのかされて、Hibernateへの期待が高まるあまり一時けもの並の知能になったモニカが、4年の間に現実を知り絶望していくさまが生々しく怖い話だ。
オブジェクト指向の都合だけでデータベーススキーマを決めてしまった辺りが一番の失敗だったんだろうか。
SQL中心に考えつつHibernateでORマッピングやスキーマを構築することも、HibernateとSQL両方熟知してればできるんだろうか。&lt;/p&gt;

&lt;p&gt;なんにせよ、Hibernateが忌み嫌われるようになった理由がよくわかる面白い記事だった。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ブログアドレスを変更したときにやったこと</title>
          <link>https://www.kaitoy.xyz/2017/02/14/change-subdomain/</link>
          <pubDate>Tue, 14 Feb 2017 09:51:42 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/02/14/change-subdomain/</guid>
          <description>

&lt;p&gt;このブログの閲覧数がそこそこの規模になってきたので、&lt;a href=&#34;https://www.google.co.jp/adsense/start/&#34;&gt;Google AdSense&lt;/a&gt;で小遣い稼ぎを始めようとしたら、最近サブドメインが&lt;code&gt;www&lt;/code&gt;じゃないとできないようになったようだったので、サブドメインを&lt;code&gt;tbd&lt;/code&gt;から&lt;code&gt;www&lt;/code&gt;に変更した話。&lt;/p&gt;

&lt;p&gt;変更自体はそんなに難しくなかったけど、Googleの検索順位を保つためにいろいろ気を使う必要があった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;ブログアドレスの変更&#34;&gt;ブログアドレスの変更&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/08/28/using-hugo/&#34;&gt;以前&lt;/a&gt;にも書いたが、このブログは&lt;a href=&#34;https://gohugo.io/&#34;&gt;&lt;strong&gt;Hugo&lt;/strong&gt;&lt;/a&gt;で作って&lt;a href=&#34;https://pages.github.com/&#34;&gt;&lt;strong&gt;GitHub Pages&lt;/strong&gt;&lt;/a&gt;でカスタムドメインで公開している。&lt;/p&gt;

&lt;p&gt;コメント欄を設けるために&lt;a href=&#34;https://disqus.com/&#34;&gt;&lt;strong&gt;Disqus&lt;/strong&gt;&lt;/a&gt;を使っている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cloudflare.com/&#34;&gt;&lt;strong&gt;Cloudflare&lt;/strong&gt;&lt;/a&gt;を使って&lt;a href=&#34;https://www.kaitoy.xyz/2016/07/01/https-support-by-cloudflare/&#34;&gt;全体をHTTPS化&lt;/a&gt;していて、その関係で&lt;code&gt;kaitoy.xyz&lt;/code&gt;ドメインの名前解決にはCloudflareのDNSを使っている。&lt;/p&gt;

&lt;p&gt;アクセス解析などのために&lt;a href=&#34;https://analytics.google.com/&#34;&gt;&lt;strong&gt;Google Analytics&lt;/strong&gt;&lt;/a&gt;と&lt;a href=&#34;https://www.google.com/webmasters/tools/home&#34;&gt;&lt;strong&gt;Google Search Console&lt;/strong&gt;&lt;/a&gt;を使ってる。&lt;/p&gt;

&lt;p&gt;この構成で、ブログアドレスの変更に必要だった修正を列挙する。(この順にやったわけではない。)&lt;/p&gt;

&lt;h4 id=&#34;1-ブログソース修正&#34;&gt;1. ブログソース修正&lt;/h4&gt;

&lt;p&gt;Hugoの設定ファイルである&lt;code&gt;config.toml&lt;/code&gt;に書いてある&lt;code&gt;baseurl&lt;/code&gt;の値を&lt;code&gt;https://tbd.kaitoy.xyz&lt;/code&gt;から&lt;code&gt;https://www.kaitoy.xyz&lt;/code&gt;に変え、また、各記事の内部リンクのURLも&lt;code&gt;www&lt;/code&gt;のに変えた。&lt;/p&gt;

&lt;p&gt;あと&lt;code&gt;robots.txt&lt;/code&gt;の&lt;code&gt;Sitemap&lt;/code&gt;のURLも&lt;code&gt;https://www.kaitoy.xyz/sitemap.xml&lt;/code&gt;に更新した。&lt;/p&gt;

&lt;h4 id=&#34;2-github-pagesの設定変更&#34;&gt;2. GitHub Pagesの設定変更&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kaitoy/blog&#34;&gt;ブログリポジトリ&lt;/a&gt;に行って、&lt;code&gt;Settings&lt;/code&gt;の&lt;code&gt;GitHub Pages&lt;/code&gt;欄の&lt;code&gt;Custom domain&lt;/code&gt;の値を&lt;code&gt;https://www.kaitoy.xyz&lt;/code&gt;に変えた。&lt;/p&gt;

&lt;p&gt;ついでにブログリポジトリのトップに表示される&lt;code&gt;Description&lt;/code&gt;の&lt;code&gt;Website&lt;/code&gt;の値も新しいURLに変更した。&lt;/p&gt;

&lt;p&gt;この変更によりありがたい副作用もあった。
GitHub Pagesは&lt;code&gt;www&lt;/code&gt;というサブドメインを特別扱いしていて、以下の恩恵を受けられるのだ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;wwwを省略したURL(apex domain)でアクセスすると、GitHub Pagesサーバがwww付きのURLに&lt;a href=&#34;https://help.github.com/articles/setting-up-an-apex-domain-and-www-subdomain/&#34;&gt;リダイレクトしてくれる&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://help.github.com/articles/about-supported-custom-domains/#www-subdomains&#34;&gt;安定していて速い&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;3-cloudflareのdns設定変更&#34;&gt;3. CloudflareのDNS設定変更&lt;/h4&gt;

&lt;p&gt;CloudflareのDNSで、もともと&lt;code&gt;CNAME&lt;/code&gt;レコードで&lt;code&gt;kaitoy.github.io&lt;/code&gt;(GitHub Pagesのデフォルトのドメイン)のエイリアスを&lt;code&gt;tbd&lt;/code&gt;にしていたのを&lt;code&gt;www&lt;/code&gt;に変更した。&lt;/p&gt;

&lt;p&gt;また、上記の通りapex domainでGitHub Pagesにアクセスしても上手いことやってくれるようになったので、&lt;code&gt;www.kaitoy.xyz&lt;/code&gt;のエイリアスを&lt;code&gt;kaitoy.xyz&lt;/code&gt;とする&lt;code&gt;CNAME&lt;/code&gt;レコードを追加した。
CloudflareのDNSはapex domain(i.e. &lt;code&gt;kaitoy.xyz&lt;/code&gt;)に対する&lt;code&gt;CNAME&lt;/code&gt;レコード設定を&lt;a href=&#34;https://support.cloudflare.com/hc/en-us/articles/200169056-CNAME-Flattening-RFC-compliant-support-for-CNAME-at-the-root&#34;&gt;サポートしている&lt;/a&gt;ので、これで&lt;code&gt;www.kaitoy.xyz&lt;/code&gt;でも&lt;code&gt;kaitoy.xyz&lt;/code&gt;でもGitHub Pagesにルーティングされるようになった。&lt;/p&gt;

&lt;h4 id=&#34;4-disqusの設定変更&#34;&gt;4. Disqusの設定変更&lt;/h4&gt;

&lt;p&gt;ホームの右上の歯車アイコンから&lt;code&gt;Admin&lt;/code&gt;を開いて、ヘッダの&lt;code&gt;Settings&lt;/code&gt;からブログのURLを選んでその設定画面を開き、&lt;code&gt;Website URL&lt;/code&gt;を&lt;code&gt;https://www.kaitoy.xyz&lt;/code&gt;に変更した。&lt;/p&gt;

&lt;h4 id=&#34;5-google-analyticsの設定変更&#34;&gt;5. Google Analyticsの設定変更&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;管理&lt;/code&gt;タブの&lt;code&gt;プロパティ設定&lt;/code&gt;の&lt;code&gt;デフォルトの URL&lt;/code&gt;を&lt;code&gt;https://www.kaitoy.xyz&lt;/code&gt;に変更しただけ。&lt;/p&gt;

&lt;h1 id=&#34;googleのページランクを保つためのあれこれ&#34;&gt;Googleのページランクを保つためのあれこれ&lt;/h1&gt;

&lt;p&gt;以前もどこかに書いたが、どんなにすばらしい内容の記事を書いてもGoogle検索結果の2,3ページくらいまでに出てこないんであれば誰も読んでくれない。
このブログのいくつかの記事はそれなりにいいキーワードでいい検索順位になっていたので、サブドメイン変更によってページランクに悪影響が出るのはなるべく避けたかった。&lt;/p&gt;

&lt;p&gt;調べたら、&lt;a href=&#34;https://support.google.com/webmasters/answer/6033049?hl=ja&amp;amp;ref_topic=6033084&#34;&gt;Google Search Consoleのヘルプ&lt;/a&gt;にまさにその悪影響を防ぐ方法が載っていたので、これに従ってあれこれした。&lt;/p&gt;

&lt;h4 id=&#34;1-自身を参照する-rel-canonical-リンクタグを付ける&#34;&gt;1. 自身を参照する &lt;code&gt;rel=&amp;quot;canonical&amp;quot;&lt;/code&gt;リンクタグを付ける&lt;/h4&gt;

&lt;p&gt;ブログの全てのページのヘッダに以下の様な移転先アドレスを指すlinkタグを付け、変更後のアドレスが正式なアドレスであることをGooglebotに教えてやる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;link rel=&amp;quot;canonical&amp;quot; href=&amp;quot;https://www.kaitoy.xyz/2015/07/18/first-post/&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hugoのソースでいうと以下の感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;link rel=&amp;quot;canonical&amp;quot; href=&amp;quot;{{ .Permalink }}&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;2-http-301リダイレクトを設定&#34;&gt;2. HTTP 301リダイレクトを設定&lt;/h4&gt;

&lt;p&gt;多分これが一番重要なんじゃなかろうか。&lt;/p&gt;

&lt;p&gt;HTTPステータスコードの&lt;a href=&#34;https://support.google.com/webmasters/answer/93633&#34;&gt;301&lt;/a&gt;はサイトのコンテンツが別のURLに恒久的に移転したことを示すもので、移転前のURLにアクセスしたクライアントに301を移転先のURLとともに返してやることで、HTTPレベルでのリダイレクトをさせることができる。&lt;/p&gt;

&lt;p&gt;GooglebotもこのステータスコードでブログURLの変更を知ることができるので、検索結果をよしなに移行してくれるはず。&lt;/p&gt;

&lt;p&gt;301を返すサーバには&lt;a href=&#34;https://www.xrea.com/&#34;&gt;XREA&lt;/a&gt;の無料サーバを使った。
このブログのドメインは&lt;a href=&#34;https://www.value-domain.com/&#34;&gt;バリュードメイン&lt;/a&gt;で買ったもので、ここがXREAと提携していたので無料サーバも合わせて確保していたもののほとんど使っていなかったので調度よかった。
調べたらこのサーバで、&lt;a href=&#34;https://httpd.apache.org/&#34;&gt;Apache HTTP Server&lt;/a&gt;の設定ファイルである&lt;code&gt;.htaccess&lt;/code&gt;が使えることが分かったので、以下の内容で作って&lt;code&gt;/public_html/&lt;/code&gt;に置いた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;Files ~ &amp;quot;^\.ht&amp;quot;&amp;gt;
deny from all
&amp;lt;/Files&amp;gt;

# Redirect
Redirect permanent / https://www.kaitoy.xyz/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、サーバの管理ページからドメインウェブ設定画面に行き、Mainのドメイン名を&lt;code&gt;tbd.kaitoy.xyz&lt;/code&gt;に設定。&lt;/p&gt;

&lt;p&gt;あとはCloudflareのDNS設定で、&lt;code&gt;tbd&lt;/code&gt;を上記XREAサーバのIPアドレスに解決する&lt;code&gt;A&lt;/code&gt;レコードを追加して完了。&lt;/p&gt;

&lt;h4 id=&#34;3-google-search-consoleのアドレス変更ツール実行&#34;&gt;3. Google Search Consoleのアドレス変更ツール実行&lt;/h4&gt;

&lt;p&gt;最後の仕上げとして、Google Search Consoleの&lt;a href=&#34;https://support.google.com/webmasters/answer/83106&#34;&gt;アドレス変更ツール&lt;/a&gt;を使ってGooglebotにアドレス変更を通知した。&lt;/p&gt;

&lt;p&gt;このツールはGoogle Search Consoleの管理サイトごとのページの右上の歯車アイコンから&lt;code&gt;アドレス変更&lt;/code&gt;を選択すると開け、以下のようなものが表示される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/change-subdomain/change_address.png&#34; alt=&#34;change_address.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;このウィザードに従って、移転先URL(プロパティ)の追加、301リダイレクトの動作確認、サイトの存在確認をして、アドレス変更のリクエストを送信するだけ。&lt;/p&gt;

&lt;p&gt;最後に、追加したプロパティの&lt;code&gt;クロール&lt;/code&gt;の&lt;code&gt;サイトマップ&lt;/code&gt;から、移転先サイトのサイトマップを送信して完了。
サイトマップはHugoがビルド時に生成してくれたやつ。&lt;/p&gt;

&lt;p&gt;今&lt;a href=&#34;https://support.google.com/webmasters/answer/6033049?hl=ja&amp;amp;ref_topic=6033084&#34;&gt;Google Search Consoleのヘルプ&lt;/a&gt;を見直したら移転前のサイトマップも送信しろと書いてあるのに気付いた。
これはやらなかったけど、やった方がよかったのかも。&lt;/p&gt;

&lt;p&gt;ともあれ、移転後一時的に検索順位が大きく落ちたものの、1,2週間位でもとにもどったので、この移転は概ね成功だったと思う。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goslings開発メモ - その5: Spring Boot最終編 (静的リソース処理)</title>
          <link>https://www.kaitoy.xyz/2017/01/24/goslings-development-memo5-spring-boot-static-resources/</link>
          <pubDate>Tue, 24 Jan 2017 09:01:49 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/01/24/goslings-development-memo5-spring-boot-static-resources/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/17/goslings-development-memo4-spring-boot-logging/&#34;&gt;Goslings開発メモ - その4: Spring Boot続続続編 (ロギング)&lt;/a&gt;」の続き。&lt;/p&gt;

&lt;p&gt;Spring Boot最終編で、静的リソース処理について。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;spring-boot-spring-mvc-での静的リソース処理&#34;&gt;Spring Boot(Spring MVC)での静的リソース処理&lt;/h1&gt;

&lt;p&gt;この時点でのGoslingsは単なるREST APIサーバで、アクセスしてもJSONを返すだけだ。
アプリとしての体を成すためには、そのAPIを利用するクライアントコード、つまりHTMLドキュメントやCSSファイルやJavaScriptファイル(静的リソース)も返すようにしないといけない。
HTMLドキュメントを返す場合、普通はなんらかの&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%86%E3%83%B3%E3%83%97%E3%83%AC%E3%83%BC%E3%83%88%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%B3&#34;&gt;テンプレートエンジン&lt;/a&gt;を使うものだが、Goslingsは本当に単純なGUIなので、サーバに置いたHTMLファイルをそのまま返したい。&lt;/p&gt;

&lt;p&gt;「Getting Started Guides」には&lt;a href=&#34;https://spring.io/guides/gs/serving-web-content/&#34;&gt;Serving Web Content with Spring MVC&lt;/a&gt;というのが乗っているが、これは&lt;a href=&#34;http://www.thymeleaf.org/&#34;&gt;Thymeleaf&lt;/a&gt;というテンプレートエンジンを使うものなのでちょっと違う。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/htmlsingle/#boot-features-spring-mvc-static-content&#34;&gt;Spring Bootリファレンスガイド&lt;/a&gt;によると、クラスパス(または&lt;code&gt;ServletContext&lt;/code&gt;のルート)の&lt;code&gt;/static/&lt;/code&gt;、&lt;code&gt;/public/&lt;/code&gt;、&lt;code&gt;/resources/&lt;/code&gt;、&lt;code&gt;/META-INF/resources/&lt;/code&gt;のいずれかに静的リソースを置けば、特にコードを書かなくてもクライアントからアクセスできるらしい。
(逆に、一般的に静的リソースを置く場所である、プロジェクトの&lt;code&gt;src/main/webapp/&lt;/code&gt;には置くべきでないとのこと。これは、jarにパッケージングするときにビルドツールに無視されることが多いため。)&lt;/p&gt;

&lt;p&gt;この仕組みについて、&lt;a href=&#34;https://spring.io/blog/2013/12/19/serving-static-web-content-with-spring-boot&#34;&gt;この記事&lt;/a&gt;を参考にちょろっとソースを見た感じでは、これらのパスは&lt;a href=&#34;https://github.com/spring-projects/spring-boot/blob/v1.4.3.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/ResourceProperties.java#L44&#34;&gt;&lt;code&gt;ResourceProperties&lt;/code&gt;の&lt;code&gt;CLASSPATH_RESOURCE_LOCATIONS&lt;/code&gt;&lt;/a&gt;に定義されていて、これを&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/api/org/springframework/boot/autoconfigure/web/WebMvcAutoConfiguration.html&#34;&gt;&lt;code&gt;WebMvcAutoConfiguration&lt;/code&gt;&lt;/a&gt;が&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/config/annotation/ResourceHandlerRegistry.html&#34;&gt;&lt;code&gt;ResourceHandlerRegistry&lt;/code&gt;&lt;/a&gt;で&lt;a href=&#34;https://github.com/spring-projects/spring-boot/blob/v1.4.3.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/WebMvcAutoConfiguration.java#L291&#34;&gt;リソースロケーションとして登録する&lt;/a&gt;ことで静的リソース置き場たらしめている模様。
(この&lt;code&gt;ResourceHandlerRegistry&lt;/code&gt;は&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/ResourceHttpRequestHandler.html&#34;&gt;&lt;code&gt;ResourceHttpRequestHandler&lt;/code&gt;&lt;/a&gt;を設定するファサード的なものっぽい。)&lt;/p&gt;

&lt;p&gt;で、&lt;code&gt;@SpringBootApplication&lt;/code&gt;(&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/&#34;&gt;その1&lt;/a&gt;参照)が付いているクラスがあって、&lt;code&gt;spring-webmvc.jar&lt;/code&gt;がクラスパスにあると、&lt;a href=&#34;http://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/config/annotation/EnableWebMvc.html&#34;&gt;&lt;code&gt;@EnableWebMvc&lt;/code&gt;&lt;/a&gt;がSpring Bootによって付けられ、そこからごにょごにょして上記&lt;code&gt;WebMvcAutoConfiguration&lt;/code&gt;が実行される。
&lt;code&gt;spring-webmvc.jar&lt;/code&gt;は&lt;code&gt;spring-boot-starter-web.jar&lt;/code&gt;(&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/&#34;&gt;その1&lt;/a&gt;参照)が引っ張ってくる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;なお、Spring MVCの静的リソース処理の全体の流れについては
、ちょっと古いけど「&lt;a href=&#34;https://spring.io/blog/2014/07/24/spring-framework-4-1-handling-static-web-resources&#34;&gt;handling static web resources&lt;/a&gt;」という記事が分かりやすい。
要は、URLに指定されたパスからサーバ上のリソースを探し当てる&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/ResourceResolver.html&#34;&gt;&lt;code&gt;ResourceResolver&lt;/code&gt;&lt;/a&gt;というものが優先度順に連なっているリゾルバチェイン(&lt;a href=&#34;http://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/ResourceResolverChain.html&#34;&gt;&lt;code&gt;ResourceResolverChain&lt;/code&gt;&lt;/a&gt;)があって、まずこいつがリソースを取得する。
次に、そのリソースを加工するトランスフォーマチェイン(&lt;a href=&#34;http://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/ResourceTransformerChain.html&#34;&gt;&lt;code&gt;ResourceTransformerChain&lt;/code&gt;&lt;/a&gt;)というものに通し、その結果をクライアントに返す。
トランスフォーマチェインは&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/ResourceTransformer.html&#34;&gt;&lt;code&gt;ResourceTransformer&lt;/code&gt;&lt;/a&gt;が連なったもの。
リゾルバチェインとトランスフォーマチェインは上記&lt;code&gt;ResourceHttpRequestHandler&lt;/code&gt;に設定される。&lt;/p&gt;

&lt;p&gt;リゾルバには以下の様なものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/PathResourceResolver.html&#34;&gt;&lt;code&gt;PathResourceResolver&lt;/code&gt;&lt;/a&gt;: &lt;code&gt;ResourceHttpRequestHandler&lt;/code&gt;に設定されたリソースロケーションからリソースを単純に検索するリゾルバ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/CachingResourceResolver.html&#34;&gt;&lt;code&gt;CachingResourceResolver&lt;/code&gt;&lt;/a&gt;: キャッシュからリソースを検索するリゾルバ。テンプレートエンジンの処理結果のキャッシュとかが返るのは多分ここから。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/GzipResourceResolver.html&#34;&gt;&lt;code&gt;GzipResourceResolver&lt;/code&gt;&lt;/a&gt;: &lt;a href=&#34;https://ja.wikipedia.org/wiki/Gzip&#34;&gt;gzip&lt;/a&gt;で圧縮されたリソース、つまりURLで指定されたパスに&lt;code&gt;.gz&lt;/code&gt;という拡張子を付けたリソースを検索するリゾルバ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/VersionResourceResolver.html&#34;&gt;&lt;code&gt;VersionResourceResolver&lt;/code&gt;&lt;/a&gt;: &lt;a href=&#34;https://spring.io/blog/2014/07/24/spring-framework-4-1-handling-static-web-resources#resource-versioning&#34;&gt;リソースバージョニング&lt;/a&gt;を実現するためのリゾルバ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/WebJarsResourceResolver.html&#34;&gt;&lt;code&gt;WebJarsResourceResolver&lt;/code&gt;&lt;/a&gt;: &lt;a href=&#34;http://www.webjars.org/&#34;&gt;WebJars&lt;/a&gt;のjarファイル内のリソースを検索するリゾルバ。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;リゾルバの設定などについてはQiitaの&lt;a href=&#34;http://qiita.com/kazuki43zoo/items/e12a72d4ac4de418ee37&#34;&gt;この記事&lt;/a&gt;ががよくまとまっている。
凝ったことをしたいときは参照しよう。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;トランスフォーマには以下の様なものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/CssLinkResourceTransformer.html&#34;&gt;&lt;code&gt;CssLinkResourceTransformer&lt;/code&gt;&lt;/a&gt;: CSSファイル内のリンクをクライアントがアクセスできるURLに変換する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/CachingResourceTransformer.html&#34;&gt;&lt;code&gt;CachingResourceTransformer&lt;/code&gt;&lt;/a&gt;: 変換したリソースをキャッシュする。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/AppCacheManifestTransformer.html&#34;&gt;&lt;code&gt;AppCacheManifestTransformer&lt;/code&gt;&lt;/a&gt;: HTML5のAppCacheマニフェスト内のリソースを扱うトランスフォーマ。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;デフォルトで&lt;code&gt;ResourceHttpRequestHandler&lt;/code&gt;には&lt;code&gt;PathResourceResolver&lt;/code&gt;だけが設定されている。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上をまとめると、クライアントからGetリクエストが来ると、&lt;code&gt;WebMvcAutoConfiguration&lt;/code&gt;が設定したリソースロケーション(e.g. &lt;code&gt;/static/&lt;/code&gt;)を&lt;code&gt;PathResourceResolver&lt;/code&gt;が検索して、そこに置いてあるHTMLファイルとかをクライアントに返してくれる、ということであろう。&lt;/p&gt;

&lt;p&gt;Javaのコードを全く書かなくていいので楽。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Javaのコードを書いて静的リソースファイルを明示することもできる。
&lt;a href=&#34;http://qiita.com/tag1216/items/3680b92cf96eb5a170f0&#34;&gt;Qiitaの記事&lt;/a&gt;によれば、&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Controller.html&#34;&gt;&lt;code&gt;@Controller&lt;/code&gt;&lt;/a&gt;を付けたクラスのリクエストハンドラで以下の様にファイルへのパスを返せばいいらしい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@RequestMapping(&amp;quot;/hoge&amp;quot;)
public String hoge() {
    return &amp;quot;/hoge.html&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;単純な静的リソースに対してこれをやるユースケースはあまりなさそう。
テンプレートエンジンを使っていてパラメータを渡したいときにはこういうリクエストハンドラを書くことになる。&lt;/p&gt;

&lt;h1 id=&#34;spring-bootのウェルカムページとファビコン&#34;&gt;Spring Bootのウェルカムページとファビコン&lt;/h1&gt;

&lt;p&gt;Spring Bootは&lt;code&gt;index.html&lt;/code&gt;と&lt;code&gt;favicon.ico&lt;/code&gt;という名のファイルを特別扱いする。
前者がウェルカムページで後者がファビコン。&lt;/p&gt;

&lt;h4 id=&#34;ウェルカムページ&#34;&gt;ウェルカムページ&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/htmlsingle/#boot-features-spring-mvc-static-content&#34;&gt;Spring Bootのリファレンスガイド&lt;/a&gt;にもちらっとかいてあるけど、リソースロケーションに&lt;code&gt;index.html&lt;/code&gt;というファイルを置いておくと、それがウェルカムページとして設定され、URLのパスにルート(e.g. &lt;code&gt;http://localhost:8080/&lt;/code&gt;)を指定したときにクライアントに返るようになる。&lt;/p&gt;

&lt;p&gt;ソースを見ると、上記&lt;code&gt;WebMvcAutoConfiguration&lt;/code&gt;の&lt;a href=&#34;https://github.com/spring-projects/spring-boot/blob/v1.4.3.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/WebMvcAutoConfiguration.java#L297&#34;&gt;ここ&lt;/a&gt;でそのための設定している。
&lt;code&gt;/META-INF/resources/index.html&lt;/code&gt;、&lt;code&gt;/resources/index.html&lt;/code&gt;、&lt;code&gt;/static/index.html&lt;/code&gt;、&lt;code&gt;/public/index.html&lt;/code&gt;の順に探すようで、複数個所に&lt;code&gt;index.html&lt;/code&gt;を置いた場合は最初に見つかったものがウェルカムページになる。(そんなことする意味はないが。)&lt;/p&gt;

&lt;h4 id=&#34;ファビコン&#34;&gt;ファビコン&lt;/h4&gt;

&lt;p&gt;ファビコンについてはSpring Bootの現時点でリリース済みバージョンのリファレンスガイドにはほとんど情報がないが、&lt;code&gt;1.5.0.BUILD-SNAPSHOT&lt;/code&gt;のリファレンスガイドには以下の様に書いてある。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;27.1.6 Custom Favicon&lt;/p&gt;

&lt;p&gt;Spring Boot looks for a favicon.ico in the configured static content locations and the root of &amp;gt; the classpath (in that order). If such file is present, it is automatically used as the favicon &amp;gt; of the application.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;つまり、リソースロケーションかクラスパスのルートに&lt;code&gt;favicon.ico&lt;/code&gt;というファイルを置いておくと、それをファビコンとしてクライアントに返してくれる。&lt;/p&gt;

&lt;p&gt;これもやっぱり&lt;code&gt;WebMvcAutoConfiguration&lt;/code&gt;が&lt;a href=&#34;https://github.com/spring-projects/spring-boot/blob/v1.4.3.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/WebMvcAutoConfiguration.java#L319&#34;&gt;設定する&lt;/a&gt;。&lt;/p&gt;

&lt;h1 id=&#34;goslingsの静的リソース&#34;&gt;Goslingsの静的リソース&lt;/h1&gt;

&lt;p&gt;Goslingsの静的リソースは&lt;code&gt;favicon.ico&lt;/code&gt;以外は&lt;code&gt;/static/&lt;/code&gt;に全部直接置くことにした。
&lt;code&gt;favicon.ico&lt;/code&gt;はクラスパスのルートに。
プロジェクトのソースツリーで言うと、&lt;code&gt;src/main/resources/static/&lt;/code&gt;に&lt;code&gt;index.html&lt;/code&gt;やら&lt;code&gt;goslings.css&lt;/code&gt;やらのクライアントファイルを置いて、あとは&lt;code&gt;src/main/resources/favicon.ico&lt;/code&gt;があるという形。
こうしておけば、GradleのJavaプラグインの&lt;code&gt;processResources&lt;/code&gt;タスクによってjar内の適切な場所に取り込まれる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;index.html&lt;/code&gt;には&lt;code&gt;http://&amp;lt;Goslingsサーバ&amp;gt;/&lt;/code&gt;でアクセスできるし、&lt;code&gt;goslings.css&lt;/code&gt;も&lt;code&gt;index.html&lt;/code&gt;に&lt;code&gt;&amp;lt;link rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;goslings.css&amp;quot;&amp;gt;&lt;/code&gt;みたいに書けば取得できる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今日はここまで。
次回からはクライアントサイドの話。&lt;/p&gt;

&lt;p&gt;と思ったけど、たいして書くことないのでこれで終わりにする。
&lt;a href=&#34;http://qiita.com/kaitoy/items/91585ba1a3081ffd2111&#34;&gt;Qiita&lt;/a&gt;のほうにちょっと書いたし。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goslings開発メモ - その4: Spring Boot続続続編 (ロギング)</title>
          <link>https://www.kaitoy.xyz/2017/01/17/goslings-development-memo4-spring-boot-logging/</link>
          <pubDate>Tue, 17 Jan 2017 00:15:25 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/01/17/goslings-development-memo4-spring-boot-logging/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/13/goslings-development-memo3-spring-boot-exception/&#34;&gt;Goslings開発メモ - その3: Spring Boot続続編 (例外処理)&lt;/a&gt;」の続き。&lt;/p&gt;

&lt;p&gt;Spring Boot続続続編で、ロギングについて。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;spring-bootアプリにおけるロギング&#34;&gt;Spring Bootアプリにおけるロギング&lt;/h1&gt;

&lt;p&gt;Spring Bootアプリにおけるロギングについては公式の&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/boot-features-logging.html&#34;&gt;マニュアル&lt;/a&gt;と&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/howto-logging.html&#34;&gt;How-toガイド&lt;/a&gt;を読むべし。
この記事にはこれらの内容をまとめておく。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Spring Bootは内部でのロギングにApacheの&lt;a href=&#34;https://commons.apache.org/proper/commons-logging/&#34;&gt;Commons Logging&lt;/a&gt;を使っている。&lt;/p&gt;

&lt;p&gt;Commons Loggingはファサードライブラリだ。
つまり、Commons LoggingはロギングAPIだけをアプリケーションに提供し、実際のログ出力処理をするロギング実装ライブラリへの橋渡しとして機能する。
ロギング実装ライブラリには色々な選択肢があるが、Spring Bootは&lt;a href=&#34;https://docs.oracle.com/javase/jp/8/docs/api/java/util/logging/package-summary.html&#34;&gt;JUL&lt;/a&gt;、 &lt;a href=&#34;http://logging.apache.org/log4j/2.x/&#34;&gt;Log4j 2&lt;/a&gt;、&lt;a href=&#34;http://logback.qos.ch/&#34;&gt;Logback&lt;/a&gt;用のデフォルト設定を備えているので、これらのいずれかを使うのが楽であろう。&lt;/p&gt;

&lt;p&gt;全てのスターターは&lt;code&gt;spring-boot-starter-logging&lt;/code&gt;というロギングスターターに依存していて、これがLogbackを使うので、普通はそのままLogbackを使うことになる。
&lt;code&gt;spring-boot-starter-logging&lt;/code&gt;は、JUL、Commons Logging、Log4j、&lt;a href=&#34;https://www.slf4j.org/&#34;&gt;SLF4J&lt;/a&gt;によるログ出力をLogbackにルーティングするため、アプリ側や他の依存ライブラリがこれらを使っていてもLogbackに一本化できる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;spring-boot-starter-logging&lt;/code&gt;の代わりに&lt;code&gt;spring-boot-starter-log4j2&lt;/code&gt;に依存し、Log4j 2を使う&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/howto-logging.html#howto-configure-log4j-for-logging&#34;&gt;方法もある&lt;/a&gt;が、Goslingsには普通に&lt;code&gt;spring-boot-starter-logging&lt;/code&gt;を使った。&lt;/p&gt;

&lt;p&gt;また、Goslings本体のログ出力には、プレースホルダを使いたかったのでSLF4Jを使った。&lt;/p&gt;

&lt;h1 id=&#34;spring-bootアプリにおけるロギング設定&#34;&gt;Spring Bootアプリにおけるロギング設定&lt;/h1&gt;

&lt;p&gt;Spring Bootが備えているデフォルトのロギング設定は、&lt;code&gt;ERROR&lt;/code&gt;、&lt;code&gt;WARN&lt;/code&gt;、&lt;code&gt;INFO&lt;/code&gt;レベルのログをいい感じにフォーマットしてコンソールに吐くというものになっている。&lt;/p&gt;

&lt;p&gt;以下この設定の変更方法などを書く。&lt;/p&gt;

&lt;h4 id=&#34;ファイルへのログ出力&#34;&gt;ファイルへのログ出力&lt;/h4&gt;

&lt;p&gt;ログをファイルにも吐くようにするには、&lt;code&gt;logging.file&lt;/code&gt;というプロパティでファイルパスを指定するか、&lt;code&gt;logging.path&lt;/code&gt;というプロパティでディレクトリパスを指定すればいい。
(後者の場合ログファイル名は&lt;code&gt;spring.log&lt;/code&gt;になる。)&lt;/p&gt;

&lt;p&gt;Spring Bootアプリでプロパティを指定する方法は色々あり(&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/htmlsingle/#boot-features-external-config&#34;&gt;ここ&lt;/a&gt;とか&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/howto-properties-and-configuration.html&#34;&gt;ここ&lt;/a&gt;参照)、大抵は&lt;code&gt;application.properties&lt;/code&gt;で指定するんだろうけど、手軽にコマンドラインで以下の様に指定することもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;java -jar build/libs/goslings-0.0.1.jar --logging.file=build/hoge.log
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ログファイルはデフォルトで10MBでローテーションする。&lt;/p&gt;

&lt;h4 id=&#34;ログレベル&#34;&gt;ログレベル&lt;/h4&gt;

&lt;p&gt;ログレベルには重大度の低い方から&lt;code&gt;TRACE&lt;/code&gt;、&lt;code&gt;DEBUG&lt;/code&gt;、&lt;code&gt;INFO&lt;/code&gt;、&lt;code&gt;WARN&lt;/code&gt;、&lt;code&gt;ERROR&lt;/code&gt;、&lt;code&gt;FATAL&lt;/code&gt;の6段階があり、指定したログレベル以上のログが出力される。(&lt;code&gt;OFF&lt;/code&gt;というログ出力を止めるものもある。)
つまりSpring Bootのデフォルトのログレベルは&lt;code&gt;INFO&lt;/code&gt;だということだ。(Logbackには&lt;code&gt;FATAL&lt;/code&gt;がなく&lt;code&gt;ERROR&lt;/code&gt;として出力される。)&lt;/p&gt;

&lt;p&gt;ログレベルは&lt;code&gt;logging.level.&amp;lt;ロガー名&amp;gt;&lt;/code&gt;という形式のプロパティで指定できる。
例えばコマンドラインから指定するなら以下の感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;java -jar build/libs/goslings-0.0.1.jar --logging.level.org.springframework.web=DEBUG
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;全ロガーのログレベルは&lt;code&gt;logging.level.root&lt;/code&gt;で指定できる。&lt;/p&gt;

&lt;h4 id=&#34;ロギング実装ライブラリの設定&#34;&gt;ロギング実装ライブラリの設定&lt;/h4&gt;

&lt;p&gt;ロギング実装ライブラリの設定ファイルをカスタマイズして、より詳細な設定をすることもできる。&lt;/p&gt;

&lt;p&gt;Logbackの場合、クラスパスのルートに置かれた&lt;code&gt;logback-spring.xml&lt;/code&gt;か&lt;code&gt;logback.xml&lt;/code&gt;がロードされる。
設定ファイルの二重初期化を防いだり&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/boot-features-logging.html#boot-features-logback-extensions&#34;&gt;Spring Boot拡張設定&lt;/a&gt;を利用可能にするために、前者のファイル名が推奨されている。
(Groovyが使える環境なら&lt;code&gt;logback-spring.groovy&lt;/code&gt;でもいい。)&lt;/p&gt;

&lt;p&gt;いつものようにjavaコマンドでアプリを起動する場合は&lt;code&gt;-jar&lt;/code&gt;オプションを使うため、&lt;code&gt;-cp&lt;/code&gt;オプションでクラスパスを指定しても無視されてしまうので、基本は&lt;code&gt;logback-spring.xml&lt;/code&gt;はjarの中に入れることになる。
プロジェクトのリソースディレクトリのトップ(デフォルトでは&lt;code&gt;src/main/resources/&lt;/code&gt;)に&lt;code&gt;logback-spring.xml&lt;/code&gt;を置いておけば、GradleのJavaプラグインの&lt;code&gt;processResources&lt;/code&gt;タスクによってjar内の適切な場所に取り込まれる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;logging.config&lt;/code&gt;プロパティで設定ファイルのパスを指定することもできる。
例えばコマンドラインから指定するなら以下の感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;java -jar build/libs/goslings-0.0.1.jar --logging.config=logback-spring.xml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;logback-spring.xml&lt;/code&gt;の中身は、例えば以下の様に書くとコンソール出力をなくしてファイル出力だけにできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;configuration&amp;gt;
  &amp;lt;include resource=&amp;quot;org/springframework/boot/logging/logback/defaults.xml&amp;quot; /&amp;gt;
  &amp;lt;property name=&amp;quot;LOG_FILE&amp;quot; value=&amp;quot;${LOG_FILE:-${LOG_PATH:-${LOG_TEMP:-${java.io.tmpdir:-/tmp}}/}spring.log}&amp;quot;/&amp;gt;
  &amp;lt;include resource=&amp;quot;org/springframework/boot/logging/logback/file-appender.xml&amp;quot; /&amp;gt;
  &amp;lt;root level=&amp;quot;INFO&amp;quot;&amp;gt;
    &amp;lt;appender-ref ref=&amp;quot;FILE&amp;quot; /&amp;gt;
  &amp;lt;/root&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここで注目すべきは2点。&lt;/p&gt;

&lt;p&gt;まずは&lt;code&gt;include&lt;/code&gt;している&lt;code&gt;defaults.xml&lt;/code&gt;と&lt;code&gt;file-appender.xml&lt;/code&gt;だ。
これらはSpring Bootのコアライブラリである&lt;code&gt;spring-boot.jar&lt;/code&gt;に含まれるファイル。
&lt;code&gt;spring-boot.jar&lt;/code&gt;には他にも&lt;code&gt;base.xml&lt;/code&gt;と&lt;code&gt;console-appender.xml&lt;/code&gt;が含まれている。
これらは、前節までに書いたSpring Bootのロギング挙動を実現している設定ファイルなので、これらを&lt;code&gt;include&lt;/code&gt;して利用すれば自分のカスタム設定ファイルが簡単に書ける。&lt;/p&gt;

&lt;p&gt;もう一点は&lt;code&gt;LOG_FILE&lt;/code&gt;といったプロパティ。
これらはSpring Bootが設定してくれるプロパティで、詳細は&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/boot-features-logging.html#boot-features-custom-log-configuration&#34;&gt;ここ&lt;/a&gt;に。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今日はここまで。
&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/24/goslings-development-memo5-spring-boot-static-resources/&#34;&gt;次回&lt;/a&gt;もまたSpring Bootで、静的リソース処理について。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goslings開発メモ - その3: Spring Boot続続編 (例外処理)</title>
          <link>https://www.kaitoy.xyz/2017/01/13/goslings-development-memo3-spring-boot-exception/</link>
          <pubDate>Fri, 13 Jan 2017 14:01:01 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/01/13/goslings-development-memo3-spring-boot-exception/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/10/goslings-development-memo2-spring-boot-di/&#34;&gt;Goslings開発メモ - その2: Spring Boot続編 (DI)&lt;/a&gt;」の続き。&lt;/p&gt;

&lt;p&gt;Spring Boot続続編で、例外処理について。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;spring-mvcアプリにおける例外処理&#34;&gt;Spring MVCアプリにおける例外処理&lt;/h1&gt;

&lt;p&gt;Goslingsは&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/&#34;&gt;前々回&lt;/a&gt;書いたように&lt;code&gt;spring-boot-starter-web&lt;/code&gt;というスターターを使っていて、つまりSpring MVCアプリだ。&lt;/p&gt;

&lt;p&gt;Spring MVCアプリにおける例外処理についてはちょっと古いが&lt;a href=&#34;https://spring.io/blog/2013/11/01/exception-handling-in-spring-mvc&#34;&gt;この記事&lt;/a&gt;に詳しい。&lt;/p&gt;

&lt;p&gt;まず、Goslingsの構成で例外処理を何も書かなかった場合、コントローラのリクエストハンドラから例外が投げられると、ログにスタックトレースが出力され、クライアントにはHTTPステータスコード&lt;code&gt;500 (Internal Server Error)&lt;/code&gt;とともに以下の様なデフォルトのエラーページが返る。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-development-memo3-spring-boot-exception/err_page.png&#34; alt=&#34;err_page.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;なんだかこれでも十分な気がするが、実際にはちゃんと明示的に例外処理をしたほうがいいだろう。
エラー時に返すHTTPステータスコードをカスタマイズしたり、遷移するページを変えたりしたくなるだろうから。&lt;/p&gt;

&lt;p&gt;記事によれば、リクエストハンドラ内で例外をキャッチして処理するのはイケてなくて、関心事の分離のために別の場所に処理を書くのが良いらしい。&lt;/p&gt;

&lt;p&gt;Spring MVCアプリにおける例外処理には以下の3つの段階がある。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;投げる例外をカスタマイズする&lt;/li&gt;
&lt;li&gt;例外クラス毎の例外ハンドラをコントローラに実装する&lt;/li&gt;
&lt;li&gt;コントローラ間で共用する例外ハンドラクラスを作る&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;以下それぞれについて書く。&lt;/p&gt;

&lt;h4 id=&#34;1-投げる例外をカスタマイズする&#34;&gt;1. 投げる例外をカスタマイズする&lt;/h4&gt;

&lt;p&gt;リクエストハンドラから投げる例外に&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/ResponseStatus.html&#34;&gt;&lt;code&gt;@ResponseStatus&lt;/code&gt;&lt;/a&gt;をつけることで、クライアントに返すHTTPステータスコード(とリーズンフレーズ)をカスタマイズできる。&lt;/p&gt;

&lt;p&gt;例えば以下のような例外を投げると、HTTPステータスコード&lt;code&gt;500 (Internal Server Error)&lt;/code&gt;の代わりに&lt;code&gt;400 (Bad Request)&lt;/code&gt;がクライアントに返る。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@ResponseStatus(HttpStatus.BAD_REQUEST)
public final class BadRequestException extends RuntimeException {
  // 省略
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;2-例外クラス毎の例外ハンドラをコントローラに実装する&#34;&gt;2. 例外クラス毎の例外ハンドラをコントローラに実装する&lt;/h4&gt;

&lt;p&gt;コントローラのメソッドに&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/ExceptionHandler.html&#34;&gt;&lt;code&gt;@ExceptionHandler&lt;/code&gt;&lt;/a&gt;をつけてやると、そのメソッドは例外ハンドラになり、そのコントローラのリクエストハンドラから特定の例外が投げられたときの処理を書くことができる。
さらに例外ハンドラに&lt;code&gt;@ResponseStatus&lt;/code&gt;をつければ、HTTPステータスコードをカスタマイズできる。
例外ハンドラの戻り値はリクエストハンドラのと同様に処理されるので、遷移するページ等も自由にカスタマイズできる。&lt;/p&gt;

&lt;p&gt;Goslingsでは、上記&lt;code&gt;BadRequestException&lt;/code&gt;からは&lt;code&gt;@ResponseStatus&lt;/code&gt;を削除したうえで、&lt;code&gt;RestApiV1Controller&lt;/code&gt;に以下の様に例外ハンドラを書いた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public final class RestApiV1Controller {

  // 例外ハンドラ
  @ResponseStatus(HttpStatus.BAD_REQUEST)
  @ExceptionHandler(BadRequestException.class)
  ErrorInfo handleBadRequestException(HttpServletRequest req, Exception ex) {
    return new ErrorInfo(req.getRequestURL().toString(), ex);
  }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(RestApiV1Controller.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/controller/RestApiV1Controller.java&#34;&gt;こちら&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;こう書くと、&lt;code&gt;RestApiV1Controller&lt;/code&gt;の任意のリクエストハンドラから&lt;code&gt;BadRequestException&lt;/code&gt;が投げられると、&lt;code&gt;handleBadRequestException&lt;/code&gt;が呼び出され、HTTPステータスコード&lt;code&gt;400 (Bad Request)&lt;/code&gt;とともにクライアントにHTTPレスポンスが返る。
&lt;code&gt;RestApiV1Controller&lt;/code&gt;はREST APIコントローラなので、このHTTPレスポンスのボディは、&lt;code&gt;handleBadRequestException&lt;/code&gt;の戻り値である&lt;code&gt;ErrorInfo&lt;/code&gt;オブジェクトをJSONに変換したものになる。&lt;/p&gt;

&lt;p&gt;例外ハンドラの仮引数は、上のコードに書いたもののほか、サーブレット関係のクラスなど(e.g. &lt;code&gt;HttpServletResponse&lt;/code&gt;や&lt;code&gt;HttpSession&lt;/code&gt;。詳しくは&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/ExceptionHandler.html&#34;&gt;Javadoc&lt;/a&gt;参照)を適当に書いておくとSpring MVCがよしなに渡してくれる。&lt;/p&gt;

&lt;p&gt;冒頭に貼った記事には例外ハンドラは&lt;code&gt;Model&lt;/code&gt;を受け取れないとあるが、これは古い情報で、今は受け取れるっぽい。&lt;/p&gt;

&lt;h4 id=&#34;3-コントローラ間で共用する例外ハンドラクラスを作る&#34;&gt;3. コントローラ間で共用する例外ハンドラクラスを作る&lt;/h4&gt;

&lt;p&gt;コントローラから例外処理を完全に分離したい場合や、複数のコントローラで例外ハンドラを共有したい場合は、コントローラアドバイスクラスを書けばいい。&lt;/p&gt;

&lt;p&gt;コントローラアドバイスクラスは&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/ControllerAdvice.html&#34;&gt;&lt;code&gt;@ControllerAdvice&lt;/code&gt;&lt;/a&gt;を付けて定義したクラスで、このクラスに例外ハンドラを書いておくと複数のコントローラで有効になる。&lt;/p&gt;

&lt;p&gt;コントローラアドバイスクラスには例外ハンドラ以外も書ける。
コントローラアドバイスクラスが適用されるのはデフォルトでは全てのコントローラクラスだが、&lt;code&gt;@ControllerAdvice&lt;/code&gt;の値により適用範囲を絞ることもできる。
詳しくは&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/ControllerAdvice.html&#34;&gt;Javadoc&lt;/a&gt;参照。&lt;/p&gt;

&lt;p&gt;Goslingsではコントローラアドバイスクラスは作らなかった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今日はここまで。
&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/17/goslings-development-memo4-spring-boot-logging/&#34;&gt;次回&lt;/a&gt;もまたSpring Bootで、ロギングについて。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goslings開発メモ - その2: Spring Boot続編 (DI)</title>
          <link>https://www.kaitoy.xyz/2017/01/10/goslings-development-memo2-spring-boot-di/</link>
          <pubDate>Tue, 10 Jan 2017 00:21:27 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/01/10/goslings-development-memo2-spring-boot-di/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/&#34;&gt;Goslings開発メモ - その1: Spring Boot編&lt;/a&gt;」の続き。&lt;/p&gt;

&lt;p&gt;Spring Boot続編で、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E4%BE%9D%E5%AD%98%E6%80%A7%E3%81%AE%E6%B3%A8%E5%85%A5&#34;&gt;DI&lt;/a&gt;について。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;diとは&#34;&gt;DIとは&lt;/h1&gt;

&lt;p&gt;DIはDependency Injectionの略。依存性注入と訳される。&lt;/p&gt;

&lt;p&gt;これは、Javaの文脈で具体的目に言うと、あるクラスが依存する具象クラスのインスタンス化と取得をフレームワークに任せることで、具象クラス間の直接的な依存を排除し、よってコンポーネント間を疎結合にする手法。
これにより、アプリの拡張性を高めたり、テストがしやすくなったりする。(&lt;a href=&#34;http://qiita.com/mizunowanko/items/53eed059fc044c5aa5dc&#34;&gt;参考記事&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://projects.spring.io/spring-framework/&#34;&gt;Spring Framework&lt;/a&gt;はもともとこのDI機能を提供するフレームワーク(i.e. DIコンテナ)として普及した。&lt;/p&gt;

&lt;h1 id=&#34;goslingsでdi&#34;&gt;GoslingsでDI&lt;/h1&gt;

&lt;p&gt;Goslingsサーバの内部機能はざっくり、クライアントからのREST API呼び出しを処理するユーザインタフェース層と、Gitリポジトリにアクセスするデータベース層に分かれる。&lt;/p&gt;

&lt;p&gt;Gitリポジトリにアクセスする部分は今回は&lt;a href=&#34;https://eclipse.org/jgit/&#34;&gt;JGit&lt;/a&gt;で実装するが、将来的に別のライブラリで実装しなおす可能性が微レ存なのと、Goslingsの開発自体がWebアプリ開発の練習でもあるので、ちゃんとしたアーキテクチャでと思い、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Data_Access_Object&#34;&gt;DAO&lt;/a&gt;パターンを使ってやった。&lt;/p&gt;

&lt;p&gt;つまり例えば、GitのコミットオブジェクトはJGitのAPIでは&lt;a href=&#34;http://download.eclipse.org/jgit/site/3.7.1.201504261725-r/apidocs/org/eclipse/jgit/revwalk/RevCommit.html&#34;&gt;&lt;code&gt;RevCommitクラス&lt;/code&gt;&lt;/a&gt;で表されるが、ユーザインタフェース層からはリソースクラスである&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/resource/Commit.java&#34;&gt;Commitクラス&lt;/a&gt;(&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/#5-%E3%83%AA%E3%82%BD%E3%83%BC%E3%82%B9%E3%82%AF%E3%83%A9%E3%82%B9%E4%BD%9C%E6%88%90&#34;&gt;前回&lt;/a&gt;参照)を扱う以下の様なDAOインターフェースを呼ぶようにし、JGit依存の実装とは切り離す。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public interface ObjectDao {

  public Commit[] getCommits(String token) throws DaoException;

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(ObjectDao.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/dao/ObjectDao.java&#34;&gt;これ&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ObjectDao&lt;/code&gt;を実装する&lt;code&gt;ObjectDaoImpl&lt;/code&gt;クラスでは、以下の様にJGitを使ってごりごりと実装を書く。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public final class ObjectDaoImpl implements ObjectDao {

  // フィールド定義は省略

  @Override
  public Commit[] getCommits(String token) {
    try {
      return StreamSupport.stream(resolver.getGit(token).log().all().call().spliterator(), false)
               .map(this::convertToCommit)
               .toArray(Commit[]::new);
    } catch (NoHeadException e) {
      // エラー処理
    }
  }

  private Commit convertToCommit(RevCommit commit) {
    // RevCommitをCommitに変換する処理
  }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ユーザインターフェース層は&lt;code&gt;RestApiV1Controller&lt;/code&gt;クラス(&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/#6-%E3%82%B3%E3%83%B3%E3%83%88%E3%83%AD%E3%83%BC%E3%83%A9-rest-api%E3%82%B3%E3%83%B3%E3%83%88%E3%83%AD%E3%83%BC%E3%83%A9-%E4%BD%9C%E6%88%90&#34;&gt;前回&lt;/a&gt;参照)の&lt;code&gt;getCommits&lt;/code&gt;メソッドで、以下の様にObjectDaoを使いたい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public final class RestApiV1Controller {

  private ObjectDao objectDao;

  @RequestMapping(path=&amp;quot;{token}/objects/commits&amp;quot;)
  public Commit[] getCommits(@PathVariable String token) {
    return objectDao.getCommits(token);
  }

  // 以下他のメソッド

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ここで問題になるのが、&lt;code&gt;RestApiV1Controller&lt;/code&gt;の&lt;code&gt;objectDao&lt;/code&gt;フィールドへのインスタンスの代入だが、&lt;code&gt;RestApiV1Controller&lt;/code&gt;内(e.g. &lt;code&gt;RestApiV1Controller&lt;/code&gt;のコンストラクタ)で&lt;code&gt;ObjectDaoImpl&lt;/code&gt;をインスタンス化して代入するのでは、&lt;code&gt;ObjectDaoImpl&lt;/code&gt;というデータベース層の具象クラスへの直接的な依存(i.e. &lt;code&gt;import ObjectDaoImpl&lt;/code&gt;)が発生してしまってまずい。
ユーザインターフェース層とデータベース層が密に結合してしまう。&lt;/p&gt;

&lt;p&gt;ここがDIの使いどころだ。
&lt;code&gt;RestApiV1Controller&lt;/code&gt;への&lt;code&gt;ObjectDaoImpl&lt;/code&gt;インスタンスの注入をフレームワークに任せればいい。&lt;/p&gt;

&lt;h1 id=&#34;spring-bootでのdi&#34;&gt;Spring BootでのDI&lt;/h1&gt;

&lt;p&gt;Spring Bootアプリでは&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/spring-framework-reference/html/beans.html&#34;&gt;Spring FrameworkのDI機能&lt;/a&gt;を何でも使えるが、普通、もっとも簡単な方法である&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/context/annotation/ComponentScan.html&#34;&gt;&lt;code&gt;@ComponentScan&lt;/code&gt;&lt;/a&gt;と&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/spring-framework-reference/html/beans.html#beans-autowired-annotation&#34;&gt;&lt;code&gt;@Autowired&lt;/code&gt;&lt;/a&gt;を使う方法を採る。&lt;/p&gt;

&lt;p&gt;まずは&lt;code&gt;@ComponentScan&lt;/code&gt;だが、これは、&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/#7-%E3%83%A1%E3%82%A4%E3%83%B3%E3%82%AF%E3%83%A9%E3%82%B9%E4%BD%9C%E6%88%90&#34;&gt;前回&lt;/a&gt;書いたように既に使っていて、プロジェクト内の全てのSpring Beanが検索されDIコンテナに登録されるようになっている。
なので、注入したい&lt;code&gt;ObjectDaoImpl&lt;/code&gt;がSpring Beanと判定されるようにすればよい。&lt;/p&gt;

&lt;p&gt;そのためには、&lt;code&gt;ObjectDaoImpl&lt;/code&gt;に以下のアノテーションのいずれかを付ける必要がある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Service.html&#34;&gt;&lt;code&gt;@Service&lt;/code&gt;&lt;/a&gt;: 業務手続を表すAPIを提供する(しばしば状態を持たない)コンポーネント。またはそれっぽいもの。MVCアーキテクチャのM(モデル)や、3層アーキテクチャのビジネスロジック層のコンポーネント。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Repository.html&#34;&gt;&lt;code&gt;@Repository&lt;/code&gt;&lt;/a&gt;: データの保持、取得、検索といった振る舞いを持つ、オブジェクトコレクションを表すコンポーネント。またはそれっぽいもの。MVCアーキテクチャのM(モデル)の内、特にデータベースを扱うコンポーネントや、3層アーキテクチャのデータベース層のコンポーネント。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Controller.html&#34;&gt;&lt;code&gt;@Controller&lt;/code&gt;&lt;/a&gt;: MVCアーキテクチャのC(コントローラ)のコンポーネント。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Component.html&#34;&gt;&lt;code&gt;@Component&lt;/code&gt;&lt;/a&gt;: 一般的なコンポーネント。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(&lt;a href=&#34;http://qiita.com/KevinFQ/items/abc7369cb07eb4b9ae29&#34;&gt;参考記事&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ObjectDaoImpl&lt;/code&gt;はDAOコンポーネントで、これはもちろん&lt;code&gt;@Repository&lt;/code&gt;にあたるのでこれを付ける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Repository
public final class ObjectDaoImpl implements ObjectDao {
  // 省略
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで&lt;code&gt;ObjectDaoImpl&lt;/code&gt;がSpring Beanとして登録されるので、あとは&lt;code&gt;RestApiV1Controller&lt;/code&gt;に&lt;code&gt;@Autowired&lt;/code&gt;で注入してやればいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public final class RestApiV1Controller {

  @Autowired
  private ObjectDao objectDao;

  // 以下省略。

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;@Autowired&lt;/code&gt;を付けたことにより、&lt;code&gt;RestApiV1Controller&lt;/code&gt;のインスタンス化直後に、&lt;code&gt;objectDao&lt;/code&gt;フィールドに適切なSpring Beanが注入されるようになった。&lt;/p&gt;

&lt;p&gt;注入されるSpring Beanはフィールドの型から判断される。
&lt;code&gt;objectDao&lt;/code&gt;フィールドの型は&lt;code&gt;ObjectDao&lt;/code&gt;で、この実装はプロジェクト内に&lt;code&gt;ObjectDaoImpl&lt;/code&gt;しかないので、狙い通り&lt;code&gt;ObjectDaoImpl&lt;/code&gt;が注入される。
今はこれでもいいが、将来&lt;code&gt;ObjectDao&lt;/code&gt;の実装が増えた場合、どの実装を注入すべきかSpring Frameworkには分からなくなるので、今のうちに&lt;a href=&#34;http://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/beans/factory/annotation/Qualifier.html&#34;&gt;&lt;code&gt;@Qualifier&lt;/code&gt;&lt;/a&gt;を使って明示しておくことにする。(&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/spring-framework-reference/html/beans.html#beans-autowired-annotation-qualifiers&#34;&gt;参考&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;まずSpring Beanの方に&lt;code&gt;jgit&lt;/code&gt;という値を持つ&lt;code&gt;@Qualifier&lt;/code&gt;をつける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Repository
@Qualifier(&amp;quot;jgit&amp;quot;)
public final class ObjectDaoImpl implements ObjectDao {
  // 省略
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(ObjectDaoImpl.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/dao/jgit/ObjectDaoImpl.java&#34;&gt;これ&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Spring Beanを使う側にも同じ&lt;code&gt;@Qualifier&lt;/code&gt;をつける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public final class RestApiV1Controller {

  @Autowired
  @Qualifier(&amp;quot;jgit&amp;quot;)
  private ObjectDao objectDao;

  // 以下省略。

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(RestApiV1Controller.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/controller/RestApiV1Controller.java&#34;&gt;こちら&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで&lt;code&gt;RestApiV1Controller&lt;/code&gt;の&lt;code&gt;objectDao&lt;/code&gt;フィールドにどの&lt;code&gt;ObjectDao&lt;/code&gt;実装が注入されるかがより明確になった。
将来&lt;code&gt;ObjectDao&lt;/code&gt;の別の実装を作るときには、その実装クラスには別の値の&lt;code&gt;@Qualifier&lt;/code&gt;を付けてやれば、&lt;code&gt;RestApiV1Controller&lt;/code&gt;の方の&lt;code&gt;@Qualifier&lt;/code&gt;の値によって注入する実装を切り替えられる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今日はここまで。
&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/13/goslings-development-memo3-spring-boot-exception/&#34;&gt;次回&lt;/a&gt;もまたSpring Bootで、例外処理について。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goslings開発メモ - その1: Spring Boot編</title>
          <link>https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/</link>
          <pubDate>Tue, 03 Jan 2017 23:36:01 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2016/12/11/goslings-development-memo0-intro-design/&#34;&gt;Goslings開発メモ - その0: 紹介と概要と設計編&lt;/a&gt;」の続き。&lt;/p&gt;

&lt;p&gt;Spring Boot編。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;spring-bootとは&#34;&gt;Spring Bootとは&lt;/h1&gt;

&lt;p&gt;Spring Bootは&lt;a href=&#34;http://projects.spring.io/spring-framework/&#34;&gt;Spring Framework&lt;/a&gt;というJavaのWebアプリケーションフレームワークを簡単に利用するためのツールやライブラリ群。&lt;/p&gt;

&lt;p&gt;これを使うと、Webアプリケーションコンテナ(e.g. &lt;a href=&#34;http://tomcat.apache.org/&#34;&gt;Tomcat&lt;/a&gt;)なしで起動できるSpringアプリケーションを、自動コード生成も設定ファイル作成もせずに作ることができる。
必要な設定は自動で構成され、設定のカスタマイズもアノテーションでできる。&lt;/p&gt;

&lt;p&gt;GAになったのが&lt;a href=&#34;https://www.infoq.com/news/2014/04/spring-boot-goes-ga&#34;&gt;2014年4月&lt;/a&gt;なのでかなり新しいものだが、JavaのWebアプリケーションを作るためのものとしては今世界的に最も流行っているもの。&lt;/p&gt;

&lt;p&gt;私が昔とあるWebアプリを作った時は&lt;a href=&#34;http://projects.spring.io/spring-roo/&#34;&gt;Spring Roo&lt;/a&gt;という&lt;a href=&#34;https://ja.wikipedia.org/wiki/RAD_(%E8%A8%88%E7%AE%97%E6%A9%9F%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%E7%92%B0%E5%A2%83&#34;&gt;RADツール&lt;/a&gt;が熱かったが、これはコード自動生成をして開発を助けてくれるもので、なんだか結局あまり流行らなかったようだ。&lt;/p&gt;

&lt;p&gt;Goslingsには最新バージョンの1.4.3.RELEASEを使った。&lt;/p&gt;

&lt;h1 id=&#34;spring-bootことはじめ&#34;&gt;Spring Bootことはじめ&lt;/h1&gt;

&lt;p&gt;包括的網羅的なドキュメントは「&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/htmlsingle/&#34;&gt;Spring Boot Reference Guide&lt;/a&gt;」だが、今回あまり深く学ぶ時間が取れなかったのでこれはちら見した程度。
それよりも、ユースケースごとのチュートリアルが60個以上も載っている「&lt;a href=&#34;https://spring.io/guides/&#34;&gt;Getting Started Guides&lt;/a&gt;」を参考にした。&lt;/p&gt;

&lt;p&gt;Goslingsサーバは基本REST APIサーバなので、上記チュートリアルの内「&lt;a href=&#34;https://spring.io/guides/gs/rest-service/&#34;&gt;Building a RESTful Web Service&lt;/a&gt;」を見ながら以下を実施した。&lt;/p&gt;

&lt;h4 id=&#34;1-プロジェクト作成&#34;&gt;1. プロジェクト作成&lt;/h4&gt;

&lt;p&gt;チュートリアルにはGradleプロジェクトのディレクトリ構成を手動で作るところから書いてあるけど、そこは&lt;a href=&#34;http://qiita.com/grachro/items/d1ebad3857a794895426&#34;&gt;IDEなどで楽できる&lt;/a&gt;。
私はEclipseを使っていて、いつのまにかGradleプラグインである&lt;a href=&#34;https://projects.eclipse.org/projects/tools.buildship&#34;&gt;Eclipse Buildship: Eclipse Plug-ins for Gradle&lt;/a&gt;と&lt;a href=&#34;https://marketplace.eclipse.org/content/gradle-ide-pack&#34;&gt;Gradle IDE Pack&lt;/a&gt;がインストールされていたので、これらを使った。&lt;/p&gt;

&lt;p&gt;どちらのプラグインでもプロジェクトは作成できるが、&lt;a href=&#34;http://qiita.com/grachro/items/16bba860f9d9fe5ee4c5&#34;&gt;Qiitaのこの記事&lt;/a&gt;にあるとおり、Gradle IDE Pack(に含まれる&lt;a href=&#34;https://github.com/spring-projects/eclipse-integration-gradle/&#34;&gt;Gradle (STS) Integration for Eclipse by Pivotal&lt;/a&gt;)で作った場合、Gradle Wrapperが生成されないなどの問題があるので、Buildshipの方で作成。
ただ、Gradle IDE Packの方がパッケージ・エクスプローラでの見え方がちょっとよかったので、こちらでプロジェクトをインポートしなおした。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-development-memo1-spring-boot/gradle_import.png&#34; alt=&#34;gradle_import.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;(上がBuildshipのやつで、下がGradle IDE Packのやつ)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;出来たプロジェクトは以下の感じ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-development-memo1-spring-boot/project_structure.png&#34; alt=&#34;project_structure.png&#34; /&gt;
&lt;/p&gt;

&lt;h4 id=&#34;2-spring-boot-gradle-plugin適用&#34;&gt;2. Spring Boot Gradle plugin適用&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/build-tool-plugins-gradle-plugin.html&#34;&gt;Spring Boot Gradle plugin&lt;/a&gt;というものがあって、これをプロジェクトに適用すると以下の恩恵を受けられる。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;依存ライブラリ管理機能&lt;/p&gt;

&lt;p&gt;Spring関係のライブラリについて適切なバージョンを設定してくれるので、Gradleビルド設定(i.e. &lt;code&gt;build.gradle&lt;/code&gt;)の&lt;code&gt;dependencies&lt;/code&gt;に自分でバージョンを書かなくていい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;実行可能jar(war)のパッケージング機能&lt;/p&gt;

&lt;p&gt;ビルドされたjar(やwar)を、単独で実行可能になるようにマニフェストやライブラリを詰めて再パッケージングする&lt;code&gt;bootRepackage&lt;/code&gt;というGradleタスクが追加される。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プロジェクトから直接アプリを起動する機能&lt;/p&gt;

&lt;p&gt;jarなどのアーティファクトをビルドせずに、プロジェクトから直接アプリを起動できる&lt;code&gt;bootRun&lt;/code&gt;というGradleタスクが追加される。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;build.gradle&lt;/code&gt;に以下の様に書くとSpring Boot Gradle pluginを適用できる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Gradle 2.1より古いバージョン&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;buildscript {
  repositories {
    mavenCentral()
  }
  dependencies {
    classpath(&#39;org.springframework.boot:spring-boot-gradle-plugin:1.4.3.RELEASE&#39;)
  }
}


apply plugin: &#39;org.springframework.boot&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(&lt;code&gt;apply plugin: &#39;org.springframework.boot&#39;&lt;/code&gt;の部分は、Spring Boot Gradle plugin 1.4.1.RELEASE以前は&lt;code&gt;apply plugin: &#39;spring-boot&#39;&lt;/code&gt;だった。)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Gradle 2.1以降&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;plugins {
  id &#39;org.springframework.boot&#39; version &#39;1.4.3.RELEASE&#39;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;3-依存ライブラリ追加&#34;&gt;3. 依存ライブラリ追加&lt;/h4&gt;

&lt;p&gt;Spring Bootは依存ライブラリの管理も簡易化してくれる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;spring-boot-starter-&lt;/code&gt;で始まる&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/htmlsingle/#using-boot-starter&#34;&gt;スターター&lt;/a&gt;と呼ばれるライブラリがいくつか提供されていて、作りたいアプリの種類や機能に応じたものをプロジェクトの依存ライブラリとして追加すると、推移的に諸々の必要なライブラリが追加されるようになっている。
例えば、&lt;a href=&#34;http://www.thymeleaf.org/&#34;&gt;Thymeleaf&lt;/a&gt;をテンプレートエンジンに使ったWebアプリを作るなら&lt;code&gt;spring-boot-starter-thymeleaf&lt;/code&gt;、&lt;a href=&#34;http://projects.spring.io/spring-data-jpa/&#34;&gt;JPA&lt;/a&gt; (&lt;a href=&#34;http://hibernate.org/orm/&#34;&gt;Hibernate&lt;/a&gt;)でデータベースアクセスしたい場合は&lt;code&gt;spring-boot-starter-data-jpa&lt;/code&gt;を使う。&lt;/p&gt;

&lt;p&gt;Webアプリを作るのに最も一般的なのは&lt;code&gt;spring-boot-starter-web&lt;/code&gt;で、Goslingsにもこれを使った。
これを使うと&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/spring-framework-reference/html/mvc.html&#34;&gt;Spring MVC&lt;/a&gt;でアプリを作ることになる。&lt;/p&gt;

&lt;p&gt;また、&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/htmlsingle/#production-ready&#34;&gt;Spring Boot Actuator&lt;/a&gt;という、アプリをプロダクション環境で運用するための機能を有効にするため、&lt;code&gt;spring-boot-starter-actuator&lt;/code&gt;も使った。
これを有効にすると、Web APIでアプリの状態取得などができるようになる。
例えば、&lt;code&gt;http://&amp;lt;サーバ&amp;gt;/health&lt;/code&gt;にアクセスするとアプリの基本的なヘルス情報がJSONで取得できる。&lt;/p&gt;

&lt;p&gt;これら二つのスターターを追加するには、&lt;code&gt;build.gradle&lt;/code&gt;の&lt;code&gt;dependencies&lt;/code&gt;に以下の様に書くだけでいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;dependencies {
  compile &#39;org.springframework.boot:spring-boot-starter-web&#39;
  compile &#39;org.springframework.boot:spring-boot-starter-actuator&#39;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;前節に書いた通り、Spring Boot Gradle pluginのおかげでバージョンの指定は不要。&lt;/p&gt;

&lt;h4 id=&#34;4-ディベロッパツール追加&#34;&gt;4. ディベロッパツール追加&lt;/h4&gt;

&lt;p&gt;Spring Bootの&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/using-boot-devtools.html&#34;&gt;ディベロッパツール&lt;/a&gt;を利用すると、以下の恩恵を受けられる。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;キャッシュの無効化&lt;/p&gt;

&lt;p&gt;Spring Bootがサポートしているライブラリ(e.g. Thymeleafといったテンプレートエンジン)にはキャッシュ機能を持つものがある。
こうした機能はプロダクション環境では性能改善に有効だが、開発時にはじゃまになる。
ディベロッパツールを使うとデフォルトで様々なキャッシュを無効にしてくれる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;自動再起動&lt;/p&gt;

&lt;p&gt;クラスパスに含まれるファイルに変更があるとアプリが自動で再起動される。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ライブリロード&lt;/p&gt;

&lt;p&gt;ブラウザのアドオンを&lt;a href=&#34;http://livereload.com/extensions/&#34;&gt;インストール&lt;/a&gt;すると、アプリに変更があったらブラウザが自動でリロードしてくれるようになる。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ディベロッパツールを追加するには、&lt;code&gt;build.gradle&lt;/code&gt;の&lt;code&gt;dependencies&lt;/code&gt;に以下の様に書くだけでいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;dependencies {
  compile &#39;org.springframework.boot:spring-boot-devtools&#39;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ディベロッパツールは、アプリがプロダクション環境で起動されたと判定すると自動で無効になるので、アーティファクトに含まれても問題ない。
&lt;code&gt;java -jar&lt;/code&gt;で起動されるか、または通常のものではないクラスローダが起動に使われると、プロダクション環境だと判定される。
&lt;code&gt;build.gradle&lt;/code&gt;に以下の様に書けば、アーティファクトに含まれないようにもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;bootRepackage {
  excludeDevtools = true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ディベロッパツールへの推移的依存を避けるための&lt;a href=&#34;https://github.com/spring-projects/gradle-plugins/tree/master/propdeps-plugin&#34;&gt;propdeps-plugin&lt;/a&gt;というプラグインもあるが、Goslingsは他のアプリが依存するようなものではないので使わなかった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;自動再起動については、Eclipseの自動ビルドはデフォルトで&lt;code&gt;goslings/bin&lt;/code&gt;にクラスファイルを吐くので、ビルドパスの構成で「デフォルト出力フォルダー」を&lt;code&gt;goslings/build/classes/main&lt;/code&gt;に変えないと動かなかった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ここまででベースとなる&lt;code&gt;build.gradle&lt;/code&gt;ができて、以下の様になった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;buildscript {
  repositories {
    mavenCentral()
  }
  dependencies {
    classpath &amp;quot;org.springframework.boot:spring-boot-gradle-plugin:${springBootVer}&amp;quot;
  }
}

repositories {
  mavenCentral()
}

apply plugin: &#39;java&#39;
apply plugin: &#39;org.springframework.boot&#39;

archivesBaseName = &#39;goslings&#39;
version = &#39;0.0.1&#39;

[compileJava, compileTestJava]*.options*.encoding = &#39;UTF-8&#39;
sourceCompatibility = 1.8
targetCompatibility = 1.8

bootRepackage {
  excludeDevtools = true
}

dependencies {
  compile &#39;org.springframework.boot:spring-boot-starter-web&#39;
  compile &#39;org.springframework.boot:spring-boot-starter-actuator&#39;
  compile &#39;org.springframework.boot:spring-boot-devtools&#39;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;5-リソースクラス作成&#34;&gt;5. リソースクラス作成&lt;/h3&gt;

&lt;p&gt;ここからやっとコーディング。
まずはREST APIで取得するリソースを表現するクラスを作る。&lt;/p&gt;

&lt;p&gt;Goslingsの場合、Gitリポジトリのオブジェクトやリファレンスなどがリソースになる。
例えばコミットオブジェクトを表すクラスは以下の様に書いた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public final class Commit {

  private final String id;
  private final String[] parentIds;
  private final String treeId;

  // 以下、全フィールドをセットするコンストラクタとgetters。

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(Commit.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/resource/Commit.java&#34;&gt;これ&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;POJOとして書けばいいので、&lt;a href=&#34;https://projectlombok.org/&#34;&gt;Lombok&lt;/a&gt;の&lt;code&gt;@Data&lt;/code&gt;か&lt;code&gt;@Value&lt;/code&gt;を使うと楽だろうが、Goslingsには使わなかった。&lt;/p&gt;

&lt;h4 id=&#34;6-コントローラ-rest-apiコントローラ-作成&#34;&gt;6. コントローラ(REST APIコントローラ)作成&lt;/h4&gt;

&lt;p&gt;クライアントからのHTTPリクエストを処理するクラスはコントローラクラスと呼ばれる。
クライアントからのREST API呼び出しもHTTPリクエストなのでコントローラクラスで処理する。&lt;/p&gt;

&lt;p&gt;REST API呼び出しを処理するコントローラクラスは、&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/RestController.html&#34;&gt;&lt;code&gt;@RestController&lt;/code&gt;&lt;/a&gt;を付けて宣言して、&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/RequestMapping.html&#34;&gt;&lt;code&gt;@RequestMapping&lt;/code&gt;&lt;/a&gt;を付けたメソッド(リクエストハンドラ)にURL毎の処理を書いてやればいい。&lt;/p&gt;

&lt;p&gt;以下の様な感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@RestController
@RequestMapping(
  path=&amp;quot;/v1&amp;quot;,
  method=RequestMethod.GET
)
public final class RestApiV1Controller {

  // この辺でフィールド定義など

  @RequestMapping(path=&amp;quot;{token}/objects/commits&amp;quot;)
  public Commit[] getCommits(@PathVariable String token) {
    return objectDao.getCommits(token);
  }

  // 以下他のメソッド

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(RestApiV1Controller.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/controller/RestApiV1Controller.java&#34;&gt;こちら&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;上のコードでは、&lt;code&gt;http://&amp;lt;Goslingsサーバ&amp;gt;/v1/&amp;lt;トークン&amp;gt;/objects/commits&lt;/code&gt;というURLを&lt;code&gt;getCommits&lt;/code&gt;メソッドで処理するようにしている。
このAPIを呼び出すと、前節で作った&lt;code&gt;Commit&lt;/code&gt;クラスのインスタンスの配列がJSON形式で返ってくる。
(getCommitsの実装については次回書く。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;@RestController&lt;/code&gt;を付けると以下の二つのアノテーションを付けたのと同じことになる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Controller.html&#34;&gt;&lt;code&gt;@Controller&lt;/code&gt;&lt;/a&gt;: 一般的なコントローラクラスに付けるアノテーション。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/ResponseBody.html&#34;&gt;&lt;code&gt;@ResponseBody&lt;/code&gt;&lt;/a&gt;: メソッドの戻り値をHTTPレスポンスボディにバインドすることを指示する。これを付けると、戻り値は&lt;a href=&#34;http://wiki.fasterxml.com/JacksonHome&#34;&gt;Jackson JSON&lt;/a&gt;でJSONに変換されてクライアントに返される。これを付けないと、戻り値はスタティックリソースへのパスなどとして扱われ、View(e.g. Thymeleaf)が処理した結果がクライアントに返される。(&lt;a href=&#34;http://qiita.com/tag1216/items/3680b92cf96eb5a170f0&#34;&gt;参考記事&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;見ての通り、URLのパス中の値は&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/PathVariable.html&#34;&gt;&lt;code&gt;@PathVariable&lt;/code&gt;&lt;/a&gt;を使って取得できる。&lt;/p&gt;

&lt;p&gt;ここには書いてないけど、URLクエリパラメータは&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/RequestParam.html&#34;&gt;&lt;code&gt;@RequestParam&lt;/code&gt;&lt;/a&gt;を使って取得できるし、&lt;a href=&#34;http://mergedoc.osdn.jp/tomcat-servletapi-5-ja/javax/servlet/http/HttpServletRequest.html&#34;&gt;&lt;code&gt;HttpServletRequest&lt;/code&gt;&lt;/a&gt;もメソッドの引数として宣言しておけばSpringが渡してくれる。&lt;/p&gt;

&lt;h4 id=&#34;7-メインクラス作成&#34;&gt;7. メインクラス作成&lt;/h4&gt;

&lt;p&gt;最後に、アプリを起動するメインクラスを作る。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/api/org/springframework/boot/autoconfigure/SpringBootApplication.html&#34;&gt;&lt;code&gt;@SpringBootApplication&lt;/code&gt;&lt;/a&gt;を付けたクラスに&lt;code&gt;main&lt;/code&gt;メソッドを以下の様に定義すればいいだけ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@SpringBootApplication
public class Application {

  public static void main(String[] args) {
    SpringApplication.run(Application.class, args);
  }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(Application.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/Application.java&#34;&gt;こちら&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;@SpringBootApplication&lt;/code&gt;を付けると、以下の三つのアノテーションを付けたのと同じことになる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/context/annotation/Configuration.html&#34;&gt;&lt;code&gt;@Configuration&lt;/code&gt;&lt;/a&gt; (&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/api/org/springframework/boot/SpringBootConfiguration.html&#34;&gt;&lt;code&gt;@SpringBootConfiguration&lt;/code&gt;&lt;/a&gt;): Spring Bean定義を提供するクラスであることを示す。(意味不明。)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/api/org/springframework/boot/autoconfigure/EnableAutoConfiguration.html&#34;&gt;&lt;code&gt;@EnableAutoConfiguration&lt;/code&gt;&lt;/a&gt;: Springの&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/using-boot-auto-configuration.html&#34;&gt;自動設定機能&lt;/a&gt;を有効にする。この機能は、ライブラリの依存関係から推定して必要な設定をしてくれるもの。例えば&lt;code&gt;tomcat-embedded.jar&lt;/code&gt;に依存していたら、&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/api/org/springframework/boot/context/embedded/tomcat/TomcatEmbeddedServletContainerFactory.html&#34;&gt;&lt;code&gt;TomcatEmbeddedServletContainerFactory&lt;/code&gt;&lt;/a&gt;をセットアップしてくれるなど。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/context/annotation/ComponentScan.html&#34;&gt;&lt;code&gt;@ComponentScan&lt;/code&gt;&lt;/a&gt;: このアノテーションを付けたクラスのパッケージ以下から、&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Component.html&#34;&gt;&lt;code&gt;@Component&lt;/code&gt;&lt;/a&gt;、&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Service.html&#34;&gt;&lt;code&gt;@Service&lt;/code&gt;&lt;/a&gt;、&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Repository.html&#34;&gt;&lt;code&gt;@Repository&lt;/code&gt;&lt;/a&gt;、&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Controller.html&#34;&gt;&lt;code&gt;@Controller&lt;/code&gt;&lt;/a&gt;(など?)が付いたクラスが検索され、Spring Beanとして登録される。XMLのSpring Bean設定ファイルを書かなくてよい。前節で作ったリソースコントローラがこのアノテーションによって利用できるようになる。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;@SpringBootApplication&lt;/code&gt;、というか&lt;code&gt;@Configuration&lt;/code&gt;をつけたクラスは&lt;code&gt;final&lt;/code&gt;にしてはいけない。
すると実行時にエラーになる。&lt;/p&gt;

&lt;h4 id=&#34;8-ビルド-実行&#34;&gt;8. ビルド、実行&lt;/h4&gt;

&lt;p&gt;以上でとりあえず動くものができた。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;gradlew bootRun&lt;/code&gt;を実行するとディベロッパツール付きでアプリが動くし、&lt;code&gt;gradlew build&lt;/code&gt;を実行すれば&lt;code&gt;build/libs/goslings-0.0.1.jar&lt;/code&gt;というアーティファクトが生成され、&lt;code&gt;java -jar build/libs/goslings-0.0.1.jar&lt;/code&gt;でアプリを起動できる。
(いずれもポートは8080)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今日はここまで。
&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/10/goslings-development-memo2-spring-boot-di/&#34;&gt;次回&lt;/a&gt;はまたSpring Bootで、DIについて。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goslings開発メモ - その0: 紹介と概要と設計編</title>
          <link>https://www.kaitoy.xyz/2016/12/11/goslings-development-memo0-intro-design/</link>
          <pubDate>Sun, 11 Dec 2016 15:26:45 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/12/11/goslings-development-memo0-intro-design/</guid>
          <description>

&lt;p&gt;つい先日&lt;a href=&#34;https://github.com/kaitoy/goslings&#34;&gt;&lt;strong&gt;Goslings&lt;/strong&gt;&lt;/a&gt;というものを作った。
&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;Gitのリポジトリの中身&lt;/a&gt;をビジュアライズするWebアプリケーションだ。
なんとなく見て楽しいという効用がある他は、Gitの勉強にちょっと使えるかもしれないという程度のものだが、もともと&lt;a href=&#34;http://qiita.com/advent-calendar/2016/git&#34;&gt;Git Advent Calendar 2016&lt;/a&gt;のネタを作るために作ろうと思ったものなので、とりあえずはこんなものでいいのだ。
将来気が向いたら、リポジトリの変更をリアルタイムに反映したり、リポジトリの操作もできるように拡張してもいいかもしれないけど、実用性が感じられないので多分やらない。&lt;/p&gt;

&lt;p&gt;因みに、goslingsというのはgeese(雁)の子供を指す、ちょっとマイナーな英語。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-development-memo0-design/geese.JPG&#34; alt=&#34;geese&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Gitオブジェクトを見るアプリだから、GOで始まる名前にしようかと思っていて、そういえば今住んでいるFort Collinsに大量にいるgeeseの子供がgoslingsというし、並んで歩いている姿がちょうどコミットグラフのようだと思い、Goslilngsと名付けた。
単数形だと&lt;a href=&#34;https://en.wikipedia.org/wiki/Ryan_Gosling&#34;&gt;カナダのイケメン俳優&lt;/a&gt;かと思われてしまうので、複数形にした。goslingが一人でいることってないし。&lt;/p&gt;

&lt;p&gt;Goslingsは&lt;a href=&#34;https://projects.spring.io/spring-boot/&#34;&gt;Spring Boot&lt;/a&gt;や&lt;a href=&#34;https://eclipse.org/jgit/&#34;&gt;JGit&lt;/a&gt;などの習作でもある。
学んだことはアプリケーションとしてアウトプットするとよく身に付くものだ。
また文章としてもアウトプットしておくとさらによく身に付き、備忘録にもなるので、Goslingsの開発メモをいくつかのエントリに分けて書いていくことにする。&lt;/p&gt;

&lt;p&gt;まずはSpring Boot編を書こうかと思うが、その前にGoslingsの設計等について書いておく。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;goslingsのアーキテクチャ&#34;&gt;Goslingsのアーキテクチャ&lt;/h1&gt;

&lt;p&gt;GoslingsはWebサーバとして動き、始めにクライアントにHTML文書を返した後は、REST APIサーバとして働く。&lt;/p&gt;

&lt;p&gt;サーバ側はJavaでできていて、Spring BootとJGitを使っている。
JGitを使いたかったのでJavaにしたが、そうでなければ&lt;a href=&#34;https://nodejs.org/ja/&#34;&gt;Node&lt;/a&gt;で書きたかった。&lt;/p&gt;

&lt;p&gt;因みに、今回はコーディングの詳細にあまりこだわらないつもりだったので、&lt;a href=&#34;https://projectlombok.org/&#34;&gt;Lombok&lt;/a&gt;で楽をしようかと思ったけど、うっとうしい&lt;a href=&#34;https://github.com/rzwitserloot/lombok/issues/879&#34;&gt;バグ&lt;/a&gt;を踏み、どうやっても回避できなかったので使うのやめた。
二度と使うまい。&lt;/p&gt;

&lt;p&gt;クライアント側はJavaScript(ES2015 + async/await)の&lt;a href=&#34;https://en.wikipedia.org/wiki/Single-page_application&#34;&gt;SPA&lt;/a&gt;で、禁&lt;a href=&#34;https://jquery.com/&#34;&gt;jQuery&lt;/a&gt;縛り。
&lt;a href=&#34;https://facebook.github.io/react/&#34;&gt;React&lt;/a&gt; + &lt;a href=&#34;https://github.com/reactjs/redux&#34;&gt;Redux&lt;/a&gt;というのをやってみたかったが、なんか大げさだしそこまで時間がとれなそうだったので、フレームワークなしで作った。ので、
「&lt;a href=&#34;http://qiita.com/tatesuke/items/b9548dd484b01b139b74&#34;&gt;You Don&amp;rsquo;t Need jQuery&lt;/a&gt;」とにらめっこしながら書いた。&lt;/p&gt;

&lt;p&gt;Gitのコミットグラフの描画には、&lt;a href=&#34;http://visjs.org/&#34;&gt;vis.js&lt;/a&gt;を使った。
&lt;a href=&#34;http://stackoverflow.com/questions/7034/graph-visualization-library-in-javascript&#34;&gt;Stack Overflowの回答&lt;/a&gt;から雰囲気で選んだけど、やりたかったことが全部できて、見た目もよかったのでよかった。&lt;/p&gt;

&lt;p&gt;サーバは&lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt;で動かすためにステートレスに作ったつもりで、後述の作業ディレクトリをコンテナ間で共有し、サーバの負荷に応じてコンテナを増やしたり減らしたり、簡単にスケールするようになっているはず。&lt;/p&gt;

&lt;h1 id=&#34;goslingsの機能設計&#34;&gt;Goslingsの機能設計&lt;/h1&gt;

&lt;p&gt;Goslingsサーバにブラウザでアクセスすると、まず参照したいGitリポジトリのURIを入力するフォームが表示される。
ここにはローカルにあるリポジトリへのファイルシステム上のパス(e.g. &lt;code&gt;C:\repos\project-hoge\.git&lt;/code&gt;)か、リモートにあるリポジトリのURL(e.g. &lt;code&gt;https://repos.foo.com/project-hoge.git&lt;/code&gt;)を入力できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-development-memo0-design/goslings-form.png&#34; alt=&#34;goslings-form&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;URIを入力して&lt;code&gt;Browse&lt;/code&gt;ボタンを&lt;a href=&#34;http://qiita.com/yaju/items/0ceb6a0343561b4d208e&#34;&gt;押下する&lt;/a&gt;と、Goslingsの作業ディレクトリ(デフォルトではtmpディレクトリの下の&lt;code&gt;goslings&lt;/code&gt;)に、ローカルリポジトリの場合はそこへのsymlinkを、リモートリポジトリの場合はベアなクローンを作成する。
いずれの場合にも、正規化したURIから生成したUID(SHA-1ハッシュ)をsymlinkファイル名とクローンディレクトリ名に使う。
サーバはリポジトリの準備ができたら、そのUIDをトークン(i.e. リポジトリ引換券)としてクライアントに渡す。
クライアントはそのトークンを使って、リポジトリの情報をサーバに要求する。&lt;/p&gt;

&lt;p&gt;こうすることで、以下の様に後でリポジトリを取り扱いやすくなる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;クライアントやサーバは、可変長の長ったらしい特殊文字の含まれたURIの代わりに、40文字の数字とアルファベットだけで構成されたトークンでリポジトリを特定でき、処理がしやすい。&lt;/li&gt;
&lt;li&gt;後でサーバがリポジトリにアクセスする際、ローカルとリモートを区別する必要がないので、処理がしやすい。&lt;/li&gt;
&lt;li&gt;サーバ内部でリポジトリというエンティティを扱う際、リポジトリに直接触るデータレイヤと、クライアントからのリクエストをさばくインターフェースレイヤとの間で、単なる文字列であるトークンをやりとりすればよく、データレイヤの実装の詳細をインターフェースレイヤに曝さなくてよくなり、レイヤをきれいに分離できる。これはJavaの&lt;a href=&#34;https://docs.oracle.com/javase/tutorial/java/IandI/createinterface.html&#34;&gt;インターフェース&lt;/a&gt;を作ってやってもできるが、インターフェースのAPIを考える手間を考えるとトークンの方が楽。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;クライアントはトークンを受け取ったらコミットグラフビューに遷移する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-development-memo0-design/graph.png&#34; alt=&#34;graph&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;このビューでの表示は&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;以前Gitリポジトリの中身を解説した記事&lt;/a&gt;に合わせた。&lt;/p&gt;

&lt;p&gt;初期状態ではコミットと参照とタグだけが表示されていて、コミットをダブルクリックするとツリーが表示され、さらにツリーをダブルクリックするとドリルダウンしていける。
ノードをシングルクリックするとそのコンテンツを参照できる。&lt;/p&gt;

&lt;h1 id=&#34;goslingsの使い方&#34;&gt;Goslingsの使い方&lt;/h1&gt;

&lt;p&gt;Spring Bootを使ったおかげで、ビルド成果物は単一のjarで、これを以下の様に実行するだけでサーバが立ち上がる。Webアプリケーションコンテナいらず。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ java -jar goslings-server-0.0.1.jar --server.port=80
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;com.github.kaitoy.goslings.server.reposDir&lt;/code&gt;というシステムプロパティを使って作業ディレクトリのパスを指定できる。&lt;/p&gt;

&lt;p&gt;また、&lt;code&gt;com.github.kaitoy.goslings.server.uriPrefix&lt;/code&gt;というシステムプロパティに値を設定すると、その値で始まるURI以外をフォームで入力するとエラーになるようになる。
リモートリポジトリを何でもかんでもクローンされるとディスク容量がいくらあっても足りないので、URLに制限をかけるために作った設定。
汎用性は考えておらず、複数指定したり正規表現を指定したりといったことはできない。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/r/kaitoy/goslings/&#34;&gt;Dockerコンテナイメージ&lt;/a&gt;もあって、以下のようなコマンドでダウンロードして起動できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker pull kaitoy/goslings
$ docker run -p 80:80 -itd kaitoy/goslings 80 /goslings-repos https://github.com/kaitoy/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;docker run&lt;/code&gt;の後ろの方の&lt;code&gt;80 /goslings-repos https://github.com/kaitoy/&lt;/code&gt;が、それぞれ&lt;code&gt;--server.port&lt;/code&gt;、&lt;code&gt;com.github.kaitoy.goslings.server.reposDir&lt;/code&gt;、&lt;code&gt;com.github.kaitoy.goslings.server.uriPrefix&lt;/code&gt;に渡される。
&lt;code&gt;--server.port&lt;/code&gt;のもの以外は省略してもいい。&lt;/p&gt;

&lt;h1 id=&#34;goslings-as-a-service&#34;&gt;Goslings as a Service&lt;/h1&gt;

&lt;p&gt;Goslings as a Service、略してGaaSを &lt;a href=&#34;http://www.goslings.tk&#34;&gt;http://www.goslings.tk&lt;/a&gt; で公開している。
&lt;code&gt;https://github.com/kaitoy/&lt;/code&gt;で始まるURLしか受け付けないようにしてある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/&#34;&gt;AWS&lt;/a&gt;の無料枠を活用して&lt;a href=&#34;https://aws.amazon.com/ecs/&#34;&gt;EC2 Container Service (ECS)&lt;/a&gt;でホストしていて、&lt;a href=&#34;http://www.freenom.com/ja/index.html&#34;&gt;Freenom&lt;/a&gt;で無料で取得した&lt;code&gt;goslings.tk&lt;/code&gt;ドメインとこれまた無料のFreenomのネームサーバを利用して上記のアドレスにしている。&lt;/p&gt;

&lt;p&gt;AWSもFreenomも無料なのは12か月だけなので、それが過ぎたらGaaSは終了する予定。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Currently Pcap4J Doesn&#39;t Work on Bash on Windows</title>
          <link>https://www.kaitoy.xyz/2016/11/19/pcap4j-doesnt-work-on-bow-yet/</link>
          <pubDate>Sat, 19 Nov 2016 11:41:07 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/11/19/pcap4j-doesnt-work-on-bow-yet/</guid>
          <description>

&lt;h1 id=&#34;tl-dr&#34;&gt;TL;DR&lt;/h1&gt;

&lt;p&gt;I&amp;rsquo;ve attempted to run &lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;&lt;strong&gt;Pcap4J&lt;/strong&gt;&lt;/a&gt; on &lt;a href=&#34;https://msdn.microsoft.com/en-us/commandline/wsl/about&#34;&gt;&lt;strong&gt;Bash on Windows&lt;/strong&gt;&lt;/a&gt; (BoW) but it didn&amp;rsquo;t work due to lack of support for network staff in BoW.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;what-s-bash-on-windows&#34;&gt;What&amp;rsquo;s Bash on Windows&lt;/h1&gt;

&lt;p&gt;Bash on Windows is a feature released in &lt;a href=&#34;https://blogs.windows.com/windowsexperience/2016/08/02/how-to-get-the-windows-10-anniversary-update/#j0WW1oOyf4smWkeX.97&#34;&gt;Windows 10 Anniversary Update&lt;/a&gt; to add Linux fanctionalities to Windows.&lt;/p&gt;

&lt;p&gt;With this feature, we can run Bash and several Linux commands on Windows.&lt;/p&gt;

&lt;p&gt;It sounds similar to &lt;a href=&#34;https://www.cygwin.com/&#34;&gt;Cygwin&lt;/a&gt; and &lt;a href=&#34;http://www.mingw.org/&#34;&gt;MinGW&lt;/a&gt; but actually different. Linux commands Cygwin and MinGW provides are Windows-native binaries. On the other hand, BoW enables to run Ubuntu instance as a subsystem of Windows and to execute Ubuntu-native binaries on it.&lt;/p&gt;

&lt;p&gt;BoW can be easily installed by only 2 steps as per &lt;a href=&#34;https://msdn.microsoft.com/commandline/wsl/install_guide&#34;&gt;the installation guide&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;try-pcap4j-in-bow&#34;&gt;Try Pcap4J in BoW&lt;/h1&gt;

&lt;p&gt;BoW can be started by &lt;code&gt;bash&lt;/code&gt; command in command prompt.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;bash
kaitoy@DESKTOP-41L0NMU:/mnt/c/Users/kaitoy$ uname -a
Linx DESKTOP-41L0NMU 3.4.0+ #1 PREEMPT Thu Aug 1 17:06:05 CST 2013 x86_64 x86_64 x86_64 GNU/Linux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the bash, I ran the following commands to install Pcap4J dependencies:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt-get update
sudo apt-get install openjdk-7-jdk libpcap-dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then, I executed Pcap4J (org.pcap4j.sample.GetNextPacketEx) and got an error as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ java -cp pcap4j-core-1.6.2.jar:pcap4j-packetfactory-static-1.6.2.jar:pcap4j-sample-1.6.2.jar:jna-4.2.1.jar:slf4j-api-1.7.12.jar:logback-classic-1.0.0.jar:logback-core-1.0.0.jar org.pcap4j.sample.GetNextPacketEx
org.pcap4j.sample.GetNextPacketEx.count: 5
org.pcap4j.sample.GetNextPacketEx.readTimeout: 10
org.pcap4j.sample.GetNextPacketEx.snaplen: 65536


java.io.IOException: Return code: -1, Message: getifaddrs: Invalid argument
        at org.pcap4j.util.NifSelector.selectNetworkInterface(NifSelector.java:40)
        at org.pcap4j.sample.GetNextPacketEx.main(GetNextPacketEx.java:43)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This error seems due to &lt;a href=&#34;https://github.com/Microsoft/BashOnWindows/issues/69&#34;&gt;lack of support&lt;/a&gt; for network staff in BoW.&lt;/p&gt;

&lt;p&gt;BoW is still beta. I will try again after its production release.&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Bash on WindowsでWindows側からUbuntu側のファイルをいじると壊れることがあるので注意</title>
          <link>https://www.kaitoy.xyz/2016/11/19/bow-do-not-change-linux-files-from-windows/</link>
          <pubDate>Sat, 19 Nov 2016 01:05:26 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/11/19/bow-do-not-change-linux-files-from-windows/</guid>
          <description>

&lt;p&gt;Bash on WindowsでWindows側からUbuntu側のファイルをいじると危険という情報を見つけたので、試してみたら確かに困った状態になった話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;bash-on-windowsとは&#34;&gt;Bash on Windowsとは&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://msdn.microsoft.com/en-us/commandline/wsl/about&#34;&gt;Bash on Windows&lt;/a&gt; (aka BoW)は、2016/8/3に公開されたWindows 10 Anniversary Updateで使えるようになった、Windows上でBashが使えるようになる機能。&lt;/p&gt;

&lt;p&gt;POSIX APIのWindows実装を提供する&lt;a href=&#34;https://www.cygwin.com/&#34;&gt;Cygwin&lt;/a&gt;などとは違い、WindowsのサブシステムとしてUbuntuが動き、その上でBashが動き、そこからUbuntu用のバイナリをそのまま利用できるというもの。&lt;/p&gt;

&lt;p&gt;2016/11/17現在でまだベータ版の機能。&lt;/p&gt;

&lt;h1 id=&#34;windows側からubuntu側のファイルをいじると壊れる問題&#34;&gt;Windows側からUbuntu側のファイルをいじると壊れる問題&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://blogs.msdn.microsoft.com/commandline/2016/11/17/do-not-change-linux-files-using-windows-apps-and-tools/&#34;&gt;Microsoftの中の人のブログ&lt;/a&gt;に、BoWがセットアップされた環境で、Windows側からUbuntu側のファイル(i.e. &lt;code&gt;%localappdata%\lxss\&lt;/code&gt;以下のファイル)をいじると壊れるという話があった。
いかにもやってしまいそうな操作で危険だし、実際このブログの人はこれに関する問い合わせに毎日1,2件対応しているそうな。&lt;/p&gt;

&lt;p&gt;原因は上記ブログに詳しいが、簡単に言うと、Windows側のプロセスがUbuntu側のファイルを作ったり編集したりする際、パーミッションなどのメタデータを適切に設定しないため、Ubuntu側でファイルが壊れたと判断されてしまうから。
こうなると、結果としてファイルが消えてしまったり、壊れたデータで上書きされてしまったりするとのこと。&lt;/p&gt;

&lt;p&gt;因みに、Ubuntu側からWindows側のファイルをいじるのは問題ないらしい。&lt;/p&gt;

&lt;h1 id=&#34;再現確認&#34;&gt;再現確認&lt;/h1&gt;

&lt;p&gt;そういえばまだBoWをさわったことがなかったので、セットアップして件の問題を体験してみた。&lt;/p&gt;

&lt;p&gt;環境は、VMware Player 7.1.0で作ったVMに評価版のWindows 10 Enterprise v1607をインストールしたもの。
セットアップは&lt;a href=&#34;https://msdn.microsoft.com/en-us/commandline/wsl/install_guide&#34;&gt;公式の手順&lt;/a&gt;に従うだけ。2ステップだけの簡単な手順。&lt;/p&gt;

&lt;p&gt;セットアップ後、コマンドプロンプトで&lt;code&gt;bash&lt;/code&gt;とうつとBoWが起動する。(初回はインストール処理が走り、十数分待たされる。)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[コマンドプロンプト → Bash]&lt;/strong&gt;
&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/bow.png&#34; alt=&#34;bow.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;再現確認に使うのは&lt;code&gt;hoge&lt;/code&gt;と書いた&lt;code&gt;hoge.txt&lt;/code&gt;。
これをWindows側の&lt;code&gt;C:\Users\kaitoy\Desktop\&lt;/code&gt;とUbuntu側の&lt;code&gt;/home/kaitoy/&lt;/code&gt;に置く。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[コマンドプロンプト]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/hoge_cmd.png&#34; alt=&#34;hoge_cmd.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/hoge_ubuntu.png&#34; alt=&#34;hoge_ubuntu.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Windows側からは、Ubuntuのファイルシステムが&lt;code&gt;%localappdata%\lxss\&lt;/code&gt;にマウントされているように見える。
(&lt;code&gt;lxss&lt;/code&gt;はエクスプローラーのオプションから「保護されたオペレーティングシステムファイルを表示しない（推奨）」のチェックをはずさないと見えない。見えなくてもアドレスバーにパスを入力すればアクセスできるけど。)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/lxss.png&#34; alt=&#34;lxss.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;一方Ubuntu側からは、WindowsのCドライブが&lt;code&gt;/mnt/c&lt;/code&gt;にマウントされているように見える。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/mntc.png&#34; alt=&#34;mntc.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ここで、コマンドプロンプトを開き、&lt;code&gt;%localappdata%\lxss\hoge\kaitoy\&lt;/code&gt;(i.e. Ubuntu側の&lt;code&gt;/home/kaitoy/&lt;/code&gt;)に&lt;code&gt;cd&lt;/code&gt;し、&lt;code&gt;hoge.txt&lt;/code&gt;を&lt;code&gt;echo&lt;/code&gt;で編集してみた。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[コマンドプロンプト]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/mod_from_cmd.png&#34; alt=&#34;mod_from_cmd.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;したらBashから見えなくなった。アクセスしようとすると「Input/output error」というエラーになる。これが件の現象か。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/disappeared.png&#34; alt=&#34;disappeared.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;エクスプローラからは見えていたので、GUIで&lt;code&gt;%localappdata%\lxss\hoge\kaitoy\hoge.txt&lt;/code&gt;を削除したら正常な状態に戻った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;再度同じ&lt;code&gt;hoge.txt&lt;/code&gt;を作り、今度はメモ帳で編集して内容を&lt;code&gt;foo&lt;/code&gt;に変えてみた。
この場合は特に問題なし。なぜだ?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/no_problem.png&#34; alt=&#34;no_problem.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;例のブログをよく読むと、実際に問題になるのはファイルの作成だけのように読める。
編集しているようにみえても、アプリによっては新規ファイルを作って既存のを置き換えていることがあるから、編集もするなと言っている模様。
メモ帳は実際に編集しているから大丈夫だったということか。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今編集した&lt;code&gt;hoge.txt&lt;/code&gt;を今度はエクスプローラから消してみる。
Ubuntu側からは消えてないように見えるが、アクセスしようとするとないと言われる。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/not_deleted.png&#34; alt=&#34;not_deleted.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;エクスプローラのビューをF5で更新したら、今消したはずの&lt;code&gt;hoge.txt&lt;/code&gt;が復活した。
これをダブルクリックで開こうとしたら「Access is denied.」。
エクスプローラから何度消してもすぐ復活する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/access_denied.png&#34; alt=&#34;access_denied.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Bashで消そうとしても「Permission denied」。詰んだ。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/permission_denied.png&#34; alt=&#34;permission_denied.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ということで、むしろWindows側からUbuntu側のファイルを消すのがもっともやばいと言うことがわかった。
&lt;code&gt;lxrun /uninstall /full&lt;/code&gt;、&lt;code&gt;lxrun /install&lt;/code&gt;でUbuntuイメージをインストールしなおさないと直らない。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;最後に、Ubuntu側(i.e. Bash)からWindows側の&lt;code&gt;C:\Users\kaitoy\Desktop\hoge.txt&lt;/code&gt;をいじってみたが、例のブログに書いてある通りなんの問題もなかった。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/fin.png&#34; alt=&#34;fin.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;件の問題もベータがとれたら直るかもしれないが、&lt;code&gt;%localappdata%\lxss\&lt;/code&gt;は保護された隠しフォルダなのでやはり触らないのが無難か。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>git checkoutを図解する</title>
          <link>https://www.kaitoy.xyz/2016/10/08/git-checkout/</link>
          <pubDate>Sat, 08 Oct 2016 16:39:46 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/10/08/git-checkout/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;この記事&lt;/a&gt;を読んだ、またはGitのオブジェクトモデルを理解していることを前提に、&lt;a href=&#34;https://git-scm.com/&#34;&gt;&lt;strong&gt;Git&lt;/strong&gt;&lt;/a&gt;の &lt;code&gt;git checkout&lt;/code&gt; というコマンドについて説明する。&lt;/p&gt;

&lt;p&gt;このコマンドは普通ブランチを切り替えるものと説明されるが、主たる機能は &lt;strong&gt;オブジェクト格納領域から指定されたファイルを取り出し、ワーキングディレクトリに配置する&lt;/strong&gt; ものである。
つまりこれがGitにおけるチェックアウトで、チェックアウト=ブランチの切り替えではない。&lt;/p&gt;

&lt;p&gt;コマンドに与える引数によっては &lt;code&gt;HEAD&lt;/code&gt; の付け替え、つまりはブランチの切り替えもする、というだけ。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git checkout&lt;/code&gt; の動作を &lt;code&gt;HEAD&lt;/code&gt; の付け替えの有無によって分けて考えると分かりやすく覚えやすいので、以下そのように説明する。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;headを付け替えないgit-checkout&#34;&gt;HEADを付け替えないgit checkout&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;HEAD&lt;/code&gt; を付け替えない &lt;code&gt;git checkout&lt;/code&gt; は、引数にワーキングディレクトリ内の &lt;strong&gt;ファイルまたはディレクトリへのパスを与えた場合&lt;/strong&gt; のもの。
ディレクトリを指定した場合はそれ以下の全ファイルが操作対象となる。
パスは絶対パスかカレントディレクトリからの相対パスで、複数指定できる。&lt;/p&gt;

&lt;p&gt;つまりは以下の様なコマンド形式になる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git checkout &amp;lt;パス(複数可)&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;これを実行すると、指定したファイルについて、&lt;strong&gt;インデックスが指しているブロブ&lt;/strong&gt; をオブジェクト格納領域から取り出し、ワーキングディレクトリのファイルを置き変える。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド6.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド7.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;上のスライドではインデックスが指しているブロブを取り出したが、任意のブロブを取り出すこともできる。
この場合、以下の様なコマンド形式を使う。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git checkout &amp;lt;コミット&amp;gt; &amp;lt;パス(複数可)&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;このコマンド形式だと、&lt;strong&gt;指定したコミットが指すツリー以下のブロブ&lt;/strong&gt; が取り出される。
&lt;code&gt;&amp;lt;コミット&amp;gt;&lt;/code&gt;の部分には、コミットオブジェクトのSHA1ハッシュ値、参照(i.e. ブランチかタグ)、シンボリック参照(e.g. &lt;code&gt;HEAD&lt;/code&gt;)を指定できる。(実際にはこれらが全てではないが、実用的にはこの3種。)&lt;/p&gt;

&lt;p&gt;この形式だと、ワーキングディレクトリだけでなく、取り出すブロブを指すよう &lt;strong&gt;インデックスも更新される&lt;/strong&gt; ことに注意。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths_commit/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths_commit/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths_commit/スライド3.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h1 id=&#34;headを付け替えるgit-checkout&#34;&gt;HEADを付け替えるgit checkout&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;HEAD&lt;/code&gt; を付け替える &lt;code&gt;git checkout&lt;/code&gt; は、引数に &lt;strong&gt;パスを与えない場合&lt;/strong&gt; のもの。
代わりにコミットを与える。&lt;/p&gt;

&lt;p&gt;つまりは以下の様なコマンド形式になる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git checkout &amp;lt;コミット&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;コミット&amp;gt;&lt;/code&gt;の部分には、コミットオブジェクトのSHA1ハッシュ値、参照(i.e. ブランチかタグ)、シンボリック参照(e.g. &lt;code&gt;HEAD&lt;/code&gt;)を指定できる。(実際にはこれらが全てではないが、実用的にはこの3種。)&lt;/p&gt;

&lt;p&gt;これを実行すると、&lt;strong&gt;指定したコミットが指すツリー以下の全てのブロブ&lt;/strong&gt; を指すようインデックスを更新し、それらのブロブをオブジェクト格納領域から取り出してワーキングディレクトリに配置する。&lt;/p&gt;

&lt;p&gt;この上更に&lt;code&gt;HEAD&lt;/code&gt;を付け替えるわけだが、付け替え先は&lt;code&gt;&amp;lt;コミット&amp;gt;&lt;/code&gt;の種類によって以下の三通りある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;コミット&amp;gt;&lt;/code&gt;がブランチ: &lt;code&gt;HEAD&lt;/code&gt;はそのブランチを指すよう更新される。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;コミット&amp;gt;&lt;/code&gt;がSHA1ハッシュ値: &lt;code&gt;HEAD&lt;/code&gt;はコミットを指すよう更新される。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;コミット&amp;gt;&lt;/code&gt;がタグかシンボリック参照: &lt;code&gt;HEAD&lt;/code&gt;はタグかシンボリック参照が指すコミットを指すよう更新される。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド6.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド7.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド8.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド9.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;上のスライド中のコミットをチェックアウトした例を見ると分かるが、コマンド実行前後でワーキングディレクトリからファイルが削除されることもある。
これは多分、実際にはインデックスの更新処理の前に、&lt;code&gt;HEAD&lt;/code&gt;が指すコミットに含まれるファイルをワーキングディレクトリから削除する処理があるからだと考えられる。&lt;/p&gt;

&lt;p&gt;また、上のスライドには表現していないが、コマンド実行前にワーキングディレクトリやインデックスに未コミットな変更が入っている場合、Gitはそれをコマンド実行後のワーキングディレクトリに適用しようとしてくれる。
これは例えばあるブランチで作った変更を別のブランチにコミットしたいようなときは便利だが、&lt;code&gt;checkout&lt;/code&gt;したコミットに別途変更が入っているとその適用は失敗し、コマンドがエラーになるので、普通はコマンド実行前に&lt;code&gt;git stash&lt;/code&gt;しておくのが無難。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Gitの良さが分からない？ ちょっとそこに座れ</title>
          <link>https://www.kaitoy.xyz/2016/10/06/git-vs-subversion/</link>
          <pubDate>Thu, 06 Oct 2016 00:18:05 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/10/06/git-vs-subversion/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://crapp.hatenablog.com/entry/2016/10/01/111528&#34;&gt;Gitの良さがいまだに分からない&lt;/a&gt;という人がいるようなので、Git派の一人としてSubversion(以下SVN)と比較してのGitの良さ(メリット)について語りたい。
(GitとSVNの違いについては他の人の記事に詳しいのであまり書いていない一方、勢い余ってGitのデメリットも書いた。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;本題に入る前に、冒頭にリンクを貼った記事についてひとつだけつっこんでおく。
つっこみどころは他にも沢山あるけど。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;※話の前提としてgitとSVNを採用している現場に下記のような割と違いがあるとする。&lt;/p&gt;

&lt;p&gt;git
イシューごとにブランチを切り、ローカルでコミットして、リモートブランチにpushして、GitHub・GitLab・Bitbucket経由でマージリクエスト。コードレビューの後にマージ。&lt;/p&gt;

&lt;p&gt;SVN
リモートのtrunkに個々人が直接コミット。コードレビューはあまりない。ブランチを切ることもない。&lt;/p&gt;

&lt;p&gt;このような違いが出る背景には次のものがある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gitを採用する現場は、猫も杓子もgit-flowというプラクティスに従う傾向がある
gitを採用する現場は、コードの品質もある程度管理する傾向がある
SVNは集中型でありブランチ機能などが非常に使いにくい
SVNを採用する現場はコードの品質よりも「リリースに含めるならさっさとコミット」と考える傾向がある
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;p&gt;この前提には無理がある。&lt;/p&gt;

&lt;p&gt;Gitのところに書いてあるのが、Gitというツールの枠を大きくはみだした&lt;a href=&#34;https://gist.github.com/Gab-km/3705015&#34;&gt;GitHub Flow&lt;/a&gt;というブランチ戦略+開発プロセスに当たるものであり、
それでGitを批判するのはお門違いであろうという点については、Gitの流行がGitHubの人気によるところが大きく、GitHubを使えることがGitの大きなメリットであるので、目をつむることにする。(マージリクエストを使う羽目になるデメリットなんて言いがかりでしかないとだけ言っておく。)&lt;/p&gt;

&lt;p&gt;看過できないのは、SVNを使った開発がコードレビューもブランチもないという点。&lt;/p&gt;

&lt;p&gt;どこの世界の話をしているんだろうか。
Gitが世に出る前は世間にコードレビューもブランチもあまりなかったかのような前提だが、もちろんそんなことは全くない。
60万個以上のOSSプロジェクト情報を統括する&lt;a href=&#34;https://ja.wikipedia.org/wiki/Ohloh&#34;&gt;Open HUB&lt;/a&gt;によれば、OSSプロジェクトの&lt;a href=&#34;https://www.openhub.net/repositories/compare&#34;&gt;46%がSVNを使っている&lt;/a&gt;。この中にはGitの誕生以降にSVNを使い始めたプロジェクトも多くある。270000余りのプロジェクトの大部分がブランチすら使っていないとでも?&lt;/p&gt;

&lt;p&gt;GitHub Flowと対比するために無理やりこじつけたんだろうけど、その無理のせいで議論のスタート地点からめちゃくちゃだ。&lt;/p&gt;

&lt;p&gt;まともな開発にはコードレビューもブランチも必要だ。
品質管理もリリース管理もしないなら要らないのかもしれないが、そんないい加減な開発現場を前提にSVNかGitかなんて議論しても意味がない。
高品質なソフトウェアを効率よく開発するために則りたい素晴らしい開発フローがあるとして、そのフローをSVNやGitやその他のツールないしひょっとしたらアナクロな日付フォルダの内どれがもっとも上手く実現してくれるか、というのがあるべき議論だ。
この「素晴らしい開発フロー」には一般的に品質管理と並行開発が含まれていて、それらにはコードレビューとブランチの利用が含まれている。
Git(+GitHub)がこんなにも急速にSVNに取って代わって流行ったのは、分散リポジトリの仕組みとブランチの軽量な実装によって効率的な並行開発が実現でき、またプルリクエストなどの機能によりコードレビューを含む快適なソーシャルコーディングが実現できるからだ。
逆に言えば、Gitが流行ったことが、人々が効率的な並行開発やコードレビューを開発フローに取り入れたかった証拠と言えるかもしれない。&lt;/p&gt;

&lt;h1 id=&#34;gitのメリット&#34;&gt;Gitのメリット&lt;/h1&gt;

&lt;p&gt;前置きが長くなったが、少なくともブランチとコードレビューを活用した高品質で高効率なソフトウェア開発をしたいという前提で、SVNに対するGitのメリットを挙げてみたい。&lt;/p&gt;

&lt;h4 id=&#34;1-リポジトリ構造がシンプル&#34;&gt;1. リポジトリ構造がシンプル&lt;/h4&gt;

&lt;p&gt;Gitリポジトリはすごくシンプルに作られているそうな。
確かに、&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;その構造&lt;/a&gt;を見ると、&lt;code&gt;add&lt;/code&gt;、&lt;code&gt;commit&lt;/code&gt;、&lt;code&gt;log&lt;/code&gt;、&lt;code&gt;reset&lt;/code&gt;くらいは自前ですぐに実装できそうだ。&lt;/p&gt;

&lt;p&gt;このシンプルな構造のおかげで、Gitリポジトリは壊れにくい。ここで壊れにくいとは、リポジトリ内部で不整合が起こりにくいということで、コマンドミスでコミット履歴が一部消えたりとかいうトラブルは壊れるに入らない。&lt;/p&gt;

&lt;p&gt;実のところSVNリポジトリの構造を知らないので経験的なことしか言えないが、SVNリポジトリ(というより作業ディレクトリの管理情報?)はちょくちょく変な状態になり、クリーンアップしたり、酷い時には.svn内のファイルを手動でいじったりしなければならなかった。&lt;/p&gt;

&lt;p&gt;因みに、シンプルというのはリポジトリサイズがすごく小さいということにはならず、同等の履歴を含むGitリポジトリとSVNリポジトリはだいたい同サイズなんだそうな。&lt;/p&gt;

&lt;h4 id=&#34;2-ブランチが軽い&#34;&gt;2. ブランチが軽い&lt;/h4&gt;

&lt;p&gt;Gitのブランチは単一のコミットを指す参照で、リポジトリ内ではSHA-1ハッシュ値が書かれただけのたった一つのファイルに過ぎない。
その為ブランチは一瞬で作成できるし、ディスクも圧迫しないので、じゃんじゃん作ってじゃんじゃん消せる。
さらに、ローカルリポジトリに過去の全ファイルの全バージョンが入っているという分散リポジトリの特長のおかげで、ブランチの切り替えも軽快にできる。
ローカルから必要なファイルを作業ディレクトリに展開するだけなので。&lt;/p&gt;

&lt;p&gt;一方SVNはそもそもブランチをサポートする直接的な機能がないため、ブランチはリビジョンのコピーという形で実装されている。
コピーと言ってもハードリンクみたいなものでディスク上に物理的なコピーが作られるわけではなく、軽量という点ではGitと大差ないが、集中リポジトリなせいでブランチの切り替えには差が出る。
&lt;code&gt;svn switch&lt;/code&gt;にしろ&lt;code&gt;svn checkout&lt;/code&gt;にしろネットワークの向こうのサーバとの通信が必要なので、それなりの時間がかかるし、通信が途切れると切り替えられなくなる。&lt;/p&gt;

&lt;p&gt;冒頭に貼った記事にはGitはブランチを切り替える際に&lt;code&gt;stash&lt;/code&gt;とかしないといけなくて面倒とあったが、そんなのSVNだって同じだし、&lt;code&gt;stash&lt;/code&gt;すればいいだけだし、&lt;code&gt;stash&lt;/code&gt;という機能があるだけSVNよりまし。Gitならコミットはあとから書き変えられるので、&lt;code&gt;stash&lt;/code&gt;の代わりに一時的にコミットしちゃってもいい。&lt;/p&gt;

&lt;p&gt;それも嫌なら&lt;a href=&#34;http://qiita.com/shibukk/items/80430b54ecda7f36ca44&#34;&gt;&lt;code&gt;worktree&lt;/code&gt;&lt;/a&gt;使えばよろしい。&lt;/p&gt;

&lt;h4 id=&#34;3-バージョン間の差分取得が速い&#34;&gt;3. バージョン間の差分取得が速い&lt;/h4&gt;

&lt;p&gt;Gitは全てのファイルについて全てのバージョンのコンテンツをまるまるリポジトリに持っている。
一方SVNのリポジトリにはバージョン間の変更が記録されている。
このため、あるファイルについて任意のバージョン間の差分を取るのに、Gitはシンプルにそれぞれのバージョンのファイルを取り出して比較するだけでよいが、SVNは隣り合ったバージョンでなければバージョン間の変更を足し合わせて差分を計算しなければいけない。&lt;/p&gt;

&lt;p&gt;さらに、Gitは比較するファイルをローカルリポジトリから取り出すだけでよいが、SVNはサーバへのアクセスが必要なので、差分取得はGitの方が大分速い。&lt;/p&gt;

&lt;h4 id=&#34;4-ログ取得が速い&#34;&gt;4. ログ取得が速い&lt;/h4&gt;

&lt;p&gt;Gitのコミットは常にプロジェクトの全ファイルに対するものだ。
これは変更したファイルの一部だけを対象とするコミット操作ができないという意味ではない。
Gitがひとつのコミット操作をコミットオブジェクトと呼ばれる単一のファイルに記録し、そのファイルが常にプロジェクトの全ファイルの特定のバージョンを参照しているという意味だ。(正確に言うとこのファイル自身に全ての参照が記録されているわけではないが。)&lt;/p&gt;

&lt;p&gt;このためGitのコミット履歴は実にシンプルで、ログ一覧を取得するには単にコミットをたどりながらコミットオブジェクトに書かれたログを集めればいい。&lt;/p&gt;

&lt;p&gt;一方SVNはファイル毎にバージョンを管理するので、もう少しややこしい。&lt;/p&gt;

&lt;p&gt;さらに、Gitはコミットオブジェクトをローカルリポジトリから持ってこれるがSVNは(以下略)。&lt;/p&gt;

&lt;h4 id=&#34;5-オフラインでだいたいなんでもできる&#34;&gt;5. オフラインでだいたいなんでもできる&lt;/h4&gt;

&lt;p&gt;と、ここまで書いて、Gitのいいところはオフライン作業が捗るところではないかと思い立った。&lt;/p&gt;

&lt;p&gt;実際Gitは、&lt;code&gt;clone&lt;/code&gt;、&lt;code&gt;fetch&lt;/code&gt;、&lt;code&gt;pull&lt;/code&gt;、&lt;code&gt;push&lt;/code&gt;といったあからさまな操作以外はオフラインでできる。
多くの操作にネットワーク通信コストを払わなくていい上、リモートリポジトリサーバが落ちたりネットワークが落ちたり山に籠ったりしていても作業が続けられる。&lt;/p&gt;

&lt;p&gt;ノマドに最適。&lt;/p&gt;

&lt;p&gt;一方SVNがネットワーク通信なしでできることは、…ベースバージョンとのdiffくらい?&lt;/p&gt;

&lt;h4 id=&#34;6-コミット履歴を汚さずにコードレビューできる&#34;&gt;6. コミット履歴を汚さずにコードレビューできる&lt;/h4&gt;

&lt;p&gt;私の職場はSVNを使っていて、コードを書いたら一旦コミットして、リビジョンを偉い人に通知してレビューしてもらっている。
偉い人は遠い異国にいたりするが、こちらがコミットしてしまえばSVNの機能で変更内容の取得も確認もできるという寸法だ。
リポジトリ外で変更内容をやりとりする方法とは違って、レビュー後のコミットミスや漏れが起こる余地がないのがいいが、レビューで受けた指摘は別のコミットを加えて反映したり、酷い時はリバースコミットで変更を取り消す必要がある。
こういうコミット履歴は大抵単なるノイズで、そうでなくてもリポジトリにある必要はない情報だ。&lt;/p&gt;

&lt;p&gt;一方GitならP2Pで偉い人にコミットを送れるし、レビュー後にコミットの作り直しもできるので、コミット履歴をきれいに保てる。
履歴がきれいだと変更のトレーサビリティが高まる。
変更のトレーサビリティが高いと、保守性が高くなり、低メンテナンスコストで高品質なプロダクトの開発につながる。&lt;/p&gt;

&lt;h4 id=&#34;7-ソーシャルコーディングできる&#34;&gt;7. ソーシャルコーディングできる&lt;/h4&gt;

&lt;p&gt;SaaSなら&lt;a href=&#34;https://github.com/&#34;&gt;GitHub&lt;/a&gt;や&lt;a href=&#34;https://bitbucket.org/product&#34;&gt;Bitbucket&lt;/a&gt;、オンプレミスなら&lt;a href=&#34;https://enterprise.github.com/home&#34;&gt;GitHub Enterprise&lt;/a&gt;や&lt;a href=&#34;https://about.gitlab.com/&#34;&gt;GitLab&lt;/a&gt;を利用して、ソーシャルコーディングを実現できるのはやはりGitの大きな強みだ。&lt;/p&gt;

&lt;p&gt;ソーシャルコーディングはアジャイルの先にあるDevOpsに必須とも言える要素で、今後これを実現できないIT企業やユーザ企業は開発力で他企業に差を付けられ、苦しい競争を強いられるであろう。&lt;/p&gt;

&lt;p&gt;バージョン管理ツール単体だけでなく、その上に乗っかるものまで見た場合、GitはSVNに大きく差を付けている感がある。&lt;/p&gt;

&lt;h1 id=&#34;git対svnの迷信&#34;&gt;Git対SVNの迷信&lt;/h1&gt;

&lt;p&gt;調べているうちに、Git対SVNで広く信じられている迷信があることを知ったので、ついでに書き残しておく。&lt;/p&gt;

&lt;h4 id=&#34;1-svnのマージはクソ&#34;&gt;1. SVNのマージはクソ&lt;/h4&gt;

&lt;p&gt;例えば&lt;a href=&#34;http://catcher-in-the-tech.net/806/&#34;&gt;「SVNからGitに移行して分かった、今すぐSVNを捨てるべき3つの理由」&lt;/a&gt;という記事の3つめの理由にSVNのマージ機能がクソと書いてあるが、これは最近では迷信とされている。&lt;/p&gt;

&lt;p&gt;SVNは確かにかつてブランチとマージに対するサポートが貧弱で、ブランチがどこを起点に作られたか、どのコミットをマージしたかといった情報を記憶しなかったため、ユーザがコマンドに教えてあげたり、コミットログを工夫して記録してやらなければならなかった。
しかし、&lt;a href=&#34;https://subversion.apache.org/docs/release-notes/1.5.html#merge-tracking&#34;&gt;バージョン1.5&lt;/a&gt;からこの状況が改善され始め、&lt;a href=&#34;https://subversion.apache.org/docs/release-notes/1.8.html#auto-reintegrate&#34;&gt;バージョン1.8&lt;/a&gt;で成熟したオートマージ機能により、SVNのマージも十分強力なものになった。&lt;/p&gt;

&lt;p&gt;Gitは&lt;a href=&#34;https://git-scm.com/docs/merge-strategies&#34;&gt;オクトパスマージとかマージ戦略オプションとか&lt;/a&gt;あってさらに強力そうではあるけど、そんな高機能を必要とする場面があまりなさそう。&lt;/p&gt;

&lt;h4 id=&#34;2-svnフォルダが各フォルダにあってうっとうしくてほんとクソ&#34;&gt;2. .svnフォルダが各フォルダにあってうっとうしくてほんとクソ&lt;/h4&gt;

&lt;p&gt;これも今では迷信。&lt;a href=&#34;https://subversion.apache.org/docs/release-notes/1.7.html#wc-ng&#34;&gt;バージョン1.7&lt;/a&gt;から&lt;code&gt;.svn&lt;/code&gt;はルートフォルダだけに作られるようになった。&lt;/p&gt;

&lt;h1 id=&#34;gitのデメリット&#34;&gt;Gitのデメリット&lt;/h1&gt;

&lt;p&gt;GitはSVNより全ての点で優れているというわけでもない。
以下、SVNに対するGitのデメリットを挙げてみたい。&lt;/p&gt;

&lt;h4 id=&#34;1-cloneに時間がかかる&#34;&gt;1. cloneに時間がかかる&lt;/h4&gt;

&lt;p&gt;Gitでの開発は基本的にリポジトリ全体を&lt;code&gt;clone&lt;/code&gt;することから始まる。
上記の「オフラインでだいたいなんでもできる」というのは、最初に全部ローカルに持ってきてしまうことで活きてくる利点だ。&lt;/p&gt;

&lt;p&gt;けどリポジトリが大きいとやっぱり&lt;code&gt;clone&lt;/code&gt;は時間がかかる操作になる。
例えば、&lt;a href=&#34;https://github.com/torvalds/linux&#34;&gt;Linuxカーネル&lt;/a&gt;をGitHubから&lt;code&gt;clone&lt;/code&gt;してみたら 45 分程かかった。
そんなに気軽にできる操作ではない。&lt;/p&gt;

&lt;p&gt;このデメリットに対処する方法は&lt;a href=&#34;http://japan.blogs.atlassian.com/2014/05/handle-big-repositories-git/&#34;&gt;いくつかある&lt;/a&gt;が、それをするとオフライン作業の幅を狭めることになる。&lt;/p&gt;

&lt;p&gt;SVNには&lt;code&gt;clone&lt;/code&gt;の概念がないのでこの悩みはない。&lt;/p&gt;

&lt;h4 id=&#34;2-部分cloneのサポートが貧弱&#34;&gt;2. 部分cloneのサポートが貧弱&lt;/h4&gt;

&lt;p&gt;上でも書いたが、GitはSVNのように履歴をディレクトリやファイル毎に管理しているわけではなく、コミットはプロジェクトの全ファイルを参照(i.e. 依存)しているので、特定のディレクトリ以下だけのcloneといった部分cloneの完全な実装は技術的に困難だ。&lt;/p&gt;

&lt;p&gt;Gitはリリース当初、部分cloneのサポートを全く提供せず、バージョン1.7になってそれっぽい&lt;a href=&#34;http://stackoverflow.com/questions/600079/how-do-i-clone-a-subdirectory-only-of-a-git-repository&#34;&gt;sparse checkout&lt;/a&gt;が実装されたが、あまり使い勝手が良くない。
Gitの開発陣は当初から部分cloneの実装に乗り気ではないし、上記の技術的な壁もあるので、今後この状況が大きく改善されることは恐らくないであろう。&lt;/p&gt;

&lt;p&gt;妥協になるだろうが、ソースをモジュール毎に分割して別々のリポジトリに突っ込み、必要に応じて&lt;code&gt;submodule&lt;/code&gt;か&lt;code&gt;subtree&lt;/code&gt;でつなげるのが実用的な解ではないだろうか。
それにしたって面倒だが。&lt;/p&gt;

&lt;p&gt;SVNではリポジトリの一部を&lt;code&gt;checkout&lt;/code&gt;する操作は第一級市民であり、何の制限もなく快適にできる。
この点においてはSVNパイセンの圧勝だ。&lt;/p&gt;

&lt;h4 id=&#34;3-コマンドが分かり辛い&#34;&gt;3. コマンドが分かり辛い&lt;/h4&gt;

&lt;p&gt;Gitはもともと低レベルなバージョン管理ツールとして開発されたためか、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%AA%E3%83%BC%E3%83%8A%E3%82%B9%E3%83%BB%E3%83%88%E3%83%BC%E3%83%90%E3%83%AB%E3%82%BA&#34;&gt;神&lt;/a&gt;の思考パターンが凡人のそれとはかけ離れているためか、Gitのコマンド体系は分かり辛く使いにくいというのは世界共通の認識のようだ。
このためGitの導入に当たってはどうしても高い学習コストを払わなければいけない。&lt;/p&gt;

&lt;p&gt;これは、分散バージョン管理システムというアーキテクチャが複雑だから、という理由からくるものではない。
同じ分散バージョン管理システムでも、&lt;a href=&#34;https://www.mercurial-scm.org/&#34;&gt;Mercurial&lt;/a&gt;は&lt;a href=&#34;https://blogs.atlassian.com/2012/02/mercurial-vs-git-why-mercurial/&#34;&gt;一貫したきれいな使いやすいコマンド体系をもっている&lt;/a&gt;らしい。&lt;/p&gt;

&lt;p&gt;好みの問題もあるだろうが、この点についてもSVNに分があるというのが一般的な認識だ。&lt;/p&gt;

&lt;p&gt;まあGitのGUIツールも&lt;a href=&#34;https://git-scm.com/docs/git-gui&#34;&gt;バンドルされてるやつ&lt;/a&gt;とか&lt;a href=&#34;https://tortoisegit.org/&#34;&gt;TortoiseGit&lt;/a&gt;とか&lt;a href=&#34;https://ja.atlassian.com/software/sourcetree&#34;&gt;SourceTree&lt;/a&gt;とか&lt;a href=&#34;https://www.gitkraken.com/&#34;&gt;イカ&lt;/a&gt;とか色々あるので、それで大分カバーできるだろうが。&lt;/p&gt;

&lt;h4 id=&#34;4-バイナリファイルの扱いが下手&#34;&gt;4. バイナリファイルの扱いが下手&lt;/h4&gt;

&lt;p&gt;Gitは基本的にテキストファイルを扱うよう作られていて、バイナリファイルの扱いは下手だ。
これはSVNも同じだけど、SVNの方がましらしい。&lt;/p&gt;

&lt;p&gt;例えば、バイナリファイルの同等の履歴を管理するのに、GitはSVNより少しだけ多くリポジトリ容量を食う。&lt;/p&gt;

&lt;p&gt;また、Gitはファイルのコンテンツに注目して管理するツールであるが、バイナリファイルは人間から見ると少しの変更(e.g. 画像の明度の変更)でもコンテンツが大きく変わるため、Gitが変更前のファイルと変更後のファイルを別のファイルとして扱ってしまうことがある。(最近のバージョンでは修正されているかも。)&lt;/p&gt;

&lt;p&gt;SVNはファイルそのものに注目しているので、その内容がどんなに劇的に変わっても見失うことはない。&lt;/p&gt;

&lt;p&gt;Gitでバイナリファイル、特にサイズが大きかったり頻繁に修正されるものを扱う必要があるときは、&lt;a href=&#34;https://git-annex.branchable.com/&#34;&gt;git-annex&lt;/a&gt;や&lt;a href=&#34;https://git-lfs.github.com/&#34;&gt;Git Large File Storage (LFS)&lt;/a&gt;の利用を検討すべし。&lt;/p&gt;

&lt;h4 id=&#34;5-アクセスコントロール機能がない&#34;&gt;5. アクセスコントロール機能がない&lt;/h4&gt;

&lt;p&gt;Git自身にはアクセスコントロール機能が全く実装されていない(多分)。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;clone&lt;/code&gt;するときなんかは、HTTPやSSHやTLSの力を借りてリポジトリ単位でのユーザ認証ができたり、&lt;code&gt;push&lt;/code&gt;するときにはファイルシステムのアクセスコントロールの力を借りて特定のファイルの変更を防いだりはできるが、もっと細かい制御をしたい場合は&lt;a href=&#34;https://github.com/sitaramc/gitolite&#34;&gt;Gitolite&lt;/a&gt;の力を借りる必要がある。&lt;/p&gt;

&lt;p&gt;借りてばっかだ。&lt;/p&gt;

&lt;p&gt;一方SVNは自前で&lt;a href=&#34;http://svnbook.red-bean.com/en/1.8/svn.serverconfig.pathbasedauthz.html&#34;&gt;Path-Based Authorization&lt;/a&gt;という機能を持っていて、ユーザ認証とディレクトリまたはファイル単位での読み書き制限ができる。&lt;/p&gt;

&lt;h4 id=&#34;6-ファイル単位の履歴を保持しない&#34;&gt;6. ファイル単位の履歴を保持しない&lt;/h4&gt;

&lt;p&gt;上にも書いたが、GitはSVNのようにファイル単位でバージョン管理をしているわけではないし、また、ファイルそのものではなくそのコンテンツに注目してバージョン管理する。この特徴のせいで、Gitはたまにファイルの行方を見失うことがある。&lt;/p&gt;

&lt;p&gt;上記バイナリファイルの問題もそうだし、テキストファイルでもリネームとコンテンツ変更を同時にやると&lt;code&gt;git log --follow&lt;/code&gt;で&lt;a href=&#34;https://svnvsgit.com/#losing-history-after-rename-in-Git&#34;&gt;ファイルの履歴が追えなくなる&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;SVNはリネームにちゃんと&lt;code&gt;svn mv&lt;/code&gt;を使っている限りファイルを見失うことはない。&lt;/p&gt;

&lt;p&gt;ただこれは実際、Gitのデメリットと言うよりは、GitとSVNの思想の違いと言った方がいいかもしれない。
&lt;code&gt;git log --follow&lt;/code&gt;は単に&lt;a href=&#34;http://stackoverflow.com/questions/5743739/how-to-really-show-logs-of-renamed-files-with-git&#34;&gt;SVNに慣れ親しんだGit初心者のための機能&lt;/a&gt;で、真のGit使いは特定のファイルの履歴を追うということを必要としない。&lt;/p&gt;

&lt;p&gt;ファイルの履歴を見たい煩悩に駆られたら、心を静め、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%AA%E3%83%BC%E3%83%8A%E3%82%B9%E3%83%BB%E3%83%88%E3%83%BC%E3%83%90%E3%83%AB%E3%82%BA&#34;&gt;神&lt;/a&gt;に祈りを捧げ、Gitのソースコードを写経し、Gitコマンドを108回たたいて悟りを開くべし。&lt;/p&gt;

&lt;h1 id=&#34;まとめ&#34;&gt;まとめ&lt;/h1&gt;

&lt;p&gt;Git派としてGit押しの記事を書こうと思っていたが、意外とデメリットもたくさん見えてきてしまった。
結局、GitとSVNどちらが単純に優れているということはないので、プロジェクトの構成やワークフローなどの要件を鑑みて使い分ければよしということか。&lt;/p&gt;

&lt;h1 id=&#34;参考資料&#34;&gt;参考資料&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873114408/&#34;&gt;蝙蝠本&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://git.wiki.kernel.org/index.php/GitSvnComparsion&#34;&gt;GitSvnComparison&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://svnvsgit.com/&#34;&gt;Subversion vs. Git: Myths and Facts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Pcap4J on Nano Server on Hyper-V Containers on Windows 10 on VMware Playerにトライ</title>
          <link>https://www.kaitoy.xyz/2016/09/15/pcap4j-on-hyper-v-container-on-win10/</link>
          <pubDate>Thu, 15 Sep 2016 13:56:35 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/09/15/pcap4j-on-hyper-v-container-on-win10/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;Pcap4J&lt;/a&gt;が動くHyper-VコンテナをWindows 10上でビルドしようとしたけど3合目あたりで息絶えた話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;hyper-v-containersとは&#34;&gt;Hyper-V Containersとは&lt;/h2&gt;

&lt;p&gt;Hyper-V Containersは、MicrosoftによるWindowsネイティブなコンテナ技術である&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/about/about_overview&#34;&gt;Windows Containers&lt;/a&gt;の一種で、これによるコンテナは、同じくWindows Containersの一種であるWindows Server Containersのものに比べて、より厳密に隔離されている分、起動コストが高い。&lt;/p&gt;

&lt;p&gt;実体は&lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt;そのもので、コンテナイメージは&lt;a href=&#34;https://hub.docker.com/&#34;&gt;Docker Hub&lt;/a&gt;からpullできるし、コンテナの操作や管理はdockerコマンドでやる。(昔はコンテナ操作用PowerShellコマンドレットもあったが、不評だったので廃止したようだ。)
&lt;a href=&#34;https://github.com/docker/docker&#34;&gt;ソース&lt;/a&gt;もLinuxとWindowsで一本化されている。&lt;/p&gt;

&lt;p&gt;Windows 10の&lt;a href=&#34;https://blogs.windows.com/japan/2016/08/03/how-to-get-the-windows-10-anniversary-update/#eFCYhK68sDp1V0F7.97&#34;&gt;Anniversary Update&lt;/a&gt;で正式にリリースされたが、なんだかあまり注目されていない気がする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2016/07/31/docker-for-windows/#docker-for-windows%E3%81%A8%E3%81%AF&#34;&gt;Docker for Windows&lt;/a&gt;とは全く別物なので注意。&lt;/p&gt;

&lt;h2 id=&#34;hyper-v-containersのインストール-on-vmware-player&#34;&gt;Hyper-V Containersのインストール (on VMware Player)&lt;/h2&gt;

&lt;p&gt;自前のPCが5年前に買った&lt;a href=&#34;https://dynabook.com/&#34;&gt;dynabook&lt;/a&gt;でWindows 10をサポートしていないので、VMware PlayerのVM上のWindows 10にHyper-V Containersをインストールしてみる。&lt;/p&gt;

&lt;p&gt;VMは、Windows 7に入れたVMware Workstation 11.1.0 build-2496824に付属の VMware Player 7.1.0 build-2496824で作ったもの。
VMのバージョンは11.0。
2CPUでメモリは2.5GB。
ネットワークインターフェースはNAT。
このVMを、&lt;a href=&#34;https://www.kaitoy.xyz/2016/07/31/docker-for-windows/#vmware-player%E3%81%AEvm%E3%81%A7hyper-v%E3%82%92%E4%BD%BF%E3%81%86%E3%81%9F%E3%82%81%E3%81%AE%E8%A8%AD%E5%AE%9A&#34;&gt;Hyper-Vが使えるように設定しておく&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://ascii.jp/elem/000/001/216/1216220/&#34;&gt;この記事&lt;/a&gt;にしたがい、Windows 10の評価版をダウンロード。
今公開されている評価版はAnniversary Update適用済みのバージョン1607で、Hyper-V Containersをサポートしている。&lt;/p&gt;

&lt;p&gt;これをさっき作ったVMにインストール。&lt;/p&gt;

&lt;p&gt;Windows 10を起動し、以下、&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/quick_start/quick_start_windows_10&#34;&gt;Windows Containers on Windows 10&lt;/a&gt;に従って進める。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;containers機能有効化&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.thewindowsclub.com/how-to-open-an-elevated-powershell-prompt-in-windows-10&#34;&gt;PowerShellプロンプトを管理者権限でひらき&lt;/a&gt;、以下のコマンドで&lt;code&gt;containers&lt;/code&gt;機能を有効化。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;Enable-WindowsOptionalFeature -Online -FeatureName containers -All
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1分程度経つと再起動を促されるので再起動。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Hyper-V機能有効化&lt;/p&gt;

&lt;p&gt;再度PowerShellプロンプトを管理者権限で開いて、以下のコマンドでHyper-Vを有効化。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V -All
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1分程度経つと再起動を促されるので再起動。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;OpLocks無効化&lt;/p&gt;

&lt;p&gt;現在のHyper-Vコンテナは、安定性を上げるためにOpLocksという機能を無効にすべきらしい。
再度PowerShellプロンプトを管理者権限で開いて、以下のコマンドを実行する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;Set-ItemProperty -Path &#39;HKLM:SOFTWARE\Microsoft\Windows NT\CurrentVersion\Virtualization\Containers&#39; -Name VSmbDisableOplocks -Type DWord -Value 1 -Force
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dockerインストール&lt;/p&gt;

&lt;p&gt;同じPowerShellプロンプトで以下のコマンドを実行してDocker(EngineとClient)のアーカイブをダウンロード。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;Invoke-WebRequest &amp;quot;https://master.dockerproject.org/windows/amd64/docker-1.13.0-dev.zip&amp;quot; -OutFile &amp;quot;$env:TEMP\docker-1.13.0-dev.zip&amp;quot; -UseBasicParsing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ダウンロードしたアーカイブを解凍。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;Expand-Archive -Path &amp;quot;$env:TEMP\docker-1.13.0-dev.zip&amp;quot; -DestinationPath $env:ProgramFiles
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここまででDockerが&lt;code&gt;C:\Program Files\docker\&lt;/code&gt;に入るので、このパスを環境変数&lt;code&gt;PATH&lt;/code&gt;に追加。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;PATH&lt;/code&gt;の変更を反映させるために再度PowerShellプロンプトを管理者権限で開いて、以下のコマンドでDockerデーモンをサービスに登録。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;dockerd --register-service
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dockerサービスを起動。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;Start-Service Docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(Dockerサービスは自動起動に設定されているので、OS再起動時は上記&lt;code&gt;Start-Service&lt;/code&gt;は不要。)&lt;/p&gt;

&lt;p&gt;これでDockerが使えるようになった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;docker version
Client:
 Version:      1.13.0-dev
 API version:  1.25
 Go version:   go1.7.1
 Git commit:   130db0a
 Built:        Sat Sep 10 13:25:48 2016
 OS/Arch:      windows/amd64


Server:
 Version:      1.13.0-dev
 API version:  1.25
 Go version:   go1.7.1
 Git commit:   130db0a
 Built:        Sat Sep 10 13:25:48 2016
 OS/Arch:      windows/amd64
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;コンテナイメージダウンロード&lt;/p&gt;

&lt;p&gt;どうもDockerコマンドの実行には管理者権限が必要なようなので、このまま管理者権限のPowerShellプロンプトで続ける。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker pull&lt;/code&gt;でNano Serverのコンテナイメージをダウンロード。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;docker pull microsoft/nanoserver
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;docker images&lt;/code&gt;で確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;docker images
REPOSITORY             TAG                 IMAGE ID            CREATED             SIZE
microsoft/nanoserver   latest              3a703c6e97a2        12 weeks ago        970 MB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;試しにコンテナ起動。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;PS C:\Windows\system32&amp;gt;docker run -it microsoft/nanoserver cmd&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;起動はかなり遅い。1分近くかかった。ともあれちゃんと起動した。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/pcap4j-on-hyper-v-container-on-win10/test_container.png&#34; alt=&#34;test_container.png&#34; /&gt;
&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;pcap4jコンテナのビルド&#34;&gt;Pcap4Jコンテナのビルド&lt;/h2&gt;

&lt;p&gt;Pcap4Jコンテナを、&lt;code&gt;docker build&lt;/code&gt;でビルドしてみる。
Dockerfileはとりあえず&lt;a href=&#34;https://www.kaitoy.xyz/2016/07/11/windows_containers_on_tp5/#pcap4j%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A%E3%82%A4%E3%83%A1%E3%83%BC%E3%82%B8%E3%81%AE%E3%83%93%E3%83%AB%E3%83%89&#34;&gt;以前のもの&lt;/a&gt;をちょっと書き変えただけのものを試す。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-dockerfile&#34;&gt;# escape=`

#
# Dockerfile for Pcap4J on Windows Nano Server
#

FROM microsoft/nanoserver
MAINTAINER Kaito Yamada &amp;lt;kaitoy@pcap4j.org&amp;gt;

# Install Chocolatey.
RUN mkdir C:\pcap4j
WORKDIR C:\\pcap4j
ADD https://chocolatey.org/install.ps1 install.ps1
RUN powershell .\install.ps1

# Install dependencies.
RUN choco install -y nmap jdk7 &amp;amp;&amp;amp; `
    choco install -y maven -version 3.2.5

# Build Pcap4J.
RUN powershell -Command Invoke-WebRequest https://github.com/kaitoy/pcap4j/archive/v1.zip -OutFile pcap4j.zip &amp;amp;&amp;amp; `
    powershell -Command Expand-Archive -Path pcap4j.zip -DestinationPath .
WORKDIR pcap4j-1
RUN powershell -Command &amp;quot;mvn -P distribution-assembly install 2&amp;gt;&amp;amp;1 | Add-Content -Path build.log -PassThru&amp;quot;

# Collect libraries.
RUN mkdir bin &amp;amp;&amp;amp; `
    cd pcap4j-packetfactory-static &amp;amp;&amp;amp; `
    mvn -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeScope=compile dependency:copy-dependencies &amp;amp;&amp;amp; `
    mvn -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeGroupIds=ch.qos.logback dependency:copy-dependencies &amp;amp;&amp;amp; `
    cd ../pcap4j-distribution &amp;amp;&amp;amp; `
    mvn -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeArtifactIds=pcap4j-packetfactory-static,pcap4j-sample dependency:copy-dependencies

# Generate sample script. (C:\pcap4j\pcap4j-1\bin\capture.bat)
RUN echo @echo off &amp;gt; bin\capture.bat &amp;amp;&amp;amp; `
    echo &amp;quot;%JAVA_HOME%\bin\java&amp;quot; -cp C:\pcap4j\pcap4j-1\bin\pcap4j-core.jar;C:\pcap4j\pcap4j-1\bin\pcap4j-packetfactory-static.jar;C:\pcap4j\pcap4j-1\bin\pcap4j-sample.jar;C:\pcap4j\pcap4j-1\bin\jna.jar;C:\pcap4j\pcap4j-1\bin\slf4j-api.jar;C:\pcap4j\pcap4j-1\bin\logback-classic.jar;C:\pcap4j\pcap4j-1\bin\logback-core.jar org.pcap4j.sample.GetNextPacketEx &amp;gt;&amp;gt; bin\capture.bat
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#/escape&#34;&gt;escapeディレクティブ&lt;/a&gt;が使えるようになっていたので使うようにしている。
(というか以前Windows Server 2016 TP5で試した時はescapeディレクティブをDockerfileの先頭に書かなかったのがだめだったってだけかもしれない。)
&lt;code&gt;WORKDIR&lt;/code&gt;のパスの区切りにはescapeディレクティブは利かない変な仕様。&lt;/p&gt;

&lt;h4 id=&#34;nano-serverでsystem-net-webclient使えない問題&#34;&gt;Nano ServerでSystem.Net.WebClient使えない問題&lt;/h4&gt;

&lt;p&gt;このDockerfileでビルドしたら、&lt;a href=&#34;https://chocolatey.org/&#34;&gt;Chocolatey&lt;/a&gt;のダウンロード・インストールスクリプトを実行する&lt;code&gt;RUN powershell .\install.ps1&lt;/code&gt;のステップで&lt;code&gt;System.Net.WebClient&lt;/code&gt;が見つからないというエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;new-object : Cannot find type [System.Net.WebClient]: verify that the assembly
containing this type is loaded.
At C:\pcap4j\install.ps1:84 char:17
+   $downloader = new-object System.Net.WebClient
+                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : InvalidType: (:) [New-Object], PSArgumentExcepti
   on
    + FullyQualifiedErrorId : TypeNotFound,Microsoft.PowerShell.Commands.NewOb
   jectCommand
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nano Serverに入っているPowerShellは&lt;a href=&#34;https://technet.microsoft.com/en-us/windows-server-docs/compute/nano-server/powershell-on-nano-server&#34;&gt;Core Editionなる機能限定版&lt;/a&gt;で、System.Net.WebClientだけでなく、&lt;a href=&#34;http://serverfault.com/questions/788949/download-a-file-with-powershell-on-nano-server&#34;&gt;WebアクセスのためのAPIがいろいろ欠けているもよう&lt;/a&gt;。&lt;/p&gt;

&lt;h4 id=&#34;hyper-v-containersでserver-core使えない問題&#34;&gt;Hyper-V ContainersでServer Core使えない問題&lt;/h4&gt;

&lt;p&gt;Nano Serverめんどくさそうなので、Server Coreをpullする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Windows\system32&amp;gt;docker pull microsoft/windowsservercore
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dockerfileの&lt;code&gt;FROM&lt;/code&gt;を&lt;code&gt;microsoft/windowsservercore&lt;/code&gt;に書き変えてビルドしたら、最初の&lt;code&gt;RUN&lt;/code&gt;で以下のエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;container 4bc8d8d38993426fa7a3c76e4aabbe6a229cbd025754723ff396aec04ffbfa1d encountered an error during Start failed in Win32: The operating system of the container does not match the operating system of the host. (0xc0370101)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;調べたら、Hyper-V Containersはまだ&lt;a href=&#34;https://social.msdn.microsoft.com/Forums/en-US/9eea93ac-18de-4953-bc7c-efd76a155526/are-microsoftwindowsservercore-containers-working-on-windows-10?forum=windowscontainers&#34;&gt;Nano Serverしかサポートしていない&lt;/a&gt;ようだ。&lt;/p&gt;

&lt;h4 id=&#34;unzip難しい問題&#34;&gt;unzip難しい問題&lt;/h4&gt;

&lt;p&gt;Chocolateyのダウンロード・インストールスクリプトを実行するのはあきらめて、&lt;a href=&#34;https://chocolatey.org/install#download-powershell-method&#34;&gt;アーカイブを自分でダウンロードする方法&lt;/a&gt;を試す。&lt;/p&gt;

&lt;p&gt;これは&lt;code&gt;https://chocolatey.org/api/v2/package/chocolatey/&lt;/code&gt;というWeb APIをたたいてアーカイブをダウンロードする方法だけど、このURLを&lt;code&gt;ADD&lt;/code&gt;に渡してもうまくいかなかったので、このWeb APIが最終的に呼ぶ&lt;code&gt;https://packages.chocolatey.org/chocolatey.0.10.0.nupkg&lt;/code&gt;を&lt;code&gt;ADD&lt;/code&gt;するようにした。
これでダウンロードできる&lt;code&gt;chocolatey.0.10.0.nupkg&lt;/code&gt;はzipファイルで、unzipするとインストールスクリプトが出てくる。&lt;/p&gt;

&lt;p&gt;しかしこのunzipが曲者で、&lt;a href=&#34;https://www.kaitoy.xyz/2016/09/12/unzip-on-nanoserver/&#34;&gt;妙に苦労した話&lt;/a&gt;を最近書いた。&lt;/p&gt;

&lt;p&gt;で、苦労して取り出したインストールスクリプトを実行したら、エラーがわんさと出ただけだった。
そんなこったろうと思ってはいたが。&lt;/p&gt;

&lt;p&gt;どうせChocolateyをインストールできても、パッケージのインストールスクリプトがまた動かないんだろうから、もうChocolateyはあきらめる。&lt;/p&gt;

&lt;h4 id=&#34;wow64サポートしてない問題&#34;&gt;WoW64サポートしてない問題&lt;/h4&gt;

&lt;p&gt;Chocolateyを使わないようにDockerfileの前半を以下の様に書き変えた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-dockerfile&#34;&gt;(snip)

FROM michaeltlombardi/nanoserveropenjdk
MAINTAINER Kaito Yamada &amp;lt;kaitoy@pcap4j.org&amp;gt;

RUN mkdir C:\pcap4j
WORKDIR C:\\pcap4j

# Install Maven
ADD http://archive.apache.org/dist/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.zip maven.zip
RUN jar xf maven.zip
RUN powershell -command $env:path += &#39;;C:\pcap4j\apache-maven-3.3.9\bin&#39;; setx PATH $env:path /M

# Install Npcap
ADD https://github.com/nmap/npcap/releases/download/v0.08-r7/npcap-0.08-r7.exe npcap.exe
RUN npcap.exe /S

# Build Pcap4J.

(snip)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(因みにこの時点で、&lt;code&gt;PATH&lt;/code&gt;を設定するのに&lt;code&gt;GetEnvironmentVariable&lt;/code&gt;と&lt;code&gt;SetEnvironmentVariable&lt;/code&gt;がうまく使えない問題を乗り越えている。&lt;code&gt;Cannot find an overload for &amp;quot;GetEnvironmentVariable&amp;quot; and the argument count: &amp;quot;2&amp;quot;.&lt;/code&gt;というエラーが出て、PowerShell Desktop Editionのものと仕様がちょっと違うようだったので、&lt;code&gt;GetEnvironmentVariable&lt;/code&gt;も&lt;code&gt;SetEnvironmentVariable&lt;/code&gt;も使わないようにした。)&lt;/p&gt;

&lt;p&gt;このDockerfileでビルドしたら、&lt;code&gt;RUN npcap.exe /S&lt;/code&gt;で以下のエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;The subsystem needed to support the image type is not present.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このsubsystemというのはどうも&lt;a href=&#34;https://ja.wikipedia.org/wiki/WOW64&#34;&gt;WoW64&lt;/a&gt;を指しているようで、&lt;a href=&#34;https://blogs.technet.microsoft.com/windowsserver/2016/02/10/exploring-nano-server-for-windows-server-2016/&#34;&gt;Nano ServerがWoW64をサポートしていない&lt;/a&gt;のにnpcap.exeが32bitバイナリであることが問題のようであった。&lt;/p&gt;

&lt;p&gt;ついでに&lt;a href=&#34;https://ja.wikipedia.org/wiki/Microsoft_Windows_Installer&#34;&gt;MSI&lt;/a&gt;もサポートされていないことがわかった。大丈夫かこれ。&lt;/p&gt;

&lt;h4 id=&#34;nano-serverパッケージプロバイダバグってる問題&#34;&gt;Nano Serverパッケージプロバイダバグってる問題&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://technet.microsoft.com/en-us/windows-server-docs/compute/nano-server/getting-started-with-nano-server#a-namebkmkonlineainstalling-roles-and-features-online&#34;&gt;Nano Serverにもロールや機能の追加ができる&lt;/a&gt;らしいので、ひょっとしてこれで何か改善できないかと思って試した。&lt;/p&gt;

&lt;p&gt;Nano Serverへのロール・機能の追加は、Windowsのパッケージマネジメントシステムである&lt;a href=&#34;https://github.com/OneGet/oneget&#34;&gt;PackageManagement (a.k.a. OneGet)&lt;/a&gt;を使ってやる。PowerShellで&lt;code&gt;Install-PackageProvider NanoServerPackage&lt;/code&gt;と&lt;code&gt;Import-PackageProvider NanoServerPackage&lt;/code&gt;を実行するとNano Serverのパッケージプロバイダが使えるようになり、&lt;code&gt;Find-NanoServerPackage&lt;/code&gt;で利用できるパッケージの一覧が見れる。&lt;/p&gt;

&lt;p&gt;はずなんだけど、&lt;code&gt;Find-NanoServerPackage&lt;/code&gt;でエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;C:\pcap4j&amp;gt;powershell -command Find-NanoServerPackage
DownloadFile : Save-HTTPItem: Bits Transfer failed. Job State:  ExitCode = 255
At C:\Program Files\WindowsPowerShell\Modules\NanoServerPackage\0.1.1.0\NanoServerPackage.psm1:1294 char:9
+         DownloadFile -downloadURL $fullUrl `
+         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : InvalidOperation: (https://nanoser...ServerIndex.txt:String) [DownloadFile], RuntimeException
    + FullyQualifiedErrorId : FailedToDownload,DownloadFile

Get-Content : Cannot find drive. A drive with the name &#39;CleanUp&#39; does not exist.
At C:\Program Files\WindowsPowerShell\Modules\NanoServerPackage\0.1.1.0\NanoServerPackage.psm1:674 char:26
+     $searchFileContent = Get-Content $searchFile
+                          ~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : ObjectNotFound: (CleanUp:String) [Get-Content], DriveNotFoundException
    + FullyQualifiedErrorId : DriveNotFound,Microsoft.PowerShell.Commands.GetContentCommand

Get-Content : Cannot find path
&#39;C:\Users\ContainerAdministrator\AppData\Local\NanoServerPackageProvider\searchNanoPackageIndex.txt&#39; because it does not exist.
At C:\Program Files\WindowsPowerShell\Modules\NanoServerPackage\0.1.1.0\NanoServerPackage.psm1:674 char:26
+     $searchFileContent = Get-Content $searchFile
+                          ~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : ObjectNotFound: (C:\Users\Contai...ackageIndex.txt:String) [Get-Content], ItemNotFoundException
    + FullyQualifiedErrorId : PathNotFound,Microsoft.PowerShell.Commands.GetContentCommand
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/OneGet/NanoServerPackage/issues/4&#34;&gt;NanoServerPackageのIssues&lt;/a&gt;にこのエラーが登録されていた。1か月放置されてる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;パトラッシュ、僕はもう疲れたよ。&lt;/p&gt;
</description>
        </item>
      
    

  </channel>
</rss>
