<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>To Be Decided </title>
    <link>https://www.kaitoy.xyz/</link>
    <language>en-us</language>
    <author>Kaito Yamada</author>
    <rights>(C) 2018</rights>
    <updated>2018-02-06 00:37:11 &#43;0900 JST</updated>

    
      
        <item>
          <title>CourseraのDeep Learning SpecializationのConvolutional Neural Networksコースを修了した</title>
          <link>https://www.kaitoy.xyz/2018/02/06/coursera-deep-learning-convolutional-neural-networks/</link>
          <pubDate>Tue, 06 Feb 2018 00:37:11 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/02/06/coursera-deep-learning-convolutional-neural-networks/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/01/16/coursera-deep-learning-ml-strategy/&#34;&gt;CourseraのDeep Learning SpecializationのStructuring Machine Learning Projectsコースを修了した&lt;/a&gt;のに続き、&lt;a href=&#34;https://www.coursera.org/learn/convolutional-neural-networks&#34;&gt;Convolutional Neural Networksコース&lt;/a&gt;を修了した。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;このコースは、CNNの原理、代表的なアーキテクチャ、応用などについて学べる4週間のコース。
動画は今のところ全部英語。
プログラミング課題は初のKeras。&lt;/p&gt;

&lt;p&gt;このコースは結構難しくて、特に3週目と4週目は理解に苦しんだ。
というか理解しきれなかったような。
けどNST面白かった。&lt;/p&gt;

&lt;p&gt;2018/1/16に始めて、2/6に完了。
22日間かかった。
修了したらまた&lt;a href=&#34;https://www.coursera.org/account/accomplishments/certificate/MVNK5ZA5CDKA&#34;&gt;Certifacate&lt;/a&gt;もらえた。&lt;/p&gt;

&lt;p&gt;以下、4週分の内容をメモ程度に書いておく。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;p&gt;畳み込みニューラルネットワーク(CNN: Convolutional neural network)の基本。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;畳み込み計算&lt;/p&gt;

&lt;p&gt;画像認識でよく使われるNNのアーキテクチャ。&lt;/p&gt;

&lt;p&gt;低層ではエッジを検出し、層が進むにつれて複雑な特徴を学習する。&lt;/p&gt;

&lt;p&gt;画像を特定の行列(普通は奇数の正方行列。3×3が多い。)で畳み込むことで、特定の方向のエッジを検出できる。
この行列をフィルタ(filter)という。カーネルと呼ばれることもある。
例えば縦なら以下。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[[1, 0, -1],
 [1, 0, -1],
 [1, 0, -1]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;縦でもいろいろフィルタはあって、以下はSobelフィルタというもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[[1, 0, -1],
 [2, 0, -2],
 [1, 0, -1]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下はScharrフィルタ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[[ 3, 0,  -3],
 [10, 0, -10],
 [ 3, 0,  -3]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;縦のフィルタを90度回転すると横のフィルタになる。&lt;/p&gt;

&lt;p&gt;深層学習では、フィルタもパラメータとして学習させる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;パディング(Padding)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;n×n&lt;/code&gt;の行列を&lt;code&gt;f×f&lt;/code&gt;のフィルタで畳み込むと&lt;code&gt;n-f+1×n-f+1&lt;/code&gt;の行列になる。
つまり畳み込めば畳み込むほど画像が小さくなってしまう。
また、画像の端のほうはフィルタにかかる割合が小さいので、情報量が小さくなってしまう。
これらを解決するテクニックがパディング(Padding)。
行列の周囲を0でパディングして、サイズを大きくしてから畳み込む。
パディングがないのをValidな畳み込み、出力が入力と同じサイズになるようにパディングするのをSameな畳み込みという。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Strided畳み込み&lt;/p&gt;

&lt;p&gt;畳み込むときにフィルタをずらす幅を1より大きくする。
パディングサイズがpでストライドがsのとき、&lt;code&gt;n×n&lt;/code&gt;の行列を&lt;code&gt;f×f&lt;/code&gt;のフィルタで畳み込むと&lt;code&gt;(n+2p-f)/s+1×(n+2p-f)/s+1&lt;/code&gt;の行列になる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;3次元(カラー画像)の畳み込み&lt;/p&gt;

&lt;p&gt;カラー画像は3次元の行列、つまり&lt;code&gt;n×n×c&lt;/code&gt;の行列で、それを畳み込むのは&lt;code&gt;f×f×c&lt;/code&gt;のフィルタで、出力は&lt;code&gt;n-f+1×n-f+1&lt;/code&gt;の行列になる。
チャネルごとにフィルタを設定して、色ごとにエッジ検出できる。
フィルタごとの出力は全部スタックして、最終的な出力は3次元になる。&lt;/p&gt;

&lt;p&gt;畳み込み層はフィルタの要素数がパラメータ数になる。
入力画像の大きさに依存しないので、パラメータ数が少なくて済み、過学習しにくい。&lt;/p&gt;

&lt;p&gt;入力を複数の畳み込み層に通したら、最終的に3次元の出力をなべてベクトルにして、後ろの層に渡す。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プーリング層(Pooling layer)&lt;/p&gt;

&lt;p&gt;計算量を減らすため、また特徴の抽出のために、畳み込み層のあとに使われる層。
基本Max poolingが使われるけど、Average poolingというのもある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Max pooling: フィルタをかけた部分を畳み込む代わりに、最大値を出力とする。大きな値が特徴が大きく出ているところだから、特徴を凝縮するイメージだけど、経験的にこれで上手くいくことが分かっているだけで、なぜ上手くいくかは判明していない。この層はパラメータを持たない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Average pooling: フィルタをかけた部分を畳み込む代わりに、平均を出力とする。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;プーリング層のフィルタは大抵、サイズが&lt;code&gt;2×2&lt;/code&gt;でパディングが0でストライドは2。&lt;/p&gt;

&lt;p&gt;普通、畳み込み層とプーリング層とセットで1層と数える。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;全結合層(Fully connected layer)&lt;/p&gt;

&lt;p&gt;全ノードがメッシュ状につながった普通の層。
畳み込み層とプーリング層のセットがいくつかあって、その出力をベクトルになべて、全結合層につなぐ。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;一般的なCNN&lt;/p&gt;

&lt;p&gt;畳み込み層は、普通nhとnwを縮め、ncを増やす。
また、全体として、層が浅くなるほど出力が減るのが多い。&lt;/p&gt;

&lt;p&gt;CNNはハイパーパラメータが多すぎるので、アーキテクチャは自分で考えるんではなく、論文呼んで自分の問題に合いそうなのを探すべし。&lt;/p&gt;

&lt;p&gt;畳み込み層は全結合層に比べてパラメータ数がかなり少なくて済むのがいいところ。
これはパラメーター共有(Parameter sharing)という、画像のある個所で上手く動いたフィルタ(e.g. 縦エッジ検出器)は、その画像の他の箇所でも上手く働くという考え方がベース。&lt;/p&gt;

&lt;p&gt;また、層間の接続がまばらなのもパラメータを減らす要因。
つまり出力のあるピクセルは、入力のうちフィルタ分のサイズのピクセルとしか関連していない。&lt;/p&gt;

&lt;p&gt;CNNは空間変化の不変性(Translation invariance)に強い。
つまり画像の中の物体の位置が変わってもよく検出できる。
これは同じフィルタを画像全体に適用するから。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;p&gt;CNNの順伝播をNumPyで実装。&lt;/p&gt;

&lt;p&gt;CNNによる画像の分類をTensorFlowで実装。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ケーススタディ&lt;/p&gt;

&lt;p&gt;畳み込み層とかプーリング層をどう組み合わせるといいかは、事例を見ていくことで雰囲気をつかめる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;古いやつ&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;LeNet-5&lt;/p&gt;

&lt;p&gt;1980年代にできたふるいやつ。
モノクロ画像(32×32)の手書き数字認識。&lt;/p&gt;

&lt;p&gt;当時はソフトマックスもReLUもなかった。
けど、畳み込み層とプーリング層のセットを繰り返して入力をチャネル方向に引き伸ばし、全結合層に流し込むアーキテクチャは、モダンなCNNにも通じる。&lt;/p&gt;

&lt;p&gt;5層(内2層が全結合層)の浅いネットワークで、比較的パラメータが少なく、6万個くらい。
モダンなのだとこの1000倍くらいあるのが普通。&lt;/p&gt;

&lt;p&gt;LeNet-5は、チャネルごとに違うフィルタを使っているが、今日では普通同じのを使う。&lt;/p&gt;

&lt;p&gt;また、プーリング層のあとに活性化関数(シグモイド)かけてるのも特殊。
(モダンなアーキテクチャではプーリング層の前にかける?)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;AlexNet&lt;/p&gt;

&lt;p&gt;227×227×3のカラー画像
8層(内3層が全結合層)でパラメータは6千万個くらい。
活性化関数にReLU。&lt;/p&gt;

&lt;p&gt;Local Response Normalizationという正規化層がある。
昨今ではあまり使われない。&lt;/p&gt;

&lt;p&gt;論文が比較的読みやすい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;VGG-16&lt;/p&gt;

&lt;p&gt;2014年に発表。&lt;/p&gt;

&lt;p&gt;各層に同じフィルタを使い、フィルタ数も線形増加させるシンプルなアーキテクチャ。
16層(内2層が全結合層)で、1億3800万個のパラメータ。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;モダンなやつ&lt;/p&gt;

&lt;p&gt;理論的にはネットワークを深くすると精度が高くなるけど、現実的にそうはいかない。
深いネットワークは勾配消失や勾配爆発で訓練しにくいので。
モダンなアーキテクチャはこの問題に対応。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ResNet(Residual Network)&lt;/p&gt;

&lt;p&gt;残差ブロック(Residual block)を持つ。
このブロックでは、浅い層からの出力を深い層のReLUの入力に足し合わせる。
この深い層からの依存はショートカット(short cut)とかskip connectionとか呼ばれる。&lt;/p&gt;

&lt;p&gt;ショートカットのおかげで深い層の学習が効率的になり、層を152まで深くできた。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Network in Network&lt;/p&gt;

&lt;p&gt;畳み込み層に1×1のフィルタを使う。
1×1畳み込み(one by one convolution)、またはNetwork in Networkと呼ばれる。&lt;/p&gt;

&lt;p&gt;これを使うと、入力のhとwを変えずに、チャネル数を減らして計算量を減らしたり、非線形性を追加することができる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Inception Network (GoogleNet)&lt;/p&gt;

&lt;p&gt;フィルタのサイズや畳み込みかプーリングかを考えるのが難しいので、1層内で複数のフィルタサイズで畳み込みやプーリングして、スタックしたものを出力する手法がある。
これをする部分をInception moduleという。
計算コストが大きくなるので、最初に1×1畳み込みで圧縮してからその後の畳み込みをする。
1×1畳み込みの部分でデータがいったん小さくなるので、そこをボトルネック層(Bottleneck layer)と呼ぶ。&lt;/p&gt;

&lt;p&gt;ボトルネック層によって、精度に影響が出ることはない。&lt;/p&gt;

&lt;p&gt;Inception moduleを組み合わせたネットワークをInception Networkという。
Inception Networkの例の一つがGoogLeNet。
GoogLeNetは中間層から全結合層・ソフトマックス層につなげる支流をもっていて、中間層まででうまく学習できているかを見れて、過学習を防げるようになっている。&lt;/p&gt;

&lt;p&gt;因みにInceptionという名前は映画のInceptionから来ている。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;実践&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;既存の実装の利用&lt;/p&gt;

&lt;p&gt;モダンなCNNは複雑すぎて、エキスパートが論文を読み込んでも再現することが難しい。
が、普通は論文の著者がOSSで実装を公開するのでそれを使ったりベースにしたりすべし。&lt;/p&gt;

&lt;p&gt;学習済みのモデルもあることがあるので、転移学習にも使える。
ソフトマックス層だけ入れ替えて、そこのWだけ学習させて自分の問題に使うなど。
色んな深層学習フレームワークが転移学習をサポートしてる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;データ合成(Data augmentation)&lt;/p&gt;

&lt;p&gt;画像認識の分野では基本的にデータが沢山要るけどデータが手に入りにくい。
ので合成するのが効果的。&lt;/p&gt;

&lt;p&gt;左右判定とか、切り抜きとか、回したり、歪めたりとかは、有効だけどあんまりやられない。
若干編集が複雑なので。&lt;/p&gt;

&lt;p&gt;色相を変える(Color shifting)のがよくやられる。赤味を増やしたり。
色を選ぶときには主成分分析(PCA)が使える。(PCA Color Augmentation)&lt;/p&gt;

&lt;p&gt;一つのCPUスレッドに元画像のロードと合成をやらせて、別のスレッドで並列に学習を処理するのが一般的な実装。&lt;/p&gt;

&lt;p&gt;データ合成するにも、どの程度変化させるかというハイパーパラメータが付きまとうので、既存の実装やアイデアを使うのがいい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;画像認識の現状&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;データ vs hand engineering&lt;/p&gt;

&lt;p&gt;データが沢山ある分野の問題だと、でかいネットワークを適当に組んで学習させれば上手く解ける。
データがあんまりないと、色々工夫(hand engineering)が必要になってくる。
特徴量を選んだり、アーキテクチャを工夫したり。
例えば物体検知は画像認識よりかなりデータが少ない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ベンチマークやコンペで上手くやるコツ&lt;/p&gt;

&lt;p&gt;研究者は、論文を通しやすくするため、ベンチマークやコンペのデータに対して頑張る。
ベンチマークに対して上手くやるコツ:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;アンサンブル(Ensembling)&lt;/p&gt;

&lt;p&gt;複数のNNを独立に訓練して、それらの出力の平均を使う。
1,2%の性能向上が見込める。
けど計算コストが高いので、普通プロダクションでは使わない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Multi-crop at test time&lt;/p&gt;

&lt;p&gt;テスト時にテストデータを色んな感じに切り抜いて、それらに対する予測値を平均する。
10-crop。
アンサンブルに比べ、訓練時の計算コストが少ないし、予測時に1つのモデルを保持すればいいのでメモリ使用量が少ない。
若干の性能向上が見込め、プロダクションでも使われることがある。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;オープンソースコードの利用&lt;/p&gt;

&lt;p&gt;だれかが考えたアーキテクチャを使え。&lt;/p&gt;

&lt;p&gt;OSS実装を使え。&lt;/p&gt;

&lt;p&gt;なんなら訓練済みモデルを使え。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Kerasのチュートリアル&lt;/p&gt;

&lt;p&gt;というほど解説してくれるわけではないけど。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kerasで50層のResNetを実装&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;3週目&lt;/p&gt;

&lt;p&gt;物体認識(Object detection)。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;位置特定(Localization)&lt;/p&gt;

&lt;p&gt;画像を与えられて単にラベルを付けるのは分類。
ラベルの物体の位置を示すのが位置特定。
分類したあとさらに位置特定したい。&lt;/p&gt;

&lt;p&gt;分類する画像は、普通一つの画像の中に一つの物体が大きく映っている。
一方、物体認識は、一つの画像の中に複数の物体があったりする、もう少し複雑な問題。&lt;/p&gt;

&lt;p&gt;位置特定するには、ソフトマックス層に、クラス以外に4つの出力をさせる。
すなわち物体の中心点のx座標、y座標、それと物体を囲む枠の高さ、幅。
それぞれ0～1の値で、画像全体に対する割合を示す。&lt;/p&gt;

&lt;p&gt;また、物体があるかないかという予測値Pcも出力する。
この予測値が0のときは、損失関数でそれいがいの出力を計算に入れない。&lt;/p&gt;

&lt;p&gt;より一般的には、物体の位置を示す任意の数のランドマーク(Landmark)の座標を出力させる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;物体認識&lt;/p&gt;

&lt;p&gt;スライディングウィンドウ認識(Sliding windows detection)する。
すなわち、小さい枠をずらしながら画像の切り抜きをたくさん作って、それぞれ分類する。
ウィンドウサイズを変えてもやる。
計算コストがかかる。&lt;/p&gt;

&lt;p&gt;のでCNNでやる。&lt;/p&gt;

&lt;p&gt;まず、全結合層は、数学的に等価な畳み込み層で置き換えられる。
5×5×16の入力を受け取って、5×5の400個のフィルタで畳み込むと、
1×1×400の出力が得られ、これは400ノードの全結合層と一緒。
最後に1×1の4個のフィルタで畳み込むと、4つの出力をするソフトマックス層みたいになる。
こういう、全部畳み込み層のNNをFCN(Fully Convolutional Networks)という。&lt;/p&gt;

&lt;p&gt;で、入力のサイズ(高さと幅)を広げてやると、中間層と出力もちょっと広がる。
このCNNは、入力の一部を5×5のウィンドウで切り抜いた部分の分類結果が、出力の1ピクセルに対応するようなものになる。
なので一回CNNに通せば、一回の計算でスライディングウィンドウできる。&lt;/p&gt;

&lt;p&gt;けどこれは、物体を囲む枠が正確でないという欠点がある。
実際は長方形であるべきだったりするので。
これを解決するのがYOLO(You Only Look Once)アルゴリズム。&lt;/p&gt;

&lt;p&gt;YOLOでは、まず入力画像をグリッド状に分割して、それぞれについて分類と位置特定する。
複数のセルに物体がまたがっている場合は、物体の中心があるセルだけにあるものとする。
それぞれのセルの出力をスタックして、3次元の出力にする。
つまり、グリッドが3×3なら、3×3×(もとのyベクトルの次元)とする。
(普通はもっと細かいグリッドにする。)
で、CNNをこういう形の出力をするように組む。&lt;/p&gt;

&lt;p&gt;YOLOの論文はかなりむずい。&lt;/p&gt;

&lt;p&gt;位置特定の評価をするのに、IoU(Intersection over Union)という指標がある。
これは、2つの領域の重なり具合を示すもので、2つの領域が重なった部分の面積を、2つの領域全体の面積で割った値。
モデルが特定した枠と期待する枠とで、IoUが0.5以上だとよしとすることが多い。&lt;/p&gt;

&lt;p&gt;YOLOを使うと、複数のセルで同じ物体を認識してしまうことが多い。
これを一つに絞るのがNMS(Non-max suppression)。
ざっくり言うと、それぞれのセルの確度(Pc)を見て、一番でかいの以外を無効化する。&lt;/p&gt;

&lt;p&gt;詳しく言うとまず、Pcがある閾値(e.g.0.6)以下のものを無効化する。
で、残ったものの中から、最大のPcを選び、それとおおきくかぶっている枠(IoUが0.5以上など)を無効化する。
で、また残ったのものの中から最大のPcを選び、同じことを繰り返していく。
クラスが複数あったら、これをクラスごとにやる。&lt;/p&gt;

&lt;p&gt;一つのセルに複数の物体があったらどうか。
境界ボックス(Anchor box)を使う。
事前に複数の形の枠(境界ボックス)を用意しておいて、それぞれについての予測を出力ベクトルに並べる。
で、一番IoUが高い境界ボックスを採用する。&lt;/p&gt;

&lt;p&gt;境界ボックスは手動で作ったり、k平均法で作ったりする。&lt;/p&gt;

&lt;p&gt;スライディングウィンドウは、明らかに何もない部分の計算もしちゃうのでちょっと無駄。
なので、そういう部分はスキップしようというのがR-CNN(Regions with CNN)。
これはRegion proposalsとCNNを組み合わせたもの。
Region proposalsは、セグメンテーション(Segmentation)アルゴリズムで画像をざっくり区分けして、それっぽい部分を処理対象にするもの。&lt;/p&gt;

&lt;p&gt;R-CNNはすごく遅いので、あまり使われていないし、Andrew先生も好んで使わない。
Fast R-CNN、Faster R-CNNってのもあるけど、まだ遅い。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;KerasでYOLOv2モデルを実装。&lt;/p&gt;

&lt;p&gt;CNN部分は訓練済みのモデルを使って、出力をフィルタリングする部分を作る。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;4週目&lt;/p&gt;

&lt;p&gt;顔認識(Face recognition)とNeural style transfer。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;顔認識&lt;/p&gt;

&lt;p&gt;顔認証(Face authentication)には、顔認識と、生きた人間かの判定(Liveness detection)が要るけど、前者を主に学ぶ。&lt;/p&gt;

&lt;p&gt;顔認識は顔検証(Face verification)の難しい版。
後者は顔画像と名前を与えて、正しい組み合わせかを判定する。
前者は顔画像を与えて、DBからその人を探す。&lt;/p&gt;

&lt;p&gt;顔認識は一般的に、One-shot learning問題に対応する必要がある。
つまり一つの訓練データから学習しないといけない。
DBに一人のひとについて何個も画像があるというケースは少ない。&lt;/p&gt;

&lt;p&gt;CNNに顔画像を入力して、ソフトマックス層で分類するのは、訓練データが少なすぎるのでうまくいかない。
代わりに類似関数(Similarity function)を学習する。
つまり、二つの画像を入力として、異なる度合いを出力するもの。
で、その出力が閾値以下だったら同一人物と判定する。
これをDBに入っている画像それぞれについてやる。&lt;/p&gt;

&lt;p&gt;類似関数にはシャム(Siamese)ネットワークをつかう。&lt;/p&gt;

&lt;p&gt;CNNの最後の全結合層の出力ベクトルは、入力画像をエンコードしたものだと考えられる。
二つの画像を、別々に同じCNNにいれて、二つの出力ベクトルを得たら、それらのユークリッド距離の二乗を差として出力する。
これがシャムネットワーク。
二つの画像が同一人物ならユークリッド距離が小さくなるように、違うなら大きくなるように訓練する。&lt;/p&gt;

&lt;p&gt;損失関数にはTriplet loss関数を使う。
同一人物を比較するとき、Anchor画像とPositive画像の比較、違う人物の比較はAnchor画像とNegative画像の比較と呼ぶ。
AnchorとPositiveのユークリッド距離がAnchorとNegativeのユークリッド距離以下になってほしい。
つまり前者マイナス後者がゼロ以下になって欲しい。
ただこれだと、CNNが全ての画像について同じ出力をするように学習してしまうかもしれないので、&lt;code&gt;0-α&lt;/code&gt;以下になるように訓練する。
αはマージンと呼ばれるハイパーパラメータ。&lt;/p&gt;

&lt;p&gt;AnchorとPositiveとNegativeの一組をTripletと呼ぶ。
Negativeをランダムに選ぶと、全然違う顔の組み合わせが多くなって、類似関数があまり学習しない。
ので、似てるひとを組み合わせたTripletを多く作ってやると効率よく学習する。&lt;/p&gt;

&lt;p&gt;シャムネットワークの二つの出力ベクトルをロジスティック回帰ユニットに入れて、同一人物か否かの二値分類する方法もある。
ベクトル間の距離も、ユークリッド距離の他、カイ二乗値(χ square similarity)ってのもある。&lt;/p&gt;

&lt;p&gt;DBには、顔画像そのものよりも、エンコードしたベクトルを入れておくと計算量を省けるし、DBサイズも抑えられる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ニューラル画風変換(NST: Neural style transfer)&lt;/p&gt;

&lt;p&gt;Content画像&amp;copy;とStyle画像(S)から、あらたな画像(G)を生成するCNN。
(CNNは別途訓練済みのものを使うので、転移学習の一種。)&lt;/p&gt;

&lt;p&gt;CNNの可視化ができる。
画像の一部を入力して、ある層の一つのユニットの出力が最大になるものを選んで集めると、そのユニットがどのような特徴を抽出しているかがわかる。
深い層ほど広い範囲を見て、複雑なパターンを学ぶ。&lt;/p&gt;

&lt;p&gt;コスト関数&lt;code&gt;J(G)&lt;/code&gt;を最小化する。
&lt;code&gt;J(G)&lt;/code&gt;はコンテントコスト&lt;code&gt;Jcontent(C, G)×α&lt;/code&gt;とスタイルコスト&lt;code&gt;Jstyle(S, G)×β&lt;/code&gt;の和。
前者はCとGの類似関数で、後者はSとGの類似関数。
αとβはハイパーパラメータ。
Gをランダムに初期化して、最急降下法でGを調整していく。&lt;/p&gt;

&lt;p&gt;訓練済みのCNN(VGGなど)を使って、中間層lを選ぶ。
Cを入力してlから出てきた値と、Gを入力してlから出てきた値が似てたら、CとGを似ているとする。
つまりそれらをベクトルにアンロールしたものの二乗誤差が&lt;code&gt;Jcontent(C, G)&lt;/code&gt;。
lが浅ければ浅いほど、CとGは似たものになる。&lt;/p&gt;

&lt;p&gt;スタイルは、ある層lの出力のx座標とy座標の各点について、チャネル間で値の関連性を見る。
あるチャネルのあるニューロンが縦縞を検出していて、ほかのチャネルのあるニューロンがオレンジ色を検出していたとしたら、画像にオレンジの縦縞がよく現れるなら両者は関連が高く、そうでなければ低い。
SとGとの間でこの関連性が似てれば、スタイルが似ていると言える。&lt;/p&gt;

&lt;p&gt;スタイル行列(Style matrix)で表す。
ある層のスタイル行列は&lt;code&gt;nc×nc&lt;/code&gt;で、チャネル間の関連度を表す。
行列の一つの値は、二つのチャネルの各アクティベーションの掛け合わせものの合計。
関連性が強いとこの掛け合わせは大きくなる。
(対角成分は同じチャネル同士の積になって、そのスタイルがどれだけ全体的に出ているかを示す。)
この行列は代数学ではグラム行列(Gram matrix)と呼ばれる。&lt;/p&gt;

&lt;p&gt;このスタイル行列をSとGで計算して、それらの二乗誤差をl層のスタイルコストとする。
で、これにハイパーパラメータλlをかけたものを層ごとに計算して、足し合わせたものを全体のスタイルコストとする。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2D以外の画像の処理&lt;/p&gt;

&lt;p&gt;心電図のデータとかの1Dデータや、CTスキャンみたいな3Dデータでも、それに合わせた次元のフィルタを使えば畳み込める。
1DデータはRNNでもできるけど、CNNでもできて、それぞれメリットデメリットがある。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;TensorFlowでニューラル画風変換を実装&lt;/p&gt;

&lt;p&gt;VGG-19をImageNetのデータで訓練したものを使う。
ルーブル美術館の写真をContent画像に、モネの絵をStyle画像に使って画像を生成。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kerasで顔認識モデルを実装&lt;/p&gt;

&lt;p&gt;現時点でtriplet_lossの採点にバグがある。
対策はフォーラム参照。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CourseraのDeep Learning SpecializationのStructuring Machine Learning Projectsコースを修了した</title>
          <link>https://www.kaitoy.xyz/2018/01/16/coursera-deep-learning-ml-strategy/</link>
          <pubDate>Tue, 16 Jan 2018 07:56:43 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/01/16/coursera-deep-learning-ml-strategy/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/01/12/coursera-deep-learning-improving-deep-neural-networks/&#34;&gt;CourseraのDeep Learning SpecializationのImproving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimizationコースを修了した&lt;/a&gt;のに続き、&lt;a href=&#34;https://www.coursera.org/learn/machine-learning-projects&#34;&gt;Structuring Machine Learning Projectsコース&lt;/a&gt;を修了した。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;このコースは、深層学習プロジェクトの進め方のコツや問題への対処方法などについて学べる2週間のコース。
今回はプログラミング課題がない。
動画は今のところ全部英語。&lt;/p&gt;

&lt;p&gt;ちょっと動画編集ミスが多かった。
同じことを二回言ったり、無音無絵の時間があったり、マイクテストしてたり。&lt;/p&gt;

&lt;p&gt;2018/1/13に始めて、1/15に完了。
3日間かかった。
修了したらまた&lt;a href=&#34;https://www.coursera.org/account/accomplishments/certificate/7MHFMLHP67C4&#34;&gt;Certifacate&lt;/a&gt;もらえた。&lt;/p&gt;

&lt;p&gt;以下、2週分の内容をメモ程度に書いておく。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;p&gt;モデルの改善をするのに、データを増やしたりハイパーパラメータを変えたり色々な手法がある。
一つを試すのに下手すると数か月とかかかるので、効率よく手法の取捨選択し、モデルを改善していくための戦略について学ぶ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;直交化(Orthogonalization)&lt;/p&gt;

&lt;p&gt;一つの要素で複数の制御をしようとすると難しいので、一つの制御だけするようにする。
具体的には、以下のことを別々に扱う。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;訓練データに目標の精度までフィットさせる。&lt;/li&gt;
&lt;li&gt;devデータに目標の精度までフィットさせる。&lt;/li&gt;
&lt;li&gt;テストデータに目標の精度までフィットさせる。&lt;/li&gt;
&lt;li&gt;現実のデータでうまく動くようにする。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;それぞれの目的について、チューニングすべき要素は別々になる。&lt;/p&gt;

&lt;p&gt;早期終了は直行化の原則に反しているので、ほかの方法があるならそっちをやったほうがいい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;指標(Goal)の設定&lt;/p&gt;

&lt;p&gt;モデルの改善はイテレーティブなプロセスなので、サイクルを速く回したい。
そのため、モデルを評価する単一の数値があるといい。
F1スコアとか。平均とか&lt;/p&gt;

&lt;p&gt;単一の指標にまとめるのがむずいときもある。
精度と速さとか。
そんなときは一つ以外の指標を足切りだけに使う。
ある閾値以上の速さが出てるもののなかで精度をくらべるなど。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;データの分け方&lt;/p&gt;

&lt;p&gt;devデータとテストデータの分布(と評価指標)は同じ感じにしないといけない。
そのために、いったん全データをシャッフルしてから分割する。
訓練データの分布は異なってても問題ない。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;訓練:テスト = 70:30&lt;/code&gt;とか、&lt;code&gt;訓練:dev:テスト = 60:20:20&lt;/code&gt;とかいう比率は、1万くらいのデータなら適当。
けど100万くらいなら、98:1:1くらいが妥当。&lt;/p&gt;

&lt;p&gt;テストデータはモデルの最終評価をするためのものなので、どれだけ評価したいかによってサイズを変える。
0もありがちだけど、非推奨。&lt;/p&gt;

&lt;p&gt;猫の画像のなかにエロ画像が混じっちゃうようなモデルはだめ。
猫判定率が多少下がっても、エロ画像が含まれないほうがまし。
こういう場合は評価指標を変える必要がある。
エロ画像を猫と判定した場合にペナルティを大きくするなど。&lt;/p&gt;

&lt;p&gt;直行化の観点で言うと、指標を決めるのと、その指標に従って最適化するのは、別のタスクとして扱うべき。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;人並性能(Human-level performance)との比較&lt;/p&gt;

&lt;p&gt;人並性能とは、人が手動で達成できる精度。そのエラー率、つまり人並誤差(Human-level error)はベイズ誤差(Bayes optimal error)に近い。&lt;/p&gt;

&lt;p&gt;モデルを改良していくと、人並性能を超え、その後改善速度は鈍化し、人並誤差はベイズ誤差に漸近していく。
鈍化する理由は、人並性能がベイズ誤差に近いのと、人以上の精度に人がチューニングするのが無理があるから。
人手でラベル付きデータを作れないし、エラー分析もできなくなるので。&lt;/p&gt;

&lt;p&gt;人並誤差より訓練データでのエラー率が結構高いなら、高バイアス対策をする。
人並誤差と訓練データでのエラー率が近くて、devデータでのエラー率が結構高いなら、高バリアンス対策をする。
人並誤差と訓練データでのエラー率との差ををAndrew先生は可避バイアス(Avoidable bias)と名付けた。&lt;/p&gt;

&lt;p&gt;人並誤差はベイズ誤差の近似として使える。
人並誤差は、ある判別問題に関して、その道のエキスパート達が議論して解を出すみたいな、人類が全力を尽くしたうえでの誤差とする。
人並誤差が分かれば、訓練データとdevデータのエラー率を見て、高バイアスか高バリアンス化を判別できる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;モデルの性能改善手順&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;訓練データにフィットさせ、可避バイアスを最小化する。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;モデルを大きくする。&lt;/li&gt;
&lt;li&gt;最適化アルゴリズムを高度なものにするか、長く訓練する。&lt;/li&gt;
&lt;li&gt;NNのレイヤを深くしたり隠れ層のノードを増やしたり、CNNとかRNNとかの高度なアーキテクチャにする。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;dev・テストデータで評価し、バリアンスを下げる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;データを増やす。&lt;/li&gt;
&lt;li&gt;正則化する。&lt;/li&gt;
&lt;li&gt;ハイパーパラメータをいじる。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Andrej Karpathyへのインタビュー&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;エラー分析&lt;/p&gt;

&lt;p&gt;エラー率が高いときに、エラーが起きたdevデータのサンプルを見て原因を分析する。
天井分析(Ceiling analysis)も併せてやる。
例えば、猫判定器で、犬を猫と判定したサンプルがあったとして、犬の問題に取り組むかどうかは、全体のエラーサンプル数に対する犬のエラーサンプル数の割合を見て、その取り組みで最大どれだけの効果を得るかを分析する。&lt;/p&gt;

&lt;p&gt;天井分析を複数の問題点に対してやれば、どれに時間をかける価値があるかの指標を得られる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ラベリングミスへの対処&lt;/p&gt;

&lt;p&gt;ディープラーニングは、ランダムエラーに対して堅牢で、訓練データに多少のラベリングミスがあっても問題なく動く。&lt;/p&gt;

&lt;p&gt;devデータにミスがあった場合、エラー分析の際にそれも数えておいて、対処すべきかどうかを判断する。
他の問題によるエラーの割合と比べて、ラベリングミスによるものの割合が大きければ対処すればいいし、そうでなければほっておく。
また、エラー全体に対するラベリングミスの割合が大きくなると、モデルの性能比較に支障が出てくるので、そうなったらラベリングミスに対処する必要が高まってくる。&lt;/p&gt;

&lt;p&gt;devデータのラベリングミスを直すときは、テストデータも同時に直し、分布に違いが出ないようにする。
また、エラーなサンプルだけじゃなく、正答したサンプルも見直すべし。
けど、訓練データは直さなくてもいい。数も多いし、devデータと分布が違っていても問題ないし。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;新しいディープラーニングシステムを作るときのガイドライン&lt;/p&gt;

&lt;p&gt;あまり経験のない分野のシステムを新たに作るなら、早く立ち上げてイテレーションを回すべし。
具体的には、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;dev・テストデータと、指標を用意する。&lt;/li&gt;
&lt;li&gt;さっさとシステムを実装する。&lt;/li&gt;
&lt;li&gt;バイアス/バリアンス分析やエラー分析をして、次のアクションを決める。&lt;/li&gt;
&lt;li&gt;システムを改善する。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;というのを速く回す。
経験が深かったり、確かな研究結果がすでにあったりするなら、最初から凝ったシステムにしてもいい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;訓練データとdev・テストデータの分布のミスマッチ&lt;/p&gt;

&lt;p&gt;ディープラーニングでは訓練データは大抵不足するから、現実的に、訓練データはいろんなデータのかき集めで、dev・テストデータとは分布が異なってくる。&lt;/p&gt;

&lt;p&gt;例えば、実際のデータが10000個で、かき集めのが200000個あったら、全部合わせてシャッフルしてデータ分割するのは、dev・テストデータの質が悪くなるのでダメ。
dev・テストデータには実際のデータだけ使って、かき集めのは全部訓練データに使うべし。&lt;/p&gt;

&lt;p&gt;分布がミスマッチになると、バイアス/バリアンス分析がむずくなる。
devデータでエラーが増えても、単にdevデータのほうが判別が難しいデータなのかもしれない。&lt;/p&gt;

&lt;p&gt;分析をしやすくするため、訓練devデータを作る。
これは、訓練データと同じ分布のデータで訓練に使わないデータ。訓練データのサブセット。&lt;/p&gt;

&lt;p&gt;訓練データと訓練devデータのエラー率の差が大きければオーバーフィット。
訓練データと訓練devデータのエラー率の差が小さくて、devデータのエラー率が高いなら、データミスマッチ問題(Data missmatch problem)。&lt;/p&gt;

&lt;p&gt;あんまり発生しないけど、devデータよりテストデータのエラー率が結構大きいなら、devデータにオーバーフィットしてるので、devデータサイズを増やしたりする必要がある。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;データミスマッチ問題への対応&lt;/p&gt;

&lt;p&gt;データミスマッチ問題が発覚したら、訓練データをdevデータに近づけたり、devデータに近いものを訓練データに加えたりすることを考える。
例えば、車内の音声認識のためのモデルを開発していて、devデータに車の雑音が入っていることが分かったら、訓練データにそういう雑音を合成してやるなど。
ただし、その場合、同じ雑音をすべての訓練データに適用すると、その雑音にモデルがオーバーフィットするリスクがあるので注意。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;転移学習(Transfer learning)&lt;/p&gt;

&lt;p&gt;ある問題に対して作ったモデルを、別の問題に再利用する。
(但し入力は同種のデータ。画像なら画像、音声なら音声。)
その際、NNの、出力層だけのパラメータをランダム初期化したり、層を足したりして、あたらしい訓練データで学習させる。
新たな訓練データが少ない場合は、後ろの1,2層だけを再学習させ、データがたくさんあったら全体を再学習させる。&lt;/p&gt;

&lt;p&gt;最初の学習を事前学習(Pre-training)、新たなデータでの学習をファインチューニング(Fine tuning)という。
画像認識の分野でよく使われる。NNの浅い層のほうが、汎用的な特徴(エッジ検出など)を学習するので再利用できると考えられているが、詳しい原理は判明していない。&lt;/p&gt;

&lt;p&gt;事前学習するデータより、ファインチューニングに使えるデータが少ないときに効果的。
データ量が同じくらいだったり、後者のほうが多い場合は、最初から目的のデータで学習させたほうがいい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;マルチタスク学習(Multi-task learning)&lt;/p&gt;

&lt;p&gt;一度に複数の判別をさせるモデルをつくる。
ソフトマックス層つかった多クラス分類に似てるけど、一つのサンプルから複数のクラスを検出する。
例えば車と歩行者と標識など。
物体検知によく使われる。&lt;/p&gt;

&lt;p&gt;一つ一つのクラスのデータが少なくても低層が学んだ共通特徴を活用できるので、一つのタスクをするNNを複数訓練するより性能が良くなることがある。&lt;/p&gt;

&lt;p&gt;ラベルが歯抜けでも学習できる。&lt;/p&gt;

&lt;p&gt;複数タスクをこなすため、大き目なネットワークにする必要がある。&lt;/p&gt;

&lt;p&gt;それぞれのクラスのデータが十分あるときはあまり使われない手法。
目的のクラスのデータが少ないとき、転移学習のほうがよく使われる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;End-to-end学習&lt;/p&gt;

&lt;p&gt;従来、ある入力から解となる出力を得るのに、パイプラインで複数の処理をしていたが、これを全部一つのNNで処理する手法。
データ量が多いと上手くいく。&lt;/p&gt;

&lt;p&gt;例えば、人の認識をするときパイプラインでは、顔検出して、拡大してクロップしてからNNにかける。
こっちのほうが個々のタスクがシンプルで、それぞれのデータも手に入りやすいので性能を出しやすい。
けどもし、end-to-endのラベル付きデータが十分にあればend-to-end学習でもいける。&lt;/p&gt;

&lt;p&gt;翻訳タスクの場合、現実的に大量のデータが手に入るので、end-to-endで上手くいく。&lt;/p&gt;

&lt;p&gt;データさえたくさんあれば、パイプラインのコンポーネント的なところも勝手に学んでくれるので、ヒトが考え付くよりもいい特徴を学んでくれるかもしれない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Ruslan Salakhutdinovへのインタビュー&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CourseraのDeep Learning SpecializationのImproving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimizationコースを修了した</title>
          <link>https://www.kaitoy.xyz/2018/01/12/coursera-deep-learning-improving-deep-neural-networks/</link>
          <pubDate>Fri, 12 Jan 2018 23:41:57 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/01/12/coursera-deep-learning-improving-deep-neural-networks/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/01/05/coursera-deep-learning-neural-networks-and-deep-learning/&#34;&gt;CourseraのDeep Learning SpecializationのNeural Networks and Deep Learningコースを修了した&lt;/a&gt;のに続き、&lt;a href=&#34;https://www.coursera.org/learn/deep-neural-network&#34;&gt;Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimizationコース&lt;/a&gt;を修了した。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;このコースは、ディープニューラルネットワークのチューニングなどについて学べる3週間のコース。
今のところ全部英語。&lt;/p&gt;

&lt;p&gt;2018/1/5に始めて、1/12に完了。
8日間かかった。
修了したらまた&lt;a href=&#34;https://www.coursera.org/account/accomplishments/certificate/5VS9EJJ6TJ3A&#34;&gt;Certifacate&lt;/a&gt;もらえた。&lt;/p&gt;

&lt;p&gt;以下、3週分の内容をメモ程度に書いておく。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;p&gt;OverfittingやUnderfittingを防ぐテクニックについて。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;データ分割&lt;/p&gt;

&lt;p&gt;深層学習のモデル構築は、検討(Idea)、実装(Code)、検証(Experiment)というサイクルの繰り返し(Iterative process)。
取り組む課題、課題のドメイン、データ量、マシンの構成などにより、ハイパーパラメータは変わるので、経験をもって事前に予測することは無理なので、サイクルをどれだけ速く回せるかが鍵。&lt;/p&gt;

&lt;p&gt;データは、訓練データ(Training set)、Devデータ(Development set))(a.k.a. Cross-validation set)、テストデータ(Test set)に分割する。
訓練データで学習し、Devデータでハイパーパラメータを評価し、テストデータで最終的な評価と性能見積をする。
テストデータは無くてもいい。&lt;/p&gt;

&lt;p&gt;サンプル数が1万くらいだった時代は、6:2:2くらいで分割してたけど、近年は数百万とかのデータを扱い、交差検証データやテストデータの割合はもっと小さくするのがトレンド。
98:1:1など。&lt;/p&gt;

&lt;p&gt;Devデータとテストデータは同じようなものを使うべき。
訓練データは必ずしも同様でなくてもいい。訓練データは沢山要るので、別のデータソースからとることもある。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;バイアス vs バリアンス&lt;/p&gt;

&lt;p&gt;でかいネットワークで正則化して大量データで学習させるのが吉。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;正則化&lt;/p&gt;

&lt;p&gt;過学習(Overfitting)を防ぐため、コスト関数を正則化(Regularization)すべし。&lt;/p&gt;

&lt;p&gt;ロジスティック回帰ではL2ノルム(L2 norm)を使ったL2正則化が一般的。
L1正則化はあまり使われない。
L1正則化をすると、wがスパース行列になってモデルを圧縮できると言われることがあるが、経験上その効果はほとんどない。&lt;/p&gt;

&lt;p&gt;正則化パラメータλはハイパーパラメータで、Devデータで評価する。&lt;/p&gt;

&lt;p&gt;ニューラルネットワークでは正則化項にフロベニウスノルム(Frobenius norm)を使う。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dropout(Inverted Dropout)&lt;/p&gt;

&lt;p&gt;ランダムにノードを無効化しながら学習することで過学習を防ぐ。
画像処理の分野では、特徴量の数が多く学習データが少ない傾向があるので、ほぼ常に使われる。&lt;/p&gt;

&lt;p&gt;コスト関数が計算できなくなるのが欠点。
計算する必要があるときにはDropoutを無効化する。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;データ拡張(Data augmentation)&lt;/p&gt;

&lt;p&gt;データを加工して増やせば、高バリアンス対策になる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;早期終了(Early stopping)&lt;/p&gt;

&lt;p&gt;過学習するまえに学習を止めるテクニック。
訓練データとDevデータについてコストをプロットして、Devデータのものが上がる前に止める。&lt;/p&gt;

&lt;p&gt;これは、直交化(Orthogonalization)の原則、つまり一度に一つのことを考慮すべきという原則に反していて、コストを最小化するという問題と、過学習を避けるという問題に同時に対処することになるので微妙。&lt;/p&gt;

&lt;p&gt;普通は代わりにL2正則化使えばいいけど、λを最適化する手間を省きたいときには選択肢になりうる、というか実現場ではちょくちょく選択肢になる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;訓練データの正規化(Normalization)&lt;/p&gt;

&lt;p&gt;訓練データの各特徴量について平均を0にして分散を1にすると学習が速くなる。&lt;/p&gt;

&lt;p&gt;訓練データを正規化したらテストデータも正規化する。
その際、正規化パラメータは訓練データのものを使う。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;勾配消失(Vanishing gradient)、勾配爆発(Exploding gradient)&lt;/p&gt;

&lt;p&gt;ニューラルネットワークの層が深くなると、層の出力や勾配が指数関数的に大きくなったり小さくなったりして、学習が難しくなる問題。
長年ディープニューラルネットワークの発展を妨げてきた問題。&lt;/p&gt;

&lt;p&gt;パラメータのランダム初期化をすると防げる。
ガウス分布で作ったパラメータに特定の値を掛けてを分散が1/n(ReLUの時は2/n)になるように調整して、活性化関数に入力する値を約1に抑える。
掛ける値は活性化関数ごとにだいたい決まっていて((e.g. Xavier Initialization)、その値をハイパーパラメータとして調整するのはそれほど優先度は高くない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Gradient checking&lt;/p&gt;

&lt;p&gt;順伝播・逆伝播が正確に実装できているかを、数値計算手法で概算した勾配と逆伝播で出した勾配を比べてチェックするテクニック。
計算コストが高くなるので、デバッグ時にのみ使う。&lt;/p&gt;

&lt;p&gt;Dropoutしてるときには使えない。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;初期化&lt;/p&gt;

&lt;p&gt;ゼロ初期化、大きい値でのランダム初期化、He初期化(Xavier初期化っぽいやつ)を実装して性能を比べる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;正則化&lt;/p&gt;

&lt;p&gt;正則化無し、L2正則化、Dropoutの実装と比較。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Gradient checking&lt;/p&gt;

&lt;p&gt;Gradient checkingの実装と、その結果を利用した逆伝播のデバッグ。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Yoshua Bengioへのインタビュー&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;p&gt;学習を速くするテクニックについて。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ミニバッチ勾配降下法(Mini-batch gradient descent)&lt;/p&gt;

&lt;p&gt;普通の勾配降下法(i.e. バッチ勾配降下法)よりかなり速いので、大規模データでよく使われるテクニック。
学習回数に対するコストのプロットはノイジーになる。&lt;/p&gt;

&lt;p&gt;ミニバッチサイズというハイパーパラメータが増える。
ミニバッチサイズがmならバッチ勾配降下法、1なら確率的勾配降下法(Stochastic gradient descent)になる。&lt;/p&gt;

&lt;p&gt;ミニバッチ勾配降下法と確率的勾配降下法は収束しない。&lt;/p&gt;

&lt;p&gt;バッチ勾配降下法は遅すぎる。
確率的勾配降下法はベクトル化の恩恵がなくなるという欠点がある。
ので、適当なミニバッチサイズにするのがよく、それが一番速い。&lt;/p&gt;

&lt;p&gt;2000個くらいのデータならバッチ勾配降下法。
それより多ければ、64～512位のミニバッチサイズがいい。
メモリ効率を考えると2の累乗数がいいし、CPU/GPUメモリサイズに乗るサイズにすべし。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;指数加重移動平均 (EWMA: Exponentially Weighted Moving Average)&lt;/p&gt;

&lt;p&gt;ノイズのあるデータから、よりスムーズなプロットを書く手法。
過去数日の平均をもとにプロットする。&lt;/p&gt;

&lt;p&gt;この手法だと、最初の方のデータが不当に小さくなってしまう。
これが問題になるなら、バイアス補正(Bias correction)をかける。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;モーメンタム(Momentum)付き勾配降下法&lt;/p&gt;

&lt;p&gt;パラメータを更新するときに、勾配そのままではなく、勾配の指数加重移動平均を使う手法。
勾配降下を滑らかに速くできる。
慣性(勢い)をつけて走り抜ける感じ。&lt;/p&gt;

&lt;p&gt;指数加重移動平均を計算するときのβが新たなハイパーパラメータになる。
普通0.9。この場合バイアス補正はそんなに効果ないので普通かけない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;RMSprop&lt;/p&gt;

&lt;p&gt;パラメータを更新するときに、勾配そのままではなく、勾配の二乗平均平方根(RMS: Root Mean Square)を使う手法。
学習率を上げつつ、勾配降下を滑らかに速くできる。&lt;/p&gt;

&lt;p&gt;二乗平均平方根を計算するときのβと、ゼロ除算を防ぐためのεが新たなハイパーパラメータになる。
提唱者は、&lt;code&gt;β=0.999&lt;/code&gt;、&lt;code&gt;ε=10^-8&lt;/code&gt;を推奨しているし、これらをチューニングすることはあまりない。&lt;/p&gt;

&lt;p&gt;Couseraが広めたことで、よく使われるようになった。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Adam(Adaptive Moment Estimation)&lt;/p&gt;

&lt;p&gt;モーメンタムとRMSpropとバイアス補正を組み合わせた最適化アルゴリズム。
これをミニバッチ勾配降下法と一緒に使えばだいたい上手くいく。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;学習率減衰(Learning rate decay)&lt;/p&gt;

&lt;p&gt;ミニバッチ勾配降下を収束させるために、学習率を徐々に小さくする手法。
エポックごとに学習率を下げる。&lt;/p&gt;

&lt;p&gt;学習率αが、α0と 減衰率(Decay rate)とエポック番号から計算されるようになるので、α0と減衰率がハイパーパラメータ。&lt;/p&gt;

&lt;p&gt;学習率の計算方法にはいくつかある。
指数関数的に下げたり、階段状に下げたり。&lt;/p&gt;

&lt;p&gt;Andrew先生はあまり使わない手法。
学習率をよくチューニングすれば十分。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;局所最適解(Local optima)&lt;/p&gt;

&lt;p&gt;かつて、勾配が0になる点は、コストの谷、つまり局所最適解だと考えられていて、そこに嵌ることが問題だった。&lt;/p&gt;

&lt;p&gt;けど、ディープニューラルネットワークでは多くは尾根的なもの。
鞍の上みたいな部分なので鞍点(Saddle point)と呼ばれる。
特徴量が沢山あるので、ちょっと動かすとどれかの勾配は負になる。&lt;/p&gt;

&lt;p&gt;よって局所最適解はあまり恐れなくていい。
代わりに、鞍点の台地みたいな部分では勾配が小さいので学習効率が悪くなる。
ここを勢いよく抜けたいので、モーメンタムやRMSpropやAdamが有効になる。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ミニバッチ勾配降下法実装&lt;/p&gt;

&lt;p&gt;訓練データをシャッフルして、ミニバッチサイズに分割して(余りは余りでミニバッチにする)、forループで回す。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;モーメンタムとAdam実装&lt;/p&gt;

&lt;p&gt;単なるミニバッチ勾配降下法とモーメンタム付きとAdamを比較。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Yuanqing Linへのインタビュー&lt;/p&gt;

&lt;p&gt;中国の国立深層学習研究所のトップ。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;p&gt;ハイパーパラメータのチューニング方法、バッチ正規化、ソフトマックス回帰、TensorFlow。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ハイパーパラメータのチューニング&lt;/p&gt;

&lt;p&gt;一番重要なのは学習率。
次はモーメンタムのβとかミニバッチサイズとか隠れ層のノード数。
その次がレイヤ数とか学習率減衰率。&lt;/p&gt;

&lt;p&gt;チューニングの際は、かつてはグリッドサーチ(Grid search)がよく使われたけど、これはハイパーパラメータが多くなるとつらい。
ランダムサーチ(Randomized search)がより効率的。&lt;/p&gt;

&lt;p&gt;グリッドサーチだとあるパラメータを固定して別のパラメータを変化させるけど、変化させたパラメータがどうでもいいものだった場合、その試行がほとんど無駄になるので。&lt;/p&gt;

&lt;p&gt;粗くランダムサーチして当たりをつけ、範囲を絞って細かいランダムサーチする。&lt;/p&gt;

&lt;p&gt;ランダムといってもいろいろあって、ユニット数なんかは一様にランダムでいいけど、学習率なんかはlogスケールの上でランダムにしたほうがいい。&lt;/p&gt;

&lt;p&gt;実運用では、計算リソースが少ない場合に採るパンダアプローチと、潤沢なリソースで複数のモデルを同時に訓練するキャビアアプローチがある。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;バッチ正規化(Batch normalization)&lt;/p&gt;

&lt;p&gt;深層学習の実用化において最も重要なアルゴリズムの一つ。
ハイパーパラメータの選定を簡単にして、ディープニューラルネットワークの訓練を簡単にする。&lt;/p&gt;

&lt;p&gt;バッチ正規化では、各層の入力を正規化する。
ミニバッチごとに平均を0、分散を1に正規化した後、βとγというパラメータでそれぞれを調整する。
aよりz(i.e. 活性化関数適用前)を正規化するのが普通。&lt;/p&gt;

&lt;p&gt;(ハイパーではない)パラメータとしてβとγが層ごとに増える。
これらもWとともに学習する。
βがbの役割をするので、bはいらなくなる。&lt;/p&gt;

&lt;p&gt;バッチ正規化は共変量シフト(Covariate shift)という問題に対応するもの。
共変量シフトは、訓練した後で入力の分散が変わると、また訓練しなおさないといけないという問題。
ニューラルネットワークの内部では、前のほうの層のWが学習を進めるたびに変わり、その層の出力が変わる。
つまり後のほうの層への入力が変わるので、後のほうの層の学習が進みにくい。
バッチ正規化は、この後のほうの層への入力の分散を一定範囲に抑えることで、後のほうの層の学習を効率化する。&lt;/p&gt;

&lt;p&gt;Dropoutと同様な論理(ノードへの依存が分散される)で正則化の効果もややある。&lt;/p&gt;

&lt;p&gt;訓練が終わったら、最後のミニバッチの平均μと分散σ^2を保存しておいて、予測時に使う。
μとσ^2は訓練データ全体から再計算してもよさそうだけど、普通はやらない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ソフトマックス回帰(Softmax regression)&lt;/p&gt;

&lt;p&gt;ニューラルネットワークで多値分類(Multi-class classification)するアルゴリズム。
出力層(ソフトマックス層)のノード数をクラス数にして、活性化関数にソフトマックス関数を使う。
出力層の各ノードは、サンプルが各クラスに属する確率を出力する。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;TensorFlow&lt;/p&gt;

&lt;p&gt;ディープラーニングフレームワークはいろいろある: Caffe/Caffe2、CNTK、DL2J、Keras、Lasagne、mxnet、PaddlePaddle、TensorFlow、Theano、Torch。
プログラミングしやすいこと、訓練性能がいいこと、オープンであることが重要。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;TensorFlowの基本&lt;/p&gt;

&lt;p&gt;TensorFlowでのプログラムはだいたい以下のような手順で書く。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;テンソル(tensor)をつくる。これはまだ評価されない。&lt;/li&gt;
&lt;li&gt;テンソル間の計算式(計算グラフ)を書く。&lt;/li&gt;
&lt;li&gt;テンソルを初期化する。&lt;/li&gt;
&lt;li&gt;セッションを作る。&lt;/li&gt;
&lt;li&gt;セッションを実行する。ここで計算が実行される。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;後で(セッション実行時に)値を入れたい場合はプレースホルダ(placeholder)を使う。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;TensorFlowでのニューラルネットワーク実装&lt;/p&gt;

&lt;p&gt;画像を読み込んで多クラス分類するNNを作る。
以下、今回使った関数の一部。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;シグモイド関数: &lt;code&gt;tf.sigmoid(x)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;エントロピーコスト: &lt;code&gt;tf.nn.sigmoid_cross_entropy_with_logits(logits, labels)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;One-hotエンコーディング: &lt;code&gt;tf.one_hot(labels, depth, axis)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;最急降下法: &lt;code&gt;tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CourseraのDeep Learning SpecializationのNeural Networks and Deep Learningコースを修了した</title>
          <link>https://www.kaitoy.xyz/2018/01/05/coursera-deep-learning-neural-networks-and-deep-learning/</link>
          <pubDate>Fri, 05 Jan 2018 15:20:23 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/01/05/coursera-deep-learning-neural-networks-and-deep-learning/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2017/12/22/coursera-machine-learning/&#34;&gt;CourseraのMachine Learningコース&lt;/a&gt;に続いて、同じくAndrew先生による&lt;a href=&#34;https://www.coursera.org/specializations/deep-learning&#34;&gt;Deep Learning Specialization&lt;/a&gt;を受講中。&lt;/p&gt;

&lt;p&gt;これは深層学習の基本を学べるもので、以下の5つのコースからなる。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Neural Networks and Deep Learning&lt;/li&gt;
&lt;li&gt;Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization&lt;/li&gt;
&lt;li&gt;Structuring Machine Learning Projects&lt;/li&gt;
&lt;li&gt;Convolutional Neural Networks&lt;/li&gt;
&lt;li&gt;Sequence Models&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;この内、最初のNeural Networks and Deep Learningを修了したので、記念にブログしておく。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;deep-learning-specializationとは&#34;&gt;Deep Learning Specializationとは&lt;/h1&gt;

&lt;p&gt;Deep Learning Specializationは&lt;a href=&#34;https://learner.coursera.help/hc/en-us/articles/208280296&#34;&gt;Coursera Specialization&lt;/a&gt;のひとつ。
Coursera Specializationはサブスクリプションモデルで、つまりあるSpecializationのサブスクリプションを購入すると、受講完了するまで毎月定額の料金を支払うことになる。&lt;/p&gt;

&lt;p&gt;Deep Learning Specializationは月$49で、5コース合わせて13週+α分の内容。
(Sequence Modelsが2018年1月に公開予定となっていて、現時点でまだ公開されていないので内容が不明。)
最初の7日間はトライアルで無料なので、この間に全部終わらせられればタダ。
無理だけど。&lt;/p&gt;

&lt;p&gt;Deep Learning Specializationでは、PythonとTensorFlowでディープニューラルネットワーク、CNN、RNN、LSTM、Adam、Dropout、バッチ正規化、Xavier/He initializationなどを学べる。
Machine Learningコースと同じく、5分～15分くらいの動画による講義と、小テストと、プログラミング課題から構成されている。&lt;/p&gt;

&lt;p&gt;プログラミング課題は、coursera hubという、ホステッドJupyter Notebookで解いて提出できるので楽。&lt;/p&gt;

&lt;h1 id=&#34;neural-networks-and-deep-learningコースとは&#34;&gt;Neural Networks and Deep Learningコースとは&lt;/h1&gt;

&lt;p&gt;ディープニューラルネットワークの仕組みを学んで実装する4週間のコース。
また、深層学習の偉い人へのインタビューを見れる。
Machine Learningコースと被っている内容が少なくなく、かなり楽だったが、結構ペースが速いので、Machine Learningコースをやっていなかったら辛かったと思う。&lt;/p&gt;

&lt;p&gt;動画は大抵日本語字幕が付いている。
日本語字幕が付いていない奴は、英語字幕が機械生成したっぽいもので見辛い。&lt;/p&gt;

&lt;p&gt;2018/1/1に始めて、1/5に完了。
5日間かかった。
修了したら&lt;a href=&#34;https://www.coursera.org/account/accomplishments/certificate/G77XMU9TNEKX&#34;&gt;Certifacate&lt;/a&gt;もらえた。&lt;/p&gt;

&lt;p&gt;以下、4週分の内容をキーワードレベルで書いておく。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;深層学習(Deep Learning)概要&lt;/p&gt;

&lt;p&gt;AIは次世代の電気。産業革命を起こす。
AIで今一番熱い分野が深層学習。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ニューラルネットワーク(Neural Network)。&lt;/li&gt;
&lt;li&gt;畳み込みニューラルネットワーク(CNN: Convolutional Neural Network)。&lt;/li&gt;
&lt;li&gt;再帰型ニューラルネットワーク(RNN: Recurrent Neural Network)。&lt;/li&gt;
&lt;li&gt;深層学習の適用分野・例。&lt;/li&gt;
&lt;li&gt;深層学習が実用化した背景。&lt;/li&gt;
&lt;li&gt;シグモイド関数(Sigmoid function) vs ReLU(Rectified Linear Unit)関数。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;深層学習のゴッドファーザー、Geoffrey Hintonへのインタビュー。&lt;/p&gt;

&lt;p&gt;ニューラルネットワークの黎明期を支え、ReLU関数の有効性を証明したりボルツマンマシンを発明したりした人。
自身が歩んできた深層学習の歴史や今取り組んでいる・注目している理論について、
高尚な話をしていたようだったが、高尚すぎてよくわからなかった。&lt;/p&gt;

&lt;p&gt;今日成果を出しているのは教師あり学習だけど、教師無し学習のほうが重要と考えているとのこと。&lt;/p&gt;

&lt;p&gt;これから機械学習に取り組む人へ、以下のアドバイスをしていた。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;文献を読みすぎるな。&lt;/li&gt;
&lt;li&gt;文献を読んで、間違っていると感じるところをみつけて、それに取り組め。&lt;/li&gt;
&lt;li&gt;人から何を言われても気にせず、自分の信念に従って研究しろ。&lt;/li&gt;
&lt;li&gt;誰かに無意味なことをしていると指摘されたら、むしろ価値のあることをしていると思え。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ニューラルネットワークプログラミングの基礎&lt;/p&gt;

&lt;p&gt;ロジスティック回帰は小さい(1層1ノード)ニューラルネットワーク。
ロジスティック回帰の微分を逆伝播で計算する。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;二値分類(Binary classification)、ロジスティック回帰(Logistic regression)。&lt;/li&gt;
&lt;li&gt;損失関数(Loss function)、交差エントロピー(Cross entropy)、目的関数(Cost function)。&lt;/li&gt;
&lt;li&gt;最急降下法(Gradient descent)。&lt;/li&gt;
&lt;li&gt;微分(Derivatives)。&lt;/li&gt;
&lt;li&gt;逆伝播(Backpropagation)、計算グラフ(Computation graph)、連鎖律(Chain rule)。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Pythonとベクトル化(Vectorization)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;forループ vs ベクトル化。&lt;/li&gt;
&lt;li&gt;Jupyter Notebook、NumPy、ブロードキャスト(Broadcasting)。&lt;/li&gt;
&lt;li&gt;ロジスティック回帰のベクトル化。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ロジスティック回帰で猫の画像の判別。&lt;/li&gt;
&lt;li&gt;NumPy、h5py、Matplotlib、PIL、SciPy。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;深層学習とロボットの研究者、Pieter Abbeelへのインタビュー&lt;/p&gt;

&lt;p&gt;深層強化学習の有名な研究者。DQN。&lt;/p&gt;

&lt;p&gt;かつて、機械学習で成果を出すためには、取り組んでいる課題特有の分野の知識が必要だったが、2012年にGeoffreyが発表したAlexNetがそれを覆した。
Pieterはそのアイデアを深層強化学習に適用し発展させた。&lt;/p&gt;

&lt;p&gt;強化学習は、どこからデータ収集するのか、報酬の分配はどうするかといったところに課題がある。
また、安全性にも課題。学習の過程で失敗を繰り返すので、自動運転などをどう学習させるか、またどう学び続けさせるか。
ネガティブデータを集めるのがむずい。&lt;/p&gt;

&lt;p&gt;短時間の実験でうまくいっても、長時間の稼働でうまくいくとも限らない。&lt;/p&gt;

&lt;p&gt;強化学習は複雑すぎるので、アルゴリズム自体を学習できるようにしたい。
プログラムを自動で変更しながら学習するなど。&lt;/p&gt;

&lt;p&gt;強化学習は、アルゴリズムを変更しなくても様々なことを学べる。
けど、ゼロから学ぶと時間がかかるので、以前学んだことを活かして次の課題に取り組めるようにするのが最先端の研究。&lt;/p&gt;

&lt;p&gt;まずは教師あり学習で人の代わりができるようになり、その後目的を与えて、強化学習で改善していく、っていう感じのことができるとうれしい。&lt;/p&gt;

&lt;p&gt;これから機械学習に取り組む人へ、以下のアドバイスをしていた。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;需要が高まっているので、AIを始めるにはよい時期。&lt;/li&gt;
&lt;li&gt;オンライン講座がたくさんあるので、学びやすい。自分で試したり再現したりしてみることが重要。&lt;/li&gt;
&lt;li&gt;TensorFlow、Chainer、Theano、PyTorchなど、手軽に試せるツールが色々ある。&lt;/li&gt;
&lt;li&gt;専門的な教育を受けなくても、自己学習でトップクラスになれる。&lt;/li&gt;
&lt;li&gt;機械学習を学ぶのに、大学で研究すべきか大企業で仕事を得るべきかについては、どれくらいの指導を受けれるかによる。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;3週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;浅いニューラルネットワーク&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ロジスティック回帰を多重にして2層のニューラルネットワーク化。&lt;/li&gt;
&lt;li&gt;ニューラルネットワークアルゴリズムのベクトル化。&lt;/li&gt;
&lt;li&gt;活性化関数(Activation function)の選択: シグモイド vs tanh vs ReLU vs Leaky ReLU vs 線形活性化関数(Linear activation function)。&lt;/li&gt;
&lt;li&gt;順伝播(Forward propagation)、逆伝播(Backpropagation)。&lt;/li&gt;
&lt;li&gt;ランダム初期化(Random initialization)。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;二値分類するニューラルネットワークを実装。&lt;/li&gt;
&lt;li&gt;scikit-learn。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;GAN(Generative Adversarial Network)の発明者、Ian Goodfellowへのインタビュー&lt;/p&gt;

&lt;p&gt;GANは生成モデル(学習したデータに似たデータを生成するモデル)。
バーで飲んでいるときに思いつき、一晩で実装した。&lt;/p&gt;

&lt;p&gt;GANは今は繊細過ぎるのが課題で、安定性の向上に今取り組んでいる。&lt;/p&gt;

&lt;p&gt;機械学習のセキュリティにも興味がある。モデルをだまして想定外の動作をさせるような攻撃への対策など。&lt;/p&gt;

&lt;p&gt;これから機械学習に取り組む人へ、以下のアドバイスをしていた。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;機械学習のアルゴリズムよりも、線形代数や確率といった数学の基礎を習得することが重要。&lt;/li&gt;
&lt;li&gt;AIの道を進むのに、近年では博士号は必ずしも要らない。コードを書いてGitHubに上げろ。自身も実際に、オープンソース活動をしているひとの貢献を見て興味をもって採用したことがある。&lt;/li&gt;
&lt;li&gt;論文を公開するとよりいいけど、コードのほうが楽。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;4週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;深いニューラルネットワーク&lt;/p&gt;

&lt;p&gt;3層以上のニューラルネットワーク。その実装方法と有効性について。
ハイパーパラメータ(Hyperparameters): 学習率(Learning rate)、学習回数、レイヤ数、ノード数、活性化関数、等。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ディープニューラルネットワークの実装。&lt;/li&gt;
&lt;li&gt;再度猫画像の判別。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CourseraのMachine Learningコースを修了した</title>
          <link>https://www.kaitoy.xyz/2017/12/22/coursera-machine-learning/</link>
          <pubDate>Fri, 22 Dec 2017 10:20:44 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/12/22/coursera-machine-learning/</guid>
          <description>

&lt;p&gt;機械学習の入門教材として有名な&lt;a href=&#34;https://www.coursera.org/learn/machine-learning&#34;&gt;CourseraのMachine Learningコース&lt;/a&gt;を修了した記念日記。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;courseraとは&#34;&gt;Courseraとは&lt;/h2&gt;

&lt;p&gt;Courseraは、2012年にスタンフォード大学のコンピュータ工学科の2人の教授によって設立されたサービスで、世界トップクラスの大学の講座をオンラインで受けることができるもの。
東京大学とも提携している。&lt;/p&gt;

&lt;p&gt;講座の一部は無料で受けることができる。&lt;/p&gt;

&lt;h2 id=&#34;courseraのmachine-learningコースとは&#34;&gt;CourseraのMachine Learningコースとは&lt;/h2&gt;

&lt;p&gt;Machine Learningコースは、Courseraの設立者の一人であるAndrew Ngによる、機械学習の基礎から実践まで浅く広く(?)学べる世界的に有名な講座。
Andrew先生は一時期Googleで働き、&lt;a href=&#34;https://en.wikipedia.org/wiki/Google_Brain&#34;&gt;Google Brain&lt;/a&gt;というDeep Learningのプロジェクトをリードしていたこともある機械学習のエキスパートで、さらにスタンフォードの教授だっただけあって教え方が非常にうまくてわかりやすい。&lt;/p&gt;

&lt;p&gt;この講座は主に、5分～15分くらいの動画による講義と、小テストと、プログラミング課題から構成されている。
1週間分の内容が、1.5時間分くらいの動画と、15分くらいでできる小テストと、2、3時間で終わるプログラミング課題で、全体で11週間分やれば修了できる。
1、10、11週目はプログラミング課題が無くてすぐ終わる一方、3～5週目辺りは結構ハード。&lt;/p&gt;

&lt;p&gt;私は2017/10/30に始めて、2017/12/19に完了したので、ちょうど50日かかったことになる。&lt;/p&gt;

&lt;p&gt;動画は当然英語だが、有志により英語や日本語の字幕が付けられてるので聞き取れなくても問題はあまりない。
ただ、1～4週目くらいまでは、日本語の字幕がずれている動画が少なくなく、それらは英語の字幕でみる必要がある。
1つだけ英語の字幕もダメなものがあって、それだけは字幕なしで見た。&lt;/p&gt;

&lt;p&gt;プログラミング課題は、&lt;a href=&#34;https://www.gnu.org/software/octave/&#34;&gt;Octave&lt;/a&gt;というオープンソースの数値解析言語で解く。
聞いたことない言語だったが、&lt;a href=&#34;https://jp.mathworks.com/programs/trials/trial_request.html?ref=ggl&amp;amp;s_eid=ppc_30300738322&amp;amp;q=matlab&#34;&gt;MATLAB&lt;/a&gt;との互換性維持を重視して開発されている言語なので、まあ覚えておいて損はない。
Octaveグラフ描画APIは、MATLABのグラフ描画APIをまねていて、MATLABのグラフ描画APIは、Pythonでよく使われるグラフ描画ライブラリである&lt;a href=&#34;https://matplotlib.org/&#34;&gt;Matplotlib&lt;/a&gt;がまねていて、つまりOctaveやってるとMatplotlibの勉強にもなる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以下、11週間分の内容を、キーワードレベルで書いておく。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;機械学習の概要&lt;/p&gt;

&lt;p&gt;背景、歴史、活用例。
教師あり学習(Supervised learning) vs 教師なし(Unsupervised learning)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;線形単回帰(Linear regression with one variable)&lt;/p&gt;

&lt;p&gt;仮説関数(Hypothesis)、目的関数(Cost function)、平均二乗誤差(Mean squared error)、最小二乗法(Least squares method)、最急降下法(Gradient descent)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;行列&lt;/p&gt;

&lt;p&gt;行列(Matrix)とベクトル(Vector)。
行列演算。
逆行列(Inverse)、転置行列(Transpose)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;線形重回帰(Linear regression with multiple variables)&lt;/p&gt;

&lt;p&gt;特徴量のスケーリング(Feature scaling)、平均正則化(Mean normalization)。
学習率(Learning rate)。
多項式回帰(Polynomial regression)。
正規方程式(Normal equation)、特異行列(singular matrix)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Octaveチュートリアル&lt;/p&gt;

&lt;p&gt;基本操作、データロード・セーブ、データ計算、描画、制御構文、ベクトル化。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;3週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ロジスティック回帰(Logistic regression)&lt;/p&gt;

&lt;p&gt;二値分類(Binary classification)。
シグモイド関数(Sigmoid function)。
決定境界(Decision boundary)。
共役勾配法(Conjugate gradient)、BFGS、L-BFGS。
多値分類(Multi-class classification)、1対その他(One-vs-all)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;過学習(Overfitting)&lt;/p&gt;

&lt;p&gt;正則化(Regularization)、未学習(Underfitting)。
バイアス(Bias)、バリアンス(Variance)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;4週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ニューラルネットワーク(Neural Network)&lt;/p&gt;

&lt;p&gt;入力層(Input layer)、隠れ層(Hidden layer)、出力層(Output layer)。
ユニット(Unit)、バイアスユニット(Bias unit)、重み(Weight)。
活性化関数(Activation function)。
順伝播(Forward propagation)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;5週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ニューラルネットワーク続き&lt;/p&gt;

&lt;p&gt;逆伝播(Backpropagation)。
Gradient checking。
対称性破壊(Symmetry breaking)、ランダム初期化(Random initialization)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;6週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;機械学習へのアドバイス&lt;/p&gt;

&lt;p&gt;訓練データ(Training set)、テストデータ(Test set)、交差検証データ(Cross-validation set)。
一般化エラー(Generalization error)。
高バイアス(High bias)、高バリアンス(High variance)。
学習曲線(Learning curve)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;機械学習システムの設計&lt;/p&gt;

&lt;p&gt;実装の優先度付け。
スパム分類器(Spam classifier)。
エラー分析(Error analysis)。
歪んだクラス(Skewed classes)。
真陽性(True positive)、偽陽性(False positive)、真陰性(True negative)、偽陰性(False negative)。
適合率(Precision)、再現率(Recall)、F値(F1 score)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;7週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;サポートベクタマシン(SVM: Support Vector Machine)&lt;/p&gt;

&lt;p&gt;マージン(Margin)。
線形カーネル(Linear kernel)、ガウスカーネル(Gaussian kernel)、多項式カーネル(Polynomial kernel)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;8週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;K平均法(K-means algorithm)&lt;/p&gt;

&lt;p&gt;クラスタリング(Clustering)。
ランダム初期化(Random initialization)、局所最適解(Local optima)。
エルボー法(Elbow method)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;主成分分析(PCA: Principal Component Analysis)&lt;/p&gt;

&lt;p&gt;データ圧縮(Data compression)、データ可視化(Data visualization)、次元削減(Dimensionality Reduction)、データ復元(Reconstruction from compressed representation)。
投影誤差(Projection error)、分散(Variance)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;9週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;異常検知(Anomaly detection)&lt;/p&gt;

&lt;p&gt;密度推定(Density estimation)。
ガウス分布(Gaussian distribution)、正規分布(Normal distribution)。
異常検知 vs 教師あり学習。
多変量ガウス分布(Multivariate gaussian distribution)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;レコメンダシステム(Recommender system)&lt;/p&gt;

&lt;p&gt;映画レーティング(Movie rating)。
コンテンツベース(Content-­based recommendation)、協調フィルタリング(Collaborative filtering)。
低ランク行列因子分解(Low-rank matrix factorization)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;10週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;大規模機械学習&lt;/p&gt;

&lt;p&gt;バッチ勾配降下法(Batch gradient descent)、確率的勾配降下法(Stochastic gradient descent)、ミニバッチ勾配降下法(Mini-batch gradient descent)。
オンライン学習(Online learning)。
Map­‐reduce、データ並列性(Data parallelism)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;11週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;写真OCR(Photo OCR)&lt;/p&gt;

&lt;p&gt;写真OCRパイプライン(Photo OCR pipeline)、テキスト検出(Text detection)、文字分割(character segmentation)、文字認識(character recognition)。
スライディングウィンドウ(Sliding window)。
人工データ合成(Artificial data synthesis)、歪曲収差(Distortion)。
天井分析(Ceiling analysis)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次は&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873117584/&#34;&gt;ゼロから作るDeep Learning&lt;/a&gt;かな。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetes 1.8のアクセス制御について。あとDashboard。</title>
          <link>https://www.kaitoy.xyz/2017/10/31/retry-dashboard-on-k8s-cluster-by-kubeadm/</link>
          <pubDate>Tue, 31 Oct 2017 16:57:04 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/10/31/retry-dashboard-on-k8s-cluster-by-kubeadm/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/21/build-kubernetes-cluster-by-kubeadm/&#34;&gt;Kubernetes1.8のクラスタを構築する。kubeadmで。&lt;/a&gt;」で、Dashboardがうまく動かない問題が発生したんだけど、それを解決した話。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;問題の現象&#34;&gt;問題の現象&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/kubeadm/&#34;&gt;kubeadm&lt;/a&gt;でKubernetesクラスタを組んで、自前のアプリ(&lt;a href=&#34;https://www.kaitoy.xyz/2016/12/11/goslings-development-memo0-intro-design/&#34;&gt;Goslings&lt;/a&gt;)のデプロイまではうまくできたんだけど、&lt;a href=&#34;https://github.com/kubernetes/dashboard&#34;&gt;Dashboard&lt;/a&gt;をデプロイしたら動かず、Web UIに&lt;code&gt;kubectl proxy&lt;/code&gt;経由でつないでもタイムアウトしてしまった。&lt;/p&gt;

&lt;h2 id=&#34;対策&#34;&gt;対策&lt;/h2&gt;

&lt;p&gt;なんとなく、クラスタ内部での名前解決には&lt;a href=&#34;https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/dns&#34;&gt;kube-dns&lt;/a&gt;によるDNSサービスが使われているっぽいので、&lt;code&gt;/etc/hosts&lt;/code&gt;に余計な事書いたのがいけなかったと思った。&lt;/p&gt;

&lt;p&gt;ので、&lt;code&gt;/etc/hosts&lt;/code&gt;からk8s-masterとk8s-nodeのエントリを削除してから、&lt;code&gt;kubeadm init&lt;/code&gt;からやり直してみた。&lt;/p&gt;

&lt;h2 id=&#34;結果&#34;&gt;結果&lt;/h2&gt;

&lt;p&gt;したらちゃんと動いた。&lt;/p&gt;

&lt;p&gt;VMのホストで&lt;code&gt;kubectl proxy&lt;/code&gt;して、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop&amp;gt;kubectl proxy
Starting to serve on 127.0.0.1:8001
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/&lt;/code&gt;にブラウザでつないだらサインイン画面が表示された。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/retry-dashboard-on-k8s-cluster-by-kubeadm/dashboard.png&#34; alt=&#34;dashboard&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Dashboardのサインイン処理はKubernetes(というかkube-apiserver)のそれに移譲している。
Dashboardはそこで認証されたユーザでクラスタのリソースにアクセスし、情報を取得して表示する。多分。&lt;/p&gt;

&lt;p&gt;Dashboardへのサインイン方法は&lt;a href=&#34;https://github.com/kubernetes/dashboard/wiki/Access-control&#34;&gt;いくつかある&lt;/a&gt;が、それらを理解するにはKubernetesのアクセス制御について学ぶことを推奨とあったのでちょっと&lt;a href=&#34;https://kubernetes.io/docs/admin/accessing-the-api/&#34;&gt;Kubernetesのドキュメント&lt;/a&gt;を読んだ。&lt;/p&gt;

&lt;h2 id=&#34;kubernetesのアクセス制御&#34;&gt;Kubernetesのアクセス制御&lt;/h2&gt;

&lt;p&gt;Kubernetesクラスタのエンドポイントはkube-apiserverであり、クラスタのリソースへのアクセス制御もkube-apiserverがやる。
クライアントとkube-apiserverとのTLSセッションが確立した後、HTTP層のデータを見てアクセス制御をするんだけど、その処理は&lt;a href=&#34;https://kubernetes.io/docs/admin/authentication/&#34;&gt;Authentication&lt;/a&gt;(認証)、&lt;a href=&#34;https://kubernetes.io/docs/admin/authorization/&#34;&gt;Authorization&lt;/a&gt;(認可)、&lt;a href=&#34;https://kubernetes.io/docs/admin/admission-controllers/&#34;&gt;Admission&lt;/a&gt;(許可)の三段階からなる。&lt;/p&gt;

&lt;h3 id=&#34;authentication&#34;&gt;Authentication&lt;/h3&gt;

&lt;p&gt;第一段階がAuthentication。
ここでは、kube-apiserverに仕込まれたAuthenticatorモジュールがユーザ認証をする。&lt;/p&gt;

&lt;p&gt;Kubernetesが認証するユーザには、Kubernetesが管理するService Accountと、クラスタ外部で管理される通常ユーザの二通りがある。
Service AccountはPodがkube-apiserverと話すためのユーザで、通常ユーザは主に人がkubectlとかでkube-apiserverと話すためのユーザ。(匿名で話すこともできる。)
前者はServiceAccountオブジェクトで定義されるけど、後者用のオブジェクトはない。&lt;/p&gt;

&lt;p&gt;ServiceAccountはNamespaceと関連付き(つまりnamespace毎にユニーク)、Secretに紐づく。
Secretオブジェクトはクレデンシャルのセットを定義し、Podにマウントされる。
ServiceAccountとSecretは、ふつうは自動で作られ、Podに割り当てられる。&lt;/p&gt;

&lt;p&gt;kube-apiserverには一つ以上のAuthenticatorモジュールを設定できて、どれかで認証できれば次の段階に進める。
認証失敗するとHTTPステータスコード401が返る。&lt;/p&gt;

&lt;p&gt;Authenticatorモジュールには以下のようなものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authentication/#x509-client-certs&#34;&gt;クライアント証明書&lt;/a&gt;: X.509のディジタル証明書を使うモジュール。kube-apiserver起動時に&lt;code&gt;--client-ca-file&lt;/code&gt;オプションで証明書ファイルを渡してやると有効になる。証明書のCommon Nameがユーザ名になり、Organizationがグループになる。クライアント側は、その証明書と対応する秘密鍵をクレデンシャルとして指定する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authentication/#putting-a-bearer-token-in-a-request&#34;&gt;Bearer Token&lt;/a&gt;: 無記名トークンを使うモジュール。kube-apiserver起動時に&lt;code&gt;--token-auth-file&lt;/code&gt;オプションでトークン情報を渡してやると有効になる。トークン情報はCSVで、「&lt;code&gt;token,user,uid,&amp;quot;group1,group2,group3&amp;quot;&lt;/code&gt;」という形式で書く。クライアント側は、トークン文字列をクレデンシャルとして指定する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authentication/#static-password-file&#34;&gt;ベーシック認証&lt;/a&gt;: ユーザ名とパスワードで認証するモジュール。kube-apiserver起動時に&lt;code&gt;--basic-auth-file&lt;/code&gt;オプションでユーザ名とパスワードのリストを渡してやると有効になる。このリストはCSVで、「&lt;code&gt;password,user,uid,&amp;quot;group1,group2,group3&amp;quot;&lt;/code&gt;」という形式で書く。クライアント側は、ユーザ名とパスワードをクレデンシャルとして指定する。HTTPクライアントの時はAuthorizationヘッダが使える。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authentication/#service-account-tokens&#34;&gt;Service Account Token&lt;/a&gt;: Service Accountを署名付きBearer Tokenで認証するモジュール。デフォルトで有効になる。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;このあたり、Qiitaの「&lt;a href=&#34;https://qiita.com/hiyosi/items/43465d4fc501c2044d01#x509-client-certs&#34;&gt;kubernetesがサポートする認証方法の全パターンを動かす&lt;/a&gt;」という記事をみると理解が深まる。&lt;/p&gt;

&lt;h3 id=&#34;authorization&#34;&gt;Authorization&lt;/h3&gt;

&lt;p&gt;Authenticationをパスすると、クライアントのユーザ(とグループ)が認証され、第二段階のAuthorizationモジュールの処理に移る。
ここでは、リクエストの内容(操作対象、操作種別(メソッド)等)を見て、それがユーザに許されたものなら認可する。
何を許すかは事前にクラスタにポリシーを定義しておく。&lt;/p&gt;

&lt;p&gt;kube-apiserver起動時に&lt;code&gt;--authorization-mode&lt;/code&gt;オプションで一つ以上のAuthenticatorモジュールを指定できて、どれかで認可されれば次の段階に進める。
さもなくばHTTPステータスコード403が返る。&lt;/p&gt;

&lt;p&gt;Authorizationモジュールには以下のようなものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authorization/node/&#34;&gt;Node&lt;/a&gt;: kubeletからのリクエストを認可する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authorization/abac/&#34;&gt;ABAC Mode&lt;/a&gt;: Attribute-based Access Control。リクエストに含まれる属性とPolicyオブジェクトを比較して、マッチするものがあれば認可。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authorization/rbac/&#34;&gt;RBAC Mode&lt;/a&gt;: Role-Based Access Control。RoleオブジェクトやClusterRoleオブジェクトでロールを作成し、アクセスできるリソースや許可する操作を定義して、RoleBindingオブジェクトやClusterRoleBindingオブジェクトでユーザ名やグループと紐づける。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authorization/webhook/&#34;&gt;Webhook Mode&lt;/a&gt;: リクエストの内容を示すSubjectAccessReviewオブジェクトをシリアライズしたJSONデータをHTTPでPOSTして、そのレスポンスによって認可可否を決める。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;admission-control&#34;&gt;Admission Control&lt;/h3&gt;

&lt;p&gt;Authorizationをパスすると、第三段階のAdmission Controlモジュールの処理に移る。
ここでは、オブジェクトの作成、削除、更新などのリクエストをインターセプトして、オブジェクトの永続化前にそのオブジェクトを確認して、永続化を許可するかを決める。
リクエストされたオブジェクトやそれに関連するオブジェクトを永続化前にいじって、デフォルト値を設定したりもできる。
読み取りリクエストの場合は実行されない。&lt;/p&gt;

&lt;p&gt;kube-apiserver起動時に&lt;code&gt;--admission-control&lt;/code&gt;オプションで複数のAdmission Controlモジュールを指定できて、全てが許可しないとリクエストが却下される。&lt;/p&gt;

&lt;p&gt;Admission Controlモジュールは色々あるんだけど、Kubernetes 1.6以降では&lt;code&gt;--admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,DefaultStorageClass,ResourceQuota,DefaultTolerationSeconds&lt;/code&gt;と指定するのが強く推奨されている。
ここで指定している&lt;a href=&#34;https://kubernetes.io/docs/admin/admission-controllers/#serviceaccount&#34;&gt;ServiceAccountモジュール&lt;/a&gt;は、kube-controller-managerに含まれるServiceAccountControllerとTokenControllerと協調し、Service Account周りの処理を&lt;a href=&#34;https://kubernetes.io/docs/admin/service-accounts-admin/#service-account-automation&#34;&gt;自動化&lt;/a&gt;してくれるもの。&lt;/p&gt;

&lt;p&gt;ServiceAccountControllerは、各Namespaceに&lt;code&gt;default&lt;/code&gt;という名前のService Accountを作る。&lt;/p&gt;

&lt;p&gt;ServiceAccountが作成されるとTokenControllerが動き、対応したSecretとトークンを生成して紐づける。&lt;/p&gt;

&lt;p&gt;ServiceAccountモジュールは、Podの作成や更新時に動き、以下の処理をする。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;PodにServiceAccountが設定されていなければ、&lt;code&gt;default&lt;/code&gt;を設定する。&lt;/li&gt;
&lt;li&gt;Podに設定されたServiceAccountが存在していることを確認し、存在していなければリクエストを却下する。&lt;/li&gt;
&lt;li&gt;PodがImagePullSecretsを含んでいなければ、ServiceAccountのImagePullSecretsをPodに追加する。&lt;/li&gt;
&lt;li&gt;トークンを含んだVolumeをPodに追加する。&lt;/li&gt;
&lt;li&gt;Pod内の各コンテナの&lt;code&gt;/var/run/secrets/kubernetes.io/serviceaccount&lt;/code&gt;にそのVolumeをマウントさせる。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;dashboardへbearer-tokenでサインイン&#34;&gt;DashboardへBearer Tokenでサインイン&lt;/h2&gt;

&lt;p&gt;Dashboardの話に戻る。
とりあえず&lt;a href=&#34;https://github.com/kubernetes/dashboard/wiki/Access-control#bearer-token&#34;&gt;Bearer Tokenでのサインイン&lt;/a&gt;を試す。&lt;/p&gt;

&lt;p&gt;クラスタにはデフォルトで色んなService Accountが作られていて、異なる権限を持っている。
そのいずれかのSecretのTokenを使ってDashboardへサインインできるらしい。&lt;/p&gt;

&lt;p&gt;以下のコマンドで&lt;code&gt;kube-system&lt;/code&gt;というNamespaceのSecretを一覧できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl -n kube-system get secret
NAME                                     TYPE                                  DATA      AGE
attachdetach-controller-token-skzmj      kubernetes.io/service-account-token   3         18m
bootstrap-signer-token-mhqfh             kubernetes.io/service-account-token   3         18m
bootstrap-token-2964e0                   bootstrap.kubernetes.io/token         7         18m
certificate-controller-token-fvrgm       kubernetes.io/service-account-token   3         18m
cronjob-controller-token-hmrdm           kubernetes.io/service-account-token   3         18m
daemon-set-controller-token-vqz85        kubernetes.io/service-account-token   3         18m
default-token-h987g                      kubernetes.io/service-account-token   3         18m
deployment-controller-token-86bp9        kubernetes.io/service-account-token   3         18m
disruption-controller-token-6mskg        kubernetes.io/service-account-token   3         18m
endpoint-controller-token-d4wz6          kubernetes.io/service-account-token   3         18m
generic-garbage-collector-token-smfgq    kubernetes.io/service-account-token   3         18m
horizontal-pod-autoscaler-token-wsbn9    kubernetes.io/service-account-token   3         18m
job-controller-token-fttt2               kubernetes.io/service-account-token   3         18m
kube-dns-token-sn5qq                     kubernetes.io/service-account-token   3         18m
kube-proxy-token-w96xd                   kubernetes.io/service-account-token   3         18m
kubernetes-dashboard-certs               Opaque                                2         7m
kubernetes-dashboard-key-holder          Opaque                                2         6m
kubernetes-dashboard-token-gtppc         kubernetes.io/service-account-token   3         7m
namespace-controller-token-5kksd         kubernetes.io/service-account-token   3         18m
node-controller-token-chpwt              kubernetes.io/service-account-token   3         18m
persistent-volume-binder-token-d5x49     kubernetes.io/service-account-token   3         18m
pod-garbage-collector-token-l8sct        kubernetes.io/service-account-token   3         18m
replicaset-controller-token-njjwr        kubernetes.io/service-account-token   3         18m
replication-controller-token-qrr5h       kubernetes.io/service-account-token   3         18m
resourcequota-controller-token-dznjm     kubernetes.io/service-account-token   3         18m
service-account-controller-token-99nh8   kubernetes.io/service-account-token   3         18m
service-controller-token-9cw7k           kubernetes.io/service-account-token   3         18m
statefulset-controller-token-8z8w9       kubernetes.io/service-account-token   3         18m
token-cleaner-token-cxbkc                kubernetes.io/service-account-token   3         18m
ttl-controller-token-k7gh7               kubernetes.io/service-account-token   3         18m
weave-net-token-lqdgm                    kubernetes.io/service-account-token   3         17m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、適当にそれっぽいSecret、&lt;code&gt;deployment-controller-token-86bp9&lt;/code&gt;を選んで、&lt;code&gt;kubectl describe&lt;/code&gt;したらTokenが見れた。
(Dataセクションの&lt;code&gt;token&lt;/code&gt;のとこ。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl -n kube-system describe secret deployment-controller-token-86bp9
Name:         deployment-controller-token-86bp9
Namespace:    kube-system
Labels:       &amp;lt;none&amp;gt;
Annotations:  kubernetes.io/service-account.name=deployment-controller
              kubernetes.io/service-account.uid=17fc5207-b627-11e7-9867-000c2938deae

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkZXBsb3ltZW50LWNvbnRyb2xsZXItdG9rZW4tODZicDkiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGVwbG95bWVudC1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMTdmYzUyMDctYjYyNy0xMWU3LTk4NjctMDAwYzI5MzhkZWFlIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRlcGxveW1lbnQtY29udHJvbGxlciJ9.ZGV9XDd-GQjAwRuLKpdsWL_dTeF0Mr_2gF117OW4BhEuLwPujnsfOuysAQ-DUtNOp1NHKGitlfxjh6fKo4tFsdwLVJWrRK6i4YH1Mm2No7Sheks7IQn1FnwSmr7yCuvjlHD2e4RpZH0wupOFoY7FHntilhOWbXTJzJzi7TozLX02EKbkVGAsvch3LZ6p8jmUH5hr8DdKc4jbmTRp86SOiFS4_-TJ3RtAHCxiioAuKzXm3-rAWdeGLLcKrM2pAFSAGaBNu8MO5BZlAi6h3Xt4x-8-1ZXs4mudtJiECvjB-XIwiwzhpq8wIPZvvQQ-f1khixOyk1RfIXRJhIE5Gqvi8g
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;サインイン画面でTokenを選択し、
この、&lt;code&gt;eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkZXBsb3ltZW50LWNvbnRyb2xsZXItdG9rZW4tODZicDkiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGVwbG95bWVudC1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMTdmYzUyMDctYjYyNy0xMWU3LTk4NjctMDAwYzI5MzhkZWFlIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRlcGxveW1lbnQtY29udHJvbGxlciJ9.ZGV9XDd-GQjAwRuLKpdsWL_dTeF0Mr_2gF117OW4BhEuLwPujnsfOuysAQ-DUtNOp1NHKGitlfxjh6fKo4tFsdwLVJWrRK6i4YH1Mm2No7Sheks7IQn1FnwSmr7yCuvjlHD2e4RpZH0wupOFoY7FHntilhOWbXTJzJzi7TozLX02EKbkVGAsvch3LZ6p8jmUH5hr8DdKc4jbmTRp86SOiFS4_-TJ3RtAHCxiioAuKzXm3-rAWdeGLLcKrM2pAFSAGaBNu8MO5BZlAi6h3Xt4x-8-1ZXs4mudtJiECvjB-XIwiwzhpq8wIPZvvQQ-f1khixOyk1RfIXRJhIE5Gqvi8g&lt;/code&gt;を入力したらサインインできて、GoslingsのDeploymentの情報が見れた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/retry-dashboard-on-k8s-cluster-by-kubeadm/deploy.png&#34; alt=&#34;deploy&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Podも見れる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/retry-dashboard-on-k8s-cluster-by-kubeadm/pods.png&#34; alt=&#34;pods&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;けどServiceは見れない。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/retry-dashboard-on-k8s-cluster-by-kubeadm/service.png&#34; alt=&#34;service&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;各画面でオレンジ色のワーニングも出ていて、&lt;code&gt;deployment-controller&lt;/code&gt;ユーザで見れる範囲はあまり広くないことが分かる。&lt;/p&gt;

&lt;h2 id=&#34;dashboardへadmin権限でサインイン&#34;&gt;DashboardへAdmin権限でサインイン&lt;/h2&gt;

&lt;p&gt;DashboardのPodのService Accountである&lt;code&gt;kubernetes-dashboard&lt;/code&gt;にAdmin権限を付けてやって、サインイン画面でSKIPを押すとなんでも見れるようになる。セキュリティリスクがあるので本番ではNG設定だけど。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;cluster-admin&lt;/code&gt;というClusterRoleがあって、これを&lt;code&gt;kubernetes-dashboard&lt;/code&gt;にバインドするClusterRoleBindingを作ってやればいい。&lt;/p&gt;

&lt;p&gt;ので、以下のようなYAMLファイルを書いて、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: kubernetes-dashboard
  labels:
    k8s-app: kubernetes-dashboard
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: kubernetes-dashboard
  namespace: kube-system
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;kubectl&lt;/code&gt;で投げる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop&amp;gt;kubectl create -f dashboard-admin.yml
clusterrolebinding &amp;quot;kubernetes-dashboard&amp;quot; created
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;したらServiceも見えるようになった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/retry-dashboard-on-k8s-cluster-by-kubeadm/service-admin.png&#34; alt=&#34;service-admin&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ついでにHWリソース情報も見れた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/retry-dashboard-on-k8s-cluster-by-kubeadm/resources.png&#34; alt=&#34;resources&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;満足した。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetes1.8のクラスタを構築する。kubeadmで。</title>
          <link>https://www.kaitoy.xyz/2017/10/21/build-kubernetes-cluster-by-kubeadm/</link>
          <pubDate>Sat, 21 Oct 2017 10:42:46 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/10/21/build-kubernetes-cluster-by-kubeadm/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/&#34;&gt;Kubernetes 1.8が出たので、Minikubeを触ってみる&lt;/a&gt;」でMinikubeをやったんだけど、もう一歩ステップアップすべく、&lt;a href=&#34;https://kubernetes.io/docs/admin/kubeadm/&#34;&gt;kubeadm&lt;/a&gt;でKubernetesクラスタを組んでみた話。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;kubeadmとは&#34;&gt;kubeadmとは&lt;/h2&gt;

&lt;p&gt;kubeadm(キューブアダム)はKubernetesに含まれるコマンドで、Kubernetesクラスタを簡単に構築するツール。
Kubernetes 1.4で追加され、Kubernetes 1.8の時点でまだベータで、本番環境には使わないでとなっている。
Qiitaの「&lt;a href=&#34;https://qiita.com/helix_kaz/items/9c4a83532f949d8a94ef&#34;&gt;kubeadmが何をやっているのかみてみた&lt;/a&gt;」という記事が、中でどんな動作をしてるかを解説していて参考になる。&lt;/p&gt;

&lt;p&gt;コマンドの使用感からすると、&lt;a href=&#34;https://docs.docker.com/engine/swarm/&#34;&gt;DockerのSwarmモード&lt;/a&gt;でのクラスタ構築の容易さをKubernetesに取り込むことを目指して開発されている気がした。&lt;/p&gt;

&lt;p&gt;ネットで見かけた評判だと、確かに簡単にクラスタ構築できて素晴らしいけど、TLSの証明書生成など、細かく制御できなくて困るところがあって、やはり本番に使えるレベルではないとのこと。&lt;/p&gt;

&lt;p&gt;まあとにかく試してみる価値はあろう。&lt;/p&gt;

&lt;h2 id=&#34;kubeadmインストール&#34;&gt;kubeadmインストール&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/setup/independent/install-kubeadm/&#34;&gt;Kubernetesのドキュメント&lt;/a&gt;に従ってkubeadmをインストールする。
バージョンは最新版の1.8.1。&lt;/p&gt;

&lt;h3 id=&#34;vm作成&#34;&gt;VM作成&lt;/h3&gt;

&lt;p&gt;kubeadmのサポートOSは、Ubuntu 16.04+、Debian 9、CentOS 7、RHEL 7、Fedora 25/26、HypriotOS v1.0.1+となっている。
慣れているCentOS 7を使うことにする。
(HypriotOSってなんだろう?)&lt;/p&gt;

&lt;p&gt;自前のノートPCのWindows 10 x64 Home Edition上のVMware Player 12のVMにCentOS 7を入れた。
メモリは1GB以上が要件なので、味を付けて1.4GBで。
VM間で通信できることって要件があったけど、インターネット接続も必要なはずなので、NICはNATのやつで。&lt;/p&gt;

&lt;p&gt;このVMはMasterになる。&lt;/p&gt;

&lt;h3 id=&#34;os設定&#34;&gt;OS設定&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/setup/independent/install-kubeadm/#check-required-ports&#34;&gt;Kubernetesが使うポート&lt;/a&gt;をいろいろ開けなければいけないんだけど、めんどいのでfirewalldを無効にする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@localhost ~]# systemctl stop firewalld
[root@localhost ~]# systemctl disable firewalld
Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.
Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;なんとなくIPアドレスをDHCPから静的割り当てに。(192.168.171.200)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# nmcli c modify ens33 ipv4.method manual
[root@k8s-master ~]# nmcli c modify ens33 ipv4.addresses 192.168.171.200/24
[root@k8s-master ~]# nmcli c modify ens33 ipv4.dns 192.168.171.2
[root@k8s-master ~]# nmcli c modify ens33 ipv4.gateway 192.168.171.2
[root@k8s-master ~]# systemctl restart network
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ホスト名をlocalhost.localdomainからk8s-masterに変更。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@localhost ~]# hostnamectl set-hostname k8s-master
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ログアウトログインで反映。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/etc/hosts&lt;/code&gt;を編集して、k8s-masterのエントリを追加。
あとで作るもう一つのVM、k8s-nodeのほうもエントリを追加。
(これはだめだったっぽい。詳細は後述。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;クラスタを構成するノードは、一意のMACアドレスとproduct_uuidを持っていないといけない。
Kubernetesがそれらでクラスタ内のノードを区別してるので。&lt;/p&gt;

&lt;p&gt;MACアドレスは&lt;code&gt;ip link&lt;/code&gt;コマンドなどで確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# ip link
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT qlen 1
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: ens33: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT qlen 1000
    link/ether 00:0c:29:38:de:ae brd ff:ff:ff:ff:ff:ff
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;product_uuidは、&lt;a href=&#34;https://ja.wikipedia.org/wiki/SMBIOS&#34;&gt;SMBIOS&lt;/a&gt;という、PC固有のデータを保存・参照するための仕様があって、それに従って保存されたシステムの識別子らしい。
product_uuidは&lt;code&gt;dmidecode&lt;/code&gt;コマンドなどで確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# dmidecode -s system-uuid
58114D56-A744-3610-C3C5-9B15A838DEAE
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;kubeletがちゃんと動くためにはswapを無効にする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# swapoff -a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(このコマンドはよくなかった。詳細は後述。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ebtablesとethtoolを入れる必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# yum install -y ebtables ethtool
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Dockerも入れないと。
v1.12が推奨で、v1.11かv1.13でもいい。
適当に入れたらv1.12.6だった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# yum install -y docker
[root@k8s-master ~]# systemctl enable docker &amp;amp;&amp;amp; systemctl start docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Podネットワークなどが機能する要件として、コンテナがホストファイルシステムにアクセスできる必要があるが、そのためには現状、SELinuxを無効化する必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# setenforce 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(このコマンドもよくなかった。詳細は後述。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;RHEL系の場合、iptablesがバイパスされてトラフィックが変にルーティングされる問題があるため、&lt;code&gt;net.bridge.bridge-nf-call-iptables&lt;/code&gt;を1にセットしておく必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# cat &amp;lt;&amp;lt;EOF &amp;gt;  /etc/sysctl.d/k8s.conf
&amp;gt; net.bridge.bridge-nf-call-ip6tables = 1
&amp;gt; net.bridge.bridge-nf-call-iptables = 1
&amp;gt; EOF
[root@k8s-master ~]# sysctl --system
* Applying /usr/lib/sysctl.d/00-system.conf ...
net.bridge.bridge-nf-call-ip6tables = 0
net.bridge.bridge-nf-call-iptables = 0
net.bridge.bridge-nf-call-arptables = 0
* Applying /usr/lib/sysctl.d/10-default-yama-scope.conf ...
kernel.yama.ptrace_scope = 0
* Applying /usr/lib/sysctl.d/50-default.conf ...
kernel.sysrq = 16
kernel.core_uses_pid = 1
net.ipv4.conf.default.rp_filter = 1
net.ipv4.conf.all.rp_filter = 1
net.ipv4.conf.default.accept_source_route = 0
net.ipv4.conf.all.accept_source_route = 0
net.ipv4.conf.default.promote_secondaries = 1
net.ipv4.conf.all.promote_secondaries = 1
fs.protected_hardlinks = 1
fs.protected_symlinks = 1
* Applying /usr/lib/sysctl.d/99-docker.conf ...
fs.may_detach_mounts = 1
* Applying /etc/sysctl.d/99-sysctl.conf ...
* Applying /etc/sysctl.d/k8s.conf ...
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
* Applying /etc/sysctl.conf ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Cgroup Driverを、Dockerとkubeletとの間で一致させておく必要がある。
以下のようにして確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# cat /etc/systemd/system/kubelet.service.d/10-kubeadm.conf | grep KUBELET_CGROUP_ARGS
Environment=&amp;quot;KUBELET_CGROUP_ARGS=--cgroup-driver=systemd&amp;quot;
ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_SYSTEM_PODS_ARGS $KUBELET_NETWORK_ARGS $KUBELET_DNS_ARGS $KUBELET_AUTHZ_ARGS $KUBELET_CADVISOR_ARGS $KUBELET_CGROUP_ARGS $KUBELET_CERTIFICATE_ARGS $KUBELET_EXTRA_ARGS
[root@k8s-master ~]# docker info |grep -i cgroup
 WARNING: Usage of loopback devices is strongly discouraged for production use. Use `--storage-opt dm.thinpooldev` to specify a custom block storage device.
Cgroup Driver: systemd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;どっちもsystemdだったので問題なし。
(違ってたら&lt;a href=&#34;https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#troubleshooting&#34;&gt;&lt;code&gt;KUBELET_CGROUP_ARGS&lt;/code&gt;を変更する必要がある&lt;/a&gt;。)&lt;/p&gt;

&lt;h3 id=&#34;kubelet-kubeadm-kubectlインストール&#34;&gt;kubelet、kubeadm、kubectlインストール&lt;/h3&gt;

&lt;p&gt;ここでやっとkubeadmのインストール。
kubeletとkubectlも一緒にインストールする。&lt;/p&gt;

&lt;p&gt;まずYUMリポジトリを追加して、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/yum.repos.d/kubernetes.repo
&amp;gt; [kubernetes]
&amp;gt; name=Kubernetes
&amp;gt; baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
&amp;gt; enabled=1
&amp;gt; gpgcheck=1
&amp;gt; repo_gpgcheck=1
&amp;gt; gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
&amp;gt;         https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
&amp;gt; EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;インストール。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# yum install kubelet kubeadm kubectl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、kubeletをサービス登録。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# systemctl enable kubelet &amp;amp;&amp;amp; systemctl start kubelet
Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /etc/systemd/system/kubelet.service.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ここでVMのスナップショットをとっておいて、後でNodeを追加するときに使う。&lt;/p&gt;

&lt;h2 id=&#34;master構築&#34;&gt;Master構築&lt;/h2&gt;

&lt;p&gt;Masterは&lt;code&gt;kubeadm init&lt;/code&gt;で構築できる。
&lt;code&gt;--apiserver-advertise-address&lt;/code&gt;でkube-apiserverがlistenするIPアドレスを指定すべし。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubeadm init --apiserver-advertise-address=192.168.171.200
[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
[init] Using Kubernetes version: v1.8.1
[init] Using Authorization modes: [Node RBAC]
[preflight] Running pre-flight checks
[preflight] WARNING: Running with swap on is not supported. Please disable swap or set kubelet&#39;s --fail-swap-on flag to false.
[kubeadm] WARNING: starting in 1.8, tokens expire after 24 hours by default (if you require a non-expiring token use --token-ttl 0)
[certificates] Generated ca certificate and key.
[certificates] Generated apiserver certificate and key.
[certificates] apiserver serving cert is signed for DNS names [k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.171.200]
[certificates] Generated apiserver-kubelet-client certificate and key.
[certificates] Generated sa key and public key.
[certificates] Generated front-proxy-ca certificate and key.
[certificates] Generated front-proxy-client certificate and key.
[certificates] Valid certificates and keys now exist in &amp;quot;/etc/kubernetes/pki&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;admin.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;kubelet.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;controller-manager.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;scheduler.conf&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-apiserver to &amp;quot;/etc/kubernetes/manifests/kube-apiserver.yaml&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-controller-manager to &amp;quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-scheduler to &amp;quot;/etc/kubernetes/manifests/kube-scheduler.yaml&amp;quot;
[etcd] Wrote Static Pod manifest for a local etcd instance to &amp;quot;/etc/kubernetes/manifests/etcd.yaml&amp;quot;
[init] Waiting for the kubelet to boot up the control plane as Static Pods from directory &amp;quot;/etc/kubernetes/manifests&amp;quot;
[init] This often takes around a minute; or longer if the control plane images have to be pulled.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz&#39; failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz&#39; failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz&#39; failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz/syncloop&#39; failed with error: Get http://localhost:10255/healthz/syncloop: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz/syncloop&#39; failed with error: Get http://localhost:10255/healthz/syncloop: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz/syncloop&#39; failed with error: Get http://localhost:10255/healthz/syncloop: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz&#39; failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz/syncloop&#39; failed with error: Get http://localhost:10255/healthz/syncloop: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz&#39; failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.

Unfortunately, an error has occurred:
        timed out waiting for the condition

This error is likely caused by that:
        - The kubelet is not running
        - The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)
        - There is no internet connection; so the kubelet can&#39;t pull the following control plane images:
                - gcr.io/google_containers/kube-apiserver-amd64:v1.8.1
                - gcr.io/google_containers/kube-controller-manager-amd64:v1.8.1
                - gcr.io/google_containers/kube-scheduler-amd64:v1.8.1

You can troubleshoot this for example with the following commands if you&#39;re on a systemd-powered system:
        - &#39;systemctl status kubelet&#39;
        - &#39;journalctl -xeu kubelet&#39;
couldn&#39;t initialize a Kubernetes cluster
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なんか失敗した。
&lt;code&gt;getsockopt: connection refused.&lt;/code&gt;ってのがたくさん出てる。
ググると、swapがあやしい。
確認してみたら、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# swapon -s
Filename                                Type            Size    Used    Priority
/dev/dm-1                               partition       2097148 0       -1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;無効になってない。
&lt;code&gt;swapoff -a&lt;/code&gt;でswap無効にしても、OS再起動したらもとに戻ってしまうのか。&lt;/p&gt;

&lt;p&gt;永続的に無効にするため、&lt;code&gt;/etc/fstab&lt;/code&gt;を編集して、以下の行を削除した。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;/dev/mapper/centos-swap swap                    swap    defaults        0 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、OSリブート。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;kubeadm initをやり直す前に、いったん&lt;code&gt;kubeadm reset&lt;/code&gt;して初期化する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubeadm reset
[preflight] Running pre-flight checks
[reset] Stopping the kubelet service
[reset] Unmounting mounted directories in &amp;quot;/var/lib/kubelet&amp;quot;
[reset] Removing kubernetes-managed containers
[reset] Deleting contents of stateful directories: [/var/lib/kubelet /etc/cni/net.d /var/lib/dockershim /var/run/kubernetes /var/lib/etcd]
[reset] Deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki]
[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;2回目の&lt;code&gt;kubeadm init&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubeadm init --apiserver-advertise-address=192.168.171.200
[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
[init] Using Kubernetes version: v1.8.1
[init] Using Authorization modes: [Node RBAC]
[preflight] Running pre-flight checks
[preflight] Starting the kubelet service
[kubeadm] WARNING: starting in 1.8, tokens expire after 24 hours by default (if you require a non-expiring token use --token-ttl 0)
[certificates] Generated ca certificate and key.
[certificates] Generated apiserver certificate and key.
[certificates] apiserver serving cert is signed for DNS names [k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.171.200]
[certificates] Generated apiserver-kubelet-client certificate and key.
[certificates] Generated sa key and public key.
[certificates] Generated front-proxy-ca certificate and key.
[certificates] Generated front-proxy-client certificate and key.
[certificates] Valid certificates and keys now exist in &amp;quot;/etc/kubernetes/pki&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;admin.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;kubelet.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;controller-manager.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;scheduler.conf&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-apiserver to &amp;quot;/etc/kubernetes/manifests/kube-apiserver.yaml&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-controller-manager to &amp;quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-scheduler to &amp;quot;/etc/kubernetes/manifests/kube-scheduler.yaml&amp;quot;
[etcd] Wrote Static Pod manifest for a local etcd instance to &amp;quot;/etc/kubernetes/manifests/etcd.yaml&amp;quot;
[init] Waiting for the kubelet to boot up the control plane as Static Pods from directory &amp;quot;/etc/kubernetes/manifests&amp;quot;
[init] This often takes around a minute; or longer if the control plane images have to be pulled.

Unfortunately, an error has occurred:
        timed out waiting for the condition

This error is likely caused by that:
        - The kubelet is not running
        - The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)
        - There is no internet connection; so the kubelet can&#39;t pull the following control plane images:
                - gcr.io/google_containers/kube-apiserver-amd64:v1.8.1
                - gcr.io/google_containers/kube-controller-manager-amd64:v1.8.1
                - gcr.io/google_containers/kube-scheduler-amd64:v1.8.1

You can troubleshoot this for example with the following commands if you&#39;re on a systemd-powered system:
        - &#39;systemctl status kubelet&#39;
        - &#39;journalctl -xeu kubelet&#39;
couldn&#39;t initialize a Kubernetes cluster
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また違う感じのエラー。
エラーメッセージに従って、&lt;code&gt;journalctl -xeu kubelet&lt;/code&gt;でログを見てみたら、以下のようなエラーが。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Post https://192.168.171.200:6443/api/v1/nodes: dial tcp 192.168.171.200:6443: getsockopt: connection refused
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/kubeadm/issues/228&#34;&gt;kubeadmにIssue&lt;/a&gt;にこのエラーが載っている。
原因はいろいろあるっぽいけど、そのひとつにSELinuxがあったので確認してみたら、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# getenforce
Enforcing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SELinuxが有効になっていた。
&lt;code&gt;setenforce 0&lt;/code&gt;もOS再起動で元に戻ってしまった模様。&lt;/p&gt;

&lt;p&gt;永続的にSELinuxを無効にするため、&lt;code&gt;/etc/selinux/config&lt;/code&gt;を編集して、&lt;code&gt;SELINUX&lt;/code&gt;を&lt;code&gt;disabled&lt;/code&gt;にして、OS再起動した。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、&lt;code&gt;kubeadm reset&lt;/code&gt;したら3回目の&lt;code&gt;kubeadm init&lt;/code&gt;する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubeadm init --apiserver-advertise-address=192.168.171.200
[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
[init] Using Kubernetes version: v1.8.1
[init] Using Authorization modes: [Node RBAC]
[preflight] Running pre-flight checks
[kubeadm] WARNING: starting in 1.8, tokens expire after 24 hours by default (if you require a non-expiring token use --token-ttl 0)
[certificates] Generated ca certificate and key.
[certificates] Generated apiserver certificate and key.
[certificates] apiserver serving cert is signed for DNS names [k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.171.200]
[certificates] Generated apiserver-kubelet-client certificate and key.
[certificates] Generated sa key and public key.
[certificates] Generated front-proxy-ca certificate and key.
[certificates] Generated front-proxy-client certificate and key.
[certificates] Valid certificates and keys now exist in &amp;quot;/etc/kubernetes/pki&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;admin.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;kubelet.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;controller-manager.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;scheduler.conf&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-apiserver to &amp;quot;/etc/kubernetes/manifests/kube-apiserver.yaml&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-controller-manager to &amp;quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-scheduler to &amp;quot;/etc/kubernetes/manifests/kube-scheduler.yaml&amp;quot;
[etcd] Wrote Static Pod manifest for a local etcd instance to &amp;quot;/etc/kubernetes/manifests/etcd.yaml&amp;quot;
[init] Waiting for the kubelet to boot up the control plane as Static Pods from directory &amp;quot;/etc/kubernetes/manifests&amp;quot;
[init] This often takes around a minute; or longer if the control plane images have to be pulled.
[apiclient] All control plane components are healthy after 99.510003 seconds
[uploadconfig]?Storing the configuration used in ConfigMap &amp;quot;kubeadm-config&amp;quot; in the &amp;quot;kube-system&amp;quot; Namespace
[markmaster] Will mark node k8s-master as master by adding a label and a taint
[markmaster] Master k8s-master tainted and labelled with key/value: node-role.kubernetes.io/master=&amp;quot;&amp;quot;
[bootstraptoken] Using token: 957b7b.eaaf0cb656edba7b
[bootstraptoken] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstraptoken] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstraptoken] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstraptoken] Creating the &amp;quot;cluster-info&amp;quot; ConfigMap in the &amp;quot;kube-public&amp;quot; namespace
[addons] Applied essential addon: kube-dns
[addons] Applied essential addon: kube-proxy

Your Kubernetes master has initialized successfully!

To start using your cluster, you need to run (as a regular user):

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run &amp;quot;kubectl apply -f [podnetwork].yaml&amp;quot; with one of the options listed at:
  http://kubernetes.io/docs/admin/addons/

You can now join any number of machines by running the following on each node
as root:

  kubeadm join --token 957b7b.eaaf0cb656edba7b 192.168.171.200:6443 --discovery-token-ca-cert-hash sha256:7d16ade2b651ebac573368b1b4db5c0f1236979584e61833efe90a96ff34ae2e
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できた。
このメッセージの最後に書かれたコマンドを、後でNodeを追加するときに使う。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;kubectlがこのVM上のkube-apiserverと話せるように、コンテキストを設定する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# mkdir -p $HOME/.kube
[root@k8s-master ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
[root@k8s-master ~]# chown $(id -u):$(id -g) $HOME/.kube/config
[root@k8s-master ~]# kubectl get nodes
NAME         STATUS     ROLES     AGE       VERSION
k8s-master   NotReady   master    16m       v1.8.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;podネットワークアドオンインストール&#34;&gt;Podネットワークアドオンインストール&lt;/h3&gt;

&lt;p&gt;Podネットワークはアプリのデプロイの前にセットアップしておく必要がある。&lt;/p&gt;

&lt;p&gt;多くの選択肢があるなか、有名な&lt;a href=&#34;https://github.com/coreos/flannel&#34;&gt;Flannel&lt;/a&gt;にしようと思ったけど、Flannelを使うには
&lt;code&gt;kubeadm init&lt;/code&gt;時に&lt;code&gt;--pod-network-cidr=10.244.0.0/16&lt;/code&gt;を渡さないといけなかった。
やり直すのは面倒なので代わりに&lt;a href=&#34;https://www.weave.works/docs/net/latest/kube-addon/&#34;&gt;Weave Net&lt;/a&gt;にする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# export kubever=$(kubectl version | base64 | tr -d &#39;\n&#39;)
[root@k8s-master ~]# kubectl apply -f &amp;quot;https://cloud.weave.works/k8s/net?k8s-version=$kubever&amp;quot;
serviceaccount &amp;quot;weave-net&amp;quot; created
clusterrole &amp;quot;weave-net&amp;quot; created
clusterrolebinding &amp;quot;weave-net&amp;quot; created
daemonset &amp;quot;weave-net&amp;quot; created
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これでPodネットワークアドオンインストール完了。
しばらくして、&lt;code&gt;kube-dns&lt;/code&gt;のPodが起動していれば(i.e. STATUSがRunningになってれば)OK。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubectl get pods --all-namespaces
NAMESPACE     NAME                                 READY     STATUS    RESTARTS   AGE
kube-system   etcd-k8s-master                      1/1       Running   0          1m
kube-system   kube-apiserver-k8s-master            1/1       Running   0          1m
kube-system   kube-controller-manager-k8s-master   1/1       Running   0          1m
kube-system   kube-dns-545bc4bfd4-xtlnh            3/3       Running   0          6m
kube-system   kube-proxy-922wk                     1/1       Running   0          6m
kube-system   kube-scheduler-k8s-master            1/1       Running   0          1m
kube-system   weave-net-s2kkw                      2/2       Running   0          2m
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;masterにpodをデプロイさせる設定&#34;&gt;MasterにPodをデプロイさせる設定&lt;/h3&gt;

&lt;p&gt;デフォルトでは、セキュリティの都合でMasterコンポーネントが動くNodeにはPodがデプロイされない。
けど、VM2個でPodを分散デプロイしてみたいので、この縛りを外しておく。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubectl taint nodes --all node-role.kubernetes.io/master-
node &amp;quot;k8s-master&amp;quot; untainted
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でMasterのセットアップは完了。&lt;/p&gt;

&lt;h2 id=&#34;node追加&#34;&gt;Node追加&lt;/h2&gt;

&lt;p&gt;次にNodeをひとつ追加する。&lt;/p&gt;

&lt;p&gt;k8s-masterで&lt;code&gt;kubeadm init&lt;/code&gt;するまえに撮ったスナップショットをクローンして、ホスト名とIPアドレスを変更し、これを追加するNodeのマシン(k8s-node)にする。
クローンしたらMACアドレスもproduct_uuidも変わったので、問題なく使えそう。&lt;/p&gt;

&lt;p&gt;k8s-nodeをクラスタに追加するには、このVM上で、&lt;code&gt;kubeadm init&lt;/code&gt;成功時のメッセージの最後に表示されたコマンド(i.e. &lt;code&gt;kubeadm join&lt;/code&gt;)を実行するだけ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-node ~]# kubeadm join --token 957b7b.eaaf0cb656edba7b 192.168.171.200:6443 --discovery-token-ca-cert-hash sha256:7d16ade2b651ebac573368b1b4db5c0f1236979584e61833efe90a96ff34ae2e
[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
[preflight] Running pre-flight checks
[discovery] Trying to connect to API Server &amp;quot;192.168.171.200:6443&amp;quot;
[discovery] Created cluster-info discovery client, requesting info from &amp;quot;https://192.168.171.200:6443&amp;quot;
[discovery] Requesting info from &amp;quot;https://192.168.171.200:6443&amp;quot; again to validate TLS against the pinned public key
[discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server &amp;quot;192.168.171.200:6443&amp;quot;
[discovery] Successfully established connection with API Server &amp;quot;192.168.171.200:6443&amp;quot;
[bootstrap] Detected server version: v1.8.1
[bootstrap] The server supports the Certificates API (certificates.k8s.io/v1beta1)

Node join complete:
* Certificate signing request sent to master and response
  received.
* Kubelet informed of new secure connection details.

Run &#39;kubectl get nodes&#39; on the master to see this machine join.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できた。
k8s-masterでNodeの状態を確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubectl get nodes
NAME         STATUS    ROLES     AGE       VERSION
k8s-master   Ready     master    42m       v1.8.1
k8s-node     Ready     &amp;lt;none&amp;gt;    45s       v1.8.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;k8s-masterもk8s-nodeもReady。&lt;/p&gt;

&lt;h2 id=&#34;vmホストのkubectlの設定&#34;&gt;VMホストのkubectlの設定&lt;/h2&gt;

&lt;p&gt;kubectlはkube-apiserverのWeb APIを呼ぶコマンドなので、接続先さえちゃんと設定すればMasterのマシン上でなくても使える。
VMのホスト(i.e. Windows 10 PC)で使えるようにしたい。&lt;/p&gt;

&lt;p&gt;kubectlの接続先情報は、&lt;code&gt;kubeadm init&lt;/code&gt;時に生成された&lt;code&gt;/etc/kubernetes/admin.conf&lt;/code&gt;に書かれているので、これをホストに持ってきてkubectlに渡してやればいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf get nodes
NAME         STATUS    ROLES     AGE       VERSION
k8s-master   Ready     master    51m       v1.8.1
k8s-node     Ready     &amp;lt;none&amp;gt;    10m       v1.8.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できた。&lt;/p&gt;

&lt;p&gt;admin.confを&lt;code&gt;%UserProfile%\.kube\&lt;/code&gt;の下に&lt;code&gt;config&lt;/code&gt;という名前で置いてやると、&lt;code&gt;--kubeconfig&lt;/code&gt;で指定しなくても読んでくれる。&lt;/p&gt;

&lt;h2 id=&#34;goslingsデプロイ&#34;&gt;Goslingsデプロイ&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/11/goslings-on-kubernetes-cont/#%E7%95%AA%E5%A4%96%E7%B7%A82-%E5%91%BD%E4%BB%A4%E7%9A%84%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E8%A8%AD%E5%AE%9A&#34;&gt;「Kubernetesのチュートリアルをやる」の番外編&lt;/a&gt;で作ったオブジェクト定義ファイルを使って、今回作ったクラスタに&lt;a href=&#34;https://www.kaitoy.xyz/2016/12/11/goslings-development-memo0-intro-design/&#34;&gt;Goslings&lt;/a&gt;をデプロイしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf create -f deploy_goslings.yml
deployment &amp;quot;goslings-sample&amp;quot; created

C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf create -f service_goslings.yml
service &amp;quot;goslings-sample&amp;quot; created

C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf get po -o wide
NAME                              READY     STATUS    RESTARTS   AGE       IP           NODE
goslings-sample-dfd84c69c-4mgh9   1/1       Running   0          12m       10.244.1.3   k8s-node
goslings-sample-dfd84c69c-cd5mm   1/1       Running   0          12m       10.244.0.3   k8s-master
goslings-sample-dfd84c69c-nwwh7   1/1       Running   0          12m       10.244.1.2   k8s-node

C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf get svc
NAME              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
goslings-sample   NodePort    10.109.174.204   &amp;lt;none&amp;gt;        8080:30004/TCP   7m
kubernetes        ClusterIP   10.96.0.1        &amp;lt;none&amp;gt;        443/TCP          1h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;普通にデプロイできた。
レプリカ3つがちゃんと2つのNodeに分散されてる。&lt;/p&gt;

&lt;p&gt;k8s-masterのIPアドレス( &lt;a href=&#34;http://192.168.171.200:30004/&#34;&gt;http://192.168.171.200:30004/&lt;/a&gt; )でもk8s-nodeのIPアドレス( &lt;a href=&#34;http://192.168.171.201:30004/&#34;&gt;http://192.168.171.201:30004/&lt;/a&gt; )でもGoslingsにつなげた。
普通はMasterのIPアドレスを使うらしい。
そりゃそうか。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/build-kubernetes-cluster-by-kubeadm/goslings.png&#34; alt=&#34;goslings&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;試しにk8s-nodeのVMを落としてみる。
k8s-node上のPodがk8s-masterに移動してくれることを期待してたけど、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf get po -o wide
NAME                              READY     STATUS    RESTARTS   AGE       IP           NODE
goslings-sample-dfd84c69c-4mgh9   1/1       Running   0          55m       10.244.1.3   k8s-node
goslings-sample-dfd84c69c-cd5mm   1/1       Running   0          55m       10.244.0.3   k8s-master
goslings-sample-dfd84c69c-nwwh7   1/1       Running   0          55m       10.244.1.2   k8s-node
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なんかk8s-nodeで動き続けていることになってる。&lt;/p&gt;

&lt;p&gt;クラスタうまく動いていないんだろうか…&lt;/p&gt;

&lt;h2 id=&#34;ダッシュボードデプロイ&#34;&gt;ダッシュボードデプロイ&lt;/h2&gt;

&lt;p&gt;Kubernetesクラスタの状態をWeb UIで確認できる、&lt;a href=&#34;https://github.com/kubernetes/dashboard&#34;&gt;Dashboard&lt;/a&gt;をデプロイしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml
secret &amp;quot;kubernetes-dashboard-certs&amp;quot; created
serviceaccount &amp;quot;kubernetes-dashboard&amp;quot; created
role &amp;quot;kubernetes-dashboard-minimal&amp;quot; created
rolebinding &amp;quot;kubernetes-dashboard-minimal&amp;quot; created
deployment &amp;quot;kubernetes-dashboard&amp;quot; created
service &amp;quot;kubernetes-dashboard&amp;quot; created
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できた。&lt;/p&gt;

&lt;p&gt;Dashboardが起動するまでしばらくまってから、&lt;code&gt;kubectl proxy&lt;/code&gt;して、
&lt;code&gt;http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/&lt;/code&gt;にブラウザでつなげばGUIが開くはずなんだけど、タイムアウトしてつながらなかった。&lt;/p&gt;

&lt;p&gt;クラスタうまく動いていないんだろうか…&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;NICがNATなのがだめだったかもと思い、ブリッジにしてみたけど同じ結果だった。
PodのフェールオーバーもしないしDashboardも開けない。&lt;/p&gt;

&lt;p&gt;ちゃんと一つ一つ自分で構築しないとよく分からないな。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あとでふと思い立って、&lt;code&gt;/etd/hosts&lt;/code&gt;をいじったらDashboardは動いた。
それについてはまた&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/31/retry-dashboard-on-k8s-cluster-by-kubeadm/&#34;&gt;別の記事&lt;/a&gt;で。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetesのチュートリアルをやる</title>
          <link>https://www.kaitoy.xyz/2017/10/11/goslings-on-kubernetes-cont/</link>
          <pubDate>Wed, 11 Oct 2017 23:48:40 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/10/11/goslings-on-kubernetes-cont/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/&#34;&gt;Kubernetes 1.8が出たので、Minikubeを触ってみる&lt;/a&gt;」の続き。
Minikubeのセットアップまではできたので、&lt;a href=&#34;https://kubernetes.io/docs/tutorials/kubernetes-basics/&#34;&gt;Kubernetes Basics&lt;/a&gt;というチュートリアルをやりながら、&lt;a href=&#34;https://kaitoy.github.io/goslings/&#34;&gt;Goslings&lt;/a&gt;をデプロイする。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;kubernetes-basics-概要&#34;&gt;Kubernetes Basics - 概要&lt;/h2&gt;

&lt;p&gt;Kubernetes Basicsは、公式のチュートリアルで、Kubernetesクラスタのオーケストレーションの基本を学ぶことができるもの。
以下の6つのモジュールからなる。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Kubernetesクラスタを作る&lt;/li&gt;
&lt;li&gt;アプリをデプロイする&lt;/li&gt;
&lt;li&gt;アプリを調査する&lt;/li&gt;
&lt;li&gt;アプリを公開する&lt;/li&gt;
&lt;li&gt;アプリをスケールする&lt;/li&gt;
&lt;li&gt;アプリをアップデートする&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;チュートリアルで使うのは&lt;a href=&#34;https://github.com/kubernetes/minikube&#34;&gt;Minikube&lt;/a&gt;だけど、自分でセットアップする必要はない。
&lt;a href=&#34;https://www.katacoda.com/&#34;&gt;Katacoda&lt;/a&gt;という、ブラウザ上でIT技術を学べるプラットフォームがあり、Kubernetes Basicsはそれを利用して、ブラウザ上のターミナルからホステッドMinikubeを操作できるようにしている。&lt;/p&gt;

&lt;p&gt;が、&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/&#34;&gt;前回の記事&lt;/a&gt;で自PC上にMinikubeをセットアップしたので、そちらを使うことにする。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;kubernetes-basics-モジュール-1-kubernetesクラスタを作る&#34;&gt;Kubernetes Basics - モジュール 1: Kubernetesクラスタを作る&lt;/h2&gt;

&lt;p&gt;Minikubeを起動してkubectlでクラスタの状態をみるだけのモジュール。&lt;/p&gt;

&lt;p&gt;これは&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/&#34;&gt;前回の記事&lt;/a&gt;でカバーしている。&lt;/p&gt;

&lt;h2 id=&#34;kubernetes-basics-モジュール-2-アプリをデプロイする&#34;&gt;Kubernetes Basics - モジュール 2: アプリをデプロイする&lt;/h2&gt;

&lt;p&gt;アプリ(i.e. コンテナ)をデプロイするにはDeploymentオブジェクトを作る。
MasterはDeploymentのspecに従って各ノードにアプリのインスタンスをスケジューリングする。
Deploymentは、アプリが落ちたら再起動してくれる、つまりself-healingも実現する。&lt;/p&gt;

&lt;p&gt;Deploymentオブジェクトを作るコマンドは&lt;code&gt;kubectl run &amp;lt;オブジェクト名&amp;gt; --image=&amp;lt;Dockerイメージ名&amp;gt;&lt;/code&gt;。
Goslingsをこれでデプロイする。&lt;/p&gt;

&lt;p&gt;Goslingsコンテナは3つの引数を受け取り、指定したポートでWebサーバを起動する。
&lt;code&gt;--port&lt;/code&gt;オプションでそのポートをexposeするようにして、&lt;code&gt;--&lt;/code&gt;の後にコンテナに渡す引数を記述する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl run goslings --image=kaitoy/goslings:latest --port 8080 -- 8080 /tmp https://github.com/kaitoy/
deployment &amp;quot;goslings&amp;quot; created

C:\Users\kaitoy&amp;gt;kubectl get deployment
NAME       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
goslings   1         1         1            1           27s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;デプロイできた。
裏でPodも作られていて、アプリが起動されている。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get pods
NAME                        READY     STATUS              RESTARTS   AGE
goslings-1210510689-6w5tf   0/1       ContainerCreating   0          1m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(&lt;code&gt;kubectl get&lt;/code&gt;に指定するのは、省略形の&lt;code&gt;deploy&lt;/code&gt;とか&lt;code&gt;po&lt;/code&gt;でもいい。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Podは隔離されたネットワークで動くので、そのままではPod同士は通信できるけど、外からはアクセスできない。
kubectlでプロキシを作ってやることで、外からアクセスできるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl proxy
Starting to serve on 127.0.0.1:8001
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで、kube-apiserverへのプロキシがローカルホストで起動した。
この状態で&lt;code&gt;http://localhost:8001&lt;/code&gt;を開くと、kube-apiserverのAPI一覧が見れる。
例えば、&lt;code&gt;http://localhost:8001/version&lt;/code&gt;にアクセスすると、以下のJSONデータが返ってくる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;major&amp;quot;: &amp;quot;1&amp;quot;,
  &amp;quot;minor&amp;quot;: &amp;quot;7&amp;quot;,
  &amp;quot;gitVersion&amp;quot;: &amp;quot;v1.7.0&amp;quot;,
  &amp;quot;gitCommit&amp;quot;: &amp;quot;d3ada0119e776222f11ec7945e6d860061339aad&amp;quot;,
  &amp;quot;gitTreeState&amp;quot;: &amp;quot;dirty&amp;quot;,
  &amp;quot;buildDate&amp;quot;: &amp;quot;2017-10-04T09:25:40Z&amp;quot;,
  &amp;quot;goVersion&amp;quot;: &amp;quot;go1.8.3&amp;quot;,
  &amp;quot;compiler&amp;quot;: &amp;quot;gc&amp;quot;,
  &amp;quot;platform&amp;quot;: &amp;quot;linux/amd64&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;各Podへも以下のURLでアクセスできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;http://localhost:8001/api/v1/proxy/namespaces/default/pods/&amp;lt;Pod名&amp;gt;/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Pod名の部分は&lt;code&gt;kubectl get&lt;/code&gt;で確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get po
NAME                        READY     STATUS    RESTARTS   AGE
goslings-1210510689-6w5tf   1/1       Running   0          24m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実際に、&lt;code&gt;http://localhost:8001/api/v1/proxy/namespaces/default/pods/goslings-1210510689-6w5tf/&lt;/code&gt;をブラウザで開いたら、GoslingsのGUIが出た。
ヒュー。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-on-kubernetes-cont/goslings-proxy.png&#34; alt=&#34;goslings-proxy&#34; /&gt;
&lt;/p&gt;

&lt;h2 id=&#34;kubernetes-basics-モジュール-3-アプリを調査する&#34;&gt;Kubernetes Basics - モジュール 3: アプリを調査する&lt;/h2&gt;

&lt;p&gt;以下のコマンドで、アプリの状態を調査するモジュール。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;kubectl get: リソースをリスト表示する。&lt;/li&gt;
&lt;li&gt;kubectl describe: リソースの詳細情報を表示する。&lt;/li&gt;
&lt;li&gt;kubectl logs: コンテナのログを表示する。&lt;code&gt;docker logs&lt;/code&gt;的な。&lt;/li&gt;
&lt;li&gt;kubectl exec: コンテナ内でコマンドを実行する。&lt;code&gt;docker exec&lt;/code&gt;的な。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl get&lt;/code&gt;はさんざんやったので飛ばして、&lt;code&gt;kubectl describe&lt;/code&gt;してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl describe po
Name:           goslings-1210510689-6w5tf
Namespace:      default
Node:           minikube/192.168.99.100
Start Time:     Tue, 10 Oct 2017 21:51:48 +0900
Labels:         pod-template-hash=1210510689
                run=goslings
Annotations:    kubernetes.io/created-by={&amp;quot;kind&amp;quot;:&amp;quot;SerializedReference&amp;quot;,&amp;quot;apiVersion&amp;quot;:&amp;quot;v1&amp;quot;,&amp;quot;reference&amp;quot;:{&amp;quot;kind&amp;quot;:&amp;quot;ReplicaSet&amp;quot;,&amp;quot;namespace&amp;quot;:&amp;quot;default&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;goslings-1210510689&amp;quot;,&amp;quot;uid&amp;quot;:&amp;quot;c74b6518-adb9-11e7-88a0-08002798178d...
Status:         Running
IP:             172.17.0.2
Created By:     ReplicaSet/goslings-1210510689
Controlled By:  ReplicaSet/goslings-1210510689
Containers:
  goslings:
    Container ID:       docker://ce90460886c9555f7748bf59e8d9892f05c05020e7841154ee85713d6d9b0c2d
    Image:              kaitoy/goslings:latest
    Image ID:           docker-pullable://kaitoy/goslings@sha256:a587e3c5f202cdaa6d4d5a9c4f6a01ba6f4782e00277c3a18c77dd034daa0109
    Port:               8080/TCP
    Args:
      8080
      C:/Users/kaitoy/AppData/Local/Temp
    State:              Running
      Started:          Tue, 10 Oct 2017 21:55:54 +0900
    Ready:              True
    Restart Count:      0
    Environment:        &amp;lt;none&amp;gt;
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-cqq59 (ro)
Conditions:
  Type          Status
  Initialized   True
  Ready         True
  PodScheduled  True
Volumes:
  default-token-cqq59:
    Type:       Secret (a volume populated by a Secret)
    SecretName: default-token-cqq59
    Optional:   false
QoS Class:      BestEffort
Node-Selectors: &amp;lt;none&amp;gt;
Tolerations:    &amp;lt;none&amp;gt;
Events:
  FirstSeen     LastSeen        Count   From                    SubObjectPath                   Type            Reason
                Message
  ---------     --------        -----   ----                    -------------                   --------        ------
                -------
  45m           45m             1       default-scheduler                                       Normal          Scheduled               Successfully assigned goslings-1210510689-6w5tf to minikube
  45m           45m             1       kubelet, minikube                                       Normal          SuccessfulMountVolume   MountVolume.SetUp succeeded for volume &amp;quot;default-token-cqq59&amp;quot;
  45m           45m             1       kubelet, minikube       spec.containers{goslings}       Normal          Pulling
                pulling image &amp;quot;kaitoy/goslings:latest&amp;quot;
  41m           41m             1       kubelet, minikube       spec.containers{goslings}       Normal          Pulled
                Successfully pulled image &amp;quot;kaitoy/goslings:latest&amp;quot;
  41m           41m             1       kubelet, minikube       spec.containers{goslings}       Normal          Created
                Created container
  41m           41m             1       kubelet, minikube       spec.containers{goslings}       Normal          Started
                Started container
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Podの詳細な情報が出た。
EventsのとこにKubernetesの頑張りが見えて面白い。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次は&lt;code&gt;kubectl logs&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl logs goslings-1210510689-6w5tf

  .   ____          _            __ _ _
 /\\ / ___&#39;_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | &#39;_ | &#39;_| | &#39;_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  &#39;  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v1.4.3.RELEASE)

2017-10-10 12:56:02.498  INFO 6 --- [           main] c.g.kaitoy.goslings.server.Application   : Starting Application on goslings-1210510689-6w5tf with PID 6 (/usr/local/src/goslings/goslings-server/build/libs/goslings-server-0.0.1.jar started by root in /usr/local/src/goslings)
(snip)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Goslingsは&lt;a href=&#34;https://projects.spring.io/spring-boot/&#34;&gt;Spring Boot&lt;/a&gt;でできてるので、そのログが出てる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次は&lt;code&gt;kubectl exec&lt;/code&gt;を試す。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl exec goslings-1210510689-6w5tf env
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=goslings-1210510689-6w5tf
KUBERNETES_PORT_443_TCP=tcp://10.0.0.1:443
KUBERNETES_PORT_443_TCP_PROTO=tcp
KUBERNETES_PORT_443_TCP_PORT=443
KUBERNETES_PORT_443_TCP_ADDR=10.0.0.1
KUBERNETES_SERVICE_HOST=10.0.0.1
KUBERNETES_SERVICE_PORT=443
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBERNETES_PORT=tcp://10.0.0.1:443
LANG=C.UTF-8
JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
JAVA_VERSION=8u111
JAVA_DEBIAN_VERSION=8u111-b14-2~bpo8+1
CA_CERTIFICATES_JAVA_VERSION=20140324
HOME=/root
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;env&lt;/code&gt;コマンドを実行し、コンテナ内の環境変数一覧を出せた。
Kubernetes関係の変数が定義されていることが分かる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker exec&lt;/code&gt;と同様に、&lt;code&gt;-it&lt;/code&gt;オプションを付ければ、コンテナ内に「入る」こともできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl exec -it goslings-1210510689-6w5tf sh
# ls
Dockerfile  _config.yml  build.log     goslings-server  gradle.properties  gradlew.bat
# exit

C:\Users\kaitoy&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;kubernetes-basics-モジュール-4-アプリを公開する&#34;&gt;Kubernetes Basics - モジュール 4: アプリを公開する&lt;/h2&gt;

&lt;p&gt;Serviceオブジェクト扱うモジュール。&lt;/p&gt;

&lt;p&gt;例えば、以下のような状況にあるとする。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;PodがあるNodeで動いていたんだけど、そのNodeが死んだので、Kubernetesが別のNodeにPodを起動しなおしてくれた。&lt;/li&gt;
&lt;li&gt;同じコンテナイメージを3つのPodで動かして、負荷分散させたい。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;こういう場合、KubernetesはPod毎に固有のIPアドレスを割り当てるので、Podにアクセスするユーザはアクセス先が不安定でめんどいことになる。
この問題を解決してくれるのがServiceで、こいつは、Podを抽象化して、安定したIPアドレスを公開してくれる。
しかもそれはクラスタ外からアクセスできる。&lt;/p&gt;

&lt;p&gt;PodとServiceの紐づけには、&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/&#34;&gt;ラベルとセレクタ&lt;/a&gt;というものが使われる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Serviceの情報はDeploymentとかと同様に&lt;code&gt;kubectl get&lt;/code&gt;で見れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get svc
NAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   10.0.0.1     &amp;lt;none&amp;gt;        443/TCP   1d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここで出ているkubernetesというのは、Minikubeがデフォルトで作るService。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Serviceオブジェクトは、&lt;code&gt;kubectl expose&lt;/code&gt;で作ることができる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;goslings&lt;/code&gt;という名のDeploymentに対し、NodePortのServiceを作り、コンテナの8080ポートを公開するコマンドは以下のようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl expose deploy/goslings --type=NodePort --port 8080
service &amp;quot;goslings&amp;quot; exposed

C:\Users\kaitoy&amp;gt;kubectl get services
NAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE
goslings     10.0.0.69    &amp;lt;nodes&amp;gt;       8080:32406/TCP   11s
kubernetes   10.0.0.1     &amp;lt;none&amp;gt;        443/TCP          1d

C:\Users\kaitoy&amp;gt;kubectl describe services/goslings
Name:                   goslings
Namespace:              default
Labels:                 run=goslings
Annotations:            &amp;lt;none&amp;gt;
Selector:               run=goslings
Type:                   NodePort
IP:                     10.0.0.69
Port:                   &amp;lt;unset&amp;gt; 8080/TCP
NodePort:               &amp;lt;unset&amp;gt; 32406/TCP
Endpoints:              172.17.0.2:8080
Session Affinity:       None
Events:                 &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;goslingsという名前のServiceができた。
上記&lt;code&gt;kubectl describe&lt;/code&gt;の出力のNodePortのとこに書いてあるのが外部にさらされたポート。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;minikube ip&lt;/code&gt;を実行すると、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube ip
192.168.99.100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;MinikubeのVMのIPアドレスも分かるので、NodePortのポートと合わせて、&lt;code&gt;http://192.168.99.100:32406&lt;/code&gt;にブラウザでアクセスしたら、GoslingsのGUI見れた。
ヒュー。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-on-kubernetes-cont/goslings-service.png&#34; alt=&#34;goslings-service&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ところで、上記&lt;code&gt;kubectl describe&lt;/code&gt;の出力を見ると、特に指定はしなかったが、Podに&lt;code&gt;run=goslings&lt;/code&gt;というLabelが付いていることが分かる。
Serviceのdescribeを見ると、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl describe svc goslings
Name:                   goslings
Namespace:              default
Labels:                 run=goslings
Annotations:            &amp;lt;none&amp;gt;
Selector:               run=goslings
Type:                   NodePort
IP:                     10.0.0.69
Port:                   &amp;lt;unset&amp;gt; 8080/TCP
NodePort:               &amp;lt;unset&amp;gt; 32406/TCP
Endpoints:              172.17.0.2:8080
Session Affinity:       None
Events:                 &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;run=goslings&lt;/code&gt;というSelectorがServiceに紐づいている。
つまり、ServiceとPodが、&lt;code&gt;run=goslings&lt;/code&gt;で紐づいているというわけだ。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Labelはクエリ時のフィルタとかにも使える。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get po -l run=goslings
NAME                        READY     STATUS    RESTARTS   AGE
goslings-1210510689-6w5tf   1/1       Running   0          1h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;後からラベル付けることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl label pod goslings-1210510689-6w5tf ver=1.2.3
pod &amp;quot;goslings-1210510689-6w5tf&amp;quot; labeled
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;kubernetes-basics-モジュール-5-アプリをスケールする&#34;&gt;Kubernetes Basics - モジュール 5: アプリをスケールする&lt;/h2&gt;

&lt;p&gt;アプリのスケールアウト・スケールインを学ぶモジュール。&lt;/p&gt;

&lt;p&gt;Deploymentの定義でPodのレプリカ数を変えると、その数に合わせてKubernetesがPodを起動したり止めたりしてくれてスケールできる仕組み。
レプリカを作っておくとローリングアップデートできるのも利点。
&lt;a href=&#34;http://kubernetes.io/docs/user-guide/horizontal-pod-autoscaling/&#34;&gt;オートスケール機能&lt;/a&gt;もあるけど、それはチュートリアルでは扱われない。&lt;/p&gt;

&lt;p&gt;複数のPodで負荷分散するということなので、Serviceでロードバランシングするのが前提。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;現在のDeploymentの状態をみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get deploy
NAME       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
goslings   1         1         1            1           1h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Podのレプリカ数は、期待してる(DESIRED)のが1で、今(CURRENT)も1。&lt;/p&gt;

&lt;p&gt;スケールアウトするには、&lt;code&gt;kubectl scale&lt;/code&gt;コマンドでレプリカ数を増やしてやる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl scale deploy/goslings --replicas=3
deployment &amp;quot;goslings&amp;quot; scaled

C:\Users\kaitoy&amp;gt;kubectl get deploy
NAME       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
goslings   3         3         3            3           1h

C:\Users\kaitoy&amp;gt;kubectl get po -o wide
NAME                       READY     STATUS    RESTARTS   AGE       IP           NODE
goslings-442066424-jn1lw   1/1       Running   0          1h        172.17.0.2   minikube
goslings-442066424-rdw4k   1/1       Running   0          1m        172.17.0.3   minikube
goslings-442066424-rwwjw   1/1       Running   0          1m        172.17.0.4   minikube
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;レプリカが3個になった。&lt;/p&gt;

&lt;p&gt;スケールインするには、&lt;code&gt;kubectl scale&lt;/code&gt;コマンドでレプリカ数を減らす。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl scale deploy/goslings --replicas=2
deployment &amp;quot;goslings&amp;quot; scaled

C:\Users\kaitoy&amp;gt;kubectl get po
NAME                       READY     STATUS        RESTARTS   AGE
goslings-442066424-0mv4x   1/1       Terminating   0          1m
goslings-442066424-34h1f   1/1       Running       0          1m
goslings-442066424-kmn3p   1/1       Running       0          17m

C:\Users\kaitoy&amp;gt;kubectl get po
NAME                       READY     STATUS    RESTARTS   AGE
goslings-442066424-34h1f   1/1       Running   0          1m
goslings-442066424-kmn3p   1/1       Running   0          17m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;kubectl scale&lt;/code&gt;直後の&lt;code&gt;kubectl get po&lt;/code&gt;では、一つのPodを停止している最中の様子が見えていて、再度の&lt;code&gt;kubectl get po&lt;/code&gt;ではレプリカが2個になったのが確認できた。&lt;/p&gt;

&lt;p&gt;この状態がKubernetes Basicsで作るクラスタの最終形で、図にすると以下の感じ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-on-kubernetes-cont/objects.png&#34; alt=&#34;objects&#34; /&gt;
&lt;/p&gt;

&lt;h2 id=&#34;kubernetes-basics-モジュール-6-アプリをアップデートする&#34;&gt;Kubernetes Basics - モジュール 6: アプリをアップデートする&lt;/h2&gt;

&lt;p&gt;デプロイしたアプリのアップデート(i.e. コンテナイメージの変更)を学ぶモジュール。&lt;/p&gt;

&lt;p&gt;Deploymentの定義をいじってコンテナイメージを変えてやると、その中のPodを新しいイメージで順次(デフォルトだと一つ一つ)起動しなおしてくれる。&lt;/p&gt;

&lt;p&gt;アプリのアップデートはバージョン管理もされて、ロールバックもできる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;コンテナイメージを変更するには、&lt;code&gt;kubectl set image&lt;/code&gt;コマンドを使う。
&lt;code&gt;goslings&lt;/code&gt;という名のDeployment内の、&lt;code&gt;goslings&lt;/code&gt;という名のContainerのイメージを&lt;code&gt;kaitoy/goslings:hoge&lt;/code&gt;に変更するコマンドは以下。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl set image deploy/goslings goslings=kaitoy/goslings:hoge
deployment &amp;quot;goslings&amp;quot; image updated
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実際には&lt;code&gt;kaitoy/goslings:hoge&lt;/code&gt;というイメージはないので、イメージのPullに失敗したというエラー(ErrImagePull)になる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get po
NAME                       READY     STATUS         RESTARTS   AGE
goslings-274047280-jxmmh   0/1       ErrImagePull   0          9s
goslings-274047280-rgg2v   0/1       ErrImagePull   0          8s
goslings-442066424-34h1f   1/1       Terminating    0          1h
goslings-442066424-kmn3p   1/1       Running        0          1h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;イメージ変更前に戻すには、&lt;code&gt;kubectl rollout undo&lt;/code&gt;する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl rollout undo deploy/goslings
deployment &amp;quot;goslings&amp;quot; rolled back

C:\Users\kaitoy&amp;gt;kubectl rollout status deploy/goslings
deployment &amp;quot;goslings&amp;quot; successfully rolled out

C:\Users\kaitoy&amp;gt;kubectl get po
NAME                       READY     STATUS    RESTARTS   AGE
goslings-442066424-kmn3p   1/1       Running   0          1h
goslings-442066424-m3873   1/1       Running   0          5s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;無事に戻った。&lt;/p&gt;

&lt;h2 id=&#34;番外編1-3つのオブジェクト管理手法&#34;&gt;番外編1 - 3つのオブジェクト管理手法&lt;/h2&gt;

&lt;p&gt;Kubernetesオブジェクトを管理する手法は&lt;a href=&#34;https://kubernetes.io/docs/tutorials/object-management-kubectl/object-management/&#34;&gt;大きく3つある&lt;/a&gt;。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;管理手法&lt;/th&gt;
&lt;th&gt;いじる対象&lt;/th&gt;
&lt;th&gt;難易度&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;命令的コマンド&lt;/td&gt;
&lt;td&gt;生のオブジェクト&lt;/td&gt;
&lt;td&gt;簡単&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;命令的オブジェクト設定&lt;/td&gt;
&lt;td&gt;個々のファイル&lt;/td&gt;
&lt;td&gt;普通&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;宣言的オブジェクト設定&lt;/td&gt;
&lt;td&gt;ディレクトリに入ったファイル群&lt;/td&gt;
&lt;td&gt;難しい&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Kubernetes Basicsでやってた手法は一番上の命令的コマンド。
これは簡単で分かりやすい。
けど、何度も同じようなデプロイするならコマンドを毎回打つのが面倒だし、作成されるオブジェクトは明示的じゃないし、変更管理もできない。
この手法は主に開発中に使う。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;二つ目の手法の命令的オブジェクト設定では、YAML(かJSON)ファイルにオブジェクト定義を書いておいて、kubectlに渡す。
この手法だと、定義ファイルをオブジェクトのテンプレートとして使えるし、Gitとかのリポジトリに入れることでバージョン管理・変更管理できる。
けど、Kubernetesのオブジェクトモデルを理解しないと使えない。
(オブジェクト定義の詳細は&lt;a href=&#34;https://kubernetes.io/docs/api-reference/v1.8/&#34;&gt;APIリファレンス&lt;/a&gt;を参照。)&lt;/p&gt;

&lt;p&gt;命令的オブジェクト設定は以下のような形でやる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ kubectl create -f nginx.yaml
$ kubectl delete -f nginx.yaml -f redis.yaml
$ kubectl replace -f nginx.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;三つ目の手法の宣言的オブジェクト設定では、設定フォルダに定義ファイル群を置く。
ユーザは明示的にcreateとかupdateとか指示する必要が無く、kubectlが勝手に判断してくれる。
生のオブジェクトを直接いじった後、同じオブジェクトの設定を設定ファイルで変更しても、
両者の変更が上手くマージされる。&lt;/p&gt;

&lt;p&gt;なんかすごいけど、上手くいかなかったときのデバッグがむずい。&lt;/p&gt;

&lt;p&gt;宣言的オブジェクト設定は以下のような形でやる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ kubectl apply -R -f configs/
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;番外編2-命令的オブジェクト設定&#34;&gt;番外編2 - 命令的オブジェクト設定&lt;/h2&gt;

&lt;p&gt;3つの手法の内、命令的オブジェクト設定でGoslingsをMinikubeにデプロイしてみる。&lt;/p&gt;

&lt;p&gt;まず、Kubernetes Basicsで作ったオブジェクトを消すため、MinikubeのVMを作り直す。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube stop
Stopping local Kubernetes cluster...
Machine stopped.

C:\Users\kaitoy&amp;gt;minikube delete
Deleting local Kubernetes cluster...
Machine deleted.

C:\Users\kaitoy&amp;gt;minikube start --vm-driver virtualbox --kubernetes-version v1.7.0
Starting local Kubernetes v1.7.0 cluster...
Starting VM...
Getting VM IP address...
Moving files into cluster...
Setting up certs...
Connecting to cluster...
Setting up kubeconfig...
Starting cluster components...
Kubectl is now configured to use the cluster.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次に定義ファイルを書いていく。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://v1-7.docs.kubernetes.io/docs/api-reference/v1.7/#deployment-v1beta1-apps&#34;&gt;APIリファレンスのDeploymentのとこ&lt;/a&gt;をみると、Kubernetes Basicsの最終形と同じようなDeploymentを作る定義は以下のように書ける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: goslings-sample
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: goslings
        ver: latest
    spec:
      containers:
        - name: goslings
          image: kaitoy/goslings:latest
          ports:
            - name: http
              containerPort: 8080
          args:
            - &#39;8080&#39;
            - /tmp
            - https://github.com/kaitoy/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同様に、Serviceは、&lt;a href=&#34;https://v1-7.docs.kubernetes.io/docs/api-reference/v1.7/#service-v1-core&#34;&gt;APIリファレンスのServiceのとこ&lt;/a&gt;みると以下のように書ける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;kind: Service
apiVersion: v1
metadata:
  name: goslings-sample
spec:
  ports:
    - name: http
      port: 8080
      targetPort: 8080
  selector:
    app: goslings
  type: NodePort
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、それぞれのYAMLファイルを&lt;code&gt;kubectl create&lt;/code&gt;に渡してやると、Goslingsデプロイ完了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\kubeTest&amp;gt;kubectl create -f deploy_goslings.yml
deployment &amp;quot;goslings-sample&amp;quot; created

C:\Users\kaitoy\kubeTest&amp;gt;kubectl create -f service_goslings.yml
service &amp;quot;goslings-sample&amp;quot; created
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;オブジェクトの種類もパラメータも大量にあるので、使いこなすのは難しそう。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetes 1.8が出たので、Minikubeを触ってみる</title>
          <link>https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/</link>
          <pubDate>Tue, 10 Oct 2017 00:10:59 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt;1.8のリリースが話題になっていたので、ちょっと触って見たという話。
(1.8を触ったとは言っていない。)&lt;/p&gt;

&lt;p&gt;具体的には、&lt;a href=&#34;https://kubernetes.io/docs/tutorials/kubernetes-basics/&#34;&gt;Kubernetes Basics&lt;/a&gt;というチュートリアルをやりながら、&lt;a href=&#34;https://github.com/kubernetes/minikube&#34;&gt;Minikube&lt;/a&gt;に&lt;a href=&#34;https://kaitoy.github.io/goslings/&#34;&gt;Goslings&lt;/a&gt;をデプロイしたんだけど、この記事ではMinikubeをセットアップしたところまで。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;kubernetesとは&#34;&gt;Kubernetesとは&lt;/h2&gt;

&lt;p&gt;KubernetesはOSSのコンテナオーケストレーションツール。
英語だとクーバネティスみたいに発音する。
Googleが自身のコンテナ技術である&lt;a href=&#34;https://research.google.com/pubs/pub43438.html&#34;&gt;Borg&lt;/a&gt;の運用で培ったノウハウを活かして開発したもの。
2014年ころに開発が始まり、2015年夏にv1がリリースされたということで、かなり新しいツール。
よく比べられるものには&lt;a href=&#34;https://docs.docker.com/engine/swarm/&#34;&gt;DockerのSwarmモード&lt;/a&gt;や&lt;a href=&#34;http://mesos.apache.org/&#34;&gt;Apache Mesos&lt;/a&gt;があるが、何が違うのかは調べてないので知らない。
ただ、Dockerコンテナ管理ツールとしてはKubernetesが一番勢いがある雰囲気を感じる。&lt;/p&gt;

&lt;p&gt;(2017/10/18追記: &lt;a href=&#34;http://www.publickey1.jp/blog/17/dockerkubernetesdockercon_eu_2017.html&#34;&gt;DockerがKubernetesとの統合を発表&lt;/a&gt;した。KubernetesはDockerネイティブなツールになり、Dockerとともにインストールされ、Docker ComposeのConposeファイルでデプロイできるようになったりする。Kubernetesの大勝利っぽい。)&lt;/p&gt;

&lt;p&gt;Kubernetesを使うと、複数の物理マシンからなるHAクラスタ(Kubernetesクラスタ)を構成し、その上にコンテナをデプロイして管理できる。
Kubernetesクラスタは、一組のMasterコンポーネント群(a.k.a. Kubernetes Control Plane、または単にMaster)と一つ以上のNode(昔はMinionと呼ばれてたもの)で構成される。
Nodeは、Masterの管理下でコンテナを実行する機能を備えた、一台のVMや物理マシン。
MasterはNode上で動き、クラスタを管理し、コンテナのスケジューリング、状態管理、スケーリング、アップデートなどを担う。&lt;/p&gt;

&lt;p&gt;Kubernetesの&lt;a href=&#34;https://github.com/kubernetes/community/blob/master/contributors/design-proposals/architecture/architecture.md&#34;&gt;アーキテクチャ&lt;/a&gt;を図にすると以下の感じ。
矢印の向きとかはちょっと間違ってるかも。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-on-kubernetes/architecture.png&#34; alt=&#34;architecture&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;ごちゃごちゃするので省いたけど、図の下部のNode内のコンポーネントは、他のNode内でも動いている。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Masterには&lt;a href=&#34;https://kubernetes.io/docs/admin/kube-apiserver/&#34;&gt;kube-apiserver&lt;/a&gt;が含まれていて、&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/kubernetes-api/&#34;&gt;Kubernetes API&lt;/a&gt;というREST APIを公開する。
このAPIを通して&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/&#34;&gt;Kubernetesオブジェクト&lt;/a&gt;を定義したりすることで、宣言的にコンテナの管理ができる仕組み。
ユーザは普通、&lt;a href=&#34;https://kubernetes.io/docs/user-guide/kubectl/&#34;&gt;kubectl&lt;/a&gt;(キューブシーティーエル)というコマンドでkube-apiserverとやり取りする。&lt;/p&gt;

&lt;p&gt;KubernetesオブジェクトはMasterの&lt;a href=&#34;https://github.com/coreos/etcd&#34;&gt;etcd&lt;/a&gt;によって分散キーバリューストアに永続化され、そのストアを&lt;a href=&#34;https://kubernetes.io/docs/admin/kube-controller-manager/&#34;&gt;kube-controller-manager&lt;/a&gt;と&lt;a href=&#34;https://kubernetes.io/docs/admin/kube-scheduler/&#34;&gt;kube-scheduler&lt;/a&gt;がwatchしてて、変更に応じた処理をする。&lt;/p&gt;

&lt;p&gt;kube-controller-managerは、ノードの管理や、オブジェクトのライフサイクルの管理や、コンテナのスケーリングなど、クラスタレベルの機能を実行する。
(よくわからない。)&lt;/p&gt;

&lt;p&gt;kube-schedulerは、コンテナを実行するホストを選出し、コンテナのスケジューリングをする。&lt;/p&gt;

&lt;p&gt;あと、図にはないけど、&lt;a href=&#34;https://kubernetes.io/docs/admin/cloud-controller-manager/&#34;&gt;cloud-controller-manager&lt;/a&gt;というのがMasterで動くこともあって、クラウドプラットフォームとやり取りしてクラウド固有の仕事をするらしい。
クラウドベンダじゃなければ気にしなくて良さそう。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;一方、各Nodeでは、&lt;a href=&#34;https://kubernetes.io/docs/admin/kubelet/&#34;&gt;kubelet&lt;/a&gt;(キューブレット)というMasterのエージェントになるプロセスが動く。&lt;/p&gt;

&lt;p&gt;kubeletはkube-apiserverからの指示で、コンテナイメージを取得してコンテナを起動したり監視したり止めたりする。&lt;/p&gt;

&lt;p&gt;kubeletがコンテナを扱うためのコンテナランタイムは、普通は&lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt;だけど、&lt;a href=&#34;https://coreos.com/rkt/&#34;&gt;rkt&lt;/a&gt;とか&lt;a href=&#34;https://github.com/kubernetes-incubator/cri-o&#34;&gt;cri-o&lt;/a&gt;とか&lt;a href=&#34;https://github.com/kubernetes/frakti&#34;&gt;frakti&lt;/a&gt;とかも使える。&lt;a href=&#34;https://github.com/opencontainers/runc&#34;&gt;runc&lt;/a&gt;や&lt;a href=&#34;https://github.com/oracle/railcar&#34;&gt;RailCar&lt;/a&gt;はどうなんだろう。&lt;/p&gt;

&lt;p&gt;コンテナはデフォルトではクラスタ内のプライベートネットワークにつながるので、そこで動いているアプリにユーザからアクセスするには、何らかの形でトラフィックを中継してやる必要がある。
これをするのが&lt;a href=&#34;https://kubernetes.io/docs/admin/kube-proxy/&#34;&gt;kube-proxy&lt;/a&gt;。
ロードバランシングもしてくれる。&lt;/p&gt;

&lt;h2 id=&#34;kubernetesオブジェクトとは&#34;&gt;Kubernetesオブジェクトとは&lt;/h2&gt;

&lt;p&gt;Kubernetesオブジェクトは、Kubernetesクラスタ上で機能する構成要素を表現するもの。
オブジェクトは&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/#object-spec-and-status&#34;&gt;specとstatus&lt;/a&gt;を持ち、オブジェクトに期待する状態やふるまい(spec)を定義しておくと、Kubernetesが実際の状態(status)をそれに合わせてくれる。
宣言的。&lt;/p&gt;

&lt;p&gt;オブジェクトには以下のようなものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/&#34;&gt;Pod&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;デプロイの最小単位。
一つ(またはリソースを共有する複数)のコンテナと、ストレージ、ネットワークなどを内包する。
一つのPodには一つのIPアドレスが付く。&lt;/p&gt;

&lt;p&gt;kubeletはPodの定義に従ってコンテナを起動する。&lt;/p&gt;

&lt;p&gt;因みに、etcd以外のMasterコンポーネントもPodとしてデプロイされる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/&#34;&gt;Service&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Podの論理グループ。
PodのIPアドレスは外部に公開されないので、外とのやり取りをするためにServiceがある。
kube-proxyはこいつの定義に従って働く。&lt;/p&gt;

&lt;p&gt;Serviceには複数のEndpoint(i.e. Pod等)が紐づき、外部からのトラフィックをラウンドロビンでルーティングするので、冗長化やロードバランサ的な働きもする。
ServiceはPodを抽象化するので、Podが死んだり入れ替わったりしても外に影響が見えにくくなる。&lt;/p&gt;

&lt;p&gt;Serviceには以下のtypeがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ClusterIP (デフォルト): Kubernetesクラスタ内からだけアクセスできる内部IPアドレスだけをもつ。&lt;/li&gt;
&lt;li&gt;NodePort: ClusterIPの拡張。内部IPアドレスに加え、クラスタ外からアクセスできるポートを一つ持つ。&lt;/li&gt;
&lt;li&gt;LoadBalancer: NodePortの拡張。外部ロードバランサを作って、固定の外部IPアドレスを付けて、内部IPアドレスへルーティングする。&lt;/li&gt;
&lt;li&gt;ExternalName: 抽象名をもつサービス。Kubernetes DNS serverで名前解決する。&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/&#34;&gt;詳細&lt;/a&gt;は読んでないので知らない。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/volumes/&#34;&gt;Volume&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;永続化やPod内でのファイル共有のためのオブジェクト。
Podとともに作られ、Podとともに破棄される。
実態はファイルシステム上のディレクトリ。
hostPathとか、nfsとか、awsElasticBlockStoreとかの種類があるらしい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/&#34;&gt;Namespace&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;仮想クラスタを表すオブジェクト。
これを定義すると、ひとつの物理クラスタを複数の仮想クラスタに分割できる。
大規模ユーザ・プロジェクト向け機能。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Controller&lt;/p&gt;

&lt;p&gt;Podを管理するオブジェクト。レプリケーションしたり、スケーリングや自動再起動したり。&lt;/p&gt;

&lt;p&gt;以下のようなものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&#34;&gt;Deployment&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Podのデプロイを管理するオブジェクト。
PodとReplicaSetの宣言的な生成・更新を実現する。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/&#34;&gt;ReplicaSet&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;指定した数のPodのレプリカを維持してくれる。
基本はDeploymentから作られて、Podの作成・削除・更新をオーケストレイトする。
&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller/&#34;&gt;ReplicationController&lt;/a&gt;というのもあるけど、今はReplicaSetが推奨。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/&#34;&gt;StatefulSet&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ステートフルなアプリを管理するオブジェクト。
現時点でのKubernetes最新版の1.8でまだベータ。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/&#34;&gt;DaemonSet&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;全てのノードで動くアプリを実現するオブジェクト。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/&#34;&gt;Job&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ジョブを表すオブジェクト。
指定された回数、Podを成功で完了させる。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;オブジェクトには&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/&#34;&gt;ラベル&lt;/a&gt;というキーバリューな属性を付けることができ、PodとServiceの紐づけや、オブジェクト検索時のフィルタとかに使える。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今回Goslingsを動かすのに使ったのは、Pod、Deployment、ReplicaSet、Service (NodePort)。&lt;/p&gt;

&lt;h2 id=&#34;podネットワーク&#34;&gt;Podネットワーク&lt;/h2&gt;

&lt;p&gt;ちょっと細かい話だけど、Pod間の通信はどうなっているかという話についてちょっと調べたのでざっくり書いておく。&lt;/p&gt;

&lt;p&gt;普通の&lt;a href=&#34;https://www.kaitoy.xyz/2015/07/25/how-to-capture-packets-on-a-local-network-with-pcap4j-container/#docker-network&#34;&gt;Dockerネットワーク&lt;/a&gt;だと、コンテナはdocker0という仮想ブリッジ上のプライベートネットワークで動くため、同じホスト上のコンテナ間は通信できるけど、別のホスト上のコンテナ通信させたい場合は、ホストのIPアドレスのポートを割り当ててやらなければいけない。&lt;/p&gt;

&lt;p&gt;これはめんどいので、Kubernetesは、各Podに一意なIPアドレスを与え、Podがどのホストにいるかにかかわらず、NAT無しで相互に通信できる&lt;a href=&#34;https://kubernetes.io/docs/concepts/cluster-administration/networking/&#34;&gt;ネットワーク&lt;/a&gt;を提供する。
これがPodネットワークとか呼ばれ、その仕様は&lt;a href=&#34;https://github.com/containernetworking/cni&#34;&gt;CNI&lt;/a&gt;でオープンに定められていて、以下のような実装がある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.projectcalico.org/v2.6/getting-started/kubernetes/installation/hosted/kubeadm/&#34;&gt;Calico&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/projectcalico/canal/tree/master/k8s-install&#34;&gt;Canal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/coreos/flannel&#34;&gt;Flannel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudnativelabs/kube-router/blob/master/Documentation/kubeadm.md&#34;&gt;Kube-router&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/romana/romana/tree/master/containerize#using-kubeadm&#34;&gt;Romana&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.weave.works/docs/net/latest/kube-addon/&#34;&gt;Weave Net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;minikubeとは&#34;&gt;Minikubeとは&lt;/h2&gt;

&lt;p&gt;Kubernetesクラスタを構築する方法は&lt;a href=&#34;https://kubernetes.io/docs/setup/pick-right-solution/&#34;&gt;いくつかある&lt;/a&gt;が、中でももっとも簡単な方法がMinikube。&lt;/p&gt;

&lt;p&gt;Minikubeは、単一NodeのKubernetesクラスタを詰めたVMをダウンロードして起動して、ローカルのkubectlから使えるようにしてくれるツール。
Linux、Windows、OS Xで動き、開発やテスト用途のKubernetes環境として使われる。&lt;/p&gt;

&lt;p&gt;ちょっと&lt;a href=&#34;https://www.vagrantup.com/&#34;&gt;Vagrant&lt;/a&gt;っぽい感じ。Kubernetes専用の。&lt;/p&gt;

&lt;h2 id=&#34;minikubeインストール&#34;&gt;Minikubeインストール&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-minikube/&#34;&gt;Kubernetesのドキュメント&lt;/a&gt;にしたがって、Minikubeをインストールする。
環境はWindows 10 Home x64。&lt;/p&gt;

&lt;p&gt;まず、MinikubeのVMを動かす仮想化ツールを入れる。
今のところMinikubeがサポートしてるのは、Windowsだと&lt;a href=&#34;https://www.virtualbox.org/&#34;&gt;VirtualBox&lt;/a&gt;か&lt;a href=&#34;https://docs.microsoft.com/ja-jp/virtualization/hyper-v-on-windows/quick-start/enable-hyper-v&#34;&gt;Hyper-V&lt;/a&gt;。
Windows 10 HomeだとHyper-Vが使えないので、VirtualBox一択。
VirtualBoxは、適当にVT-xを有効にして(してあった)、インストーラダウンロードしてインストールしただけ。
バージョンは5.1.28。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次に、minikubeコマンドを入れる。
このコマンドはGoで書かれていて、各プラットフォーム用にビルドされたバイナリがGitHubのプロジェクトページの&lt;a href=&#34;https://github.com/kubernetes/minikube/releases&#34;&gt;Releases&lt;/a&gt;に上がってるので、ダウンロードしてPathの通ったとこに置くだけ。
今回ダウンロードしたのはv0.22.2のminikube-windows-amd64で、これをminikube.exeにリネームして配置した。&lt;/p&gt;

&lt;p&gt;で、minikubeがサポートしているKubernetesのバージョンを調べると、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube get-k8s-versions
The following Kubernetes versions are available:
        - v1.7.5
        - v1.7.4
        - v1.7.3
        - v1.7.2
        - v1.7.0
        (snip)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1.8はまだサポートされていない…&lt;/p&gt;

&lt;p&gt;1.7.5が最新なのでそれでやることにする。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ということで、kubectlの1.7.5をインストールする。
kubectlもGoで書かれているので、以下のアドレスからWindowsバイナリをダウンロードしてPathの通ったところに置くだけ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.7.5/bin/windows/amd64/kubectl.exe
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でMinikubeの環境ができた。
簡単。&lt;/p&gt;

&lt;h2 id=&#34;minikube起動&#34;&gt;Minikube起動&lt;/h2&gt;

&lt;p&gt;Minikubeは、&lt;code&gt;minikube start&lt;/code&gt;で起動することができ、Minikubeが起動したらすぐにKubernetesをいじれるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube start --vm-driver virtualbox --kubernetes-version v1.7.5
Starting local Kubernetes v1.7.5 cluster...
Starting VM...
Downloading Minikube ISO
 106.37 MB / 106.37 MB [============================================] 100.00% 0s
Getting VM IP address...
Moving files into cluster...
Setting up certs...
Connecting to cluster...
Setting up kubeconfig...
Starting cluster components...
Kubectl is now configured to use the cluster.

C:\Users\kaitoy&amp;gt;minikube status
minikube: Running
cluster: Running
kubectl: Correctly Configured: pointing to minikube-vm at 192.168.99.100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;起動した。
VirtualBoxのGUIを見ると、minikubeというVMが起動しているのが分かる。
この中でKubernetesクラスタが動いているはずだ。&lt;/p&gt;

&lt;p&gt;このVMには、&lt;code&gt;minikube ssh&lt;/code&gt;でログインできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube ssh
                         _             _
            _         _ ( )           ( )
  ___ ___  (_)  ___  (_)| |/&#39;)  _   _ | |_      __
/&#39; _ ` _ `\| |/&#39; _ `\| || , &amp;lt;  ( ) ( )| &#39;_`\  /&#39;__`\
| ( ) ( ) || || ( ) || || |\`\ | (_) || |_) )(  ___/
(_) (_) (_)(_)(_) (_)(_)(_) (_)`\___/&#39;(_,__/&#39;`\____)

$ uname -a
Linux minikube 4.9.13 #1 SMP Fri Sep 15 23:35:16 UTC 2017 x86_64 GNU/Linux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;すごくVagrantっぽい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Minikubeを起動すると、kubectlのコンテキストがminikubeというものに設定され、kubectlコマンドの接続先がMinikubeのKubernetesになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl config current-context
minikube
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、kubectlでクラスタの状態とかを見てみようと思ったら、なんか様子が変。
なしのつぶて。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get nodes
Unable to connect to the server: dial tcp 192.168.99.100:8443: connectex: No connection could be made because the target machine actively refused it.

C:\Users\kaitoy&amp;gt;kubectl cluster-info dump
Unable to connect to the server: dial tcp 192.168.99.100:8443: connectex: No connection could be made because the target machine actively refused it.

C:\Users\kaitoy&amp;gt;minikube dashboard
Could not find finalized endpoint being pointed to by kubernetes-dashboard: Error validating service: Error getting service kubernetes-dashboard: Get https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kubernetes-dashboard: dial tcp 192.168.99.100:8443: connectex: No connection could be made because the target machine actively refused it.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再度&lt;code&gt;minikube status&lt;/code&gt;してみたら、クラスタが落ちていた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube status
minikube: Running
cluster: Stopped
kubectl: Correctly Configured: pointing to minikube-vm at 192.168.99.100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;minikube logs&lt;/code&gt;でログを見てみると、エラーがたくさん出ていた。
以下のようなログが最初のほうに出てたので、認証系がだめで、サービス間でやり取りができなかったんじゃないかという感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Oct 04 23:08:43 minikube localkube[2783]: W1004 23:08:43.599396    2783 authentication.go:368] AnonymousAuth is not allowed with the AllowAll authorizer.  Resetting AnonymousAuth to false. You should use a different authorizer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;エラーの原因はよくわからないので、Kubernetesのバージョンをちょっと古いの(1.7.0)変えてみる。&lt;/p&gt;

&lt;p&gt;kubectlの1.7.0をPathに置いて、Minikubeを1.7.0で再起動する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube stop
Stopping local Kubernetes cluster...
Machine stopped.

C:\Users\kaitoy&amp;gt;minikube start --vm-driver virtualbox --kubernetes-version v1.7.0
Starting local Kubernetes v1.7.0 cluster...
Starting VM...
Getting VM IP address...
Kubernetes version downgrade is not supported. Using version: v1.7.5
Moving files into cluster...
Setting up certs...
Connecting to cluster...
Setting up kubeconfig...
Starting cluster components...
Kubectl is now configured to use the cluster.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kubernetesのダウングレードはサポートされてないと言われた。
ので一回VMを消してからやりなおす。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube stop
Stopping local Kubernetes cluster...
Machine stopped.

C:\Users\kaitoy&amp;gt;minikube delete
Deleting local Kubernetes cluster...
Machine deleted.

C:\Users\kaitoy&amp;gt;minikube start --vm-driver virtualbox --kubernetes-version v1.7.0
Starting local Kubernetes v1.7.0 cluster...
Starting VM...
Getting VM IP address...
Moving files into cluster...
Setting up certs...
Connecting to cluster...
Setting up kubeconfig...
Starting cluster components...
Kubectl is now configured to use the cluster.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1.7.0で動いた。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;様子はどうか。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop\bin\pleiades\workspace\blog&amp;gt;minikube status
minikube: Running
cluster: Running
kubectl: Correctly Configured: pointing to minikube-vm at 192.168.99.100

C:\Users\kaitoy\Desktop\bin\pleiades\workspace\blog&amp;gt;kubectl get nodes
NAME       STATUS    AGE       VERSION
minikube   Ready     22s       v1.7.0

C:\Users\kaitoy\Desktop\bin\pleiades\workspace\blog&amp;gt;kubectl version
Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;7&amp;quot;, GitVersion:&amp;quot;v1.7.0&amp;quot;, GitCommit:&amp;quot;d3ada0119e776222f11ec7945e6d860061339aad&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, BuildDate:&amp;quot;2017-06-29T23:15:59Z&amp;quot;, GoVersion:&amp;quot;go1.8.3&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;windows/amd64&amp;quot;}
Server Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;7&amp;quot;, GitVersion:&amp;quot;v1.7.0&amp;quot;, GitCommit:&amp;quot;d3ada0119e776222f11ec7945e6d860061339aad&amp;quot;, GitTreeState:&amp;quot;dirty&amp;quot;, BuildDate:&amp;quot;2017-10-04T09:25:40Z&amp;quot;, GoVersion:&amp;quot;go1.8.3&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;linux/amd64&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちゃんと動いているっぽい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ダッシュボードだけはなぜか相変わらず開けないけどまあいいか。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube dashboard
Could not find finalized endpoint being pointed to by kubernetes-dashboard: Error validating service: Error getting service kubernetes-dashboard: services &amp;quot;kubernetes-dashboard&amp;quot; not found
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;続きはまた&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/11/goslings-on-kubernetes-cont/&#34;&gt;別の記事&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;因みに、ベーシック認証ありのプロキシ環境でMinikube on Windowsする場合は、まず以下の環境変数を設定:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;NO_PROXY&lt;/code&gt;: 192.168.99.100&lt;/li&gt;
&lt;li&gt;&lt;code&gt;http_proxy&lt;/code&gt;: username:password@domain.com:port&lt;/li&gt;
&lt;li&gt;&lt;code&gt;https_proxy&lt;/code&gt;: username:password@domain.com:port&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;NO_PROXY&lt;/code&gt;の値は&lt;code&gt;minikube ip&lt;/code&gt;の値。
で、&lt;/p&gt;

&lt;p&gt;&lt;code&gt;minikube start --docker-env HTTP_PROXY=http://%http_proxy% --docker-env HTTPS_PROXY=https://%https_proxy% --docker-env NO_PROXY=%NO_PROXY%&lt;/code&gt;みたいにすればできる。&lt;/p&gt;

&lt;p&gt;はず。(参考: &lt;a href=&#34;https://github.com/kubernetes/minikube/issues/530&#34;&gt;https://github.com/kubernetes/minikube/issues/530&lt;/a&gt;)&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>スタートアップはReactを使うべきではない (BSD &#43; patentsライセンスを考慮して) — もし、いつか大企業に買収されたいと望むなら</title>
          <link>https://www.kaitoy.xyz/2017/08/25/if-youre-a-startup-you-should-not-use-react-reflecting-on-the-bsd-patents-license/</link>
          <pubDate>Fri, 25 Aug 2017 00:29:39 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/08/25/if-youre-a-startup-you-should-not-use-react-reflecting-on-the-bsd-patents-license/</guid>
          <description>

&lt;p&gt;このエントリでは、Raúl Kripalaniによる記事、&lt;a href=&#34;https://medium.com/@raulk/if-youre-a-startup-you-should-not-use-react-reflecting-on-the-bsd-patents-license-b049d4a67dd2&#34;&gt;If you’re a startup, you should not use React (reflecting on the BSD + patents license)&lt;/a&gt;を紹介する。
(Raúlから和訳と転載の許可は得た。)
以下はその全文の和訳だが、意訳超訳が混じっているので、もとのニュアンスを知りたければ元記事を読んでもいいし、読まなくてもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;2017/9/23追記: React、Jest、Flow、Immutable.jsが&lt;a href=&#34;https://code.facebook.com/posts/300798627056246/relicensing-react-jest-flow-and-immutable-js/&#34;&gt;MITにリライセンスされる&lt;/a&gt;というアナウンスがFacebookからあった。
コミュニティの大勝利だ。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;現在オープンソースコミュニティで起こっていることには落胆させられる。&lt;/strong&gt;
特に、オープンソースのおかげで多くのスタートアップやビジネスが存在することを認識したときは。
独占的なソフトウェアのために法外なライセンス料を払わなければならないとしたら、それらは存続できない。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;オープンソースとは、より良いソフトウェアをみんなで構築するためのコミュニティをつくることだ。
それを、— Facebookが意図しているような — 人々の権利を交換するための市場として決して使用すべきではない。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Facebookは「BSD + patents」というライセンスモデルを推進している。
広く人気のあるReactを含む、すべてのプロジェクトで。&lt;/p&gt;

&lt;p&gt;基本的に、「BSD + patents」はコードが(誰でも参照し利用できるように)公開されていることを意味するが、しかしそれは常にFacebookの著作物でもある。
そして彼らは、&lt;strong&gt;君がFacebookを特許侵害で訴えないで&lt;/strong&gt; 仲良くやっている限り、君に特許ライセンスを与える。&lt;/p&gt;

&lt;p&gt;Facebookを訴えた瞬間、Reactの他、君の使っているあらゆるFacebookの「オープンソース」技術の特許権は自動的に取り消されてしまう。&lt;/p&gt;

&lt;p&gt;アディオス、バイバイ、どこかへ行ってしまう。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://cdn-images-1.medium.com/max/800/1*crzf_h-aHXU-g3J0W6Ryig.png&#34; alt=&#34;React PATENTS&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;(&lt;a href=&#34;https://github.com/facebook/react/blob/b8ba8c83f318b84e42933f6928f231dc0918f864/PATENTS&#34;&gt;https://github.com/facebook/react/blob/b8ba8c83f318b84e42933f6928f231dc0918f864/PATENTS&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;この問題は、Apache Software Foundationによって&lt;a href=&#34;https://github.com/facebook/react/issues/10191#issuecomment-323486580&#34;&gt;衆目にさらされることとなった&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;この制限は広大で、残忍だ。&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;・・・&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;その知的財産がReactを使用しているドメインと関連しているかどうかは関係ない。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;君がReactを使うなら、Facebookが保持する特許に逆らうことはできない。
いつまでも。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;言い換えれば、代償。&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Facebook、それが君らの考えるオープンソースなのか?&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;・・・&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;fridgebook-inc&#34;&gt;Fridgebook Inc.&lt;/h2&gt;

&lt;p&gt;例として、君の会社「Fridgebook Inc.」はインテリジェントな冷蔵庫を販売しているとしよう。
君の冷蔵庫にはスクリーンが付いていて、独自のアプリケーションを実行していて、そのUIにはReactが使われている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://cdn-images-1.medium.com/max/800/1*vfurq6EY120rZCwkaVtsCg.png&#34; alt=&#34;Fridge&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;突然、Facebookは冷蔵庫業界への進出を決め、新製品「FBfridge」をわずか1週間後に世界中でローンチすると発表した。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;仮に、Facebookがあなたの特許の一部を「FBfridge」で露骨に侵害していた場合、どうすればいい?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;そう、&lt;strong&gt;君は即座に彼らを訴えることはできない。&lt;/strong&gt;
君は顧客が使うアプリにReactを使っている、だろ?&lt;/p&gt;

&lt;p&gt;もし他のもの(&lt;a href=&#34;https://vuejs.org/&#34;&gt;vue.js&lt;/a&gt;とか)に移行せずに訴えたら、Reactのために与えられたライセンスを即座に失い、思いがけず君自身が違反している状態になり、&lt;strong&gt;ソフトウェア不正使用の訴訟を約5000億ドルの会社から起こされる可能性と戦うことになる。&lt;/strong&gt;
君だけで。&lt;/p&gt;

&lt;p&gt;もちろん、君は顧客サービスを中断したくはない。&lt;/p&gt;

&lt;p&gt;だから、もし彼らを訴えたい、もしくは少なくともそれをするための効力を保持したいのであれば、&lt;strong&gt;記録的な期間でReactから移行できる解決策を見つける必要がある&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;それが君の陥るひどい窮地だ。そうだろ?
それはほとんど致命的な状況だ。
&lt;strong&gt;回避策?
最初からReactを使わないことだ。&lt;/strong&gt;
そうすれば権利を主張する自由を維持できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;注: 私は特許に支持も反対もしない。私はこの問題について明確な立場を持っていない。
ここでは私は単にギブアンドテイクのバランスを分析しているだけだ。
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;facebookの釈明&#34;&gt;Facebookの釈明&lt;/h2&gt;

&lt;p&gt;私が最後に見たとき、オープンソースの哲学は、よりよいソフトウェアを構築し、技術をより先に推し進めるために、有能な人々が砂粒に貢献するコミュニティを主要なテーマとしていた。&lt;/p&gt;

&lt;p&gt;それが、Apache Software FoundationやLinux Foundationなどの、&lt;strong&gt;オープンソース界の主要な基準組織の精神だ&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;それで、なぜ特許をオープンソースに持ち込んだのか?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Facebookは&lt;a href=&#34;https://code.facebook.com/posts/112130496157735/explaining-react-s-license/&#34;&gt;正式な釈明&lt;/a&gt;を発表した。
短く要約すると次のようなものだ:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Facebookは、多くのメリットのない特許請求を受けている。
それらに対抗すると多くのリソースを無駄にする。
そこで、(Reactのなどの)オープンソースプロジェクトの成功を利用して、ユーザが理論上メリットのない特許請求を提起するのを阻止するトロイの木馬を導入することに決めた。
彼らはこの制限を交換しない。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;しかしここに重要な部分がある&lt;/strong&gt;。
彼らは、オープンソースソフトウェアをリリースする他のすべての企業が同じことを &lt;em&gt;すべきだと主張している&lt;/em&gt; 。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;残念ながら、これはうまくいかず、以下のような要因により、いずれ再び業界のクローズドソース化を招くだろう：&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;それは市場最大級のプレーヤー間のコンセンサスを必要とする。
&lt;strong&gt;彼らは競合他社に対抗する力として実際の特許兵器(下の画像参照)を保有している。&lt;/strong&gt;
突然、これらの兵器の価値が$0になってしまう。&lt;/li&gt;
&lt;li&gt;そのコンセンサスに達するまず不可能だ。
参加しない悪徳企業が1つでもあれば、残りの企業は「守備/特許兵器」を維持する必要がある。&lt;/li&gt;
&lt;li&gt;すべての巨人達が「BSD + patents」スキームに基づくオープンソースに合意した場合でも、&lt;strong&gt;相互採用はしだいに無くなるだろう。
なぜかって?&lt;/strong&gt;
GoogleがProject Xを「BSD + patents」でリリースし、Amazonがそれを本当に気に入ったら、それを採用してGoogleに特許訴訟をする権利を永久に失うよりは、&lt;strong&gt;それを見限って自分たちで作ってしまうだろう。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;これは、そうした製品の周りにコミュニティが形成されないことを意味する。
コミュニティは、オープンソース製品の燃料でありインセンティブだ。
&lt;strong&gt;コミュニティに着火するチャンスがないならば、オープンソースにする理由はない。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;やがて、上記の状況が何度も繰り返されるにつれ、巨人達は製品をオープンソース化することに価値を見出さなくなり、業界は結局クローズドソースモデルに陥る。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://cdn-images-1.medium.com/max/800/1*VL9qHHrYQ_HMiShoNO4qeg.png&#34; alt=&#34;patent arsenals&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;(2012) &lt;a href=&#34;http://www.droid-life.com/2012/01/24/web-of-tech-patent-lawsuits-infographic/&#34;&gt;http://www.droid-life.com/2012/01/24/web-of-tech-patent-lawsuits-infographic/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;facebookによるオープンソース哲学の非倫理的な利用&#34;&gt;Facebookによるオープンソース哲学の非倫理的な利用&lt;/h2&gt;

&lt;p&gt;特許はアイデアや発明を保護する。
ほとんどの場合特許主張裁判は、白黒が付くのではなく、勝ち負けになる。
&lt;strong&gt;侵害の評価は複雑でコストがかかる。&lt;/strong&gt;
ひとつの訴訟を提起して遂行するのに、何十万か何百万ドルもかかり得る。
FBが君の特許を侵害したという85％の確信を持っていたとしても、それを追求するのに多額の費用がかかるだろう。&lt;/p&gt;

&lt;p&gt;それに加え、まずは別のフロントエンドフレームワークへの移行に投資し、&lt;strong&gt;さらにすべての顧客が新しいバージョンの製品を使用していることを確認する必要がある。&lt;/strong&gt;
(React Nativeを使用していたとするとどうなる? ユーザは一斉にはアプリをアップグレードしてくれないかもしれない!)
そうしなければ、訴訟を起こすことさえできない。
これがオープンソース哲学の誠実で倫理的な利用法だと思うか?&lt;/p&gt;

&lt;p&gt;要点:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;オープンソースは、「代償」取引ではない。
オープンソースは、よりよいソフトウェアを一緒に構築するためのコミュニティをつくることだ。
権利を交換するための市場として使用されるべきではない。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;君はどう思う?&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;・・・&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;なぜスタートアップはreactを避けるべきなのか&#34;&gt;なぜスタートアップはReactを避けるべきなのか&lt;/h2&gt;

&lt;p&gt;君がスタートアップを立ち上げているなら、君と君の投資家は、いつかは百万ドルの価値のある出口に到達することを望んでいるんだろう?&lt;/p&gt;

&lt;p&gt;君は、すべての買収元、特にApple、Microsoft、Google、Amazonなどの大企業に扉を開いておきたい。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;そうした企業は、Facebookに対抗して特許兵器を保有している可能性が高いし、そうでなかったとしても、いざという時にFacebookを訴える権利を放棄したくはない。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;君の製品がReactで構築されている場合、君を買収することはその権利を失うことを意味し、これは恐らく彼らが覚悟できていないことだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;基本的に、もし君を買収することがFacebookの特許侵害を訴える権利を永久に放棄することを意味するなら、
潜在的なバイヤーは10フィートの棒で君を触らない。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;よって、選択肢を残しておきたいのであれば…&lt;/p&gt;

&lt;h2 id=&#34;悪いことは言わない-reactを使うのをやめろ&#34;&gt;悪いことは言わない、Reactを使うのをやめろ&lt;/h2&gt;

&lt;p&gt;私は特に&lt;a href=&#34;https://github.com/developit/preact&#34;&gt;Preact&lt;/a&gt;が好きだが、FacebookにVirtual DOMやReact APIのソフトウェア特許を持っているかは定かではない。&lt;/p&gt;

&lt;p&gt;もし持っていたら、Preactはそれらの特許を侵害しているかもしれないので、&lt;a href=&#34;https://vuejs.org/&#34;&gt;vue.js&lt;/a&gt;や&lt;a href=&#34;https://cycle.js.org/&#34;&gt;cycle.js&lt;/a&gt;も見てみるといい。&lt;/p&gt;

&lt;p&gt;いずれ、知的財産の観点でPreactと&lt;a href=&#34;https://github.com/infernojs/inferno&#34;&gt;Inferno&lt;/a&gt;(もうひとつの軽量なReactの代替品)がどうなのかをコミュニティが明確にできることを願う。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上がRaúlの記事。&lt;/p&gt;

&lt;p&gt;Facebookの「BSD + Patents」への流れは、2015年4月に書かれた&lt;a href=&#34;https://code.facebook.com/posts/1639473982937255/updating-our-open-source-patent-grant/&#34;&gt;Updating Our Open Source Patent Grant&lt;/a&gt;というブログ記事でのアナウンスから始まったようだ。&lt;/p&gt;

&lt;p&gt;Reactのコミットログを見てみると、2014年10月、v16.0.0のアルファ版で「Apache License Version 2.0」から「BSD + Patents」に変わったことが以下のコミットからわかる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/facebook/react/commit/dcf415c2b91ce52fd5d4dd02b70875ba9d33290f&#34;&gt;BSD + PATENTS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;そのPATENTSの部分をより明確にしたのが2015年4月の以下のコミット。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/facebook/react/commit/b8ba8c83f318b84e42933f6928f231dc0918f864&#34;&gt;Update Patent Grant&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;このPATENTSの条項をApache Software Foundationが問題視し、2017年7月に、Apache Software Foundationは自身の全プロジェクトで「BSD + Patents」なOSSの使用を禁止した。
で、Reactのライセンスを「Apache License Version 2.0」に戻せと言ったのをFacebookがごね、ついには、2017/8/19に公式に&lt;a href=&#34;https://code.facebook.com/posts/112130496157735/explaining-react-s-license/&#34;&gt;「BSD + Patents」と心中する&lt;/a&gt;という声明を出して炎上した、というのが今までの流れ。&lt;/p&gt;

&lt;p&gt;Reactのほか、Jest、Flow、Immutable.js、GraphQLなんかもアウト。
うちのプロジェクトでちょっとJestとFlow使いたいと思ってたけど様子見だな。&lt;/p&gt;

&lt;p&gt;Facebookの、みんなもそうすべきだという思惑に反し、今のところはPalantirという企業だけが同様のライセンスを採用しているらしい。&lt;/p&gt;

&lt;p&gt;因みに、たまにBSD + patentsライセンスが&lt;a href=&#34;http://www.opensource.jp/osd/osd-japanese.html&#34;&gt;オープンソースの定義(OSD)&lt;/a&gt;に違反しているので、ReactはOSSですらないという主張があるが、これは間違いであるというのが大方の見方だ。
この主張は、&lt;a href=&#34;https://www.elcaminolegal.com/single-post/2016/10/04/Facebook-Reactjs-License&#34;&gt;Robert Pierceによる記事&lt;/a&gt;が多分発端で、OSDの第一条「再頒布の自由」で、ソフトウェアの再配布に関して報酬(fee)を要求してはいけないとしている部分に、BSD + patentsライセンスが違反しているというもの。
すなわち、Facebookを訴えないという報酬を要求しているという主張だが、この解釈は法律家によって&lt;a href=&#34;http://lu.is/blog/2016/10/31/reacts-license-necessary-and-open/&#34;&gt;否定されている&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;また、OSDの第五条「個人やグループに対する差別の禁止」に違反しているからという主張もあるが、これも微妙。
この主張はつまり、Facebookを訴えていないグループと比較して、訴えたグループを差別しているという主張だろうが、Apache License 2.0、EPL、MPL 2.0といったメジャーなライセンスでも、そのような「差別」をする(i.e. 訴えたら特許使用権を剥奪する)条項がある。
これらのライセンスは、OSDをメンテしている組織であるOSIに&lt;a href=&#34;https://opensource.org/licenses/alphabetical&#34;&gt;承認されている&lt;/a&gt;ので、そうした差別がOSDに決定的に違反することではないことは明らか。
(&lt;a href=&#34;https://lists.opensource.org/pipermail/license-discuss/2016-December/thread.html&#34;&gt;この議論&lt;/a&gt;を見るに、厳密には違反しているけど、原理主義よりも現実主義であるべきなので、受け入れるべきといった雰囲気。)
BSD + patentsライセンスによる「差別」のような条項が、特別なものでも新しいものでもないことは&lt;a href=&#34;https://opensource.org/node/862&#34;&gt;OSI自身も言及している&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;FacebookのBSD + patentsライセンスが特別なのは、その「差別」の範囲が広いことだ。
Apache License 2.0なんかは、訴えた特許を含むソフトウェアだけが使えなくなるが、Facebookのは、Facebookに対するいかなる特許訴訟でもひとたび起こせば、Facebookが提供する広範囲の(全ての?)OSSが使えなくなるというもので、これはあまりにジャイアン的だということで炎上した。&lt;/p&gt;

&lt;p&gt;Facebookはこの炎上をどう収めるつもりなんだろう。
これをきっかけにReactが廃れ、Vue.jsとかに行ってしまうんだろうか。
結局フロントエンドフレームワークは何を学べばいいの?
Angular?&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>WebdriverIOとChromeのヘッドレスモードで自動ブラウザテストするDockerイメージ: webdriverio-chrome</title>
          <link>https://www.kaitoy.xyz/2017/08/14/webdriverio-chrome/</link>
          <pubDate>Mon, 14 Aug 2017 10:53:17 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/08/14/webdriverio-chrome/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/08/04/browser-test-framework/&#34;&gt;2017年夏、ブラウザテストフレームワーク&lt;/a&gt;」の続き。
&lt;a href=&#34;https://www.servicenow.com/ja&#34;&gt;ServiceNow&lt;/a&gt;アプリケーションのブラウザテストをしたくて色々調べている。
前回は、フレームワークに&lt;a href=&#34;http://webdriver.io/&#34;&gt;WebdriverIO&lt;/a&gt;を使うと決めたところまで書いた。&lt;/p&gt;

&lt;p&gt;今回、最終的に、&lt;a href=&#34;http://webdriver.io/&#34;&gt;WebdriverIO&lt;/a&gt;、&lt;a href=&#34;http://webdriver.io/guide/testrunner/gettingstarted.html&#34;&gt;WDIO&lt;/a&gt;、&lt;a href=&#34;https://github.com/vvo/selenium-standalone&#34;&gt;selenium-standalone&lt;/a&gt;、&lt;a href=&#34;https://jasmine.github.io/&#34;&gt;Jasmine&lt;/a&gt;と、Chromeのヘッドレスモードを使って、Dockerコンテナ(&lt;a href=&#34;https://alpinelinux.org/&#34;&gt;Alpine Linux&lt;/a&gt;)上でテストスクリプトを実行して、ServiceNowのログイン画面のスクリーンショットが取れるところまでできた。&lt;/p&gt;

&lt;p&gt;そのコンテナイメージのDockerfileは&lt;a href=&#34;https://github.com/kaitoy/webdriverio-chrome&#34;&gt;GitHubに置いた&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;とりあえずalpine-linux&#34;&gt;とりあえずAlpine Linux&lt;/h2&gt;

&lt;p&gt;テスト環境の作成は自宅でやってるけど、DockerイメージにしてDocker Hubとかに上げておけば、社内でダウンロードしてそのまま再現できる。
ダウンロードに係る社内手続きも、Dockerイメージだけに対してやればいいので、中に何を詰め込んでも、後でライブラリとか追加しても、一回こっきりで済む。&lt;/p&gt;

&lt;p&gt;というわけでWebdriverIO環境をDockerコンテナとしてつくることにする。
とりあえず、自PC(Windows 10 Home x64)に入ってるVMware Workstation Player 12.5.5でCentOS 7 x64のVMを作り、そこにDockerをインストールした。&lt;/p&gt;

&lt;p&gt;次に、そのDockerを使って、WebdriverIO環境のベースにするAlpine Linuxをpullする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ docker pull alpine:edge
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Alpine Linuxは&lt;a href=&#34;https://busybox.net/&#34;&gt;BusyBox&lt;/a&gt;と&lt;a href=&#34;https://www.musl-libc.org/&#34;&gt;musl libc&lt;/a&gt;で構成された軽量な Linuxディストリビューション。
2016年2月に&lt;a href=&#34;https://www.brianchristner.io/docker-is-moving-to-alpine-linux/&#34;&gt;すべてのオフィシャルDockerイメージがAlpine Linuxベースになる&lt;/a&gt;というアナウンスがあったし、他にそれっぽいものもなかったので、これをベースに環境を作ることにした。
&lt;a href=&#34;https://www.gnu.org/software/libc/&#34;&gt;glibc&lt;/a&gt;じゃないのがちょっと気になるけど、まあ問題ないか。&lt;/p&gt;

&lt;p&gt;現在、&lt;a href=&#34;https://pkgs.alpinelinux.org/package/edge/community/x86_64/chromium&#34;&gt;Chrome 59&lt;/a&gt;のAlpine Linuxパッケージはedgeブランチ(i.e. 開発ブランチ)でしか作られていない。
pullするタグをedgeにしたのはそのため。
(因みに現時点でAlpine Linuxのlatestは3.6。)&lt;/p&gt;

&lt;p&gt;で、起動。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ docker run -it alpine:edge sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;chrome-chromium-インストール&#34;&gt;Chrome(Chromium)インストール&lt;/h2&gt;

&lt;p&gt;まずはChrome(がAlpine Linuxパッケージにはないので、実際にはChromium)と、ついでにChromeDriverをインストールする。
Alpine Linux独自のパッケージマネージャーである&lt;a href=&#34;https://wiki.alpinelinux.org/wiki/Alpine_Linux_package_management&#34;&gt;apk&lt;/a&gt;を使う。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/ # apk add --update chromium chromium-chromedriver
/ # chromium-browser -version
Chromium 59.0.3071.115
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;無事インストールできた。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://bufferings.hatenablog.com/entry/2017/05/03/181713&#34;&gt;この記事&lt;/a&gt;を参考にヘッドレスモードで実行してみる。
ヘッドレスモードにするために&lt;code&gt;--headless&lt;/code&gt;を付けて、一時的な制限事項で&lt;code&gt;--disable-gpu&lt;/code&gt;を付ける必要があって、コンテナの権限不足を回避するために&lt;code&gt;--no-sandbox&lt;/code&gt;を付ける。
(コンテナの権限不足回避には他に、&lt;code&gt;docker run&lt;/code&gt;に&lt;code&gt;--privileged&lt;/code&gt;や&lt;code&gt;--cap-add=SYS_ADMIN&lt;/code&gt;付ける&lt;a href=&#34;https://github.com/yukinying/chrome-headless-browser-docker&#34;&gt;方法がある&lt;/a&gt;。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/ # chromium-browser --headless --no-sandbox --disable-gpu https://example.com/
[0811/145902.894023:WARNING:dns_config_service_posix.cc(326)] Failed to read DnsConfig.
[0811/145902.906137:FATAL:udev_loader.cc(38)] Check failed: false.
Received signal 6
  r8: 0000000000000061  r9: 00007fe3fe01c066 r10: 0000000000000008 r11: 0000000000000246
 r12: 00007fe3fe01bed0 r13: 00007fe3fe01be80 r14: 0000000000000000 r15: 0000000000000000
  di: 0000000000000002  si: 00007fe3fe01bda0  bp: 00007fe3fe01bda0  bx: 0000000000000006
  dx: 0000000000000000  ax: 0000000000000000  cx: ffffffffffffffff  sp: 00007fe3fe01bd88
  ip: 00007fe412a2f769 efl: 0000000000000246 cgf: 0000000000000033 erf: 0000000000000000
 trp: 0000000000000000 msk: 0000000000000000 cr2: 0000000000000000
[end of stack trace]
Calling _exit(1). Core file will not be generated.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;エラーになった。&lt;/p&gt;

&lt;p&gt;最初のWARNINGは置いといて、FATALのほうは、udev_loader.ccというのでエラーになってる。&lt;/p&gt;

&lt;p&gt;エラーメッセージでググったら、&lt;a href=&#34;http://qiita.com/dd511805/items/dfe03c5486bf1421875a&#34;&gt;Qiitaに同じエラーを解決している記事&lt;/a&gt;が。
よくわからないが、&lt;a href=&#34;https://pkgs.alpinelinux.org/package/v3.5/main/x86_64/udev&#34;&gt;udev&lt;/a&gt;と&lt;a href=&#34;https://pkgs.alpinelinux.org/package/v3.6/main/x86_64/ttf-freefont&#34;&gt;ttf-freefont&lt;/a&gt;を入れればいいらしい。
深く考えずにそれに従うことにする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/ # apk add udev ttf-freefont
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、再度実行。
(ちゃんと動いてるか分かりやすくするために&lt;code&gt;--dump-dom&lt;/code&gt;も付けた。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/ # chromium-browser --headless --no-sandbox --disable-gpu --dump-dom https://example.com/
[0811/151303.698629:WARNING:dns_config_service_posix.cc(326)] Failed to read DnsConfig.
&amp;lt;body&amp;gt;
&amp;lt;div&amp;gt;
    &amp;lt;h1&amp;gt;Example Domain&amp;lt;/h1&amp;gt;
    &amp;lt;p&amp;gt;This domain is established to be used for illustrative examples in documents. You may use this
    domain in examples without prior coordination or asking for permission.&amp;lt;/p&amp;gt;
    &amp;lt;p&amp;gt;&amp;lt;a href=&amp;quot;http://www.iana.org/domains/example&amp;quot;&amp;gt;More information...&amp;lt;/a&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;


&amp;lt;/body&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;動いた!&lt;/p&gt;

&lt;h2 id=&#34;フォント追加&#34;&gt;フォント追加&lt;/h2&gt;

&lt;p&gt;前節で参考にした&lt;a href=&#34;http://qiita.com/dd511805/items/dfe03c5486bf1421875a&#34;&gt;Qiitaの記事&lt;/a&gt;に、文字化け対策としてフォントを追加する手順も書いてあったのでそれもやる。&lt;/p&gt;

&lt;p&gt;まず試しに、何もしないでスクリーンショットを撮ってみる。
&lt;code&gt;--screenshot&lt;/code&gt;オプションで。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/ # chromium-browser --headless --no-sandbox --disable-gpu --screenshot https://www.google.co.jp/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;するとやはり文字化けしている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/webdriverio-chrome/garblings.png&#34; alt=&#34;garblings.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.google.com/get/noto/&#34;&gt;Google Noto Fonts&lt;/a&gt;を入れて対応する。
(因みにNotoはNo Tofuの略で、文字化けした時に出る、クエスチョンマークが乗った豆腐の撲滅を目指して開発されたフォント。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/ # apk add curl
/ # cd /tmp/
/tmp # curl https://noto-website.storage.googleapis.com/pkgs/NotoSansCJKjp-hinte
/tmp # unzip NotoSansCJKjp-hinted.zip
/tmp # mkdir -p /usr/share/fonts/noto
/tmp # cp *.otf /usr/share/fonts/noto
/tmp # chmod 644 -R /usr/share/fonts/noto/
/tmp # fc-cache -fv
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;後半に実行してるコマンドの詳細はよくわからないが、文字化けは直った。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/webdriverio-chrome/garblings_fixed.png&#34; alt=&#34;garblings_fixed.png&#34; /&gt;
&lt;/p&gt;

&lt;h2 id=&#34;webdriverioインストール&#34;&gt;WebdriverIOインストール&lt;/h2&gt;

&lt;p&gt;次にWebdriverIOをインストールする。
&lt;a href=&#34;https://yarnpkg.com/lang/en/&#34;&gt;Yarn&lt;/a&gt;でインストールして&lt;a href=&#34;https://nodejs.org/ja/&#34;&gt;Node.js&lt;/a&gt;で動かすので、まずそれらをapkで入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/tmp # apk add nodejs yarn
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、プロジェクトを作ってWebdriverIOを追加。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/tmp # mkdir /root/webdriverio-chrome
/tmp # cd /root/webdriverio-chrome
~/webdriverio-chrome # yarn init
~/webdriverio-chrome # yarn add webdriverio --dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;package.jsonのscriptsを編集して、WebdriverIO付属のテストランナであるWDIOを使えるようにする。&lt;/p&gt;

&lt;p&gt;package.json:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;webdriverio-chrome&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.0.1&amp;quot;,
  &amp;quot;description&amp;quot;: &amp;quot;Browser test stack with WebdriverIO and headless Chrome&amp;quot;,
  &amp;quot;scripts&amp;quot;: {
    &amp;quot;test&amp;quot;: &amp;quot;wdio&amp;quot;
  },
  &amp;quot;author&amp;quot;: &amp;quot;Kaito Yamada&amp;quot;,
  &amp;quot;license&amp;quot;: &amp;quot;MIT&amp;quot;,
  &amp;quot;devDependencies&amp;quot;: {
    &amp;quot;webdriverio&amp;quot;: &amp;quot;^4.8.0&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;wdioの設定ファイル生成&#34;&gt;WDIOの設定ファイル生成&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://webdriver.io/guide/testrunner/gettingstarted.html&#34;&gt;WDIOのconfigコマンド&lt;/a&gt;でWDIO Configuration Helperを起動し、設定ファイルwdio.conf.jsをインタラクティブに生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # yarn test -- config
yarn test v0.27.5
$ wdio &amp;quot;config&amp;quot;

=========================
WDIO Configuration Helper
=========================

? Where do you want to execute your tests? On my local machine
? Which framework do you want to use? jasmine
? Shall I install the framework adapter for you? No
? Where are your test specs located? ./test/specs/**/*.js
? Which reporter do you want to use?  spec - https://github.com/webdriverio/wdio-spec-reporter
? Shall I install the reporter library for you? No
? Do you want to add a service to your test setup?  selenium-standalone - https://github.com/webdriverio/wdio-selenium-standalone-service
? Shall I install the services for you? No
? Level of logging verbosity verbose
? In which directory should screenshots gets saved if a command fails? ./errorShots/
? What is the base url? http://localhost

Configuration file was created successfully!
To run your tests, execute:

$ wdio wdio.conf.js

Done in 53.58s.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;WDIO Configuration Helperで、テストフレームワークは&lt;a href=&#34;https://mochajs.org/&#34;&gt;Mocha&lt;/a&gt;か&lt;a href=&#34;https://jasmine.github.io/&#34;&gt;Jasmine&lt;/a&gt;か&lt;a href=&#34;https://cucumber.io/&#34;&gt;Cucumber&lt;/a&gt;から&lt;a href=&#34;http://webdriver.io/guide/testrunner/frameworks.html&#34;&gt;選択できる&lt;/a&gt;。
ServiceNowのテストフレームワーク(ATF)がJasmine使ってるので、一応それに合わせてJasmineにした。
ATFは今のところ使うつもりはないけど。&lt;/p&gt;

&lt;p&gt;レポータ(標準出力へテスト結果を出力するコンポーネント)は妙に色々ある中から、雰囲気で&lt;a href=&#34;http://webdriver.io/guide/reporters/spec.html&#34;&gt;spec&lt;/a&gt;を選択。&lt;/p&gt;

&lt;p&gt;サービス(テスト実行に必要な準備などをしてくれるコンポーネント)には&lt;a href=&#34;http://webdriver.io/guide/services/selenium-standalone.html&#34;&gt;selenium-standalone&lt;/a&gt;を選択。
こいつは、テスト実行前に、npmパッケージの&lt;a href=&#34;https://www.npmjs.com/package/selenium-standalone&#34;&gt;selenium-standalone&lt;/a&gt;を使って&lt;a href=&#34;http://docs.seleniumhq.org/download/&#34;&gt;Selenium Server&lt;/a&gt;をダウンロードして起動したり、WebDriverをセットアップしてくれたりする。&lt;/p&gt;

&lt;p&gt;因みにサービスには他に、&lt;a href=&#34;http://webdriver.io/guide/services/browserstack.html&#34;&gt;browserstack&lt;/a&gt;とか&lt;a href=&#34;http://webdriver.io/guide/services/appium.html&#34;&gt;appium&lt;/a&gt;とか&lt;a href=&#34;http://webdriver.io/guide/services/phantomjs.html&#34;&gt;phantomjs&lt;/a&gt;とかがある。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Shall I install …&lt;/code&gt;という質問には全てnoで回答した。
でないとWDIOがnpm installしようとして、npmが無くて以下のようなエラーになるので。
(apkでは、npmは&lt;a href=&#34;https://pkgs.alpinelinux.org/package/edge/main/x86_64/nodejs&#34;&gt;nodejs&lt;/a&gt;パッケージに入ってなくて、&lt;a href=&#34;https://pkgs.alpinelinux.org/package/edge/main/x86_64/nodejs-npm&#34;&gt;nodejs-npm&lt;/a&gt;に入ってる。)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Installing wdio packages:
/root/webdriverio-chrome/node_modules/webdriverio/build/lib/cli.js:278
                    throw err;
                    ^

Error: Command failed: npm i -D wdio-jasmine-framework
/bin/sh: npm: not found

    at ChildProcess.exithandler (child_process.js:204:12)
    at emitTwo (events.js:106:13)
    at ChildProcess.emit (events.js:191:7)
    at maybeClose (internal/child_process.js:891:16)
    at Socket.&amp;lt;anonymous&amp;gt; (internal/child_process.js:342:11)
    at emitOne (events.js:96:13)
    at Socket.emit (events.js:188:7)
    at Pipe._handle.close [as _onclose] (net.js:497:12)
error Command failed with exit code 1.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;生成された設定ファイルは以下の感じ。(コメントは省略してる。)&lt;/p&gt;

&lt;p&gt;wdio.conf.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;exports.config = {
    specs: [
        &#39;./test/specs/**/*.js&#39;
    ],
    exclude: [
        // &#39;path/to/excluded/files&#39;
    ],
    maxInstances: 10,
    capabilities: [{
        maxInstances: 5,
        browserName: &#39;firefox&#39;,
    }],

    sync: true,
    logLevel: &#39;verbose&#39;,
    coloredLogs: true,
    bail: 0,
    screenshotPath: &#39;./errorShots/&#39;,
    baseUrl: &#39;http://localhost&#39;,
    waitforTimeout: 10000,
    connectionRetryTimeout: 90000,
    connectionRetryCount: 3,

    services: [&#39;selenium-standalone&#39;],

    framework: &#39;jasmine&#39;,
    reporters: [&#39;spec&#39;],
    jasmineNodeOpts: {
        defaultTimeoutInterval: 50000,
        expectationResultHandler: function(passed, assertion) {
            // do something
        }
    },
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;npmパッケージとjava追加&#34;&gt;npmパッケージとJava追加&lt;/h2&gt;

&lt;p&gt;WDIO Configuration Helperの&lt;code&gt;Shall I install …&lt;/code&gt;でnoした分は自分でインストールしておく。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # yarn add wdio-jasmine-framework wdio-spec-reporter wdio-selenium-standalone-service selenium-standalone --dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;したらエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;error /root/webdriverio-chrome/node_modules/fibers: Command failed.
Exit code: 127
Command: sh
Arguments: -c node build.js || nodejs build.js
Directory: /root/webdriverio-chrome/node_modules/fibers
Output:
`linux-x64-48` exists; testing
Problem with the binary; manual build incoming
node-gyp not found! Please ensure node-gyp is in your PATH--
Try running: `sudo npm install -g node-gyp`
sh: nodejs: not found
spawn node-gyp ENOENT
info Visit https://yarnpkg.com/en/docs/cli/add for documentation about this command.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/nodejs/node-gyp&#34;&gt;node-gyp&lt;/a&gt;が無いと。
では追加する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # yarn global add node-gyp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;node-gypのREADME.md読むと、PythonとmakeとC/C++コンパイラが要るとあるので、それも入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # apk add python make gcc g++
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、再度、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # yarn add wdio-jasmine-framework wdio-spec-reporter wdio-selenium-standalone-service selenium-standalone --dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;したら入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あと、Selenium ServerがJavaで動くので、Javaも入れておく。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # apk add openjdk8
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;wdio-conf-jsの修正&#34;&gt;wdio.conf.jsの修正&lt;/h2&gt;

&lt;p&gt;生成されたwdio.conf.jsはFirefoxを使うようになっているなどの問題があるので修正する。
参考にしたのは&lt;a href=&#34;https://stackoverflow.com/questions/42303119/selenium-webdriverio-chrome-headless&#34;&gt;Stack Overflowの回答&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;     capabilities: [{
     maxInstances: 5,
-        browserName: &#39;firefox&#39;
+        browserName: &#39;chrome&#39;,
+        chromeOptions: {
+            binary: &#39;/usr/bin/chromium-browser&#39;,
+            args: [
+                &#39;headless&#39;,
+                &#39;disable-gpu&#39;,
+                &#39;no-sandbox&#39;,
+            ],
+        },
     }],
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;browserName&lt;/code&gt;を&lt;code&gt;firefox&lt;/code&gt;から&lt;code&gt;chrome&lt;/code&gt;に変えて、ヘッドレスモードで動かすためのオプションを指定している。
また、普通のChromeとは実行ファイルの名前が違うので、&lt;code&gt;binary&lt;/code&gt;で指定している。&lt;/p&gt;

&lt;h2 id=&#34;テスト作成と実行&#34;&gt;テスト作成と実行&lt;/h2&gt;

&lt;p&gt;テストはとりあえず&lt;a href=&#34;http://blog.asial.co.jp/1484&#34;&gt;この記事&lt;/a&gt;を参考に以下のようなものを書いた。&lt;/p&gt;

&lt;p&gt;test-sample.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;describe(&#39;Sample&#39;, function() {
    it(&amp;quot;takes a screenshot of www.google.co.jp&amp;quot;, function() {
        browser.url(&#39;https://www.google.co.jp/&#39;);
        browser.saveScreenshot(&#39;./screenshots/google.png&#39;);
    });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを実行すると、&lt;code&gt;https://www.google.co.jp/&lt;/code&gt;をブラウザで開いて、スクリーンショットを撮る。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これを&lt;code&gt;~/webdriverio-chrome/test/specs/&lt;/code&gt;において、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # yarn test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;でテスト実行。
したらエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # yarn test
yarn test v0.27.5
$ wdio
[06:43:04]  COMMAND     POST     &amp;quot;/wd/hub/session&amp;quot;
[06:43:04]  DATA                {&amp;quot;desiredCapabilities&amp;quot;:{&amp;quot;javascriptEnabled&amp;quot;:true,&amp;quot;locationContextEnabled&amp;quot;:true,&amp;quot;handlesAlerts&amp;quot;:true,&amp;quot;rotatable&amp;quot;:true,&amp;quot;maxInstances&amp;quot;:5,&amp;quot;browserName&amp;quot;:&amp;quot;chrome&amp;quot;,&amp;quot;chromeOptions&amp;quot;:{&amp;quot;binary&amp;quot;:&amp;quot;/usr/bin/chromium-browser&amp;quot;,&amp;quot;args&amp;quot;:[&amp;quot;headless&amp;quot;,&amp;quot;disable-gpu&amp;quot;,&amp;quot;no-sandbox&amp;quot;]},&amp;quot;loggingPrefs&amp;quot;:{&amp;quot;browser&amp;quot;:&amp;quot;ALL&amp;quot;,&amp;quot;driver&amp;quot;:&amp;quot;ALL&amp;quot;},&amp;quot;requestOrigins&amp;quot;:{&amp;quot;url&amp;quot;:&amp;quot;http://webdriver.io&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;4.6.2&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;webdriverio&amp;quot;}}}
ERROR: An unknown server-side error occurred while processing the command. (UnknownError:13)
chrome
Error: An unknown server-side error occurred while processing the command. (UnknownError:13)

error Command failed with exit code 1.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;サーバサイドでよくわからないエラーが起きたとのこと。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;試しに手動でSelenium Serverを起動してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # node ./node_modules/.bin/selenium-standalone start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正常に起動する。&lt;/p&gt;

&lt;p&gt;ChromeDriverはどうか。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # /usr/bin/chromedriver
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これも起動する。はて。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/webdriverio/wdio-selenium-standalone-service/blob/v0.0.9/lib/launcher.js&#34;&gt;wdio-selenium-standalone-serviceのソース&lt;/a&gt;を見てみたら、selenium-standaloneの&lt;code&gt;install&lt;/code&gt;を呼んでいた。
これはSelenium ServerとChromeDriverをダウンロードする機能だ。
コンテナ内を確認したら、&lt;code&gt;node_modules/selenium-standalone/.selenium/chromedrive
r/2.31-x64-chromedriver&lt;/code&gt;というのが出来てた。
これがselenium-standaloneがダウンロードしたChromeDriverだろうが、Apline Linux用ではないので、&lt;code&gt;ldd&lt;/code&gt;してやるとたくさんエラーが出る。
selenium-standaloneがこれを実行しようとしたせいでテスト実行がエラーになったんだろう。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.com/@jlchereau/how-to-configure-webdrivier-io-with-selenium-standalone-and-additional-browsers-9369d38bc4d1&#34;&gt;Mediumの記事&lt;/a&gt;などを参考にして、wdio.conf.jsを以下のように修正して、ChromeDriverのバイナリを指定してやったら動いた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;     services: [&#39;selenium-standalone&#39;],
+    seleniumArgs: {
+        javaArgs: [
+            &#39;-Dwebdriver.chrome.driver=/usr/bin/chromedriver&#39;
+        ]
+    },
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;プロキシ対策&#34;&gt;プロキシ対策&lt;/h2&gt;

&lt;p&gt;社内で使うには、ベーシック認証付きのプロキシを突破しないといけない。&lt;/p&gt;

&lt;p&gt;今回作った環境をクールな図にするとこんな↓感じ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/webdriverio-chrome/internet_accesses.png&#34; alt=&#34;internet_accesses.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;なので、二か所あるインターネッツアクセスをプロキシ対応させる必要がある。
図の左のアクセスについては、&lt;a href=&#34;https://github.com/webdriverio/wdio-selenium-standalone-service/blob/master/lib/launcher.js&#34;&gt;wdio-selenium-standalone-serviceのソース&lt;/a&gt;を見たりして、wdio.conf.jsを次のように修正すればいいことが分かった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;     services: [&#39;selenium-standalone&#39;],
     seleniumArgs: {
         javaArgs: [
             &#39;-Dwebdriver.chrome.driver=/usr/bin/chromedriver&#39;,
         ],
     },
+    seleniumInstallArgs: {
+        proxy: &#39;http://userId:password@proxy.com:8080&#39;,
+    },
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;図の右のアクセスについては、プロキシのベーシック認証のクレデンシャルを指定するオプションがChromeにないので、&lt;a href=&#34;https://github.com/sjitech/proxy-login-automator&#34;&gt;proxy-login-automator&lt;/a&gt;を使うことにして、wdio.conf.jsには次のように追記しておく。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;         chromeOptions: {
             binary: &#39;/usr/bin/chromium-browser&#39;,
             args: [
                 &#39;headless&#39;,
                 &#39;disable-gpu&#39;,
                 &#39;no-sandbox&#39;,
+                &#39;proxy-server=localhost:18080&#39;,
             ],
         },
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで、テスト実行前に、以下みたいにproxy-login-automatorを起動しておけばいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # node node_modules/.bin/proxy-login-automator.js -local_port 18080 -remote_host proxy.com -remote_port 8080 -usr userId -pwd password`
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;以上の操作をまとめたDockerfileが以下。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-dockerfile&#34;&gt;From alpine:edge

ADD package.json wdio.conf.js yarn.lock test-sample.js /root/webdriverio-chrome/

RUN apk add --update --no-cache \
            udev \
            ttf-freefont \
            chromium \
            chromium-chromedriver \
            openjdk8 \
            nodejs \
            yarn \
            make gcc g++ python \
            curl &amp;amp;&amp;amp; \
    cd /tmp &amp;amp;&amp;amp; \
    curl https://noto-website.storage.googleapis.com/pkgs/NotoSansCJKjp-hinted.zip -O &amp;amp;&amp;amp; \
    unzip NotoSansCJKjp-hinted.zip &amp;amp;&amp;amp; \
    mkdir -p /usr/share/fonts/noto &amp;amp;&amp;amp; \
    cp *.otf /usr/share/fonts/noto &amp;amp;&amp;amp; \
    chmod 644 -R /usr/share/fonts/noto/ &amp;amp;&amp;amp; \
    fc-cache -fv &amp;amp;&amp;amp; \
    cd /root/webdriverio-chrome/ &amp;amp;&amp;amp; \
    yarn global add node-gyp &amp;amp;&amp;amp; \
    yarn &amp;amp;&amp;amp; \
    mkdir -p test/specs &amp;amp;&amp;amp; \
    mv test-sample.js test/specs/ &amp;amp;&amp;amp; \
    mkdir screenshots &amp;amp;&amp;amp; \
    yarn global remove node-gyp &amp;amp;&amp;amp; \
    rm -rf /root/.node-gyp &amp;amp;&amp;amp; \
    rm -rf /tmp/* &amp;amp;&amp;amp; \
    yarn cache clean &amp;amp;&amp;amp; \
    apk del --purge make gcc g++ python curl

WORKDIR /root/webdriverio-chrome
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できるイメージを小さくするため、レイヤを減らしたり、ビルド用パッケージを消したりしてる。
&lt;a href=&#34;http://qiita.com/minamijoyo/items/711704e85b45ff5d6405&#34;&gt;Multi-Stage build&lt;/a&gt;が&lt;a href=&#34;https://hub.docker.com/&#34;&gt;Docker Hub&lt;/a&gt;のAutomated Buildで&lt;a href=&#34;https://github.com/docker/hub-feedback/issues/1039&#34;&gt;もうすぐサポートされる&lt;/a&gt;ので、そしたらもう少しきれいに書き直せるはず。&lt;/p&gt;

&lt;p&gt;(後日書き直して&lt;a href=&#34;https://github.com/kaitoy/webdriverio-chrome/blob/master/Dockerfile&#34;&gt;きれいになった&lt;/a&gt;。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;最終的なpackage.jsonは&lt;a href=&#34;https://github.com/kaitoy/webdriverio-chrome/blob/v0.0.3/package.json&#34;&gt;これ&lt;/a&gt;。
wdio.conf.jsは&lt;a href=&#34;https://github.com/kaitoy/webdriverio-chrome/blob/v0.0.3/wdio.conf.js&#34;&gt;これ&lt;/a&gt;。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>2017年夏、ブラウザテストフレームワーク</title>
          <link>https://www.kaitoy.xyz/2017/08/04/browser-test-framework/</link>
          <pubDate>Fri, 04 Aug 2017 15:29:37 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/08/04/browser-test-framework/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/07/12/2017-selenium-headless-browsers/&#34;&gt;2017年夏、Selenium、ヘッドレスブラウザ&lt;/a&gt;」の続き。
&lt;a href=&#34;https://www.servicenow.com/ja&#34;&gt;ServiceNow&lt;/a&gt;アプリケーションのブラウザテストをしたくて色々調べている。
前回は、Selenium(WebDriver)とChromeのヘッドレスモードを使うのがよさそうというところまで書いた。&lt;/p&gt;

&lt;p&gt;この記事では、ブラウザテストフレームワークを選ぶ。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;ブラウザ操作ツールとかブラウザテストフレームワークとか&#34;&gt;ブラウザ操作ツールとかブラウザテストフレームワークとか&lt;/h2&gt;

&lt;p&gt;Seleniumを直接使って、&lt;a href=&#34;http://junit.org/junit4/&#34;&gt;JUnit&lt;/a&gt;なんかのテストフレームワークでブラウザテストを書くこともできるけど、それは結構つらい。
Seleniumは低レベルなブラウザ操作APIを提供するので、単純にテスト書き辛いし、動的サイトを扱うときには、かなり気を使ってwait処理を入れていかないとテストが安定しない。
テスト前に、WebDriverの準備をしないといけなかったりするのも面倒。&lt;/p&gt;

&lt;p&gt;なので、昨今はもう少し高級なツールやフレームワークを使うのが普通な模様。
あまり知らなかったので色々記事を読んだ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://qiita.com/cognitom/items/27b7375bea653b414c8f&#34;&gt;Seleniumアレルギーのための処方箋&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://qiita.com/cognitom/items/6cce719b57341769c14d&#34;&gt;ブラウザテストツール総まとめ・2016年夏版&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://postd.cc/a-complete-guide-to-testing-javascript-in-2017/&#34;&gt;2017年JavaScriptのテスト概論&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;結果、ブラウザ操作ツールやブラウザテストフレームワークには以下のようなものがあることが分かった。
(SeleniumやWebDriver系じゃないのも含む。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://nightwatchjs.org/&#34;&gt;Nightwatch.js&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は6835。&lt;/p&gt;

&lt;p&gt;JavaScriptでブラウザテストを書けるフレームワーク。
WebDriverプロトコルに対応していて、Seleniumと異なる独自のクライアントAPIを実装。
つまり使えるブラウザの幅が広い。&lt;/p&gt;

&lt;p&gt;テストフレームワークは独自のもの。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://webdriver.io/&#34;&gt;WebdriverIO&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は3217。&lt;/p&gt;

&lt;p&gt;JavaScriptでブラウザを操作できるツール。
WebDriverプロトコルに対応していて、Seleniumと異なる独自のクライアントAPI(ラッパ?)を実装。
つまり使えるブラウザの幅が広い。&lt;/p&gt;

&lt;p&gt;独自のテストランナである&lt;a href=&#34;http://webdriver.io/guide/testrunner/gettingstarted.html&#34;&gt;WDIO&lt;/a&gt;付きで、テストフレームワークに&lt;a href=&#34;https://mochajs.org/&#34;&gt;Mocha&lt;/a&gt;、&lt;a href=&#34;https://jasmine.github.io/&#34;&gt;Jasmine&lt;/a&gt;、&lt;a href=&#34;https://cucumber.io/&#34;&gt;Cucumber&lt;/a&gt;など、いろいろ利用できる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.protractortest.org/#/&#34;&gt;Protractor&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は6801。&lt;/p&gt;

&lt;p&gt;JavaScriptでブラウザテストを書けるフレームワーク。
WebDriverプロトコルに対応していて、&lt;a href=&#34;https://github.com/SeleniumHQ/selenium/wiki/WebDriverJs&#34;&gt;selenium-webdriver&lt;/a&gt;をラップしたAPIを提供する。
WebDriverなのでブラウザはなんでも。&lt;/p&gt;

&lt;p&gt;テストフレームワークは、Jasmine、Mocha、Cucumberのほか、いろいろ選べる模様。&lt;/p&gt;

&lt;p&gt;AngularとAngularJS向けだけどそれ以外にも使える。
Google製なので信頼感があるし、ドキュメントもコミュニティもしっかりしてる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://casperjs.org/&#34;&gt;Casper.js&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は6337。&lt;/p&gt;

&lt;p&gt;JavaScriptでブラウザテストを書けるフレームワーク。
使えるブラウザは&lt;a href=&#34;http://phantomjs.org/&#34;&gt;PhantomJS&lt;/a&gt;か&lt;a href=&#34;https://slimerjs.org/&#34;&gt;SlimerJS&lt;/a&gt;だけで、多分WebDriver使ってない。&lt;/p&gt;

&lt;p&gt;テストフレームワークは独自のもの。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.nightmarejs.org/&#34;&gt;Nightmare&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は12964。&lt;/p&gt;

&lt;p&gt;JavaScriptでブラウザを操作できるツール。
ブラウザは、昔の1系はPhantomJSを使ってたけど、今の2系は&lt;a href=&#34;https://electron.atom.io/&#34;&gt;Electron&lt;/a&gt;。
WebDriverは使ってないはず。&lt;/p&gt;

&lt;p&gt;テストフレームワーク機能は付いてないけど、同じ作者の&lt;a href=&#34;https://open.segment.com/niffy&#34;&gt;Niffy&lt;/a&gt;というNightmareベースのツールがちょっとそれっぽい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://devexpress.github.io/testcafe/&#34;&gt;TestCafe&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は3029。&lt;/p&gt;

&lt;p&gt;JavaScriptでブラウザテストを書けるフレームワーク。
すごい多機能っぽいし、TypeScriptやasync/awaitをサポートしててなんかモダン。
WebDriverは使ってないっぽいけど、Chrome、Firefox、IE、Edge、Safariなど、一通りのブラウザが使える。
なぜかリモートテストもできる。&lt;/p&gt;

&lt;p&gt;どうもSelenium 1みたいにJavaScriptコードを挿入してテスト実行するらしいんだけど、よくわからない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://zombie.js.org/&#34;&gt;Zombie.js&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は4608。&lt;/p&gt;

&lt;p&gt;JavaScriptでjsdomを操作できるツール。
なぜか妙にアサーション機能に凝っている。&lt;/p&gt;

&lt;p&gt;WebDriverは使ってないはず。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/OnetapInc/chromy&#34;&gt;Chromy&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は294。&lt;/p&gt;

&lt;p&gt;JavaScriptでChromeを操作できるツール。
&lt;a href=&#34;https://github.com/cyrus-and/chrome-remote-interface&#34;&gt;chrome-remote-interface&lt;/a&gt;をラップして、
NightmareっぽいAPIを提供する。&lt;/p&gt;

&lt;p&gt;WebDriverは使ってない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://codeception.com/&#34;&gt;Codeception&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は2900。&lt;/p&gt;

&lt;p&gt;PHPUnitとSeleniumをラップして、ユーザ視点のブラウザテスト(受入テスト)をPHPで書けるフレームワーク。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://teamcapybara.github.io/capybara/&#34;&gt;Capybara&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は7937。&lt;/p&gt;

&lt;p&gt;Seleniumをラップして、ブラウザテスト(受入テスト)をRubyで書けるフレームワーク。
テストフレームワークはRack::Testを始め、いろいろ選べる模様。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.gebish.org/&#34;&gt;Geb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は759。&lt;/p&gt;

&lt;p&gt;Seleniumをラップして、 JUnitやTestNGと連携して、ブラウザテストをGroovyで書けるフレームワーク。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://selenide.org/&#34;&gt;Selenide&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は555。&lt;/p&gt;

&lt;p&gt;Seleniumをラップして、ブラウザテストをJavaで書けるフレームワーク。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これらよりさらに高級なツールに、&lt;a href=&#34;http://codecept.io/&#34;&gt;CodeceptJS&lt;/a&gt;というのがあって、これはJavaScriptでユーザ視点のブラウザテスト(受入テスト)を書けるフレームワーク。
基本的にはMochaとWebdriverIOをラップして、より抽象的なAPIを提供する。
WebdriverIOをProtractorとかNightmareとか&lt;a href=&#34;http://appium.io/&#34;&gt;Appium&lt;/a&gt;に代えられて、色んな環境のテストが統一的なAPIで書ける。
すごいけどバグを踏んだ時辛そう。&lt;/p&gt;

&lt;p&gt;また、ブラウザテストの文脈でよく名前が出る&lt;a href=&#34;http://karma-runner.github.io/1.0/index.html&#34;&gt;Karma&lt;/a&gt;は、テストフレームワークではなくて、HTTPサーバを起動して、テストを実行するためのHTMLを生成して、ブラウザを起動してそれを読み込んでくれたりするツール(i.e. テストランナ)。
主にユニットテストを色んなブラウザで実行するためのもので、ServiceNowのようなSaaSのテストには使えないはず。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;どれを使うか。&lt;/p&gt;

&lt;p&gt;ServiceNowアプリの開発がJavaScriptなので、テストもJavaScriptで書いてユニバーサルな感じにしたい。
のでCodeceptionとCapybaraとGebとSelenideは無し。&lt;/p&gt;

&lt;p&gt;テストのリモート実行やクロスブラウザテストを見据えてWebDriver使ってたほうがよさそうなので、
NightmareとCasper.jsとZombie.jsとChromyも無し。&lt;/p&gt;

&lt;p&gt;TestCafeはWebDriverにこだわらなければよさそうだけど、今回はWebDriverで行きたい気分なのでパス。&lt;/p&gt;

&lt;p&gt;Protractorはよさそうだったけど、Angularで開発してるわけではないので、利用するのはちょっと違和感が。&lt;/p&gt;

&lt;p&gt;Nightwatch.jsは、全部メソッドチェーンでつなげる形で書くので、ブラウザ操作とアサーションがごっちゃになるのがちょっと見にくそう。
テストフレームワークは自分の好みで選びたい。&lt;/p&gt;

&lt;p&gt;ということで残ったのがWebdriverIO。
ややドキュメントが少なそうなのと、★が比較的少ないのが懸念。
ProtractorかNightwatch.jsにしとけばよかったってなりそうではある。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2017/08/14/webdriverio-chrome/&#34;&gt;WebdriverIOの環境を構築した記事&lt;/a&gt;を書いた。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>2017年夏、Selenium、ヘッドレスブラウザ</title>
          <link>https://www.kaitoy.xyz/2017/07/12/2017-selenium-headless-browsers/</link>
          <pubDate>Wed, 12 Jul 2017 22:36:22 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/07/12/2017-selenium-headless-browsers/</guid>
          <description>

&lt;p&gt;現在仕事で&lt;a href=&#34;https://www.servicenow.com/ja&#34;&gt;ServiceNow&lt;/a&gt;上で動くアプリケーションを開発していて、それのブラウザテストをどうやろうかというのを少し考えたので、書き残しておく。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;servicenowとは&#34;&gt;ServiceNowとは&lt;/h1&gt;

&lt;p&gt;本題とほとんど関係ないけど、一応ServiceNowに簡単に触れる。&lt;/p&gt;

&lt;p&gt;ServiceNowはITサービス管理のSaaS。
世界的にはITサービス管理のデファクトスタンダードとなっているが、日本ではこれから盛り上がりそうといった感じ。&lt;/p&gt;

&lt;p&gt;アプリケーションを開発するプラットフォームとしての側面もあり、JavaScript(ブラウザ側とサーバ側両方)でServiceNowの機能を拡張し、他システムと連携させたり処理を自動化したりできる。&lt;/p&gt;

&lt;p&gt;アプリケーションがServiceNowプラットフォームで動くので、テスト方法が悩ましい。
&lt;a href=&#34;https://docs.servicenow.com/bundle/istanbul-release-notes/page/release-notes/servicenow-platform/automated-test-framework-rn.html&#34;&gt;Automated Test Framework&lt;/a&gt;というテストフレームワークが提供されてはいるが、2017年1月にリリースされたばかりということもあるのか、機能がしょぼく、大したことはできない。
これが自前でブラウザテスト環境を作ろうと思った理由。&lt;/p&gt;

&lt;p&gt;アプリケーションがJavaScriptなので、テストもJavaScriptで書きたい。&lt;/p&gt;

&lt;h1 id=&#34;ブラウザテストとは&#34;&gt;ブラウザテストとは&lt;/h1&gt;

&lt;p&gt;ここでブラウザテストとは、稼働しているWebアプリケーションに、HTTPクライアントで接続して、レンダリングされたWebページを操作して実行する自動E2Eテストのこととする。
HTTPでWebコンテンツを取得して、HTML・CSSをパースしてレンダリングして、JavaScriptを実行するツール、つまりWebブラウザを何にするかというのと、それを自動で操作するのをどうするかというのと、テストどう書くのかということと、書いたテストをどう実行するかということと、テスト結果をどう集計してレポートするかといった辺りを考える必要がある。&lt;/p&gt;

&lt;p&gt;Qiitaの記事「&lt;a href=&#34;http://qiita.com/cognitom/items/6cce719b57341769c14d&#34;&gt;ブラウザテストツール総まとめ・2016年夏版&lt;/a&gt;」にブラウザテストのためのツールが色々載っている。
レイヤや目的が異なるツールがちょっとごっちゃになってる気がするけど。&lt;/p&gt;

&lt;h1 id=&#34;seleniumとかwebdriverとか&#34;&gt;SeleniumとかWebDriverとか&lt;/h1&gt;

&lt;p&gt;ブラウザテストはWebDriver抜きでは語れないので、とりあえずそれについて書く。
それにはまず&lt;a href=&#34;http://www.seleniumhq.org/&#34;&gt;Selenium&lt;/a&gt;について語らなければなるまい。&lt;/p&gt;

&lt;p&gt;ブラウザテスト創世記にはこうある。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;神は「光あれ」と言われた。
するとSeleniumがあった。&lt;/p&gt;

&lt;p&gt;神はその光を見て、良しとされた。
神はその光と闇とを分けられた。&lt;/p&gt;

&lt;p&gt;神は光を&lt;a href=&#34;http://www.seleniumhq.org/projects/remote-control/&#34;&gt;Selenium RC&lt;/a&gt; (aka Selenium 1)と名づけ、
闇 を&lt;a href=&#34;http://www.seleniumhq.org/projects/webdriver/&#34;&gt;Selenium WebDriver&lt;/a&gt; (aka Selenium 2)と名づけられた。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(Seleniumの歴史をもっとちゃんと知りたければ&lt;a href=&#34;http://blog.trident-qa.com/2013/05/so-many-seleniums/&#34;&gt;この記事&lt;/a&gt;を読むべし。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;要は、今ブラウザテストと言ったらSelenium、Seleniumと言ったらSelenium WebDriverというわけだ。&lt;/p&gt;

&lt;p&gt;Selenium WebDriverは、WebDriver APIでブラウザやDOMエレメントを操作するツール。
このAPIを実装したクライアントライブラリが各言語(Java、Ruby、Python、JavaScriptなど)で提供されていて、テストコードから利用できる。&lt;/p&gt;

&lt;p&gt;APIの裏ではドライバなるものが暗躍していて、OSやブラウザのネイティブAPIを使ってブラウザを操作している。
このドライバはブラウザごと(Chrome、Firefox、IEなど)に用意されていて、その実装形式がドライバ毎に割と違っている。
例えばFirefox用のやつ(&lt;a href=&#34;https://github.com/SeleniumHQ/selenium/wiki/FirefoxDriver&#34;&gt;Firefox Driver&lt;/a&gt;)はFirefox のアドオンを使うし、Chrome用のやつ(&lt;a href=&#34;https://github.com/SeleniumHQ/selenium/wiki/ChromeDriver&#34;&gt;ChromeDriver&lt;/a&gt;)は独立したネイティブアプリを介してブラウザを操作する。&lt;/p&gt;

&lt;p&gt;ドライバは(基本的に)ブラウザと同じマシンにある必要があり、実行するテストコードとも(基本的に)同居している必要がある。
テストを実行するマシンとは別のマシンのブラウザでテストしたければ&lt;a href=&#34;http://docs.seleniumhq.org/download/&#34;&gt;Selenium Server&lt;/a&gt; (aka Selenium Standalone Server)を使う。
Selenium Serverはブラウザとドライバと同じマシンで動き、テストコードから送信されたブラウザ操作コマンドを受信してドライバに伝える、プロキシ的な働きをしてくれる。&lt;/p&gt;

&lt;p&gt;Selenium Serverを使えば、クライアントライブラリが対応していないドライバでも利用できるというメリットもある。
Selenium Serverを使うと、オーバーヘッドはあるけどメリットが多いので、とりあえず使うようにしておけば間違いなさそう。&lt;/p&gt;

&lt;p&gt;Selenium Serverが受け取るブラウザ操作コマンドは、HTTPでJSONデータとして送信される。
この辺りの通信は、もともと&lt;a href=&#34;https://github.com/SeleniumHQ/selenium/wiki/JsonWireProtocol&#34;&gt;JsonWireProtocol&lt;/a&gt; (aka WebDriver Wire Protocol)で規定されていた。
JsonWireProtocolを&lt;a href=&#34;https://en.wikipedia.org/wiki/World_Wide_Web_Consortium&#34;&gt;W3C&lt;/a&gt;が国際標準規格化したのが&lt;a href=&#34;https://www.w3.org/TR/webdriver/&#34;&gt;WebDriver&lt;/a&gt;というプロトコル。
このWebDriverプロトコルは、ユーザエージェントとDOMエレメントをリモートコントロールするためのインターフェースを定めている。
現在、JsonWireProtocolは廃止扱いで、Selenium WebDriverはWebDriverプロトコルを実装している。&lt;/p&gt;

&lt;p&gt;この辺り、&lt;a href=&#34;https://app.codegrid.net/entry/selenium-1&#34;&gt;この記事&lt;/a&gt;が図解してて分かりやすい。&lt;/p&gt;

&lt;p&gt;ChromeDriverはWebDriverプロトコルを実装してるので、Selenium Server無しでもリモート実行できるけど、それでもやはりSelenium Serverを介したほうが、ドライバを簡単に切り替えられそうでよさそう。&lt;/p&gt;

&lt;p&gt;Selenium ServerとかChromeDriverのようにWebDriverプロトコルのサーバ機能を実装したものは&lt;a href=&#34;https://github.com/SeleniumHQ/selenium/wiki/RemoteWebDriverServer&#34;&gt;RemoteWebDriverServer&lt;/a&gt;と呼ばれることもある。
それにアクセスするクライアントは&lt;a href=&#34;https://github.com/SeleniumHQ/selenium/wiki/RemoteWebDriver&#34;&gt;RemoteWebDriver&lt;/a&gt;とかRemoteWebDriverクライアントとか呼ばれる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ということで、色々ややこしい(公式も自分でややこしいと言ってる)が、結局WebDriverは何かと言えば、普通は上記ドライバそのものを指す。
ので、以下においても、WebDriverと書いたらそれを指すこととする。&lt;/p&gt;

&lt;h1 id=&#34;ヘッドレス&#34;&gt;ヘッドレス&lt;/h1&gt;

&lt;p&gt;もう一つブラウザテストの文脈で重要なのが、&lt;a href=&#34;https://en.wikipedia.org/wiki/Headless_software&#34;&gt;ヘッドレス&lt;/a&gt;という概念なので、ここでちょっと触れる。&lt;/p&gt;

&lt;p&gt;ヘッドレスとは、ソフトウェアがGUIなしで動く性質とか機能のこと。&lt;/p&gt;

&lt;p&gt;ブラウザテストは、テスト実行時にブラウザを起動するわけだが、ブラウザってのは普通GUIが付いていて、Windowsだったらログインしてないと動かせないし、LinuxだったらXの起動も必要だ。
これだと、テストを定期的に自動実行したり、CIしたりするのが難しい。
また、GUIは動作が遅く、テストに時間がかかる。&lt;/p&gt;

&lt;h3 id=&#34;ヘッドレスブラウザ&#34;&gt;ヘッドレスブラウザ&lt;/h3&gt;

&lt;p&gt;こうした問題を解決するため、ヘッドレスブラウザというものが開発された。
ヘッドレスブラウザには以下のようなものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://phantomjs.org/&#34;&gt;PhantomJS&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;多分一番有名なヘッドレスブラウザ。
JavaScriptとC++などで書かれていて、JavaScriptから操作できる。
2011年にリリースされ、まだ開発が続いている。
レンダリングエンジンはWebKitで、JavaScriptエンジンはWebKitに組み込みの&lt;a href=&#34;https://trac.webkit.org/wiki/JavaScriptCore&#34;&gt;JavaScriptCore&lt;/a&gt;で、
Windows、OS X、Linuxなどで動く。
WebDriver有り。(&lt;a href=&#34;https://github.com/detro/ghostdriver&#34;&gt;Ghost Driver&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://htmlunit.sourceforge.net/&#34;&gt;HtmlUnit&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Chrome、Firefox、IEをシミュレートできるJava製のツールで、
JavaのAPIで操作できる。
2002年にリリースされ、まだ開発が続いている。
レンダリングエンジンは(多分)自前で、JavaScriptエンジンはRhino。
WebDriver有り。(&lt;a href=&#34;https://github.com/SeleniumHQ/htmlunit-driver&#34;&gt;HtmlUnitDriver&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://scrapinghub.com/splash/&#34;&gt;Splash&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Python製。2013年に開発がスタートし、現在も鋭意開発中。
LinuxとOS Xをサポートしてて、Windowsでは(多分)動かない。
HTTP APIにJSONをPOSTして操作するもので、&lt;a href=&#34;https://www.lua.org/&#34;&gt;Lua&lt;/a&gt;のクライアントライブラリが提供されている。
レンダリングエンジンはWebKitで、JavaScriptエンジンはWebKitに組み込みのJavaScriptCore。
WebDriverなさげ。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://triflejs.org/&#34;&gt;TrifleJS&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;JavaScriptとC#(.NET 4.0)で書かれていて、Windowsでしか動かない。
 レンダリングエンジンはTridentで、IEをエミュレートする。
 JavaScriptエンジンはV8。PhantomJSと同じAPIを実装していて、JavaScriptから操作できる。
 2013年に開発がスタートし、ベータ版のまま開発中断してしまった模様。
 WebDriverは、ロードマップにはあるけどまだ実装されてない。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あと、似たようなものに&lt;a href=&#34;https://slimerjs.org/index.html&#34;&gt;SlimerJS&lt;/a&gt;と&lt;a href=&#34;https://electron.atom.io/&#34;&gt;Electron&lt;/a&gt;と&lt;a href=&#34;https://github.com/tmpvar/jsdom&#34;&gt;jsdom&lt;/a&gt;がある。&lt;/p&gt;

&lt;p&gt;SlimerJSは、GeckoとSpiderMonkeyの上に開発された、スクリプトから操作できるテスト用途向けブラウザだけど、ヘッドレスではない。&lt;/p&gt;

&lt;p&gt;ElectronはJavaScriptでデスクトップアプリケーションを開発するためのフレームワーク。
&lt;a href=&#34;https://www.chromium.org/Home&#34;&gt;Chromium&lt;/a&gt;というブラウザを積んでいて、それをElectron APIでプログラマティックに操作できるらしく、ブラウザテストにも使われる。
(&lt;a href=&#34;http://qiita.com/hiroshitoda/items/288706978cd4c6df0f5f&#34;&gt;Seleniumでも操作できる&lt;/a&gt;。)
けどこれもヘッドレスではない。&lt;/p&gt;

&lt;p&gt;jsdomはDOMツリーとそれに対する操作をエミュレートするツールで、そもそもブラウザではないはずなんだけど、HTTPでWebコンテンツダウンロードして解析もできるし、すごくヘッドレスブラウザっぽい。
けどちゃんとブラウザしてるかが怪しく、UIテストには使われてもブラウザテストにはあまり使われないっぽい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ヘッドレスブラウザにも色々あるが結局、テスト用に作られたブラウザであって、実際に多くのエンドユーザに使われて揉まれているGUI有りブラウザに比べて、品質が悪かったり動きが違ったりする(らしい)。
JavaScriptのバージョンのキャッチアップが遅かったりも。&lt;/p&gt;

&lt;h3 id=&#34;xvfb&#34;&gt;Xvfb&lt;/h3&gt;

&lt;p&gt;ヘッドレスブラウザの問題は、実際のブラウザではないということに尽きる。
実際のブラウザをヘッドレスで使えたら万事が上手くいくわけだが、実はこれがLinuxでなら出来る。
&lt;a href=&#34;https://www.x.org/releases/X11R7.7/doc/man/man1/Xvfb.1.xhtml&#34;&gt;Xvfb&lt;/a&gt;というツールを使って。
(Xvfbはあまりメンテされてなくて&lt;a href=&#34;https://xpra.org/trac/wiki/Xdummy&#34;&gt;Xdummy&lt;/a&gt;が代わりに最近熱いみたいだけど。)&lt;/p&gt;

&lt;p&gt;Xvfbはフレームバッファをエミュレートし、ディスプレイが無い環境でも動くヘッドレスXサーバ。
これを使うと、GUIのある普通のブラウザでもヘッドレス環境で動かせる。&lt;/p&gt;

&lt;p&gt;Xvfbについては&lt;a href=&#34;http://blog.amedama.jp/entry/2016/01/03/115602&#34;&gt;この記事&lt;/a&gt;が分かりやすい。&lt;/p&gt;

&lt;h3 id=&#34;chrome-59&#34;&gt;Chrome 59&lt;/h3&gt;

&lt;p&gt;Xvfbを使えば大分幸せになりそうだが、ブラウザ以外のツールを起動しなければいけなかったり、Windowsで使えなかったり、まだちょっと不満が残る。&lt;/p&gt;

&lt;p&gt;そんななか、2017年6月、Chrome 59がリリースされ、ヘッドレスモードを搭載した。
Windowsは現時点で未対応だけど、すぐに対応されるはずだ。
ほかの実ブラウザもこの流れに乗ってヘッドレスモードを実装したら、最高に幸せな世界になるではないか。&lt;/p&gt;

&lt;p&gt;Chromeのヘッドレスモード搭載を受け、&lt;a href=&#34;https://www.infoq.com/jp/news/2017/04/Phantomjs-future-uncertain&#34;&gt;PhantomJSは開発停止&lt;/a&gt;した。
もうヘッドレスブラウザはその役目を終えつつあるということなのだろう。&lt;/p&gt;

&lt;p&gt;Chrome 59のヘッドレスモードの使い方は&lt;a href=&#34;https://developers.google.com/web/updates/2017/04/headless-chrome?hl=ja&#34;&gt;この記事&lt;/a&gt;が分かりやすい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;
&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上のような感じのことが調べて分かって、SeleniumとChromeのヘッドレスモードを使いたいと思ったところで、
続きはまた&lt;a href=&#34;https://www.kaitoy.xyz/2017/08/04/browser-test-framework/&#34;&gt;別の記事&lt;/a&gt;。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>git rebaseを図解する</title>
          <link>https://www.kaitoy.xyz/2017/06/10/git-rebase/</link>
          <pubDate>Sat, 10 Jun 2017 00:00:17 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/06/10/git-rebase/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;この記事&lt;/a&gt;を読んだ、またはGitのオブジェクトモデルを理解していることを前提に、&lt;a href=&#34;https://git-scm.com/&#34;&gt;&lt;strong&gt;Git&lt;/strong&gt;&lt;/a&gt;の &lt;code&gt;git rebase&lt;/code&gt; というコマンドについて説明する。&lt;/p&gt;

&lt;p&gt;このコマンドは、コミット履歴を改変できるGit特有のコマンドで、&lt;a href=&#34;http://qiita.com/kaitoy/items/ed22474837b943eb6d97&#34;&gt;分かり辛いGitコマンド&lt;/a&gt;の中でも最も分かり辛い部類のものだ。
Gitの最後の関門と言えよう。
けど、それだけに使いこなせばとても便利なものでもある。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;git-rebaseがもつたった一つの機能&#34;&gt;git rebaseがもつたった一つの機能&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;git rebase&lt;/code&gt;にはいろんなオプションがあって、ちょっと調べただけだと、コミットを移動する機能とコミットを修正する機能の二つがあるように見えるかもしれないが、実際は単一の機能しかないシンプルなコマンドだ。&lt;/p&gt;

&lt;p&gt;その機能とは、指定した範囲のコミットが含む変更を、別に指定したコミットのコードベースに適用するというもの。&lt;/p&gt;

&lt;p&gt;コマンドの基本形は次のようなものだ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ git rebase --onto master dev bugfix
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このコマンドは、&lt;code&gt;bugfix&lt;/code&gt;から辿れるコミット群から、&lt;code&gt;dev&lt;/code&gt;から辿れるコミット群を除いたコミット群が含む変更を、&lt;code&gt;master&lt;/code&gt;のコードベースに適用する。&lt;/p&gt;

&lt;p&gt;と書いても分からないので図解する。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase/スライド6.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;このスライドを見ると、&lt;code&gt;git rebase&lt;/code&gt;に指定した3つのブランチのそれぞれの使われ方が分かるはず。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git rebase --onto master dev bugfix&lt;/code&gt;が実行する処理をもっと正確に言うと、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;bugfix&lt;/code&gt;を&lt;code&gt;checkout&lt;/code&gt;して(i.e. &lt;code&gt;HEAD&lt;/code&gt;を&lt;code&gt;bugfix&lt;/code&gt;にして)、&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dev..HEAD&lt;/code&gt;のコミット群が含む変更を、それぞれ仮領域にパッチとして保存して、&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git reset --hard master&lt;/code&gt;して、&lt;/li&gt;
&lt;li&gt;仮領域に保存した変更を、&lt;code&gt;HEAD&lt;/code&gt;が指すコミットのコードベースにひとつひとつ順番に適用する。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;上記コマンドで&lt;code&gt;bugfix&lt;/code&gt;のところを省略すると、ステップ1の&lt;code&gt;checkout&lt;/code&gt;が省略される。
言い換えると、上記コマンドは次の二つのコマンドに分解できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ git checkout bugfix
$ git rebase --onto master dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;さらに、&lt;code&gt;--onto master&lt;/code&gt;を省略すると、ステップ3の&lt;code&gt;reset&lt;/code&gt;先が変わり、&lt;code&gt;dev&lt;/code&gt;になる。
このときのコマンドの形は、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ git rebase dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;という見慣れたものになるが、これが最初に挙げた基本形の省略形だと認識しておくと応用が利く。&lt;/p&gt;

&lt;p&gt;以下に&lt;code&gt;git rebase dev&lt;/code&gt;の動きを細かめに図解する。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド6.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド7.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;インタラクティブモード&#34;&gt;インタラクティブモード&lt;/h2&gt;

&lt;p&gt;前節のスライドに書いたパッチの適用をカスタマイズできるのがインタラクティブモードで、これは&lt;code&gt;-i&lt;/code&gt;オプションで有効にできる。
インタラクティブモードを使うと、パッチをスキップしたり、順番を変えたり、まとめたり、分割したり、編集したりでき、またパッチとパッチの間に任意のコマンドを実行でき、例えばパッチごとにユニットテストを実行できたりする。&lt;/p&gt;

&lt;p&gt;インタラクティブモードの使い方についてはググればたくさん出てくるのでここには書かない。
&lt;a href=&#34;http://tkengo.github.io/blog/2013/05/16/git-rebase-reference/&#34;&gt;この記事&lt;/a&gt;辺りがわかりやすい。&lt;/p&gt;

&lt;p&gt;インタラクティブモードのユースケースとしてよく紹介されるのが、&lt;code&gt;git rebase -i HEAD^^&lt;/code&gt;で直近の二つのコミットを変更するといったものだが、これを図解すると以下のようになる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド6.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド7.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド8.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド9.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;このスライドを見ると、&lt;code&gt;git rebase dev&lt;/code&gt;と&lt;code&gt;git rebase -i HEAD^^&lt;/code&gt;は、パッチの適用がインタラクティブかどうか以外は同じ処理をしていることがわかる。
見た目の違いに惑わされないようにしたい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git rebase&lt;/code&gt;はブランチを複数指定したりして分かり辛いコマンドであることは確かだけど、上記の基本形を押さえておけばすんなり理解できるはず。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Elasticsearch、Logstash、Filebeat、elasticsearch-headでログを見てみた</title>
          <link>https://www.kaitoy.xyz/2017/04/04/elasticsearch-in-nnmi-log/</link>
          <pubDate>Tue, 04 Apr 2017 09:24:12 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/04/04/elasticsearch-in-nnmi-log/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://www8.hp.com/jp/ja/software-solutions/network-node-manager-i-network-management-software/&#34;&gt;NNMi&lt;/a&gt;ログを&lt;a href=&#34;https://www.elastic.co/jp/products/beats/filebeat&#34;&gt;Filebeat&lt;/a&gt;で集めて&lt;a href=&#34;https://www.elastic.co/jp/products/logstash&#34;&gt;Logstash&lt;/a&gt;で構造化して&lt;a href=&#34;https://www.elastic.co/jp/products/elasticsearch&#34;&gt;Elasticsearch&lt;/a&gt;に入れて&lt;a href=&#34;https://mobz.github.io/elasticsearch-head/&#34;&gt;elasticsearch-head&lt;/a&gt;で見てみたけど、ログ量が少なかったせいかあんまり恩恵が感じられなかった話。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;elasticsearchとは&#34;&gt;Elasticsearchとは&lt;/h1&gt;

&lt;p&gt;Elasticsearchは&lt;a href=&#34;https://www.elastic.co/&#34;&gt;Elastic社&lt;/a&gt;が開発している&lt;a href=&#34;https://www.elastic.co/products&#34;&gt;Elastic Stack&lt;/a&gt;(旧ELK Stack)というオープンソースなデータ収集分析ツール群のコア製品。
内部で&lt;a href=&#34;https://lucene.apache.org/core/&#34;&gt;Lucene&lt;/a&gt;を使っていて、そのためJava製。
「分散型RESTful検索/分析エンジン」と自称しているが、スキーマレスでNoSQLなドキュメント指向分散データベース管理システムとも見れる。&lt;/p&gt;

&lt;p&gt;Elasticsearchインスタンスはノードと呼ばれ、単一または複数のノードによるシステムはクラスタと呼ばれる。
同一ネットワークに複数のノードを立ち上げると自動で相互検出してクラスタを構成してくれ、そこにデータを入れると自動で冗長化して分散配置してくれるので、堅牢でレジリエントでスケーラブルなシステムが簡単に構築できる。&lt;/p&gt;

&lt;p&gt;Elasticsearchが管理するデータの最小単位はドキュメントと呼ばれ、これはひとつのJSONオブジェクトで、RDBにおける行にあたる。
つまり、JSONオブジェクトの各フィールドがRDBにおける列にあたる。
同種のドキュメントの集まりはインデックスと呼ばれ、これはRDBにおけるテーブルにあたる。
テーブルのスキーマにあたるものはマッピングと呼ばれ、ドキュメントのフィールドの型情報(e.g. string, integer)などを含み、Elasticsearchが自動で生成してくれる。(指定もできる、というかすべきらしい。)
インデックス内ではさらにタイプという属性でドキュメントをカテゴライズできる、が、マニュアルからはタイプはあまり&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/general-recommendations.html#_avoid_types&#34;&gt;使ってほしくない&lt;/a&gt;雰囲気が感じられる。&lt;/p&gt;

&lt;p&gt;因みに、インデックスがRDBのデータベースでタイプがRDBのテーブルと説明されることもあるが、これは古いたとえで、&lt;a href=&#34;https://www.elastic.co/blog/index-vs-type&#34;&gt;公式が間違いだったとしている&lt;/a&gt;ので忘れてあげたい。&lt;/p&gt;

&lt;p&gt;インデックスは分散処理のために分割でき、分割した各部分はシャードと呼ばれる。
シャードを冗長化のためにコピーしたものはレプリカシャードと呼ばれ、レプリカシャードにより成るインデックスはレプリカと呼ばれる。
デフォルトでは、ひとつのインデックスは5つのシャードに分割され、1つのレプリカが作成される。&lt;/p&gt;

&lt;p&gt;インターフェースはREST APIだけ。
REST APIに検索したいドキュメントを投げると、ドキュメントのフィールド毎に自動で形態素解析とかして&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E8%BB%A2%E7%BD%AE%E3%82%A4%E3%83%B3%E3%83%87%E3%83%83%E3%82%AF%E3%82%B9&#34;&gt;転置インデックス&lt;/a&gt;作って保管してくれる。
検索もJSONで表現したクエリをREST APIに投げることで結果をJSONで受け取ることができる。
検索は転置インデックスや分散処理のおかげで速く、また&lt;a href=&#34;http://qiita.com/r4-keisuke/items/d653d26b6fc8b7955c05#%E3%82%B9%E3%82%B3%E3%82%A2%E3%83%AA%E3%83%B3%E3%82%B0&#34;&gt;スコアリング&lt;/a&gt;によってより適切な結果が得られるようになっている。&lt;/p&gt;

&lt;p&gt;今回使ったのはv5.2.1。&lt;/p&gt;

&lt;h1 id=&#34;logstashとは&#34;&gt;Logstashとは&lt;/h1&gt;

&lt;p&gt;LogstashはElastic Stackに含まれる製品で、データ収集エンジンであり、データの受け取り、解析/加工、出力の三つの機能を持つリアルタイムパイプラインを構成する。
この三つの機能はそれぞれ&lt;a href=&#34;https://www.elastic.co/guide/en/logstash/5.2/input-plugins.html&#34;&gt;インプットプラグイン&lt;/a&gt;、&lt;a href=&#34;https://www.elastic.co/guide/en/logstash/5.2/filter-plugins.html&#34;&gt;フィルタプラグイン&lt;/a&gt;、&lt;a href=&#34;https://www.elastic.co/guide/en/logstash/5.2/output-plugins.html&#34;&gt;アウトプットプラグイン&lt;/a&gt;で提供されていて、プラグインの組み合わせにより様々なパイプラインを構成できる。&lt;/p&gt;

&lt;p&gt;インプットプラグインは単位データ(一回分のログなど)を受け取り、タイムスタンプなどのメタデータを付けたりパースしたりしてイベントを生成し、パイプラインに流す。
フィルタプラグインはインプットプラグインからイベントを受け取り、設定されたルールに従って情報を拡充したり変更したり構造化したり秘匿情報を消したりしてアウトプットプラグインに渡す。
アウトプットプラグインは指定されたディスク上のパスやデータベースやアプリやサービスにイベントを書き込んだり送信したりする。&lt;/p&gt;

&lt;p&gt;名前の通りもともとログ収集ツールだったが、今では様々なデータに対応していて、テキストログファイルの他にsyslog、HTTPリクエストやJDBCなんかの入力を受けることもできる。&lt;/p&gt;

&lt;p&gt;Ruby(とJava)で書かれている。&lt;/p&gt;

&lt;p&gt;今回使ったのはv5.2.2で、プラグインは以下を使った。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;インプット: &lt;a href=&#34;https://www.elastic.co/guide/en/logstash/5.2/plugins-inputs-beats.html&#34;&gt;beats&lt;/a&gt; 3.1.12: Beats(後述)からデータを受け取るプラグイン。&lt;a href=&#34;https://github.com/logstash-plugins/logstash-input-beats/blob/v3.1.12/PROTOCOL.md&#34;&gt;Lumberjack&lt;/a&gt;というElastic社が開発しているプロトコルを使い、TCPネットワーク上でデータを受信する。&lt;/li&gt;
&lt;li&gt;フィルタ: &lt;a href=&#34;https://www.elastic.co/guide/en/logstash/5.2/plugins-filters-grok.html&#34;&gt;grok&lt;/a&gt; 3.3.1: 正規表現でパターンマッチして非構造化データを構造化するプラグイン。ログ解析の定番で、例えば、ログからタイムスタンプ、クラス名、ログメッセージを抽出したりする。&lt;a href=&#34;https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns&#34;&gt;組み込みのパターン&lt;/a&gt;が120個くらいあり、&lt;a href=&#34;https://httpd.apache.org/&#34;&gt;Apache HTTP Server&lt;/a&gt;やsyslogのログであれば自分で正規表現を書く必要はない。&lt;/li&gt;
&lt;li&gt;アウトプット: &lt;a href=&#34;https://www.elastic.co/guide/en/logstash/5.2/plugins-outputs-elasticsearch.html&#34;&gt;elasticsearch&lt;/a&gt; 6.2.6: Elasticsearchにイベントをポストするプラグイン。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;beatsとは&#34;&gt;Beatsとは&lt;/h1&gt;

&lt;p&gt;BeatsもElastic Stackに含まれる製品で、データを採取してLogstashやElasticsearchに送信する製品群の総称。
&lt;a href=&#34;https://github.com/elastic/beats/tree/master/libbeat&#34;&gt;libbeat&lt;/a&gt;というGoのライブラリを使って作られていて、以下のようなものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/elastic/beats/tree/master/filebeat&#34;&gt;Filebeat&lt;/a&gt;: ログファイルからログを取得する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/elastic/beats/tree/master/heartbeat&#34;&gt;Heartbeat&lt;/a&gt;: リモートサービスをpingして生死監視する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/elastic/beats/tree/master/metricbeat&#34;&gt;Metricbeat&lt;/a&gt;: OSとその上のサービスやアプリから稼動情報を取得する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/elastic/beats/tree/master/packetbeat&#34;&gt;Packetbeat&lt;/a&gt;: パケットキャプチャしてネットワークのトラフィックを監視する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/elastic/beats/tree/master/winlogbeat&#34;&gt;Winlogbeat&lt;/a&gt;: Windowsのイベントログを取得する。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;今回使ったのはFilebeat 5.2.2。&lt;/p&gt;

&lt;p&gt;Filebeatは指定したログファイルを監視し、変更を検知してリアルタイムにログを送信してくれる。
FilebeatとLogstashが仲良くやってくれて、バッファがあふれるなどすることによるログの損失が起きないようにしてくれるらしい。
Logstashが単位データを受け取るので、ログファイルからひとつひとつのログを切り出すのはFilebeatの責務。
一行一ログなら何も考えなくていいけど、大抵複数行のログがあるのでなんとかする必要がある。&lt;/p&gt;

&lt;h1 id=&#34;elasticsearch-headとは&#34;&gt;elasticsearch-headとは&lt;/h1&gt;

&lt;p&gt;elasticsearch-headは3rdパーティ製(個人製?)のElasticsearchのWeb UI。
ElasticsearchのUIはREST APIしかないのでこういうものを使わないと辛い。&lt;/p&gt;

&lt;p&gt;ElasticsearchのGUIとしてはElastic Stackの&lt;a href=&#34;https://www.elastic.co/jp/products/kibana&#34;&gt;Kibana&lt;/a&gt;が有名だけど、これは大量のログから統計的な情報を見るのに便利そうなものであって、今回やりたかった障害原因調査のためにログを細かく追うのには向いてなさそうだったので使わなかった。&lt;/p&gt;

&lt;h1 id=&#34;実験環境&#34;&gt;実験環境&lt;/h1&gt;

&lt;p&gt;今回は単にログがどんな感じに見えるか試したかっただけなので、全部ローカルで動かして、ローカルに置いた静的なログファイルを読むだけ。
環境はWindows 7のノートPC。&lt;/p&gt;

&lt;p&gt;ログファイルは&lt;code&gt;C:\Users\Kaito\Desktop\logs\&lt;/code&gt;においた&lt;code&gt;nnm-trace.log&lt;/code&gt;と&lt;code&gt;nnm-trace.log.1&lt;/code&gt;。
これらはNNMiのメインログで、&lt;a href=&#34;https://docs.oracle.com/javase/8/docs/api/java/util/logging/package-summary.html&#34;&gt;JUL&lt;/a&gt;で出力されたもの。
NNMiは無料のコミュニティエディションのv10.00をVMのCentOSに適当に入れて採った。&lt;/p&gt;

&lt;p&gt;ログはだいたい以下の様な一行のもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2017-03-15 19:09:55.896 INFO  [com.hp.ov.nms.spi.common.deployment.deployers.ExtensionServicesDeployer] (Thread-2) Deploying arris-device
2017-03-15 19:09:55.923 WARNING [com.hp.ov.nms.topo.spi.server.concurrent.NmsTimerTaskImpl] (NmsWorkManager Scheduler) Skipping task execution because previous execution has not completed: com.hp.ov.nnm.im.NnmIntegrationModule$EnablerTask@3abdac77
2017-03-15 19:09:56.120 INFO  [com.hp.ov.nms.disco.spi.DiscoExtensionNotificationListener] (Thread-2) Disco deployed mapping rules: META-INF/disco/rules/cards/ArrisCard.xml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;たまに複数行のものがある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2017-03-15 19:13:30.872 INFO  [com.hp.ov.nms.trapd.narrowfilter.NarrowTrapAnalysis] (pool-1-thread-18)
***** Hosted Object Trap Rate Report *****
Hosted object trap storm detection and suppression stage started: Wed Mar 15, 2017 19:09:00.746 PM.

***** General Statistics *****
Hosted Object trap rate threshold: 10 traps/sec.
Average trap rate: 0 traps/sec.
Total traps received: 0.
Total traps received without configuration: 0.
Total traps suppressed: 0.
Number of trap configurations: 1.


***** END Hosted object trap storm report END *****
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ログレベルの部分(e.g. INFO、WARNING)はロケールによって日本語になったりする。&lt;/p&gt;

&lt;p&gt;スレッド名の部分(e.g. pool-1-thread-18)は丸括弧で囲われているが、丸括弧を含むことがある。&lt;/p&gt;

&lt;p&gt;クラス名の部分(e.g. com.hp.ov.nms.trapd.narrowfilter.NarrowTrapAnalysis)は、パッケージ名がついていないこともある。デフォルトパッケージってこともないだろうに。&lt;/p&gt;

&lt;h1 id=&#34;elastic-stackのインストールと設定&#34;&gt;Elastic Stackのインストールと設定&lt;/h1&gt;

&lt;p&gt;Elastic Stackの三つはどれも、サイトからアーカイブをダウンロードして展開すればインストール完了。&lt;/p&gt;

&lt;p&gt;Filebeatの設定は、展開したディレクトリのトップにある&lt;code&gt;filebeat.yml&lt;/code&gt;に以下を書いた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;filebeat.prospectors:

- input_type: log
  paths:
    - C:\Users\Kaito\Desktop\logs\*

  multiline.pattern: &#39;^[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9]{3} &#39;
  multiline.negate: true
  multiline.match: after

output.logstash:
  hosts: [&amp;quot;localhost:5043&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;paths&lt;/code&gt;でログファイルを指定して、&lt;code&gt;hosts&lt;/code&gt;でログの送信先を指定している。
また、複数行のログに対応するため、&lt;code&gt;multiline&lt;/code&gt;という設定を書いていて、タイムスタンプで始まらない行は前の行の続きになるようにしている。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Logstashの設定は、展開したディレクトリのトップに&lt;code&gt;pipeline.conf&lt;/code&gt;というファイルを作ってそこに以下を書いた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;input {
    beats {
        port =&amp;gt; &amp;quot;5043&amp;quot;
    }
}
filter {
    grok {
        match =&amp;gt; { &amp;quot;message&amp;quot; =&amp;gt; &amp;quot;%{TIMESTAMP_ISO8601:timestamp} (?&amp;lt;log_level&amp;gt;[^ ]+) +\[(?:%{JAVACLASS:class}|(?&amp;lt;class&amp;gt;[A-Za-z0-9_]+))\] \((?&amp;lt;thread&amp;gt;.+(?=\) ))\) (?&amp;lt;log_message&amp;gt;.*)&amp;quot;}
    }
}
output {
    elasticsearch {
        hosts =&amp;gt; [ &amp;quot;localhost:9200&amp;quot; ]
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;input&lt;/code&gt;と&lt;code&gt;output&lt;/code&gt;の部分は単にbeatsプラグインとelasticsearchプラグイン使うようにして送受信先を指定しているだけ。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;filter&lt;/code&gt;の部分は、grokプラグインを使うようにしつつそのパターンマッチングを指定している。
FilebeatがJSONオブジェクトの&lt;code&gt;message&lt;/code&gt;というフィールドに一回分のログを入れて送ってくるので、そこからタイムスタンプ、ログレベル、クラス、スレッド、ログメッセージを抽出し、それぞれ&lt;code&gt;timestamp&lt;/code&gt;、&lt;code&gt;log_level&lt;/code&gt;、&lt;code&gt;class&lt;/code&gt;、&lt;code&gt;thread&lt;/code&gt;、&lt;code&gt;log_message&lt;/code&gt;というフィールドに入れるように設定。
&lt;code&gt;TIMESTAMP_ISO8601&lt;/code&gt;と&lt;code&gt;JAVACLASS&lt;/code&gt;が組み込みのパターンで、それぞれタイムスタンプとJavaのクラス名にマッチする。
けど&lt;code&gt;JAVACLASS&lt;/code&gt;がパッケージ名の付いてないクラス名にマッチしないのでちょっと細工している。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Elasticsearchの設定は、展開したディレクトリ内の&lt;code&gt;config/elasticsearch.yml&lt;/code&gt;に以下を書いた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;http.cors.enabled: true
http.cors.allow-origin: &amp;quot;*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これは、elasticsearch-headがWebアプリなので、そこからElasticsearchにアクセスできるように&lt;a href=&#34;https://en.wikipedia.org/wiki/Cross-origin_resource_sharing&#34;&gt;CORS&lt;/a&gt;を有効にする設定。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで設定は終わり。&lt;/p&gt;

&lt;h1 id=&#34;各製品の起動&#34;&gt;各製品の起動&lt;/h1&gt;

&lt;p&gt;Filebeatは普通はサービスとして起動するみたいだけど、今回はコマンドラインで起動する。&lt;/p&gt;

&lt;p&gt;展開したディレクトリで以下のコマンドを実行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;filebeat.exe -e -c filebeat.yml -d &amp;quot;publish&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Logstashは展開したディレクトリで以下のコマンド。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;bin\logstash.bat -f pipeline.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Elasticsearchは展開したディレクトリで以下のコマンド。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;bin\elasticsearch.bat
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;しばらく待つと起動完了し、&lt;code&gt;localhost:9200&lt;/code&gt;でHTTPリクエストを待ち始める。
試しにブラウザで&lt;code&gt;http://localhost:9200/_cluster/health&lt;/code&gt;にアクセスすると、以下の様にElasticsearchクラスタのステータスがJSONで返ってきた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;{&amp;quot;cluster_name&amp;quot;:&amp;quot;elasticsearch&amp;quot;,&amp;quot;status&amp;quot;:&amp;quot;yellow&amp;quot;,&amp;quot;timed_out&amp;quot;:false,&amp;quot;number_of_nodes&amp;quot;:1,&amp;quot;number_of_data_nodes&amp;quot;:1,&amp;quot;active_primary_shards&amp;quot;:5,&amp;quot;active_shards&amp;quot;:5,&amp;quot;relocating_shards&amp;quot;:0,&amp;quot;initializing_shards&amp;quot;:0,&amp;quot;unassigned_shards&amp;quot;:5,&amp;quot;delayed_unassigned_shards&amp;quot;:0,&amp;quot;number_of_pending_tasks&amp;quot;:0,&amp;quot;number_of_in_flight_fetch&amp;quot;:0,&amp;quot;task_max_waiting_in_queue_millis&amp;quot;:0,&amp;quot;active_shards_percent_as_number&amp;quot;:50.0}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でElastic Stackが起動し、Elasticsearchにログが読み込まれた。&lt;/p&gt;

&lt;h1 id=&#34;elasticsearch-headでログを見る&#34;&gt;elasticsearch-headでログを見る&lt;/h1&gt;

&lt;p&gt;elasticsearch-headは&lt;code&gt;git clone https://github.com/mobz/elasticsearch-head.git&lt;/code&gt;してその中の&lt;code&gt;index.html&lt;/code&gt;をブラウザで開けば動く。組み込みのWebサーバを起動する手順もあるけど。&lt;/p&gt;

&lt;p&gt;開くと&lt;code&gt;http://localhost:9200/&lt;/code&gt;(i.e. Elasticsearch)にアクセスしてGUIに情報を表示してくれる。
Overviewタブには以下の様に、&lt;code&gt;logstash-2017.03.17&lt;/code&gt;というインデックスが作られていて、それに対して5つのシャードとレプリカシャードが作られている様が表示される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/elasticsearch-in-nnmi-log/overview.png&#34; alt=&#34;overview.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Browserタブではざっくりとログの一覧が見れる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/elasticsearch-in-nnmi-log/browser.png&#34; alt=&#34;browser.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Structured Queryタブでは条件を指定してログを表示できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/elasticsearch-in-nnmi-log/query.png&#34; alt=&#34;query.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;ここでは2017/3/15 19:09:50から2017/3/15 19:10:00の間のINFOレベルのDiscoExtensionNotificationListenerクラスのログを10件表示した。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;不要な列を非表示にできないし、ソートもできないし、ログメッセージ見難くくて全く使えない。
もう少しいいGUIがあれば使えるのか、そもそもElasticsearchを使うのが間違っているのか。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Firedrop(プライベートベータ)が全く期待外れだった件</title>
          <link>https://www.kaitoy.xyz/2017/03/05/firedrop-private-beta/</link>
          <pubDate>Sun, 05 Mar 2017 23:28:03 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/03/05/firedrop-private-beta/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://firedrop.ai/&#34;&gt;Firedrop&lt;/a&gt;という現在開発中のサービスがある。
WebサイトのデザインをAIがサポートしてくれるサービスだ。&lt;/p&gt;

&lt;p&gt;2016年夏の&lt;a href=&#34;https://bita.jp/dml/dwango_dennosho2-1&#34;&gt;ニュース&lt;/a&gt;を見たとき、AIがテキストコンテンツを解析してサイトを自動構成してくれ、さらにA/Bテストなどを自動でやってサイトを継続的に改善すると言う衝撃的なふれこみだったので、即座にアーリーアクセスに登録した。&lt;/p&gt;

&lt;p&gt;それからしばらく忘れていたが、3月2日にプライベートベータへの招待メールが来たので早速試してみたら、かなりのスモールスタートをしたようで全く期待外れだった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h1 id=&#34;firedrop-プライベートベータ-の機能&#34;&gt;Firedrop(プライベートベータ)の機能&lt;/h1&gt;

&lt;p&gt;Firedrop(プライベートベータ)では、SachaというAIがWebサイトの構築をサポートしてくれる。
こいつが実のところほとんど知性を感じない単なるチャットボットで、なるほどこれは見事な&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%84%A1%E8%84%B3&#34;&gt;人工無脳&lt;/a&gt;だと感心してしまうほどだ。&lt;/p&gt;

&lt;p&gt;Firedropのアカウントを作るとまず、Sachaとチャットしながらサイトの概要(タイトル、概要、画像など)を教えることになる。
するとSachaがざっくりとシングルページのサイトを作ってくれるので、それをまたSachaとのチャットで調整したりコンテンツ追加したりする。&lt;/p&gt;

&lt;p&gt;チャットと言っても、基本はこちらは5,6個ある選択肢の中からセリフを選ぶサウンドノベル方式で、一応任意の文章も入力できるがあいさつするくらいしか使い道がない。&lt;/p&gt;

&lt;p&gt;追加コンテンツはテキストと画像を渡すと自動でレイアウトしてくれるが、すごくいい感じにしてくれるというわけでもないし、むしろ画像が見切れたりするし、細かい調整はできないので、妥協できるレイアウトになるまでチェンジを繰り返すデリヘル方式を採ることになる。
デリヘルなんて利用したことないけど。&lt;/p&gt;

&lt;p&gt;画像は自分でアップロードもできるけどFiredropが提供しているものもあって、後者のやつはSachaにキーワードを伝えるとそれっぽい画像を探してくれるあたりに唯一知性を感じる。&lt;/p&gt;

&lt;p&gt;デザインができたらSachaに頼むと&lt;code&gt;firedrop.me&lt;/code&gt;ドメインで公開してくれる。&lt;/p&gt;

&lt;p&gt;(FiredropのUIのスクリーンショットを載せようかと思ったけど、プライベートベータの規約を読んだ感じだめそうだったので載せない。)&lt;/p&gt;

&lt;h1 id=&#34;実際に作ってみた&#34;&gt;実際に作ってみた&lt;/h1&gt;

&lt;p&gt;今回実際にFiredropで&lt;a href=&#34;https://www.kaitoy.xyz/2016/12/11/goslings-development-memo0-intro-design/&#34;&gt;Goslings&lt;/a&gt;のサイトを作ってみて、できたのが&lt;a href=&#34;https://quvoi3op.firedrop.me/&#34;&gt;これ&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;ひどい。&lt;/p&gt;

&lt;p&gt;そもそも当初のテキストコンテンツを解析してサイトを自動構成というコンセプトはどこへ行ったのか。
GoslingsのReadmeを入力したらシャレオツなサイトをささっと作ってくれるイメージだったんだけど。&lt;/p&gt;

&lt;p&gt;まだまだ開発中の機能がたくさんあるそうなので、GAまでにはもうちょっとなんとかなるんだろう。
あまり期待はしない。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Hibernateはどのようにして私のキャリアを破滅寸前にしたか</title>
          <link>https://www.kaitoy.xyz/2017/02/23/how-hibernate-ruined-my-career/</link>
          <pubDate>Thu, 23 Feb 2017 00:25:03 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/02/23/how-hibernate-ruined-my-career/</guid>
          <description>

&lt;p&gt;このエントリでは、Grzegorz Gajosによる記事、&lt;a href=&#34;http://ggajos.com/how-hibernate-ruined-my-career/&#34;&gt;How Hibernate Almost Ruined My Career&lt;/a&gt;を紹介する。
(Grzegorzから和訳と転載の許可は得た。)
以下はその全文の和訳だが、意訳超訳が混じっているので、もとのニュアンスを知りたければ元記事を読んでもいいし、読まなくてもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;想像してくれ。
君はJava開発者で、次のビッグプロジェクトを開始しようとしているところだ。
君は、そのプロジェクト全体に影響する根本的な決断をする必要がある。
君の柔軟なデータモデルをオブジェクト指向で抽象化するベストな方法を選択したい。生のSQLを扱いたくはないからね。
どんな種類のデータもサポートしたいし、理想では全種のデータベースをサポートしたい。&lt;/p&gt;

&lt;p&gt;すぐに思いつくのは、単にHibernateを使うという解だ。そうだろ？
Javaディベロッパの90%は君に同意するだろう。
しかし、それって正しい決断になっているだろうか？&lt;/p&gt;

&lt;p&gt;Hibernateが一般に受け入れられているスタンダードだからといって盲目的に採用してしまうと、どんな問題が発生するかを見てみよう。&lt;/p&gt;

&lt;p&gt;モニカというJava開発者がいるとしよう。
モニカは最近出世してアーキテクトの役職に就き、会社の新製品のための技術スタックを選定する責任者になった。
彼女は、Javaの世界にはデータベースとのやり取りを扱うたった一つの適切なツールがあることを知っている。Hibernateだ。
Hibernateは良く知られ支持されているJPAのスタンダードではあるが、プロジェクト開始前に多少のチェックをするのが定跡だ。
幸いにも、同僚のベンが適任者を知っている。&lt;/p&gt;

&lt;h1 id=&#34;4年前-hibernateは銀の弾丸かのように見えた&#34;&gt;4年前、Hibernateは銀の弾丸かのように見えた&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;ベン: やあモニカ。ジョンを紹介させてくれ。彼はHibernateの達人だ。君の助けになるはずだ。&lt;/li&gt;
&lt;li&gt;モニカ: ジョン、時間を取ってくれてありがとう。
今、私たちが次なる目玉製品を開発しようとしてるのは知ってる？
次のFacebookやGoogleになるつもりなの。
忙しくなるわ。巨大なものになる。
本当にすてき！
みんなとても興奮してる！
私はアーキテクトの役に就いたから、とりあえず採用する技術スタックを選定しなければいけないの。
ひとつだけまだ欠けてるのが永続化なんだけど…&lt;/li&gt;
&lt;li&gt;ジョン: Hibernate！&lt;/li&gt;
&lt;li&gt;モニカ: そう！そのとおり！
わたしもそう考えていたの！
それならわたしたちにぴったりで上手く行きそうでしょう。
マーケットと豊富な実績に裏付けられた、真の業務問題のための真の業務ソリューション。
とてもたくさんのポジティブな経験談を聞いたことがあるわ。
けど、一つ問題があって、チームメンバのひとりがそれに絶対反対してるの。
アプリケーションとデータベースの間に別のレイヤを加えるのを気にして。
彼はすごく頭がいいから、これが良い決断だと納得させるには本当にしっかりした根拠が必要なの。
助けてくれる？&lt;/li&gt;
&lt;li&gt;ジョン: もちろん、よろこんで！
Hibernateは、実際、すばらしいツールです。
銀行といった、大きな真の業務ソリューションで広く使われています。
それを使って失敗するということはありえません。
永続化ときたらHibernate。
Javaで書いているならそれが完全に正しい選択ですし、さらには他の言語への移植もあります。
どれだけ多くの職務記述書がそれを要求しているか！&lt;/li&gt;
&lt;li&gt;モニカ: 全く同感！
同じことを感じていたわ。
前のプロジェクトで、ほとんどのところで生のJDBCからSQLを使っていたんだけど、ばかげてた！
そうでしょ！
けど、実は、ほんとに優秀なSQL屋がチームにいて、Hibernateが生成したSQLを見て神経質になってるの。
きたなくて読みにくいって。
これって将来問題になりそう？&lt;/li&gt;
&lt;li&gt;ジョン: 気を付けてください。DBA屋ってのは違ったものの見方をします。
彼らはプロジェクトにおける自分の立場をHibernateに奪われるのではないかと危惧しています。
さらに、データベースには組み込みのクエリ最適化機構があるので、クエリの実際の見た目がどんなかは気にする必要はありません。
データベースが最適化してくれます。
それが高速開発ってものです。
SQLにはまねできません。&lt;/li&gt;
&lt;li&gt;モニカ: ほんとに？
もうSQLを触らなくていいの？
すごい！
この前DBAがクエリの最適化に数週間かけていたわ。
数週間！
あぁ、こんなこと言うのは恥ずかしいんだけど、わたしたちが何を使っていたか分かる？
…ストアドプロシージャ(笑)
もうくちゃくちゃだった。
そのプロジェクト、まだそれ使ってるって信じられる？
そこの人たちほんとに気の毒だわ。
未だにあんな退屈なコードを何度も何度も書かないといけないなんて。
あれってJavaというかもうSQLプロジェクトじゃない？&lt;/li&gt;
&lt;li&gt;ジョン: それはまさにオブジェクト指向とリレーショナルのアプローチの違いです。
いわゆるオブジェクト指向インピーダンスミスマッチですね。
Hibernateはその溝を埋めてくれます。
開発者はビジネスロジックの構築に専念できます。
ステークホルダもマネージメント全体も幸せになれます。
最も重要となることをしましょう。ビジネスです！
ボイラープレートの多くは消え去り、魔法のようで目には見えませんが、ロジックとデータとの間にしっかりとしたコネクションができるのです。&lt;/li&gt;
&lt;li&gt;モニカ: 相互協調。充実したシナジー。
まるでデータベースが最初から言語の一部だったかのよう。
信念の技術的飛躍の指導者になれてとても幸せ。
ソフトウェアという旅路でワープスピードに乗ったみたい。&lt;/li&gt;
&lt;li&gt;ジョン: そう！その調子！&lt;/li&gt;
&lt;li&gt;モニカ: わーい！すごーい！
わくわくしてきた！たーのしー！
ありがとうジョン。
準備万端！&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;3年前-柔軟性のないソリューションとともに大きくなる苦悩&#34;&gt;3年前、柔軟性のないソリューションとともに大きくなる苦悩&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;モニカ: ねえジョン、去年話したプロジェクト覚えてる？&lt;/li&gt;
&lt;li&gt;ジョン: もちろん。調子はどうですか？&lt;/li&gt;
&lt;li&gt;モニカ: もうすぐリリースするわ。
全て順調。だけどいくつか疑問がわいてきたの。&lt;/li&gt;
&lt;li&gt;ジョン: いいですよ。聞いてください。&lt;/li&gt;
&lt;li&gt;モニカ: ええと、もうデータベーススキーマを一から生成することはできないんだけど、データロスのないスキーマ変更をサポートするにはどうするのが一番いい？&lt;/li&gt;
&lt;li&gt;ジョン: えぇ、まず、Hibernateはプロダクション環境での移行ツールとして使われることを想定していません。
FlywayDBやLiquibaseといったものを使うべきです。
結構簡単ですよ。移行スクリプトを書いて、それでエンティティモデルを更新しつつ、Hibernateのマッピングも直して、
実際のデータベース構造と同期するようにしてください。&lt;/li&gt;
&lt;li&gt;モニカ: ふーん、分かった。前のプロジェクトでは単に生のSQLで移行してた。&lt;/li&gt;
&lt;li&gt;ジョン: それでもいいと思います。エンティティモデルとスキーマが同期してさえいれば、好きなやり方でやってください。&lt;/li&gt;
&lt;li&gt;モニカ: そうね。
もう一つ、わたしたちいつも遅延フェッチと即時フェッチの問題と戦ってるの。
ある時、全部を即時でやることに決めたんだけど、それって最適じゃないでしょ？
それに、たまにセッションが残ってないせいかなにかで、フィールドにアクセスできないことがあるの。
それって普通？&lt;/li&gt;
&lt;li&gt;ジョン: もっとHibernateについて学ぶ必要があります。
データベースとのマッピングは単純ではありません。
複数のやりかたがあるのが普通です。
その中から自分に合ったものを選ぶのです。
遅延フェッチはオブジェクトを必要なときにロードできるようにしますが、アクティブなセッションの中で実行しないといけません。&lt;/li&gt;
&lt;li&gt;モニカ: わたしたちはまだ最終的なデプロイでどのデータベースエンジンを使うべきか迷ってるの。
Hibernateってポータブルだと思ってたけど、MS SQLの魔法を使うためにちょっとネイティブクエリを使ってて、実際にはプロダクション環境ではMySQLで行きたいんだけど。&lt;/li&gt;
&lt;li&gt;ジョン: HibernateはdetachedなCriteriaクエリかHQLを使っている限りは柔軟です。
ネイティブクエリを使ったらそのデータベースにソリューションが固定されちゃいますよ。&lt;/li&gt;
&lt;li&gt;モニカ: それならMS SQL専用にしないとダメみたいね。
最後の質問。チームメンバからHQLには「limit」キーワードがないと聞いたわ。
冗談かと思ったけど、わたしも見つけられなかった。
バカな質問で申し訳ないんだけど…&lt;/li&gt;
&lt;li&gt;ジョン: 確かに。HQLには「limit」はありません。
クエリオブジェクトでコントロールすることはできます。
データベースベンダ依存のものなので。&lt;/li&gt;
&lt;li&gt;モニカ: 他の要素は全部HQLにあるのに変ね。
まあ気にしないで。
時間取ってくれてありがとう！&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;2年前-わたしたちは今再びsqlでソリューションをハックしている&#34;&gt;2年前、わたしたちは今再びSQLでソリューションをハックしている&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;モニカ: ジョン、最初わたしたちSQLを触らないつもりだったけど、今はその必要があると感じてる。
要件が大きくなってきていて、それを避ける手立てはないみたいなの。
間違ったことをしているかもしれないけど、またSQLを毎日のように使い始めたわ。&lt;/li&gt;
&lt;li&gt;ジョン: いえ、それは間違っていません。
最初期にはデータベースを気に掛ける必要はありませんでしたが、プロジェクトが進んだ今では、SQLを使ってパフォーマンスの最適化に取り組むのはいいことです。&lt;/li&gt;
&lt;li&gt;モニカ: ときどきエラーを調査するのに数日かかるの。
なぜ期待通りに動かないのか、なぜ思いがけない結果が出力されるのかが全く分からないから、Hibernateが生成したSQLを解析しないといけないみたい。
Hibernateのバグトラッカーに載ってる有名な問題に当たったこともある。
それだけじゃない。エンティティモデルの同期を保ったまま適切な移行処理を書くのは難しいの。
Hibernateの内部をよく調査して、どう動くのかを予測する必要があって、時間を取られてしまう。&lt;/li&gt;
&lt;li&gt;ジョン: 学習曲線というのは常にあります。
たくさんの記述はいりませんが、どう動くかは知っておく必要があります。&lt;/li&gt;
&lt;li&gt;モニカ: 大きなデータセットを扱うのも厄介。
最近データベースに大量のインポートをしたんだけど、あまりにも遅かった。
あとで、速くするにはセッションをクリアする必要があったって分かったんだけど、それでもまだ全然遅い。
だから生のSQLで書き直すことにしたの。
笑ったわ。生のSQLを書くのが実際最速の方法だったから。
だから最後の選択肢としてそうすることに決めたの。&lt;/li&gt;
&lt;li&gt;ジョン: インポートはオブジェクト指向な処理ではないです。
Hibernateはオブジェクト指向設計に焦点を当てています。
ネイティブクエリという選択肢を忘れてはいけません。&lt;/li&gt;
&lt;li&gt;モニカ: Hibernateのキャッシュがどう動くか知りたいんだけど、教えてくれる？
ちょっと分からないの。
一次キャッシュとか二次キャッシュとかあるけど、どういうものなの？&lt;/li&gt;
&lt;li&gt;ジョン: もちろんです。
それはいわゆる永続データのトランザクションレベルキャッシュです。
クラスタやJVMレベルで、クラス毎やコレクション毎のキャッシュを設定できます。
クラスタキャッシュを組み込むことさえできます。
しかし、キャッシュは他のアプリケーションが永続化領域に加えた変更については関知しないことを覚えておいてください。
期限切れのキャッシュデータを定期的に消すように設定することはできますが。&lt;/li&gt;
&lt;li&gt;モニカ: ごめん。気分が悪くなってきた。
もう少し説明してくれる？&lt;/li&gt;
&lt;li&gt;ジョン: はい。
&lt;code&gt;save&lt;/code&gt;とか&lt;code&gt;update&lt;/code&gt;とか&lt;code&gt;saveOrUpdate&lt;/code&gt;にオブジェクトを渡したり、&lt;code&gt;load&lt;/code&gt;、&lt;code&gt;get&lt;/code&gt;、&lt;code&gt;list&lt;/code&gt;、&lt;code&gt;iterate&lt;/code&gt;、&lt;code&gt;scroll&lt;/code&gt;でオブジェクトを取得するときは常に、そのオブジェクトはセッションの内部キャッシュに追加されます。
一次キャッシュからオブジェクトやそのコレクションを削除することもできます。&lt;/li&gt;
&lt;li&gt;モニカ: あぁ…&lt;/li&gt;
&lt;li&gt;ジョン: さらに、キャッシュモードを制御することもできます。
&lt;code&gt;normal&lt;/code&gt;モードでは読み込みと書き込みで二次キャッシュを使います。
&lt;code&gt;get&lt;/code&gt;モードでは二次から読みますがライトバックはできません。
&lt;code&gt;put&lt;/code&gt;は&lt;code&gt;get&lt;/code&gt;と同じですが二次から読むことはできません。
&lt;code&gt;refresh&lt;/code&gt;モードもあります。
これは二次に書き込みますが、そこからは読み込まず、&lt;code&gt;use minimal puts&lt;/code&gt;プロパティを無視し、データベースからの全ての読み込み時に二次キャッシュを強制リフレッシュします。&lt;/li&gt;
&lt;li&gt;モニカ: いいわ。わかった。
ちょっと考えさせて。
もう遅いわ。行かなきゃ。
説明ありがとう！&lt;/li&gt;
&lt;li&gt;ジョン: どういたしまして！&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;2週間前-hibernateをあきらめる&#34;&gt;2週間前、Hibernateをあきらめる&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;モニカ: ジョン、わたしソフトウェア開発の新時代に入ろうとしてるんだと思ってた。
一光年の飛躍をしてるんだと思ってた。
けど、4年たった今も、わたしたちは同じ問題に対応してるみたい。単に違う方向から。
私はHibernateのアーキテクチャ、設定、ロギング、ネーミング戦略、Tuplizer、エンティティ名リゾルバ、拡張IDジェネレータ、IDジェネレータ最適化、ユニオンサブクラス、XDocletマークアップ、インデックス付きコレクションの双方向関連、3項関連、idbag、暗黙的ポリモーフィズムと他の継承マッピングの組み合わせ、二つの異なるデータストア間でのオブジェクトレプリケーション、detachedオブジェクトと自動バージョニング、コネクション開放モード、ステートレスセッションインターフェース、コレクション永続化の分類法、キャッシュレベル、遅延/即時フェッチ、他にもいろんなことを学ばなければならなかった。
わたしの知ってる全てがあっても、ひどい失敗になっていたと思う。
ソフトウェアの出来損ないだわ！
究極の失敗！
大参事！
アルマゲドン！&lt;/li&gt;
&lt;li&gt;ジョン: 待ってください！なにがあったんですか？&lt;/li&gt;
&lt;li&gt;モニカ: わたしたち行き詰ったの。
わたしたちのアプリケーションの性能はばかばかしいほど遅い！
レポートを取得するのに二日も待たないといけない！
二日でやっと顧客にダッシュボードを生成して見せられるの。
つまり毎日計算処理を開始させなければならない上に、ダッシュボードの情報はどんどん遅れてしまう。
うちのDBAエキスパートがクエリ最適化に2か月取り組んでるけど、データベース構造がめちゃくちゃで。
それを手伝ってる開発者もいるけど、困ったことに、DBAはSQLで考えているから、開発者はそれをdetached CriteriaかHQLに翻訳しようと何日も費やしてしまうの。
今となっては性能がかなり重要だから、できるだけネイティブSQLを使おうとしてるわ。
なんにせよ、データベーススキーマがはっきり間違っちゃってるから大したことはできない。
オブジェクト指向な視点ではそれでいいと感じていたけど、リレーショナルな視点では最悪だったみたい。
どうしてこうなっちゃったんだろう？
開発者はエンティティ構造を変えるのはかなりの労力になると言うから、それをする余裕はないし。
前のプロジェクトは乱雑ではあったけど、そんな窮地には陥らなかった。
既存のデータを処理する完全に別のアプリケーションを書くこともできた。
今は、生成されたテーブルを変えるのは危険だわ。
エンティティモデルが完全に正しく動くことを保証するのは本当に難しいもの。
けどこれさえも最悪な点ってわけではないわ！
性能改善するには、データベース問題だけでなく、データベースとアプリケーションの間のレイヤ全体の問題も解決しないといけない。
それが圧倒的！
この新しく加わった人たちはね、コンサルタントなの。
彼らはデータを抽出して、なにか別のストレージに入れて、外側から計算を実行しようとしてる。
どれも時間かかりすぎ！&lt;/li&gt;
&lt;li&gt;ジョン: なんと言っていいか分かりません。&lt;/li&gt;
&lt;li&gt;モニカ: いいのよジョン、あなたを責めはしないわ。
わたしはHibernateを選択して全ての問題を解決しようとしたけど、今ではそれが銀の弾丸ではないと分かる。
もうダメージは負ったし、それをなかったことにはできない。
実は、あなたにお願いしたいことがあるの。
わたしはこの4年間のキャリアをHibernateのあれこれとの戦いに費やしてしまったわ。
もう今の会社でわたしに未来はないみたい。
助けてくれない？&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;今日-学んだ教訓は&#34;&gt;今日、学んだ教訓は？&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;ジョン: やあピーター、モニカを紹介するよ。&lt;/li&gt;
&lt;li&gt;ピーター: やあモニカ！
わたしたちは新しい次なる目玉を開発しようとしてるんだけどね。
巨大なものになりそうだよ！
Uberみたいになりたいんだ！
永続化について何か知って…&lt;/li&gt;
&lt;li&gt;モニカ: Hibernateはダメ！&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;まとめ&#34;&gt;まとめ&lt;/h1&gt;

&lt;p&gt;モニカはHibernateのエキスパートだ。
しかし、この例ではHibernateは間違った選択だった。
彼女のソリューションが以前より大きな問題に変化したと気付いたときには、プロジェクト全体を脅かす最大の脅威になってしまっていた。&lt;/p&gt;

&lt;p&gt;データはアプリケーションの目的の中心で、好むと好まざるにかかわらず、アーキテクチャ全体に影響する。
このストーリーから学んだとおり、アプリケーションがデータベースを使うからとか、&lt;a href=&#34;http://d.hatena.ne.jp/keyword/%A5%BD%A1%BC%A5%B7%A5%E3%A5%EB%A5%D7%A5%EB%A1%BC%A5%D5&#34;&gt;ソーシャルプルーフ&lt;/a&gt;があるからというだけの理由でHibernateを選択してはいけない。
柔軟性をもつソリューションを選ぶべきだ。
堅牢なJDBCラッパには&lt;a href=&#34;http://docs.spring.io/spring/docs/current/javadoc-api/org/springframework/jdbc/core/JdbcTemplate.html&#34;&gt;JdbcTemplate&lt;/a&gt;や&lt;a href=&#34;http://jdbc.jcabi.com/&#34;&gt;Fluent JDBC Wrapper&lt;/a&gt;といった多くの選択肢がある。
あるいは他にも、&lt;a href=&#34;http://www.jooq.org/&#34;&gt;jOOQ&lt;/a&gt;といった強力なソリューションがある。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上がGrzegorzの記事。&lt;/p&gt;

&lt;p&gt;ジョンにそそのかされて、Hibernateへの期待が高まるあまり一時けもの並の知能になったモニカが、4年の間に現実を知り絶望していくさまが生々しく怖い話だ。
オブジェクト指向の都合だけでデータベーススキーマを決めてしまった辺りが一番の失敗だったんだろうか。
SQL中心に考えつつHibernateでORマッピングやスキーマを構築することも、HibernateとSQL両方熟知してればできるんだろうか。&lt;/p&gt;

&lt;p&gt;なんにせよ、Hibernateが忌み嫌われるようになった理由がよくわかる面白い記事だった。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ブログアドレスを変更したときにやったこと</title>
          <link>https://www.kaitoy.xyz/2017/02/14/change-subdomain/</link>
          <pubDate>Tue, 14 Feb 2017 09:51:42 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/02/14/change-subdomain/</guid>
          <description>

&lt;p&gt;このブログの閲覧数がそこそこの規模になってきたので、&lt;a href=&#34;https://www.google.co.jp/adsense/start/&#34;&gt;Google AdSense&lt;/a&gt;で小遣い稼ぎを始めようとしたら、最近サブドメインが&lt;code&gt;www&lt;/code&gt;じゃないとできないようになったようだったので、サブドメインを&lt;code&gt;tbd&lt;/code&gt;から&lt;code&gt;www&lt;/code&gt;に変更した話。&lt;/p&gt;

&lt;p&gt;変更自体はそんなに難しくなかったけど、Googleの検索順位を保つためにいろいろ気を使う必要があった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;ブログアドレスの変更&#34;&gt;ブログアドレスの変更&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/08/28/using-hugo/&#34;&gt;以前&lt;/a&gt;にも書いたが、このブログは&lt;a href=&#34;https://gohugo.io/&#34;&gt;&lt;strong&gt;Hugo&lt;/strong&gt;&lt;/a&gt;で作って&lt;a href=&#34;https://pages.github.com/&#34;&gt;&lt;strong&gt;GitHub Pages&lt;/strong&gt;&lt;/a&gt;でカスタムドメインで公開している。&lt;/p&gt;

&lt;p&gt;コメント欄を設けるために&lt;a href=&#34;https://disqus.com/&#34;&gt;&lt;strong&gt;Disqus&lt;/strong&gt;&lt;/a&gt;を使っている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cloudflare.com/&#34;&gt;&lt;strong&gt;Cloudflare&lt;/strong&gt;&lt;/a&gt;を使って&lt;a href=&#34;https://www.kaitoy.xyz/2016/07/01/https-support-by-cloudflare/&#34;&gt;全体をHTTPS化&lt;/a&gt;していて、その関係で&lt;code&gt;kaitoy.xyz&lt;/code&gt;ドメインの名前解決にはCloudflareのDNSを使っている。&lt;/p&gt;

&lt;p&gt;アクセス解析などのために&lt;a href=&#34;https://analytics.google.com/&#34;&gt;&lt;strong&gt;Google Analytics&lt;/strong&gt;&lt;/a&gt;と&lt;a href=&#34;https://www.google.com/webmasters/tools/home&#34;&gt;&lt;strong&gt;Google Search Console&lt;/strong&gt;&lt;/a&gt;を使ってる。&lt;/p&gt;

&lt;p&gt;この構成で、ブログアドレスの変更に必要だった修正を列挙する。(この順にやったわけではない。)&lt;/p&gt;

&lt;h4 id=&#34;1-ブログソース修正&#34;&gt;1. ブログソース修正&lt;/h4&gt;

&lt;p&gt;Hugoの設定ファイルである&lt;code&gt;config.toml&lt;/code&gt;に書いてある&lt;code&gt;baseurl&lt;/code&gt;の値を&lt;code&gt;https://tbd.kaitoy.xyz&lt;/code&gt;から&lt;code&gt;https://www.kaitoy.xyz&lt;/code&gt;に変え、また、各記事の内部リンクのURLも&lt;code&gt;www&lt;/code&gt;のに変えた。&lt;/p&gt;

&lt;p&gt;あと&lt;code&gt;robots.txt&lt;/code&gt;の&lt;code&gt;Sitemap&lt;/code&gt;のURLも&lt;code&gt;https://www.kaitoy.xyz/sitemap.xml&lt;/code&gt;に更新した。&lt;/p&gt;

&lt;h4 id=&#34;2-github-pagesの設定変更&#34;&gt;2. GitHub Pagesの設定変更&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kaitoy/blog&#34;&gt;ブログリポジトリ&lt;/a&gt;に行って、&lt;code&gt;Settings&lt;/code&gt;の&lt;code&gt;GitHub Pages&lt;/code&gt;欄の&lt;code&gt;Custom domain&lt;/code&gt;の値を&lt;code&gt;https://www.kaitoy.xyz&lt;/code&gt;に変えた。&lt;/p&gt;

&lt;p&gt;ついでにブログリポジトリのトップに表示される&lt;code&gt;Description&lt;/code&gt;の&lt;code&gt;Website&lt;/code&gt;の値も新しいURLに変更した。&lt;/p&gt;

&lt;p&gt;この変更によりありがたい副作用もあった。
GitHub Pagesは&lt;code&gt;www&lt;/code&gt;というサブドメインを特別扱いしていて、以下の恩恵を受けられるのだ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;wwwを省略したURL(apex domain)でアクセスすると、GitHub Pagesサーバがwww付きのURLに&lt;a href=&#34;https://help.github.com/articles/setting-up-an-apex-domain-and-www-subdomain/&#34;&gt;リダイレクトしてくれる&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://help.github.com/articles/about-supported-custom-domains/#www-subdomains&#34;&gt;安定していて速い&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;3-cloudflareのdns設定変更&#34;&gt;3. CloudflareのDNS設定変更&lt;/h4&gt;

&lt;p&gt;CloudflareのDNSで、もともと&lt;code&gt;CNAME&lt;/code&gt;レコードで&lt;code&gt;kaitoy.github.io&lt;/code&gt;(GitHub Pagesのデフォルトのドメイン)のエイリアスを&lt;code&gt;tbd&lt;/code&gt;にしていたのを&lt;code&gt;www&lt;/code&gt;に変更した。&lt;/p&gt;

&lt;p&gt;また、上記の通りapex domainでGitHub Pagesにアクセスしても上手いことやってくれるようになったので、&lt;code&gt;www.kaitoy.xyz&lt;/code&gt;のエイリアスを&lt;code&gt;kaitoy.xyz&lt;/code&gt;とする&lt;code&gt;CNAME&lt;/code&gt;レコードを追加した。
CloudflareのDNSはapex domain(i.e. &lt;code&gt;kaitoy.xyz&lt;/code&gt;)に対する&lt;code&gt;CNAME&lt;/code&gt;レコード設定を&lt;a href=&#34;https://support.cloudflare.com/hc/en-us/articles/200169056-CNAME-Flattening-RFC-compliant-support-for-CNAME-at-the-root&#34;&gt;サポートしている&lt;/a&gt;ので、これで&lt;code&gt;www.kaitoy.xyz&lt;/code&gt;でも&lt;code&gt;kaitoy.xyz&lt;/code&gt;でもGitHub Pagesにルーティングされるようになった。&lt;/p&gt;

&lt;h4 id=&#34;4-disqusの設定変更&#34;&gt;4. Disqusの設定変更&lt;/h4&gt;

&lt;p&gt;ホームの右上の歯車アイコンから&lt;code&gt;Admin&lt;/code&gt;を開いて、ヘッダの&lt;code&gt;Settings&lt;/code&gt;からブログのURLを選んでその設定画面を開き、&lt;code&gt;Website URL&lt;/code&gt;を&lt;code&gt;https://www.kaitoy.xyz&lt;/code&gt;に変更した。&lt;/p&gt;

&lt;h4 id=&#34;5-google-analyticsの設定変更&#34;&gt;5. Google Analyticsの設定変更&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;管理&lt;/code&gt;タブの&lt;code&gt;プロパティ設定&lt;/code&gt;の&lt;code&gt;デフォルトの URL&lt;/code&gt;を&lt;code&gt;https://www.kaitoy.xyz&lt;/code&gt;に変更しただけ。&lt;/p&gt;

&lt;h1 id=&#34;googleのページランクを保つためのあれこれ&#34;&gt;Googleのページランクを保つためのあれこれ&lt;/h1&gt;

&lt;p&gt;以前もどこかに書いたが、どんなにすばらしい内容の記事を書いてもGoogle検索結果の2,3ページくらいまでに出てこないんであれば誰も読んでくれない。
このブログのいくつかの記事はそれなりにいいキーワードでいい検索順位になっていたので、サブドメイン変更によってページランクに悪影響が出るのはなるべく避けたかった。&lt;/p&gt;

&lt;p&gt;調べたら、&lt;a href=&#34;https://support.google.com/webmasters/answer/6033049?hl=ja&amp;amp;ref_topic=6033084&#34;&gt;Google Search Consoleのヘルプ&lt;/a&gt;にまさにその悪影響を防ぐ方法が載っていたので、これに従ってあれこれした。&lt;/p&gt;

&lt;h4 id=&#34;1-自身を参照する-rel-canonical-リンクタグを付ける&#34;&gt;1. 自身を参照する &lt;code&gt;rel=&amp;quot;canonical&amp;quot;&lt;/code&gt;リンクタグを付ける&lt;/h4&gt;

&lt;p&gt;ブログの全てのページのヘッダに以下の様な移転先アドレスを指すlinkタグを付け、変更後のアドレスが正式なアドレスであることをGooglebotに教えてやる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;link rel=&amp;quot;canonical&amp;quot; href=&amp;quot;https://www.kaitoy.xyz/2015/07/18/first-post/&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hugoのソースでいうと以下の感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;link rel=&amp;quot;canonical&amp;quot; href=&amp;quot;{{ .Permalink }}&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;2-http-301リダイレクトを設定&#34;&gt;2. HTTP 301リダイレクトを設定&lt;/h4&gt;

&lt;p&gt;多分これが一番重要なんじゃなかろうか。&lt;/p&gt;

&lt;p&gt;HTTPステータスコードの&lt;a href=&#34;https://support.google.com/webmasters/answer/93633&#34;&gt;301&lt;/a&gt;はサイトのコンテンツが別のURLに恒久的に移転したことを示すもので、移転前のURLにアクセスしたクライアントに301を移転先のURLとともに返してやることで、HTTPレベルでのリダイレクトをさせることができる。&lt;/p&gt;

&lt;p&gt;GooglebotもこのステータスコードでブログURLの変更を知ることができるので、検索結果をよしなに移行してくれるはず。&lt;/p&gt;

&lt;p&gt;301を返すサーバには&lt;a href=&#34;https://www.xrea.com/&#34;&gt;XREA&lt;/a&gt;の無料サーバを使った。
このブログのドメインは&lt;a href=&#34;https://www.value-domain.com/&#34;&gt;バリュードメイン&lt;/a&gt;で買ったもので、ここがXREAと提携していたので無料サーバも合わせて確保していたもののほとんど使っていなかったので調度よかった。
調べたらこのサーバで、&lt;a href=&#34;https://httpd.apache.org/&#34;&gt;Apache HTTP Server&lt;/a&gt;の設定ファイルである&lt;code&gt;.htaccess&lt;/code&gt;が使えることが分かったので、以下の内容で作って&lt;code&gt;/public_html/&lt;/code&gt;に置いた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;Files ~ &amp;quot;^\.ht&amp;quot;&amp;gt;
deny from all
&amp;lt;/Files&amp;gt;

# Redirect
Redirect permanent / https://www.kaitoy.xyz/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、サーバの管理ページからドメインウェブ設定画面に行き、Mainのドメイン名を&lt;code&gt;tbd.kaitoy.xyz&lt;/code&gt;に設定。&lt;/p&gt;

&lt;p&gt;あとはCloudflareのDNS設定で、&lt;code&gt;tbd&lt;/code&gt;を上記XREAサーバのIPアドレスに解決する&lt;code&gt;A&lt;/code&gt;レコードを追加して完了。&lt;/p&gt;

&lt;h4 id=&#34;3-google-search-consoleのアドレス変更ツール実行&#34;&gt;3. Google Search Consoleのアドレス変更ツール実行&lt;/h4&gt;

&lt;p&gt;最後の仕上げとして、Google Search Consoleの&lt;a href=&#34;https://support.google.com/webmasters/answer/83106&#34;&gt;アドレス変更ツール&lt;/a&gt;を使ってGooglebotにアドレス変更を通知した。&lt;/p&gt;

&lt;p&gt;このツールはGoogle Search Consoleの管理サイトごとのページの右上の歯車アイコンから&lt;code&gt;アドレス変更&lt;/code&gt;を選択すると開け、以下のようなものが表示される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/change-subdomain/change_address.png&#34; alt=&#34;change_address.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;このウィザードに従って、移転先URL(プロパティ)の追加、301リダイレクトの動作確認、サイトの存在確認をして、アドレス変更のリクエストを送信するだけ。&lt;/p&gt;

&lt;p&gt;最後に、追加したプロパティの&lt;code&gt;クロール&lt;/code&gt;の&lt;code&gt;サイトマップ&lt;/code&gt;から、移転先サイトのサイトマップを送信して完了。
サイトマップはHugoがビルド時に生成してくれたやつ。&lt;/p&gt;

&lt;p&gt;今&lt;a href=&#34;https://support.google.com/webmasters/answer/6033049?hl=ja&amp;amp;ref_topic=6033084&#34;&gt;Google Search Consoleのヘルプ&lt;/a&gt;を見直したら移転前のサイトマップも送信しろと書いてあるのに気付いた。
これはやらなかったけど、やった方がよかったのかも。&lt;/p&gt;

&lt;p&gt;ともあれ、移転後一時的に検索順位が大きく落ちたものの、1,2週間位でもとにもどったので、この移転は概ね成功だったと思う。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goslings開発メモ - その5: Spring Boot最終編 (静的リソース処理)</title>
          <link>https://www.kaitoy.xyz/2017/01/24/goslings-development-memo5-spring-boot-static-resources/</link>
          <pubDate>Tue, 24 Jan 2017 09:01:49 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/01/24/goslings-development-memo5-spring-boot-static-resources/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/17/goslings-development-memo4-spring-boot-logging/&#34;&gt;Goslings開発メモ - その4: Spring Boot続続続編 (ロギング)&lt;/a&gt;」の続き。&lt;/p&gt;

&lt;p&gt;Spring Boot最終編で、静的リソース処理について。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;spring-boot-spring-mvc-での静的リソース処理&#34;&gt;Spring Boot(Spring MVC)での静的リソース処理&lt;/h1&gt;

&lt;p&gt;この時点でのGoslingsは単なるREST APIサーバで、アクセスしてもJSONを返すだけだ。
アプリとしての体を成すためには、そのAPIを利用するクライアントコード、つまりHTMLドキュメントやCSSファイルやJavaScriptファイル(静的リソース)も返すようにしないといけない。
HTMLドキュメントを返す場合、普通はなんらかの&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%86%E3%83%B3%E3%83%97%E3%83%AC%E3%83%BC%E3%83%88%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%B3&#34;&gt;テンプレートエンジン&lt;/a&gt;を使うものだが、Goslingsは本当に単純なGUIなので、サーバに置いたHTMLファイルをそのまま返したい。&lt;/p&gt;

&lt;p&gt;「Getting Started Guides」には&lt;a href=&#34;https://spring.io/guides/gs/serving-web-content/&#34;&gt;Serving Web Content with Spring MVC&lt;/a&gt;というのが乗っているが、これは&lt;a href=&#34;http://www.thymeleaf.org/&#34;&gt;Thymeleaf&lt;/a&gt;というテンプレートエンジンを使うものなのでちょっと違う。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/htmlsingle/#boot-features-spring-mvc-static-content&#34;&gt;Spring Bootリファレンスガイド&lt;/a&gt;によると、クラスパス(または&lt;code&gt;ServletContext&lt;/code&gt;のルート)の&lt;code&gt;/static/&lt;/code&gt;、&lt;code&gt;/public/&lt;/code&gt;、&lt;code&gt;/resources/&lt;/code&gt;、&lt;code&gt;/META-INF/resources/&lt;/code&gt;のいずれかに静的リソースを置けば、特にコードを書かなくてもクライアントからアクセスできるらしい。
(逆に、一般的に静的リソースを置く場所である、プロジェクトの&lt;code&gt;src/main/webapp/&lt;/code&gt;には置くべきでないとのこと。これは、jarにパッケージングするときにビルドツールに無視されることが多いため。)&lt;/p&gt;

&lt;p&gt;この仕組みについて、&lt;a href=&#34;https://spring.io/blog/2013/12/19/serving-static-web-content-with-spring-boot&#34;&gt;この記事&lt;/a&gt;を参考にちょろっとソースを見た感じでは、これらのパスは&lt;a href=&#34;https://github.com/spring-projects/spring-boot/blob/v1.4.3.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/ResourceProperties.java#L44&#34;&gt;&lt;code&gt;ResourceProperties&lt;/code&gt;の&lt;code&gt;CLASSPATH_RESOURCE_LOCATIONS&lt;/code&gt;&lt;/a&gt;に定義されていて、これを&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/api/org/springframework/boot/autoconfigure/web/WebMvcAutoConfiguration.html&#34;&gt;&lt;code&gt;WebMvcAutoConfiguration&lt;/code&gt;&lt;/a&gt;が&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/config/annotation/ResourceHandlerRegistry.html&#34;&gt;&lt;code&gt;ResourceHandlerRegistry&lt;/code&gt;&lt;/a&gt;で&lt;a href=&#34;https://github.com/spring-projects/spring-boot/blob/v1.4.3.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/WebMvcAutoConfiguration.java#L291&#34;&gt;リソースロケーションとして登録する&lt;/a&gt;ことで静的リソース置き場たらしめている模様。
(この&lt;code&gt;ResourceHandlerRegistry&lt;/code&gt;は&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/ResourceHttpRequestHandler.html&#34;&gt;&lt;code&gt;ResourceHttpRequestHandler&lt;/code&gt;&lt;/a&gt;を設定するファサード的なものっぽい。)&lt;/p&gt;

&lt;p&gt;で、&lt;code&gt;@SpringBootApplication&lt;/code&gt;(&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/&#34;&gt;その1&lt;/a&gt;参照)が付いているクラスがあって、&lt;code&gt;spring-webmvc.jar&lt;/code&gt;がクラスパスにあると、&lt;a href=&#34;http://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/config/annotation/EnableWebMvc.html&#34;&gt;&lt;code&gt;@EnableWebMvc&lt;/code&gt;&lt;/a&gt;がSpring Bootによって付けられ、そこからごにょごにょして上記&lt;code&gt;WebMvcAutoConfiguration&lt;/code&gt;が実行される。
&lt;code&gt;spring-webmvc.jar&lt;/code&gt;は&lt;code&gt;spring-boot-starter-web.jar&lt;/code&gt;(&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/&#34;&gt;その1&lt;/a&gt;参照)が引っ張ってくる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;なお、Spring MVCの静的リソース処理の全体の流れについては
、ちょっと古いけど「&lt;a href=&#34;https://spring.io/blog/2014/07/24/spring-framework-4-1-handling-static-web-resources&#34;&gt;handling static web resources&lt;/a&gt;」という記事が分かりやすい。
要は、URLに指定されたパスからサーバ上のリソースを探し当てる&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/ResourceResolver.html&#34;&gt;&lt;code&gt;ResourceResolver&lt;/code&gt;&lt;/a&gt;というものが優先度順に連なっているリゾルバチェイン(&lt;a href=&#34;http://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/ResourceResolverChain.html&#34;&gt;&lt;code&gt;ResourceResolverChain&lt;/code&gt;&lt;/a&gt;)があって、まずこいつがリソースを取得する。
次に、そのリソースを加工するトランスフォーマチェイン(&lt;a href=&#34;http://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/ResourceTransformerChain.html&#34;&gt;&lt;code&gt;ResourceTransformerChain&lt;/code&gt;&lt;/a&gt;)というものに通し、その結果をクライアントに返す。
トランスフォーマチェインは&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/ResourceTransformer.html&#34;&gt;&lt;code&gt;ResourceTransformer&lt;/code&gt;&lt;/a&gt;が連なったもの。
リゾルバチェインとトランスフォーマチェインは上記&lt;code&gt;ResourceHttpRequestHandler&lt;/code&gt;に設定される。&lt;/p&gt;

&lt;p&gt;リゾルバには以下の様なものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/PathResourceResolver.html&#34;&gt;&lt;code&gt;PathResourceResolver&lt;/code&gt;&lt;/a&gt;: &lt;code&gt;ResourceHttpRequestHandler&lt;/code&gt;に設定されたリソースロケーションからリソースを単純に検索するリゾルバ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/CachingResourceResolver.html&#34;&gt;&lt;code&gt;CachingResourceResolver&lt;/code&gt;&lt;/a&gt;: キャッシュからリソースを検索するリゾルバ。テンプレートエンジンの処理結果のキャッシュとかが返るのは多分ここから。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/GzipResourceResolver.html&#34;&gt;&lt;code&gt;GzipResourceResolver&lt;/code&gt;&lt;/a&gt;: &lt;a href=&#34;https://ja.wikipedia.org/wiki/Gzip&#34;&gt;gzip&lt;/a&gt;で圧縮されたリソース、つまりURLで指定されたパスに&lt;code&gt;.gz&lt;/code&gt;という拡張子を付けたリソースを検索するリゾルバ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/VersionResourceResolver.html&#34;&gt;&lt;code&gt;VersionResourceResolver&lt;/code&gt;&lt;/a&gt;: &lt;a href=&#34;https://spring.io/blog/2014/07/24/spring-framework-4-1-handling-static-web-resources#resource-versioning&#34;&gt;リソースバージョニング&lt;/a&gt;を実現するためのリゾルバ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/WebJarsResourceResolver.html&#34;&gt;&lt;code&gt;WebJarsResourceResolver&lt;/code&gt;&lt;/a&gt;: &lt;a href=&#34;http://www.webjars.org/&#34;&gt;WebJars&lt;/a&gt;のjarファイル内のリソースを検索するリゾルバ。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;リゾルバの設定などについてはQiitaの&lt;a href=&#34;http://qiita.com/kazuki43zoo/items/e12a72d4ac4de418ee37&#34;&gt;この記事&lt;/a&gt;ががよくまとまっている。
凝ったことをしたいときは参照しよう。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;トランスフォーマには以下の様なものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/CssLinkResourceTransformer.html&#34;&gt;&lt;code&gt;CssLinkResourceTransformer&lt;/code&gt;&lt;/a&gt;: CSSファイル内のリンクをクライアントがアクセスできるURLに変換する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/CachingResourceTransformer.html&#34;&gt;&lt;code&gt;CachingResourceTransformer&lt;/code&gt;&lt;/a&gt;: 変換したリソースをキャッシュする。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/AppCacheManifestTransformer.html&#34;&gt;&lt;code&gt;AppCacheManifestTransformer&lt;/code&gt;&lt;/a&gt;: HTML5のAppCacheマニフェスト内のリソースを扱うトランスフォーマ。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;デフォルトで&lt;code&gt;ResourceHttpRequestHandler&lt;/code&gt;には&lt;code&gt;PathResourceResolver&lt;/code&gt;だけが設定されている。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上をまとめると、クライアントからGetリクエストが来ると、&lt;code&gt;WebMvcAutoConfiguration&lt;/code&gt;が設定したリソースロケーション(e.g. &lt;code&gt;/static/&lt;/code&gt;)を&lt;code&gt;PathResourceResolver&lt;/code&gt;が検索して、そこに置いてあるHTMLファイルとかをクライアントに返してくれる、ということであろう。&lt;/p&gt;

&lt;p&gt;Javaのコードを全く書かなくていいので楽。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Javaのコードを書いて静的リソースファイルを明示することもできる。
&lt;a href=&#34;http://qiita.com/tag1216/items/3680b92cf96eb5a170f0&#34;&gt;Qiitaの記事&lt;/a&gt;によれば、&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Controller.html&#34;&gt;&lt;code&gt;@Controller&lt;/code&gt;&lt;/a&gt;を付けたクラスのリクエストハンドラで以下の様にファイルへのパスを返せばいいらしい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@RequestMapping(&amp;quot;/hoge&amp;quot;)
public String hoge() {
    return &amp;quot;/hoge.html&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;単純な静的リソースに対してこれをやるユースケースはあまりなさそう。
テンプレートエンジンを使っていてパラメータを渡したいときにはこういうリクエストハンドラを書くことになる。&lt;/p&gt;

&lt;h1 id=&#34;spring-bootのウェルカムページとファビコン&#34;&gt;Spring Bootのウェルカムページとファビコン&lt;/h1&gt;

&lt;p&gt;Spring Bootは&lt;code&gt;index.html&lt;/code&gt;と&lt;code&gt;favicon.ico&lt;/code&gt;という名のファイルを特別扱いする。
前者がウェルカムページで後者がファビコン。&lt;/p&gt;

&lt;h4 id=&#34;ウェルカムページ&#34;&gt;ウェルカムページ&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/htmlsingle/#boot-features-spring-mvc-static-content&#34;&gt;Spring Bootのリファレンスガイド&lt;/a&gt;にもちらっとかいてあるけど、リソースロケーションに&lt;code&gt;index.html&lt;/code&gt;というファイルを置いておくと、それがウェルカムページとして設定され、URLのパスにルート(e.g. &lt;code&gt;http://localhost:8080/&lt;/code&gt;)を指定したときにクライアントに返るようになる。&lt;/p&gt;

&lt;p&gt;ソースを見ると、上記&lt;code&gt;WebMvcAutoConfiguration&lt;/code&gt;の&lt;a href=&#34;https://github.com/spring-projects/spring-boot/blob/v1.4.3.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/WebMvcAutoConfiguration.java#L297&#34;&gt;ここ&lt;/a&gt;でそのための設定している。
&lt;code&gt;/META-INF/resources/index.html&lt;/code&gt;、&lt;code&gt;/resources/index.html&lt;/code&gt;、&lt;code&gt;/static/index.html&lt;/code&gt;、&lt;code&gt;/public/index.html&lt;/code&gt;の順に探すようで、複数個所に&lt;code&gt;index.html&lt;/code&gt;を置いた場合は最初に見つかったものがウェルカムページになる。(そんなことする意味はないが。)&lt;/p&gt;

&lt;h4 id=&#34;ファビコン&#34;&gt;ファビコン&lt;/h4&gt;

&lt;p&gt;ファビコンについてはSpring Bootの現時点でリリース済みバージョンのリファレンスガイドにはほとんど情報がないが、&lt;code&gt;1.5.0.BUILD-SNAPSHOT&lt;/code&gt;のリファレンスガイドには以下の様に書いてある。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;27.1.6 Custom Favicon&lt;/p&gt;

&lt;p&gt;Spring Boot looks for a favicon.ico in the configured static content locations and the root of &amp;gt; the classpath (in that order). If such file is present, it is automatically used as the favicon &amp;gt; of the application.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;つまり、リソースロケーションかクラスパスのルートに&lt;code&gt;favicon.ico&lt;/code&gt;というファイルを置いておくと、それをファビコンとしてクライアントに返してくれる。&lt;/p&gt;

&lt;p&gt;これもやっぱり&lt;code&gt;WebMvcAutoConfiguration&lt;/code&gt;が&lt;a href=&#34;https://github.com/spring-projects/spring-boot/blob/v1.4.3.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/WebMvcAutoConfiguration.java#L319&#34;&gt;設定する&lt;/a&gt;。&lt;/p&gt;

&lt;h1 id=&#34;goslingsの静的リソース&#34;&gt;Goslingsの静的リソース&lt;/h1&gt;

&lt;p&gt;Goslingsの静的リソースは&lt;code&gt;favicon.ico&lt;/code&gt;以外は&lt;code&gt;/static/&lt;/code&gt;に全部直接置くことにした。
&lt;code&gt;favicon.ico&lt;/code&gt;はクラスパスのルートに。
プロジェクトのソースツリーで言うと、&lt;code&gt;src/main/resources/static/&lt;/code&gt;に&lt;code&gt;index.html&lt;/code&gt;やら&lt;code&gt;goslings.css&lt;/code&gt;やらのクライアントファイルを置いて、あとは&lt;code&gt;src/main/resources/favicon.ico&lt;/code&gt;があるという形。
こうしておけば、GradleのJavaプラグインの&lt;code&gt;processResources&lt;/code&gt;タスクによってjar内の適切な場所に取り込まれる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;index.html&lt;/code&gt;には&lt;code&gt;http://&amp;lt;Goslingsサーバ&amp;gt;/&lt;/code&gt;でアクセスできるし、&lt;code&gt;goslings.css&lt;/code&gt;も&lt;code&gt;index.html&lt;/code&gt;に&lt;code&gt;&amp;lt;link rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;goslings.css&amp;quot;&amp;gt;&lt;/code&gt;みたいに書けば取得できる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今日はここまで。
次回からはクライアントサイドの話。&lt;/p&gt;

&lt;p&gt;と思ったけど、たいして書くことないのでこれで終わりにする。
&lt;a href=&#34;http://qiita.com/kaitoy/items/91585ba1a3081ffd2111&#34;&gt;Qiita&lt;/a&gt;のほうにちょっと書いたし。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goslings開発メモ - その4: Spring Boot続続続編 (ロギング)</title>
          <link>https://www.kaitoy.xyz/2017/01/17/goslings-development-memo4-spring-boot-logging/</link>
          <pubDate>Tue, 17 Jan 2017 00:15:25 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/01/17/goslings-development-memo4-spring-boot-logging/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/13/goslings-development-memo3-spring-boot-exception/&#34;&gt;Goslings開発メモ - その3: Spring Boot続続編 (例外処理)&lt;/a&gt;」の続き。&lt;/p&gt;

&lt;p&gt;Spring Boot続続続編で、ロギングについて。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;spring-bootアプリにおけるロギング&#34;&gt;Spring Bootアプリにおけるロギング&lt;/h1&gt;

&lt;p&gt;Spring Bootアプリにおけるロギングについては公式の&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/boot-features-logging.html&#34;&gt;マニュアル&lt;/a&gt;と&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/howto-logging.html&#34;&gt;How-toガイド&lt;/a&gt;を読むべし。
この記事にはこれらの内容をまとめておく。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Spring Bootは内部でのロギングにApacheの&lt;a href=&#34;https://commons.apache.org/proper/commons-logging/&#34;&gt;Commons Logging&lt;/a&gt;を使っている。&lt;/p&gt;

&lt;p&gt;Commons Loggingはファサードライブラリだ。
つまり、Commons LoggingはロギングAPIだけをアプリケーションに提供し、実際のログ出力処理をするロギング実装ライブラリへの橋渡しとして機能する。
ロギング実装ライブラリには色々な選択肢があるが、Spring Bootは&lt;a href=&#34;https://docs.oracle.com/javase/jp/8/docs/api/java/util/logging/package-summary.html&#34;&gt;JUL&lt;/a&gt;、 &lt;a href=&#34;http://logging.apache.org/log4j/2.x/&#34;&gt;Log4j 2&lt;/a&gt;、&lt;a href=&#34;http://logback.qos.ch/&#34;&gt;Logback&lt;/a&gt;用のデフォルト設定を備えているので、これらのいずれかを使うのが楽であろう。&lt;/p&gt;

&lt;p&gt;全てのスターターは&lt;code&gt;spring-boot-starter-logging&lt;/code&gt;というロギングスターターに依存していて、これがLogbackを使うので、普通はそのままLogbackを使うことになる。
&lt;code&gt;spring-boot-starter-logging&lt;/code&gt;は、JUL、Commons Logging、Log4j、&lt;a href=&#34;https://www.slf4j.org/&#34;&gt;SLF4J&lt;/a&gt;によるログ出力をLogbackにルーティングするため、アプリ側や他の依存ライブラリがこれらを使っていてもLogbackに一本化できる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;spring-boot-starter-logging&lt;/code&gt;の代わりに&lt;code&gt;spring-boot-starter-log4j2&lt;/code&gt;に依存し、Log4j 2を使う&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/howto-logging.html#howto-configure-log4j-for-logging&#34;&gt;方法もある&lt;/a&gt;が、Goslingsには普通に&lt;code&gt;spring-boot-starter-logging&lt;/code&gt;を使った。&lt;/p&gt;

&lt;p&gt;また、Goslings本体のログ出力には、プレースホルダを使いたかったのでSLF4Jを使った。&lt;/p&gt;

&lt;h1 id=&#34;spring-bootアプリにおけるロギング設定&#34;&gt;Spring Bootアプリにおけるロギング設定&lt;/h1&gt;

&lt;p&gt;Spring Bootが備えているデフォルトのロギング設定は、&lt;code&gt;ERROR&lt;/code&gt;、&lt;code&gt;WARN&lt;/code&gt;、&lt;code&gt;INFO&lt;/code&gt;レベルのログをいい感じにフォーマットしてコンソールに吐くというものになっている。&lt;/p&gt;

&lt;p&gt;以下この設定の変更方法などを書く。&lt;/p&gt;

&lt;h4 id=&#34;ファイルへのログ出力&#34;&gt;ファイルへのログ出力&lt;/h4&gt;

&lt;p&gt;ログをファイルにも吐くようにするには、&lt;code&gt;logging.file&lt;/code&gt;というプロパティでファイルパスを指定するか、&lt;code&gt;logging.path&lt;/code&gt;というプロパティでディレクトリパスを指定すればいい。
(後者の場合ログファイル名は&lt;code&gt;spring.log&lt;/code&gt;になる。)&lt;/p&gt;

&lt;p&gt;Spring Bootアプリでプロパティを指定する方法は色々あり(&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/htmlsingle/#boot-features-external-config&#34;&gt;ここ&lt;/a&gt;とか&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/howto-properties-and-configuration.html&#34;&gt;ここ&lt;/a&gt;参照)、大抵は&lt;code&gt;application.properties&lt;/code&gt;で指定するんだろうけど、手軽にコマンドラインで以下の様に指定することもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;java -jar build/libs/goslings-0.0.1.jar --logging.file=build/hoge.log
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ログファイルはデフォルトで10MBでローテーションする。&lt;/p&gt;

&lt;h4 id=&#34;ログレベル&#34;&gt;ログレベル&lt;/h4&gt;

&lt;p&gt;ログレベルには重大度の低い方から&lt;code&gt;TRACE&lt;/code&gt;、&lt;code&gt;DEBUG&lt;/code&gt;、&lt;code&gt;INFO&lt;/code&gt;、&lt;code&gt;WARN&lt;/code&gt;、&lt;code&gt;ERROR&lt;/code&gt;、&lt;code&gt;FATAL&lt;/code&gt;の6段階があり、指定したログレベル以上のログが出力される。(&lt;code&gt;OFF&lt;/code&gt;というログ出力を止めるものもある。)
つまりSpring Bootのデフォルトのログレベルは&lt;code&gt;INFO&lt;/code&gt;だということだ。(Logbackには&lt;code&gt;FATAL&lt;/code&gt;がなく&lt;code&gt;ERROR&lt;/code&gt;として出力される。)&lt;/p&gt;

&lt;p&gt;ログレベルは&lt;code&gt;logging.level.&amp;lt;ロガー名&amp;gt;&lt;/code&gt;という形式のプロパティで指定できる。
例えばコマンドラインから指定するなら以下の感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;java -jar build/libs/goslings-0.0.1.jar --logging.level.org.springframework.web=DEBUG
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;全ロガーのログレベルは&lt;code&gt;logging.level.root&lt;/code&gt;で指定できる。&lt;/p&gt;

&lt;h4 id=&#34;ロギング実装ライブラリの設定&#34;&gt;ロギング実装ライブラリの設定&lt;/h4&gt;

&lt;p&gt;ロギング実装ライブラリの設定ファイルをカスタマイズして、より詳細な設定をすることもできる。&lt;/p&gt;

&lt;p&gt;Logbackの場合、クラスパスのルートに置かれた&lt;code&gt;logback-spring.xml&lt;/code&gt;か&lt;code&gt;logback.xml&lt;/code&gt;がロードされる。
設定ファイルの二重初期化を防いだり&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/boot-features-logging.html#boot-features-logback-extensions&#34;&gt;Spring Boot拡張設定&lt;/a&gt;を利用可能にするために、前者のファイル名が推奨されている。
(Groovyが使える環境なら&lt;code&gt;logback-spring.groovy&lt;/code&gt;でもいい。)&lt;/p&gt;

&lt;p&gt;いつものようにjavaコマンドでアプリを起動する場合は&lt;code&gt;-jar&lt;/code&gt;オプションを使うため、&lt;code&gt;-cp&lt;/code&gt;オプションでクラスパスを指定しても無視されてしまうので、基本は&lt;code&gt;logback-spring.xml&lt;/code&gt;はjarの中に入れることになる。
プロジェクトのリソースディレクトリのトップ(デフォルトでは&lt;code&gt;src/main/resources/&lt;/code&gt;)に&lt;code&gt;logback-spring.xml&lt;/code&gt;を置いておけば、GradleのJavaプラグインの&lt;code&gt;processResources&lt;/code&gt;タスクによってjar内の適切な場所に取り込まれる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;logging.config&lt;/code&gt;プロパティで設定ファイルのパスを指定することもできる。
例えばコマンドラインから指定するなら以下の感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;java -jar build/libs/goslings-0.0.1.jar --logging.config=logback-spring.xml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;logback-spring.xml&lt;/code&gt;の中身は、例えば以下の様に書くとコンソール出力をなくしてファイル出力だけにできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;configuration&amp;gt;
  &amp;lt;include resource=&amp;quot;org/springframework/boot/logging/logback/defaults.xml&amp;quot; /&amp;gt;
  &amp;lt;property name=&amp;quot;LOG_FILE&amp;quot; value=&amp;quot;${LOG_FILE:-${LOG_PATH:-${LOG_TEMP:-${java.io.tmpdir:-/tmp}}/}spring.log}&amp;quot;/&amp;gt;
  &amp;lt;include resource=&amp;quot;org/springframework/boot/logging/logback/file-appender.xml&amp;quot; /&amp;gt;
  &amp;lt;root level=&amp;quot;INFO&amp;quot;&amp;gt;
    &amp;lt;appender-ref ref=&amp;quot;FILE&amp;quot; /&amp;gt;
  &amp;lt;/root&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここで注目すべきは2点。&lt;/p&gt;

&lt;p&gt;まずは&lt;code&gt;include&lt;/code&gt;している&lt;code&gt;defaults.xml&lt;/code&gt;と&lt;code&gt;file-appender.xml&lt;/code&gt;だ。
これらはSpring Bootのコアライブラリである&lt;code&gt;spring-boot.jar&lt;/code&gt;に含まれるファイル。
&lt;code&gt;spring-boot.jar&lt;/code&gt;には他にも&lt;code&gt;base.xml&lt;/code&gt;と&lt;code&gt;console-appender.xml&lt;/code&gt;が含まれている。
これらは、前節までに書いたSpring Bootのロギング挙動を実現している設定ファイルなので、これらを&lt;code&gt;include&lt;/code&gt;して利用すれば自分のカスタム設定ファイルが簡単に書ける。&lt;/p&gt;

&lt;p&gt;もう一点は&lt;code&gt;LOG_FILE&lt;/code&gt;といったプロパティ。
これらはSpring Bootが設定してくれるプロパティで、詳細は&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/boot-features-logging.html#boot-features-custom-log-configuration&#34;&gt;ここ&lt;/a&gt;に。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今日はここまで。
&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/24/goslings-development-memo5-spring-boot-static-resources/&#34;&gt;次回&lt;/a&gt;もまたSpring Bootで、静的リソース処理について。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goslings開発メモ - その3: Spring Boot続続編 (例外処理)</title>
          <link>https://www.kaitoy.xyz/2017/01/13/goslings-development-memo3-spring-boot-exception/</link>
          <pubDate>Fri, 13 Jan 2017 14:01:01 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/01/13/goslings-development-memo3-spring-boot-exception/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/10/goslings-development-memo2-spring-boot-di/&#34;&gt;Goslings開発メモ - その2: Spring Boot続編 (DI)&lt;/a&gt;」の続き。&lt;/p&gt;

&lt;p&gt;Spring Boot続続編で、例外処理について。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;spring-mvcアプリにおける例外処理&#34;&gt;Spring MVCアプリにおける例外処理&lt;/h1&gt;

&lt;p&gt;Goslingsは&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/&#34;&gt;前々回&lt;/a&gt;書いたように&lt;code&gt;spring-boot-starter-web&lt;/code&gt;というスターターを使っていて、つまりSpring MVCアプリだ。&lt;/p&gt;

&lt;p&gt;Spring MVCアプリにおける例外処理についてはちょっと古いが&lt;a href=&#34;https://spring.io/blog/2013/11/01/exception-handling-in-spring-mvc&#34;&gt;この記事&lt;/a&gt;に詳しい。&lt;/p&gt;

&lt;p&gt;まず、Goslingsの構成で例外処理を何も書かなかった場合、コントローラのリクエストハンドラから例外が投げられると、ログにスタックトレースが出力され、クライアントにはHTTPステータスコード&lt;code&gt;500 (Internal Server Error)&lt;/code&gt;とともに以下の様なデフォルトのエラーページが返る。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-development-memo3-spring-boot-exception/err_page.png&#34; alt=&#34;err_page.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;なんだかこれでも十分な気がするが、実際にはちゃんと明示的に例外処理をしたほうがいいだろう。
エラー時に返すHTTPステータスコードをカスタマイズしたり、遷移するページを変えたりしたくなるだろうから。&lt;/p&gt;

&lt;p&gt;記事によれば、リクエストハンドラ内で例外をキャッチして処理するのはイケてなくて、関心事の分離のために別の場所に処理を書くのが良いらしい。&lt;/p&gt;

&lt;p&gt;Spring MVCアプリにおける例外処理には以下の3つの段階がある。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;投げる例外をカスタマイズする&lt;/li&gt;
&lt;li&gt;例外クラス毎の例外ハンドラをコントローラに実装する&lt;/li&gt;
&lt;li&gt;コントローラ間で共用する例外ハンドラクラスを作る&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;以下それぞれについて書く。&lt;/p&gt;

&lt;h4 id=&#34;1-投げる例外をカスタマイズする&#34;&gt;1. 投げる例外をカスタマイズする&lt;/h4&gt;

&lt;p&gt;リクエストハンドラから投げる例外に&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/ResponseStatus.html&#34;&gt;&lt;code&gt;@ResponseStatus&lt;/code&gt;&lt;/a&gt;をつけることで、クライアントに返すHTTPステータスコード(とリーズンフレーズ)をカスタマイズできる。&lt;/p&gt;

&lt;p&gt;例えば以下のような例外を投げると、HTTPステータスコード&lt;code&gt;500 (Internal Server Error)&lt;/code&gt;の代わりに&lt;code&gt;400 (Bad Request)&lt;/code&gt;がクライアントに返る。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@ResponseStatus(HttpStatus.BAD_REQUEST)
public final class BadRequestException extends RuntimeException {
  // 省略
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;2-例外クラス毎の例外ハンドラをコントローラに実装する&#34;&gt;2. 例外クラス毎の例外ハンドラをコントローラに実装する&lt;/h4&gt;

&lt;p&gt;コントローラのメソッドに&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/ExceptionHandler.html&#34;&gt;&lt;code&gt;@ExceptionHandler&lt;/code&gt;&lt;/a&gt;をつけてやると、そのメソッドは例外ハンドラになり、そのコントローラのリクエストハンドラから特定の例外が投げられたときの処理を書くことができる。
さらに例外ハンドラに&lt;code&gt;@ResponseStatus&lt;/code&gt;をつければ、HTTPステータスコードをカスタマイズできる。
例外ハンドラの戻り値はリクエストハンドラのと同様に処理されるので、遷移するページ等も自由にカスタマイズできる。&lt;/p&gt;

&lt;p&gt;Goslingsでは、上記&lt;code&gt;BadRequestException&lt;/code&gt;からは&lt;code&gt;@ResponseStatus&lt;/code&gt;を削除したうえで、&lt;code&gt;RestApiV1Controller&lt;/code&gt;に以下の様に例外ハンドラを書いた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public final class RestApiV1Controller {

  // 例外ハンドラ
  @ResponseStatus(HttpStatus.BAD_REQUEST)
  @ExceptionHandler(BadRequestException.class)
  ErrorInfo handleBadRequestException(HttpServletRequest req, Exception ex) {
    return new ErrorInfo(req.getRequestURL().toString(), ex);
  }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(RestApiV1Controller.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/controller/RestApiV1Controller.java&#34;&gt;こちら&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;こう書くと、&lt;code&gt;RestApiV1Controller&lt;/code&gt;の任意のリクエストハンドラから&lt;code&gt;BadRequestException&lt;/code&gt;が投げられると、&lt;code&gt;handleBadRequestException&lt;/code&gt;が呼び出され、HTTPステータスコード&lt;code&gt;400 (Bad Request)&lt;/code&gt;とともにクライアントにHTTPレスポンスが返る。
&lt;code&gt;RestApiV1Controller&lt;/code&gt;はREST APIコントローラなので、このHTTPレスポンスのボディは、&lt;code&gt;handleBadRequestException&lt;/code&gt;の戻り値である&lt;code&gt;ErrorInfo&lt;/code&gt;オブジェクトをJSONに変換したものになる。&lt;/p&gt;

&lt;p&gt;例外ハンドラの仮引数は、上のコードに書いたもののほか、サーブレット関係のクラスなど(e.g. &lt;code&gt;HttpServletResponse&lt;/code&gt;や&lt;code&gt;HttpSession&lt;/code&gt;。詳しくは&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/ExceptionHandler.html&#34;&gt;Javadoc&lt;/a&gt;参照)を適当に書いておくとSpring MVCがよしなに渡してくれる。&lt;/p&gt;

&lt;p&gt;冒頭に貼った記事には例外ハンドラは&lt;code&gt;Model&lt;/code&gt;を受け取れないとあるが、これは古い情報で、今は受け取れるっぽい。&lt;/p&gt;

&lt;h4 id=&#34;3-コントローラ間で共用する例外ハンドラクラスを作る&#34;&gt;3. コントローラ間で共用する例外ハンドラクラスを作る&lt;/h4&gt;

&lt;p&gt;コントローラから例外処理を完全に分離したい場合や、複数のコントローラで例外ハンドラを共有したい場合は、コントローラアドバイスクラスを書けばいい。&lt;/p&gt;

&lt;p&gt;コントローラアドバイスクラスは&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/ControllerAdvice.html&#34;&gt;&lt;code&gt;@ControllerAdvice&lt;/code&gt;&lt;/a&gt;を付けて定義したクラスで、このクラスに例外ハンドラを書いておくと複数のコントローラで有効になる。&lt;/p&gt;

&lt;p&gt;コントローラアドバイスクラスには例外ハンドラ以外も書ける。
コントローラアドバイスクラスが適用されるのはデフォルトでは全てのコントローラクラスだが、&lt;code&gt;@ControllerAdvice&lt;/code&gt;の値により適用範囲を絞ることもできる。
詳しくは&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/ControllerAdvice.html&#34;&gt;Javadoc&lt;/a&gt;参照。&lt;/p&gt;

&lt;p&gt;Goslingsではコントローラアドバイスクラスは作らなかった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今日はここまで。
&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/17/goslings-development-memo4-spring-boot-logging/&#34;&gt;次回&lt;/a&gt;もまたSpring Bootで、ロギングについて。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goslings開発メモ - その2: Spring Boot続編 (DI)</title>
          <link>https://www.kaitoy.xyz/2017/01/10/goslings-development-memo2-spring-boot-di/</link>
          <pubDate>Tue, 10 Jan 2017 00:21:27 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/01/10/goslings-development-memo2-spring-boot-di/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/&#34;&gt;Goslings開発メモ - その1: Spring Boot編&lt;/a&gt;」の続き。&lt;/p&gt;

&lt;p&gt;Spring Boot続編で、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E4%BE%9D%E5%AD%98%E6%80%A7%E3%81%AE%E6%B3%A8%E5%85%A5&#34;&gt;DI&lt;/a&gt;について。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;diとは&#34;&gt;DIとは&lt;/h1&gt;

&lt;p&gt;DIはDependency Injectionの略。依存性注入と訳される。&lt;/p&gt;

&lt;p&gt;これは、Javaの文脈で具体的目に言うと、あるクラスが依存する具象クラスのインスタンス化と取得をフレームワークに任せることで、具象クラス間の直接的な依存を排除し、よってコンポーネント間を疎結合にする手法。
これにより、アプリの拡張性を高めたり、テストがしやすくなったりする。(&lt;a href=&#34;http://qiita.com/mizunowanko/items/53eed059fc044c5aa5dc&#34;&gt;参考記事&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://projects.spring.io/spring-framework/&#34;&gt;Spring Framework&lt;/a&gt;はもともとこのDI機能を提供するフレームワーク(i.e. DIコンテナ)として普及した。&lt;/p&gt;

&lt;h1 id=&#34;goslingsでdi&#34;&gt;GoslingsでDI&lt;/h1&gt;

&lt;p&gt;Goslingsサーバの内部機能はざっくり、クライアントからのREST API呼び出しを処理するユーザインタフェース層と、Gitリポジトリにアクセスするデータベース層に分かれる。&lt;/p&gt;

&lt;p&gt;Gitリポジトリにアクセスする部分は今回は&lt;a href=&#34;https://eclipse.org/jgit/&#34;&gt;JGit&lt;/a&gt;で実装するが、将来的に別のライブラリで実装しなおす可能性が微レ存なのと、Goslingsの開発自体がWebアプリ開発の練習でもあるので、ちゃんとしたアーキテクチャでと思い、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Data_Access_Object&#34;&gt;DAO&lt;/a&gt;パターンを使ってやった。&lt;/p&gt;

&lt;p&gt;つまり例えば、GitのコミットオブジェクトはJGitのAPIでは&lt;a href=&#34;http://download.eclipse.org/jgit/site/3.7.1.201504261725-r/apidocs/org/eclipse/jgit/revwalk/RevCommit.html&#34;&gt;&lt;code&gt;RevCommitクラス&lt;/code&gt;&lt;/a&gt;で表されるが、ユーザインタフェース層からはリソースクラスである&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/resource/Commit.java&#34;&gt;Commitクラス&lt;/a&gt;(&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/#5-%E3%83%AA%E3%82%BD%E3%83%BC%E3%82%B9%E3%82%AF%E3%83%A9%E3%82%B9%E4%BD%9C%E6%88%90&#34;&gt;前回&lt;/a&gt;参照)を扱う以下の様なDAOインターフェースを呼ぶようにし、JGit依存の実装とは切り離す。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public interface ObjectDao {

  public Commit[] getCommits(String token) throws DaoException;

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(ObjectDao.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/dao/ObjectDao.java&#34;&gt;これ&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ObjectDao&lt;/code&gt;を実装する&lt;code&gt;ObjectDaoImpl&lt;/code&gt;クラスでは、以下の様にJGitを使ってごりごりと実装を書く。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public final class ObjectDaoImpl implements ObjectDao {

  // フィールド定義は省略

  @Override
  public Commit[] getCommits(String token) {
    try {
      return StreamSupport.stream(resolver.getGit(token).log().all().call().spliterator(), false)
               .map(this::convertToCommit)
               .toArray(Commit[]::new);
    } catch (NoHeadException e) {
      // エラー処理
    }
  }

  private Commit convertToCommit(RevCommit commit) {
    // RevCommitをCommitに変換する処理
  }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ユーザインターフェース層は&lt;code&gt;RestApiV1Controller&lt;/code&gt;クラス(&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/#6-%E3%82%B3%E3%83%B3%E3%83%88%E3%83%AD%E3%83%BC%E3%83%A9-rest-api%E3%82%B3%E3%83%B3%E3%83%88%E3%83%AD%E3%83%BC%E3%83%A9-%E4%BD%9C%E6%88%90&#34;&gt;前回&lt;/a&gt;参照)の&lt;code&gt;getCommits&lt;/code&gt;メソッドで、以下の様にObjectDaoを使いたい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public final class RestApiV1Controller {

  private ObjectDao objectDao;

  @RequestMapping(path=&amp;quot;{token}/objects/commits&amp;quot;)
  public Commit[] getCommits(@PathVariable String token) {
    return objectDao.getCommits(token);
  }

  // 以下他のメソッド

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ここで問題になるのが、&lt;code&gt;RestApiV1Controller&lt;/code&gt;の&lt;code&gt;objectDao&lt;/code&gt;フィールドへのインスタンスの代入だが、&lt;code&gt;RestApiV1Controller&lt;/code&gt;内(e.g. &lt;code&gt;RestApiV1Controller&lt;/code&gt;のコンストラクタ)で&lt;code&gt;ObjectDaoImpl&lt;/code&gt;をインスタンス化して代入するのでは、&lt;code&gt;ObjectDaoImpl&lt;/code&gt;というデータベース層の具象クラスへの直接的な依存(i.e. &lt;code&gt;import ObjectDaoImpl&lt;/code&gt;)が発生してしまってまずい。
ユーザインターフェース層とデータベース層が密に結合してしまう。&lt;/p&gt;

&lt;p&gt;ここがDIの使いどころだ。
&lt;code&gt;RestApiV1Controller&lt;/code&gt;への&lt;code&gt;ObjectDaoImpl&lt;/code&gt;インスタンスの注入をフレームワークに任せればいい。&lt;/p&gt;

&lt;h1 id=&#34;spring-bootでのdi&#34;&gt;Spring BootでのDI&lt;/h1&gt;

&lt;p&gt;Spring Bootアプリでは&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/spring-framework-reference/html/beans.html&#34;&gt;Spring FrameworkのDI機能&lt;/a&gt;を何でも使えるが、普通、もっとも簡単な方法である&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/context/annotation/ComponentScan.html&#34;&gt;&lt;code&gt;@ComponentScan&lt;/code&gt;&lt;/a&gt;と&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/spring-framework-reference/html/beans.html#beans-autowired-annotation&#34;&gt;&lt;code&gt;@Autowired&lt;/code&gt;&lt;/a&gt;を使う方法を採る。&lt;/p&gt;

&lt;p&gt;まずは&lt;code&gt;@ComponentScan&lt;/code&gt;だが、これは、&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/#7-%E3%83%A1%E3%82%A4%E3%83%B3%E3%82%AF%E3%83%A9%E3%82%B9%E4%BD%9C%E6%88%90&#34;&gt;前回&lt;/a&gt;書いたように既に使っていて、プロジェクト内の全てのSpring Beanが検索されDIコンテナに登録されるようになっている。
なので、注入したい&lt;code&gt;ObjectDaoImpl&lt;/code&gt;がSpring Beanと判定されるようにすればよい。&lt;/p&gt;

&lt;p&gt;そのためには、&lt;code&gt;ObjectDaoImpl&lt;/code&gt;に以下のアノテーションのいずれかを付ける必要がある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Service.html&#34;&gt;&lt;code&gt;@Service&lt;/code&gt;&lt;/a&gt;: 業務手続を表すAPIを提供する(しばしば状態を持たない)コンポーネント。またはそれっぽいもの。MVCアーキテクチャのM(モデル)や、3層アーキテクチャのビジネスロジック層のコンポーネント。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Repository.html&#34;&gt;&lt;code&gt;@Repository&lt;/code&gt;&lt;/a&gt;: データの保持、取得、検索といった振る舞いを持つ、オブジェクトコレクションを表すコンポーネント。またはそれっぽいもの。MVCアーキテクチャのM(モデル)の内、特にデータベースを扱うコンポーネントや、3層アーキテクチャのデータベース層のコンポーネント。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Controller.html&#34;&gt;&lt;code&gt;@Controller&lt;/code&gt;&lt;/a&gt;: MVCアーキテクチャのC(コントローラ)のコンポーネント。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Component.html&#34;&gt;&lt;code&gt;@Component&lt;/code&gt;&lt;/a&gt;: 一般的なコンポーネント。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(&lt;a href=&#34;http://qiita.com/KevinFQ/items/abc7369cb07eb4b9ae29&#34;&gt;参考記事&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ObjectDaoImpl&lt;/code&gt;はDAOコンポーネントで、これはもちろん&lt;code&gt;@Repository&lt;/code&gt;にあたるのでこれを付ける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Repository
public final class ObjectDaoImpl implements ObjectDao {
  // 省略
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで&lt;code&gt;ObjectDaoImpl&lt;/code&gt;がSpring Beanとして登録されるので、あとは&lt;code&gt;RestApiV1Controller&lt;/code&gt;に&lt;code&gt;@Autowired&lt;/code&gt;で注入してやればいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public final class RestApiV1Controller {

  @Autowired
  private ObjectDao objectDao;

  // 以下省略。

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;@Autowired&lt;/code&gt;を付けたことにより、&lt;code&gt;RestApiV1Controller&lt;/code&gt;のインスタンス化直後に、&lt;code&gt;objectDao&lt;/code&gt;フィールドに適切なSpring Beanが注入されるようになった。&lt;/p&gt;

&lt;p&gt;注入されるSpring Beanはフィールドの型から判断される。
&lt;code&gt;objectDao&lt;/code&gt;フィールドの型は&lt;code&gt;ObjectDao&lt;/code&gt;で、この実装はプロジェクト内に&lt;code&gt;ObjectDaoImpl&lt;/code&gt;しかないので、狙い通り&lt;code&gt;ObjectDaoImpl&lt;/code&gt;が注入される。
今はこれでもいいが、将来&lt;code&gt;ObjectDao&lt;/code&gt;の実装が増えた場合、どの実装を注入すべきかSpring Frameworkには分からなくなるので、今のうちに&lt;a href=&#34;http://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/beans/factory/annotation/Qualifier.html&#34;&gt;&lt;code&gt;@Qualifier&lt;/code&gt;&lt;/a&gt;を使って明示しておくことにする。(&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/spring-framework-reference/html/beans.html#beans-autowired-annotation-qualifiers&#34;&gt;参考&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;まずSpring Beanの方に&lt;code&gt;jgit&lt;/code&gt;という値を持つ&lt;code&gt;@Qualifier&lt;/code&gt;をつける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Repository
@Qualifier(&amp;quot;jgit&amp;quot;)
public final class ObjectDaoImpl implements ObjectDao {
  // 省略
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(ObjectDaoImpl.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/dao/jgit/ObjectDaoImpl.java&#34;&gt;これ&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Spring Beanを使う側にも同じ&lt;code&gt;@Qualifier&lt;/code&gt;をつける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public final class RestApiV1Controller {

  @Autowired
  @Qualifier(&amp;quot;jgit&amp;quot;)
  private ObjectDao objectDao;

  // 以下省略。

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(RestApiV1Controller.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/controller/RestApiV1Controller.java&#34;&gt;こちら&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで&lt;code&gt;RestApiV1Controller&lt;/code&gt;の&lt;code&gt;objectDao&lt;/code&gt;フィールドにどの&lt;code&gt;ObjectDao&lt;/code&gt;実装が注入されるかがより明確になった。
将来&lt;code&gt;ObjectDao&lt;/code&gt;の別の実装を作るときには、その実装クラスには別の値の&lt;code&gt;@Qualifier&lt;/code&gt;を付けてやれば、&lt;code&gt;RestApiV1Controller&lt;/code&gt;の方の&lt;code&gt;@Qualifier&lt;/code&gt;の値によって注入する実装を切り替えられる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今日はここまで。
&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/13/goslings-development-memo3-spring-boot-exception/&#34;&gt;次回&lt;/a&gt;もまたSpring Bootで、例外処理について。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goslings開発メモ - その1: Spring Boot編</title>
          <link>https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/</link>
          <pubDate>Tue, 03 Jan 2017 23:36:01 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2016/12/11/goslings-development-memo0-intro-design/&#34;&gt;Goslings開発メモ - その0: 紹介と概要と設計編&lt;/a&gt;」の続き。&lt;/p&gt;

&lt;p&gt;Spring Boot編。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;spring-bootとは&#34;&gt;Spring Bootとは&lt;/h1&gt;

&lt;p&gt;Spring Bootは&lt;a href=&#34;http://projects.spring.io/spring-framework/&#34;&gt;Spring Framework&lt;/a&gt;というJavaのWebアプリケーションフレームワークを簡単に利用するためのツールやライブラリ群。&lt;/p&gt;

&lt;p&gt;これを使うと、Webアプリケーションコンテナ(e.g. &lt;a href=&#34;http://tomcat.apache.org/&#34;&gt;Tomcat&lt;/a&gt;)なしで起動できるSpringアプリケーションを、自動コード生成も設定ファイル作成もせずに作ることができる。
必要な設定は自動で構成され、設定のカスタマイズもアノテーションでできる。&lt;/p&gt;

&lt;p&gt;GAになったのが&lt;a href=&#34;https://www.infoq.com/news/2014/04/spring-boot-goes-ga&#34;&gt;2014年4月&lt;/a&gt;なのでかなり新しいものだが、JavaのWebアプリケーションを作るためのものとしては今世界的に最も流行っているもの。&lt;/p&gt;

&lt;p&gt;私が昔とあるWebアプリを作った時は&lt;a href=&#34;http://projects.spring.io/spring-roo/&#34;&gt;Spring Roo&lt;/a&gt;という&lt;a href=&#34;https://ja.wikipedia.org/wiki/RAD_(%E8%A8%88%E7%AE%97%E6%A9%9F%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%E7%92%B0%E5%A2%83&#34;&gt;RADツール&lt;/a&gt;が熱かったが、これはコード自動生成をして開発を助けてくれるもので、なんだか結局あまり流行らなかったようだ。&lt;/p&gt;

&lt;p&gt;Goslingsには最新バージョンの1.4.3.RELEASEを使った。&lt;/p&gt;

&lt;h1 id=&#34;spring-bootことはじめ&#34;&gt;Spring Bootことはじめ&lt;/h1&gt;

&lt;p&gt;包括的網羅的なドキュメントは「&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/htmlsingle/&#34;&gt;Spring Boot Reference Guide&lt;/a&gt;」だが、今回あまり深く学ぶ時間が取れなかったのでこれはちら見した程度。
それよりも、ユースケースごとのチュートリアルが60個以上も載っている「&lt;a href=&#34;https://spring.io/guides/&#34;&gt;Getting Started Guides&lt;/a&gt;」を参考にした。&lt;/p&gt;

&lt;p&gt;Goslingsサーバは基本REST APIサーバなので、上記チュートリアルの内「&lt;a href=&#34;https://spring.io/guides/gs/rest-service/&#34;&gt;Building a RESTful Web Service&lt;/a&gt;」を見ながら以下を実施した。&lt;/p&gt;

&lt;h4 id=&#34;1-プロジェクト作成&#34;&gt;1. プロジェクト作成&lt;/h4&gt;

&lt;p&gt;チュートリアルにはGradleプロジェクトのディレクトリ構成を手動で作るところから書いてあるけど、そこは&lt;a href=&#34;http://qiita.com/grachro/items/d1ebad3857a794895426&#34;&gt;IDEなどで楽できる&lt;/a&gt;。
私はEclipseを使っていて、いつのまにかGradleプラグインである&lt;a href=&#34;https://projects.eclipse.org/projects/tools.buildship&#34;&gt;Eclipse Buildship: Eclipse Plug-ins for Gradle&lt;/a&gt;と&lt;a href=&#34;https://marketplace.eclipse.org/content/gradle-ide-pack&#34;&gt;Gradle IDE Pack&lt;/a&gt;がインストールされていたので、これらを使った。&lt;/p&gt;

&lt;p&gt;どちらのプラグインでもプロジェクトは作成できるが、&lt;a href=&#34;http://qiita.com/grachro/items/16bba860f9d9fe5ee4c5&#34;&gt;Qiitaのこの記事&lt;/a&gt;にあるとおり、Gradle IDE Pack(に含まれる&lt;a href=&#34;https://github.com/spring-projects/eclipse-integration-gradle/&#34;&gt;Gradle (STS) Integration for Eclipse by Pivotal&lt;/a&gt;)で作った場合、Gradle Wrapperが生成されないなどの問題があるので、Buildshipの方で作成。
ただ、Gradle IDE Packの方がパッケージ・エクスプローラでの見え方がちょっとよかったので、こちらでプロジェクトをインポートしなおした。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-development-memo1-spring-boot/gradle_import.png&#34; alt=&#34;gradle_import.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;(上がBuildshipのやつで、下がGradle IDE Packのやつ)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;出来たプロジェクトは以下の感じ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-development-memo1-spring-boot/project_structure.png&#34; alt=&#34;project_structure.png&#34; /&gt;
&lt;/p&gt;

&lt;h4 id=&#34;2-spring-boot-gradle-plugin適用&#34;&gt;2. Spring Boot Gradle plugin適用&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/build-tool-plugins-gradle-plugin.html&#34;&gt;Spring Boot Gradle plugin&lt;/a&gt;というものがあって、これをプロジェクトに適用すると以下の恩恵を受けられる。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;依存ライブラリ管理機能&lt;/p&gt;

&lt;p&gt;Spring関係のライブラリについて適切なバージョンを設定してくれるので、Gradleビルド設定(i.e. &lt;code&gt;build.gradle&lt;/code&gt;)の&lt;code&gt;dependencies&lt;/code&gt;に自分でバージョンを書かなくていい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;実行可能jar(war)のパッケージング機能&lt;/p&gt;

&lt;p&gt;ビルドされたjar(やwar)を、単独で実行可能になるようにマニフェストやライブラリを詰めて再パッケージングする&lt;code&gt;bootRepackage&lt;/code&gt;というGradleタスクが追加される。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プロジェクトから直接アプリを起動する機能&lt;/p&gt;

&lt;p&gt;jarなどのアーティファクトをビルドせずに、プロジェクトから直接アプリを起動できる&lt;code&gt;bootRun&lt;/code&gt;というGradleタスクが追加される。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;build.gradle&lt;/code&gt;に以下の様に書くとSpring Boot Gradle pluginを適用できる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Gradle 2.1より古いバージョン&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;buildscript {
  repositories {
    mavenCentral()
  }
  dependencies {
    classpath(&#39;org.springframework.boot:spring-boot-gradle-plugin:1.4.3.RELEASE&#39;)
  }
}


apply plugin: &#39;org.springframework.boot&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(&lt;code&gt;apply plugin: &#39;org.springframework.boot&#39;&lt;/code&gt;の部分は、Spring Boot Gradle plugin 1.4.1.RELEASE以前は&lt;code&gt;apply plugin: &#39;spring-boot&#39;&lt;/code&gt;だった。)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Gradle 2.1以降&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;plugins {
  id &#39;org.springframework.boot&#39; version &#39;1.4.3.RELEASE&#39;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;3-依存ライブラリ追加&#34;&gt;3. 依存ライブラリ追加&lt;/h4&gt;

&lt;p&gt;Spring Bootは依存ライブラリの管理も簡易化してくれる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;spring-boot-starter-&lt;/code&gt;で始まる&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/htmlsingle/#using-boot-starter&#34;&gt;スターター&lt;/a&gt;と呼ばれるライブラリがいくつか提供されていて、作りたいアプリの種類や機能に応じたものをプロジェクトの依存ライブラリとして追加すると、推移的に諸々の必要なライブラリが追加されるようになっている。
例えば、&lt;a href=&#34;http://www.thymeleaf.org/&#34;&gt;Thymeleaf&lt;/a&gt;をテンプレートエンジンに使ったWebアプリを作るなら&lt;code&gt;spring-boot-starter-thymeleaf&lt;/code&gt;、&lt;a href=&#34;http://projects.spring.io/spring-data-jpa/&#34;&gt;JPA&lt;/a&gt; (&lt;a href=&#34;http://hibernate.org/orm/&#34;&gt;Hibernate&lt;/a&gt;)でデータベースアクセスしたい場合は&lt;code&gt;spring-boot-starter-data-jpa&lt;/code&gt;を使う。&lt;/p&gt;

&lt;p&gt;Webアプリを作るのに最も一般的なのは&lt;code&gt;spring-boot-starter-web&lt;/code&gt;で、Goslingsにもこれを使った。
これを使うと&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/spring-framework-reference/html/mvc.html&#34;&gt;Spring MVC&lt;/a&gt;でアプリを作ることになる。&lt;/p&gt;

&lt;p&gt;また、&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/htmlsingle/#production-ready&#34;&gt;Spring Boot Actuator&lt;/a&gt;という、アプリをプロダクション環境で運用するための機能を有効にするため、&lt;code&gt;spring-boot-starter-actuator&lt;/code&gt;も使った。
これを有効にすると、Web APIでアプリの状態取得などができるようになる。
例えば、&lt;code&gt;http://&amp;lt;サーバ&amp;gt;/health&lt;/code&gt;にアクセスするとアプリの基本的なヘルス情報がJSONで取得できる。&lt;/p&gt;

&lt;p&gt;これら二つのスターターを追加するには、&lt;code&gt;build.gradle&lt;/code&gt;の&lt;code&gt;dependencies&lt;/code&gt;に以下の様に書くだけでいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;dependencies {
  compile &#39;org.springframework.boot:spring-boot-starter-web&#39;
  compile &#39;org.springframework.boot:spring-boot-starter-actuator&#39;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;前節に書いた通り、Spring Boot Gradle pluginのおかげでバージョンの指定は不要。&lt;/p&gt;

&lt;h4 id=&#34;4-ディベロッパツール追加&#34;&gt;4. ディベロッパツール追加&lt;/h4&gt;

&lt;p&gt;Spring Bootの&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/using-boot-devtools.html&#34;&gt;ディベロッパツール&lt;/a&gt;を利用すると、以下の恩恵を受けられる。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;キャッシュの無効化&lt;/p&gt;

&lt;p&gt;Spring Bootがサポートしているライブラリ(e.g. Thymeleafといったテンプレートエンジン)にはキャッシュ機能を持つものがある。
こうした機能はプロダクション環境では性能改善に有効だが、開発時にはじゃまになる。
ディベロッパツールを使うとデフォルトで様々なキャッシュを無効にしてくれる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;自動再起動&lt;/p&gt;

&lt;p&gt;クラスパスに含まれるファイルに変更があるとアプリが自動で再起動される。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ライブリロード&lt;/p&gt;

&lt;p&gt;ブラウザのアドオンを&lt;a href=&#34;http://livereload.com/extensions/&#34;&gt;インストール&lt;/a&gt;すると、アプリに変更があったらブラウザが自動でリロードしてくれるようになる。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ディベロッパツールを追加するには、&lt;code&gt;build.gradle&lt;/code&gt;の&lt;code&gt;dependencies&lt;/code&gt;に以下の様に書くだけでいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;dependencies {
  compile &#39;org.springframework.boot:spring-boot-devtools&#39;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ディベロッパツールは、アプリがプロダクション環境で起動されたと判定すると自動で無効になるので、アーティファクトに含まれても問題ない。
&lt;code&gt;java -jar&lt;/code&gt;で起動されるか、または通常のものではないクラスローダが起動に使われると、プロダクション環境だと判定される。
&lt;code&gt;build.gradle&lt;/code&gt;に以下の様に書けば、アーティファクトに含まれないようにもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;bootRepackage {
  excludeDevtools = true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ディベロッパツールへの推移的依存を避けるための&lt;a href=&#34;https://github.com/spring-projects/gradle-plugins/tree/master/propdeps-plugin&#34;&gt;propdeps-plugin&lt;/a&gt;というプラグインもあるが、Goslingsは他のアプリが依存するようなものではないので使わなかった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;自動再起動については、Eclipseの自動ビルドはデフォルトで&lt;code&gt;goslings/bin&lt;/code&gt;にクラスファイルを吐くので、ビルドパスの構成で「デフォルト出力フォルダー」を&lt;code&gt;goslings/build/classes/main&lt;/code&gt;に変えないと動かなかった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ここまででベースとなる&lt;code&gt;build.gradle&lt;/code&gt;ができて、以下の様になった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;buildscript {
  repositories {
    mavenCentral()
  }
  dependencies {
    classpath &amp;quot;org.springframework.boot:spring-boot-gradle-plugin:${springBootVer}&amp;quot;
  }
}

repositories {
  mavenCentral()
}

apply plugin: &#39;java&#39;
apply plugin: &#39;org.springframework.boot&#39;

archivesBaseName = &#39;goslings&#39;
version = &#39;0.0.1&#39;

[compileJava, compileTestJava]*.options*.encoding = &#39;UTF-8&#39;
sourceCompatibility = 1.8
targetCompatibility = 1.8

bootRepackage {
  excludeDevtools = true
}

dependencies {
  compile &#39;org.springframework.boot:spring-boot-starter-web&#39;
  compile &#39;org.springframework.boot:spring-boot-starter-actuator&#39;
  compile &#39;org.springframework.boot:spring-boot-devtools&#39;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;5-リソースクラス作成&#34;&gt;5. リソースクラス作成&lt;/h3&gt;

&lt;p&gt;ここからやっとコーディング。
まずはREST APIで取得するリソースを表現するクラスを作る。&lt;/p&gt;

&lt;p&gt;Goslingsの場合、Gitリポジトリのオブジェクトやリファレンスなどがリソースになる。
例えばコミットオブジェクトを表すクラスは以下の様に書いた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public final class Commit {

  private final String id;
  private final String[] parentIds;
  private final String treeId;

  // 以下、全フィールドをセットするコンストラクタとgetters。

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(Commit.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/resource/Commit.java&#34;&gt;これ&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;POJOとして書けばいいので、&lt;a href=&#34;https://projectlombok.org/&#34;&gt;Lombok&lt;/a&gt;の&lt;code&gt;@Data&lt;/code&gt;か&lt;code&gt;@Value&lt;/code&gt;を使うと楽だろうが、Goslingsには使わなかった。&lt;/p&gt;

&lt;h4 id=&#34;6-コントローラ-rest-apiコントローラ-作成&#34;&gt;6. コントローラ(REST APIコントローラ)作成&lt;/h4&gt;

&lt;p&gt;クライアントからのHTTPリクエストを処理するクラスはコントローラクラスと呼ばれる。
クライアントからのREST API呼び出しもHTTPリクエストなのでコントローラクラスで処理する。&lt;/p&gt;

&lt;p&gt;REST API呼び出しを処理するコントローラクラスは、&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/RestController.html&#34;&gt;&lt;code&gt;@RestController&lt;/code&gt;&lt;/a&gt;を付けて宣言して、&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/RequestMapping.html&#34;&gt;&lt;code&gt;@RequestMapping&lt;/code&gt;&lt;/a&gt;を付けたメソッド(リクエストハンドラ)にURL毎の処理を書いてやればいい。&lt;/p&gt;

&lt;p&gt;以下の様な感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@RestController
@RequestMapping(
  path=&amp;quot;/v1&amp;quot;,
  method=RequestMethod.GET
)
public final class RestApiV1Controller {

  // この辺でフィールド定義など

  @RequestMapping(path=&amp;quot;{token}/objects/commits&amp;quot;)
  public Commit[] getCommits(@PathVariable String token) {
    return objectDao.getCommits(token);
  }

  // 以下他のメソッド

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(RestApiV1Controller.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/controller/RestApiV1Controller.java&#34;&gt;こちら&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;上のコードでは、&lt;code&gt;http://&amp;lt;Goslingsサーバ&amp;gt;/v1/&amp;lt;トークン&amp;gt;/objects/commits&lt;/code&gt;というURLを&lt;code&gt;getCommits&lt;/code&gt;メソッドで処理するようにしている。
このAPIを呼び出すと、前節で作った&lt;code&gt;Commit&lt;/code&gt;クラスのインスタンスの配列がJSON形式で返ってくる。
(getCommitsの実装については次回書く。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;@RestController&lt;/code&gt;を付けると以下の二つのアノテーションを付けたのと同じことになる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Controller.html&#34;&gt;&lt;code&gt;@Controller&lt;/code&gt;&lt;/a&gt;: 一般的なコントローラクラスに付けるアノテーション。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/ResponseBody.html&#34;&gt;&lt;code&gt;@ResponseBody&lt;/code&gt;&lt;/a&gt;: メソッドの戻り値をHTTPレスポンスボディにバインドすることを指示する。これを付けると、戻り値は&lt;a href=&#34;http://wiki.fasterxml.com/JacksonHome&#34;&gt;Jackson JSON&lt;/a&gt;でJSONに変換されてクライアントに返される。これを付けないと、戻り値はスタティックリソースへのパスなどとして扱われ、View(e.g. Thymeleaf)が処理した結果がクライアントに返される。(&lt;a href=&#34;http://qiita.com/tag1216/items/3680b92cf96eb5a170f0&#34;&gt;参考記事&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;見ての通り、URLのパス中の値は&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/PathVariable.html&#34;&gt;&lt;code&gt;@PathVariable&lt;/code&gt;&lt;/a&gt;を使って取得できる。&lt;/p&gt;

&lt;p&gt;ここには書いてないけど、URLクエリパラメータは&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/RequestParam.html&#34;&gt;&lt;code&gt;@RequestParam&lt;/code&gt;&lt;/a&gt;を使って取得できるし、&lt;a href=&#34;http://mergedoc.osdn.jp/tomcat-servletapi-5-ja/javax/servlet/http/HttpServletRequest.html&#34;&gt;&lt;code&gt;HttpServletRequest&lt;/code&gt;&lt;/a&gt;もメソッドの引数として宣言しておけばSpringが渡してくれる。&lt;/p&gt;

&lt;h4 id=&#34;7-メインクラス作成&#34;&gt;7. メインクラス作成&lt;/h4&gt;

&lt;p&gt;最後に、アプリを起動するメインクラスを作る。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/api/org/springframework/boot/autoconfigure/SpringBootApplication.html&#34;&gt;&lt;code&gt;@SpringBootApplication&lt;/code&gt;&lt;/a&gt;を付けたクラスに&lt;code&gt;main&lt;/code&gt;メソッドを以下の様に定義すればいいだけ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@SpringBootApplication
public class Application {

  public static void main(String[] args) {
    SpringApplication.run(Application.class, args);
  }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(Application.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/Application.java&#34;&gt;こちら&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;@SpringBootApplication&lt;/code&gt;を付けると、以下の三つのアノテーションを付けたのと同じことになる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/context/annotation/Configuration.html&#34;&gt;&lt;code&gt;@Configuration&lt;/code&gt;&lt;/a&gt; (&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/api/org/springframework/boot/SpringBootConfiguration.html&#34;&gt;&lt;code&gt;@SpringBootConfiguration&lt;/code&gt;&lt;/a&gt;): Spring Bean定義を提供するクラスであることを示す。(意味不明。)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/api/org/springframework/boot/autoconfigure/EnableAutoConfiguration.html&#34;&gt;&lt;code&gt;@EnableAutoConfiguration&lt;/code&gt;&lt;/a&gt;: Springの&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/using-boot-auto-configuration.html&#34;&gt;自動設定機能&lt;/a&gt;を有効にする。この機能は、ライブラリの依存関係から推定して必要な設定をしてくれるもの。例えば&lt;code&gt;tomcat-embedded.jar&lt;/code&gt;に依存していたら、&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/api/org/springframework/boot/context/embedded/tomcat/TomcatEmbeddedServletContainerFactory.html&#34;&gt;&lt;code&gt;TomcatEmbeddedServletContainerFactory&lt;/code&gt;&lt;/a&gt;をセットアップしてくれるなど。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/context/annotation/ComponentScan.html&#34;&gt;&lt;code&gt;@ComponentScan&lt;/code&gt;&lt;/a&gt;: このアノテーションを付けたクラスのパッケージ以下から、&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Component.html&#34;&gt;&lt;code&gt;@Component&lt;/code&gt;&lt;/a&gt;、&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Service.html&#34;&gt;&lt;code&gt;@Service&lt;/code&gt;&lt;/a&gt;、&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Repository.html&#34;&gt;&lt;code&gt;@Repository&lt;/code&gt;&lt;/a&gt;、&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Controller.html&#34;&gt;&lt;code&gt;@Controller&lt;/code&gt;&lt;/a&gt;(など?)が付いたクラスが検索され、Spring Beanとして登録される。XMLのSpring Bean設定ファイルを書かなくてよい。前節で作ったリソースコントローラがこのアノテーションによって利用できるようになる。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;@SpringBootApplication&lt;/code&gt;、というか&lt;code&gt;@Configuration&lt;/code&gt;をつけたクラスは&lt;code&gt;final&lt;/code&gt;にしてはいけない。
すると実行時にエラーになる。&lt;/p&gt;

&lt;h4 id=&#34;8-ビルド-実行&#34;&gt;8. ビルド、実行&lt;/h4&gt;

&lt;p&gt;以上でとりあえず動くものができた。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;gradlew bootRun&lt;/code&gt;を実行するとディベロッパツール付きでアプリが動くし、&lt;code&gt;gradlew build&lt;/code&gt;を実行すれば&lt;code&gt;build/libs/goslings-0.0.1.jar&lt;/code&gt;というアーティファクトが生成され、&lt;code&gt;java -jar build/libs/goslings-0.0.1.jar&lt;/code&gt;でアプリを起動できる。
(いずれもポートは8080)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今日はここまで。
&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/10/goslings-development-memo2-spring-boot-di/&#34;&gt;次回&lt;/a&gt;はまたSpring Bootで、DIについて。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goslings開発メモ - その0: 紹介と概要と設計編</title>
          <link>https://www.kaitoy.xyz/2016/12/11/goslings-development-memo0-intro-design/</link>
          <pubDate>Sun, 11 Dec 2016 15:26:45 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/12/11/goslings-development-memo0-intro-design/</guid>
          <description>

&lt;p&gt;つい先日&lt;a href=&#34;https://github.com/kaitoy/goslings&#34;&gt;&lt;strong&gt;Goslings&lt;/strong&gt;&lt;/a&gt;というものを作った。
&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;Gitのリポジトリの中身&lt;/a&gt;をビジュアライズするWebアプリケーションだ。
なんとなく見て楽しいという効用がある他は、Gitの勉強にちょっと使えるかもしれないという程度のものだが、もともと&lt;a href=&#34;http://qiita.com/advent-calendar/2016/git&#34;&gt;Git Advent Calendar 2016&lt;/a&gt;のネタを作るために作ろうと思ったものなので、とりあえずはこんなものでいいのだ。
将来気が向いたら、リポジトリの変更をリアルタイムに反映したり、リポジトリの操作もできるように拡張してもいいかもしれないけど、実用性が感じられないので多分やらない。&lt;/p&gt;

&lt;p&gt;因みに、goslingsというのはgeese(雁)の子供を指す、ちょっとマイナーな英語。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-development-memo0-design/geese.JPG&#34; alt=&#34;geese&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Gitオブジェクトを見るアプリだから、GOで始まる名前にしようかと思っていて、そういえば今住んでいるFort Collinsに大量にいるgeeseの子供がgoslingsというし、並んで歩いている姿がちょうどコミットグラフのようだと思い、Goslilngsと名付けた。
単数形だと&lt;a href=&#34;https://en.wikipedia.org/wiki/Ryan_Gosling&#34;&gt;カナダのイケメン俳優&lt;/a&gt;かと思われてしまうので、複数形にした。goslingが一人でいることってないし。&lt;/p&gt;

&lt;p&gt;Goslingsは&lt;a href=&#34;https://projects.spring.io/spring-boot/&#34;&gt;Spring Boot&lt;/a&gt;や&lt;a href=&#34;https://eclipse.org/jgit/&#34;&gt;JGit&lt;/a&gt;などの習作でもある。
学んだことはアプリケーションとしてアウトプットするとよく身に付くものだ。
また文章としてもアウトプットしておくとさらによく身に付き、備忘録にもなるので、Goslingsの開発メモをいくつかのエントリに分けて書いていくことにする。&lt;/p&gt;

&lt;p&gt;まずはSpring Boot編を書こうかと思うが、その前にGoslingsの設計等について書いておく。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;goslingsのアーキテクチャ&#34;&gt;Goslingsのアーキテクチャ&lt;/h1&gt;

&lt;p&gt;GoslingsはWebサーバとして動き、始めにクライアントにHTML文書を返した後は、REST APIサーバとして働く。&lt;/p&gt;

&lt;p&gt;サーバ側はJavaでできていて、Spring BootとJGitを使っている。
JGitを使いたかったのでJavaにしたが、そうでなければ&lt;a href=&#34;https://nodejs.org/ja/&#34;&gt;Node&lt;/a&gt;で書きたかった。&lt;/p&gt;

&lt;p&gt;因みに、今回はコーディングの詳細にあまりこだわらないつもりだったので、&lt;a href=&#34;https://projectlombok.org/&#34;&gt;Lombok&lt;/a&gt;で楽をしようかと思ったけど、うっとうしい&lt;a href=&#34;https://github.com/rzwitserloot/lombok/issues/879&#34;&gt;バグ&lt;/a&gt;を踏み、どうやっても回避できなかったので使うのやめた。
二度と使うまい。&lt;/p&gt;

&lt;p&gt;クライアント側はJavaScript(ES2015 + async/await)の&lt;a href=&#34;https://en.wikipedia.org/wiki/Single-page_application&#34;&gt;SPA&lt;/a&gt;で、禁&lt;a href=&#34;https://jquery.com/&#34;&gt;jQuery&lt;/a&gt;縛り。
&lt;a href=&#34;https://facebook.github.io/react/&#34;&gt;React&lt;/a&gt; + &lt;a href=&#34;https://github.com/reactjs/redux&#34;&gt;Redux&lt;/a&gt;というのをやってみたかったが、なんか大げさだしそこまで時間がとれなそうだったので、フレームワークなしで作った。ので、
「&lt;a href=&#34;http://qiita.com/tatesuke/items/b9548dd484b01b139b74&#34;&gt;You Don&amp;rsquo;t Need jQuery&lt;/a&gt;」とにらめっこしながら書いた。&lt;/p&gt;

&lt;p&gt;Gitのコミットグラフの描画には、&lt;a href=&#34;http://visjs.org/&#34;&gt;vis.js&lt;/a&gt;を使った。
&lt;a href=&#34;http://stackoverflow.com/questions/7034/graph-visualization-library-in-javascript&#34;&gt;Stack Overflowの回答&lt;/a&gt;から雰囲気で選んだけど、やりたかったことが全部できて、見た目もよかったのでよかった。&lt;/p&gt;

&lt;p&gt;サーバは&lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt;で動かすためにステートレスに作ったつもりで、後述の作業ディレクトリをコンテナ間で共有し、サーバの負荷に応じてコンテナを増やしたり減らしたり、簡単にスケールするようになっているはず。&lt;/p&gt;

&lt;h1 id=&#34;goslingsの機能設計&#34;&gt;Goslingsの機能設計&lt;/h1&gt;

&lt;p&gt;Goslingsサーバにブラウザでアクセスすると、まず参照したいGitリポジトリのURIを入力するフォームが表示される。
ここにはローカルにあるリポジトリへのファイルシステム上のパス(e.g. &lt;code&gt;C:\repos\project-hoge\.git&lt;/code&gt;)か、リモートにあるリポジトリのURL(e.g. &lt;code&gt;https://repos.foo.com/project-hoge.git&lt;/code&gt;)を入力できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-development-memo0-design/goslings-form.png&#34; alt=&#34;goslings-form&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;URIを入力して&lt;code&gt;Browse&lt;/code&gt;ボタンを&lt;a href=&#34;http://qiita.com/yaju/items/0ceb6a0343561b4d208e&#34;&gt;押下する&lt;/a&gt;と、Goslingsの作業ディレクトリ(デフォルトではtmpディレクトリの下の&lt;code&gt;goslings&lt;/code&gt;)に、ローカルリポジトリの場合はそこへのsymlinkを、リモートリポジトリの場合はベアなクローンを作成する。
いずれの場合にも、正規化したURIから生成したUID(SHA-1ハッシュ)をsymlinkファイル名とクローンディレクトリ名に使う。
サーバはリポジトリの準備ができたら、そのUIDをトークン(i.e. リポジトリ引換券)としてクライアントに渡す。
クライアントはそのトークンを使って、リポジトリの情報をサーバに要求する。&lt;/p&gt;

&lt;p&gt;こうすることで、以下の様に後でリポジトリを取り扱いやすくなる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;クライアントやサーバは、可変長の長ったらしい特殊文字の含まれたURIの代わりに、40文字の数字とアルファベットだけで構成されたトークンでリポジトリを特定でき、処理がしやすい。&lt;/li&gt;
&lt;li&gt;後でサーバがリポジトリにアクセスする際、ローカルとリモートを区別する必要がないので、処理がしやすい。&lt;/li&gt;
&lt;li&gt;サーバ内部でリポジトリというエンティティを扱う際、リポジトリに直接触るデータレイヤと、クライアントからのリクエストをさばくインターフェースレイヤとの間で、単なる文字列であるトークンをやりとりすればよく、データレイヤの実装の詳細をインターフェースレイヤに曝さなくてよくなり、レイヤをきれいに分離できる。これはJavaの&lt;a href=&#34;https://docs.oracle.com/javase/tutorial/java/IandI/createinterface.html&#34;&gt;インターフェース&lt;/a&gt;を作ってやってもできるが、インターフェースのAPIを考える手間を考えるとトークンの方が楽。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;クライアントはトークンを受け取ったらコミットグラフビューに遷移する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-development-memo0-design/graph.png&#34; alt=&#34;graph&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;このビューでの表示は&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;以前Gitリポジトリの中身を解説した記事&lt;/a&gt;に合わせた。&lt;/p&gt;

&lt;p&gt;初期状態ではコミットと参照とタグだけが表示されていて、コミットをダブルクリックするとツリーが表示され、さらにツリーをダブルクリックするとドリルダウンしていける。
ノードをシングルクリックするとそのコンテンツを参照できる。&lt;/p&gt;

&lt;h1 id=&#34;goslingsの使い方&#34;&gt;Goslingsの使い方&lt;/h1&gt;

&lt;p&gt;Spring Bootを使ったおかげで、ビルド成果物は単一のjarで、これを以下の様に実行するだけでサーバが立ち上がる。Webアプリケーションコンテナいらず。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ java -jar goslings-server-0.0.1.jar --server.port=80
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;com.github.kaitoy.goslings.server.reposDir&lt;/code&gt;というシステムプロパティを使って作業ディレクトリのパスを指定できる。&lt;/p&gt;

&lt;p&gt;また、&lt;code&gt;com.github.kaitoy.goslings.server.uriPrefix&lt;/code&gt;というシステムプロパティに値を設定すると、その値で始まるURI以外をフォームで入力するとエラーになるようになる。
リモートリポジトリを何でもかんでもクローンされるとディスク容量がいくらあっても足りないので、URLに制限をかけるために作った設定。
汎用性は考えておらず、複数指定したり正規表現を指定したりといったことはできない。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/r/kaitoy/goslings/&#34;&gt;Dockerコンテナイメージ&lt;/a&gt;もあって、以下のようなコマンドでダウンロードして起動できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker pull kaitoy/goslings
$ docker run -p 80:80 -itd kaitoy/goslings 80 /goslings-repos https://github.com/kaitoy/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;docker run&lt;/code&gt;の後ろの方の&lt;code&gt;80 /goslings-repos https://github.com/kaitoy/&lt;/code&gt;が、それぞれ&lt;code&gt;--server.port&lt;/code&gt;、&lt;code&gt;com.github.kaitoy.goslings.server.reposDir&lt;/code&gt;、&lt;code&gt;com.github.kaitoy.goslings.server.uriPrefix&lt;/code&gt;に渡される。
&lt;code&gt;--server.port&lt;/code&gt;のもの以外は省略してもいい。&lt;/p&gt;

&lt;h1 id=&#34;goslings-as-a-service&#34;&gt;Goslings as a Service&lt;/h1&gt;

&lt;p&gt;Goslings as a Service、略してGaaSを &lt;a href=&#34;http://www.goslings.tk&#34;&gt;http://www.goslings.tk&lt;/a&gt; で公開している。
&lt;code&gt;https://github.com/kaitoy/&lt;/code&gt;で始まるURLしか受け付けないようにしてある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/&#34;&gt;AWS&lt;/a&gt;の無料枠を活用して&lt;a href=&#34;https://aws.amazon.com/ecs/&#34;&gt;EC2 Container Service (ECS)&lt;/a&gt;でホストしていて、&lt;a href=&#34;http://www.freenom.com/ja/index.html&#34;&gt;Freenom&lt;/a&gt;で無料で取得した&lt;code&gt;goslings.tk&lt;/code&gt;ドメインとこれまた無料のFreenomのネームサーバを利用して上記のアドレスにしている。&lt;/p&gt;

&lt;p&gt;AWSもFreenomも無料なのは12か月だけなので、それが過ぎたらGaaSは終了する予定。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Currently Pcap4J Doesn&#39;t Work on Bash on Windows</title>
          <link>https://www.kaitoy.xyz/2016/11/19/pcap4j-doesnt-work-on-bow-yet/</link>
          <pubDate>Sat, 19 Nov 2016 11:41:07 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/11/19/pcap4j-doesnt-work-on-bow-yet/</guid>
          <description>

&lt;h1 id=&#34;tl-dr&#34;&gt;TL;DR&lt;/h1&gt;

&lt;p&gt;I&amp;rsquo;ve attempted to run &lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;&lt;strong&gt;Pcap4J&lt;/strong&gt;&lt;/a&gt; on &lt;a href=&#34;https://msdn.microsoft.com/en-us/commandline/wsl/about&#34;&gt;&lt;strong&gt;Bash on Windows&lt;/strong&gt;&lt;/a&gt; (BoW) but it didn&amp;rsquo;t work due to lack of support for network staff in BoW.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;what-s-bash-on-windows&#34;&gt;What&amp;rsquo;s Bash on Windows&lt;/h1&gt;

&lt;p&gt;Bash on Windows is a feature released in &lt;a href=&#34;https://blogs.windows.com/windowsexperience/2016/08/02/how-to-get-the-windows-10-anniversary-update/#j0WW1oOyf4smWkeX.97&#34;&gt;Windows 10 Anniversary Update&lt;/a&gt; to add Linux fanctionalities to Windows.&lt;/p&gt;

&lt;p&gt;With this feature, we can run Bash and several Linux commands on Windows.&lt;/p&gt;

&lt;p&gt;It sounds similar to &lt;a href=&#34;https://www.cygwin.com/&#34;&gt;Cygwin&lt;/a&gt; and &lt;a href=&#34;http://www.mingw.org/&#34;&gt;MinGW&lt;/a&gt; but actually different. Linux commands Cygwin and MinGW provides are Windows-native binaries. On the other hand, BoW enables to run Ubuntu instance as a subsystem of Windows and to execute Ubuntu-native binaries on it.&lt;/p&gt;

&lt;p&gt;BoW can be easily installed by only 2 steps as per &lt;a href=&#34;https://msdn.microsoft.com/commandline/wsl/install_guide&#34;&gt;the installation guide&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;try-pcap4j-in-bow&#34;&gt;Try Pcap4J in BoW&lt;/h1&gt;

&lt;p&gt;BoW can be started by &lt;code&gt;bash&lt;/code&gt; command in command prompt.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;bash
kaitoy@DESKTOP-41L0NMU:/mnt/c/Users/kaitoy$ uname -a
Linx DESKTOP-41L0NMU 3.4.0+ #1 PREEMPT Thu Aug 1 17:06:05 CST 2013 x86_64 x86_64 x86_64 GNU/Linux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the bash, I ran the following commands to install Pcap4J dependencies:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt-get update
sudo apt-get install openjdk-7-jdk libpcap-dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then, I executed Pcap4J (org.pcap4j.sample.GetNextPacketEx) and got an error as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ java -cp pcap4j-core-1.6.2.jar:pcap4j-packetfactory-static-1.6.2.jar:pcap4j-sample-1.6.2.jar:jna-4.2.1.jar:slf4j-api-1.7.12.jar:logback-classic-1.0.0.jar:logback-core-1.0.0.jar org.pcap4j.sample.GetNextPacketEx
org.pcap4j.sample.GetNextPacketEx.count: 5
org.pcap4j.sample.GetNextPacketEx.readTimeout: 10
org.pcap4j.sample.GetNextPacketEx.snaplen: 65536


java.io.IOException: Return code: -1, Message: getifaddrs: Invalid argument
        at org.pcap4j.util.NifSelector.selectNetworkInterface(NifSelector.java:40)
        at org.pcap4j.sample.GetNextPacketEx.main(GetNextPacketEx.java:43)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This error seems due to &lt;a href=&#34;https://github.com/Microsoft/BashOnWindows/issues/69&#34;&gt;lack of support&lt;/a&gt; for network staff in BoW.&lt;/p&gt;

&lt;p&gt;BoW is still beta. I will try again after its production release.&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Bash on WindowsでWindows側からUbuntu側のファイルをいじると壊れることがあるので注意</title>
          <link>https://www.kaitoy.xyz/2016/11/19/bow-do-not-change-linux-files-from-windows/</link>
          <pubDate>Sat, 19 Nov 2016 01:05:26 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/11/19/bow-do-not-change-linux-files-from-windows/</guid>
          <description>

&lt;p&gt;Bash on WindowsでWindows側からUbuntu側のファイルをいじると危険という情報を見つけたので、試してみたら確かに困った状態になった話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;bash-on-windowsとは&#34;&gt;Bash on Windowsとは&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://msdn.microsoft.com/en-us/commandline/wsl/about&#34;&gt;Bash on Windows&lt;/a&gt; (aka BoW)は、2016/8/3に公開されたWindows 10 Anniversary Updateで使えるようになった、Windows上でBashが使えるようになる機能。&lt;/p&gt;

&lt;p&gt;POSIX APIのWindows実装を提供する&lt;a href=&#34;https://www.cygwin.com/&#34;&gt;Cygwin&lt;/a&gt;などとは違い、WindowsのサブシステムとしてUbuntuが動き、その上でBashが動き、そこからUbuntu用のバイナリをそのまま利用できるというもの。&lt;/p&gt;

&lt;p&gt;2016/11/17現在でまだベータ版の機能。&lt;/p&gt;

&lt;h1 id=&#34;windows側からubuntu側のファイルをいじると壊れる問題&#34;&gt;Windows側からUbuntu側のファイルをいじると壊れる問題&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://blogs.msdn.microsoft.com/commandline/2016/11/17/do-not-change-linux-files-using-windows-apps-and-tools/&#34;&gt;Microsoftの中の人のブログ&lt;/a&gt;に、BoWがセットアップされた環境で、Windows側からUbuntu側のファイル(i.e. &lt;code&gt;%localappdata%\lxss\&lt;/code&gt;以下のファイル)をいじると壊れるという話があった。
いかにもやってしまいそうな操作で危険だし、実際このブログの人はこれに関する問い合わせに毎日1,2件対応しているそうな。&lt;/p&gt;

&lt;p&gt;原因は上記ブログに詳しいが、簡単に言うと、Windows側のプロセスがUbuntu側のファイルを作ったり編集したりする際、パーミッションなどのメタデータを適切に設定しないため、Ubuntu側でファイルが壊れたと判断されてしまうから。
こうなると、結果としてファイルが消えてしまったり、壊れたデータで上書きされてしまったりするとのこと。&lt;/p&gt;

&lt;p&gt;因みに、Ubuntu側からWindows側のファイルをいじるのは問題ないらしい。&lt;/p&gt;

&lt;h1 id=&#34;再現確認&#34;&gt;再現確認&lt;/h1&gt;

&lt;p&gt;そういえばまだBoWをさわったことがなかったので、セットアップして件の問題を体験してみた。&lt;/p&gt;

&lt;p&gt;環境は、VMware Player 7.1.0で作ったVMに評価版のWindows 10 Enterprise v1607をインストールしたもの。
セットアップは&lt;a href=&#34;https://msdn.microsoft.com/en-us/commandline/wsl/install_guide&#34;&gt;公式の手順&lt;/a&gt;に従うだけ。2ステップだけの簡単な手順。&lt;/p&gt;

&lt;p&gt;セットアップ後、コマンドプロンプトで&lt;code&gt;bash&lt;/code&gt;とうつとBoWが起動する。(初回はインストール処理が走り、十数分待たされる。)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[コマンドプロンプト → Bash]&lt;/strong&gt;
&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/bow.png&#34; alt=&#34;bow.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;再現確認に使うのは&lt;code&gt;hoge&lt;/code&gt;と書いた&lt;code&gt;hoge.txt&lt;/code&gt;。
これをWindows側の&lt;code&gt;C:\Users\kaitoy\Desktop\&lt;/code&gt;とUbuntu側の&lt;code&gt;/home/kaitoy/&lt;/code&gt;に置く。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[コマンドプロンプト]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/hoge_cmd.png&#34; alt=&#34;hoge_cmd.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/hoge_ubuntu.png&#34; alt=&#34;hoge_ubuntu.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Windows側からは、Ubuntuのファイルシステムが&lt;code&gt;%localappdata%\lxss\&lt;/code&gt;にマウントされているように見える。
(&lt;code&gt;lxss&lt;/code&gt;はエクスプローラーのオプションから「保護されたオペレーティングシステムファイルを表示しない（推奨）」のチェックをはずさないと見えない。見えなくてもアドレスバーにパスを入力すればアクセスできるけど。)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/lxss.png&#34; alt=&#34;lxss.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;一方Ubuntu側からは、WindowsのCドライブが&lt;code&gt;/mnt/c&lt;/code&gt;にマウントされているように見える。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/mntc.png&#34; alt=&#34;mntc.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ここで、コマンドプロンプトを開き、&lt;code&gt;%localappdata%\lxss\hoge\kaitoy\&lt;/code&gt;(i.e. Ubuntu側の&lt;code&gt;/home/kaitoy/&lt;/code&gt;)に&lt;code&gt;cd&lt;/code&gt;し、&lt;code&gt;hoge.txt&lt;/code&gt;を&lt;code&gt;echo&lt;/code&gt;で編集してみた。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[コマンドプロンプト]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/mod_from_cmd.png&#34; alt=&#34;mod_from_cmd.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;したらBashから見えなくなった。アクセスしようとすると「Input/output error」というエラーになる。これが件の現象か。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/disappeared.png&#34; alt=&#34;disappeared.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;エクスプローラからは見えていたので、GUIで&lt;code&gt;%localappdata%\lxss\hoge\kaitoy\hoge.txt&lt;/code&gt;を削除したら正常な状態に戻った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;再度同じ&lt;code&gt;hoge.txt&lt;/code&gt;を作り、今度はメモ帳で編集して内容を&lt;code&gt;foo&lt;/code&gt;に変えてみた。
この場合は特に問題なし。なぜだ?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/no_problem.png&#34; alt=&#34;no_problem.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;例のブログをよく読むと、実際に問題になるのはファイルの作成だけのように読める。
編集しているようにみえても、アプリによっては新規ファイルを作って既存のを置き換えていることがあるから、編集もするなと言っている模様。
メモ帳は実際に編集しているから大丈夫だったということか。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今編集した&lt;code&gt;hoge.txt&lt;/code&gt;を今度はエクスプローラから消してみる。
Ubuntu側からは消えてないように見えるが、アクセスしようとするとないと言われる。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/not_deleted.png&#34; alt=&#34;not_deleted.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;エクスプローラのビューをF5で更新したら、今消したはずの&lt;code&gt;hoge.txt&lt;/code&gt;が復活した。
これをダブルクリックで開こうとしたら「Access is denied.」。
エクスプローラから何度消してもすぐ復活する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/access_denied.png&#34; alt=&#34;access_denied.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Bashで消そうとしても「Permission denied」。詰んだ。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/permission_denied.png&#34; alt=&#34;permission_denied.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ということで、むしろWindows側からUbuntu側のファイルを消すのがもっともやばいと言うことがわかった。
&lt;code&gt;lxrun /uninstall /full&lt;/code&gt;、&lt;code&gt;lxrun /install&lt;/code&gt;でUbuntuイメージをインストールしなおさないと直らない。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;最後に、Ubuntu側(i.e. Bash)からWindows側の&lt;code&gt;C:\Users\kaitoy\Desktop\hoge.txt&lt;/code&gt;をいじってみたが、例のブログに書いてある通りなんの問題もなかった。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/fin.png&#34; alt=&#34;fin.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;件の問題もベータがとれたら直るかもしれないが、&lt;code&gt;%localappdata%\lxss\&lt;/code&gt;は保護された隠しフォルダなのでやはり触らないのが無難か。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>git checkoutを図解する</title>
          <link>https://www.kaitoy.xyz/2016/10/08/git-checkout/</link>
          <pubDate>Sat, 08 Oct 2016 16:39:46 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/10/08/git-checkout/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;この記事&lt;/a&gt;を読んだ、またはGitのオブジェクトモデルを理解していることを前提に、&lt;a href=&#34;https://git-scm.com/&#34;&gt;&lt;strong&gt;Git&lt;/strong&gt;&lt;/a&gt;の &lt;code&gt;git checkout&lt;/code&gt; というコマンドについて説明する。&lt;/p&gt;

&lt;p&gt;このコマンドは普通ブランチを切り替えるものと説明されるが、主たる機能は &lt;strong&gt;オブジェクト格納領域から指定されたファイルを取り出し、ワーキングディレクトリに配置する&lt;/strong&gt; ものである。
つまりこれがGitにおけるチェックアウトで、チェックアウト=ブランチの切り替えではない。&lt;/p&gt;

&lt;p&gt;コマンドに与える引数によっては &lt;code&gt;HEAD&lt;/code&gt; の付け替え、つまりはブランチの切り替えもする、というだけ。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git checkout&lt;/code&gt; の動作を &lt;code&gt;HEAD&lt;/code&gt; の付け替えの有無によって分けて考えると分かりやすく覚えやすいので、以下そのように説明する。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;headを付け替えないgit-checkout&#34;&gt;HEADを付け替えないgit checkout&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;HEAD&lt;/code&gt; を付け替えない &lt;code&gt;git checkout&lt;/code&gt; は、引数にワーキングディレクトリ内の &lt;strong&gt;ファイルまたはディレクトリへのパスを与えた場合&lt;/strong&gt; のもの。
ディレクトリを指定した場合はそれ以下の全ファイルが操作対象となる。
パスは絶対パスかカレントディレクトリからの相対パスで、複数指定できる。&lt;/p&gt;

&lt;p&gt;つまりは以下の様なコマンド形式になる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git checkout &amp;lt;パス(複数可)&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;これを実行すると、指定したファイルについて、&lt;strong&gt;インデックスが指しているブロブ&lt;/strong&gt; をオブジェクト格納領域から取り出し、ワーキングディレクトリのファイルを置き変える。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド6.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド7.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;上のスライドではインデックスが指しているブロブを取り出したが、任意のブロブを取り出すこともできる。
この場合、以下の様なコマンド形式を使う。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git checkout &amp;lt;コミット&amp;gt; &amp;lt;パス(複数可)&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;このコマンド形式だと、&lt;strong&gt;指定したコミットが指すツリー以下のブロブ&lt;/strong&gt; が取り出される。
&lt;code&gt;&amp;lt;コミット&amp;gt;&lt;/code&gt;の部分には、コミットオブジェクトのSHA1ハッシュ値、参照(i.e. ブランチかタグ)、シンボリック参照(e.g. &lt;code&gt;HEAD&lt;/code&gt;)を指定できる。(実際にはこれらが全てではないが、実用的にはこの3種。)&lt;/p&gt;

&lt;p&gt;この形式だと、ワーキングディレクトリだけでなく、取り出すブロブを指すよう &lt;strong&gt;インデックスも更新される&lt;/strong&gt; ことに注意。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths_commit/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths_commit/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths_commit/スライド3.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h1 id=&#34;headを付け替えるgit-checkout&#34;&gt;HEADを付け替えるgit checkout&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;HEAD&lt;/code&gt; を付け替える &lt;code&gt;git checkout&lt;/code&gt; は、引数に &lt;strong&gt;パスを与えない場合&lt;/strong&gt; のもの。
代わりにコミットを与える。&lt;/p&gt;

&lt;p&gt;つまりは以下の様なコマンド形式になる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git checkout &amp;lt;コミット&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;コミット&amp;gt;&lt;/code&gt;の部分には、コミットオブジェクトのSHA1ハッシュ値、参照(i.e. ブランチかタグ)、シンボリック参照(e.g. &lt;code&gt;HEAD&lt;/code&gt;)を指定できる。(実際にはこれらが全てではないが、実用的にはこの3種。)&lt;/p&gt;

&lt;p&gt;これを実行すると、&lt;strong&gt;指定したコミットが指すツリー以下の全てのブロブ&lt;/strong&gt; を指すようインデックスを更新し、それらのブロブをオブジェクト格納領域から取り出してワーキングディレクトリに配置する。&lt;/p&gt;

&lt;p&gt;この上更に&lt;code&gt;HEAD&lt;/code&gt;を付け替えるわけだが、付け替え先は&lt;code&gt;&amp;lt;コミット&amp;gt;&lt;/code&gt;の種類によって以下の三通りある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;コミット&amp;gt;&lt;/code&gt;がブランチ: &lt;code&gt;HEAD&lt;/code&gt;はそのブランチを指すよう更新される。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;コミット&amp;gt;&lt;/code&gt;がSHA1ハッシュ値: &lt;code&gt;HEAD&lt;/code&gt;はコミットを指すよう更新される。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;コミット&amp;gt;&lt;/code&gt;がタグかシンボリック参照: &lt;code&gt;HEAD&lt;/code&gt;はタグかシンボリック参照が指すコミットを指すよう更新される。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド6.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド7.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド8.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド9.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;上のスライド中のコミットをチェックアウトした例を見ると分かるが、コマンド実行前後でワーキングディレクトリからファイルが削除されることもある。
これは多分、実際にはインデックスの更新処理の前に、&lt;code&gt;HEAD&lt;/code&gt;が指すコミットに含まれるファイルをワーキングディレクトリから削除する処理があるからだと考えられる。&lt;/p&gt;

&lt;p&gt;また、上のスライドには表現していないが、コマンド実行前にワーキングディレクトリやインデックスに未コミットな変更が入っている場合、Gitはそれをコマンド実行後のワーキングディレクトリに適用しようとしてくれる。
これは例えばあるブランチで作った変更を別のブランチにコミットしたいようなときは便利だが、&lt;code&gt;checkout&lt;/code&gt;したコミットに別途変更が入っているとその適用は失敗し、コマンドがエラーになるので、普通はコマンド実行前に&lt;code&gt;git stash&lt;/code&gt;しておくのが無難。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Gitの良さが分からない？ ちょっとそこに座れ</title>
          <link>https://www.kaitoy.xyz/2016/10/06/git-vs-subversion/</link>
          <pubDate>Thu, 06 Oct 2016 00:18:05 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/10/06/git-vs-subversion/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://crapp.hatenablog.com/entry/2016/10/01/111528&#34;&gt;Gitの良さがいまだに分からない&lt;/a&gt;という人がいるようなので、Git派の一人としてSubversion(以下SVN)と比較してのGitの良さ(メリット)について語りたい。
(GitとSVNの違いについては他の人の記事に詳しいのであまり書いていない一方、勢い余ってGitのデメリットも書いた。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;本題に入る前に、冒頭にリンクを貼った記事についてひとつだけつっこんでおく。
つっこみどころは他にも沢山あるけど。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;※話の前提としてgitとSVNを採用している現場に下記のような割と違いがあるとする。&lt;/p&gt;

&lt;p&gt;git
イシューごとにブランチを切り、ローカルでコミットして、リモートブランチにpushして、GitHub・GitLab・Bitbucket経由でマージリクエスト。コードレビューの後にマージ。&lt;/p&gt;

&lt;p&gt;SVN
リモートのtrunkに個々人が直接コミット。コードレビューはあまりない。ブランチを切ることもない。&lt;/p&gt;

&lt;p&gt;このような違いが出る背景には次のものがある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gitを採用する現場は、猫も杓子もgit-flowというプラクティスに従う傾向がある
gitを採用する現場は、コードの品質もある程度管理する傾向がある
SVNは集中型でありブランチ機能などが非常に使いにくい
SVNを採用する現場はコードの品質よりも「リリースに含めるならさっさとコミット」と考える傾向がある
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;p&gt;この前提には無理がある。&lt;/p&gt;

&lt;p&gt;Gitのところに書いてあるのが、Gitというツールの枠を大きくはみだした&lt;a href=&#34;https://gist.github.com/Gab-km/3705015&#34;&gt;GitHub Flow&lt;/a&gt;というブランチ戦略+開発プロセスに当たるものであり、
それでGitを批判するのはお門違いであろうという点については、Gitの流行がGitHubの人気によるところが大きく、GitHubを使えることがGitの大きなメリットであるので、目をつむることにする。(マージリクエストを使う羽目になるデメリットなんて言いがかりでしかないとだけ言っておく。)&lt;/p&gt;

&lt;p&gt;看過できないのは、SVNを使った開発がコードレビューもブランチもないという点。&lt;/p&gt;

&lt;p&gt;どこの世界の話をしているんだろうか。
Gitが世に出る前は世間にコードレビューもブランチもあまりなかったかのような前提だが、もちろんそんなことは全くない。
60万個以上のOSSプロジェクト情報を統括する&lt;a href=&#34;https://ja.wikipedia.org/wiki/Ohloh&#34;&gt;Open HUB&lt;/a&gt;によれば、OSSプロジェクトの&lt;a href=&#34;https://www.openhub.net/repositories/compare&#34;&gt;46%がSVNを使っている&lt;/a&gt;。この中にはGitの誕生以降にSVNを使い始めたプロジェクトも多くある。270000余りのプロジェクトの大部分がブランチすら使っていないとでも?&lt;/p&gt;

&lt;p&gt;GitHub Flowと対比するために無理やりこじつけたんだろうけど、その無理のせいで議論のスタート地点からめちゃくちゃだ。&lt;/p&gt;

&lt;p&gt;まともな開発にはコードレビューもブランチも必要だ。
品質管理もリリース管理もしないなら要らないのかもしれないが、そんないい加減な開発現場を前提にSVNかGitかなんて議論しても意味がない。
高品質なソフトウェアを効率よく開発するために則りたい素晴らしい開発フローがあるとして、そのフローをSVNやGitやその他のツールないしひょっとしたらアナクロな日付フォルダの内どれがもっとも上手く実現してくれるか、というのがあるべき議論だ。
この「素晴らしい開発フロー」には一般的に品質管理と並行開発が含まれていて、それらにはコードレビューとブランチの利用が含まれている。
Git(+GitHub)がこんなにも急速にSVNに取って代わって流行ったのは、分散リポジトリの仕組みとブランチの軽量な実装によって効率的な並行開発が実現でき、またプルリクエストなどの機能によりコードレビューを含む快適なソーシャルコーディングが実現できるからだ。
逆に言えば、Gitが流行ったことが、人々が効率的な並行開発やコードレビューを開発フローに取り入れたかった証拠と言えるかもしれない。&lt;/p&gt;

&lt;h1 id=&#34;gitのメリット&#34;&gt;Gitのメリット&lt;/h1&gt;

&lt;p&gt;前置きが長くなったが、少なくともブランチとコードレビューを活用した高品質で高効率なソフトウェア開発をしたいという前提で、SVNに対するGitのメリットを挙げてみたい。&lt;/p&gt;

&lt;h4 id=&#34;1-リポジトリ構造がシンプル&#34;&gt;1. リポジトリ構造がシンプル&lt;/h4&gt;

&lt;p&gt;Gitリポジトリはすごくシンプルに作られているそうな。
確かに、&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;その構造&lt;/a&gt;を見ると、&lt;code&gt;add&lt;/code&gt;、&lt;code&gt;commit&lt;/code&gt;、&lt;code&gt;log&lt;/code&gt;、&lt;code&gt;reset&lt;/code&gt;くらいは自前ですぐに実装できそうだ。&lt;/p&gt;

&lt;p&gt;このシンプルな構造のおかげで、Gitリポジトリは壊れにくい。ここで壊れにくいとは、リポジトリ内部で不整合が起こりにくいということで、コマンドミスでコミット履歴が一部消えたりとかいうトラブルは壊れるに入らない。&lt;/p&gt;

&lt;p&gt;実のところSVNリポジトリの構造を知らないので経験的なことしか言えないが、SVNリポジトリ(というより作業ディレクトリの管理情報?)はちょくちょく変な状態になり、クリーンアップしたり、酷い時には.svn内のファイルを手動でいじったりしなければならなかった。&lt;/p&gt;

&lt;p&gt;因みに、シンプルというのはリポジトリサイズがすごく小さいということにはならず、同等の履歴を含むGitリポジトリとSVNリポジトリはだいたい同サイズなんだそうな。&lt;/p&gt;

&lt;h4 id=&#34;2-ブランチが軽い&#34;&gt;2. ブランチが軽い&lt;/h4&gt;

&lt;p&gt;Gitのブランチは単一のコミットを指す参照で、リポジトリ内ではSHA-1ハッシュ値が書かれただけのたった一つのファイルに過ぎない。
その為ブランチは一瞬で作成できるし、ディスクも圧迫しないので、じゃんじゃん作ってじゃんじゃん消せる。
さらに、ローカルリポジトリに過去の全ファイルの全バージョンが入っているという分散リポジトリの特長のおかげで、ブランチの切り替えも軽快にできる。
ローカルから必要なファイルを作業ディレクトリに展開するだけなので。&lt;/p&gt;

&lt;p&gt;一方SVNはそもそもブランチをサポートする直接的な機能がないため、ブランチはリビジョンのコピーという形で実装されている。
コピーと言ってもハードリンクみたいなものでディスク上に物理的なコピーが作られるわけではなく、軽量という点ではGitと大差ないが、集中リポジトリなせいでブランチの切り替えには差が出る。
&lt;code&gt;svn switch&lt;/code&gt;にしろ&lt;code&gt;svn checkout&lt;/code&gt;にしろネットワークの向こうのサーバとの通信が必要なので、それなりの時間がかかるし、通信が途切れると切り替えられなくなる。&lt;/p&gt;

&lt;p&gt;冒頭に貼った記事にはGitはブランチを切り替える際に&lt;code&gt;stash&lt;/code&gt;とかしないといけなくて面倒とあったが、そんなのSVNだって同じだし、&lt;code&gt;stash&lt;/code&gt;すればいいだけだし、&lt;code&gt;stash&lt;/code&gt;という機能があるだけSVNよりまし。Gitならコミットはあとから書き変えられるので、&lt;code&gt;stash&lt;/code&gt;の代わりに一時的にコミットしちゃってもいい。&lt;/p&gt;

&lt;p&gt;それも嫌なら&lt;a href=&#34;http://qiita.com/shibukk/items/80430b54ecda7f36ca44&#34;&gt;&lt;code&gt;worktree&lt;/code&gt;&lt;/a&gt;使えばよろしい。&lt;/p&gt;

&lt;h4 id=&#34;3-バージョン間の差分取得が速い&#34;&gt;3. バージョン間の差分取得が速い&lt;/h4&gt;

&lt;p&gt;Gitは全てのファイルについて全てのバージョンのコンテンツをまるまるリポジトリに持っている。
一方SVNのリポジトリにはバージョン間の変更が記録されている。
このため、あるファイルについて任意のバージョン間の差分を取るのに、Gitはシンプルにそれぞれのバージョンのファイルを取り出して比較するだけでよいが、SVNは隣り合ったバージョンでなければバージョン間の変更を足し合わせて差分を計算しなければいけない。&lt;/p&gt;

&lt;p&gt;さらに、Gitは比較するファイルをローカルリポジトリから取り出すだけでよいが、SVNはサーバへのアクセスが必要なので、差分取得はGitの方が大分速い。&lt;/p&gt;

&lt;h4 id=&#34;4-ログ取得が速い&#34;&gt;4. ログ取得が速い&lt;/h4&gt;

&lt;p&gt;Gitのコミットは常にプロジェクトの全ファイルに対するものだ。
これは変更したファイルの一部だけを対象とするコミット操作ができないという意味ではない。
Gitがひとつのコミット操作をコミットオブジェクトと呼ばれる単一のファイルに記録し、そのファイルが常にプロジェクトの全ファイルの特定のバージョンを参照しているという意味だ。(正確に言うとこのファイル自身に全ての参照が記録されているわけではないが。)&lt;/p&gt;

&lt;p&gt;このためGitのコミット履歴は実にシンプルで、ログ一覧を取得するには単にコミットをたどりながらコミットオブジェクトに書かれたログを集めればいい。&lt;/p&gt;

&lt;p&gt;一方SVNはファイル毎にバージョンを管理するので、もう少しややこしい。&lt;/p&gt;

&lt;p&gt;さらに、Gitはコミットオブジェクトをローカルリポジトリから持ってこれるがSVNは(以下略)。&lt;/p&gt;

&lt;h4 id=&#34;5-オフラインでだいたいなんでもできる&#34;&gt;5. オフラインでだいたいなんでもできる&lt;/h4&gt;

&lt;p&gt;と、ここまで書いて、Gitのいいところはオフライン作業が捗るところではないかと思い立った。&lt;/p&gt;

&lt;p&gt;実際Gitは、&lt;code&gt;clone&lt;/code&gt;、&lt;code&gt;fetch&lt;/code&gt;、&lt;code&gt;pull&lt;/code&gt;、&lt;code&gt;push&lt;/code&gt;といったあからさまな操作以外はオフラインでできる。
多くの操作にネットワーク通信コストを払わなくていい上、リモートリポジトリサーバが落ちたりネットワークが落ちたり山に籠ったりしていても作業が続けられる。&lt;/p&gt;

&lt;p&gt;ノマドに最適。&lt;/p&gt;

&lt;p&gt;一方SVNがネットワーク通信なしでできることは、…ベースバージョンとのdiffくらい?&lt;/p&gt;

&lt;h4 id=&#34;6-コミット履歴を汚さずにコードレビューできる&#34;&gt;6. コミット履歴を汚さずにコードレビューできる&lt;/h4&gt;

&lt;p&gt;私の職場はSVNを使っていて、コードを書いたら一旦コミットして、リビジョンを偉い人に通知してレビューしてもらっている。
偉い人は遠い異国にいたりするが、こちらがコミットしてしまえばSVNの機能で変更内容の取得も確認もできるという寸法だ。
リポジトリ外で変更内容をやりとりする方法とは違って、レビュー後のコミットミスや漏れが起こる余地がないのがいいが、レビューで受けた指摘は別のコミットを加えて反映したり、酷い時はリバースコミットで変更を取り消す必要がある。
こういうコミット履歴は大抵単なるノイズで、そうでなくてもリポジトリにある必要はない情報だ。&lt;/p&gt;

&lt;p&gt;一方GitならP2Pで偉い人にコミットを送れるし、レビュー後にコミットの作り直しもできるので、コミット履歴をきれいに保てる。
履歴がきれいだと変更のトレーサビリティが高まる。
変更のトレーサビリティが高いと、保守性が高くなり、低メンテナンスコストで高品質なプロダクトの開発につながる。&lt;/p&gt;

&lt;h4 id=&#34;7-ソーシャルコーディングできる&#34;&gt;7. ソーシャルコーディングできる&lt;/h4&gt;

&lt;p&gt;SaaSなら&lt;a href=&#34;https://github.com/&#34;&gt;GitHub&lt;/a&gt;や&lt;a href=&#34;https://bitbucket.org/product&#34;&gt;Bitbucket&lt;/a&gt;、オンプレミスなら&lt;a href=&#34;https://enterprise.github.com/home&#34;&gt;GitHub Enterprise&lt;/a&gt;や&lt;a href=&#34;https://about.gitlab.com/&#34;&gt;GitLab&lt;/a&gt;を利用して、ソーシャルコーディングを実現できるのはやはりGitの大きな強みだ。&lt;/p&gt;

&lt;p&gt;ソーシャルコーディングはアジャイルの先にあるDevOpsに必須とも言える要素で、今後これを実現できないIT企業やユーザ企業は開発力で他企業に差を付けられ、苦しい競争を強いられるであろう。&lt;/p&gt;

&lt;p&gt;バージョン管理ツール単体だけでなく、その上に乗っかるものまで見た場合、GitはSVNに大きく差を付けている感がある。&lt;/p&gt;

&lt;h1 id=&#34;git対svnの迷信&#34;&gt;Git対SVNの迷信&lt;/h1&gt;

&lt;p&gt;調べているうちに、Git対SVNで広く信じられている迷信があることを知ったので、ついでに書き残しておく。&lt;/p&gt;

&lt;h4 id=&#34;1-svnのマージはクソ&#34;&gt;1. SVNのマージはクソ&lt;/h4&gt;

&lt;p&gt;例えば&lt;a href=&#34;http://catcher-in-the-tech.net/806/&#34;&gt;「SVNからGitに移行して分かった、今すぐSVNを捨てるべき3つの理由」&lt;/a&gt;という記事の3つめの理由にSVNのマージ機能がクソと書いてあるが、これは最近では迷信とされている。&lt;/p&gt;

&lt;p&gt;SVNは確かにかつてブランチとマージに対するサポートが貧弱で、ブランチがどこを起点に作られたか、どのコミットをマージしたかといった情報を記憶しなかったため、ユーザがコマンドに教えてあげたり、コミットログを工夫して記録してやらなければならなかった。
しかし、&lt;a href=&#34;https://subversion.apache.org/docs/release-notes/1.5.html#merge-tracking&#34;&gt;バージョン1.5&lt;/a&gt;からこの状況が改善され始め、&lt;a href=&#34;https://subversion.apache.org/docs/release-notes/1.8.html#auto-reintegrate&#34;&gt;バージョン1.8&lt;/a&gt;で成熟したオートマージ機能により、SVNのマージも十分強力なものになった。&lt;/p&gt;

&lt;p&gt;Gitは&lt;a href=&#34;https://git-scm.com/docs/merge-strategies&#34;&gt;オクトパスマージとかマージ戦略オプションとか&lt;/a&gt;あってさらに強力そうではあるけど、そんな高機能を必要とする場面があまりなさそう。&lt;/p&gt;

&lt;h4 id=&#34;2-svnフォルダが各フォルダにあってうっとうしくてほんとクソ&#34;&gt;2. .svnフォルダが各フォルダにあってうっとうしくてほんとクソ&lt;/h4&gt;

&lt;p&gt;これも今では迷信。&lt;a href=&#34;https://subversion.apache.org/docs/release-notes/1.7.html#wc-ng&#34;&gt;バージョン1.7&lt;/a&gt;から&lt;code&gt;.svn&lt;/code&gt;はルートフォルダだけに作られるようになった。&lt;/p&gt;

&lt;h1 id=&#34;gitのデメリット&#34;&gt;Gitのデメリット&lt;/h1&gt;

&lt;p&gt;GitはSVNより全ての点で優れているというわけでもない。
以下、SVNに対するGitのデメリットを挙げてみたい。&lt;/p&gt;

&lt;h4 id=&#34;1-cloneに時間がかかる&#34;&gt;1. cloneに時間がかかる&lt;/h4&gt;

&lt;p&gt;Gitでの開発は基本的にリポジトリ全体を&lt;code&gt;clone&lt;/code&gt;することから始まる。
上記の「オフラインでだいたいなんでもできる」というのは、最初に全部ローカルに持ってきてしまうことで活きてくる利点だ。&lt;/p&gt;

&lt;p&gt;けどリポジトリが大きいとやっぱり&lt;code&gt;clone&lt;/code&gt;は時間がかかる操作になる。
例えば、&lt;a href=&#34;https://github.com/torvalds/linux&#34;&gt;Linuxカーネル&lt;/a&gt;をGitHubから&lt;code&gt;clone&lt;/code&gt;してみたら 45 分程かかった。
そんなに気軽にできる操作ではない。&lt;/p&gt;

&lt;p&gt;このデメリットに対処する方法は&lt;a href=&#34;http://japan.blogs.atlassian.com/2014/05/handle-big-repositories-git/&#34;&gt;いくつかある&lt;/a&gt;が、それをするとオフライン作業の幅を狭めることになる。&lt;/p&gt;

&lt;p&gt;SVNには&lt;code&gt;clone&lt;/code&gt;の概念がないのでこの悩みはない。&lt;/p&gt;

&lt;h4 id=&#34;2-部分cloneのサポートが貧弱&#34;&gt;2. 部分cloneのサポートが貧弱&lt;/h4&gt;

&lt;p&gt;上でも書いたが、GitはSVNのように履歴をディレクトリやファイル毎に管理しているわけではなく、コミットはプロジェクトの全ファイルを参照(i.e. 依存)しているので、特定のディレクトリ以下だけのcloneといった部分cloneの完全な実装は技術的に困難だ。&lt;/p&gt;

&lt;p&gt;Gitはリリース当初、部分cloneのサポートを全く提供せず、バージョン1.7になってそれっぽい&lt;a href=&#34;http://stackoverflow.com/questions/600079/how-do-i-clone-a-subdirectory-only-of-a-git-repository&#34;&gt;sparse checkout&lt;/a&gt;が実装されたが、あまり使い勝手が良くない。
Gitの開発陣は当初から部分cloneの実装に乗り気ではないし、上記の技術的な壁もあるので、今後この状況が大きく改善されることは恐らくないであろう。&lt;/p&gt;

&lt;p&gt;妥協になるだろうが、ソースをモジュール毎に分割して別々のリポジトリに突っ込み、必要に応じて&lt;code&gt;submodule&lt;/code&gt;か&lt;code&gt;subtree&lt;/code&gt;でつなげるのが実用的な解ではないだろうか。
それにしたって面倒だが。&lt;/p&gt;

&lt;p&gt;SVNではリポジトリの一部を&lt;code&gt;checkout&lt;/code&gt;する操作は第一級市民であり、何の制限もなく快適にできる。
この点においてはSVNパイセンの圧勝だ。&lt;/p&gt;

&lt;h4 id=&#34;3-コマンドが分かり辛い&#34;&gt;3. コマンドが分かり辛い&lt;/h4&gt;

&lt;p&gt;Gitはもともと低レベルなバージョン管理ツールとして開発されたためか、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%AA%E3%83%BC%E3%83%8A%E3%82%B9%E3%83%BB%E3%83%88%E3%83%BC%E3%83%90%E3%83%AB%E3%82%BA&#34;&gt;神&lt;/a&gt;の思考パターンが凡人のそれとはかけ離れているためか、Gitのコマンド体系は分かり辛く使いにくいというのは世界共通の認識のようだ。
このためGitの導入に当たってはどうしても高い学習コストを払わなければいけない。&lt;/p&gt;

&lt;p&gt;これは、分散バージョン管理システムというアーキテクチャが複雑だから、という理由からくるものではない。
同じ分散バージョン管理システムでも、&lt;a href=&#34;https://www.mercurial-scm.org/&#34;&gt;Mercurial&lt;/a&gt;は&lt;a href=&#34;https://blogs.atlassian.com/2012/02/mercurial-vs-git-why-mercurial/&#34;&gt;一貫したきれいな使いやすいコマンド体系をもっている&lt;/a&gt;らしい。&lt;/p&gt;

&lt;p&gt;好みの問題もあるだろうが、この点についてもSVNに分があるというのが一般的な認識だ。&lt;/p&gt;

&lt;p&gt;まあGitのGUIツールも&lt;a href=&#34;https://git-scm.com/docs/git-gui&#34;&gt;バンドルされてるやつ&lt;/a&gt;とか&lt;a href=&#34;https://tortoisegit.org/&#34;&gt;TortoiseGit&lt;/a&gt;とか&lt;a href=&#34;https://ja.atlassian.com/software/sourcetree&#34;&gt;SourceTree&lt;/a&gt;とか&lt;a href=&#34;https://www.gitkraken.com/&#34;&gt;イカ&lt;/a&gt;とか色々あるので、それで大分カバーできるだろうが。&lt;/p&gt;

&lt;h4 id=&#34;4-バイナリファイルの扱いが下手&#34;&gt;4. バイナリファイルの扱いが下手&lt;/h4&gt;

&lt;p&gt;Gitは基本的にテキストファイルを扱うよう作られていて、バイナリファイルの扱いは下手だ。
これはSVNも同じだけど、SVNの方がましらしい。&lt;/p&gt;

&lt;p&gt;例えば、バイナリファイルの同等の履歴を管理するのに、GitはSVNより少しだけ多くリポジトリ容量を食う。&lt;/p&gt;

&lt;p&gt;また、Gitはファイルのコンテンツに注目して管理するツールであるが、バイナリファイルは人間から見ると少しの変更(e.g. 画像の明度の変更)でもコンテンツが大きく変わるため、Gitが変更前のファイルと変更後のファイルを別のファイルとして扱ってしまうことがある。(最近のバージョンでは修正されているかも。)&lt;/p&gt;

&lt;p&gt;SVNはファイルそのものに注目しているので、その内容がどんなに劇的に変わっても見失うことはない。&lt;/p&gt;

&lt;p&gt;Gitでバイナリファイル、特にサイズが大きかったり頻繁に修正されるものを扱う必要があるときは、&lt;a href=&#34;https://git-annex.branchable.com/&#34;&gt;git-annex&lt;/a&gt;や&lt;a href=&#34;https://git-lfs.github.com/&#34;&gt;Git Large File Storage (LFS)&lt;/a&gt;の利用を検討すべし。&lt;/p&gt;

&lt;h4 id=&#34;5-アクセスコントロール機能がない&#34;&gt;5. アクセスコントロール機能がない&lt;/h4&gt;

&lt;p&gt;Git自身にはアクセスコントロール機能が全く実装されていない(多分)。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;clone&lt;/code&gt;するときなんかは、HTTPやSSHやTLSの力を借りてリポジトリ単位でのユーザ認証ができたり、&lt;code&gt;push&lt;/code&gt;するときにはファイルシステムのアクセスコントロールの力を借りて特定のファイルの変更を防いだりはできるが、もっと細かい制御をしたい場合は&lt;a href=&#34;https://github.com/sitaramc/gitolite&#34;&gt;Gitolite&lt;/a&gt;の力を借りる必要がある。&lt;/p&gt;

&lt;p&gt;借りてばっかだ。&lt;/p&gt;

&lt;p&gt;一方SVNは自前で&lt;a href=&#34;http://svnbook.red-bean.com/en/1.8/svn.serverconfig.pathbasedauthz.html&#34;&gt;Path-Based Authorization&lt;/a&gt;という機能を持っていて、ユーザ認証とディレクトリまたはファイル単位での読み書き制限ができる。&lt;/p&gt;

&lt;h4 id=&#34;6-ファイル単位の履歴を保持しない&#34;&gt;6. ファイル単位の履歴を保持しない&lt;/h4&gt;

&lt;p&gt;上にも書いたが、GitはSVNのようにファイル単位でバージョン管理をしているわけではないし、また、ファイルそのものではなくそのコンテンツに注目してバージョン管理する。この特徴のせいで、Gitはたまにファイルの行方を見失うことがある。&lt;/p&gt;

&lt;p&gt;上記バイナリファイルの問題もそうだし、テキストファイルでもリネームとコンテンツ変更を同時にやると&lt;code&gt;git log --follow&lt;/code&gt;で&lt;a href=&#34;https://svnvsgit.com/#losing-history-after-rename-in-Git&#34;&gt;ファイルの履歴が追えなくなる&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;SVNはリネームにちゃんと&lt;code&gt;svn mv&lt;/code&gt;を使っている限りファイルを見失うことはない。&lt;/p&gt;

&lt;p&gt;ただこれは実際、Gitのデメリットと言うよりは、GitとSVNの思想の違いと言った方がいいかもしれない。
&lt;code&gt;git log --follow&lt;/code&gt;は単に&lt;a href=&#34;http://stackoverflow.com/questions/5743739/how-to-really-show-logs-of-renamed-files-with-git&#34;&gt;SVNに慣れ親しんだGit初心者のための機能&lt;/a&gt;で、真のGit使いは特定のファイルの履歴を追うということを必要としない。&lt;/p&gt;

&lt;p&gt;ファイルの履歴を見たい煩悩に駆られたら、心を静め、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%AA%E3%83%BC%E3%83%8A%E3%82%B9%E3%83%BB%E3%83%88%E3%83%BC%E3%83%90%E3%83%AB%E3%82%BA&#34;&gt;神&lt;/a&gt;に祈りを捧げ、Gitのソースコードを写経し、Gitコマンドを108回たたいて悟りを開くべし。&lt;/p&gt;

&lt;h1 id=&#34;まとめ&#34;&gt;まとめ&lt;/h1&gt;

&lt;p&gt;Git派としてGit押しの記事を書こうと思っていたが、意外とデメリットもたくさん見えてきてしまった。
結局、GitとSVNどちらが単純に優れているということはないので、プロジェクトの構成やワークフローなどの要件を鑑みて使い分ければよしということか。&lt;/p&gt;

&lt;h1 id=&#34;参考資料&#34;&gt;参考資料&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873114408/&#34;&gt;蝙蝠本&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://git.wiki.kernel.org/index.php/GitSvnComparsion&#34;&gt;GitSvnComparison&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://svnvsgit.com/&#34;&gt;Subversion vs. Git: Myths and Facts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Pcap4J on Nano Server on Hyper-V Containers on Windows 10 on VMware Playerにトライ</title>
          <link>https://www.kaitoy.xyz/2016/09/15/pcap4j-on-hyper-v-container-on-win10/</link>
          <pubDate>Thu, 15 Sep 2016 13:56:35 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/09/15/pcap4j-on-hyper-v-container-on-win10/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;Pcap4J&lt;/a&gt;が動くHyper-VコンテナをWindows 10上でビルドしようとしたけど3合目あたりで息絶えた話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;hyper-v-containersとは&#34;&gt;Hyper-V Containersとは&lt;/h2&gt;

&lt;p&gt;Hyper-V Containersは、MicrosoftによるWindowsネイティブなコンテナ技術である&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/about/about_overview&#34;&gt;Windows Containers&lt;/a&gt;の一種で、これによるコンテナは、同じくWindows Containersの一種であるWindows Server Containersのものに比べて、より厳密に隔離されている分、起動コストが高い。&lt;/p&gt;

&lt;p&gt;実体は&lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt;そのもので、コンテナイメージは&lt;a href=&#34;https://hub.docker.com/&#34;&gt;Docker Hub&lt;/a&gt;からpullできるし、コンテナの操作や管理はdockerコマンドでやる。(昔はコンテナ操作用PowerShellコマンドレットもあったが、不評だったので廃止したようだ。)
&lt;a href=&#34;https://github.com/docker/docker&#34;&gt;ソース&lt;/a&gt;もLinuxとWindowsで一本化されている。&lt;/p&gt;

&lt;p&gt;Windows 10の&lt;a href=&#34;https://blogs.windows.com/japan/2016/08/03/how-to-get-the-windows-10-anniversary-update/#eFCYhK68sDp1V0F7.97&#34;&gt;Anniversary Update&lt;/a&gt;で正式にリリースされたが、なんだかあまり注目されていない気がする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2016/07/31/docker-for-windows/#docker-for-windows%E3%81%A8%E3%81%AF&#34;&gt;Docker for Windows&lt;/a&gt;とは全く別物なので注意。&lt;/p&gt;

&lt;h2 id=&#34;hyper-v-containersのインストール-on-vmware-player&#34;&gt;Hyper-V Containersのインストール (on VMware Player)&lt;/h2&gt;

&lt;p&gt;自前のPCが5年前に買った&lt;a href=&#34;https://dynabook.com/&#34;&gt;dynabook&lt;/a&gt;でWindows 10をサポートしていないので、VMware PlayerのVM上のWindows 10にHyper-V Containersをインストールしてみる。&lt;/p&gt;

&lt;p&gt;VMは、Windows 7に入れたVMware Workstation 11.1.0 build-2496824に付属の VMware Player 7.1.0 build-2496824で作ったもの。
VMのバージョンは11.0。
2CPUでメモリは2.5GB。
ネットワークインターフェースはNAT。
このVMを、&lt;a href=&#34;https://www.kaitoy.xyz/2016/07/31/docker-for-windows/#vmware-player%E3%81%AEvm%E3%81%A7hyper-v%E3%82%92%E4%BD%BF%E3%81%86%E3%81%9F%E3%82%81%E3%81%AE%E8%A8%AD%E5%AE%9A&#34;&gt;Hyper-Vが使えるように設定しておく&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://ascii.jp/elem/000/001/216/1216220/&#34;&gt;この記事&lt;/a&gt;にしたがい、Windows 10の評価版をダウンロード。
今公開されている評価版はAnniversary Update適用済みのバージョン1607で、Hyper-V Containersをサポートしている。&lt;/p&gt;

&lt;p&gt;これをさっき作ったVMにインストール。&lt;/p&gt;

&lt;p&gt;Windows 10を起動し、以下、&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/quick_start/quick_start_windows_10&#34;&gt;Windows Containers on Windows 10&lt;/a&gt;に従って進める。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;containers機能有効化&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.thewindowsclub.com/how-to-open-an-elevated-powershell-prompt-in-windows-10&#34;&gt;PowerShellプロンプトを管理者権限でひらき&lt;/a&gt;、以下のコマンドで&lt;code&gt;containers&lt;/code&gt;機能を有効化。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;Enable-WindowsOptionalFeature -Online -FeatureName containers -All
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1分程度経つと再起動を促されるので再起動。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Hyper-V機能有効化&lt;/p&gt;

&lt;p&gt;再度PowerShellプロンプトを管理者権限で開いて、以下のコマンドでHyper-Vを有効化。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V -All
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1分程度経つと再起動を促されるので再起動。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;OpLocks無効化&lt;/p&gt;

&lt;p&gt;現在のHyper-Vコンテナは、安定性を上げるためにOpLocksという機能を無効にすべきらしい。
再度PowerShellプロンプトを管理者権限で開いて、以下のコマンドを実行する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;Set-ItemProperty -Path &#39;HKLM:SOFTWARE\Microsoft\Windows NT\CurrentVersion\Virtualization\Containers&#39; -Name VSmbDisableOplocks -Type DWord -Value 1 -Force
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dockerインストール&lt;/p&gt;

&lt;p&gt;同じPowerShellプロンプトで以下のコマンドを実行してDocker(EngineとClient)のアーカイブをダウンロード。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;Invoke-WebRequest &amp;quot;https://master.dockerproject.org/windows/amd64/docker-1.13.0-dev.zip&amp;quot; -OutFile &amp;quot;$env:TEMP\docker-1.13.0-dev.zip&amp;quot; -UseBasicParsing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ダウンロードしたアーカイブを解凍。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;Expand-Archive -Path &amp;quot;$env:TEMP\docker-1.13.0-dev.zip&amp;quot; -DestinationPath $env:ProgramFiles
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここまででDockerが&lt;code&gt;C:\Program Files\docker\&lt;/code&gt;に入るので、このパスを環境変数&lt;code&gt;PATH&lt;/code&gt;に追加。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;PATH&lt;/code&gt;の変更を反映させるために再度PowerShellプロンプトを管理者権限で開いて、以下のコマンドでDockerデーモンをサービスに登録。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;dockerd --register-service
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dockerサービスを起動。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;Start-Service Docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(Dockerサービスは自動起動に設定されているので、OS再起動時は上記&lt;code&gt;Start-Service&lt;/code&gt;は不要。)&lt;/p&gt;

&lt;p&gt;これでDockerが使えるようになった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;docker version
Client:
 Version:      1.13.0-dev
 API version:  1.25
 Go version:   go1.7.1
 Git commit:   130db0a
 Built:        Sat Sep 10 13:25:48 2016
 OS/Arch:      windows/amd64


Server:
 Version:      1.13.0-dev
 API version:  1.25
 Go version:   go1.7.1
 Git commit:   130db0a
 Built:        Sat Sep 10 13:25:48 2016
 OS/Arch:      windows/amd64
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;コンテナイメージダウンロード&lt;/p&gt;

&lt;p&gt;どうもDockerコマンドの実行には管理者権限が必要なようなので、このまま管理者権限のPowerShellプロンプトで続ける。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker pull&lt;/code&gt;でNano Serverのコンテナイメージをダウンロード。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;docker pull microsoft/nanoserver
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;docker images&lt;/code&gt;で確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;docker images
REPOSITORY             TAG                 IMAGE ID            CREATED             SIZE
microsoft/nanoserver   latest              3a703c6e97a2        12 weeks ago        970 MB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;試しにコンテナ起動。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;PS C:\Windows\system32&amp;gt;docker run -it microsoft/nanoserver cmd&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;起動はかなり遅い。1分近くかかった。ともあれちゃんと起動した。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/pcap4j-on-hyper-v-container-on-win10/test_container.png&#34; alt=&#34;test_container.png&#34; /&gt;
&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;pcap4jコンテナのビルド&#34;&gt;Pcap4Jコンテナのビルド&lt;/h2&gt;

&lt;p&gt;Pcap4Jコンテナを、&lt;code&gt;docker build&lt;/code&gt;でビルドしてみる。
Dockerfileはとりあえず&lt;a href=&#34;https://www.kaitoy.xyz/2016/07/11/windows_containers_on_tp5/#pcap4j%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A%E3%82%A4%E3%83%A1%E3%83%BC%E3%82%B8%E3%81%AE%E3%83%93%E3%83%AB%E3%83%89&#34;&gt;以前のもの&lt;/a&gt;をちょっと書き変えただけのものを試す。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-dockerfile&#34;&gt;# escape=`

#
# Dockerfile for Pcap4J on Windows Nano Server
#

FROM microsoft/nanoserver
MAINTAINER Kaito Yamada &amp;lt;kaitoy@pcap4j.org&amp;gt;

# Install Chocolatey.
RUN mkdir C:\pcap4j
WORKDIR C:\\pcap4j
ADD https://chocolatey.org/install.ps1 install.ps1
RUN powershell .\install.ps1

# Install dependencies.
RUN choco install -y nmap jdk7 &amp;amp;&amp;amp; `
    choco install -y maven -version 3.2.5

# Build Pcap4J.
RUN powershell -Command Invoke-WebRequest https://github.com/kaitoy/pcap4j/archive/v1.zip -OutFile pcap4j.zip &amp;amp;&amp;amp; `
    powershell -Command Expand-Archive -Path pcap4j.zip -DestinationPath .
WORKDIR pcap4j-1
RUN powershell -Command &amp;quot;mvn -P distribution-assembly install 2&amp;gt;&amp;amp;1 | Add-Content -Path build.log -PassThru&amp;quot;

# Collect libraries.
RUN mkdir bin &amp;amp;&amp;amp; `
    cd pcap4j-packetfactory-static &amp;amp;&amp;amp; `
    mvn -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeScope=compile dependency:copy-dependencies &amp;amp;&amp;amp; `
    mvn -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeGroupIds=ch.qos.logback dependency:copy-dependencies &amp;amp;&amp;amp; `
    cd ../pcap4j-distribution &amp;amp;&amp;amp; `
    mvn -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeArtifactIds=pcap4j-packetfactory-static,pcap4j-sample dependency:copy-dependencies

# Generate sample script. (C:\pcap4j\pcap4j-1\bin\capture.bat)
RUN echo @echo off &amp;gt; bin\capture.bat &amp;amp;&amp;amp; `
    echo &amp;quot;%JAVA_HOME%\bin\java&amp;quot; -cp C:\pcap4j\pcap4j-1\bin\pcap4j-core.jar;C:\pcap4j\pcap4j-1\bin\pcap4j-packetfactory-static.jar;C:\pcap4j\pcap4j-1\bin\pcap4j-sample.jar;C:\pcap4j\pcap4j-1\bin\jna.jar;C:\pcap4j\pcap4j-1\bin\slf4j-api.jar;C:\pcap4j\pcap4j-1\bin\logback-classic.jar;C:\pcap4j\pcap4j-1\bin\logback-core.jar org.pcap4j.sample.GetNextPacketEx &amp;gt;&amp;gt; bin\capture.bat
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#/escape&#34;&gt;escapeディレクティブ&lt;/a&gt;が使えるようになっていたので使うようにしている。
(というか以前Windows Server 2016 TP5で試した時はescapeディレクティブをDockerfileの先頭に書かなかったのがだめだったってだけかもしれない。)
&lt;code&gt;WORKDIR&lt;/code&gt;のパスの区切りにはescapeディレクティブは利かない変な仕様。&lt;/p&gt;

&lt;h4 id=&#34;nano-serverでsystem-net-webclient使えない問題&#34;&gt;Nano ServerでSystem.Net.WebClient使えない問題&lt;/h4&gt;

&lt;p&gt;このDockerfileでビルドしたら、&lt;a href=&#34;https://chocolatey.org/&#34;&gt;Chocolatey&lt;/a&gt;のダウンロード・インストールスクリプトを実行する&lt;code&gt;RUN powershell .\install.ps1&lt;/code&gt;のステップで&lt;code&gt;System.Net.WebClient&lt;/code&gt;が見つからないというエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;new-object : Cannot find type [System.Net.WebClient]: verify that the assembly
containing this type is loaded.
At C:\pcap4j\install.ps1:84 char:17
+   $downloader = new-object System.Net.WebClient
+                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : InvalidType: (:) [New-Object], PSArgumentExcepti
   on
    + FullyQualifiedErrorId : TypeNotFound,Microsoft.PowerShell.Commands.NewOb
   jectCommand
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nano Serverに入っているPowerShellは&lt;a href=&#34;https://technet.microsoft.com/en-us/windows-server-docs/compute/nano-server/powershell-on-nano-server&#34;&gt;Core Editionなる機能限定版&lt;/a&gt;で、System.Net.WebClientだけでなく、&lt;a href=&#34;http://serverfault.com/questions/788949/download-a-file-with-powershell-on-nano-server&#34;&gt;WebアクセスのためのAPIがいろいろ欠けているもよう&lt;/a&gt;。&lt;/p&gt;

&lt;h4 id=&#34;hyper-v-containersでserver-core使えない問題&#34;&gt;Hyper-V ContainersでServer Core使えない問題&lt;/h4&gt;

&lt;p&gt;Nano Serverめんどくさそうなので、Server Coreをpullする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Windows\system32&amp;gt;docker pull microsoft/windowsservercore
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dockerfileの&lt;code&gt;FROM&lt;/code&gt;を&lt;code&gt;microsoft/windowsservercore&lt;/code&gt;に書き変えてビルドしたら、最初の&lt;code&gt;RUN&lt;/code&gt;で以下のエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;container 4bc8d8d38993426fa7a3c76e4aabbe6a229cbd025754723ff396aec04ffbfa1d encountered an error during Start failed in Win32: The operating system of the container does not match the operating system of the host. (0xc0370101)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;調べたら、Hyper-V Containersはまだ&lt;a href=&#34;https://social.msdn.microsoft.com/Forums/en-US/9eea93ac-18de-4953-bc7c-efd76a155526/are-microsoftwindowsservercore-containers-working-on-windows-10?forum=windowscontainers&#34;&gt;Nano Serverしかサポートしていない&lt;/a&gt;ようだ。&lt;/p&gt;

&lt;h4 id=&#34;unzip難しい問題&#34;&gt;unzip難しい問題&lt;/h4&gt;

&lt;p&gt;Chocolateyのダウンロード・インストールスクリプトを実行するのはあきらめて、&lt;a href=&#34;https://chocolatey.org/install#download-powershell-method&#34;&gt;アーカイブを自分でダウンロードする方法&lt;/a&gt;を試す。&lt;/p&gt;

&lt;p&gt;これは&lt;code&gt;https://chocolatey.org/api/v2/package/chocolatey/&lt;/code&gt;というWeb APIをたたいてアーカイブをダウンロードする方法だけど、このURLを&lt;code&gt;ADD&lt;/code&gt;に渡してもうまくいかなかったので、このWeb APIが最終的に呼ぶ&lt;code&gt;https://packages.chocolatey.org/chocolatey.0.10.0.nupkg&lt;/code&gt;を&lt;code&gt;ADD&lt;/code&gt;するようにした。
これでダウンロードできる&lt;code&gt;chocolatey.0.10.0.nupkg&lt;/code&gt;はzipファイルで、unzipするとインストールスクリプトが出てくる。&lt;/p&gt;

&lt;p&gt;しかしこのunzipが曲者で、&lt;a href=&#34;https://www.kaitoy.xyz/2016/09/12/unzip-on-nanoserver/&#34;&gt;妙に苦労した話&lt;/a&gt;を最近書いた。&lt;/p&gt;

&lt;p&gt;で、苦労して取り出したインストールスクリプトを実行したら、エラーがわんさと出ただけだった。
そんなこったろうと思ってはいたが。&lt;/p&gt;

&lt;p&gt;どうせChocolateyをインストールできても、パッケージのインストールスクリプトがまた動かないんだろうから、もうChocolateyはあきらめる。&lt;/p&gt;

&lt;h4 id=&#34;wow64サポートしてない問題&#34;&gt;WoW64サポートしてない問題&lt;/h4&gt;

&lt;p&gt;Chocolateyを使わないようにDockerfileの前半を以下の様に書き変えた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-dockerfile&#34;&gt;(snip)

FROM michaeltlombardi/nanoserveropenjdk
MAINTAINER Kaito Yamada &amp;lt;kaitoy@pcap4j.org&amp;gt;

RUN mkdir C:\pcap4j
WORKDIR C:\\pcap4j

# Install Maven
ADD http://archive.apache.org/dist/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.zip maven.zip
RUN jar xf maven.zip
RUN powershell -command $env:path += &#39;;C:\pcap4j\apache-maven-3.3.9\bin&#39;; setx PATH $env:path /M

# Install Npcap
ADD https://github.com/nmap/npcap/releases/download/v0.08-r7/npcap-0.08-r7.exe npcap.exe
RUN npcap.exe /S

# Build Pcap4J.

(snip)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(因みにこの時点で、&lt;code&gt;PATH&lt;/code&gt;を設定するのに&lt;code&gt;GetEnvironmentVariable&lt;/code&gt;と&lt;code&gt;SetEnvironmentVariable&lt;/code&gt;がうまく使えない問題を乗り越えている。&lt;code&gt;Cannot find an overload for &amp;quot;GetEnvironmentVariable&amp;quot; and the argument count: &amp;quot;2&amp;quot;.&lt;/code&gt;というエラーが出て、PowerShell Desktop Editionのものと仕様がちょっと違うようだったので、&lt;code&gt;GetEnvironmentVariable&lt;/code&gt;も&lt;code&gt;SetEnvironmentVariable&lt;/code&gt;も使わないようにした。)&lt;/p&gt;

&lt;p&gt;このDockerfileでビルドしたら、&lt;code&gt;RUN npcap.exe /S&lt;/code&gt;で以下のエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;The subsystem needed to support the image type is not present.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このsubsystemというのはどうも&lt;a href=&#34;https://ja.wikipedia.org/wiki/WOW64&#34;&gt;WoW64&lt;/a&gt;を指しているようで、&lt;a href=&#34;https://blogs.technet.microsoft.com/windowsserver/2016/02/10/exploring-nano-server-for-windows-server-2016/&#34;&gt;Nano ServerがWoW64をサポートしていない&lt;/a&gt;のにnpcap.exeが32bitバイナリであることが問題のようであった。&lt;/p&gt;

&lt;p&gt;ついでに&lt;a href=&#34;https://ja.wikipedia.org/wiki/Microsoft_Windows_Installer&#34;&gt;MSI&lt;/a&gt;もサポートされていないことがわかった。大丈夫かこれ。&lt;/p&gt;

&lt;h4 id=&#34;nano-serverパッケージプロバイダバグってる問題&#34;&gt;Nano Serverパッケージプロバイダバグってる問題&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://technet.microsoft.com/en-us/windows-server-docs/compute/nano-server/getting-started-with-nano-server#a-namebkmkonlineainstalling-roles-and-features-online&#34;&gt;Nano Serverにもロールや機能の追加ができる&lt;/a&gt;らしいので、ひょっとしてこれで何か改善できないかと思って試した。&lt;/p&gt;

&lt;p&gt;Nano Serverへのロール・機能の追加は、Windowsのパッケージマネジメントシステムである&lt;a href=&#34;https://github.com/OneGet/oneget&#34;&gt;PackageManagement (a.k.a. OneGet)&lt;/a&gt;を使ってやる。PowerShellで&lt;code&gt;Install-PackageProvider NanoServerPackage&lt;/code&gt;と&lt;code&gt;Import-PackageProvider NanoServerPackage&lt;/code&gt;を実行するとNano Serverのパッケージプロバイダが使えるようになり、&lt;code&gt;Find-NanoServerPackage&lt;/code&gt;で利用できるパッケージの一覧が見れる。&lt;/p&gt;

&lt;p&gt;はずなんだけど、&lt;code&gt;Find-NanoServerPackage&lt;/code&gt;でエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;C:\pcap4j&amp;gt;powershell -command Find-NanoServerPackage
DownloadFile : Save-HTTPItem: Bits Transfer failed. Job State:  ExitCode = 255
At C:\Program Files\WindowsPowerShell\Modules\NanoServerPackage\0.1.1.0\NanoServerPackage.psm1:1294 char:9
+         DownloadFile -downloadURL $fullUrl `
+         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : InvalidOperation: (https://nanoser...ServerIndex.txt:String) [DownloadFile], RuntimeException
    + FullyQualifiedErrorId : FailedToDownload,DownloadFile

Get-Content : Cannot find drive. A drive with the name &#39;CleanUp&#39; does not exist.
At C:\Program Files\WindowsPowerShell\Modules\NanoServerPackage\0.1.1.0\NanoServerPackage.psm1:674 char:26
+     $searchFileContent = Get-Content $searchFile
+                          ~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : ObjectNotFound: (CleanUp:String) [Get-Content], DriveNotFoundException
    + FullyQualifiedErrorId : DriveNotFound,Microsoft.PowerShell.Commands.GetContentCommand

Get-Content : Cannot find path
&#39;C:\Users\ContainerAdministrator\AppData\Local\NanoServerPackageProvider\searchNanoPackageIndex.txt&#39; because it does not exist.
At C:\Program Files\WindowsPowerShell\Modules\NanoServerPackage\0.1.1.0\NanoServerPackage.psm1:674 char:26
+     $searchFileContent = Get-Content $searchFile
+                          ~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : ObjectNotFound: (C:\Users\Contai...ackageIndex.txt:String) [Get-Content], ItemNotFoundException
    + FullyQualifiedErrorId : PathNotFound,Microsoft.PowerShell.Commands.GetContentCommand
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/OneGet/NanoServerPackage/issues/4&#34;&gt;NanoServerPackageのIssues&lt;/a&gt;にこのエラーが登録されていた。1か月放置されてる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;パトラッシュ、僕はもう疲れたよ。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Hyper-Vコンテナ(Nano Server)でunzipしたいならjarを使え</title>
          <link>https://www.kaitoy.xyz/2016/09/12/unzip-on-nanoserver/</link>
          <pubDate>Mon, 12 Sep 2016 16:46:54 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/09/12/unzip-on-nanoserver/</guid>
          <description>

&lt;p&gt;Nano Serverでunzipしたかっただけだったのに、妙に苦労した話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;nano-serverとは&#34;&gt;Nano Serverとは&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://technet.microsoft.com/en-us/windows-server-docs/compute/nano-server/getting-started-with-nano-server&#34;&gt;Nano Server&lt;/a&gt;は、Windows Server 2016で追加されるWindows Serverの新たなインストール形式で、&lt;a href=&#34;https://en.wikipedia.org/wiki/Server_Core&#34;&gt;Server Core&lt;/a&gt;よりさらに機能を絞り、リモートで管理するクラウドホストやWebサーバ向けにに特化したもの。&lt;/p&gt;

&lt;p&gt;Server Coreが数GBくらいなのに対し、Nano Serverは数百MBととても軽量で、それゆえ起動が速くセキュア。&lt;/p&gt;

&lt;h2 id=&#34;unzipとは&#34;&gt;unzipとは&lt;/h2&gt;

&lt;p&gt;unzipとは、&lt;a href=&#34;https://ja.wikipedia.org/wiki/ZIP_(%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%83%95%E3%82%A9%E3%83%BC%E3%83%9E%E3%83%83%E3%83%88&#34;&gt;zip&lt;/a&gt;ファイルを解凍する、ただそれだけのこと。&lt;/p&gt;

&lt;p&gt;ただそれだけのことで、基本的な機能だと思うのだが、Windowsはこれを&lt;a href=&#34;https://technet.microsoft.com/en-us/library/dn841359.aspx&#34;&gt;コマンドラインで実行する方法&lt;/a&gt;をつい最近まで正式に提供していなかった。&lt;/p&gt;

&lt;h2 id=&#34;nano-serverでunzip&#34;&gt;Nano Serverでunzip&lt;/h2&gt;

&lt;p&gt;Windows 10の&lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#windows-containers%E3%81%A8%E3%81%AF&#34;&gt;Hyper-V Containers&lt;/a&gt;の上で&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;Pcap4J&lt;/a&gt;のビルドとテストをするDockerイメージをビルドしたくて、そのための依存ライブラリなどをインストールする処理をDockerfileに書いていて、&lt;code&gt;ADD&lt;/code&gt;でzipをダウンロードしたところまではいいんだけど、このzipどうやって解凍してやろうかとなった。
(Dockerホストに置いたものをコンテナに&lt;code&gt;ADD&lt;/code&gt;するのはなんか格好悪いから無しで。Dockerfile裸一貫で実現したい。)&lt;/p&gt;

&lt;p&gt;Windows 10のHyper-V Containersは、&lt;a href=&#34;https://social.msdn.microsoft.com/Forums/en-US/9eea93ac-18de-4953-bc7c-efd76a155526/are-microsoftwindowsservercore-containers-working-on-windows-10?forum=windowscontainers&#34;&gt;現時点でNano Serverしかサポートしていない&lt;/a&gt;のが厳しい点。Server Coreだったら楽だったのに。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以下、いろいろ試したことを書く。&lt;/p&gt;

&lt;h4 id=&#34;正攻法-expand-archive&#34;&gt;正攻法: Expand-Archive&lt;/h4&gt;

&lt;p&gt;PowerShellの v5 で実装されたExpand-Archiveというコマンドレットでzipを解凍できる。
Nano ServerのPowerShellのバージョンを確認したら 5.1 だったのでこれでいけるかと思った。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\&amp;gt;powershell -command &amp;quot;$PSVersionTable.PSVersion&amp;quot;

Major  Minor  Build  Revision
-----  -----  -----  --------
5      1      14284  1000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;したらこのエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Add-Type : Cannot find path &#39;C:\System.IO.Compression.FileSystem.dll&#39; because it does not exist.
At
C:\windows\system32\windowspowershell\v1.0\Modules\Microsoft.PowerShell.Archive\Microsoft.PowerShell.Archive.psm1:914
char:5
+     Add-Type -AssemblyName System.IO.Compression.FileSystem
+     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : ObjectNotFound: (C:\System.IO.Compression.FileSystem.dll:String) [Add-Type], ItemNotFoun
   dException
    + FullyQualifiedErrorId : PathNotFound,Microsoft.PowerShell.Commands.AddTypeCommand
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;どうもPowerShellの 5.1 以降には、.NET FrameworkベースのDesktop Editionと、そこから機能を絞った.NET CoreベースのCore Editionがあり、&lt;a href=&#34;https://technet.microsoft.com/en-us/windows-server-docs/compute/nano-server/powershell-on-nano-server&#34;&gt;Nano ServerのはCore Editionなんだそうな&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;Expand-ArchiveはSystem.IO.Compression.FileSystem.dllの中のZipFileクラスに依存しているんだけど、.NET CoreにはSystem.IO.Compression.FileSystem.dllが含まれていないっぽい。&lt;/p&gt;

&lt;h4 id=&#34;shellオブジェクトのcopyhere&#34;&gt;ShellオブジェクトのCopyHere&lt;/h4&gt;

&lt;p&gt;PowerShellでのunzip方法を調べたらStack Overflowに&lt;a href=&#34;http://stackoverflow.com/questions/27768303/how-to-unzip-a-file-in-powershell&#34;&gt;いくつか載っていた&lt;/a&gt;。
Expand-Archiveと、System.IO.Compression.ZipFileを直接使う方法と、Shellオブジェクト(COMオブジェクト)のCopyHereメソッドを使う方法。&lt;/p&gt;

&lt;p&gt;最初の2つはCore Editionでは使えないことが分かっているので、3つめにトライ。
こんなの↓&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;$shell = New-Object -ComObject shell.application
$zip = $shell.NameSpace(&amp;quot;C:\a.zip&amp;quot;)
MkDir(&amp;quot;C:\a&amp;quot;)
foreach ($item in $zip.items()) {
  $shell.Namespace(&amp;quot;C:\a&amp;quot;).CopyHere($item)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;調べたらこの方法は&lt;a href=&#34;https://support.microsoft.com/ja-jp/kb/2679832&#34;&gt;Microsoftから非推奨にされている&lt;/a&gt;ことが分かったんだけど、一応やってみる。&lt;/p&gt;

&lt;p&gt;したら以下のエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;new-object : Retrieving the COM class factory for component with CLSID {00000000-0000-0000-0000-000000000000} failed
due to the following error: 80040154 Class not registered (Exception from HRESULT: 0x80040154 (REGDB_E_CLASSNOTREG)).
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この方法で利用しようとしているのは&lt;a href=&#34;https://en.wikipedia.org/wiki/Windows_shell&#34;&gt;Windows shell&lt;/a&gt;、つまり&lt;a href=&#34;https://ja.wikipedia.org/wiki/Windows_Explorer&#34;&gt;Windows Explorer&lt;/a&gt;の機能らしく、そうであればまあGUIがないNano Serverで動かないのも当然か。&lt;/p&gt;

&lt;h4 id=&#34;サードパーティツールに頼る&#34;&gt;サードパーティツールに頼る&lt;/h4&gt;

&lt;p&gt;Stack Overflowの&lt;a href=&#34;http://stackoverflow.com/questions/1021557/how-to-unzip-a-file-using-the-command-line&#34;&gt;別の質問&lt;/a&gt;にサードパーティツールに頼る方法がいくつか紹介されていた。&lt;/p&gt;

&lt;p&gt;ここで挙げられていたもののうち、&lt;a href=&#34;http://www.7-zip.org/download.html&#34;&gt;7-Zip&lt;/a&gt;、&lt;a href=&#34;http://www.freebyte.com/fbzip/&#34;&gt;Freebyte Zip&lt;/a&gt;、&lt;a href=&#34;http://infozip.sourceforge.net/&#34;&gt;Info-ZIP&lt;/a&gt;は、配布形式がダメ。&lt;/p&gt;

&lt;p&gt;7-Zipのインストーラをコンテナで実行してみたら、「The subsystem needed to support the image type is not present.」というエラー。7-Zipにはzipで配布されているものもあるんだけど、皮肉としか思えない。&lt;/p&gt;

&lt;p&gt;Freebyte ZipやInfo-ZIPの自己解凍ファイルもコンテナ内では動いてくれない。&lt;/p&gt;

&lt;p&gt;一方、&lt;a href=&#34;http://membrane.com/synapse/library/pkunzip.html&#34;&gt;pkunzip&lt;/a&gt;はコマンドが裸で配布されているので行けるかと思ったが、実行したら「The system cannot execute the specified program.」なるエラー。
よく見たらこれ16bitアプリケーション。Nano Serverは32bitアプリすら実行できないというのに。&lt;/p&gt;

&lt;h4 id=&#34;jarに託された最後の希望&#34;&gt;jarに託された最後の希望&lt;/h4&gt;

&lt;p&gt;上に貼ったStack Overflowの質問には&lt;a href=&#34;https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jar.html&#34;&gt;jarコマンド&lt;/a&gt;を使う方法も挙げられていたが、JDKなんてどうせインストールできないとあきらめていた。&lt;/p&gt;

&lt;p&gt;が、ふと思い立って&lt;a href=&#34;https://hub.docker.com/&#34;&gt;Docker Hub&lt;/a&gt;を検索してみたら、&lt;a href=&#34;https://hub.docker.com/r/michaeltlombardi/nanoserveropenjdk/&#34;&gt;OpenJDK入りのNano Server&lt;/a&gt;をアップしてくれている人がいた。&lt;/p&gt;

&lt;p&gt;pullしてrunしてみたら確かにJDKがインストールされていた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\&amp;gt;java -version
openjdk version &amp;quot;1.8.0_102-1-ojdkbuild&amp;quot;
OpenJDK Runtime Environment (build 1.8.0_102-1-ojdkbuild-b14)
OpenJDK 64-Bit Server VM (build 25.102-b14, mixed mode)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、無事&lt;code&gt;&amp;quot;C:\Program Files\Java\bin\jar.exe&amp;quot; xf hoge.zip&lt;/code&gt;のようにしてunzipできた。&lt;/p&gt;

&lt;p&gt;ここまで1日かかった。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>オープンソースプロジェクトのすゝめ</title>
          <link>https://www.kaitoy.xyz/2016/08/21/an-encouragement-of-open-sourcing/</link>
          <pubDate>Sun, 21 Aug 2016 20:54:12 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/08/21/an-encouragement-of-open-sourcing/</guid>
          <description>

&lt;p&gt;&lt;strong&gt;&lt;em&gt;人は生まれながらにして貴賤の別なく、ただオープンソースプロジェクトを勤めて物事をよく知る者が貴人となるなり。&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;昔、偉い人がそんな感じのことを言っていたような。&lt;/p&gt;

&lt;p&gt;私がGitHubで開発しているライブラリ、&lt;strong&gt;&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;Pcap4J&lt;/a&gt;&lt;/strong&gt; のスターの数がつい先日 &lt;strong&gt;200&lt;/strong&gt; に達したのを記念して、これまでどんな活動をしてきたか、この活動によって何を得たかなどについて書きたい。&lt;/p&gt;

&lt;p&gt;願わくは、この記事に触発されてオープンソースプロジェクトを始める人のあらんことを。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;pcap4jとは&#34;&gt;Pcap4Jとは？&lt;/h2&gt;

&lt;p&gt;Pcap4Jは、パケットキャプチャとパケット解析をするJavaのライブラリ。
ニッチ。&lt;/p&gt;

&lt;p&gt;ただ最近になってビッグデータ解析技術が発達し、大量のパケットをリアルタイムで解析してシステムや運用にフィードバックするというのが現実的になってきたので、パケットキャプチャへの注目が高まってきている雰囲気がある。
こういう分野ではJavaがまだかなり人気なのもあってワンチャンある。&lt;/p&gt;

&lt;p&gt;パケットキャプチャの部分は &lt;strong&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/Pcap&#34;&gt;pcap&lt;/a&gt;&lt;/strong&gt; のラッパ。
パケット解析の部分は割とプラガブルで、外からプロトコル追加などのカスタマイズができるはできるんだけど、作りのせいなのかJavaなせいなのか解析器を書くのが結構つらい。&lt;/p&gt;

&lt;p&gt;競合は &lt;strong&gt;&lt;a href=&#34;http://jpcap.sourceforge.net/&#34;&gt;jpcap&lt;/a&gt;&lt;/strong&gt; や &lt;strong&gt;&lt;a href=&#34;http://jnetpcap.com/&#34;&gt;jNetPcap&lt;/a&gt;&lt;/strong&gt; など。
Google.comで&lt;code&gt;java packet capture&lt;/code&gt;と検索するとだいたいjpcap、Pcap4J、jNetPcapの順で表示される。&lt;/p&gt;

&lt;p&gt;打倒jpcap。&lt;/p&gt;

&lt;h2 id=&#34;数字で見るpcap4jプロジェクト&#34;&gt;数字で見るPcap4Jプロジェクト&lt;/h2&gt;

&lt;p&gt;Pcap4Jリポジトリの一番古いコミットは &lt;strong&gt;2011/12/18&lt;/strong&gt;。
東日本大震災後の節電施策として実施された休日シフト中にコーディングしていた覚えがあるので、多分2011年夏くらいから開発していたんだけど、とりあえずこの最古のコミットをプロジェクトの開始とすると、スターが200になった &lt;strong&gt;2016/8/11&lt;/strong&gt; まで &lt;strong&gt;1698日&lt;/strong&gt; かかったことになる。
約 &lt;strong&gt;0.118個/日&lt;/strong&gt;。遅い…&lt;/p&gt;

&lt;p&gt;コミット数は &lt;strong&gt;559個&lt;/strong&gt;。ほとんどが自前のコミット。
プロジェクト成長過程の動画を &lt;strong&gt;&lt;a href=&#34;http://gource.io/&#34;&gt;Gource&lt;/a&gt;&lt;/strong&gt; というツールで生成してみたが、一人でかけずりまわっているのがよく分かる。&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;embed video-player&#34; style=&#34;text-align: center&#34;&gt;
  &lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;320&#34; height=&#34;193&#34; src=&#34;https://www.youtube.com/embed/VFjNOTGbBhA&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;コミット頻度は約 &lt;strong&gt;0.33個/日&lt;/strong&gt; で、だいたい3日に1コミット。
思っていたより多いけど、胸張れるほどの頻度ではない。&lt;/p&gt;

&lt;p&gt;リリースは &lt;strong&gt;17個&lt;/strong&gt; で、約 &lt;strong&gt;0.30個/月&lt;/strong&gt;。少ない…&lt;/p&gt;

&lt;p&gt;Issuesが &lt;strong&gt;52個&lt;/strong&gt;、Pull requestsが &lt;strong&gt;16個&lt;/strong&gt;。
自分ではIssuesもPull requestsもあまり作らないので、ほとんどが他人からのもの。
ちゃんとチケット駆動にしてトレーサビリティを確保しておくべきだったと後悔している。
けど面倒だし今更なので今後も適当にコミットしちゃう。&lt;/p&gt;

&lt;p&gt;あとはWatchが &lt;strong&gt;28人&lt;/strong&gt;、Forkが &lt;strong&gt;66個&lt;/strong&gt;、コントリビュータが &lt;strong&gt;7人&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&#34;スター200ってどうなの&#34;&gt;スター200ってどうなの?&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/jquery/jquery&#34;&gt;jQuery&lt;/a&gt;や&lt;a href=&#34;https://facebook.github.io/react/&#34;&gt;React&lt;/a&gt;なんてスター40000超えてるし、Javaなら&lt;a href=&#34;http://projects.spring.io/spring-framework/&#34;&gt;Spring Framework&lt;/a&gt;も10000に達しようとしている。200なんて全然大したことなくない?
と言う声が聞こえるようだが、そんな知らない人を探すのが難しいようなプロジェクトと比べてはいけない。&lt;/p&gt;

&lt;p&gt;スター200以上のプロジェクトは割合でみるととても少ない。&lt;/p&gt;

&lt;p&gt;現在GitHubがホストしてる全プロジェクトは &lt;strong&gt;14,308,407&lt;/strong&gt; 個。
Javaプロジェクトはその内二番目に大きい割合を占めていて &lt;strong&gt;1,501,840&lt;/strong&gt; 個 (約 &lt;strong&gt;10.5%&lt;/strong&gt; )。&lt;/p&gt;

&lt;div style=&#34;max-width: 600px; margin: 0 auto; text-align: center;&#34;&gt;
&lt;caption&gt;&lt;b&gt;GitHubのプロジェクト数 (言語別降順)&lt;/b&gt;&lt;/caption&gt;
&lt;canvas id=&#34;an-encouragement-of-open-sourcing-chart-1&#34;&gt;&lt;/canvas&gt;
(凡例をクリックして除外。グラフにホバーして値表示。)
&lt;/div&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;スター200以上のプロジェクトは &lt;strong&gt;37,031&lt;/strong&gt; 個で、全プロジェクト中、上位約 &lt;strong&gt;0.26%&lt;/strong&gt; に当たる。&lt;/p&gt;

&lt;p&gt;スター200以上のJavaプロジェクトは &lt;strong&gt;3,922&lt;/strong&gt; 個で、全Javaプロジェクト中、上位約 &lt;strong&gt;0.26%&lt;/strong&gt; に当たる。&lt;/p&gt;

&lt;div style=&#34;max-width: 600px; margin: 0 auto; text-align: center;&#34;&gt;
&lt;caption&gt;&lt;b&gt;GitHubのプロジェクト数 (スター数別降順)&lt;/b&gt;&lt;/caption&gt;
&lt;canvas id=&#34;an-encouragement-of-open-sourcing-chart-2&#34;&gt;&lt;/canvas&gt;
(凡例をクリックして除外。グラフにホバーして値表示。)
&lt;/div&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;div style=&#34;max-width: 600px; margin: 0 auto; text-align: center;&#34;&gt;
&lt;caption&gt;&lt;b&gt;GitHubのJavaプロジェクト数 (スター数別降順)&lt;/b&gt;&lt;/caption&gt;
&lt;canvas id=&#34;an-encouragement-of-open-sourcing-chart-3&#34;&gt;&lt;/canvas&gt;
(凡例をクリックして除外。グラフにホバーして値表示。)
&lt;/div&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;無名の個人にとっては、スター200、というかとりあえず100くらいは手ごろで手ごたえのある目標だ。&lt;/p&gt;

&lt;h2 id=&#34;オープンソースプロジェクトの育て方&#34;&gt;オープンソースプロジェクトの育て方&lt;/h2&gt;

&lt;p&gt;GitHubのスターの数というのはそのプロジェクトを気に入ってくれた人の数である。
この数はそのプロジェクトの成果物を実際に使ってくれている人や組織の数、つまり普及率と正の相関があるはずだ。
成果物の普及率はプロジェクトの成長度のひとつの指標であり、スターの増加を見るのはわが子のようなプロジェクトの成長を見るようでとても楽しい。&lt;/p&gt;

&lt;p&gt;ここでは、私がPcap4Jプロジェクトを育てるためにやったことと、やってないけどやるべきだと思っていることなどについて書く。
Pcap4Jはライブラリなので、アプリとかよりもライブラリよりの話が多めかも。&lt;/p&gt;

&lt;h4 id=&#34;未解決の問題を探す&#34;&gt;未解決の問題を探す&lt;/h4&gt;

&lt;p&gt;Pcap4Jプロジェクトを始める前は、競合を調べ、それらとの差別化を考えた。
他のプロジェクトが既に解決している問題を同じように解決したのでは魅力が出ない。
機能なり、性能なり、ユーザビリティなり、デザインなり、サポートプラットフォームなり、何かしらの点で競合より優れていたり、競合にないものを持っていることが重要。
そうでなければ作っていても面白くないし、モチベーションも続かない。&lt;/p&gt;

&lt;p&gt;まだ解決されていない問題を見つけたり、使っているアプリに不満を感じたら、新しいアプリやライブラリやプラグインを自分で作るチャンスととらえるべし。&lt;/p&gt;

&lt;h4 id=&#34;apiを練る&#34;&gt;APIを練る&lt;/h4&gt;

&lt;p&gt;Pcap4Jの開発を始めて、一番頭を使ったのがAPI設計。
分かりやすく、汎用的で、シンプルで、つまり使いやすいAPIを実装すべきことは言うまでもない。
APIがころころ変わるのはユーザにとても嫌がられるので、長い目で見ても問題なさそうな、拡張もしやすそうなAPIを設計すべし。
自分でそのライブラリを使ったアプリを作ってみると、ユーザ視点でAPIを評価できるのでよい。&lt;/p&gt;

&lt;p&gt;逆に、内部の設計はAPIに比べたらそんなに重要じゃない。
10年前の技術を使ったイモい実装でもいい。
とりあえずリリースして、&lt;a href=&#34;http://qiita.com/erukiti/items/9cc7850250268582dde7&#34;&gt;技術的負債&lt;/a&gt;として後で済し崩せばよし。&lt;/p&gt;

&lt;h4 id=&#34;githubに上げる&#34;&gt;GitHubに上げる&lt;/h4&gt;

&lt;p&gt;ある程度コードが書けたらどこかに公開するわけだけど、パブリックなリポジトリなら &lt;strong&gt;&lt;a href=&#34;https://github.com/&#34;&gt;GitHub&lt;/a&gt;&lt;/strong&gt; 一択。&lt;/p&gt;

&lt;p&gt;今の時代、猫も杓子も&lt;a href=&#34;https://github.com/google&#34;&gt;Google&lt;/a&gt;も&lt;a href=&#34;https://github.com/Microsoft&#34;&gt;Microsoft&lt;/a&gt;も&lt;a href=&#34;https://github.com/apple&#34;&gt;Apple&lt;/a&gt;も、ソースを公開すると言ったらGitHubだ。
迷うことはない。&lt;/p&gt;

&lt;p&gt;(弊社も最近&lt;a href=&#34;https://github.com/Hitachi&#34;&gt;組織アカウント&lt;/a&gt;を作ったようだ。知らなかった。)&lt;/p&gt;

&lt;h4 id=&#34;ドキュメントを充実させる-英語で&#34;&gt;ドキュメントを充実させる (英語で)&lt;/h4&gt;

&lt;p&gt;Pcap4JのREADME.mdやドキュメントは、大変だったけど最初から英語と日本語で書いた。
英語がメイン。&lt;/p&gt;

&lt;p&gt;英語は世界でもっとも多く使われている言語で、8.5億人が日常的に話す。実用レベルの英語を話せる人はもっと多く、17.5億人。英語を読んで理解できるというレベルならもっといるかもしれない。
一方、日本語を理解できる人は1.5億人もいない。しかもそのほとんどは極東のごく限られた地域に住む保守的な民族だ。
さらに、ソフトウェア技術の中心は英語の国アメリカにある。日本はどちらかといえばソフトウェア後進国と言わざるを得ない。
せっかくオープンソースプロジェクトに挑戦するなら、それが日本に特化したものでなければ、英語で公開してより多くの先進的な人たちに繋がり、使ってもらい、揉まれるのがやりがいがあり楽しい。&lt;/p&gt;

&lt;p&gt;ドキュメントの内容にも割と力をいれた。&lt;/p&gt;

&lt;p&gt;ドキュメントは理想的には、機能やサポートプラットフォームやインストール方法などを説明するドキュメントと、体系的で網羅的なAPIリファレンスに加え、簡易アプリケーションを書くようなチュートリアルやユースケースベースの解説があるといいと思う。&lt;/p&gt;

&lt;p&gt;因みにここでドキュメントと言っているのはユーザ向けのもの。
コントリビュータ等に向けて内部設計書みたいなものを書くと親切かと思うかもしれないが、全く必要ない。
世界的には&lt;a href=&#34;http://simplearchitect.hatenablog.com/entry/2016/06/20/080807&#34;&gt;ウォータフォールはほぼ完全にその役目を終え&lt;/a&gt;、&lt;a href=&#34;http://www.agilemanifesto.org/iso/ja/&#34;&gt;アジャイル&lt;/a&gt;な開発が当たり前になっている。
こうした開発プロセスでは体系立った設計書など書かない。知りたいことがあればソースを見ればよいというスタンス。
設計書が無くても誰も文句を言わないので安心してさぼるべし。&lt;/p&gt;

&lt;p&gt;因みに因みにプラグインの開発者はユーザの括りなので、それ向けのドキュメントはちゃんと書くべし。&lt;/p&gt;

&lt;p&gt;APIリファレンスはJavaならJavadocでもいい。
Pcap4JのJavadocは &lt;strong&gt;&lt;a href=&#34;http://qiita.com/alucky0707/items/72b578fc9f894a4169c2&#34;&gt;javadoc.io&lt;/a&gt;&lt;/strong&gt; で公開している。
このサービス最高に手軽でありがたいので、なくならないようにもっと広まってほしい。&lt;/p&gt;

&lt;h4 id=&#34;メアドを晒す&#34;&gt;メアドを晒す&lt;/h4&gt;

&lt;p&gt;README.mdには開発者へのコンタクトとしてメアドを晒すべし。&lt;/p&gt;

&lt;p&gt;質問やエンハンス依頼などをしたいがGitHub Issuesに登録するのはちょっと気が引ける、というシャイな人は海外にも意外と結構いて、Pcap4Jの場合、Issuesの5,6倍くらいのメールが来る。
また、仕事がからんでいる人はメールでコンタクトしてくる場合が多いようだ。&lt;/p&gt;

&lt;p&gt;こういう人たちの心をがっちり掴むために、メアドを晒し、素早く丁寧に、できればクールにフレンドリーに対応すべし。
アメリカ人なんかは特にこうした対応の質を重視する。
(逆に言えばバグを出してもしっかりサポートすれば万事OKみたいな雰囲気があってしまうんだけど。)&lt;/p&gt;

&lt;h4 id=&#34;パッケージマネジメントシステムを利用する&#34;&gt;パッケージマネジメントシステムを利用する&lt;/h4&gt;

&lt;p&gt;ライブラリの配布は、言語ごとに普及しているパッケージマネジメントシステムに &lt;strong&gt;必ず&lt;/strong&gt; 乗っかるべし。&lt;/p&gt;

&lt;p&gt;使いたいライブラリがオレオレ配布されていたときの絶望感ったらない。
他のライブラリと統一的に扱えないし、バージョンや依存性の解決も手動でやらなければいけない。
そんな絶望を撒き散らす魔女に自分がなってはいけない。&lt;/p&gt;

&lt;p&gt;Javascriptなら &lt;strong&gt;&lt;a href=&#34;https://www.npmjs.com/&#34;&gt;npm&lt;/a&gt;&lt;/strong&gt; や &lt;strong&gt;&lt;a href=&#34;https://bower.io/&#34;&gt;Bower&lt;/a&gt;&lt;/strong&gt;、Rubyなら &lt;strong&gt;&lt;a href=&#34;https://rubygems.org/&#34;&gt;RubyGems&lt;/a&gt;&lt;/strong&gt;、Pythonなら &lt;strong&gt;&lt;a href=&#34;https://pypi.python.org/pypi&#34;&gt;PyPI&lt;/a&gt;&lt;/strong&gt;(?)。&lt;/p&gt;

&lt;p&gt;Pcap4JはJavaなので &lt;strong&gt;&lt;a href=&#34;https://mvnrepository.com/&#34;&gt;Mavenリポジトリ&lt;/a&gt;&lt;/strong&gt;。当初から &lt;strong&gt;&lt;a href=&#34;http://search.maven.org/&#34;&gt;Maven Central Repository&lt;/a&gt;&lt;/strong&gt; に上げているけど、今なら &lt;strong&gt;&lt;a href=&#34;https://bintray.com/bintray/jcenter&#34;&gt;JCenter&lt;/a&gt;&lt;/strong&gt; の方が手軽でよさそう。
(けどjavadoc.io使うならやっぱりMaven Central Repositoryか。)&lt;/p&gt;

&lt;p&gt;敷居が高そうに見えるが、やってみると意外と簡単なので恐れることはない。&lt;/p&gt;

&lt;h4 id=&#34;ロゴを作る&#34;&gt;ロゴを作る&lt;/h4&gt;

&lt;p&gt;ロゴを作るのを勧めたい。&lt;/p&gt;

&lt;p&gt;パワポでシステム構成を説明するダイアグラムを書いているときに、ロゴがないコンポーネントを見つけた時の絶望感ったらない。
ニートなロゴを作って、希望を振りまく魔法少女たろう。&lt;/p&gt;

&lt;p&gt;プロジェクト名を&lt;a href=&#34;http://photoshopvip.net/77655&#34;&gt;おしゃれなフリーフォント&lt;/a&gt;で書いて、ちょっと&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%AB%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&#34;&gt;カーニング&lt;/a&gt;しただけの&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%AD%E3%82%B4%E3%82%BF%E3%82%A4%E3%83%97&#34;&gt;ロゴタイプ&lt;/a&gt;でもいい。
自分で作ったものがださくてかっこ悪いんじゃないかと不安になったら、&lt;a href=&#34;https://runc.io/&#34;&gt;runC&lt;/a&gt;のロゴマークを見ると心が休まるかもしれない。&lt;/p&gt;

&lt;p&gt;&lt;img alt=&#34;runc.png&#34; src=&#34;https://www.kaitoy.xyz/images/runc.png&#34; style=&#34;margin: 0px auto; display: block; width: 50%; min-width: 200px;&#34;&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kaitoy/pcap4j/blob/v1/www/logos.md&#34;&gt;Pcap4Jのロゴ&lt;/a&gt;は、PのついたキャップをJavaカラーでというアイデアをもとに嫁に描いてもらった。端っこがちょっとジャギジャギしてるのと、ファビコンにするとつぶれてしまうところをいつか何とかしたい。&lt;/p&gt;

&lt;p&gt;&lt;img alt=&#34;pcap4jlogo.png&#34; src=&#34;https://www.kaitoy.xyz/images/pcap4jlogo.png&#34; style=&#34;margin: 0px auto; display: block; width: 50%; min-width: 200px;&#34;&gt;&lt;/p&gt;

&lt;h4 id=&#34;ホームページを作る&#34;&gt;ホームページを作る&lt;/h4&gt;

&lt;p&gt;プロジェクトのホームページを作るのはいいアイデアだ。
箔がつくし、少なくとも作っている自分が楽しい。&lt;/p&gt;

&lt;p&gt;GitHubのプロジェクトページをホームページと言ってもいいが、せっかく &lt;strong&gt;&lt;a href=&#34;https://pages.github.com/&#34;&gt;GitHub Pages&lt;/a&gt;&lt;/strong&gt; が使えるのでトライすべし。(2016/12/16 追記: GitHub PagesにJekyll Theme Chooserという機能が追加され、&lt;a href=&#34;http://qiita.com/kaitoy/items/509ccefb1b31d80ba3f1&#34;&gt;非常に簡単にホームページを作れるようにもなった。&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;最近はシングルページのシンプルなホームページが流行りなので、内容は薄くても構わない。
&lt;a href=&#34;http://gulpjs.com/&#34;&gt;Gulpのホームページ&lt;/a&gt;を見て勇気づけられよう。
&lt;a href=&#34;https://webpack.github.io/&#34;&gt;webpack&lt;/a&gt;もなかなかの手抜きだ。&lt;/p&gt;

&lt;p&gt;ドキュメントには載せにくいカジュアルなPR文句とか、簡単な導入方法とかチュートリアルとかをホームページに書くのがいいかもしれない。
あとはロゴを貼ってGitHubへのリンクを張っておけば充分。
もちろん英語で。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.pcap4j.org/&#34;&gt;Pcap4Jのホームページ&lt;/a&gt;は &lt;strong&gt;&lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt;&lt;/strong&gt; を使って十数時間くらいでできた。
慣れている人ならもっと速くできるだろう。
この際ドメインを取ってしまうのもいい。箔のため。
&lt;code&gt;pcap4j.org&lt;/code&gt;は&lt;a href=&#34;https://www.value-domain.com/&#34;&gt;バリュードメイン&lt;/a&gt;で買ったけど、別にどこでもいい。
費用は業者やドメインによって異なるけど、&lt;code&gt;pcap4j.org&lt;/code&gt;の場合は年1598円。リーズナブル。&lt;/p&gt;

&lt;h4 id=&#34;stack-overflowで盛り上げる&#34;&gt;Stack Overflowで盛り上げる&lt;/h4&gt;

&lt;p&gt;プロジェクトの成熟度を &lt;strong&gt;&lt;a href=&#34;http://stackoverflow.com/&#34;&gt;Stack Overflow&lt;/a&gt;&lt;/strong&gt; の関連投稿数で図る人が一定数いる。&lt;/p&gt;

&lt;p&gt;Stack Overflowはプログラミング技術に関する世界で最も人気なフォーラムサイトだ。
Stack Overflowの投稿数が多ければそれだけコアなユーザや情報が多いということだし、困ったときにそこで質問すれば適切な回答が得られる見込みが高いということ。
ユーザコミュニティが育っているとも言え、そのライブラリを採用する根拠の一つになる。&lt;/p&gt;

&lt;p&gt;Stack Overflowに投稿される質問をチェックし、自分のライブラリなりツールで解決できる問題があったら回答してアピールすることで認知度が高まるだろう。
自分のプロジェクトに対する質問があれば、もちろん積極的に回答すべきだ。特に黎明期は。&lt;/p&gt;

&lt;p&gt;私もStack Overflowで一度だけPcap4JのPRをやったが、めんど^h^h^h時間がとれなくて続かなかった。
反応はよかったのでちょっと後悔。
自分のプロジェクトに関する質問をモニタリングする効率的な方法はないものか…&lt;/p&gt;

&lt;h4 id=&#34;コミットをし続ける&#34;&gt;コミットをし続ける&lt;/h4&gt;

&lt;p&gt;コミットはなるべく頻繁に。&lt;/p&gt;

&lt;p&gt;修正量は多くなくてもいいので、間をあけないことが重要。
今もメンテされているか、活発に開発されているかは、そのライブラリを使うかどうかの大きな判断基準の一つだ。&lt;/p&gt;

&lt;p&gt;同様にIssuesやPull requestsに迅速に対応することも重要で、できたらいいんだけど、ちょっと大変。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://issuestats.com/&#34;&gt;Issue Stats&lt;/a&gt;&lt;/strong&gt; という、IssuesやPull requestsへの対応速度などを解析してくれるサービスがある。
対応速度に自信があるならここのバッジを貼るのもいいかもしれない。&lt;/p&gt;

&lt;p&gt;&lt;img alt=&#34;stats.png&#34; src=&#34;https://www.kaitoy.xyz/images/an-encouragement-of-open-sourcing/stats.png&#34; style=&#34;margin: 0px auto; display: block; width: 50%; min-width: 200px;&#34;&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Pcap4Jのこの数字は怖くて見れない。&lt;/p&gt;

&lt;h4 id=&#34;継続的インテグレーションを実装する&#34;&gt;継続的インテグレーションを実装する&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E7%B6%99%E7%B6%9A%E7%9A%84%E3%82%A4%E3%83%B3%E3%83%86%E3%82%B0%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3&#34;&gt;継続的インテグレーション(CI)&lt;/a&gt;を実装すると、品質にまじめに取り組んでる風が出て、ライブラリへの信頼が高まる。&lt;/p&gt;

&lt;p&gt;利用するサービスは &lt;strong&gt;&lt;a href=&#34;https://travis-ci.org/&#34;&gt;Travis CI&lt;/a&gt;&lt;/strong&gt; でも &lt;strong&gt;&lt;a href=&#34;https://circleci.com/&#34;&gt;CircleCI&lt;/a&gt;&lt;/strong&gt; でも &lt;strong&gt;&lt;a href=&#34;http://www.appveyor.com/&#34;&gt;Appveyor&lt;/a&gt;&lt;/strong&gt; でも &lt;strong&gt;&lt;a href=&#34;https://codeship.com/&#34;&gt;Codeship&lt;/a&gt;&lt;/strong&gt; でも &lt;strong&gt;&lt;a href=&#34;https://drone.io/&#34;&gt;Drone&lt;/a&gt;&lt;/strong&gt; でもなんでもいい。
どれも無料で利用でき、GitHubと連携してコミットのプッシュでビルド/テストをキックできる。
なんなら&lt;a href=&#34;https://aws.amazon.com/jp/&#34;&gt;AWS&lt;/a&gt;や&lt;a href=&#34;https://cloud.google.com/&#34;&gt;GCP&lt;/a&gt;や&lt;a href=&#34;https://www.heroku.com/&#34;&gt;Heroku&lt;/a&gt;なんかへのデプロイまで自動化して&lt;a href=&#34;https://en.wikipedia.org/wiki/Continuous_delivery&#34;&gt;継続的デリバリ-(CD)&lt;/a&gt;を実現することもできる。&lt;/p&gt;

&lt;p&gt;CIを実装したらREADME.mdにバッジを貼るのを忘れずに。
とてもオフィシャル感が出る。&lt;/p&gt;

&lt;p&gt;&lt;img alt=&#34;badges.png&#34; src=&#34;https://www.kaitoy.xyz/images/an-encouragement-of-open-sourcing/badges.png&#34; style=&#34;margin: 0px auto; display: block; width: 50%; min-width: 200px;&#34;&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Pcap4JはLinux(Ubuntu)でのテストをTravis CIで、WindowsでのテストをAppveyorでやっていて、Travis CIでのテスト中に &lt;strong&gt;&lt;a href=&#34;http://cobertura.github.io/cobertura/&#34;&gt;Cobertura&lt;/a&gt;&lt;/strong&gt; でコードカバレージを測って &lt;strong&gt;&lt;a href=&#34;https://coveralls.io/github/kaitoy/pcap4j&#34;&gt;Coveralls&lt;/a&gt;&lt;/strong&gt; にアップし、Appveyorでのビルド結果をMaven Central Repositoryにアップしている。&lt;/p&gt;

&lt;p&gt;今からJavaのコードカバレージを測るなら、Coberturaよりも活発に開発されている &lt;strong&gt;&lt;a href=&#34;http://www.eclemma.org/jacoco/&#34;&gt;Jacoco&lt;/a&gt;&lt;/strong&gt; を使うべき。
コードカバレージの管理も、Coverallsより &lt;strong&gt;&lt;a href=&#34;https://codecov.io/&#34;&gt;Codecov&lt;/a&gt;&lt;/strong&gt; の方が&lt;a href=&#34;https://www.slant.co/versus/7928/7929/~coveralls_vs_codecov&#34;&gt;多機能でサポートもいい&lt;/a&gt;らしい。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E9%9D%99%E7%9A%84%E3%82%B3%E3%83%BC%E3%83%89%E8%A7%A3%E6%9E%90&#34;&gt;静的コード解析&lt;/a&gt;もCIの一部で、絶対やるべきなんだけど、Pcap4Jではまだやってない。
いつの日か。
Javaだと何を使うといいんだろう。&lt;/p&gt;

&lt;h2 id=&#34;オープンソースプロジェクトをやっていてよかったこと&#34;&gt;オープンソースプロジェクトをやっていてよかったこと&lt;/h2&gt;

&lt;p&gt;Pcap4Jを5年近く続けたことで、単純に楽しい以上によかったことがあったのでそれについて書く。&lt;/p&gt;

&lt;h4 id=&#34;グローバルな気分になった&#34;&gt;グローバルな気分になった&lt;/h4&gt;

&lt;p&gt;Pcap4Jにスターを付けてくれた人は5大陸31ヶ国にわたり、世界中に向けて公開されている実感がある。
プログラミングに国境はなく、日本も西洋諸国も同じ天地の間にあって、同じ日輪に照らされ、同じ月を眺め、海をともにし、空気をともにしているんだと、なんとなくグローバルな気分になれた。&lt;/p&gt;

&lt;div style=&#34;text-align: center;&#34;&gt;
&lt;iframe width=&#34;480&#34; height=&#34;440&#34; src=&#34;https://statpedia.com/embed/HJUP7kHq&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;br&gt;
(所在不明者のスターはグリーンランドに置いた。)
&lt;/div&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;少子高齢化で日本のマーケットは縮小していく一方だし、景気回復もまだまだ遠そうだし、グローバルに事業を展開しないとジリ貧だ、というのは10年以上前から言われている。
グローバルにやるっていうのはつまり、日本市場を特別視するんじゃなくて、プロダクトやサービスを世界で最適な市場に投入するってことなんだと思う。
日本市場→世界進出じゃなくて、世界展開→日本向けローカライズという順。
ソフトウェアやWebサービスにとって、ここでの世界とは具体的に言えば英語圏で、もっとはっきり言えばアメリカ。
&lt;a href=&#34;https://ja.wikipedia.org/wiki/PlayStation_4&#34;&gt;PS4&lt;/a&gt;はそういうやりかただったし、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Pokemon_GO&#34;&gt;Pokemon GO&lt;/a&gt;は、…ちょっと違うか。&lt;/p&gt;

&lt;p&gt;かつて日本のSNS市場を開拓し席巻した&lt;a href=&#34;https://ja.wikipedia.org/wiki/Mixi&#34;&gt;Mixi&lt;/a&gt;は、世界のSNS市場で天下を取った&lt;a href=&#34;https://ja.wikipedia.org/wiki/Facebook&#34;&gt;Facebook&lt;/a&gt;よりちょっとだけ早くサービスを開始していた。もしMixiが最初からアメリカ向けに公開されていたらどうなっていただろうと、ちょっと残念に思うときがある。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;と、こんなにもグローバルな気分、オープンソースプロジェクト無しにはなれなかったであろう。&lt;/p&gt;

&lt;p&gt;真面目な話、スペインのスタートアップに誘われたり、アメリカの国立研究所から質問が来たり、ドイツのJDの卒論をサポートしたり、ウクライナの教育機関から謝辞をもらったりと、貴重なエキサイティングな体験ができ、自分の世界が広がったのは確か。&lt;/p&gt;

&lt;h4 id=&#34;いろいろなことに取り組むモチベーションが出た&#34;&gt;いろいろなことに取り組むモチベーションが出た&lt;/h4&gt;

&lt;p&gt;Pcap4Jプロジェクトに絡めて、CIとか、&lt;a href=&#34;https://en.wikipedia.org/wiki/List_of_JVM_languages&#34;&gt;JVM言語&lt;/a&gt;とか、&lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt;とか、いろいろなことに取り組むことができた。&lt;/p&gt;

&lt;p&gt;技術とは、ただむずかしき字を知り、解し難きドキュメントを読み、世上に実のなき文学を言うにあらず。
手を動かし、Hello Worldレベルを超えたところにこそ学びがある。
とはいえ、こうした学びの作業は多くのひとにとって楽しくも大変なことなので、続けるにはちょっと工夫して動機付けしてやるのがいい。&lt;/p&gt;

&lt;p&gt;私も基本的に腰が重いタイプだが、Pcap4Jプロジェクトがいい動機付けになった。
特に、プロジェクトの改善として結果が表れ残るものは、学びのやりがいがあり高いモチベーションを保てた。&lt;/p&gt;

&lt;h4 id=&#34;ユーザから色々教えてもらえた&#34;&gt;ユーザから色々教えてもらえた&lt;/h4&gt;

&lt;p&gt;凡人一人ででなんて大したことは学べない。
Pcap4Jのユーザから、要望や指摘やIssuesやPull requestsを通して、色々なことを教えてもらった。
見つけにくい環境依存のバグ、プロジェクト構造のアドバイス、知らなかったプロトコル、思いもしなかったPcap4Jのユースケース、それを実現するためのAPI。&lt;/p&gt;

&lt;p&gt;ユーザの声を聴き、フィードバックを取り入れていくことで、ソフトウェアは真に有用なものになる。
ついでに知識も知見も知恵も深まる。
これがOSSの醍醐味であろう。&lt;/p&gt;

&lt;p&gt;理想的には、&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873116303/&#34;&gt;Team Geek&lt;/a&gt;にも書かれている通り、未完成の内からソースを公開し、可能な限り早い段階でユーザのフィードバックを受けるべきだ。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;いつも1人でやっていると、失敗のリスクが高くなる。そして、成長の可能性が低くなる。&lt;/p&gt;

&lt;p&gt;(中略)&lt;/p&gt;

&lt;p&gt;つまり、1人で仕事をするほうがリスクが高いということだ。誰かと一緒に仕事をすると、アイデアを盗まれたりバカにされたりしないかと不安になるかもしれないが、間違ったことをして時間をムダにすることを不安に思うべきだ。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;まあ、無名の個人が未完成のソフトを公開してフィードバックをもらえるかという疑問もあるが。&lt;/p&gt;

&lt;h4 id=&#34;小金を得た&#34;&gt;小金を得た&lt;/h4&gt;

&lt;p&gt;プロジェクトに興味を持ってくれる人が増えれば、中にはお金を払ってくれる人も出てくる。
それは寄付であったり、作業の見返りだったりする。&lt;/p&gt;

&lt;p&gt;私はPcap4J開発を通して、ちょっとした幾許かの小金を多少得ることができた。
普通オープンソースプロジェクトは直接的にお金を稼ぐ目的でやるものではないし、私もただ自分の楽しみのためにやっていただけだが、もらえるならもらえるに越したことはない。
ありがたや。&lt;/p&gt;

&lt;p&gt;これを目当てにすべきではないが、たなぼたな展開もあるよということで。&lt;/p&gt;

&lt;h2 id=&#34;終わりに&#34;&gt;終わりに&lt;/h2&gt;

&lt;p&gt;オープンソースプロジェクトに依っては、前節で書いたような開発者自身が得るもののほかに、その活動の成果を享受し、活用してさらなる価値を生み出す多くの他人がいる(かもしれない)ことも忘れてはいけない。&lt;/p&gt;

&lt;p&gt;およそ何人にてもいささか身に技術あればこれによりて世の益をなさんと欲するは人情の常なり。
ソフトウェア技術の発展にわずかでも貢献ができたかもしれないと思えば、開発の励みになるものだ。&lt;/p&gt;

&lt;p&gt;ひとつのオープンソースプロジェクトを生み出すのは、無限の未来を生み出すこと。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;願わくは、この記事に触発されてオープンソースプロジェクトを始める人のあらんことを。&lt;/p&gt;

&lt;div style=&#34;display: none;&#34;&gt;
アジア:
  日本: 15
  中国: 55
  台湾: 1
  韓国: 4
  シンガポール: 2
  マレーシア: 1
  インド: 1
ヨーロッパ:
  ドイツ: 6
  フランス: 2
  イギリス: 7
  オランダ: 3
  スペイン: 2
  スイス: 2
  ベルギー: 2
  ギリシャ: 1
  ポーランド: 3
  エストニア: 1
  スウェーデン: 2
  ウクライナ: 1
  ハンガリー: 1
  モンテネグロ: 1
北米:
  アメリカ: 25
  カナダ: 2
南米:
  ブラジル: 4
  ウルグアイ: 1
  セントルシア: 1
中東:
  アラブ首長国連邦: 1
アフリカ:
  ナイジェリア: 1
  モロッコ: 1
オセアニア:
  オーストラリア: 2
その他:
  ロシア: 7
不明: 42
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GitHub Pagesの新機能、ソース設定が地味にいい</title>
          <link>https://www.kaitoy.xyz/2016/08/18/simpler-github-pages-publishing/</link>
          <pubDate>Thu, 18 Aug 2016 00:26:06 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/08/18/simpler-github-pages-publishing/</guid>
          <description>

&lt;p&gt;今日、&lt;a href=&#34;https://github.com/blog/2228-simpler-github-pages-publishing&#34;&gt;よりシンプルにGitHub Pagesを使えるようになった&lt;/a&gt;というアナウンスがあり、ソース設定という新機能が追加されていたので、さっそく試してみた話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;github-pagesの新機能-ソース設定&#34;&gt;GitHub Pagesの新機能: ソース設定&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://pages.github.com/&#34;&gt;GitHub Pages&lt;/a&gt;には&lt;a href=&#34;https://help.github.com/articles/user-organization-and-project-pages/&#34;&gt;User Pages、Organization Pages、Project Pages&lt;/a&gt;の三種類があるが、ソース設定が使えるのはProject Pages、つまりGitHubリポジトリごとに使えて&lt;code&gt;username.github.io/projectname&lt;/code&gt;のようなURLのやつだけ。&lt;/p&gt;

&lt;p&gt;今まではProject Pagesで公開するサイトのソースは&lt;code&gt;gh-pages&lt;/code&gt;という名のブランチに置く必要があったが、ソース設定により&lt;code&gt;master&lt;/code&gt;ブランチのルートに置いたり&lt;code&gt;master&lt;/code&gt;ブランチの&lt;code&gt;/docs&lt;/code&gt;フォルダに置いたりもできるようになった。&lt;/p&gt;

&lt;h2 id=&#34;ソース設定の使い道&#34;&gt;ソース設定の使い道&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.pcap4j.org/&#34;&gt;Pcap4Jのホームページ&lt;/a&gt;のソースを&lt;code&gt;master&lt;/code&gt;ブランチの&lt;code&gt;/docs&lt;/code&gt;フォルダに置く設定にしたら捗った。&lt;/p&gt;

&lt;p&gt;Pcap4Jのホームページは&lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt;で作っていて、以前は、Hugoのソースを&lt;a href=&#34;https://github.com/kaitoy/pcap4j-hp&#34;&gt;pcap4j-hpリポジトリのmasterブランチ&lt;/a&gt;に置き、&lt;code&gt;gh-pages&lt;/code&gt;ブランチを作ってそこにHugoのビルド成果物(=ホームページのソース)を入れていた。&lt;/p&gt;

&lt;p&gt;ローカルPCでは、&lt;code&gt;master&lt;/code&gt;をcloneして、そこから&lt;code&gt;git worktree&lt;/code&gt;で&lt;code&gt;gh-pages&lt;/code&gt;を別のフォルダにチェックアウトしておいてあり、Hugoのビルドオプションで&lt;code&gt;gh-pages&lt;/code&gt;のフォルダにビルド成果物を出力するようにしていた。
これだと、ホームページを修正したい場合、まず&lt;code&gt;master&lt;/code&gt;でHugoソースを修正して&lt;code&gt;git add/commit/push&lt;/code&gt;、次いでビルドして&lt;code&gt;gh-pages&lt;/code&gt;フォルダに移動して&lt;code&gt;git add/commit/push&lt;/code&gt;、というように、二度手間で面倒だった。&lt;/p&gt;

&lt;p&gt;Hugoのビルド成果物を&lt;code&gt;master&lt;/code&gt;ブランチの&lt;code&gt;/docs&lt;/code&gt;フォルダに置けるようにできれば、&lt;code&gt;git add/commit/push&lt;/code&gt;はビルド後に&lt;code&gt;master&lt;/code&gt;に対して一回だけやれば済むようになる。&lt;/p&gt;

&lt;h2 id=&#34;gh-pagesからmasterブランチの-docsフォルダへの移行&#34;&gt;gh-pagesからmasterブランチの/docsフォルダへの移行&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://help.github.com/articles/configuring-a-publishing-source-for-github-pages/&#34;&gt;GitHubのヘルプ&lt;/a&gt;を参考にしつつ、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;ローカルPCで、&lt;code&gt;master&lt;/code&gt;の作業ディレクトリのルートに&lt;code&gt;docs&lt;/code&gt;というフォルダを作り、&lt;code&gt;gh-pages&lt;/code&gt;のフォルダの中身を全てそこに移動。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;master&lt;/code&gt;の&lt;code&gt;docs&lt;/code&gt;を&lt;code&gt;git add/commit/push&lt;/code&gt;。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;GitHubのpcap4j-hpリポジトリのページに行き、SettingsタブのGitHub PagesセクションのSourceを&lt;code&gt;gh-pages branch&lt;/code&gt;から&lt;code&gt;master branch /docs folder&lt;/code&gt;に変えてSaveボタンをクリック。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/simpler-github-pages-publishing/gh-pages-to-docs.png&#34; alt=&#34;gh-pages-to-docs.png&#34; title=&#34;gh-pages-to-docs.png&#34; /&gt;
&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;実にこれだけ。
カスタムドメインにしていてもこれだけ。簡単。ダウンタイムもなし。&lt;/p&gt;

&lt;p&gt;あとはローカルPCの&lt;code&gt;gh-pages&lt;/code&gt;の作業ディレクトリを削除したり、&lt;code&gt;gh-pages&lt;/code&gt;ブランチを削除したり。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Docker for Windowsがコレジャナかった</title>
          <link>https://www.kaitoy.xyz/2016/07/31/docker-for-windows/</link>
          <pubDate>Sun, 31 Jul 2016 14:34:16 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/07/31/docker-for-windows/</guid>
          <description>

&lt;p&gt;7/28にDocker for Winodws(とDocker for Mac)の正式版リリースの&lt;a href=&#34;https://blog.docker.com/2016/07/docker-for-mac-and-windows-production-ready/&#34;&gt;アナウンス&lt;/a&gt;があったので試してみたけど、期待していたものと違ったしなんだか上手く動かなかった話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;docker-for-windowsとは&#34;&gt;Docker for Windowsとは&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/docker-for-windows/&#34;&gt;Docker for Windows&lt;/a&gt;は&lt;a href=&#34;https://www.docker.com/products/docker-toolbox&#34;&gt;Docker Toolbox&lt;/a&gt;の後継製品。(多分。)&lt;/p&gt;

&lt;p&gt;Docker ToolboxはWindowsやMacでDockerを使うための製品で、以下のコンポーネントからなる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.docker.com/products/docker-engine&#34;&gt;Docker Engine&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;コンテナランタイム。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/compose/&#34;&gt;Docker Compose&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;複数のコンテナを組み合わせたアプリケーション/サービスの構築/管理ツール。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/machine/&#34;&gt;Docker Machine&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Docker仮想ホストのプロビジョニング/管理ツール。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kitematic.com/&#34;&gt;Kitematic&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Dockerコンテナを管理するGUIを提供する製品。
Docker Machineと連携してローカルマシンへのDocker仮想ホストのプロビジョニングもしてくれる。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Docker Toolboxを使うと、&lt;a href=&#34;https://ja.wikipedia.org/wiki/VirtualBox&#34;&gt;VirtualBox&lt;/a&gt;のLinux VMをWindows/Mac上にプロビジョニングして、そのVMにDockerをインストールして、Windows/Macから利用できる。&lt;/p&gt;

&lt;p&gt;Docker for Windowsもだいたい同じで、Docker EngineとDocker ComposeとDocker MachineをWinodwsで利用するための製品。
&lt;a href=&#34;http://electron.atom.io/&#34;&gt;Electron&lt;/a&gt;ベースでOracleのVirtualBox依存なKitematicの代わりに、ネイティブなインストーラがWindows内蔵の&lt;a href=&#34;https://ja.wikipedia.org/wiki/Hyper-V&#34;&gt;Hyper-V&lt;/a&gt;を使ってDockerをセットアップしてくれる。
Hyper-Vを使うため、VirtualBoxより速くて高信頼らしい。
KitematicはDocker for Windowsには付属しないが、別途ダウンロードすればコンテナ管理に使える。Docker for WindowsとDocker Toolboxとは共存はできない。&lt;/p&gt;

&lt;p&gt;私は勝手にDocker for Windowsは&lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#windows-containersとは&#34;&gt;Hyper-V Containers&lt;/a&gt;のデスクトップOS版のようなものかと勘違いしていて、Windowsのコンテナが使えるようになったのかと期待したが違った。
Docker for Windowsは単にDocker ToolboxのVirtualBoxがHyper-Vになっただけのもので、結局Linux VMの中でDockerを使うだけのものだということにセットアップ中に気付いた。&lt;/p&gt;

&lt;p&gt;(2017/9/12追記: &lt;a href=&#34;https://blogs.msdn.microsoft.com/webdev/2017/09/07/getting-started-with-windows-containers/&#34;&gt;これ&lt;/a&gt;とか&lt;a href=&#34;https://docs.docker.com/docker-for-windows/install/#about-windows-containers-and-windows-server-2016&#34;&gt;これ&lt;/a&gt;とかを見るに、いまではDocker for Winodwsは、Hyper-V ContainersやWindows Server Containersのフロントエンドでもあるようだ。)&lt;/p&gt;

&lt;p&gt;コレジャナイ感がすごかった。&lt;/p&gt;

&lt;p&gt;ともあれ、やった作業を以下に記す。&lt;/p&gt;

&lt;h2 id=&#34;docker-for-windows-on-vmware-player&#34;&gt;Docker for Windows on VMware Player&lt;/h2&gt;

&lt;p&gt;現時点ではDocker for WindowsはホストとしてWindows 10 x64 Pro/Enterprise/Education (Version 1511 Build 10586 以降)しかサポートしていない。
自前のPCが5年前に買った&lt;a href=&#34;https://dynabook.com/&#34;&gt;dynabook&lt;/a&gt;でWindows 10をサポートしていないので、VMware PlayerのVM上のWindows 10にDocker for Windowsをインストールしてみる。&lt;/p&gt;

&lt;h4 id=&#34;vmware-playerのvmでhyper-vを使うための設定&#34;&gt;VMware PlayerのVMでHyper-Vを使うための設定&lt;/h4&gt;

&lt;p&gt;VMware PlayerのVMでは通常Hyper-Vは使えないので、&lt;a href=&#34;http://social.technet.microsoft.com/wiki/contents/articles/22283.how-to-install-hyper-v-on-vmware-workstation-10.aspx&#34;&gt;How to Install Hyper-V on vmware Workstation 10 ?&lt;/a&gt;を参考にしてVMの設定をいじる。
この記事はVMware Workstationについてのものだが、VMware Playerでも全く同じ方法でいける。&lt;/p&gt;

&lt;p&gt;いじるのは、dynabookのWindows 7に入れたVMware Workstation 11.1.0 build-2496824に付属の
VMware Player 7.1.0 build-2496824で作ったWindows 10 Pro x64 (Version 1511 Build 10586.494)のVM。
VMのバージョンは11.0。2CPUでメモリは2GB。ネットワークインターフェースはNAT。&lt;/p&gt;

&lt;p&gt;このVMの.vmxファイルをテキストエディタで開いて以下を追記。意味は不明。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hypervisor.cpuid.v0 = &amp;quot;FALSE&amp;quot;
mce.enable = &amp;quot;TRUE&amp;quot;
vhu.enable = &amp;quot;TRUE&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次いで、VMware PlayerのGUIからVMのCPU設定を開き、&lt;code&gt;Intel VT-x/EPTまたはAMD-V/RVIを仮想化&lt;/code&gt;と&lt;code&gt;CPUパフォーマンスカウンタを仮想化&lt;/code&gt;にチェックを付ける。意味はなんとなくしかわからない。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/docker-for-windows/vm.jpg&#34; alt=&#34;vm.jpg&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これだけ。&lt;/p&gt;

&lt;p&gt;Hyper-VはDocker for Windowsのインストーラが有効化してくれるのでここでは何もしなくていい。&lt;/p&gt;

&lt;h4 id=&#34;docker-for-windowsインストール&#34;&gt;Docker for Windowsインストール&lt;/h4&gt;

&lt;p&gt;VMを起動して、&lt;a href=&#34;https://docs.docker.com/docker-for-windows/&#34;&gt;Getting Started with Docker for Windows&lt;/a&gt;に従ってDocker for Windowsをインストールする。&lt;/p&gt;

&lt;p&gt;まず、&lt;a href=&#34;https://download.docker.com/win/stable/InstallDocker.msi&#34;&gt;上記サイト内のリンク&lt;/a&gt;からインストーラをダウンロード。stableの方。&lt;/p&gt;

&lt;p&gt;ダウンロードした&lt;code&gt;InstallDocker.msi&lt;/code&gt;をVM上で実行してウィザードに従えばインストール完了。
ウィザードの最後で&lt;code&gt;Launch Docker&lt;/code&gt;にチェックが付いた状態で&lt;code&gt;Finish&lt;/code&gt;するとDockerを起動してくれる。
この起動中にHyper-Vを有効化してくれる。(OS再起動有り。)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/docker-for-windows/hyper-v.jpg&#34; alt=&#34;hyper-v.jpg&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;OS再起動後、「Failed to create Switch &amp;ldquo;DockerNAT&amp;rdquo;: Hyper-V was unable to find a virtual switch with name &amp;ldquo;DockerNAT&amp;rdquo;」というエラー出た。&lt;code&gt;DockerNAT&lt;/code&gt;が見つからない?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/docker-for-windows/error.jpg&#34; alt=&#34;error.jpg&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;code&gt;DockerNAT&lt;/code&gt;はDocker for Windowsがインストール中に作るHyper-Vの仮想スイッチ。&lt;/p&gt;

&lt;p&gt;以前に&lt;code&gt;hosts&lt;/code&gt;に変なエントリを書いてしまっていたのでそれを一応消して、VMware PlayerのVMのアダプタの設定もちょっといじってしまっていたので一応もとにもどして、再度Docker for Windowsをクリーンインストールしたら上記エラーは出なくなった。
なんだったんだろう。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Dockerの起動中に今度はメモリ系のエラー: 「Failed to create VM &amp;ldquo;MobyLinuxVM&amp;rdquo;: Failed to modify device &amp;lsquo;Memory&amp;rsquo;」。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/docker-for-windows/error2.jpg&#34; alt=&#34;error2.jpg&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;code&gt;MobyLinuxVM&lt;/code&gt;はDockerを動かすHyper-V VMの名前。このVMに割り当てるメモリはホストOSのメモリ量から決められるようで、これが少なすぎるとダメな模様。&lt;/p&gt;

&lt;p&gt;VMware PlayerのVMのメモリを2Gから3.3Gに増やしたらこのエラーもなくなったけど、今度はIPアドレスのエラー: 「Failed to start VM &amp;ldquo;MobyLinuxVM&amp;rdquo;: The VM couldn&amp;rsquo;t get an IP address after 60 tries」。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/docker-for-windows/error3.jpg&#34; alt=&#34;error3.jpg&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;フォーラムを見たら
&lt;a href=&#34;https://forums.docker.com/t/vm-mobylinuxvm-the-vm-couldnt-get-an-ip-address-after-60-tries/8505/11&#34;&gt;このエラーが載っていた&lt;/a&gt;。そこには以下の様な解決方法が挙がっていた。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Docker for Windowsをクリーンインストールしなおす。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;vEthernet (DockerNAT)&lt;/code&gt;のアダプタのオプションでIPv6を無効にする。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;タスクトレイの鯨アイコンから開けるDockerのSettingsで&lt;code&gt;Reset to factory defaults...&lt;/code&gt;を実行。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/docker-for-windows/docker_settings.jpg&#34; alt=&#34;docker_settings.jpg&#34; /&gt;
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;どれもだめだった。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;MobyLinuxVM&lt;/code&gt;がちゃんと起動しなくて、Dockerデーモンに接続できない。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Windows\System32&amp;gt;docker version
Client:
 Version:      1.12.0
 API version:  1.24
 Go version:   go1.6.3
 Git commit:   8eab29e
 Built:        Thu Jul 28 21:15:28 2016
 OS/Arch:      windows/amd64
An error occurred trying to connect: Get http://%2F%2F.%2Fpipe%2Fdocker_engine/v1.24/version: open //./pipe/docker_engine: The system cannot find the file specified.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因みにちゃんと起動すると以下の感じになるらしい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;PS C:\Users\samstevens&amp;gt; docker version
Client:
Version:      1.12.0-rc2
API version:  1.24
Go version:   go1.6.2
Git commit:   906eacd
Built:        Fri Jun 17 20:35:33 2016
OS/Arch:      windows/amd64
Experimental: true

Server:
Version:      1.12.0-rc2
API version:  1.24
Go version:   go1.6.2
Git commit:   a7119de
Built:        Fri Jun 17 22:09:20 2016
OS/Arch:      linux/amd64
Experimental: true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;もうあきらめる。
どうせWindowsコンテナが使えないならあまり面白くないし。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Windows Server 2016 TP5でWindows Containersにリトライ</title>
          <link>https://www.kaitoy.xyz/2016/07/11/windows_containers_on_tp5/</link>
          <pubDate>Mon, 11 Jul 2016 00:30:33 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/07/11/windows_containers_on_tp5/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.microsoft.com/ja-jp/evalcenter/evaluate-windows-server-technical-preview&#34;&gt;Windows Server 2016のTechnical Preview 5(TP5)が公開されていた&lt;/a&gt;ので、
&lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/&#34;&gt;TP4でバグに阻まれて挫折した&lt;/a&gt;、Windows Containersで&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;Pcap4J&lt;/a&gt;を使ってパケットキャプチャする試みにリトライした話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;osセットアップ&#34;&gt;OSセットアップ&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#windows-containersセットアップ&#34;&gt;TP4のとき&lt;/a&gt;と同じ環境。&lt;/p&gt;

&lt;p&gt;以降は&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/quick_start/quick_start_windows_server&#34;&gt;Windows Server Containersのクイックスタートガイド&lt;/a&gt;に沿ってセットアップを進める。
&lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#windows-containersセットアップ&#34;&gt;TP4&lt;/a&gt;からは大分変わっていて、単一のPowershellスクリプトを実行する形式から、Powershellのコマンドレットを逐次手動実行する形式になっている。
面倒だけど何やってるかわかりやすくて好き。&lt;/p&gt;

&lt;h2 id=&#34;コンテナ機能のインストール&#34;&gt;コンテナ機能のインストール&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;管理者権限のパワーシェルウィンドウを開く&lt;/p&gt;

&lt;p&gt;コマンドプロンプトから以下のコマンドを実行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;powershell start-process powershell -Verb runas
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;コンテナ機能のインストール&lt;/p&gt;

&lt;p&gt;開いた青いパワーシェルウィンドウで以下のコマンドを実行するとコンテナ機能がインストールされる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Install-WindowsFeature containers
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;数分で終わる。&lt;/p&gt;

&lt;p&gt;インストールされたのはHyper-V ContainersじゃなくてWindows Server Containersの方。
クイックスタートガイドをみると、前者がWindows 10向け、後者がWindows Server向けというように住み分けされているっぽい。TP4では両方ともWindows Serverで使えたんだけど。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;再起動&lt;/p&gt;

&lt;p&gt;変更を有効にするために再起動が必要。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Restart-Computer -Force
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;dockerインストール&#34;&gt;Dockerインストール&lt;/h2&gt;

&lt;p&gt;Dockerは、コンテナイメージの管理やコンテナの起動などもろもろの機能を提供するDockerデーモンと、その機能を利用するためのCLIを提供するDockerクライアントからなる。この節ではそれら両方をインストールする。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Dockerインストールフォルダ作成&lt;/p&gt;

&lt;p&gt;管理者権限のパワーシェルウィンドウを開いて、以下のコマンドでDockerインストールフォルダを作成。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;New-Item -Type Directory -Path &#39;C:\Program Files\docker\&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dockerデーモンインストール&lt;/p&gt;

&lt;p&gt;まずはデーモンの方をインストール。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Invoke-WebRequest https://aka.ms/tp5/b/dockerd -OutFile $env:ProgramFiles\docker\dockerd.exe -UseBasicParsing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;数分。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dockerクライアントインストール&lt;/p&gt;

&lt;p&gt;次にクライアント。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Invoke-WebRequest https://aka.ms/tp5/b/docker -OutFile $env:ProgramFiles\docker\docker.exe -UseBasicParsing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;数十秒。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;パスの設定&lt;/p&gt;

&lt;p&gt;さっき作ったDockerインストールフォルダにパスを通す。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;[Environment]::SetEnvironmentVariable(&amp;quot;Path&amp;quot;, $env:Path + &amp;quot;;C:\Program Files\Docker&amp;quot;, [EnvironmentVariableTarget]::Machine)
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dockerデーモンをサービスに登録&lt;/p&gt;

&lt;p&gt;パスの設定を反映するためにいったんパワーシェルウィンドウとコマンドプロンプトを閉じて、
また管理者権限でパワーシェルウィンドウ開いて、以下のコマンドでDockerデーモンをサービスに登録する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;dockerd --register-service
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dockerデーモン起動&lt;/p&gt;

&lt;p&gt;Dockerデーモンは以下のコマンドで起動できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Start-Service docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;数秒で立ち上がる。
デフォルトではOS再起動時にはDockerデーモンは自動起動しないので、そのつどこのコマンドを実行する必要がある。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これでDockerインストール完了。
この時点ではコンテナイメージは何もない。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\Administrator&amp;gt;docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因みにインストールされたDockerのバージョンは1.12開発版。現時点での最新版だ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\Administrator&amp;gt;docker -v
Docker version 1.12.0-dev, build 8e92415
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;コンテナイメージのインストール&#34;&gt;コンテナイメージのインストール&lt;/h2&gt;

&lt;p&gt;次に、コンテナイメージをインストールする。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;コンテナイメージのパッケージプロバイダをインストール&lt;/p&gt;

&lt;p&gt;いまいち何なのかはよくわからないが、
コンテナイメージのパッケージプロバイダというのをインストールする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Install-PackageProvider ContainerImage -Force
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;数十秒。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Windows Server Coreのイメージをインストール&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Install-ContainerImage -Name WindowsServerCore
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;9GB以上もあるファイルをダウンロードして処理するのでかなり時間がかかる。
50分くらいかかった。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dockerデーモン再起動&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Restart-Service docker
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;無事Windows Server Coreイメージがインストールされた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Users\Administrator&amp;gt; docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
windowsservercore   10.0.14300.1000     5bc36a335344        8 weeks ago         9.354 GB
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;pcap4jコンテナイメージのビルド&#34;&gt;Pcap4Jコンテナイメージのビルド&lt;/h2&gt;

&lt;p&gt;以下を&lt;code&gt;C:\Users\Administrator\Desktop\pcap4j\Dockerfile&lt;/code&gt;に書いて、&lt;code&gt;cd C:\Users\Administrator\Desktop\pcap4j&lt;/code&gt;して、&lt;code&gt;docker build -t pcap4j .&lt;/code&gt;を実行。
(Notepad使ったので、拡張子を表示する設定にして&lt;code&gt;Dockerfile&lt;/code&gt;の&lt;code&gt;.txt&lt;/code&gt;を消さないといけない罠があった。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-dockerfile&#34;&gt;#
# Dockerfile for Pcap4J on Windows
#

FROM windowsservercore:10.0.14300.1000
MAINTAINER Kaito Yamada &amp;lt;kaitoy@pcap4j.org&amp;gt;

# Install Chocolatey.
RUN mkdir C:\pcap4j
WORKDIR c:\\pcap4j
ADD https://chocolatey.org/install.ps1 install.ps1
RUN powershell .\install.ps1

# Install dependencies.
RUN choco install -y nmap jdk7 &amp;amp;&amp;amp; \
    choco install -y maven -version 3.2.5

# Build Pcap4J.
RUN powershell -Command Invoke-WebRequest https://github.com/kaitoy/pcap4j/archive/v1.zip -OutFile pcap4j.zip &amp;amp;&amp;amp; \
    powershell -Command Expand-Archive -Path pcap4j.zip -DestinationPath .
WORKDIR pcap4j-1
RUN powershell -Command &amp;quot;mvn -P distribution-assembly install 2&amp;gt;&amp;amp;1 | Add-Content -Path build.log -PassThru&amp;quot;

# Collect libraries.
RUN mkdir bin &amp;amp;&amp;amp; \
    cd pcap4j-packetfactory-static &amp;amp;&amp;amp; \
    mvn -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeScope=compile dependency:copy-dependencies &amp;amp;&amp;amp; \
    mvn -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeGroupIds=ch.qos.logback dependency:copy-dependencies &amp;amp;&amp;amp; \
    cd ../pcap4j-distribution &amp;amp;&amp;amp; \
    mvn -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeArtifactIds=pcap4j-packetfactory-static,pcap4j-sample dependency:copy-dependencies

# Generate sample script. (C:\pcap4j\pcap4j-1\bin\capture.bat)
RUN echo @echo off &amp;gt; bin\capture.bat &amp;amp;&amp;amp; \
    echo &amp;quot;%JAVA_HOME%\bin\java&amp;quot; -cp C:\pcap4j\pcap4j-1\bin\pcap4j-core.jar;C:\pcap4j\pcap4j-1\bin\pcap4j-packetfactory-static.jar;C:\pcap4j\pcap4j-1\bin\pcap4j-sample.jar;C:\pcap4j\pcap4j-1\bin\jna.jar;C:\pcap4j\pcap4j-1\bin\slf4j-api.jar;C:\pcap4j\pcap4j-1\bin\logback-classic.jar;C:\pcap4j\pcap4j-1\bin\logback-core.jar org.pcap4j.sample.GetNextPacketEx &amp;gt;&amp;gt; bin\capture.bat
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Dockerfileに書いた処理内容は&lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#pcap4j-on-windows-container&#34;&gt;TP4のとき&lt;/a&gt;とだいたい同じ。
以下、Dockerfile書いているときに気付いたこと。&lt;/p&gt;

&lt;h4 id=&#34;tp4からのアップデート&#34;&gt;TP4からのアップデート&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;WORKDIR や ENV や COPY でパスの区切りは \ 一つだと消えちゃうので \ か / を使わないといけない。
&lt;div style=&#34;font-size: 0.5em; text-align: right;&#34;&gt;&lt;cite&gt;引用元: &lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#pcap4j-on-windows-container&#34;&gt;TP4のときのエントリ&lt;/a&gt;&lt;/cite&gt;&lt;/div&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/docker/manage_windows_dockerfile&#34;&gt;このページ&lt;/a&gt;の各コマンドの&lt;strong&gt;Windows Considerations&lt;/strong&gt;に、&lt;code&gt;WORKDIR&lt;/code&gt;のパスの区切りのバックスラッシュはエスケープしないといけないとか、&lt;code&gt;ADD&lt;/code&gt;のパスの区切りはスラッシュじゃないといけないとか書いてある。
TP4のときはなかったような。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;WORKDIR や COPY のコンテナ内のパスに絶対パスを指定したい場合、C:\hoge、C:/hoge、C:\hoge、いずれもダメ。 以下の様なエラーが出る。
&lt;div style=&#34;font-size: 0.5em; text-align: right;&#34;&gt;&lt;cite&gt;引用元: &lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#pcap4j-on-windows-container&#34;&gt;TP4のときのエントリ&lt;/a&gt;&lt;/cite&gt;&lt;/div&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;これは直った。&lt;code&gt;WORKDIR c:\\pcap4j&lt;/code&gt;で行ける。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;install.ps1の中でChocolateyのインストーラをHTTPSで取ってこようとしてエラー
&lt;div style=&#34;font-size: 0.5em; text-align: right;&#34;&gt;&lt;cite&gt;引用元: &lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#pcap4j-on-windows-container&#34;&gt;TP4のときのエントリ&lt;/a&gt;&lt;/cite&gt;&lt;/div&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;普通に&lt;code&gt;choco install&lt;/code&gt;できたので、HTTPSが使えない制限は消えた模様。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;ビルドしてみると、各ステップの実行(多分レイヤの作成)がすごく遅い。
&lt;div style=&#34;font-size: 0.5em; text-align: right;&#34;&gt;&lt;cite&gt;引用元: &lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#pcap4j-on-windows-container&#34;&gt;TP4のときのエントリ&lt;/a&gt;&lt;/cite&gt;&lt;/div&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;各ステップの実行は相変わらず重い。特にファイル変更が多いときはすごく重い。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;コンテナの起動は非常に遅い。30秒以上かかる。
&lt;div style=&#34;font-size: 0.5em; text-align: right;&#34;&gt;&lt;cite&gt;引用元: &lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#windows-server-containers味見&#34;&gt;TP4のときのエントリ&lt;/a&gt;&lt;/cite&gt;&lt;/div&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;コンテナ起動は早くなったけどまだ5秒くらいかかる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;WORKDIR や ENV で環境変数が展開されない。
&lt;div style=&#34;font-size: 0.5em; text-align: right;&#34;&gt;&lt;cite&gt;引用元: &lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#pcap4j-on-windows-container&#34;&gt;TP4のときのエントリ&lt;/a&gt;&lt;/cite&gt;&lt;/div&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;これはまだ直っていない。&lt;code&gt;%tmp%&lt;/code&gt;、&lt;code&gt;%TMP%&lt;/code&gt;、&lt;code&gt;$TMP&lt;/code&gt;、&lt;code&gt;${TMP}&lt;/code&gt;、どれもだめ。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;コンテナ内で C:\ 直下に . で始まる名前のフォルダ作ると次のステップで消えてる。
&lt;div style=&#34;font-size: 0.5em; text-align: right;&#34;&gt;&lt;cite&gt;引用元: &lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#pcap4j-on-windows-container&#34;&gt;TP4のときのエントリ&lt;/a&gt;&lt;/cite&gt;&lt;/div&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;これは再現しなかった。以前のも勘違いだったのかもしれない。
なんにせよデフォルトの.m2フォルダのパスが&lt;code&gt;C:\Users\ContainerAdministrator\.m2&lt;/code&gt;になったので気にしなくてよくなった。&lt;/p&gt;

&lt;h4 id=&#34;ビルドエラー-hcsshim-importlayer-failed-in-win32-the-filename-or-extension-is-too-long-0xce&#34;&gt;ビルドエラー: hcsshim::ImportLayer failed in Win32: The filename or extension is too long. (0xce)&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;choco install&lt;/code&gt;の後で以下のエラーが出た。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;re-exec error: exit status 1: output: time=&amp;quot;2016-07-09T19:57:22-07:00&amp;quot; level=error msg=&amp;quot;hcsshim::ImportLayer failed in Win32: The filename or extension is too long. (0xce) layerId=\\\\?\\C:\\ProgramData\\docker\\windowsfilter\\103de6bf1358c506510ad67990f09ec3e2f10f9e866e846df5a88c04f5edf7aa flavour=1 folder=C:\\Windows\\TEMP\\hcs719016711&amp;quot;
hcsshim::ImportLayer failed in Win32: The filename or extension is too long. (0xce) layerId=\\?\C:\ProgramData\docker\windowsfilter\103de6bf1358c506510ad67990f09ec3e2f10f9e866e846df5a88c04f5edf7aa flavour=1 folder=C:\Windows\TEMP\hcs719016711
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;調べたら&lt;a href=&#34;https://github.com/docker/docker/issues/22449&#34;&gt;DockerのGitHub Issues&lt;/a&gt;に登録されていた。
ここのコメントを参考に以下のコマンドでコンテナホストのアップデートをしたら発生しなくなった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Invoke-WebRequest https://aka.ms/tp5/Update-Container-Host -OutFile update-containerhost.ps1
.\update-containerhost.ps1
Restart-Computer -Force
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;git-cloneできない&#34;&gt;git cloneできない&lt;/h4&gt;

&lt;p&gt;Pcap4Jのソースをダウンロードしたかったんだけど、なぜか&lt;code&gt;git clone&lt;/code&gt;がHTTPSでもGITプロトコルでもエラーを返す。
原因を調べるのが面倒で結局zipでダウンロードするようにした。&lt;/p&gt;

&lt;h4 id=&#34;未実装の機能&#34;&gt;未実装の機能&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/&#34;&gt;Dockerfileのリファレンス&lt;/a&gt;に載っていて、Windows向けのサンプルも書いてあるのに、&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#/escape&#34;&gt;escapeディレクティブ&lt;/a&gt;と&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#/shell&#34;&gt;SHELLコマンド&lt;/a&gt;
が使えなかった。&lt;/p&gt;

&lt;h2 id=&#34;コンテナ起動&#34;&gt;コンテナ起動&lt;/h2&gt;

&lt;p&gt;とりあえず上記DockerfileでPcap4Jコンテナイメージのビルドはできた。&lt;/p&gt;

&lt;p&gt;以下のコマンドでそのイメージからコンテナを起動。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\Administrator&amp;gt;docker run -it pcap4j cmd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コンテナ内で&lt;code&gt;ipconfig&lt;/code&gt;すると&lt;code&gt;vEthernet (Temp Nic Name)&lt;/code&gt;という名のネットワークインターフェースがあることがわかる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\pcap4j\pcap4j-1\bin&amp;gt;ipconfig

Windows IP Configuration


Ethernet adapter vEthernet (Temp Nic Name):

   Connection-specific DNS Suffix  . : localdomain
   Link-local IPv6 Address . . . . . : fe80::59cf:1491:6f8e:30c8%18
   IPv4 Address. . . . . . . . . . . : 172.23.71.6
   Subnet Mask . . . . . . . . . . . : 255.240.0.0
   Default Gateway . . . . . . . . . : 172.16.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;けどPcap4Jからは見えなかった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\pcap4j\pcap4j-1\bin&amp;gt;capture.bat
org.pcap4j.sample.GetNextPacketEx.count: 5
org.pcap4j.sample.GetNextPacketEx.readTimeout: 10
org.pcap4j.sample.GetNextPacketEx.snaplen: 65536


18:49:00.582 [main] INFO  org.pcap4j.core.Pcaps - No NIF was found.
java.io.IOException: No NIF to capture.
        at org.pcap4j.sample.GetNextPacketEx.main(GetNextPacketEx.java:45)java:44)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;コンテナには&lt;code&gt;ContainerAdministrator&lt;/code&gt;というユーザでログインしていて、これの権限が弱いせいなんじゃないかと。
コンテナ内にも&lt;code&gt;Administrator&lt;/code&gt;というユーザがあるようだったので、こっちでコマンド実行するよう奮闘した。&lt;/p&gt;

&lt;h2 id=&#34;コンテナ内でadministratorでコマンド実行したい&#34;&gt;コンテナ内でAdministratorでコマンド実行したい&lt;/h2&gt;

&lt;h4 id=&#34;userコマンド&#34;&gt;USERコマンド&lt;/h4&gt;

&lt;p&gt;Dockerfileのコマンドに&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#/user&#34;&gt;USER&lt;/a&gt;というのがあるので、&lt;code&gt;USER Administrator&lt;/code&gt;をDockerfileの末尾に追加してみたら以下のエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;The daemon on this platform does not support the command &#39;user&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;userオプション&#34;&gt;&amp;ndash;userオプション&lt;/h4&gt;

&lt;p&gt;docker runコマンドに&lt;a href=&#34;https://docs.docker.com/compose/reference/run/&#34;&gt;&amp;ndash;user&lt;/a&gt;というオプションがあるので以下のように試してみたところ、オプションは無視されて&lt;code&gt;ContainerAdministrator&lt;/code&gt;でコンテナに入った。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;docker run -it --user Administrator pcap4j cmd
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;runas&#34;&gt;runas&lt;/h4&gt;

&lt;p&gt;ちょっと発想の転換をして、&lt;code&gt;ContainerAdministrator&lt;/code&gt;でコンテナに入った後sudoみたいなことをすればいいかと思い、&lt;a href=&#34;https://technet.microsoft.com/en-us/library/bb490994.aspx&#34;&gt;runas&lt;/a&gt;コマンドを試したけどだめだった。
よく分からないエラーがでるし、そもそも&lt;code&gt;Administrator&lt;/code&gt;のパスワードがわからない。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\pcap4j\pcap4j-1\bin&amp;gt;runas /user:Administrator cmd
Enter the password for Administrator:
Attempting to start cmd as user &amp;quot;92EC7B3B09B4\Administrator&amp;quot; ...
RUNAS ERROR: Unable to run - cmd
1326: The user name or password is incorrect.
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\pcap4j\pcap4j-1\bin&amp;gt;runas /user:&amp;quot;User Manager\Administrator&amp;quot; capture.bat
Enter the password for User Manager\Administrator:
RUNAS ERROR: Unable to acquire user password
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;enter-pssession&#34;&gt;Enter-PSSession&lt;/h4&gt;

&lt;p&gt;フォーラムに行ったら&lt;a href=&#34;https://social.msdn.microsoft.com/Forums/en-US/0b6bd405-a235-4608-a06b-a09b9ba08b2e/runas-administrator?forum=windowscontainers&#34;&gt;Enter-PSSession&lt;/a&gt;を使う方法が書いてあった。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://technet.microsoft.com/en-us/library/hh849707.aspx&#34;&gt;Enter-PSSession&lt;/a&gt;はリモートシステムに接続するコマンドレットで、&lt;code&gt;-ContainerName&lt;/code&gt;オプションを使えばコンテナにも接続できる。&lt;/p&gt;

&lt;p&gt;試したら、コンテナが見つからないというエラーが出た。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\Administrator&amp;gt;powershell -command Enter-PSSession -ContainerName amazing_archimedes -RunAsAdministrator
Enter-PSSession : The input ContainerName amazing_archimedes does not exist, or the corresponding container is not running.
At line:1 char:1
+ Enter-PSSession -ContainerName amazing_archimedes -RunAsAdministrator
+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : InvalidOperation: (:) [Enter-PSSession], PSInvalidOperationException
    + FullyQualifiedErrorId : CreateRemoteRunspaceForContainerFailed,Microsoft.PowerShell.Commands.EnterPSSessionCommand
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://technet.microsoft.com/en-us/library/hh849719.aspx&#34;&gt;Invoke-Command&lt;/a&gt;もコンテナをターゲットにできるので試してみたけど、同様のエラー。&lt;/p&gt;

&lt;p&gt;どうもパワーシェルで扱うコンテナやコンテナイメージが、dockerコマンドが扱うものとは別になっているせいっぽい。
そんなことがTP4のときに見たドキュメントに書いてあったのを思い出した。(このドキュメントは消えてた。)&lt;/p&gt;

&lt;p&gt;実際、&lt;code&gt;docker ps&lt;/code&gt;では見えているコンテナが、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\Administrator&amp;gt;docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
a711497f29d8        pcap4j              &amp;quot;cmd&amp;quot;               13 minutes ago      Up 12 minutes                           amazing_archimedes
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コマンドレットからだと見えない。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\Administrator&amp;gt;powershell -command Get-Container
WARNING: Based on customer feedback, we are updating the Containers PowerShell module to better align with Docker. As part of that some cmdlet and parameter names may change in future releases. To learn more about these changes as well as to join in the design process or provide usage feedback please refer to http://aka.ms/windowscontainers/powershell
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そうなると、パワーシェルのコマンドレットには&lt;code&gt;docker build&lt;/code&gt;にあたるものがないのでもうどうしようもない。&lt;/p&gt;

&lt;p&gt;そもそも、TP4の頃のコマンドレットは&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/management/docker-powershell&#34;&gt;廃止になって&lt;/a&gt;、&lt;a href=&#34;https://github.com/Microsoft/Docker-PowerShell/&#34;&gt;新しいコマンドレット&lt;/a&gt;を開発中らしい。やはりdockerコマンドとコマンドレットでコンテナの相互運用ができない仕様にユーザから相当つっこみがあったようだ。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Enter-PSSession&lt;/code&gt;や&lt;code&gt;Invoke-Command&lt;/code&gt;の&lt;code&gt;-ContainerName&lt;/code&gt;オプションもその内修正されるであろう。
それまで待つか。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CloudflareでブログをHTTPS化</title>
          <link>https://www.kaitoy.xyz/2016/07/01/https-support-by-cloudflare/</link>
          <pubDate>Fri, 01 Jul 2016 14:17:41 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/07/01/https-support-by-cloudflare/</guid>
          <description>

&lt;p&gt;最近&lt;a href=&#34;https://pages.github.com/&#34;&gt;GitHub Pages&lt;/a&gt;がHTTPSに正式対応したというニュースを見たことをきっかけに、このブログを&lt;a href=&#34;https://www.cloudflare.com/&#34;&gt;Cloudflare&lt;/a&gt;で常時HTTPS化した話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;このブログ&#34;&gt;このブログ&lt;/h2&gt;

&lt;p&gt;このブログは&lt;a href=&#34;https://www.kaitoy.xyz/2015/08/15/github-pages-and-jekyll/&#34;&gt;GitHub Pagesでホストされている&lt;/a&gt;。
GitHub Pages上のWebサイトはデフォルトでは&lt;code&gt;&amp;lt;GitHubユーザ名&amp;gt;.github.io&lt;/code&gt;というドメインで公開されるが、ちょっとかっこつけたかったのでカスタムドメイン(&lt;code&gt;www.kaitoy.xyz&lt;/code&gt;)にした。&lt;/p&gt;

&lt;p&gt;GitHub Pagesは2014年3月から非公式にHTTPSをサポートしていて、2016年6月8日に&lt;a href=&#34;https://github.com/blog/2186-https-for-github-pages&#34;&gt;正式サポートを表明&lt;/a&gt;したが、これは&lt;code&gt;&amp;lt;GitHubユーザ名&amp;gt;.github.io&lt;/code&gt;ドメインだけが対象であり、カスタムドメインはHTTPSサポートされていない。&lt;/p&gt;

&lt;p&gt;要するにこのブログにはHTTP接続しかできない状態だった。
これをなんとかHTTPSに対応させたかった。&lt;/p&gt;

&lt;h2 id=&#34;なぜhttps&#34;&gt;なぜHTTPS&lt;/h2&gt;

&lt;p&gt;HTTPS化(常時SSL化)が世界的な流行りな雰囲気を感じていたのと、なにより、&lt;a href=&#34;http://googlewebmastercentral-ja.blogspot.com/2015/12/indexing-https-pages-by-default.html&#34;&gt;Googleに優遇してもらえるから&lt;/a&gt;。
Googleの検索結果の2,3ページ目までに出てこないなら、そのサイトはこの世に存在しないのとあまり変わらない。&lt;/p&gt;

&lt;p&gt;昔はHTTPSにするとSSLプロトコルのオーバーヘッドや暗号化/復号化処理によりHTTPに比べて遅くなると言われていたが、最近ではサーバ/クライアントマシンの性能が上がり、このデメリットは気にするほどのものではなくなった。
逆に、常時SSL化すると&lt;a href=&#34;https://ja.wikipedia.org/wiki/SPDY&#34;&gt;SPDY&lt;/a&gt;や&lt;a href=&#34;https://ja.wikipedia.org/wiki/HTTP/2&#34;&gt;HTTP/2&lt;/a&gt;といった高速なプロトコルの恩恵を受けることができるようになり、HTTPより速くなることもあるらしい。&lt;/p&gt;

&lt;h2 id=&#34;カスタムドメインなgithub-pagesサイトをhttps対応する方法&#34;&gt;カスタムドメインなGitHub PagesサイトをHTTPS対応する方法&lt;/h2&gt;

&lt;p&gt;上記の通りこのブログはカスタムドメインでGitHub Pagesのサポートがなく直接にはHTTPS対応できない。
よって間接的に対応することになるので、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%AA%E3%83%90%E3%83%BC%E3%82%B9%E3%83%97%E3%83%AD%E3%82%AD%E3%82%B7&#34;&gt;リバースプロキシ&lt;/a&gt;を使うことになる。
リバースプロキシサーバを自分で運用するのは大変なので、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%B3%E3%83%B3%E3%83%86%E3%83%B3%E3%83%84%E3%83%87%E3%83%AA%E3%83%90%E3%83%AA%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF&#34;&gt;CDN&lt;/a&gt;サービスを利用する。&lt;/p&gt;

&lt;p&gt;CDNサービスでまず思い当たったのはAWSの&lt;a href=&#34;https://aws.amazon.com/jp/cloudfront/&#34;&gt;CloudFront&lt;/a&gt;だけど、なんだか大げさで面倒そう。
あとは&lt;a href=&#34;https://www.cloudflare.com/&#34;&gt;Cloudflare&lt;/a&gt;が有名なので調べたところ、手軽で無料でよさそうだったのでこれにした。&lt;/p&gt;

&lt;p&gt;因みに、ごく最近始まったサービスの&lt;a href=&#34;https://www.kloudsec.com/&#34;&gt;Kloudsec&lt;/a&gt;というのも見つけたけど、まだベータが付いているし、遅いだのそもそもつながらないだの評判が悪かったのでこれは無し。&lt;/p&gt;

&lt;p&gt;Cloudflareを利用すると、もともとだいたいこんな感じ↓だったのが、&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/direct/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/direct/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/direct/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/direct/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/direct/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/direct/スライド6.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/direct/スライド7.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/direct/スライド8.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/direct/スライド9.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;こんな感じ↓になる。多分。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド6.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド7.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド8.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド9.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド10.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド11.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上のスライド中のリバースプロキシは実際にはいくつもあり、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%A8%E3%83%8B%E3%83%BC%E3%82%AD%E3%83%A3%E3%82%B9%E3%83%88&#34;&gt;エニーキャスト&lt;/a&gt;によってブラウザから一番近いものが使われる。&lt;/p&gt;

&lt;h2 id=&#34;cloudflare事始め&#34;&gt;Cloudflare事始め&lt;/h2&gt;

&lt;p&gt;Cloudflareの始め方は&lt;a href=&#34;http://qiita.com/superbrothers/items/95e5723e9bd320094537&#34;&gt;Qiitaの記事&lt;/a&gt;を参考にした。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Cloudflareのアカウント作成&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cloudflare.com/&#34;&gt;Cloudflareのサイト&lt;/a&gt;に行って&lt;code&gt;Sign up&lt;/code&gt;のリンクからメアドとパスワードを渡してアカウントを作成。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Cloudflareにサイトを登録&lt;/p&gt;

&lt;p&gt;アカウント作成後に開くページに従い、4つのステップをこなすとサービス利用開始できる。&lt;/p&gt;

&lt;p&gt;まずはサイトの登録。
サブドメインを除いた&lt;code&gt;kaitoy.xyz&lt;/code&gt;を入力して&lt;code&gt;Begin Scan&lt;/code&gt;をクリック。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/add_domain.png&#34; alt=&#34;add_domain.png&#34; title=&#34;add_domain.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;何かのスキャンが始まるので1分ほど待つ。何をしているのかはよくわからない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;CloudflareのDNSの設定&lt;/p&gt;

&lt;p&gt;次のステップでCloudflareのDNSにレコードを登録する。
ブラウザからのトラフィックの誘導には&lt;code&gt;A&lt;/code&gt;か&lt;code&gt;AAAA&lt;/code&gt;か&lt;code&gt;CNAME&lt;/code&gt;を登録できる。
トラフィックは&lt;code&gt;kaitoy.github.io&lt;/code&gt;に送りたいけど、IPアドレスは自分でコントロールできないので&lt;code&gt;A&lt;/code&gt;と&lt;code&gt;AAAA&lt;/code&gt;は使えない。
&lt;code&gt;CNAME&lt;/code&gt;を登録した。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/dns.png&#34; alt=&#34;dns.png&#34; title=&#34;dns.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;適当に入力して&lt;code&gt;Add Record&lt;/code&gt;を押すとレコードを登録できるが、&lt;code&gt;Status&lt;/code&gt;のところがデフォルトで&lt;code&gt;DNS only&lt;/code&gt;(灰色のクラウドのアイコン)になっているので、アイコンをクリックして&lt;code&gt;DNS and HTTP proxy (CDN)&lt;/code&gt;(オレンジ色のクラウドのアイコン)にしておく。
こうしないとブラウザからのトラフィックがCloudflareを経由せず、HTTPS化できないはず。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プランの選択&lt;/p&gt;

&lt;p&gt;サービスプランは無料の&lt;code&gt;Free Website&lt;/code&gt;を選択。常時SSL化するだけならこれで十分なはず。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/select_plan.png&#34; alt=&#34;select_plan.png&#34; title=&#34;select_plan.png&#34; /&gt;
&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;レジストラのネームサーバの変更&lt;/p&gt;

&lt;p&gt;最後にレジストラのサイトに行ってネームサーバを変更するように指示される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/change_your_ns.png&#34; alt=&#34;change_your_ns.png&#34; title=&#34;change_your_ns.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;Cloudflareからは二つのネームサーバが割り当てられたようだ。
指示されたとおりに変更する。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;cloudflareの設定&#34;&gt;Cloudflareの設定&lt;/h2&gt;

&lt;p&gt;サインアップが終わるとCloudflareのダッシュボードが開く。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/dashboard.png&#34; alt=&#34;dashboard.png&#34; title=&#34;dashboard.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ダッシュボードの&lt;code&gt;Overview&lt;/code&gt;の&lt;code&gt;Statusは&lt;/code&gt;最初は&lt;code&gt;Pending&lt;/code&gt;になっていて、これはネームサーバの変更を反映中ということらしかった。
ネームサーバの変更は数時間くらいかかったが、変更中も&lt;code&gt;http://www.kaitoy.xyz/&lt;/code&gt;にはアクセスできた。&lt;/p&gt;

&lt;p&gt;ダッシュボードからやった設定は以下。
これも&lt;a href=&#34;http://qiita.com/superbrothers/items/95e5723e9bd320094537&#34;&gt;Qiitaの記事&lt;/a&gt;を参考にした。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;SSL&lt;/p&gt;

&lt;p&gt;ダッシュボードの&lt;code&gt;Crypto&lt;/code&gt;の&lt;code&gt;SSL&lt;/code&gt;の設定はデフォルトで&lt;code&gt;Full (strict)&lt;/code&gt;になっている。
これはブラウザ-Cloudflare間とCloudflare-GitHub Pages間両方をSSL化する設定。
上で書いたようにGitHub Pagesの方はSSL対応できずこの設定は使えないので、&lt;code&gt;Flexible&lt;/code&gt;に変更。
こちらはブラウザ-Cloudflare間だけをSSL化する。&lt;/p&gt;

&lt;p&gt;この設定変更をして、SSL証明書が発行されるまで数時間待ったら&lt;code&gt;https://www.kaitoy.xyz/&lt;/code&gt;にアクセスできるようになった。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;HSTS&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/HTTP_Strict_Transport_Security&#34;&gt;HSTS&lt;/a&gt;はHTTPでアクセスしてきたブラウザにHTTPSでアクセスするよう指示する仕組み。
これを有効にしてよりセキュアにする。
ダッシュボードの&lt;code&gt;Crypto&lt;/code&gt;の&lt;code&gt;HTTP Strict Transport Security (HSTS)&lt;/code&gt;から以下の様に設定した。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/hsts.png&#34; alt=&#34;hsts.png&#34; title=&#34;hsts.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kaitoy.xyz&lt;/code&gt;だけじゃなくて&lt;code&gt;www.kaitoy.xyz&lt;/code&gt;で有効にするため、&lt;code&gt;Include subdomains&lt;/code&gt;を&lt;code&gt;On&lt;/code&gt;にしておくのが肝要のはず。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;HTTPSへのリダイレクト&lt;/p&gt;

&lt;p&gt;HTTPでのアクセスをHTTPSにリダイレクトする設定を加える。
ダッシュボードの&lt;code&gt;Page Rules&lt;/code&gt;で以下のルールを作った。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/page_rules.png&#34; alt=&#34;page_rules.png&#34; title=&#34;page_rules.png&#34; /&gt;
&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;ブログサイトの修正&#34;&gt;ブログサイトの修正&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;link&lt;/code&gt;タグや&lt;code&gt;script&lt;/code&gt;タグの&lt;code&gt;www.kaitoy.xyz&lt;/code&gt;を指しているURLをHTTPSに修正。
内部リンクも全部HTTPSにした。これで完了。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ソフトウェアプロジェクトの7つの大罪</title>
          <link>https://www.kaitoy.xyz/2016/06/25/seven-deadly-sins-of-a-software-project/</link>
          <pubDate>Sat, 25 Jun 2016 18:00:29 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/06/25/seven-deadly-sins-of-a-software-project/</guid>
          <description>

&lt;p&gt;このエントリでは、Yegor Bugayenkoによる記事、&lt;a href=&#34;http://www.yegor256.com/2015/06/08/deadly-sins-software-project.html&#34;&gt;Seven Deadly Sins of a Software Project&lt;/a&gt;を紹介する。
(Yegorから和訳と転載の許可は得た。)
以下はその全文の和訳だが、意訳超訳が混じっているので、もとのニュアンスを知りたければ元記事を読んでもいいし、読まなくてもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;保守性は近代ソフトウェア開発において&lt;a href=&#34;http://www.yegor256.com/2014/10/26/hacker-vs-programmer-mentality.html&#34;&gt;最も重要な美徳だ&lt;/a&gt;。
&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E4%BF%9D%E5%AE%88%E6%80%A7&#34;&gt;保守性&lt;/a&gt;は基本的に、新規開発者が本格的な修正を始める前に必要な学習時間で測ることができる。
学習時間が長いほど保守性は低い。
必要な学習時間が無限に近いプロジェクトもあるが、これは文字通り保守不能だ。
私はソフトウェアを保守不能にする7つの基本的で致命的な罪があると考えている。
それらについてここに書く。&lt;/p&gt;

&lt;h2 id=&#34;アンチパターン&#34;&gt;アンチパターン&lt;/h2&gt;

&lt;p&gt;&lt;img alt=&#34;ap.gif&#34; src=&#34;https://www.kaitoy.xyz/images/seven-deadly-sins-of-a-software-project/ap.gif&#34; width=&#34;300&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;不幸にも、我々が使っているプログラミング言語は柔軟すぎる。
可能なことが多過ぎ、禁止されていることは少なすぎる。
例えばJavaは、数千のメソッドを持った単一の「クラス」でアプリケーション全体を記述することに何の反抗もしない。
このアプリケーションは技術的にはコンパイルして実行できる。
しかしこれは&lt;a href=&#34;https://maku77.github.io/program/god-class.html&#34;&gt;ゴッドオブジェクト&lt;/a&gt;と呼ばれるよく知られたアンチパターンだ。&lt;/p&gt;

&lt;p&gt;つまり、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%B3%E3%83%81%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3&#34;&gt;アンチパターン&lt;/a&gt;は技術的には設計に取り入れることができるが、一般的には取り入れるべきではないとされている。
言語ごとに多くのアンチパターンがある。
プロダクトに使われているアンチパターンは、生きている有機体の中の腫瘍のようなものだ。
いったん成長し始めると止めるのは非常に難しい。
やがて体全体が死に至る。
やがてソフトウェア全体が保守不能になり、書き直さなければならなくなる。&lt;/p&gt;

&lt;p&gt;ひとたびアンチパターンを使ってしまうと、その量は次第に増え、「腫瘍」は育つばかりだ。&lt;/p&gt;

&lt;p&gt;これは特にオブジェクト指向言語(Java、C++、Ruby、Python)に当てはまる。
これらが手続き型言語(C、Fortran、COBOL)から多くを引き継いでしまっているからだ。
また、OOP開発者が手続き型で命令的な思考をする傾向にあるからだ。残念なことに。&lt;/p&gt;

&lt;p&gt;ところで、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%B3%E3%83%81%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3&#34;&gt;既存の有名なアンチパターン&lt;/a&gt;のほかに、私は以下のものもダメなコーディング法だと考えている。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/07/26/why-null-is-bad/&#34;&gt;NULL参照&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2016/01/03/oop-alternative-to-utility-classes/&#34;&gt;ユーティリティクラス&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.yegor256.com/2014/06/09/objects-should-be-immutable.html&#34;&gt;可変オブジェクト&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/07/22/getters-setters-evil/&#34;&gt;GetterとSetter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/09/13/orm-is-offensive-anti-pattern/&#34;&gt;オブジェクト関係マッピング(ORM)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;シングルトン&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.yegor256.com/2015/03/09/objects-end-with-er.html&#34;&gt;Controllers、Managers、Validators&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.yegor256.com/2015/02/20/utility-classes-vs-functional-programming.html&#34;&gt;Public Static メソッド&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.yegor256.com/2015/04/02/class-casting-is-anti-pattern.html&#34;&gt;キャスト&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;私ができる実践的な提案は、読んで学ぶということだけだ。
&lt;a href=&#34;http://www.yegor256.com/2015/04/22/favorite-software-books.html&#34;&gt;ここ&lt;/a&gt;に挙げた本か私の著書「&lt;a href=&#34;http://www.yegor256.com/elegant-objects.html&#34;&gt;&amp;ldquo;Elegant Objects&lt;/a&gt;」が多分助けになるだろう。
常にソフトウェアの品質を疑い、「動く」ということだけで満足してはいけない。
ちょうど癌のように、診断が早ければ早いほど生き残る可能性が大きい。&lt;/p&gt;

&lt;h2 id=&#34;追跡不能な変更&#34;&gt;追跡不能な変更&lt;/h2&gt;

&lt;p&gt;&lt;img alt=&#34;uc.gif&#34; src=&#34;https://www.kaitoy.xyz/images/seven-deadly-sins-of-a-software-project/uc.gif&#34; width=&#34;300&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;コミット履歴を見るとき、全ての個々の変更に対して、何を、誰が、なぜ変更したのかがわからないといけない。
さらに、これら3つの情報を得るのにかかる時間は秒単位で計測しないといけない。
殆どのプロジェクトがこのようにできていない。
以下に実践的な提案を示す。&lt;/p&gt;

&lt;h4 id=&#34;常にチケットを使う&#34;&gt;常にチケットを使う&lt;/h4&gt;

&lt;p&gt;プロジェクトやチームがどんなに小さくても、例え一人だけでも、修正しようとしている全ての問題に対してチケット(GitHub issues)を作れ。
チケットに問題の簡単な説明とそれに対する考えを記述しろ。
このチケットをその問題に関する全ての情報の一時的なストレージとして使え。
将来、他の誰かがその「不可解なコミット」が何であるかを理解するために参照する可能性のある全ての情報をそこに書け。&lt;/p&gt;

&lt;h4 id=&#34;コミットからチケットを参照する&#34;&gt;コミットからチケットを参照する&lt;/h4&gt;

&lt;p&gt;言うまでもないが、全てのコミットにはメッセージが付いていないといけない。
メッセージのないコミットはまったくひどい悪習だ。議論の余地はない。
しかしメッセージだけでは不十分だ。
全てのメッセージはチケット番号で始まらないといけない。
GitHub(君ももちろん使っていると思うが)は自動でコミットとチケットをリンクし、変更の追跡可能性を高めてくれる。&lt;/p&gt;

&lt;h4 id=&#34;何も消さない&#34;&gt;何も消さない&lt;/h4&gt;

&lt;p&gt;Gitは「強制」push、つまりサーバに既にあるブランチ全体を上書きするpushを許している。
これは開発履歴を破壊する方法の例のひとつだ。
また、GitHubのチケットを「きれい」にするためにコメントを削除するのをよく見るが、これはまったくの間違いだ。
何であれ決して消すな。
履歴がどんなに汚く(または乱雑に)見えても、そのまま残しておくことだ。&lt;/p&gt;

&lt;h2 id=&#34;アドホックリリース&#34;&gt;アドホックリリース&lt;/h2&gt;

&lt;p&gt;&lt;img alt=&#34;ahr.gif&#34; src=&#34;https://www.kaitoy.xyz/images/seven-deadly-sins-of-a-software-project/ahr.gif&#34; width=&#34;300&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;全てのソフトウェアはエンドユーザに届けられる前にパッケージングされなければいけない。
Javaのライブラリであれば&lt;code&gt;.jar&lt;/code&gt;ファイルにパッケージングされリポジトリにリリースされないといけない。
ウェブアプリケーションであればプラットフォームにデプロイされないといけない。
プロダクトの大きさにかかわらず、テスト、パッケージング、デプロイする正規の手順は常にあるべきだ。&lt;/p&gt;

&lt;p&gt;理想的な解決策はこの手順を自動化し、コマンドラインから単一のコマンドで実行できるようにすることだ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ ./release.sh
...
DONE (took 98.7s)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ほとんどのプロジェクトはこれに程遠い。
そのリリースプロセスにはマジックが含まれていて、担当者(DevOpともいう)はあちらこちらのボタンをクリックしないといけない。
どこかにログインして、いくつかの指標をチェックして、など。
このようなアドホックリリース手順は、ソフトウェアエンジニアリング業界全体でいまだに典型的な罪である。&lt;/p&gt;

&lt;p&gt;ここで私ができる実践的なアドバイスはひとつだけだ。自動化しろ。
私は自動化に&lt;a href=&#34;http://www.yegor256.com/2014/09/11/deployment-script-vs-rultor.html&#34;&gt;rultor.com&lt;/a&gt;を使っているが、好きなのを使えばよい。
重要なのは、手順全体が完全自動化されていてコマンドラインから実行できることだ。&lt;/p&gt;

&lt;h2 id=&#34;自発的静的解析&#34;&gt;自発的静的解析&lt;/h2&gt;

&lt;p&gt;&lt;img alt=&#34;vsa.gif&#34; src=&#34;https://www.kaitoy.xyz/images/seven-deadly-sins-of-a-software-project/vsa.gif&#34; width=&#34;300&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E9%9D%99%E7%9A%84%E3%82%B3%E3%83%BC%E3%83%89%E8%A7%A3%E6%9E%90&#34;&gt;静的解析&lt;/a&gt;はコードの見た目を良くしてくれる。
見た目がよくなると、必然的に上手く動くようになる。
しかしこれは、チームの全員が静的解析ツールに指示されたルールに従うことを強制(!)されているときだけ有効だ。
私はこれについて&lt;a href=&#34;http://www.yegor256.com/2014/08/13/strict-code-quality-control.html&#34;&gt;Strict Control of Java Code Quality&lt;/a&gt;に書いた。
私はJavaプロジェクトでは&lt;a href=&#34;http://www.qulice.com/&#34;&gt;qulice.com&lt;/a&gt;を使い、Rubyでは&lt;a href=&#34;https://github.com/bbatsov/rubocop&#34;&gt;rubocop&lt;/a&gt;を使うが、他にも似たようなツールがほとんど全ての言語にある。&lt;/p&gt;

&lt;p&gt;どんなツールを使ってもいいが、強制しなければいけない!
静的解析ツールを使っているほとんどのプロジェクトで、開発者は単に見栄えのいいレポートを生成するだけで、コードの書き方を直そうとはしない。
そのような「自発的な」アプローチはプロジェクトにとって何のメリットもない。そればかりか、品質への錯覚を生む。&lt;/p&gt;

&lt;p&gt;私が言いたいのは、静的解析は開発パイプラインの中の必須ステップでなければいけないということだ。
もし静的解析ルールがひとつでも破られたら、ビルドを成功にしてはいけない。&lt;/p&gt;

&lt;h2 id=&#34;未知のテストカバレージ&#34;&gt;未知のテストカバレージ&lt;/h2&gt;

&lt;p&gt;&lt;img alt=&#34;utc.gif&#34; src=&#34;https://www.kaitoy.xyz/images/seven-deadly-sins-of-a-software-project/utc.gif&#34; width=&#34;300&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;簡単に言うと、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%B3%E3%83%BC%E3%83%89%E7%B6%B2%E7%BE%85%E7%8E%87&#34;&gt;テストカバレージ&lt;/a&gt;はソフトウェアがユニットテストや統合テストでテストされた度合いだ。
カバレージが高いほど、テスト中に実行されたコードの量が多い。
カバレージ高いのは明らかに良いことだ。&lt;/p&gt;

&lt;p&gt;しかし、多くのプロジェクトで開発者は単にカバレージを知らない。
この指標を計測しないのだ。
テストは書いているかもしれないが、それがソフトウェアのどの程度深くまで行き渡っているか、どの部分がテストされていないのか、誰も全く知らない。
このような状態よりは、カバレージが低くても、計測されて皆にレポートされている状態の方がかなり良い。、&lt;/p&gt;

&lt;p&gt;高いカバレージは高い品質を保証するものではない。
これは明らかだ。
しかし、テストカバレージが未知であることは保守性に問題があるという明確な印だ。
プロジェクトに入った新規開発者は、修正がどの程度カバレージに影響を与えるかを確認できなければいけない。
理想的には、テストカバレージは静的解析でチェックされ、事前に決められた閾値(普通80%位)を下回ったらビルドが失敗するようになっているべきだ。&lt;/p&gt;

&lt;h2 id=&#34;ノンストップ開発&#34;&gt;ノンストップ開発&lt;/h2&gt;

&lt;p&gt;&lt;img alt=&#34;nd.gif&#34; src=&#34;https://www.kaitoy.xyz/images/seven-deadly-sins-of-a-software-project/nd.gif&#34; width=&#34;300&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;ここでノンストップが意味するのは、マイルストーンもリリースも無いということだ。
書いているソフトウェアの種類によらず、頻繁に&lt;a href=&#34;http://semver.org/lang/ja/&#34;&gt;バージョニング&lt;/a&gt;とリリースをしないといけない。
明確なリリース履歴が無いプロジェクトは保守不能なガラクタだ。&lt;/p&gt;

&lt;p&gt;これは概ね、保守性とは私が君のコードを読んで君を理解できるかということだからだ。&lt;/p&gt;

&lt;p&gt;私がソースとそのコミットとリリース履歴を見るとき、開発者の意図が何で、プロジェクトが一年前に何をしていて、今どこに向かっているのか、ロードマップは何か、といったことを説明できなければいけない。
こうした情報の全ては、ソースコード中とGit履歴(こちらがより重要)に入っていなければいけない。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://git-scm.com/book/en/v2/Git-Basics-Tagging&#34;&gt;Gitタグ&lt;/a&gt;と&lt;a href=&#34;https://github.com/blog/1547-release-your-software&#34;&gt;GitHubリリース&lt;/a&gt;はそうした情報を残すための強力な道具だ。
これらをめいっぱい使え。
また、それぞれのバージョンのバイナリは直接ダウンロードできるようにしておくことを忘れるな。
プロジェクトが今バージョン3.4を開発していたとしても、即座にバージョン0.1.3をダウンロードしてテストできなければいけない。&lt;/p&gt;

&lt;h2 id=&#34;ドキュメントに載っていないインターフェース&#34;&gt;ドキュメントに載っていないインターフェース&lt;/h2&gt;

&lt;p&gt;&lt;img alt=&#34;ui.gif&#34; src=&#34;https://www.kaitoy.xyz/images/seven-deadly-sins-of-a-software-project/ui.gif&#34; width=&#34;300&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;全てのソフトウェアは、その機能を使うためのインターフェースを持っている。
RubyのGemであれば、エンドユーザが利用できるクラスとメソッドがある。
Webアプリケーションであれば、エンドユーザが参照して操作できるWebページがある。
全てのソフトウェアプロジェクトはインターフェースを持ち、そのインターフェースは入念にドキュメント化されていないといけない。&lt;/p&gt;

&lt;p&gt;これまでに挙げた全ての項目のように、これも保守性に関することだ。
プロジェクトの新規プログラマは、ソフトウェアをインターフェースから学び始める。
そのソフトウェアが何をするものなのかを理解して自分で使ってみる、ということができなければいけない。&lt;/p&gt;

&lt;p&gt;私はここでユーザに対するドキュメンテーションの話をしている。開発者に対するものではない。
一般的に、ソフトウェア内部のドキュメンテーションには反対だ。
私は&lt;a href=&#34;http://agilemanifesto.org/iso/ja/&#34;&gt;アジャイルソフトウェア開発宣言&lt;/a&gt;に完全に同意している。
動くソフトウェアは包括的なドキュメントよりもはるかに重要だ。
しかしそれは、(開発者ではなく)ユーザが読むための「外部」ドキュメントのことを指しているわけではない。&lt;/p&gt;

&lt;p&gt;要は、エンドユーザとソフトウェアとの間の相互作用はドキュメントに明記されていなければいけない。&lt;/p&gt;

&lt;p&gt;ライブラリであれば、エンドユーザはそれを使うソフトウェア開発者だ。
コントリビュータではなく、それを「ブラックボックス」として単に使うだけの開発者だ。&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;embed video-player&#34; style=&#34;text-align: center&#34;&gt;
  &lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;320&#34; height=&#34;193&#34; src=&#34;https://www.youtube.com/embed/ZtWmlKi3ivc&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上がYegorの記事。&lt;/p&gt;

&lt;p&gt;一般的に認知されているベストプラクティスやアジャイル感に沿った、Yegorにしては丸い内容だ。
むしろ、現在は既にアジャイルは完全に浸透して、その次のステップとしてDevOpsをめざす時代になっているので、開発サイドだけに言及したこの内容だと少々保守的で古臭く感じさえする。&lt;/p&gt;

&lt;p&gt;ただ、改めてだけど、「&lt;a href=&#34;http://localhost:1313/2016/06/25/seven-deadly-sins-of-a-software-project/#%E8%BF%BD%E8%B7%A1%E4%B8%8D%E8%83%BD%E3%81%AA%E5%A4%89%E6%9B%B4&#34;&gt;追跡不能な変更&lt;/a&gt;」に書いてあることはいいプラクティスだと思う。
GitHubで開発するときは、全てのコミットがIssuesかPull Requestsに紐付いていて、相互に導出可能であると便利そう。
面倒だからやったことないけど。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;「&lt;a href=&#34;http://localhost:1313/2016/06/25/seven-deadly-sins-of-a-software-project/#%E3%83%89%E3%82%AD%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%88%E3%81%AB%E8%BC%89%E3%81%A3%E3%81%A6%E3%81%84%E3%81%AA%E3%81%84%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%BC%E3%83%95%E3%82%A7%E3%83%BC%E3%82%B9&#34;&gt;ドキュメントに載っていないインターフェース&lt;/a&gt;」に書いてあることはちょっと引っかかる。
アメリカ人ってのは、分厚い細かいドキュメントなんか書いても誰も読まねーよ、ってのが基本のスタンスだと思っていた。
Steve Jobsだったら、ドキュメントが必要なくなるまでUIを洗練させろとか言いそうだ。
もしくはユースケースベースのざっくりとしたマニュアルをメインにしたり。&lt;/p&gt;

&lt;p&gt;全てのインターフェースを入念にドキュメントしろっていうのはなんだかとても日本的だ。
そうしてくれた方が使う方は助かるんだけど、作る側はドキュメントの保守が大変だ。かなり頑張って気を使っても、ドキュメントと実装のずれってのは本当に簡単に頻繁に起こる。特に大きい会社の大きいプロジェクトで、開発チームとは別にマニュアルチームがあるような場合、このずれはほとんど全く避けられない。&lt;/p&gt;

&lt;p&gt;自然言語でのプログラミングへの希望が大昔からあるようだけど、そんなものより、プログラミング言語で書いたものから自然言語のマニュアルを生成してくれるもののほうがよっぽど価値があると思う。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Pcap4J in Kotlin</title>
          <link>https://www.kaitoy.xyz/2016/04/16/pcap4j-in-kotlin/</link>
          <pubDate>Sat, 16 Apr 2016 11:09:53 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/04/16/pcap4j-in-kotlin/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2016/04/10/pcap4j-in-groovy/&#34;&gt;Groovy&lt;/a&gt;に続いて、&lt;a href=&#34;https://kotlinlang.org/&#34;&gt;&lt;strong&gt;Kotlin&lt;/strong&gt;&lt;/a&gt;で&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;&lt;strong&gt;Pcap4J&lt;/strong&gt;&lt;/a&gt;を使ってパケットキャプチャしてみた。&lt;/p&gt;

&lt;p&gt;KotlinからでもPcap4Jちゃんと動くよということを実証するのが主な目的。
また、今後JavaなアプリはKotlinで書こうかと思っているので、その予習も兼ねている。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;kotlinとは&#34;&gt;Kotlinとは&lt;/h2&gt;

&lt;p&gt;KotlinはJVM言語、つまりJavaのバイトコードにコンパイルされてJavaの実行環境で動くプログラミング言語のひとつ。
&lt;a href=&#34;https://www.jetbrains.com/idea/&#34;&gt;IntelliJ IDEA&lt;/a&gt;で有名な&lt;a href=&#34;https://www.jetbrains.com/&#34;&gt;JetBrains社&lt;/a&gt;によって&lt;a href=&#34;https://github.com/JetBrains/kotlin&#34;&gt;OSS&lt;/a&gt;として開発されている。&lt;/p&gt;

&lt;p&gt;2011年に生まれた新しめな言語で、2016/2/17に&lt;a href=&#34;http://blog.jetbrains.com/jp/2016/02/17/578&#34;&gt;v1がリリースされ&lt;/a&gt;、主にAndroidアプリの開発用として注目されている。&lt;/p&gt;

&lt;p&gt;「実用的」であることを売りにしていて、つまり少ない学習コストで導入でき、既存のJavaコードやMavenなどのツールとの相互運用性を持つとされている。
IntelliJ IDEA、&lt;a href=&#34;http://developer.android.com/sdk/index.html&#34;&gt;Android Studio&lt;/a&gt;、&lt;a href=&#34;https://eclipse.org/&#34;&gt;Eclipse&lt;/a&gt;といった主要なIDEのサポートもあり、開発環境は整っている。
v1以降の後方互換性の維持も表明されていて、長期サポートが必要な製品開発にも堪える。&lt;/p&gt;

&lt;p&gt;さらに、厳格な静的型付けやNullable/Non-Null型などにより安全性を確保しつつ、型推論やラムダ式などで生産性を高めている。&lt;/p&gt;

&lt;p&gt;Javaのバイトコードだけでなく、JavaScriptを生成するバックエンドを持っているのも大きな特徴。
ユースケースがよく分からないが。&lt;/p&gt;

&lt;p&gt;GitHubにホストされているKotlinプロジェクトは、2016/4/15現在、全体の &lt;strong&gt;0.1%&lt;/strong&gt; (&lt;sup&gt;3493&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3215549&lt;/sub&gt;) しかない。
v1のリリースは結構注目を集めたので、この割合は今後増えていくと期待される。&lt;/p&gt;

&lt;h2 id=&#34;kotlinのインストール&#34;&gt;Kotlinのインストール&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://kotlinlang.org/docs/tutorials/&#34;&gt;チュートリアル&lt;/a&gt;に従えば、IDEやテキストエディタ+コマンドラインの環境を整えてHello Worldを書いて実行するところまで簡単にできる。
筆者はEclipse(Mars)とコマンドラインの環境をWindows 7上で作った。
Kotlinのバージョンは1.0.1-2。&lt;/p&gt;

&lt;p&gt;コマンドラインについては、&lt;a href=&#34;https://github.com/JetBrains/kotlin/releases/latest&#34;&gt;GitHub Releases&lt;/a&gt;からアーカイブをダウンロードして、適当なところに展開して&lt;code&gt;bin&lt;/code&gt;フォルダにパスを通すだけ。
前提となるJavaについては、環境変数&lt;code&gt;JAVA_HOME&lt;/code&gt;を設定するか、&lt;code&gt;java&lt;/code&gt;コマンドにパスを通せばいい模様。&lt;/p&gt;

&lt;p&gt;因みにKotlinの書き方は、&lt;a href=&#34;https://kotlinlang.org/docs/tutorials/koans.html&#34;&gt;Kotlin Koans&lt;/a&gt;という例題集を&lt;a href=&#34;http://try.kotlinlang.org/koans&#34;&gt;オンラインのIDE&lt;/a&gt;で解きながらを学ぶことができる。&lt;/p&gt;

&lt;h2 id=&#34;パケットキャプチャ-with-pcap4j-in-java&#34;&gt;パケットキャプチャ with Pcap4J in Java&lt;/h2&gt;

&lt;p&gt;Pcap4Jでパケットキャプチャするコードを普通にJavaで書くと以下の様になる。
(&lt;a href=&#34;https://www.kaitoy.xyz/2016/04/10/pcap4j-in-groovy/&#34;&gt;Groovy&lt;/a&gt;の時のと一緒。)&lt;/p&gt;

&lt;p&gt;&lt;script src=&#34;https://gist.github.com/kaitoy/eebcd5bdfab179cab916d3182f3d6d11.js&#34;&gt;&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;これを実行すると、パケットキャプチャするネットワークインターフェースを選択し、5つのパケットをキャプチャしてタイムスタンプと共にコンソールに表示する。&lt;/p&gt;

&lt;h2 id=&#34;パケットキャプチャ-with-pcap4j-in-kotlin&#34;&gt;パケットキャプチャ with Pcap4J in Kotlin&lt;/h2&gt;

&lt;p&gt;上記処理をKotlinで書くと以下の様になる。&lt;/p&gt;

&lt;p&gt;&lt;script src=&#34;https://gist.github.com/kaitoy/074769880c7bf4c0628c1c25a724c1a7.js&#34;&gt;&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;メインクラスはGroovy同様書かなくていいが、&lt;code&gt;main&lt;/code&gt;関数は必要。&lt;/p&gt;

&lt;p&gt;型推論があってとても楽。
ラムダ式、補間文字列(String interpolation)、名前付き引数といったモダンめな機能は普通に使える。
(名前付き引数はJavaで書いたメソッドをKotlinから呼ぶときは使えない。)&lt;/p&gt;

&lt;p&gt;オープンクラスを実現する機能である&lt;a href=&#34;https://kotlinlang.org/docs/reference/extensions.html&#34;&gt;Extensions&lt;/a&gt;を&lt;code&gt;PcapHandle&lt;/code&gt;に使ってみた。
なんだか便利そう。&lt;/p&gt;

&lt;p&gt;Nullable/Non-Null型がすごい。言語仕様で&lt;code&gt;NullPointerException&lt;/code&gt;が発生しないように守ってくれる。
例えば&lt;code&gt;filter&lt;/code&gt;は宣言の時点では初期化文で&lt;code&gt;null&lt;/code&gt;が入る可能性があるので&lt;code&gt;Nullable&lt;/code&gt;な&lt;code&gt;String&lt;/code&gt;という型に推論されるが、&lt;code&gt;filter?.let&lt;/code&gt;というNullチェックをするメソッドに渡したブロック内では自動で&lt;code&gt;Non-Null&lt;/code&gt;な&lt;code&gt;String&lt;/code&gt;にキャストされ、&lt;code&gt;filter.length&lt;/code&gt;を安全に評価できるようになっている。
Nullチェックをしないで&lt;code&gt;filter.length&lt;/code&gt;と書くとコンパイルエラーになる。すごい。&lt;/p&gt;

&lt;p&gt;けどJavaのコードから返ってくるオブジェクトは普通、プラットフォーム型というものになり、このNullセーフな仕組みが働かない。
これに対しては&lt;a href=&#34;https://kotlinlang.org/docs/reference/java-interop.html#nullability-annotations&#34;&gt;Null可能性アノテーション&lt;/a&gt;を使えば幸せになれるらしい。&lt;/p&gt;

&lt;p&gt;さらに、上記コードには表れていないが、キャストも安全になっている模様。(cf. &lt;a href=&#34;http://kotlinlang.org/docs/reference/typecasts.html#smart-casts&#34;&gt;スマートキャスト&lt;/a&gt;、&lt;a href=&#34;http://kotlinlang.org/docs/reference/typecasts.html#safe-nullable-cast-operator&#34;&gt;セーフキャスト&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Kotlinは基本コンパイラ言語なので、上記コードを実行するには以下ようなコマンドで一旦コンパイルする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;kotlinc -cp pcap4j-core.jar Pcap4jLoop.kt -include-runtime -d Pcap4jLoop.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このコマンドだとKotlinのランタイム入りjarファイルができる。
このjarを、Pcap4J 1.6.2、Slf4J 1.7.12、JNA 4.2.1を使って、以下のコマンドで実行できることを確認した。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;java -cp pcap4j-core.jar;pcap4j-packetfactory-static.jar;jna.jar;slf4j-api.jar;Pcap4jLoop.jar Pcap4jLoopKt tcp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このコマンドで指定しているメインクラス&lt;code&gt;Pcap4jLoopKt&lt;/code&gt;は、上記コードでクラスの記述を省いた為にKotlinがソースファイル名(Pcap4jLoop.kt)を基に自動生成したもの。&lt;/p&gt;

&lt;p&gt;コンパイル/実行方法は&lt;a href=&#34;https://kotlinlang.org/docs/tutorials/command-line.html#creating-and-running-a-first-application&#34;&gt;他にもある&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;スクリプトなkotlin&#34;&gt;スクリプトなKotlin&lt;/h2&gt;

&lt;p&gt;Kotlinプログラムはスクリプトとしても書けて、コンパイル無しで実行することができる。
この場合、&lt;code&gt;main&lt;/code&gt;関数は消してその中身をトップレベルに書き、ファイルの拡張子を&lt;code&gt;.kts&lt;/code&gt;にする。&lt;/p&gt;

&lt;p&gt;&lt;script src=&#34;https://gist.github.com/kaitoy/b6ee844ad2353585a30984ef0bedf844.js&#34;&gt;&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;上記スクリプトは以下のコマンドで実行できた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;kotlinc -cp pcap4j-core.jar;jna.jar;pcap4j-packetfactory-static.jar;slf4j-api.jar -script Pcap4jLoop.kts tcp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;EclipseのKotlinプラグインはこのスクリプト形式をまだサポートしていないようで残念。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Pcap4J in Groovy</title>
          <link>https://www.kaitoy.xyz/2016/04/10/pcap4j-in-groovy/</link>
          <pubDate>Sun, 10 Apr 2016 00:05:27 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/04/10/pcap4j-in-groovy/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://www.groovy-lang.org/index.html&#34;&gt;&lt;strong&gt;Groovy&lt;/strong&gt;&lt;/a&gt;で&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;&lt;strong&gt;Pcap4J&lt;/strong&gt;&lt;/a&gt;を使ってパケットキャプチャしてみた。&lt;/p&gt;

&lt;p&gt;GroovyからでもPcap4Jちゃんと動くよということを実証するのが主な目的。
また、さすがにそろそろ&lt;a href=&#34;https://maven.apache.org/&#34;&gt;Maven&lt;/a&gt;を卒業してGradle(下記)使おうと思うので、予習も兼ねている。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;groovyとは&#34;&gt;Groovyとは&lt;/h2&gt;

&lt;p&gt;GroovyはJVM言語、つまりJavaのバイトコードにコンパイルされてJavaの実行環境で動くプログラミング言語のひとつ。
Javaのプログラマにとってとっつきやすい文法を保ちつつ、動的型付けを実現し、また&lt;a href=&#34;https://www.ruby-lang.org/ja/&#34;&gt;Ruby&lt;/a&gt;などのスクリプト言語の記法や機能を取り入れ、生産性を高めている。&lt;/p&gt;

&lt;p&gt;現在は&lt;a href=&#34;http://www.apache.org/&#34;&gt;Apacheソフトウェア財団&lt;/a&gt;によって管理され、&lt;a href=&#34;https://github.com/apache/groovy&#34;&gt;OSS&lt;/a&gt;として開発が進められている。&lt;/p&gt;

&lt;p&gt;Webアプリケーションフレームワークの&lt;a href=&#34;https://grails.org/&#34;&gt;&lt;strong&gt;Grails&lt;/strong&gt;&lt;/a&gt; やビルドツールの&lt;a href=&#34;http://gradle.org/&#34;&gt;&lt;strong&gt;Gradle&lt;/strong&gt;&lt;/a&gt;で採用されている。
Gradleは最近Javaプロジェクトのビルドツールの主流になっていて、Groovyはその定義ファイルを記述する言語として知名度が高いが、Groovyで開発されているプロジェクトとなるとあまり多くないようだ。
GitHubにホストされているGroovyプロジェクトは、2016/4/9現在 &lt;strong&gt;0.8%弱&lt;/strong&gt; (25,087/3,200,229) しかない。&lt;/p&gt;

&lt;p&gt;なぜ人気がないのかはよく分からないが、少なくとも、長くて打ちにくい名前とダサいロゴは不評のようだ。&lt;/p&gt;

&lt;h2 id=&#34;groovyのインストール&#34;&gt;Groovyのインストール&lt;/h2&gt;

&lt;p&gt;Windows 7にGroovy 2.4.6をインストールする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.groovy-lang.org/install.html&#34;&gt;本家サイトの手順&lt;/a&gt;に従い、Binary Releaseのアーカイブをダウンロードして、適当なところに展開して、展開したフォルダのパスを環境変数&lt;code&gt;GROOVY_HOME&lt;/code&gt;にセットし、&lt;code&gt;%GROOVY_HOME%\bin&lt;/code&gt;を&lt;code&gt;PATH&lt;/code&gt;に追加するだけ。&lt;/p&gt;

&lt;p&gt;Java 6以降が前提なので、&lt;code&gt;JAVA_HOME&lt;/code&gt;にJDK 1.7.0_17のパスをセットしておいた。JREでもいいはず。&lt;/p&gt;

&lt;h2 id=&#34;パケットキャプチャ-with-pcap4j-in-java&#34;&gt;パケットキャプチャ with Pcap4J in Java&lt;/h2&gt;

&lt;p&gt;Pcap4Jでパケットキャプチャするコードを普通にJavaで書くと以下の様になる。&lt;/p&gt;

&lt;p&gt;&lt;script src=&#34;https://gist.github.com/kaitoy/eebcd5bdfab179cab916d3182f3d6d11.js&#34;&gt;&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;これを実行すると、パケットキャプチャするネットワークインターフェースを選択し、5つのパケットをキャプチャしてタイムスタンプと共にコンソールに表示する。&lt;/p&gt;

&lt;h2 id=&#34;パケットキャプチャ-with-pcap4j-in-groovy&#34;&gt;パケットキャプチャ with Pcap4J in Groovy&lt;/h2&gt;

&lt;p&gt;上記処理をGroovyで書くと以下の様になる。&lt;/p&gt;

&lt;p&gt;&lt;script src=&#34;https://gist.github.com/kaitoy/c75837d3537303b004506d3e335eac17.js&#34;&gt;&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;メインクラスを書かなくていいところが大きい。
変数の型を書かなくていいのも楽。
ラムダ式でクロージャも作れるし補間文字列(String interpolation)も使える。&lt;/p&gt;

&lt;p&gt;また、ここでは使っていないが、オープンクラスなどのメタプログラミングもサポートされている。&lt;/p&gt;

&lt;p&gt;上記コードは、Pcap4J 1.6.2、Slf4J 1.7.12、JNA 4.2.1を使って、以下のコマンドで実行できることを確認した。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;groovy -cp &amp;quot;pcap4j-core.jar;jna.jar;slf4j-api.jar;pcap4j-packetfactory-static.jar&amp;quot; Pcap4jLoop.groovy tcp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これはスクリプト的な実行方法だが、&lt;code&gt;groovyc&lt;/code&gt;コマンドで事前にコンパイルしてclassファイルを生成し、&lt;code&gt;java&lt;/code&gt;コマンドで実行することもできる。&lt;/p&gt;

&lt;h3 id=&#34;困ったところ&#34;&gt;困ったところ&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;本家サイトのドキュメントが分かり辛い。&lt;/p&gt;

&lt;p&gt;頭から読んでいくと急にディープな部分に引き込まれ、なかなかコードを書き始められなかった。&lt;/p&gt;

&lt;p&gt;最近の言語やフレームワークのサイトはチュートリアルに従って動くコードを見ながら概要から詳細に理解を深められる形になっていることが多いので、仕様の詳細が羅列されている感じのGroovyサイトはなんとも読みにくかった。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;クラスパスの指定が上手くできない。&lt;/p&gt;

&lt;p&gt;groovyコマンドにオプションで複数のクラスパスを指定するのに、普通に&lt;code&gt;-cp pcap4j-core.jar;jna.jar&lt;/code&gt;みたいにしたら最初の&lt;code&gt;pcap4j-core.jar&lt;/code&gt;にしかクラスパスが通らなかった。
区切りを&lt;code&gt;:&lt;/code&gt;にするとどちらにも通らない。&lt;/p&gt;

&lt;p&gt;環境変数&lt;code&gt;CLASSPATH&lt;/code&gt;に&lt;code&gt;pcap4j-core.jar;jna.jar&lt;/code&gt;をセットしておくと&lt;code&gt;-cp&lt;/code&gt;を使わなくても正しく両方に通るし、&lt;code&gt;%userprofile%\.groovy\&lt;/code&gt;にjarを入れておくだけでもいいみたいなんだけど、&lt;code&gt;-cp&lt;/code&gt;が中途半端にしか機能しないのが気持ち悪い。&lt;/p&gt;

&lt;p&gt;のでちょっとソースを見たら、groovyコマンドはバッチで書かれていることに気付いた。
バッチだと、&lt;code&gt;;&lt;/code&gt;で区切られているものは半角スペースで区切られているのと同じで別々の引数になってしまうので、上のような書き方だと&lt;code&gt;jna.jar&lt;/code&gt;は&lt;code&gt;-cp&lt;/code&gt;の値として処理されない。
クラスパス全体をダブルコーテーションで囲って、&lt;code&gt;-cp &amp;quot;pcap4j-core.jar;jna.jar&amp;quot;&lt;/code&gt;みたいにしたらできた。なんか残念な出来。。。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
      
    
      
        <item>
          <title> ズンドコキヨシ with Pcap4J - ZUNDOKOプロトコルを実装してみた</title>
          <link>https://www.kaitoy.xyz/2016/03/19/zundoko-kiyoshi-with-pcap4j/</link>
          <pubDate>Sat, 19 Mar 2016 11:47:03 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/03/19/zundoko-kiyoshi-with-pcap4j/</guid>
          <description>

&lt;p&gt;先週くらいから巷でズンドコズンドコ騒いでいると思ってはいたが、昨日ようやくその元ネタを見た。
以下のツイートだ。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;Javaの講義、試験が「自作関数を作り記述しなさい」って問題だったから&lt;br&gt;「ズン」「ドコ」のいずれかをランダムで出力し続けて「ズン」「ズン」「ズン」「ズン」「ドコ」の配列が出たら「キ・ヨ・シ！」って出力した後終了って関数作ったら満点で単位貰ってた&lt;/p&gt;&amp;mdash; てくも (@kumiromilk) &lt;a href=&#34;https://twitter.com/kumiromilk/status/707437861881180160&#34;&gt;2016年3月9日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;面白い。
巷ではこれを&lt;a href=&#34;http://qiita.com/shunsugai@github/items/971a15461de29563bf90&#34;&gt;いろんな言語で実装したりしているみたい&lt;/a&gt;でさらに面白い。&lt;/p&gt;

&lt;p&gt;私もこのビッグウェーブに乗らないわけにいかないので、専門分野であるネットワーク周りを開拓しようと思い、ZUNDOKOプロトコルというものを考案して実装してみた。書いたソースは&lt;a href=&#34;https://github.com/kaitoy/zundoko-protocol&#34;&gt;GitHub&lt;/a&gt;においた。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;zundokoプロトコル&#34;&gt;ZUNDOKOプロトコル&lt;/h2&gt;

&lt;p&gt;クライアントはサーバに「ズン」か「ドコ」を送る。&lt;/p&gt;

&lt;p&gt;サーバは「ズン」を4回受信した後に「ドコ」を受信するとクライアントに「キ・ヨ・シ！」を返す。&lt;/p&gt;

&lt;p&gt;クライアント/サーバ間でやり取りするメッセージ(Zundokoパケット)のフォーマットは下図。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt; 0                            15                              31
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|             zundoko (null-terminated string)                  |
|                                                               |
|                                                               |
|                                                               |
|                                                               |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;要はzundokoフィールドがあるだけ。
このzundokoフィールドは20 byte固定長で、NULL (0x00)で終わるUTF-8の文字列を保持する。&lt;/p&gt;

&lt;p&gt;このメッセージを運ぶ下位レイヤはEthernetで、EtherTypeは0x01FF。&lt;/p&gt;

&lt;p&gt;Ethernetにした理由は実装(下記)が楽だから。
EtherTypeは&lt;a href=&#34;http://www.iana.org/assignments/ieee-802-numbers/ieee-802-numbers.xhtml#ieee-802-numbers-1&#34;&gt;IANA&lt;/a&gt;でExperimentalとされている範囲から適当に選んだ。もちろんIANAに登録などはしていない。&lt;/p&gt;

&lt;p&gt;因みに、Ethernetヘッダを加えた、クライアント/サーバ間でやり取りする完全なパケットは以下の様になる。(プリアンブルとかは除く。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt; 0                            15
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|    Dst Hardware Address       |
+                               +
|                               |
+                               +
|                               |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|    Src Hardware Address       |
+                               +
|                               |
+                               +
|                               |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|    EtherType (0x01FF)         |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|        zundoko                |
| (null-terminated string)      |
|                               |
|                               |
|                               |
|                               |
|                               |
|                               |
|                               |
|                               |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|            padding            |
|                               |
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;実装&#34;&gt;実装&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;Pcap4J&lt;/a&gt;を使ってクライアントとサーバを実装した。
書いたのは以下の3つのクラス。(といくつかのインナークラス。)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kaitoy/zundoko-protocol/tree/master/src/main/java/com/github/kaitoy/zundoko/protocol/ZundokoPacket.java&#34;&gt;com.github.kaitoy.zundoko.protocol.ZundokoPacket&lt;/a&gt;: Pcap4JがZundokoパケットを解析するのに使うクラス&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kaitoy/zundoko-protocol/tree/master/src/main/java/com/github/kaitoy/zundoko/protocol/ZundokoServer.java&#34;&gt;com.github.kaitoy.zundoko.protocol.ZundokoServer&lt;/a&gt;: Zundokoサーバ&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kaitoy/zundoko-protocol/tree/master/src/main/java/com/github/kaitoy/zundoko/protocol/ZundokoClient.java&#34;&gt;com.github.kaitoy.zundoko.protocol.ZundokoClient&lt;/a&gt;: Zundokoクライアント&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;ビルド&#34;&gt;ビルド&lt;/h2&gt;

&lt;p&gt;今だに&lt;a href=&#34;https://maven.apache.org/&#34;&gt;Maven&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;以下を実行するとビルドできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;git clone https://github.com/kaitoy/zundoko-protocol.git
cd zundoko-protocol
mvn install
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;サーバ-クライアントの使い方&#34;&gt;サーバ/クライアントの使い方&lt;/h2&gt;

&lt;p&gt;下位レイヤがEthernetなのでネットワークセグメントを超えたZundokoパケットのやり取りはできない。
よってまずは同一ネットワーク内にサーバマシンとクライアントマシンを用意する。
VMware Playerのホストとゲストで可。&lt;/p&gt;

&lt;p&gt;サーバマシンとクライアントマシンには&lt;a href=&#34;http://www.winpcap.org/&#34;&gt;WinPcap&lt;/a&gt;か&lt;a href=&#34;http://www.tcpdump.org/&#34;&gt;libpcap&lt;/a&gt;をインストールしておく。&lt;/p&gt;

&lt;p&gt;依存ライブラリをダウンロードするため、&lt;code&gt;zundoko-protocol\bin\&lt;/code&gt;に&lt;code&gt;cd&lt;/code&gt;して以下のコマンドを実行する。(要Maven。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;configure.bat
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;サーバを起動するには、&lt;code&gt;zundoko-protocol\bin\&lt;/code&gt;で以下のコマンドを実行する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;run-server.bat
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;起動するとZundokoパケットをやり取りするネットワークインターフェースを聞かれるので、
クライアントとL2レベルでつながっているものを選ぶ。
選んだインターフェースのMacアドレスはクライアントの起動に使うのでメモしておく。&lt;/p&gt;

&lt;p&gt;クライアントを起動するには、&lt;code&gt;zundoko-protocol\bin\&lt;/code&gt;で以下のコマンドを実行する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;run-client.bat &amp;lt;Macアドレス&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;Macアドレス&amp;gt;&lt;/code&gt;にはサーバ起動時にメモしたMacアドレスを入力する。
起動するとZundokoパケットをやり取りするネットワークインターフェースを聞かれるので、
サーバとL2レベルでつながっているものを選ぶ。&lt;/p&gt;

&lt;p&gt;クライアントが起動すると、一秒おきに「ズン」と「ドコ」をランダムに選び、
サーバに送りつつコンソールに表示する。
また、サーバからZundokoパケット受信したらそのzundokoフィールドの値を表示する。&lt;/p&gt;

&lt;h2 id=&#34;実行例&#34;&gt;実行例&lt;/h2&gt;

&lt;p&gt;&lt;div class=&#34;embed video-player&#34; style=&#34;text-align: center&#34;&gt;
  &lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;320&#34; height=&#34;193&#34; src=&#34;https://www.youtube.com/embed/ad3u4Y86e_I&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>継続的インテグレーションは死んだ</title>
          <link>https://www.kaitoy.xyz/2016/02/09/continuous-integration-is-dead/</link>
          <pubDate>Tue, 09 Feb 2016 00:34:41 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/02/09/continuous-integration-is-dead/</guid>
          <description>

&lt;p&gt;このエントリでは、Yegor Bugayenkoによる記事、&lt;a href=&#34;http://www.yegor256.com/2014/10/08/continuous-integration-is-dead.html&#34;&gt;Continuous Integration is Dead&lt;/a&gt;を紹介する。
(Yegorから和訳と転載の許可は得た。)
以下はその全文の和訳だが、意訳超訳が混じっているので、もとのニュアンスを知りたければ元記事を読んでもいいし、読まなくてもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;数日前、「&lt;a href=&#34;http://devops.com/blogs/continuous-integration-doesnt-work/&#34;&gt;なぜ継続的インテグレーションは機能しないのか&lt;/a&gt;」という私の記事が&lt;a href=&#34;http://www.devops.com/&#34;&gt;DevOps.com&lt;/a&gt;に公開された。
それとほぼ同じ日に、Twitterで非常に否定的な批評が送られてきた。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;継続的インテグレーションが機能しないとはどういうことだ。この人気なすばらしいアイデアが。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;その求めてもない質問への返事をここに書く。&lt;/p&gt;

&lt;p&gt;私はこの分野に関して多少の経験があるが、それに基いた論拠は挙げない。
代わりにロジックだけを頼りにする。&lt;/p&gt;

&lt;p&gt;ところで、私には50以上のオープンソースや営利プロジェクトで5年間Apache Continuum、Hudson、CruiseControl、Jenkinsを利用した経験がある。
さらに、数年前&lt;a href=&#34;http://www.fazend.com/&#34;&gt;fazend.com&lt;/a&gt;(2013年に&lt;a href=&#34;http://www.rultor.com/&#34;&gt;rultor.com&lt;/a&gt;に改名)というホスト型継続的インテグレーションサービスを開発した。
現在&lt;a href=&#34;http://www.travis-ci.org/&#34;&gt;Travis&lt;/a&gt;と&lt;a href=&#34;http://www.appveyor.com/&#34;&gt;AppVeyor&lt;/a&gt;のアクティブユーザでもある。&lt;/p&gt;

&lt;h2 id=&#34;継続的インテグレーションはどう機能すべきか&#34;&gt;継続的インテグレーションはどう機能すべきか&lt;/h2&gt;

&lt;p&gt;考え方はシンプルで明確だ。
&lt;code&gt;master&lt;/code&gt;ブランチ(Subversionなら&lt;code&gt;/trunk&lt;/code&gt;)に新しくコミットをする度に、継続的インテグレーションサーバ(またはサービス)はプロダクト全体のビルドを試みる。
「ビルド」というのはコンパイル、ユニットテスト、統合テスト、品質解析&lt;a href=&#34;http://www.yegor256.com/2014/06/21/casperjs-with-maven.html&#34;&gt;など&lt;/a&gt;を意味する。&lt;/p&gt;

&lt;p&gt;その結果は「成功」か「失敗」だ。
もし成功だったら「ビルドがクリーン」であると言う。
もし失敗だったら、「ビルドが壊れている」と言う。
通常、ビルドが壊れるのは、以前通っていたユニットテストを通らなくするような新しいコードをだれかがコミットしたからだ。&lt;/p&gt;

&lt;p&gt;これは問題の技術的な面だ。
この部分はいつも上手くいく。
まあ、依存が直書きされてるとか、ビルド環境が十分分離されていないとか、ビルドの並列性が完全じゃないとか、そういう問題はあるかもしれないが、この記事はそれらについてではない。
アプリケーションが上手く書かれていてユニットテストが安定しているなら、継続的インテグレーションは簡単だ。
技術的には。&lt;/p&gt;

&lt;p&gt;組織的な面を見てみよう。&lt;/p&gt;

&lt;p&gt;継続的インテグレーションというのは、ビルドを実行するサーバだけを指すのではなく、上手く機能すべき管理的/組織的プロセスだ。
プロセスが上手く機能するとは、Jez Humbleが「&lt;a href=&#34;http://www.amazon.com/gp/product/0321601912/ref=as_li_tl?ie=UTF8&amp;amp;camp=1789&amp;amp;creative=390957&amp;amp;creativeASIN=0321601912&amp;amp;linkCode=as2&amp;amp;tag=yegor256com-20&amp;amp;linkId=GKWBKGZUJGJLFMHE&#34;&gt;継続的デリバリー: ビルド、テスト、デプロイの自動化による確実なソフトウェアリリース&lt;/a&gt;」の55ページで言っていることそのものを意味する。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;もしビルドが失敗したら、開発チームは何をやっていたとしてもそれを中断して、そのビルドの問題を速やかに直す。これが重要だ。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;これが上手くいかず、上手くできないことだ。&lt;/p&gt;

&lt;h2 id=&#34;誰がこれを必要としているのか&#34;&gt;誰がこれを必要としているのか&lt;/h2&gt;

&lt;p&gt;既に述べた通り、継続的インテグレーションとは、開発チーム全体を止めて壊れたビルドを修正させることだ。
繰り返すが、ビルドが壊れたら直ちに、それを修正し、ビルドを安定した状態に戻すコミットを入れることに全員が集中すべきだ。&lt;/p&gt;

&lt;p&gt;ここでひとつ疑問が生じる。誰が、活動中のチーム内の誰がこれを必要としているのだろうか?&lt;/p&gt;

&lt;p&gt;一刻も早く新しい機能をリリースしたいプロダクトオーナ?
または、締め切りに責任を持つ&lt;a href=&#34;http://www.yegor256.com/2015/09/22/micromanagement.html&#34;&gt;プロジェクトマネージャ&lt;/a&gt;かもしれない。
もしくは、他の誰かが作りこんだバグをプレッシャーを受けながら修正すること嫌うプログラマかもしれない。&lt;/p&gt;

&lt;p&gt;誰がこの継続的インテグレーションを好み、誰が必要としているのか?&lt;/p&gt;

&lt;p&gt;誰でもない。&lt;/p&gt;

&lt;h2 id=&#34;実際に何が起こるのか&#34;&gt;実際に何が起こるのか&lt;/h2&gt;

&lt;p&gt;教えよう。
私は何度も見たことがある。
シナリオはいつも同じだ。
継続的インテグレーションのビルドステータスは単に無視されるようになる。
ビルドがクリーンか壊れているかにかかわらず。
そして以前のやり方が継続される。&lt;/p&gt;

&lt;p&gt;Jez Humbleが推奨するように開発を止めて問題に対応したりしない。&lt;/p&gt;

&lt;p&gt;代わりに、継続的インテグレーションサーバから来る情報を無視する。&lt;/p&gt;

&lt;p&gt;しばらくして、次の日かもしれないし月曜日かもしれないが、空いた時間を探してビルドの修正に取り組む。
これは単に、ダッシュボードの赤いボタンが嫌で緑に変えたいからだ。&lt;/p&gt;

&lt;h2 id=&#34;規律についてはどうか&#34;&gt;規律についてはどうか&lt;/h2&gt;

&lt;p&gt;そう、これには別の見方もある。
チームに規律を徹底させることもできる。
ビルドは常にクリーンで、壊した人は何らかの&lt;a href=&#34;http://www.yegor256.com/2016/01/05/how-to-punish-employees.html&#34;&gt;罰&lt;/a&gt;を受けるという厳格なルールを設けることができる。&lt;/p&gt;

&lt;p&gt;これを試すとなると、恐怖駆動型開発を実施することになる。
プログラマは、ビルドを失敗させたら少なくとも&lt;a href=&#34;http://programmers.stackexchange.com/questions/79041&#34;&gt;謝罪&lt;/a&gt;しなければならなくなるため、リポジトリへのコミットを恐れるようになる。&lt;/p&gt;

&lt;p&gt;この場合の厳格な規律(私は大好きだが)は、単に状況を悪化させる。
開発プロセス全体が遅くなり、プログラマはビルドを壊さないように自身のコードをできるだけ長い間手元に保持する。
いざコミットするとなった時、変更は巨大になっていて、マージは非常に難しいか、時に不可能になる。&lt;/p&gt;

&lt;p&gt;結果、プログラマが書いた多くのコードがコミットされること無く捨てられる。
あの恐怖因子のせいだ。&lt;/p&gt;

&lt;h2 id=&#34;ok-解決策は&#34;&gt;OK。解決策は?&lt;/h2&gt;

&lt;p&gt;それについては以前書いた。
「&lt;a href=&#34;http://www.yegor256.com/2014/07/21/read-only-master-branch.html&#34;&gt;読み取り専用マスタブランチ&lt;/a&gt;」だ。&lt;/p&gt;

&lt;p&gt;これは単純で、&lt;code&gt;master&lt;/code&gt;へのマージを一切禁止し、誰でも実行できるスクリプトを作る。
このスクリプトがマージ、テスト、コミットを実行する。
このスクリプトには例外が全く無い。
どんなブランチであっても、たった一つのユニットテストに失敗しただけでも、ブランチ全体が却下される。&lt;/p&gt;

&lt;p&gt;言い換えると、&lt;code&gt;master&lt;/code&gt;にそのコードが入る前に赤いフラグを揚げる。&lt;/p&gt;

&lt;p&gt;これで全ての問題が解決する。&lt;/p&gt;

&lt;p&gt;第一に、ビルドは常にクリーンだ。
ビルドをクリーンに保たないコードは誰もコミットできないので、単純に言ってビルドを壊すことはできない。&lt;/p&gt;

&lt;p&gt;第二に、何かを壊すという恐怖が無い。
単に技術的に壊せないのだ。
マージスクリプトから却下されることしかできない。
その場合、エラーを修正してスクリプトに再挑戦を命じる。
誰もこのやりとりを見ていないので、謝罪する必要が無い。
恐怖因子は消えた。&lt;/p&gt;

&lt;p&gt;ところで、君のプロジェクトで&lt;a href=&#34;http://www.rultor.com/&#34;&gt;rultor.com&lt;/a&gt;を利用して、この「&lt;a href=&#34;http://www.yegor256.com/2014/07/21/read-only-master-branch.html&#34;&gt;読み取り専用マスタブランチ&lt;/a&gt;」原則を徹底してみてくれ。&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;embed video-player&#34; style=&#34;text-align: center&#34;&gt;
  &lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;320&#34; height=&#34;193&#34; src=&#34;https://www.youtube.com/embed/3IXk5yEJMIs&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上がYegorの記事。&lt;/p&gt;

&lt;p&gt;CIは死んだというセンセーショナルなタイトルではあるが、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E7%A5%9E%E3%81%AF%E6%AD%BB%E3%82%93%E3%81%A0&#34;&gt;ニーチェ&lt;/a&gt;とは違って神なるCIを否定しているわけではない。
CIって意外と上手くいかないけど、こうすれば改善できるよという主旨の記事だ。&lt;/p&gt;

&lt;p&gt;Yegorが指摘している、ビルドステータスが無視されるようになるという一つ目の問題は、実例を多く見たことがあるわけではないが確かになんだかよく起こりそうな話だ。
そういえば私もPcap4JのTravisでのビルドエラーをもう数か月無視している。
まあこれはTravis側の問題が原因で、回避策を入れるのが気が進まないだけなんだけど。&lt;/p&gt;

&lt;p&gt;Yegorのやり方は、&lt;a href=&#34;https://gist.github.com/juno/3112343&#34;&gt;GitHub Flow&lt;/a&gt;が&lt;code&gt;master&lt;/code&gt;は常にデプロイ可能としているのを、より厳密に守るように仕組化する感じであろうか。&lt;/p&gt;

&lt;p&gt;GitHub Flowを世に広めたScott Chaconによれば、&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;テストされていなかったり、ビルドを破壊するようなコードをmasterにpushした場合には、開発チーム間におけるソーシャルな取り決めを破ることになり、ちょっと気まずい思いをすることになる&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;とのことで、これはまさにYegorが恐怖因子と指摘した二つ目の問題である。
慣れない内のリポジトリへのコミットの緊張感や、CIサーバからエラー通知が来た時の焦燥感は、多くの人のストレスになっているんじゃないだろうか。
&lt;code&gt;master&lt;/code&gt;の更新をスクリプトに任せてしまえば、それでなおビルドが壊れたとしてもスクリプトのせいにできるので気が楽だろう。&lt;/p&gt;

&lt;p&gt;実装が簡単そうなアイデアでもあるので、いつかCIを実装する日まで覚えておきたい。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Pcap4J Meets Windows Containers</title>
          <link>https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/</link>
          <pubDate>Fri, 22 Jan 2016 17:46:43 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/</guid>
          <description>

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/about/about_overview&#34;&gt;Windows Containers&lt;/a&gt;&lt;/strong&gt; で &lt;strong&gt;&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;Pcap4J&lt;/a&gt;&lt;/strong&gt; のコンテナをビルドしてみた話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;windows-containersとは&#34;&gt;Windows Containersとは&lt;/h2&gt;

&lt;p&gt;Windows Containersは、Microsoftが&lt;a href=&#34;https://www.docker.com/company&#34;&gt;Docker, Inc&lt;/a&gt;と提携して開発している&lt;a href=&#34;http://www.sophia-it.com/content/%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A%E6%8A%80%E8%A1%93&#34;&gt;コンテナ技術&lt;/a&gt;で、Windows版&lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt;とも言われる機能。
今年リリースされる &lt;strong&gt;Windows Server 2016&lt;/strong&gt; に実装される予定で、その3つめのテクニカルプレビューである &lt;strong&gt;Windows Server 2016 Technical Preview 3&lt;/strong&gt; (2015/8/19公開)から評価できるようになった。&lt;/p&gt;

&lt;p&gt;Windows Containersには次の二種類がある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Windows Server Containers&lt;/p&gt;

&lt;p&gt;プロセスと名前空間の分離を実現する機能で、これによるコンテナはカーネルをホストと共有する。
つまり本家Dockerに近い形の機能。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Hyper-V Containers&lt;/p&gt;

&lt;p&gt;それぞれのコンテナを軽量化されたHyper-Vの仮想マシンっぽいものの上で動かす機能。
このコンテナの実行にはHyper-Vが必要。
Windows Server Containersよりコンテナ間の分離性が高く、カーネルの共有もしないが、そもそもそれってコンテナなの?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;どちらも同じようなインターフェースで操作でき、このインターフェースには&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/reference/ps_docker_comparison&#34;&gt;PowershellのコマンドレットとDockerコマンドの二種類がある&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;より詳しくは、&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/about/about_overview&#34;&gt;Microsoftによる解説&lt;/a&gt;や&lt;a href=&#34;http://www.atmarkit.co.jp/ait/articles/1512/11/news022.html&#34;&gt;@ITのこの記事&lt;/a&gt;がわかりやすい。
また、&lt;a href=&#34;http://qiita.com/Arturias/items/3e82de8328067d0e03a3&#34;&gt;Qiitaのこの記事&lt;/a&gt;がDockerとWindows Server Containersのアーキテクチャを詳細に説明していて面白い。&lt;/p&gt;

&lt;h2 id=&#34;windows-containersセットアップ&#34;&gt;Windows Containersセットアップ&lt;/h2&gt;

&lt;p&gt;まず、Windows 7 x64のノートPCにVMware Player 7.1.0を入れてWindows 10 x64用のVM(CPU2つとメモリ2.5GB)を作り、そこに2015/11/19に公開された &lt;strong&gt;Windows Server 2016 Technical Preview 4&lt;/strong&gt; をインストール。
コマンドでいろいろ設定するの慣れていないのでGUI(Desktop Experience)付きで。
(リモートデスクトップ使えばよかったのかもしれないけど。)
ロケールは英語以外は問題が起きそうなので英語で。&lt;/p&gt;

&lt;p&gt;このVMに、&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/quick_start/inplace_setup&#34;&gt;Microsoftのセットアップガイド&lt;/a&gt;と&lt;a href=&#34;http://www.atmarkit.co.jp/ait/articles/1512/14/news006.html&#34;&gt;@ITの記事&lt;/a&gt;を参照しながらWindows Containersをセットアップ。&lt;/p&gt;

&lt;p&gt;後者の記事によると、Hyper-V ContainersをVM上にセットアップするには、&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/hyperv_on_windows/user_guide/nesting&#34;&gt;Nested Virtualization&lt;/a&gt;というHyper-VのVMの上でHyper-Vを動かす機能を有効にしたホスト上のHyper-V VMを使わないといけないようなので、Windows Server Containersの方を試すことに。&lt;/p&gt;

&lt;p&gt;Windows Server Containersをセットアップする手順は以下。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;VM上でコマンドプロンプトを開いて &lt;code&gt;powershell start-process powershell -Verb runas&lt;/code&gt; を実行。&lt;/li&gt;
&lt;li&gt;青いパワーシェルウィンドウが開くのでそこで &lt;code&gt;wget -uri https://aka.ms/tp4/Install-ContainerHost -OutFile C:\Install-ContainerHost.ps1&lt;/code&gt; を実行。&lt;code&gt;Install-ContainerHost.ps1&lt;/code&gt; というスクリプトがダウンロードされる。&lt;/li&gt;
&lt;li&gt;青いパワーシェルウィンドウで &lt;code&gt;C:\Install-ContainerHost.ps1&lt;/code&gt; を実行するとWindows Server Containersのインストールが始まる。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/pcap4j-meets-windows-containers/install.png&#34; alt=&#34;install.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;途中再起動が一回あって、ログインしたらインストール処理が再開した。
全部で2時間以上かかった。&lt;/p&gt;

&lt;p&gt;仮想Ethernetスイッチ接続の追加に失敗したというエラーが出たけどなんなんだろう。
&lt;code&gt;ipconfig&lt;/code&gt; の出力によると &lt;code&gt;vEthernet&lt;/code&gt; というDockerの&lt;a href=&#34;https://www.kaitoy.xyz/2015/07/25/how-to-capture-packets-on-a-local-network-with-pcap4j-container/#docker-network&#34;&gt;virtual Ethernet bridge&lt;/a&gt;にあたるものはちゃんと作られているみたいなんだけど。&lt;/p&gt;

&lt;h2 id=&#34;windows-server-containers味見&#34;&gt;Windows Server Containers味見&lt;/h2&gt;

&lt;p&gt;コマンドプロンプトで &lt;code&gt;docker images&lt;/code&gt; を実行すると、既に &lt;code&gt;windowsservercore&lt;/code&gt; というコンテナイメージが入っていることがわかる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\Administrator&amp;gt;docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
windowsservercore   10.0.10586.0        6801d964fda5        11 weeks ago        0 B
windowsservercore   latest              6801d964fda5        11 weeks ago        0 B
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;docker run -it windowsservercore cmd&lt;/code&gt; を実行すると &lt;code&gt;windowsservercore&lt;/code&gt; からコンテナを起動してその上でコマンドプロンプトを起動できる。
コンテナの起動は非常に遅い。30秒以上かかる。これは今の時点での&lt;a href=&#34;https://msdn.microsoft.com/virtualization/windowscontainers/about/work_in_progress#windows-containers-start-slowly&#34;&gt;制限&lt;/a&gt;らしい。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker login --help&lt;/code&gt; するとわかるが、コンテナイメージのリポジトリは &lt;code&gt;https://registry-win-tp3.docker.io/v1/&lt;/code&gt; という仮っぽいサーバにあって、&lt;code&gt;docker search *&lt;/code&gt; を実行するとそこに登録されたイメージのリストが見れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\Administrator&amp;gt;docker search *
NAME                 DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED
microsoft/aspnet     ASP.NET 5 framework installed in a Windows...   1         [OK]       [OK]
microsoft/django     Django installed in a Windows Server Core ...   1                    [OK]
microsoft/dotnet35   .NET 3.5 Runtime installed in a Windows Se...   1         [OK]       [OK]
microsoft/golang     Go Programming Language installed in a Win...   1                    [OK]
microsoft/httpd      Apache httpd installed in a Windows Server...   1                    [OK]
microsoft/iis        Internet Information Services (IIS) instal...   1         [OK]       [OK]
microsoft/mongodb    MongoDB installed in a Windows Server Core...   1                    [OK]
microsoft/mysql      MySQL installed in a Windows Server Core b...   1                    [OK]
microsoft/nginx      Nginx installed in a Windows Server Core b...   1                    [OK]
microsoft/node       Node installed in a Windows Server Core ba...   1                    [OK]
microsoft/php        PHP running on Internet Information Servic...   1                    [OK]
microsoft/python     Python installed in a Windows Server Core ...   1                    [OK]
microsoft/rails      Ruby on Rails installed in a Windows Serve...   1                    [OK]
microsoft/redis      Redis installed in a Windows Server Core b...   1                    [OK]
microsoft/ruby       Ruby installed in a Windows Server Core ba...   1                    [OK]
microsoft/sqlite     SQLite installed in a Windows Server Core ...   1                    [OK]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これらはちゃんと &lt;code&gt;docker pull&lt;/code&gt; して使える。
けど多分 &lt;code&gt;docker push&lt;/code&gt; はできない。&lt;/p&gt;

&lt;h2 id=&#34;pcap4j-on-windows-container&#34;&gt;Pcap4J on Windows Container&lt;/h2&gt;

&lt;p&gt;結論から言うと、以下の &lt;code&gt;Dockerfile&lt;/code&gt; を書いて &lt;code&gt;docker build&lt;/code&gt; してPcap4Jをコンテナ上でビルドするところまではできたが、それを実行してもNIFが全く検出できず、よってパケットキャプチャも実行できなかった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;#
# Dockerfile for Pcap4J on Windows
#

FROM windowsservercore:latest
MAINTAINER Kaito Yamada &amp;lt;kaitoy@pcap4j.org&amp;gt;

# Install Chocolatey.
RUN mkdir C:\pcap4j
WORKDIR /pcap4j
ADD https://chocolatey.org/install.ps1 install.ps1
RUN powershell .\install.ps1

# Install dependencies.
RUN choco install -y nmap maven git jdk7

# Build Pcap4J.
RUN git clone git://github.com/kaitoy/pcap4j.git
WORKDIR pcap4j
RUN powershell -NoProfile -ExecutionPolicy Bypass -Command &amp;quot;mvn &#39;-Dmaven.repo.local=C:\pcap4j\repo&#39; -P distribution-assembly install 2&amp;gt;&amp;amp;1 | add-content -Path build.log -pass

# Collect libraries.
RUN mkdir bin &amp;amp;&amp;amp; \
    cd pcap4j-packetfactory-static &amp;amp;&amp;amp; \
    mvn -Dmaven.repo.local=C:\pcap4j\repo -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeScope=compile dependency:copy-dependencies &amp;amp;&amp;amp; \
    mvn -Dmaven.repo.local=C:\pcap4j\repo -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeGroupIds=ch.qos.logback dependency:copy-dependencies &amp;amp;&amp;amp; \
    cd ../pcap4j-distribution &amp;amp;&amp;amp; \
    mvn -Dmaven.repo.local=C:\pcap4j\repo -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeArtifactIds=pcap4j-packetfactory-static,pcap4j-sample dependency:copy-dependencies

# Generate sample script. (C:\pcap4j\pcap4j\bin\capture.bat)
RUN echo @echo off &amp;gt; bin\capture.bat &amp;amp;&amp;amp; \
    echo &amp;quot;%JAVA_HOME%\bin\java&amp;quot; -cp C:\pcap4j\pcap4j\bin\pcap4j-core.jar;C:\pcap4j\pcap4j\bin\pcap4j-packetfactory-static.jar;C:\pcap4j\pcap4j\bin\pcap4j-sample.jar;C:\pcap4j\pcap4j\bin\jna.jar;C:\pcap4j\pcap4j\bin\slf4j-api.jar;C:\pcap4j\pcap4j\bin\logback-classic.jar;C:\pcap4j\pcap4j\bin\logback-core.jar org.pcap4j.sample.GetNextPacketEx &amp;gt;&amp;gt; bin\capture.bat
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この &lt;code&gt;Dockerfile&lt;/code&gt; でやっていることはだいたい以下。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://chocolatey.org/&#34;&gt;Chocolatey&lt;/a&gt;をインストール。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://nmap.org/&#34;&gt;Nmap&lt;/a&gt;と&lt;a href=&#34;https://maven.apache.org/&#34;&gt;Maven&lt;/a&gt;と&lt;a href=&#34;https://git-scm.com/&#34;&gt;Git&lt;/a&gt;とJDK7をChocolateyでインストール。&lt;/li&gt;
&lt;li&gt;Pcap4Jのソースを &lt;code&gt;git clone&lt;/code&gt; でダウンロード。&lt;/li&gt;
&lt;li&gt;MavenでPcap4Jのビルドを実行。&lt;/li&gt;
&lt;li&gt;Pcap4Jのサンプルクラスを実行するスクリプトを生成。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;2でNmapは&lt;a href=&#34;http://www.winpcap.org/&#34;&gt;WinPcap&lt;/a&gt;の代わりに入れている。
GUI無しの環境でWinPcapをChocolateyで入れようとしても、エラーが発生したりしなかったりして、しかもどちらにせよ正常に入らない。
これはWinPcapのインストーラがサイレントインストールをサポートしていないから。
Nmapはサイレントインストールできて、インストール処理中にWinPcapを入れてくれるのでありがたい。&lt;/p&gt;

&lt;p&gt;ビルドしてみると、各ステップの実行(多分レイヤの作成)がすごく遅い。
&lt;code&gt;RUN choco install -y nmap maven git jdk7&lt;/code&gt; の後、次のコマンド実行まで30分くらい固まった。&lt;/p&gt;

&lt;p&gt;また、&lt;code&gt;Dockerfile&lt;/code&gt; を書いていて以下のバグに悩まされた。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;WORKDIR&lt;/code&gt; や &lt;code&gt;ENV&lt;/code&gt; で環境変数が展開されない。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;  ENV hoge %tmp%
  RUN echo %hoge%
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;とすると &lt;code&gt;%tmp%&lt;/code&gt; と表示される。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;WORKDIR&lt;/code&gt; や &lt;code&gt;ENV&lt;/code&gt; や &lt;code&gt;COPY&lt;/code&gt; でパスの区切りは &lt;code&gt;\&lt;/code&gt; 一つだと消えちゃうので &lt;code&gt;\\&lt;/code&gt; か &lt;code&gt;/&lt;/code&gt; を使わないといけない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;WORKDIR&lt;/code&gt; や &lt;code&gt;COPY&lt;/code&gt; のコンテナ内のパスに絶対パスを指定したい場合、&lt;code&gt;C:\hoge&lt;/code&gt;、&lt;code&gt;C:/hoge&lt;/code&gt;、&lt;code&gt;C:\\hoge&lt;/code&gt;、いずれもダメ。
以下の様なエラーが出る。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;  GetFileAttributesEx \\?\Volume{67df3c84-a0ef-11e5-9a63-000c2976fbc3}\C:: The filename, directory name, or volume label syntax is incorrect.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;UNIX式に &lt;code&gt;/hoge&lt;/code&gt; とするといける。C以外のドライブを指定したいときはどうするんだろう。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;コンテナ内で &lt;code&gt;C:\&lt;/code&gt; 直下に &lt;code&gt;.&lt;/code&gt; で始まる名前のフォルダ作ると次のステップで消えてる。
&lt;code&gt;.&lt;/code&gt; で始まる名前のファイルは &lt;code&gt;C:\&lt;/code&gt; 直下じゃなくても次のステップで消えてる。
Mavenのリポジトリがデフォルトで &lt;code&gt;C:\.m2\&lt;/code&gt; 以下にできるのではまる。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;これらのバグを乗り越えて頑張って &lt;code&gt;Dockerfile&lt;/code&gt; 書いたのに、NIFの検出すらできなかったという哀しい結果。
&lt;code&gt;pcap_lookupdev&lt;/code&gt; が以下のエラーを吐いて &lt;code&gt;NULL&lt;/code&gt; を返してきてたので、なんとなくコンテナのNIFに長すぎる名前がついていて検出失敗しているんじゃないかと。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;PacketGetAdapterNames: The data area passed to a system call is too small. (122)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因みにコンテナ内から見えるNIFは一つで、以下の構成。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Ethernet adapter vEthernet (Virtual Switch-d206475ce13256766b9a16383540a740fe31da8d20499349fe98693393a8490f-0):

   Connection-specific DNS Suffix  . : localdomain
   Link-local IPv6 Address . . . . . : fe80::4086:d11e:5e6:28fe%26
   IPv4 Address. . . . . . . . . . . : 172.16.0.2
   Subnet Mask . . . . . . . . . . . : 255.240.0.0
   Default Gateway . . . . . . . . . : 172.16.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コンテナ内から &lt;code&gt;www.google.com&lt;/code&gt; とかにping届いたので、このNIFはちゃんと働いていはずなんだけどPcap4Jから見えない。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;
&lt;br&gt;&lt;/p&gt;

&lt;p&gt;後日上記 &lt;code&gt;Dockerfile&lt;/code&gt; でビルドしてみたら、&lt;code&gt;RUN powershell .\install.ps1&lt;/code&gt; で以下のエラーが出るようになった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;The request was aborted: Could not create SSL/TLS secure channel.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;install.ps1の中でChocolateyのインストーラをHTTPSで取ってこようとしてエラーになっている模様。
Windows Containersの&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/about/work_in_progress#https-and-tls-are-not-supported&#34;&gt;ドキュメント&lt;/a&gt;や&lt;a href=&#34;https://social.msdn.microsoft.com/Forums/en-US/c0d93dda-37b7-4a2c-9a78-55e4ba0b88f5/https-support-in-windowsservercore-image?forum=windowscontainers&#34;&gt;フォーラム&lt;/a&gt;にHTTPSが使えないという制限が載っているけどこのせい?
ちょっと前にやったときは同じ &lt;code&gt;Dockerfile&lt;/code&gt; でビルドできたはずなんだけど。&lt;/p&gt;

&lt;p&gt;試しに以下の処理を挟んでChocolateyのインストーラをHTTPで取ってくるようにしたらChocolateyのインストールまではできた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;RUN powershell $(Get-Content install.ps1) -replace \&amp;quot;https\&amp;quot;,\&amp;quot;http\&amp;quot; &amp;gt; install.mod.ps1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;けど &lt;code&gt;choco install&lt;/code&gt; がHTTPS使うので結局駄目だった。&lt;/p&gt;

&lt;p&gt;もう面倒なのでHTTPSの制限がとれるのをまとう。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Pcap4J with Four Native Libraries on Windows 10</title>
          <link>https://www.kaitoy.xyz/2016/01/12/pcap4j-with-four-native-libraries-on-windows10/</link>
          <pubDate>Tue, 12 Jan 2016 08:43:30 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/01/12/pcap4j-with-four-native-libraries-on-windows10/</guid>
          <description>

&lt;p&gt;I did some basic tests for &lt;strong&gt;&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;Pcap4J&lt;/a&gt;&lt;/strong&gt; 1.6.2 on Windows 10 Pro on &lt;a href=&#34;https://www.vmware.com/products/player&#34;&gt;VMware Player&lt;/a&gt; 7.1.0 using the following native packet capture libraries:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;http://www.winpcap.org/&#34;&gt;Official WinPcap&lt;/a&gt;&lt;/strong&gt; 4.1.3&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;http://sourceforge.net/projects/winpcap413-176/&#34;&gt;Unofficial WinPcap based on libpcap 1.7.4&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;http://www.win10pcap.org/&#34;&gt;Win10Pcap&lt;/a&gt;&lt;/strong&gt; 10.2&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/nmap/npcap&#34;&gt;Npcap&lt;/a&gt;&lt;/strong&gt; 0.0.5&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This article explains each of the above libraries and tells the test results.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;official-winpcap&#34;&gt;Official WinPcap&lt;/h2&gt;

&lt;p&gt;WinPcap is the most common native packet capture library developed based on &lt;a href=&#34;http://www.tcpdump.org/&#34;&gt;&lt;strong&gt;libpcap&lt;/strong&gt;&lt;/a&gt;.
(WinPcap 4.1.3 is based on libpcap 1.0.0.)
It&amp;rsquo;s famous as a component of the de facto standard packet capture tool &lt;a href=&#34;https://www.wireshark.org/&#34;&gt;&lt;strong&gt;Wireshark&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;WinPcap consists of &lt;strong&gt;NPF driver&lt;/strong&gt;, &lt;strong&gt;wpcap.dll&lt;/strong&gt;, and &lt;strong&gt;Packet.dll&lt;/strong&gt;.
The structure is described in the &lt;a href=&#34;http://www.winpcap.org/docs/docs_412/html/group__NPF.html&#34;&gt;WinPcap manual&lt;/a&gt; as below:&lt;/p&gt;

&lt;p&gt;&lt;img alt=&#34;NPF&#34; src=&#34;http://www.winpcap.org/docs/docs_412/html/npf-npf.gif&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;wpcap.dll is Windows version of libpcap.so. It uses Packet Driver API implemented in Packet.dll.
Packet.dll talks with the NPF driver.
wpcap.dll and Packet.dll are installed in &lt;code&gt;C:\Windows\System32\&lt;/code&gt; (64 bit binaries) and &lt;code&gt;C:\Windows\SysWOW64\&lt;/code&gt; (32 bit binaries).&lt;/p&gt;

&lt;p&gt;WinPcap worked without any problems in my tests.&lt;/p&gt;

&lt;h2 id=&#34;winpcap-based-on-libpcap-1-7-4&#34;&gt;WinPcap based on libpcap 1.7.4&lt;/h2&gt;

&lt;p&gt;This is an unofficial version of WinPcap which was built on libpcap 1.7.4.
This doesn&amp;rsquo;t include NPF driver and doesn&amp;rsquo;t update Packet.dll.
These two components need to be installed from the official WinPcap 4.1.3.&lt;/p&gt;

&lt;p&gt;This worked well but &lt;a href=&#34;https://github.com/kaitoy/pcap4j/issues/52&#34;&gt;one moderate problem&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;win10pcap&#34;&gt;Win10Pcap&lt;/h2&gt;

&lt;p&gt;Win10Pcap is a WinPcap-based packet capture library developed by &lt;a href=&#34;http://dnobori.cs.tsukuba.ac.jp/en/&#34;&gt;Daiyuu Nobori&lt;/a&gt;.
This includes its own NPF driver and Packet.dll.
The wpcap.dll Win10Pcap installs is exactly the same as one of the official WinPcap 4.1.3.&lt;/p&gt;

&lt;p&gt;The difference between the original WinPcap and Win10Pcap is &lt;a href=&#34;http://www.ndis.com/&#34;&gt;&lt;strong&gt;NDIS&lt;/strong&gt;&lt;/a&gt; (Network Driver Interface Specification) version.
Win10Pcap is based on NDIS 6.x while WinPcap is based on 5.x.&lt;/p&gt;

&lt;p&gt;NDIS version history is as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;NDIS 2.0: MS-DOS, Windows for Workgroups 3.1&lt;/li&gt;
&lt;li&gt;NDIS 3.0: Windows for Workgroups 3.11, NT 3.5&lt;/li&gt;
&lt;li&gt;NDIS 3.1: Windows 95&lt;/li&gt;
&lt;li&gt;NDIS 4.0: Windows 95 OSR2, NT 4.0&lt;/li&gt;
&lt;li&gt;NDIS 4.1: Windows 98, NT 4.0 SP3&lt;/li&gt;
&lt;li&gt;NDIS 5.0: Windows 98 SE, Me, 2000&lt;/li&gt;
&lt;li&gt;NDIS 5.1: Windows XP&lt;/li&gt;
&lt;li&gt;NDIS 5.2: Windows Server 2003&lt;/li&gt;
&lt;li&gt;NDIS 6.0: Windows Vista&lt;/li&gt;
&lt;li&gt;NDIS 6.1: Windows Vista SP1, Server 2008&lt;/li&gt;
&lt;li&gt;NDIS 6.2: Windows 7, Server 2008 R2&lt;/li&gt;
&lt;li&gt;NDIS 6.3: Windows 8, Server 2012&lt;/li&gt;
&lt;li&gt;NDIS 6.4: Windows 8.1, Server 2012 R2&lt;/li&gt;
&lt;li&gt;NDIS 6.5: Windows 10, Server 2016&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Although NDIS 6.x is backward-compatible with 5.x and WinPcap can run on Vista and newer ones, it&amp;rsquo;s expected Win10Pcap is faster than WinPcap because the newer NDIS is more efficient than older versions.&lt;/p&gt;

&lt;p&gt;Win10Pcap worked mostly fine in my tests, but it didn&amp;rsquo;t detect MAC addresses and IPv6 addresses on devices.&lt;/p&gt;

&lt;h2 id=&#34;npcap&#34;&gt;Npcap&lt;/h2&gt;

&lt;p&gt;Npcap is another NDIS 6.x based version of WinPcap developed by &lt;a href=&#34;http://www.veotax.com/&#34;&gt;Yang Luo&lt;/a&gt; for &lt;a href=&#34;https://nmap.org/&#34;&gt;Nmap&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Npcap has a special functionality that allows to capture/send loopback packets.
It creates an adapter &lt;strong&gt;&amp;ldquo;Npcap Loopback Adapter&amp;rdquo;&lt;/strong&gt; for the functionality during its installation.
This adapter can be used in the same way as other normal adapters.&lt;/p&gt;

&lt;p&gt;Npcap provides its own NPF driver and Packet.dll but wpcap.dll is the one pulled from the official WinPcap 4.1.3.&lt;/p&gt;

&lt;p&gt;I installed Npcap with &lt;strong&gt;&amp;ldquo;WinPcap Compatible Mode&amp;rdquo;&lt;/strong&gt; ON for my tests.
It perfectly worked including MAC/IPv6 addresses detection.&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ソフトウェアアーキテクトは何をするのか?</title>
          <link>https://www.kaitoy.xyz/2016/01/11/who-is-software-architect/</link>
          <pubDate>Mon, 11 Jan 2016 14:41:29 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/01/11/who-is-software-architect/</guid>
          <description>

&lt;p&gt;このエントリでは、Yegor Bugayenkoによる記事、&lt;a href=&#34;http://www.yegor256.com/2014/10/12/who-is-software-architect.html&#34;&gt;What Does a Software Architect Do?&lt;/a&gt;を紹介する。
(Yegorから和訳と転載の許可は得た。)
以下はその全文の和訳だが、意訳超訳が混じっているので、もとのニュアンスを知りたければ元記事を読んでもいいし、読まなくてもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;君のプロジェクトにはソフトウェアアーキテクトが居るだろうか?
必要だと思う?&lt;/p&gt;

&lt;p&gt;まあ、ほとんどの&lt;a href=&#34;http://www.yegor256.com/2015/11/21/ringelmann-effect-vs-agile.html&#34;&gt;アジャイルチーム&lt;/a&gt;はそのような役割を明確には定義せず、民主的な感じで働く。
全ての重要な技術的な意思決定はチーム全体で議論され、最多数の投票を得た解決策が採用される。
しばらくして、このようなチームが「ソフトウェアアーキテクト」バッジを誰かのTシャツに付ける事に決めたときは、もっとも評判のいいプログラマがそのバッジを手にする。&lt;/p&gt;

&lt;p&gt;このバッジが彼の責務を変えることはまれだけども。
結局、チームは同じように働き続け、全員を巻き込んだ技術的議論を楽しむ。
つまり、ソフトウェアアーキテクトは責務が明確に定義された役割というよりもステータスになる。
それは最年長で最も権限のある人へのチームメンバからの尊敬の印になる。そうだろ?&lt;/p&gt;

&lt;p&gt;全く間違っている!&lt;/p&gt;

&lt;h2 id=&#34;アーキテクトは品質の責任を負う&#34;&gt;アーキテクトは品質の責任を負う&lt;/h2&gt;

&lt;p&gt;普通はアーキテクトは最も知識、スキル、経験、権限がある人がなるということは明らかだ。
もちろん普通はアーキテクトは他の人よりもものを知っていて、必要に応じて外交的指導的手腕を発揮してその知識を伝達する。
アーキテクトは普通はチームの中で最も賢いやつだ。&lt;/p&gt;

&lt;p&gt;しかしこのことは、彼をアーキテクトたらしめているものではない。&lt;/p&gt;

&lt;p&gt;そして、チームに必要なものでもない。&lt;/p&gt;

&lt;p&gt;私のソフトウェアアーキテクトの定義こうだ。
アーキテクトは品質の責任を負う人だ。&lt;/p&gt;

&lt;p&gt;「責任 (blame)」を職責 (accountability) とか 責務 (responsibility) と言い換えてもいいが、私は「責任 (blame)」という言葉を使うのがいいと思う。
なぜなら、開発中の製品の全ての品質問題がアーキテクトの個人的な失敗であることをより強調するからだ。
もちろん、その責任の対価として、品質がよかった場合には満足した顧客からの称賛は全てアーキテクトのものだ。&lt;/p&gt;

&lt;p&gt;これがチームに必要なものだ。
開発するソフトウェアの品質に対して誰かが個人的に責任を負うのだ。&lt;/p&gt;

&lt;h2 id=&#34;プロジェクトマネージャの仕事は-アーキテクトによる全ての技術的決定に対して誰にも不信を抱かせないようにすること&#34;&gt;プロジェクトマネージャの仕事は、アーキテクトによる全ての技術的決定に対して誰にも不信を抱かせないようにすること&lt;/h2&gt;

&lt;p&gt;アーキテクトが他のメンバにどのように責任を委譲するかはアーキテクト自身の仕事だ。
知識やスキル、&lt;a href=&#34;http://www.yegor256.com/2014/08/13/strict-code-quality-control.html&#34;&gt;品質管理ツール&lt;/a&gt;、ユニットテストフレームワーク、権限、コーチング、&lt;a href=&#34;http://www.yegor256.com/2016/01/05/how-to-punish-employees.html&#34;&gt;体罰&lt;/a&gt;、何を使おうとも、それが彼の仕事だ。
&lt;a href=&#34;http://www.yegor256.com/2015/09/22/micromanagement.html&#34;&gt;プロジェクトマネージャ&lt;/a&gt;は品質管理をソフトウェアアーキテクトに委譲した。
それをさらにどう委譲するかはソフトウェアアーキテクト&lt;a href=&#34;http://www.yegor256.com/2015/02/23/haircut.html&#34;&gt;次第だ&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;ソフトウェアアーキテクトの役割は全てのプロジェクトにおいて重大だ。
たとえたった二人のプログラマが同じデスクで働いている場合でもだ。
二人のうち一人はアーキテクトでなければならない。&lt;/p&gt;

&lt;p&gt;理想的なアーキテクトは上記の長所の全てを持つ。
彼は全員の意見を聞いて考慮に入れる。
彼はよいコーチであり先生だ。忍耐もある。
彼は効果的な伝達者であり交渉人だ。
外交官だ。
技術的な領域のエキスパートだ。&lt;/p&gt;

&lt;p&gt;しかし、たとえこうした長所全てを持たなくても、彼の決定は常に最終決定だ。&lt;/p&gt;

&lt;p&gt;そして、プロジェクトマネージャの仕事は、アーキテクトによる全ての技術的決定に対して誰にも不信を抱かせないようにすることだ。
これが委譲というものだ。
責任には常に権力が伴う。&lt;/p&gt;

&lt;p&gt;プロジェクトマネージャは定期的にアーキテクトの成果を評価すべきだ。
チームで開発中の製品の品質はアーキテクトの個人的な(!)責任だということを思い出してほしい。
どんな問題であっても彼の問題だ。
彼を責めたり罰したりすることを恐れてはいけない。
ただし、罰を有効なものにするためには、アーキテクトの行動に対して全力で応えるべきだということをを忘れてはいけない。
繰り返すが、彼の決定は最終決定だ。&lt;/p&gt;

&lt;p&gt;もしプロジェクトマネージャが製品の品質に満足せず、またアーキテクトがその状況を改善しないなら、アーキテクトを&lt;a href=&#34;http://www.yegor256.com/2015/09/16/how-to-fire-someone-right.html&#34;&gt;交代&lt;/a&gt;させる。
彼をプログラマに降格させ、他のプログラマをアーキテクトに昇格させる。
ただし、チームにアーキテクトは常に一人だけで、彼の決定が最終的なものであることを忘れてはいけない。&lt;/p&gt;

&lt;p&gt;それが完璧な製品を作れる可能性をもつただ一つの方法だ。&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;embed video-player&#34; style=&#34;text-align: center&#34;&gt;
  &lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;320&#34; height=&#34;193&#34; src=&#34;https://www.youtube.com/embed/0fuEgmibJc4&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上がYegorの記事。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/08/11/daily-stand-up-meetings-are-a-good-tool-for-a-bad-manager/&#34;&gt;スタンドアップミーティングに関する記事&lt;/a&gt;でも言っていた責任の委譲がこの記事でも触れられている。
プロジェクトマネージャは技術的な責任を誰かに委譲して、そいつをアーキテクトと呼べということだ。
責任には権限が伴うので、アーキテクトは技術面での最終決定権を持つ。&lt;/p&gt;

&lt;p&gt;それだけ。Yegorの他の記事に比べてシンプルな主張。
もう少し、アーキテクトが品質を確保するために何をすべきかといったことが書いてあると期待してたが。&lt;/p&gt;

&lt;p&gt;責任を委譲してそれに権限が付随するのか、権限を委譲してそれに責任が付随するのか、という細かい疑問はあるが、この記事の主な主張に対しては特に何も言うことがない。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>pcap-ng support in Pcap4J</title>
          <link>https://www.kaitoy.xyz/2016/01/10/pcap-ng-support-in-pcap4j/</link>
          <pubDate>Sun, 10 Jan 2016 09:52:06 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/01/10/pcap-ng-support-in-pcap4j/</guid>
          <description>

&lt;p&gt;Sometimes I receive inquiries about support for &lt;strong&gt;pcap-ng&lt;/strong&gt; files in &lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;&lt;strong&gt;Pcap4J&lt;/strong&gt;&lt;/a&gt;.
I wrote the result of my investigation on it in this article.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;what-s-a-pcap-ng-file&#34;&gt;What&amp;rsquo;s a pcap-ng file&lt;/h2&gt;

&lt;p&gt;A pcap-ng file (i.e. a file with &lt;code&gt;.pcapng&lt;/code&gt; extension ) is a packet dump file in &lt;a href=&#34;https://github.com/pcapng/pcapng&#34;&gt;&lt;strong&gt;The pcap Next Generation Capture File Format&lt;/strong&gt;&lt;/a&gt; (or pcap-ng format for short).
This format was created to overcome the limitations of the traditional &lt;a href=&#34;https://wiki.wireshark.org/Development/LibpcapFileFormat&#34;&gt;&lt;strong&gt;Libpcap File Format&lt;/strong&gt;&lt;/a&gt; (or pcap format for short) which is used in pcap files.&lt;/p&gt;

&lt;p&gt;Although the pcap format has been widely used for a long time, recent &lt;a href=&#34;https://www.wireshark.org/&#34;&gt;&lt;strong&gt;Wireshark&lt;/strong&gt;&lt;/a&gt;, the de facto standard packet capture tool, uses the pcap-ng format by default to save captured packets.
So, it&amp;rsquo;s expected that the pcap-ng format would be more common and pcap format would be a legacy in the future.&lt;/p&gt;

&lt;h2 id=&#34;pcap-ng-support-in-pcap4j&#34;&gt;pcap-ng support in Pcap4J&lt;/h2&gt;

&lt;p&gt;Of course Pcap4J supports traditional pcap format.
But how about the pcap-ng format?&lt;/p&gt;

&lt;p&gt;Whether Pcap4J can handle pcap-ng files is up to its underlying native library.
Remember Pcap4J is a wrapper library for &lt;a href=&#34;http://www.tcpdump.org/&#34;&gt;&lt;strong&gt;libpcap&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&#34;http://www.winpcap.org/&#34;&gt;&lt;strong&gt;WinPcap&lt;/strong&gt;&lt;/a&gt;.
If the libpcap/WinPcap supports the pcap-ng format Pcap4J does, and vice versa.&lt;/p&gt;

&lt;h2 id=&#34;pcap-ng-support-in-libpcap&#34;&gt;pcap-ng support in libpcap&lt;/h2&gt;

&lt;p&gt;The libpcap got limited support for reading pcap-ng files in &lt;a href=&#34;https://github.com/the-tcpdump-group/libpcap/blob/libpcap-1.1/CHANGES&#34;&gt;1.1.0&lt;/a&gt;, and then the following three bugs around the feature were fixed:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;filtering issue (fixed in 1.2.1)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/the-tcpdump-group/libpcap/issues/139&#34;&gt;pcap_datalink() returns wrong value&lt;/a&gt; (fixed in 1.1.2)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/the-tcpdump-group/libpcap/issues/349&#34;&gt;Wrong timestamps on big-endian machines&lt;/a&gt; (fixed in 1.7.2)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;No enhancement for pcap-ng support since 1.1.0 as of now (1.7.5).&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t know what &amp;ldquo;limited&amp;rdquo; means, but anyway it looked like Pcap4J 1.6.2 could read pcap-ng files without any problems as far as I tested it with libpcap 1.7.4.&lt;/p&gt;

&lt;p&gt;As for writing pcap-ng files, the libpcap doesn&amp;rsquo;t provide any support for it yet.&lt;/p&gt;

&lt;h2 id=&#34;pcap-ng-support-in-winpcap&#34;&gt;pcap-ng support in WinPcap&lt;/h2&gt;

&lt;p&gt;WinPcap is the Windows version of libpcap and each version of it is based on a certain version of libpcap.
The newest version of WinPcap, WinPcap 4.1.3, was developed with libpcap 1.0.0.
It means WinPcap doesn&amp;rsquo;t support pcap-ng format yet at all.&lt;/p&gt;

&lt;p&gt;But, there is an &lt;a href=&#34;http://sourceforge.net/projects/winpcap413-176/&#34;&gt;unofficial build of WinPcap based on libpcap 1.7.4&lt;/a&gt;.
As far as I tested this WinPcap through Pcap4J 1.6.2, it worked well on reading pcap-ng files as well as on basic functionalities such as finding network devices and live capture except &lt;a href=&#34;https://github.com/kaitoy/pcap4j/issues/52&#34;&gt;getting capture statistics&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;how-to-read-a-pcap-ng-file&#34;&gt;How to read a pcap-ng file&lt;/h2&gt;

&lt;p&gt;How to read a pcap-ng file is exactly the same as how to read a pcap file.&lt;/p&gt;

&lt;p&gt;Use &lt;a href=&#34;http://kaitoy.github.io/pcap4j/javadoc/latest/en/org/pcap4j/core/Pcaps.html#openOffline%28java.lang.String%29&#34;&gt;&lt;code&gt;Pcaps.openOffline()&lt;/code&gt;&lt;/a&gt; to open a pcap-ng file and call read methods such as &lt;a href=&#34;http://kaitoy.github.io/pcap4j/javadoc/latest/en/org/pcap4j/core/PcapHandle.html#getNextPacketEx%28%29&#34;&gt;&lt;code&gt;getNextPacketEx()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;http://kaitoy.github.io/pcap4j/javadoc/latest/en/org/pcap4j/core/PcapHandle.html#loop%28int,%20org.pcap4j.core.PacketListener%29&#34;&gt;&lt;code&gt;loop()&lt;/code&gt;&lt;/a&gt; on the returned &lt;a href=&#34;http://kaitoy.github.io/pcap4j/javadoc/latest/en/org/pcap4j/core/PcapHandle.html&#34;&gt;&lt;code&gt;PcapHandle&lt;/code&gt;&lt;/a&gt; object to get packets in the file.&lt;/p&gt;

&lt;p&gt;For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void main(String args[]) throws PcapNativeException, NotOpenException {
  PcapHandle ph = Pcaps.openOffline(&amp;quot;/path/to/test.pcapng&amp;quot;);
  ph.setFilter(&amp;quot;tcp&amp;quot;, BpfProgram.BpfCompileMode.OPTIMIZE);
  while (true) {
    try {
      Packet p = ph.getNextPacketEx();
      if (p != null) {
        System.out.println(p);
      }
    } catch (EOFException e) {
      System.out.println(&amp;quot;End of file&amp;quot;);
      break;
    } catch (TimeoutException e) {
      System.out.println(&amp;quot;Timed out&amp;quot;);
      break;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;If you try to read a pcap-ng file using Pcap4J with a native library which doesn&amp;rsquo;t support pcap-ng format, Pcap4J throws &lt;a href=&#34;http://kaitoy.github.io/pcap4j/javadoc/latest/en/org/pcap4j/core/PcapNativeException.html&#34;&gt;&lt;code&gt;PcapNativeException&lt;/code&gt;&lt;/a&gt; as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Exception in thread &amp;quot;main&amp;quot; org.pcap4j.core.PcapNativeException: bad dump file format
        at org.pcap4j.core.Pcaps.openOffline(Pcaps.java:203)
        at Test.main(Test.java:16)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>オブジェクト指向プログラミングにおいてユーティリティクラスに代わるもの</title>
          <link>https://www.kaitoy.xyz/2016/01/03/oop-alternative-to-utility-classes/</link>
          <pubDate>Sun, 03 Jan 2016 23:36:01 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/01/03/oop-alternative-to-utility-classes/</guid>
          <description>

&lt;p&gt;このエントリでは、Yegor Bugayenkoによる記事、&lt;a href=&#34;http://www.yegor256.com/2014/05/05/oop-alternative-to-utility-classes.html&#34;&gt;OOP Alternative to Utility Classes&lt;/a&gt;を紹介する。
(Yegorから和訳と転載の許可は得た。)
以下はその全文の和訳だが、意訳超訳が混じっているので、もとのニュアンスを知りたければ元記事を読んでもいいし、読まなくてもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;ユーティリティクラス(またはヘルパークラス)は、スタティックメソッドだけを持っていて、状態を内包しない「構造体」だ。
&lt;a href=&#34;http://commons.apache.org/&#34;&gt;Apache Commons&lt;/a&gt;の&lt;code&gt;StringUtils&lt;/code&gt;、&lt;code&gt;IOUtils&lt;/code&gt;、&lt;code&gt;FileUtils&lt;/code&gt;や、&lt;a href=&#34;https://code.google.com/p/guava-libraries/&#34;&gt;Guava&lt;/a&gt;の&lt;code&gt;Iterables&lt;/code&gt;、&lt;code&gt;Iterators&lt;/code&gt;、またJDK7の&lt;code&gt;Files&lt;/code&gt;はユーティリティクラスのいい例だ。&lt;/p&gt;

&lt;p&gt;ユーティリティクラスはよく使われる共通機能を提供するので、この設計手法はJava(やC#、Rubyなど)の世界でとても人気だ。&lt;/p&gt;

&lt;p&gt;要するに我々は、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Don&#39;t_repeat_yourself&#34;&gt;DRY原則&lt;/a&gt;に従い、重複を避けたい。
だから、共通コードをユーティリティクラスに入れて必要に応じて再利用する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// これはひどい設計なので再利用しないように。
public class NumberUtils {
  public static int max(int a, int b) {
    return a &amp;gt; b ? a : b;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実際、これはとても便利なテクニックだ!?&lt;/p&gt;

&lt;h2 id=&#34;ユーティリティクラスは悪だ&#34;&gt;ユーティリティクラスは悪だ&lt;/h2&gt;

&lt;p&gt;しかし、オブジェクト指向の世界では、ユーティリティクラスはかなり悪い(酷いという人さえいるかもしれない)手法だ。&lt;/p&gt;

&lt;p&gt;これについては多くの議論がある。
いくつか挙げると、Nick Malikの「&lt;a href=&#34;http://blogs.msdn.com/b/nickmalik/archive/2005/09/06/461404.aspx&#34;&gt;ヘルパークラスは悪か?&lt;/a&gt;」、Simon Hartの「&lt;a href=&#34;http://smart421.wordpress.com/2011/08/31/why-helper-singletons-and-utility-classes-are-mostly-bad-2/&#34;&gt;なぜヘルパー、シングルトン、ユーティリティクラスはだいたい間違っているのか&lt;/a&gt;」、Marshal Wardの「&lt;a href=&#34;http://www.marshallward.org/avoiding-utility-classes.html&#34;&gt;ユーティリティクラスを避ける&lt;/a&gt;」、Dhaval Dalalの「&lt;a href=&#34;http://www.jroller.com/DhavalDalal/entry/kill_that_util_class&#34;&gt;ユーティルクラスを殺せ!&lt;/a&gt;」、Rob Bagbyの「&lt;a href=&#34;http://www.robbagby.com/posts/helper-classes-are-a-code-smell/&#34;&gt;ヘルパークラスは問題の兆候&lt;/a&gt;」。&lt;/p&gt;

&lt;p&gt;また、StackExchangeにはユーティリティクラスについての質問がいくつかある。
例えば、「&lt;a href=&#34;http://stackoverflow.com/questions/3339929/if-a-utilities-class-is-evil-where-do-i-put-my-generic-code&#34;&gt;ユーティリティクラスが悪なら、どこに共通コードを書けばいい?&lt;/a&gt;」とか、「&lt;a href=&#34;http://stackoverflow.com/questions/3340032/utility-classes-are-evil&#34;&gt;ユーティリティクラスは悪&lt;/a&gt;」とか。&lt;/p&gt;

&lt;p&gt;これらの主張は要するに、ユーティリティクラスは適切なオブジェクトではないということだ。
だから、オブジェクト指向の世界に適合しない。
ユーティリティクラスは、当時の人々が機能分割パラダイムに慣れていたために、手続き型言語から受け継がれた。&lt;/p&gt;

&lt;p&gt;君がこの主張に同意し、ユーティリティクラスを使うのをやめたがっていると想定し、そいつをどのように適切なオブジェクトに置き換えるかを例を挙げながら教えよう。&lt;/p&gt;

&lt;h2 id=&#34;手続き型の例&#34;&gt;手続き型の例&lt;/h2&gt;

&lt;p&gt;例えば、テキストファイルを読んで、行で分割し、各行をトリムして、その結果を別のファイルに保存したいとする。
これはApache Commonsの&lt;code&gt;FileUtils&lt;/code&gt;を使えばできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;void transform(File in, File out) {
  Collection&amp;lt;String&amp;gt; src = FileUtils.readLines(in, &amp;quot;UTF-8&amp;quot;);
  Collection&amp;lt;String&amp;gt; dest = new ArrayList&amp;lt;&amp;gt;(src.size());
  for (String line : src) {
    dest.add(line.trim());
  }
  FileUtils.writeLines(out, dest, &amp;quot;UTF-8&amp;quot;);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上のコードはきれいに見える。
しかし、これは手続き型プログラミングであって、オブジェクト指向じゃない。
コードの各行で、データ(byteとbit)を操作し、コンピューターにどこからデータを取ってどこに書き込むかを明示的に指示している。
処理の手順を定義している。&lt;/p&gt;

&lt;h2 id=&#34;オブジェクト指向な方法&#34;&gt;オブジェクト指向な方法&lt;/h2&gt;

&lt;p&gt;オブジェクト指向パラダイムでは、オブジェクトをインスタンス化して合成すべきだ。
これはオブジェクトにオブジェクト自身のやり方でデータを管理させるためだ。
補足的なスタティックメソッドを呼ぶ代わりに、求めている挙動を提供できるオブジェクトを生成するべきだ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class Max implements Number {
  private final int a;
  private final int b;
  public Max(int x, int y) {
    this.a = x;
    this.b = y;
  }
  @Override
  public int intValue() {
    return this.a &amp;gt; this.b ? this.a : this.b;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下の手続き型のメソッド呼び出しは、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;int max = NumberUtils.max(10, 5);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下の様にオブジェクト指向的になる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;int max = new Max(10, 5).intValue();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;どっちでも同じ?
いや、そうでもない。
もう少し読み進めて欲しい。&lt;/p&gt;

&lt;h2 id=&#34;データ構造ではなくオブジェクト&#34;&gt;データ構造ではなくオブジェクト&lt;/h2&gt;

&lt;p&gt;私なら、上と同じファイル編集機能をオブジェクト指向なやり方で以下の様に設計する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;void transform(File in, File out) {
  Collection&amp;lt;String&amp;gt; src = new Trimmed(
    new FileLines(new UnicodeFile(in))
  );
  Collection&amp;lt;String&amp;gt; dest = new FileLines(
    new UnicodeFile(out)
  );
  dest.addAll(src);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(訳注: 上のコードは以下のコードの誤記だと思われる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;void transform(File in, File out) {
  Trimmed src = new Trimmed(
    new FileLines(new UnicodeFile(in))
  );
  FileLines dest = new FileLines(
    new UnicodeFile(out)
  );
  dest.addAll(src);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;FileLines&lt;/code&gt;は&lt;code&gt;Collection&amp;lt;String&amp;gt;&lt;/code&gt;を実装していて、ファイルの読み込みと書き込みの処理を内包している。
&lt;code&gt;FileLines&lt;/code&gt;のインスタンスは文字列のコレクションと全く同じ挙動をし、全てのI/O処理を隠蔽している。
このインスタンスを繰り返し処理するとファイルが読み込まれる。
このインスタンスに&lt;code&gt;addAll()&lt;/code&gt;するとファイルに書き込まれる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Trimmed&lt;/code&gt;も&lt;code&gt;Collection&amp;lt;String&amp;gt;&lt;/code&gt;を実装していて、文字列のコレクションを内包している(&lt;a href=&#34;https://ja.wikipedia.org/wiki/Decorator_%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3&#34;&gt;Decoratorパターン&lt;/a&gt;)。
一行が取得されるたびにトリムされる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Trimmed&lt;/code&gt;も&lt;code&gt;FileLines&lt;/code&gt;も&lt;code&gt;UnicodeFile&lt;/code&gt;も、上記スニペットに出てくる全てのクラスは小さめだ。
それぞれが自身の単一の機能に責任を持ち、つまり&lt;a href=&#34;http://d.hatena.ne.jp/asakichy/20110808/1312754662&#34;&gt;単一責任原則&lt;/a&gt;に完璧に従っている。&lt;/p&gt;

&lt;p&gt;我々側、つまりライブラリのユーザから見るとこれはそれほど重要ではないかもしれないが、ライブラリの開発者から見ると肝要だ。
80以上のメソッドを持つ3000行のユーティリティクラスである&lt;code&gt;FileUtils&lt;/code&gt;の&lt;code&gt;readLines()&lt;/code&gt;よりも、&lt;code&gt;FileLines&lt;/code&gt;の方が開発やメンテナンスやユニットテストがしやすい。
真面目な話、&lt;a href=&#34;http://svn.apache.org/viewvc/commons/proper/io/trunk/src/main/java/org/apache/commons/io/FileUtils.java?view=co&#34;&gt;そのソース&lt;/a&gt;を読んでみて欲しい。&lt;/p&gt;

&lt;p&gt;オブジェクト指向のアプローチは遅延実行を可能にする。
&lt;code&gt;in&lt;/code&gt;ファイルはそのデータが必要になるまで読まれない。
I/Oエラーで開けなかったら触られすらしない。
全ては&lt;code&gt;addAll()&lt;/code&gt;を呼んだ後に始まる。&lt;/p&gt;

&lt;p&gt;二つ目のスニペットの最終行を除く全行は、小さいオブジェクトをインスタンス化して大きいオブジェクトを合成している。
このオブジェクト合成は、データ変換を起こさないのでCPUコストはむしろ低い。&lt;/p&gt;

&lt;p&gt;さらに、二つ目のスクリプトがO(1)の空間計算量で動くのに対し、一つ目のスクリプトはO(n)で動くのは明らかだ。
これが一つ目のスクリプトでデータに対して手続き型アプローチをした結果だ。&lt;/p&gt;

&lt;p&gt;オブジェクト指向の世界では、データというものはない。オブジェクトとその挙動しかないのだ！&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;embed video-player&#34; style=&#34;text-align: center&#34;&gt;
  &lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;320&#34; height=&#34;193&#34; src=&#34;https://www.youtube.com/embed/psrp3TtaYYI&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上がYegorの記事。&lt;/p&gt;

&lt;p&gt;私はユーティリティクラスは結構好きで、以下の点で有用だと思う。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ライブラリ開発者視点:

&lt;ul&gt;
&lt;li&gt;少数のクラスで多くの共通処理を実装できる。&lt;/li&gt;
&lt;li&gt;ユーティリティクラスは(普通)状態を持たないので、マルチスレッドなどを意識せずに簡単に書ける。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ライブラリ利用者視点:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;オブジェクトを作らなくても使えるので、オーバーヘッドが少なくコードを書くのも楽。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ユーティリティクラスのメソッド呼び出しは大抵、「&amp;lt;問題領域&amp;gt;.&amp;lt;動詞&amp;gt;&amp;lt;目的語&amp;gt;()」という形になっていて、何をやっているのかわかりやすい。&lt;/p&gt;

&lt;p&gt;上で出てきた&lt;code&gt;FileUtils.readLines()&lt;/code&gt;も、ファイルを対象に(問題領域)、行を(目的語)読みこむ(動詞)メソッドであることが一目瞭然。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ユーティリティクラス反対派の主張が、それがオブジェクト真理教の教義に照らして適切なオブジェクトではなく、オブジェクト指向の世界に適合しないという哲学的なものである時点で、ユーティリティクラスをやめる動機に全くつながらない。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;transform()&lt;/code&gt;の実装は、Apache Commonsを使ったやつの方が自分でクラスを作らなくて済み、開発量が少なくてよい、というのが普通の感覚ではないだろうか。&lt;/p&gt;

&lt;p&gt;さらに、Yegorの&lt;code&gt;transform()&lt;/code&gt;の実装だと、I/O処理を隠蔽しすぎて何をやっているのかコードからさっぱりわからない。
&lt;code&gt;addAll()&lt;/code&gt;するとファイルへの書き込みが発生するなんて誰も想像だにしまい。
オブジェクト真理教の神のみぞ知るといった感じの挙動だ。
こんなコードで可読性、つまり保守性が「手続き型の例」のやつより高くなるとは到底思えない。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>git resetとrevertを図解する</title>
          <link>https://www.kaitoy.xyz/2016/01/01/git-revert-reset/</link>
          <pubDate>Fri, 01 Jan 2016 18:38:02 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/01/01/git-revert-reset/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;この記事&lt;/a&gt;を読んだ、またはGitのオブジェクトモデルを理解していることを前提に、&lt;a href=&#34;https://git-scm.com/&#34;&gt;&lt;strong&gt;Git&lt;/strong&gt;&lt;/a&gt;の &lt;code&gt;git revert&lt;/code&gt; と &lt;code&gt;git reset&lt;/code&gt;というコマンドについて説明する。
この二つはしばしばコミットを取り消すコマンドとして同じ文脈で説明されることが多いのでこのエントリでも一緒に説明するが、実際は全く異なるコマンドだし、そもそもどちらもコミットを取り消すコマンドではない。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;git-revert&#34;&gt;git revert&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;git revert&lt;/code&gt;は、指定したコミットが持ち込んだ変更を打ち消すコミットを追加する。
リバースパッチを適用すると言ってもよい。
コミットを追加しかしないので、このコマンドによって既存のコミットが消えたり変わったりすることはない。&lt;/p&gt;

&lt;p&gt;図にすると以下の感じ。単純。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-revert-reset/git_revert/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-revert-reset/git_revert/スライド2.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;git-reset&#34;&gt;git reset&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;git reset&lt;/code&gt;には二つの機能がある。
インデックスを再設定する(i.e. resetする)機能と、&lt;code&gt;HEAD&lt;/code&gt;を付け替える(i.e. resetする)機能だ。&lt;/p&gt;

&lt;h4 id=&#34;インデックスの再設定&#34;&gt;インデックスの再設定&lt;/h4&gt;

&lt;p&gt;インデックスの再設定をするコマンドは&lt;code&gt;git reset &amp;lt;ワーキングディレクトリ内のファイルのパス(複数可)&amp;gt;&lt;/code&gt;。
これを実行すると、指定したファイルについて、&lt;code&gt;HEAD&lt;/code&gt;が指すコミットが指すツリー内のブロブを指すようインデックスを更新する。&lt;/p&gt;

&lt;p&gt;何を言っているのかわからないので図にする。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-revert-reset/git_reset_path/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-revert-reset/git_reset_path/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-revert-reset/git_reset_path/スライド3.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(この図では便宜的に&lt;code&gt;HEAD&lt;/code&gt;、つまり参照をオブジェクト格納領域内に書いているが、実際には別の場所にあることに注意。)&lt;/p&gt;

&lt;p&gt;図を見ると、&lt;code&gt;git add Readme.md&lt;/code&gt;と&lt;code&gt;git reset Readme.md&lt;/code&gt;がだいたい逆のことをしていることがわかる。
要するに、&lt;code&gt;git add &amp;lt;パス&amp;gt;&lt;/code&gt;は指定したファイルをステージし、&lt;code&gt;git reset &amp;lt;パス&amp;gt;&lt;/code&gt;は指定したファイルをアンステージする。&lt;/p&gt;

&lt;h4 id=&#34;headの付け替え&#34;&gt;HEADの付け替え&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;HEAD&lt;/code&gt;の付け替えをするコマンドは&lt;code&gt;git reset &amp;lt;コミット&amp;gt;&lt;/code&gt;。
これを実行すると、&lt;code&gt;HEAD&lt;/code&gt;が指しているコミットを指すよう&lt;code&gt;ORIG_HEAD&lt;/code&gt;を作成または更新し、指定したコミットを指すよう&lt;code&gt;HEAD&lt;/code&gt;を更新する。
オプションによってはさらにインデックスやワーキングディレクトリを指定したコミットが指すツリーと同期するよう更新する。&lt;/p&gt;

&lt;p&gt;このオプションには&lt;code&gt;--soft&lt;/code&gt;、&lt;code&gt;--mixed&lt;/code&gt; (デフォルト)、&lt;code&gt;--hard&lt;/code&gt;の三種類があり、それぞれのオプションを付けた時の更新対象を次の表に示す。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;オプション&lt;/th&gt;
&lt;th&gt;HEAD&lt;/th&gt;
&lt;th&gt;インデックス&lt;/th&gt;
&lt;th&gt;ワーキングディレクトリ&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;--soft&lt;/td&gt;
&lt;td&gt;○&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;--mixed&lt;/td&gt;
&lt;td&gt;○&lt;/td&gt;
&lt;td&gt;○&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;--hard&lt;/td&gt;
&lt;td&gt;○&lt;/td&gt;
&lt;td&gt;○&lt;/td&gt;
&lt;td&gt;○&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;この三者の違いについては面倒だしだいたい分かるはずなので図にしないが、&lt;code&gt;git reset &amp;lt;コミット&amp;gt;&lt;/code&gt;したときの&lt;code&gt;HEAD&lt;/code&gt;動きについて次に図示する。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-revert-reset/git_reset_commit/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-revert-reset/git_reset_commit/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-revert-reset/git_reset_commit/スライド3.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;スライド中で&lt;code&gt;git reset HEAD^&lt;/code&gt;した時点で、コミットDは実質的に削除されたに近い状態になる。
&lt;code&gt;ORIG_HEAD&lt;/code&gt;という一時的なシンボリック参照で指されているだけで、どの参照からもたどり着けなくなるからだ。
コミットDはいずれ&lt;code&gt;git gc&lt;/code&gt;によって実際に削除されるはずだし、&lt;code&gt;git push&lt;/code&gt;してもコミットD、それが指すツリー、そのツリーの下にしかないブロブはリモートリポジトリに送られない。&lt;/p&gt;

&lt;p&gt;よって、&lt;code&gt;git reset &amp;lt;コミット&amp;gt;&lt;/code&gt;は普通コミットを削除したいときに使われる。
使われはするが、このコマンド自体がコミットを削除するわけではなくて、あくまで&lt;code&gt;HEAD&lt;/code&gt;を付け替えるコマンドであることを覚えていた方がいざというときに助かる。&lt;/p&gt;

&lt;p&gt;因みに上のスライドでやった操作は、&lt;code&gt;git commit --amend&lt;/code&gt;がやることとほぼ同じ。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Gitの分散バージョン管理の仕組み</title>
          <link>https://www.kaitoy.xyz/2015/12/31/git-dvc/</link>
          <pubDate>Thu, 31 Dec 2015 01:02:59 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/12/31/git-dvc/</guid>
          <description>

&lt;p&gt;このエントリでは、&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;この記事&lt;/a&gt;を読んだ、またはGitのオブジェクトモデルを理解していることを前提に、&lt;a href=&#34;https://git-scm.com/&#34;&gt;&lt;strong&gt;Git&lt;/strong&gt;&lt;/a&gt;の分散バージョン管理の仕組みについて説明する。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;gitの分散バージョン管理&#34;&gt;Gitの分散バージョン管理&lt;/h2&gt;

&lt;p&gt;分散バージョン管理とは、分散したリポジトリでのバージョン管理ということ。
ここでリポジトリが分散しているとは、同じプロジェクトの履歴を管理する完全で独立したリポジトリが複数あるということ。
これにより一つのプロジェクトの開発を地理的に分散して並行して進めることができる。&lt;/p&gt;

&lt;p&gt;Gitは分散バージョン管理のために、リポジトリのクローン(≒コピー)を作る機能と、リポジトリ間でコミットグラフを同期する機能を提供している。&lt;/p&gt;

&lt;p&gt;リポジトリのクローンを作ると言うと、オリジナルとクローンの間に格差があるような気がするが、
実際にはGitは全てのリポジトリが対等であるという思想のもとで実装されている。
このため、リポジトリをクローンする時には(デフォルトで)クローン元の完全なコミットグラフがクローンにコピーされるし、任意のリポジトリ間のデータのやり取りをpeer-to-peerでできる。
クローンからクローンを作ることももちろん可能。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git push&lt;/code&gt;でデータを送る先をアップストリームと呼ぶことはあるし、次節でローカルリポジトリとリモートリポジトリという関係が出てくるが、これはあくまでその時点でそういう設定になっているというだけ。
アップストリームはいつでもいくつでも&lt;code&gt;git remote&lt;/code&gt;コマンドで追加したり削除したりできる。&lt;/p&gt;

&lt;p&gt;このような実装により、Gitの分散バージョン管理ではリポジトリ間で柔軟なデータのやり取りができる。
例えば以下の様な複雑なリポジトリネットワークを組むこともできる。&lt;/p&gt;

&lt;p&gt;&lt;img alt=&#34;good-object-2.png&#34; src=&#34;https://www.kaitoy.xyz/images/git-dvc/repo_net.png&#34; style=&#34;width: 100%; max-width: 400px; margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;h2 id=&#34;ローカルリポジトリとリモートリポジトリ&#34;&gt;ローカルリポジトリとリモートリポジトリ&lt;/h2&gt;

&lt;p&gt;一人の開発者から見て、手元にあるリポジトリを &lt;strong&gt;ローカルリポジトリ&lt;/strong&gt; と呼ぶのに対して、&lt;code&gt;git push&lt;/code&gt;や&lt;code&gt;git pull&lt;/code&gt;や&lt;code&gt;git fetch&lt;/code&gt;でデータをやり取りする相手のリポジトリを &lt;strong&gt;リモートリポジトリ&lt;/strong&gt; と呼ぶ。
リモートリポジトリとのやり取りは、&lt;strong&gt;リモート追跡ブランチ&lt;/strong&gt; と &lt;strong&gt;リモート&lt;/strong&gt; というものを使って実装されている。&lt;/p&gt;

&lt;h4 id=&#34;リモート追跡ブランチ&#34;&gt;リモート追跡ブランチ&lt;/h4&gt;

&lt;p&gt;リモート追跡ブランチは、ローカルリポジトリの&lt;code&gt;.git/refs/remotes/&lt;/code&gt;に格納される参照で、リモートリポジトリ内のローカルブランチのコミットグラフを取得してローカルリポジトリ内に保持するために使われる。
&lt;code&gt;git branch -r&lt;/code&gt;でその一覧が見れる。&lt;/p&gt;

&lt;p&gt;「追跡」ブランチというだけあって、リモートリポジトリ内でコミットグラフが成長した場合、この変更に追随することができる。
このためのコマンドが&lt;code&gt;git fetch&lt;/code&gt;。
因みに&lt;code&gt;git pull&lt;/code&gt;は、&lt;code&gt;git fetch&lt;/code&gt;でリモート追跡ブランチを更新した後、&lt;code&gt;git merge&lt;/code&gt;(オプションによっては&lt;code&gt;git rebase&lt;/code&gt;)でそのリモート追跡ブランチをローカルブランチにマージするのと同じ。&lt;/p&gt;

&lt;h4 id=&#34;リモート&#34;&gt;リモート&lt;/h4&gt;

&lt;p&gt;リモートとは、リモートリポジトリのこと、またはリモートリポジトリに接続するための定義のこと。
この定義は、ローカルリポジトリの&lt;code&gt;.git/config&lt;/code&gt;に&lt;code&gt;remote&lt;/code&gt;セクションとして書かれている。
以下がその例。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[remote &amp;quot;origin&amp;quot;]
        fetch = +refs/heads/*:refs/remotes/origin/*
        url = git@github.com:kaitoy/blog.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;セクション名のところに&lt;code&gt;&amp;quot;origin&amp;quot;&lt;/code&gt;とあるがこれは、この定義で接続するリモートリポジトリをGitコマンドなどで&lt;code&gt;origin&lt;/code&gt;と指定できるということ。
ここで定義されているのは&lt;code&gt;url&lt;/code&gt;と&lt;code&gt;fetch&lt;/code&gt;で、それぞれ以下を意味する。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;url&lt;/p&gt;

&lt;p&gt;リモートリポジトリのURL。
つまり、リモートリポジトリがどのサーバのどのディレクトリにあって、それとのデータのやり取りをどのプロトコルでやるかという定義。
このURLには以下の書式が使える。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;ファイルパス&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/path/to/repo.git&lt;/code&gt;とか&lt;code&gt;C:\\Users\\Kaito\\Desktop\\pcap4j&lt;/code&gt;といった、普通のファイルパスの書式。
&lt;a href=&#34;https://ja.wikipedia.org/wiki/Network_File_System&#34;&gt;NFS&lt;/a&gt;などでリモートリポジトリが共有されている場合などに使われる。&lt;/p&gt;

&lt;p&gt;シンボリックリンクがサポートされているOS上では、クローンはリモートリポジトリをハードリンクで参照する。
このシンボリック参照でのファイル共有がトラブルの元なため、この書式は非推奨。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;ファイルURL&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;file:///path/to/repo.git&lt;/code&gt;とか&lt;code&gt;file://C:/Users/Kaito/Desktop/pcap4j&lt;/code&gt;といった、ローカルホスト上のパスを示すファイルURLの書式。
用途はファイルパスと同様だが、ハードリンクを作る代わりにコピーするのでより安全。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;HTTP(S)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;https://github.com/kaitoy/pcap4j.git&lt;/code&gt;といったHTTPSやHTTPのURL。
リポジトリへのアクセス制御にHTTPの認証機能やHTTPSのクライアント証明書などが使えるほか、HTTPSなら通信の暗号化もできる。&lt;/p&gt;

&lt;p&gt;使用するポートがファイアウォールにブロックされていることが少ないのも使いやすい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Gitプロトコル&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git://example.com/path/to/repo.git&lt;/code&gt;といった書式で、&lt;a href=&#34;https://git-scm.com/book/ja/v1/Git-%E3%82%B5%E3%83%BC%E3%83%90%E3%83%BC-Git-%E3%83%87%E3%83%BC%E3%83%A2%E3%83%B3&#34;&gt;Gitデーモン&lt;/a&gt;によるGitネイティブプロトコルを使うURL。
HTTPよりも高速な通信ができるが、認証機能も暗号化機能もない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;SSH + Gitプロトコル&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ssh://git@github.com/kaitoy/pcap4j.git&lt;/code&gt;のような&lt;a href=&#34;https://ja.wikipedia.org/wiki/Secure_Shell&#34;&gt;SSH&lt;/a&gt;のURLで、これを使うとSSHトンネルを通してGitプロトコルで通信できる。
Gitプロトコル単体を使うのに比べ、SSHの認証機能と暗号化機能を利用できるが、やや遅くなるはず。&lt;/p&gt;

&lt;p&gt;このプロトコルには、&lt;code&gt;git@github.com:kaitoy/pcap4j.git&lt;/code&gt;のような&lt;a href=&#34;https://ja.wikipedia.org/wiki/Secure_copy&#34;&gt;SCP&lt;/a&gt;書式も使える。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Git自体はGitデーモンを含めリポジトリへのアクセス制御の機能を一切持たないので、認証などが必要な場合はHTTPなどその機能を持つプロトコルのURLを使う必要がある。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;fetch&lt;/p&gt;

&lt;p&gt;リモートリポジトリ内のローカルブランチとローカルリポジトリ内の追跡ブランチとがどう対応するかを定義する。
この定義は&lt;code&gt;refspec&lt;/code&gt;と呼ばれる。&lt;/p&gt;

&lt;p&gt;上の例の&lt;code&gt;fetch = +refs/heads/*:refs/remotes/origin/*&lt;/code&gt;だと、リモートリポジトリの&lt;code&gt;.git/refs/heads/&lt;/code&gt;にある全てのブランチをそれぞれ、ローカルリポジトリの&lt;code&gt;.git/refs/remotes/origin/&lt;/code&gt;にある同名のブランチで追跡する、という意味。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;クローン時の挙動&#34;&gt;クローン時の挙動&lt;/h2&gt;

&lt;p&gt;クローン時のデフォルトの挙動は以下の様なもの。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;オブジェクト格納領域内のオブジェクトが全てクローンにコピーされる。
(多分。参照からたどれないオブジェクトもコピーされることを確認した。)
つまり、元のリポジトリ(i.e. リモートリポジトリ)と同じコミットグラフ(とタグオブジェクト)がクローンのリポジトリに入る。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;リモートリポジトリ内の全てのローカルブランチに対応する同名のリモート追跡ブランチがクローンのリポジトリ内に作成される。
これに対応するリモートも作成され、これの&lt;code&gt;fetch&lt;/code&gt;に(前節の例と同様に)&lt;code&gt;+refs/heads/*:refs/remotes/origin/*&lt;/code&gt;が設定される。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;リモートリポジトリのカレントブランチがローカルリポジトリにコピーされ、チェックアウトされる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;リモートリポジトリの全てのタグがクローンにコピーされる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ローカルリポジトリで&lt;code&gt;git fetch&lt;/code&gt;が実行され、全てのリモート追跡ブランチが更新される。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;インデックスはリポジトリ毎に固有の一時的なデータなので、クローンにはコピーされない。&lt;/p&gt;

&lt;p&gt;リモート追跡ブランチもクローンにコピーされない。&lt;/p&gt;

&lt;p&gt;シンボリック参照もクローンにコピーされない。
クローンにはカレントブランチを指す&lt;code&gt;HEAD&lt;/code&gt;だけが作成される。&lt;/p&gt;

&lt;h2 id=&#34;リモートリポジトリとのやり取りの図解&#34;&gt;リモートリポジトリとのやり取りの図解&lt;/h2&gt;

&lt;p&gt;リモートリポジトリをクローンして、変更をプルしたりプッシュしたりする様子を以下に図示する。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-dvc/git_dvc_merge/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-dvc/git_dvc_merge/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-dvc/git_dvc_merge/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-dvc/git_dvc_merge/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-dvc/git_dvc_merge/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-dvc/git_dvc_merge/スライド6.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;これはこれで完全に正しい手順だが、最終的にできるコミットグラフが無駄に分岐していて美しくない。
普通は以下の様に、リベースを挟んで一直線の履歴に保つ方が一般にいいと思う。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-dvc/git_dvc_ff/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-dvc/git_dvc_ff/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-dvc/git_dvc_ff/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-dvc/git_dvc_ff/スライド4.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;このフェッチ + リベースを一度にやってくれるのが、&lt;code&gt;git pull --rebase&lt;/code&gt;。&lt;/p&gt;

&lt;h2 id=&#34;gitで分散バージョン管理する際の注意点&#34;&gt;Gitで分散バージョン管理する際の注意点&lt;/h2&gt;

&lt;p&gt;Gitで分散バージョン管理する際の注意点を二つ挙げる。&lt;/p&gt;

&lt;h4 id=&#34;他のリポジトリにもあるコミットを変更してはいけない&#34;&gt;他のリポジトリにもあるコミットを変更してはいけない&lt;/h4&gt;

&lt;p&gt;Gitには、&lt;code&gt;git commit --amend&lt;/code&gt;、&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/28/git-merge/#%E3%83%AA%E3%83%99%E3%83%BC%E3%82%B9&#34;&gt;&lt;code&gt;git rebase&lt;/code&gt;&lt;/a&gt;といったコミットを変更するコマンドや、&lt;a href=&#34;https://www.kaitoy.xyz/2016/01/01/git-revert-reset/#git-reset&#34;&gt;&lt;code&gt;git reset&lt;/code&gt;&lt;/a&gt;というコミットの削除につながるコマンドがある。
こういうコマンドで他のリポジトリにもあるコミットを変更してはいけない。&lt;/p&gt;

&lt;p&gt;他のリポジトリにもあるコミットとは、クローン時にコピーしてきたコミット、プルしたコミット、プッシュしたコミットなどのこと。&lt;/p&gt;

&lt;p&gt;もしやると、プッシュもプルも簡単にはできなくなり非常に面倒なことになる。&lt;/p&gt;

&lt;h4 id=&#34;開発リポジトリには-基本的に-プッシュしてはいけない&#34;&gt;開発リポジトリには(基本的に)プッシュしてはいけない&lt;/h4&gt;

&lt;p&gt;リポジトリには、&lt;strong&gt;ベアリポジトリ&lt;/strong&gt; と、&lt;strong&gt;開発リポジトリ&lt;/strong&gt; がある。
開発リポジトリは普段使っている普通のリポジトリ。
ベアリポジトリは、簡単に言うとワーキングディレクトリやカレントブランチやリモートを持たないリポジトリで、開発リポジトリのリモートリポジトリとして使われ、&lt;code&gt;git init&lt;/code&gt;や&lt;code&gt;git clone&lt;/code&gt;に&lt;code&gt;--bare&lt;/code&gt;オプションを付けて実行すると作れる。&lt;/p&gt;

&lt;p&gt;ベアリポジトリにはプッシュしていい。
むしろプッシュしないベアリポジトリに意味はない。&lt;/p&gt;

&lt;p&gt;一方、開発リポジトリには(基本的に)プッシュしてはいけない。
これは、プッシュがリモートリポジトリのオブジェクトと参照だけ更新してワーキングディレクトリやインデックスは更新せず、開発者がプッシュされたことに気付けないため(※1)。
気付かないまま開発を進めてコミットを作ると、プッシュによって&lt;code&gt;HEAD&lt;/code&gt;が変わっていたりするため、コミットグラフが変な状態になってしまう。&lt;/p&gt;

&lt;p&gt;お互い示し合わせたうえでプッシュをしたりプッシュするブランチを工夫したりすれば問題が起きないようにできるはできる。&lt;/p&gt;

&lt;p&gt;(※1: と&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873114408/&#34;&gt;O&amp;rsquo;Reillyの蝙蝠本&lt;/a&gt;には書いてあったが、これは&lt;a href=&#34;https://github.com/git/git/blob/master/Documentation/RelNotes/1.7.0.txt&#34;&gt;Git 1.6.xまでの話らしい&lt;/a&gt;。
今はチェックアウトされたブランチにはデフォルトでプッシュできないので、この節に書いた問題は基本的に起きない。
2.6.3で試したら以下のエラーになった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;remote: error: refusing to update checked out branch: refs/heads/master
remote: error: By default, updating the current branch in a non-bare repository
remote: error: is denied, because it will make the index and work tree inconsistent
remote: error: with what you pushed, and will require &#39;git reset --hard&#39; to match
remote: error: the work tree to HEAD.
remote: error:
remote: error: You can set &#39;receive.denyCurrentBranch&#39; configuration variable t
remote: error: &#39;ignore&#39; or &#39;warn&#39; in the remote repository to allow pushing int
remote: error: its current branch; however, this is not recommended unless you
remote: error: arranged to update its work tree to match what you pushed in som
remote: error: other way.
remote: error:
remote: error: To squelch this message and still keep the default behaviour, se
remote: error: &#39;receive.denyCurrentBranch&#39; configuration variable to &#39;refuse&#39;.
To file://C:/Users/Kaito/Desktop/master
 ! [remote rejected] master -&amp;gt; master (branch is currently checked out)
error: failed to push some refs to &#39;file://C:/Users/Kaito/Desktop/master&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;)&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Gitのマージを図解する</title>
          <link>https://www.kaitoy.xyz/2015/12/28/git-merge/</link>
          <pubDate>Mon, 28 Dec 2015 01:05:29 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/12/28/git-merge/</guid>
          <description>

&lt;p&gt;このエントリでは、&lt;a href=&#34;https://git-scm.com/&#34;&gt;&lt;strong&gt;Git&lt;/strong&gt;&lt;/a&gt;が提供するマージのための機能の内、主なもの4つ、&lt;strong&gt;真のマージ&lt;/strong&gt;、&lt;strong&gt;リベース&lt;/strong&gt;、&lt;strong&gt;ファストフォワードマージ&lt;/strong&gt;、&lt;strong&gt;チェリーピック&lt;/strong&gt; について図解する。
ここでマージとは、とあるブランチのコミットが入れた修正を別のブランチに取り込むこととする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;この記事&lt;/a&gt;を事前に読んでGitのオブジェクトモデルを理解しておくと分かりやすいかもしれない。&lt;/p&gt;

&lt;p&gt;ここで説明するマージは全てローカルリポジトリ内のブランチを操作対象とする。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;真のマージ&#34;&gt;真のマージ&lt;/h2&gt;

&lt;p&gt;真のマージは、複数のブランチでそれぞれ開発が進んでいて、つまりそれぞれのコミットグラフが伸びている場合に、それらの修正を統合するときに実行する。
マージするブランチはいくつでも指定できる。&lt;/p&gt;

&lt;p&gt;基本的なコマンドは&lt;code&gt;git merge &amp;lt;ブランチ(複数可)&amp;gt;&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;操作に成功すると、マージ後のプロジェクトの状態を表すコミット(マージコミット)が作られ、カレントブランチの先頭に追加される。
マージコミットは、マージした全てのブランチが指していたコミットを親として持つ。&lt;/p&gt;

&lt;p&gt;このマージはマージコミットを追加するだけであり、既存のコミットを一切変更しないことを認識しておくべし。&lt;/p&gt;

&lt;p&gt;以下、真のマージの実行例を図示する。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-merge/git_merge/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-merge/git_merge/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-merge/git_merge/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-merge/git_merge/スライド4.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;リベース&#34;&gt;リベース&lt;/h2&gt;

&lt;p&gt;リベースは、あるブランチで作った一連のコミットの起点(ベース)を移動したいときに実行する。
この操作は一般的にはマージとは呼ばれないが、冒頭に書いたマージの定義からするとマージと見なせないこともないのでここに挙げる。&lt;/p&gt;

&lt;p&gt;基本的なコマンドは&lt;code&gt;git rebase &amp;lt;ブランチ&amp;gt;&lt;/code&gt;。
このコマンドは、カレントブランチの起点を指定したブランチが指すコミットに移動する。&lt;/p&gt;

&lt;p&gt;この操作に成功すると、カレントブランチで作ったコミットは(実質)消え、それと同等の修正をもたらす別のコミットが移動先のコミットを起点として作成される。(※1)&lt;/p&gt;

&lt;p&gt;リベースは既存のコミットを消し、コミットグラフを変更してしまうということを認識しておくべし。&lt;/p&gt;

&lt;p&gt;以下、リベースの簡単な実行例を図示する。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-merge/git_rebase/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-merge/git_rebase/スライド2.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;上のスライドのように単純なコミットグラフならいいが、リベースするブランチが分岐していたりするとややこしいことが起き得る。
そういうケースには&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873114408/&#34;&gt;O&amp;rsquo;Reillyの蝙蝠本&lt;/a&gt;などでよく勉強してから臨むべし。&lt;/p&gt;

&lt;p&gt;(※1: より正確には&lt;code&gt;git rebase &amp;lt;ブランチ&amp;gt;&lt;/code&gt;は、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;カレントブランチで作った各コミットが入れた変更をパッチにして、&lt;/li&gt;
&lt;li&gt;それを古い順に一つずつ、指定したブランチが指すコミットに適用しながら新しいコミットを作り、&lt;/li&gt;
&lt;li&gt;カレントブランチが指しているコミットを&lt;code&gt;ORIG_HEAD&lt;/code&gt;で指し、&lt;/li&gt;
&lt;li&gt;カレントブランチを最新のコミットを指すよう更新する。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;2で、指定したブランチが既にチェリーピック(後述)などでカレントブランチのとあるコミットの変更を取り込んでいた場合、そのコミットのパッチの適用はスキップされ、そのパッチによるコミットも作られない。&lt;/p&gt;

&lt;p&gt;また、上でカレントブランチのコミットは実質消えると書いたが、当面はオブジェクトが本当に消えるわけではないし、&lt;code&gt;ORIG_HEAD&lt;/code&gt;とかが指しているのでもどることもできる。)&lt;/p&gt;

&lt;h2 id=&#34;ファストフォワードマージ&#34;&gt;ファストフォワードマージ&lt;/h2&gt;

&lt;p&gt;ファストフォワードマージは、マージ先のコミットが全てマージ元に含まれているときに使えるマージ。
この操作は既存のコミットグラフをいじらないしマージコミットも作らない特殊なマージ。
(実のところマージじゃないと言ってもいい。)
このマージを実行した後は、コミットグラフは一直線になり、ブランチを作らずにコミットを作った場合と同様になる。&lt;/p&gt;

&lt;p&gt;このマージは、&lt;code&gt;git merge &amp;lt;ブランチ&amp;gt;&lt;/code&gt;を実行したときに可能であれば実行される。
(でなければ真のマージが実行される。オプションで選択することもできる。)&lt;/p&gt;

&lt;p&gt;以下にファストフォワードマージの例を図示する。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-merge/git_ff/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-merge/git_ff/スライド2.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ファストフォワードマージはよくリベースとともに実行される。
リベースのスライドの最後のページの図は、ここのスライドの最初のページの図と同じになっている。&lt;/p&gt;

&lt;p&gt;リベース + ファストフォワードは、トピックブランチで入れた修正を、そのブランチを作ったという履歴を残さずに別のブランチに取り入れたいときなどに使う手法。
マージコミットを作る手法よりもコミットグラフをシンプルに保てる。&lt;/p&gt;

&lt;h2 id=&#34;チェリーピック&#34;&gt;チェリーピック&lt;/h2&gt;

&lt;p&gt;チェリーピックは、あるブランチの任意のコミットによる修正を別のブランチに取り込みたいときに実行する。
他の3つのマージに比べて分かりやすい操作であり、また操作対象にするブランチやコミットの自由度が高いので使いやすい。
その反面、コミットログなどに明記しないとどこのコミットをマージしたのかが分からなくなる。&lt;/p&gt;

&lt;p&gt;基本的なコマンドは&lt;code&gt;git cherry-pick &amp;lt;コミット&amp;gt;&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;操作に成功すると、指定したコミットと同等の修正をもたらす新しいコミットが作成され、&lt;code&gt;HEAD&lt;/code&gt;に追加される。&lt;/p&gt;

&lt;p&gt;この操作はコミットを追加するだけであり、既存のコミットは変更しない。&lt;/p&gt;

&lt;p&gt;以下にチェリーピックの例を図示する。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-merge/git_cherry-pick/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-merge/git_cherry-pick/スライド2.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Gitのリポジトリの中身をなるべく正確に理解する</title>
          <link>https://www.kaitoy.xyz/2015/12/27/git-repository/</link>
          <pubDate>Sun, 27 Dec 2015 11:34:18 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/12/27/git-repository/</guid>
          <description>

&lt;p&gt;このエントリでは、&lt;a href=&#34;https://git-scm.com/&#34;&gt;&lt;strong&gt;Git&lt;/strong&gt;&lt;/a&gt;の基本的な使い方は理解している前提で、そのリポジトリの構造をなるべく正確に説明する。
ここに書いてあることは概ね、筆者が&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873114408/&#34;&gt;O&amp;rsquo;Reillyの蝙蝠本&lt;/a&gt;を読んで得た知識に基づく。&lt;/p&gt;

&lt;p&gt;リポジトリの構造というとコアで上級者向けの知識のように聞こえるが、これをまず理解しておくことで強力で複雑なGitの機能を習得するのが非常に楽になる。
具体的には、Gitにおけるブランチの概念などの理解が深まったり、&lt;a href=&#34;https://www.kaitoy.xyz/2016/01/01/git-revert-reset/#git-reset&#34;&gt;&lt;code&gt;git reset&lt;/code&gt;&lt;/a&gt;などのGit特有で分かり辛いコマンドを自信をもって使えるようになったり、なにより、Gitを使う上での最大のハードルである &lt;strong&gt;インデックス&lt;/strong&gt; や &lt;strong&gt;HEAD&lt;/strong&gt; の概念を完璧に理解できるというメリットがある。&lt;/p&gt;

&lt;p&gt;チュートリアルを終えたくらいの初心者にこそ読んでほしいエントリである。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;gitリポジトリの中身&#34;&gt;Gitリポジトリの中身&lt;/h1&gt;

&lt;p&gt;Gitのリポジトリは、プロジェクトをクローンしたときとかにできる&lt;code&gt;.git&lt;/code&gt;ディレクトリ内に詰まっている。
このディレクトリには、&lt;strong&gt;オブジェクト格納領域&lt;/strong&gt; と &lt;strong&gt;インデックス&lt;/strong&gt; というデータ構造が入っている。
また、&lt;strong&gt;参照 (ref)&lt;/strong&gt; や &lt;strong&gt;シンボリック参照 (symref)&lt;/strong&gt; というものも入っている。&lt;/p&gt;

&lt;p&gt;以下、それぞれについて説明する。&lt;/p&gt;

&lt;h3 id=&#34;オブジェクト格納領域&#34;&gt;オブジェクト格納領域&lt;/h3&gt;

&lt;p&gt;オブジェクト格納領域は、ファイルシステム上では&lt;code&gt;.git/objects/&lt;/code&gt;以下にあたる。&lt;/p&gt;

&lt;p&gt;ここには、バージョン管理されているファイルの情報やそのコミット履歴などが保存されていて、具体的には以下の4種類のオブジェクトが置かれている。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;ブロブ&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一つのファイルを表すオブジェクト。
バージョン管理対象のファイルの内容(だけ)を保持する。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;ツリー&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一つのディレクトリを表すオブジェクト。ブロブや別のツリーを指すポインタを持ち、またそれらが表すファイル/ディレクトリの名前や属性を保持する。
つまり、これとブロブを組み合わせると、ファイルシステム上のディレクトリツリーを表すことができる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;コミット&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一つのコミットを表すオブジェクト。コミット日時やログメッセージなどの情報と、一つ前のコミット(親コミット)を指すポインタと、一つのツリーを指すポインタを持つ。
このツリーはプロジェクトのルートディレクトリを表す。
つまり、一つのコミットは、プロジェクトのある時点でのディレクトリツリー全体を表してもいる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;タグ&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一つの注釈付きタグ(&lt;code&gt;git tag -a&lt;/code&gt;で作るタグ)を表すオブジェクト。
タグ名やタグにつけたコメントなどの情報と、一つのオブジェクト(普通はコミット)へのポインタを持つ。
因みに軽量タグ(&lt;code&gt;git tag&lt;/code&gt;で作るタグ)はオブジェクトにならない。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;ファイルシステム上で、一つのオブジェクトは一つのファイルに書き込まれ、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Zlib&#34;&gt;zlib&lt;/a&gt;で圧縮され、&lt;code&gt;.git/objects/&lt;/code&gt;以下に配置される。
そのファイルへのパスには、オブジェクトのコンテンツから計算されたSHA1ハッシュの値(i.e. オブジェクトの名前)が使われる。
例えば&lt;code&gt;.git/objects/16/cacde1ddabe1698b0e41e091e4697313e2b7e5&lt;/code&gt;というファイルがあったら、これは &lt;strong&gt;16cacde1ddabe1698b0e41e091e4697313e2b7e5&lt;/strong&gt; という名のオブジェクトの実体。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git cat-file -p &amp;lt;SHA1ハッシュ&amp;gt;&lt;/code&gt;でオブジェクトのコンテンツを見れるので、いくつか見てみると面白い。
たとえばコミットオブジェクトは以下の様になっている。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ git cat-file -p d444447526f91a97f2edeefc65d4f58e8e006d78
tree 5d43dfbb8dd89018b9a383d6b9f663166e3cf9f9
parent adcf8b197c6c156860dc8aa66ccb9a0c0a3bebb6
author kaitoy &amp;lt;kaitoy@pcap4j.org&amp;gt; 1480004891 -0700
committer kaitoy &amp;lt;kaitoy@pcap4j.org&amp;gt; 1480004891 -0700

[#76] Rmove unneeded makePacketForInvokingPacketField call from IcmpV4InvokingPacketPacket.
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;インデックス&#34;&gt;インデックス&lt;/h3&gt;

&lt;p&gt;インデックスは、&lt;code&gt;git add&lt;/code&gt;の説明とかに出てくる「インデックス」とか「ステージング」とか呼ばれる機能を実現するためのデータ構造で、ファイルシステム上では&lt;code&gt;.git/index&lt;/code&gt;というバイナリファイルにあたる。&lt;/p&gt;

&lt;p&gt;インデックスは、プロジェクトのある時点でのディレクトリツリー全体を表すデータをもつ。
具体的には、プロジェクトの各ファイルについて、対応するブロブへのポインタと、プロジェクトルートディレクトリからの相対パスが記録されている。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git ls-files --stage&lt;/code&gt;で&lt;code&gt;.git/index&lt;/code&gt;の内容を見れる。&lt;/p&gt;

&lt;p&gt;例として、&lt;code&gt;https://github.com/kaitoy/japanese-word-selection&lt;/code&gt;をクローンして上記コマンドを実行すると以下の様に表示される。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ git ls-files --stage
100644 ade14b9196fcad03cd0177c25ec1c31000ecf86a 0       .gitignore
100644 bbbbcd3415597bac39b0314f5c708d90684161fc 0       CHANGES.md
100644 f6b0b485fec1ee0bc53a452bc82cb6b7de2a1d91 0       LICENSE
100644 10e50f7b628d83f1b66f34f2d9d34029e7fc8670 0       README.md
100644 4dc8027d17765180fac5c3292a0195bb09b10ceb 0       assets/japanese-word-selection.gif
100644 dd92c48bae50307b55fb623c1b2beccab963096e 0       lib/japanese-word-selection.coffee
100644 8152af5ad39515fcd5021e3c8afee32910c0cf79 0       package.json
100644 9c0d180898d841bb319f51f1b1c7e07320426eeb 0       spec/japanese-word-selection-spec.coffee
100644 3d32fc0f42cc9babccd5525165e8227dce00a206 0       spec/japanese-word-selection-whitespace-spec.coffee
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一行がひとつのファイルの情報で、左からファイルモード(パーミッション)、ブロブのSHA1ハッシュ、ステージ、ファイルパスが表示されている。
ステージは0～3の値になり得る。&lt;/p&gt;

&lt;p&gt;ステージは普段は0だけだけど、マージコンフリクトが起きた場合は、ベースバージョン、一方のブランチのバージョン、他方のブランチのバージョンの3つをそれぞれステージ1、2、3としてインデックスに保持する。
これは、マージコンフリクトの解消(i.e. 3-wayマージ)を&lt;a href=&#34;https://git-scm.com/docs/git-merge#_how_to_resolve_conflicts&#34;&gt;サポートする機能&lt;/a&gt;のためだ。&lt;/p&gt;

&lt;h3 id=&#34;オブジェクト格納領域とインデックスの図解&#34;&gt;オブジェクト格納領域とインデックスの図解&lt;/h3&gt;

&lt;p&gt;ワーキングディレクトリに変更を入れ、&lt;code&gt;git add&lt;/code&gt;、&lt;code&gt;git commit&lt;/code&gt;をする中で、オブジェクト格納領域とインデックスがどう変化するかを図にした。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_repo/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_repo/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_repo/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_repo/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_repo/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_repo/スライド6.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_repo/スライド7.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(タグオブジェクトについては次の節で。)&lt;/p&gt;

&lt;p&gt;スライドの1ページ目や最後のページのようにワーキングディレクトリとインデックスとオブジェクト格納領域が同期していて、&lt;code&gt;git status&lt;/code&gt;を実行すると&lt;code&gt;nothing to commit, working directory clean&lt;/code&gt;と表示される状態をワーキングディレクトリがクリーンであると言い、そうでない状態をワーキングディレクトリがダーティであると言う。&lt;/p&gt;

&lt;p&gt;このスライドにより、Gitがファイルの履歴をどう記録しているかがよく分かるはず。
特に、ブロブが常にファイルのある時点の内容全体を保持していて、Gitが(&lt;a href=&#34;https://subversion.apache.org/&#34;&gt;Subversion&lt;/a&gt;のように)差分を保存しているわけではないことは覚えておくべし。&lt;/p&gt;

&lt;p&gt;スライドの最後のページのオブジェクト格納領域の図で、ツリーとブロブとそれらを指す矢印を省略すると、Gitのブランチ等の説明でよく見かける丸が矢印で連なった図(コミットグラフ)になる。以降の説明でそのような図を使うが、丸がコミットを意味していて、各コミットがルートツリーを指していることはよく認識しておくべし。&lt;/p&gt;

&lt;h3 id=&#34;参照-ref&#34;&gt;参照 (ref)&lt;/h3&gt;

&lt;p&gt;参照は、一つのオブジェクトを指し示すポインタのようなもので、普通はコミットオブジェクトを指す。
参照には、&lt;strong&gt;ローカルブランチ&lt;/strong&gt;、&lt;strong&gt;リモート追跡ブランチ&lt;/strong&gt;、&lt;strong&gt;タグ&lt;/strong&gt; の三種類がある。&lt;/p&gt;

&lt;p&gt;ファイルシステム上では&lt;code&gt;.git/refs/&lt;/code&gt;以下にある、指し示すオブジェクトのSHA1ハッシュ値が書かれただけのテキストファイルにあたる。
&lt;code&gt;.git/refs/heads/&lt;/code&gt;以下にローカルブランチ、&lt;code&gt;.git/refs/remotes/&lt;/code&gt;以下にリモート追跡ブランチ、&lt;code&gt;.git/refs/tags/&lt;/code&gt;以下にタグが置かれる。&lt;/p&gt;

&lt;p&gt;参照は、Gitコマンドなどにおいてコミットを指定する方法としてSHA1ハッシュ値の代わりに使える。
この時、参照の名前は上記ファイルシステム上のパスから&lt;code&gt;.git/&lt;/code&gt;を省いたものになる。
例えば&lt;code&gt;refs/heads/master&lt;/code&gt;。さらに、ディレクトリは省略できるので、同じ参照は&lt;code&gt;heads/master&lt;/code&gt;や単に&lt;code&gt;master&lt;/code&gt;とも書ける。&lt;/p&gt;

&lt;p&gt;ここで、ブランチやタグが単なる参照であるところに注目。
Subversionのようにリポジトリのコピーを作るのとはかなり異なる。
Gitのブランチを作るというのは単に参照を追加するだけだし、ブランチをチェックアウトするというのはブランチが指すコミットが指すツリーが表すディレクトリツリーをファイルシステムに展開するということ。
この実装によってGitのブランチが軽量で速いものになっている。&lt;/p&gt;

&lt;p&gt;ローカルブランチの挙動を以下に図示する。図中で、各コミットには便宜上ラベルとしてアルファベットを付けている。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_branch/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_branch/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_branch/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_branch/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_branch/スライド5.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;このスライドの最後のページでmasterブランチが本流でbugfixブランチが支流かのように書いているが、実際は実装上それらに差はなく全く対等である。&lt;/p&gt;

&lt;p&gt;また、ブランチは単なる一方的な参照であり、コミットオブジェクトからはそれに全く関与しないことに注意。
ブランチを削除してもそれによってコミットが消えることはない(※1)し、また例えば、スライドの最後のページでbugfixブランチを削除したらXがどのブランチで作られたコミットなのかを知るすべはなくなる。&lt;/p&gt;

&lt;p&gt;(※1: ブランチを削除することにより到達不能になるコミットは、結果的に&lt;a href=&#34;https://git-scm.com/book/ja/v2/Git%E3%81%AE%E5%86%85%E5%81%B4-%E3%83%A1%E3%82%A4%E3%83%B3%E3%83%86%E3%83%8A%E3%83%B3%E3%82%B9%E3%81%A8%E3%83%87%E3%83%BC%E3%82%BF%E3%83%AA%E3%82%AB%E3%83%90%E3%83%AA&#34;&gt;&lt;code&gt;git gc&lt;/code&gt;&lt;/a&gt;により削除されはする。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次に、タグの挙動を以下に図示する。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_tag/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_tag/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_tag/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_tag/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_tag/スライド5.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;図中で、タグオブジェクトはオブジェクトなのでオブジェクト格納領域に入り、それを指す参照のタグは&lt;code&gt;.git/refs/&lt;/code&gt;に入る。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;リモート追跡ブランチについては&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/31/git-dvc/&#34;&gt;別のエントリ&lt;/a&gt;で書く。&lt;/p&gt;

&lt;h3 id=&#34;シンボリック参照-symref&#34;&gt;シンボリック参照 (symref)&lt;/h3&gt;

&lt;p&gt;シンボリック参照は参照やオブジェクトを指し示すポインタのようなもので、以下の四つがある。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;HEAD&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;カレントブランチ、つまりチェックアウトしているブランチ(i.e. 参照)を指す。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;ORIG_HEAD&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git merge&lt;/code&gt;や&lt;a href=&#34;https://www.kaitoy.xyz/2016/01/01/git-revert-reset/#git-reset&#34;&gt;&lt;code&gt;git reset&lt;/code&gt;&lt;/a&gt;でHEADが更新されたとき、更新前のHEADが指していたブランチが指していたコミットを指す。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;FETCH_HEAD&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;最後にフェッチされたブランチの最新コミットを指す。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;MERGE_HEAD&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;マージ操作中に作られ、HEADにマージされようとしているコミットを指す。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;それぞれが、Gitコマンドなどにおいてコミットを指定する方法としてSHA1ハッシュ値の代わりに使える。&lt;/p&gt;

&lt;p&gt;ファイルシステム上では&lt;code&gt;.git/{HEAD,ORIG_HEAD,FETCH_HEAD,MERGE_HEAD}&lt;/code&gt;にあたり、全て単純なテキストファイルである。&lt;/p&gt;

&lt;p&gt;特によく使う&lt;code&gt;HEAD&lt;/code&gt;を図示すると以下のようになる。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_head/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_head/スライド2.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上図に見られるように、&lt;code&gt;HEAD&lt;/code&gt;は通常ブランチを指す。
実際に&lt;code&gt;.git/HEAD&lt;/code&gt;ファイルの中身を見ると以下の様になっていて、確かにブランチを指していることが見て取れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;ref: refs/heads/master
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;gitコマンドの実行内容によっては&lt;code&gt;HEAD&lt;/code&gt;が直接コミットを指すようになることもあり、この場合は特に「detached HEAD」、つまり(ブランチから)切り離されたHEADと呼ばれる。&lt;/p&gt;

&lt;p&gt;スライドの1ページ目の状態では、だいたいのgitコマンドから見てコミットEと&lt;code&gt;master&lt;/code&gt;と&lt;code&gt;HEAD&lt;/code&gt;は等価であると考えていい。
つまり例えば、&lt;code&gt;git reset &amp;lt;コミットEのSHA1ハッシュ値&amp;gt;&lt;/code&gt;、&lt;code&gt;git reset master&lt;/code&gt;、&lt;code&gt;git reset HEAD&lt;/code&gt;は同じ結果になる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上がGitリポジトリの中身のほぼ全容。あとは設定ファイルとかフックスクリプトとかがあるだけ。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;実際のGitリポジトリのオブジェクト、参照、シンボリック参照を、この記事のスライドと同じ見た目でビジュアライズするツール、&lt;a href=&#34;https://www.kaitoy.xyz/tags/goslings/&#34;&gt;&lt;strong&gt;Goslings&lt;/strong&gt;&lt;/a&gt;を作った。
このツールを使って実際のリポジトリの中身を見ながらこの記事を内容を確認すると、より理解が深まるかもしれない。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ReactをAtomパッケージ開発に使ってみた</title>
          <link>https://www.kaitoy.xyz/2015/12/21/hello-react/</link>
          <pubDate>Mon, 21 Dec 2015 00:07:28 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/12/21/hello-react/</guid>
          <description>

&lt;p&gt;私は今&lt;a href=&#34;https://www.hpe.com/us/en/home.html&#34;&gt;HPE&lt;/a&gt;の&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%95%E3%82%A9%E3%83%BC%E3%83%88%E3%83%BB%E3%82%B3%E3%83%AA%E3%83%B3%E3%82%BA_%28%E3%82%B3%E3%83%AD%E3%83%A9%E3%83%89%E5%B7%9E%29&#34;&gt;Fort Collins&lt;/a&gt;オフィスに居候している。
HPEは最近、&lt;a href=&#34;https://facebook.github.io/react/&#34;&gt;React&lt;/a&gt;を使ったUXフレームワークである&lt;a href=&#34;http://www.grommet.io/docs/&#34;&gt;Grommet&lt;/a&gt;を開発していて、私が扱っている製品もそれを使う兆しが見えてきた。
Grommetはいずれ仕事で触ることになりそうなので、まずはReactの勉強をと思い、&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/19/atom-impress/&#34;&gt;とあるAtomパッケージ&lt;/a&gt;の開発に敢えて使ってみた。&lt;/p&gt;

&lt;p&gt;このエントリには、その作業の中で得た知識などについて書いた。
ただし、Reactを使った開発のノウハウみたいなものまでは得ていないので書いていない。&lt;/p&gt;

&lt;p&gt;(因みにGrommetは&lt;a href=&#34;https://github.com/grommet/grommet&#34;&gt;GitHub&lt;/a&gt;で公開されているが、ほとんど話題になっておらずスターも現時点で245しかついていない。。。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;reactとは&#34;&gt;Reactとは&lt;/h2&gt;

&lt;p&gt;ReactはFacebookが開発しているWeb UIのフレームワークで、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Model_View_Controller&#34;&gt;MVC&lt;/a&gt;のVだけを実装したもの。
2013年に最初のバージョンが公開され、世界中で流行ってきているらしい。&lt;/p&gt;

&lt;p&gt;その特徴(というかほぼ全容)は仮想DOM(&lt;a href=&#34;https://facebook.github.io/react/docs/glossary.html&#34;&gt;Virtual DOM&lt;/a&gt;)。
ReactのAPIを使うと、リアルDOMと一対一で対応する仮想DOMのツリーを作ることができ、UIを組み立てられる。
リアルDOMの構築や更新はReactが最適化された方法でやってくれるので、性能がいいUIができるらしい。
因みに、仮想DOM自体はReact特有の技術ではなく、別の実装もある。&lt;/p&gt;

&lt;p&gt;もう一つの特徴は&lt;a href=&#34;https://facebook.github.io/jsx/&#34;&gt;JSX&lt;/a&gt;。
これは、JavaScriptのコードの中で、XMLみたいな構文で仮想DOMを記述するための拡張構文。
これを使うとReactコードが見やすく簡単に書けるけど、当然普通のJavaScript実行環境では動かないので、プリコンパイルなどが必要になる。&lt;/p&gt;

&lt;p&gt;FacebookはReactを使った開発に&lt;a href=&#34;http://facebook.github.io/flux/docs/overview.html#content&#34;&gt;Flux&lt;/a&gt;というアーキテクチャの採用を推奨している。
FluxはMVCアーキテクチャに置き換わるもので、従来の複雑なデータフローに反発し、一方向のシンプルなデータフローを提供する。
Fluxは単なるアーキテクチャで、その全体の実装を支援するフレームワークは現時点では無い。
(多分。&lt;a href=&#34;https://facebook.github.io/relay/&#34;&gt;Relay&lt;/a&gt;が一部支援してくれるっぽい。)&lt;/p&gt;

&lt;h2 id=&#34;reactを触った感想&#34;&gt;Reactを触った感想&lt;/h2&gt;

&lt;p&gt;Reactは本当にちょっとしか触っていないので、あまりよく分かっていないんだろうけど、なんだか使いにくかった。&lt;/p&gt;

&lt;p&gt;Reactは仮想DOMを作るところしか助けてくれないので、他のことは全部自分でやらないといけない。
FacebookはReact用のウィジェットすら提供していない。
昔仕事で全部入りの&lt;a href=&#34;https://ja.wikipedia.org/wiki/Dojo_Toolkit&#34;&gt;Dojo&lt;/a&gt;を使っていたので、それとのギャップをすごい感じた。&lt;/p&gt;

&lt;p&gt;そのうえ、他のフレームワークやライブラリと組み合わせて使おうとすると仮想DOMが壁になってくる。普通のフレームワークはリアルDOMを扱うからだ。
例えば、JavaScriptを書いているとすぐ&lt;a href=&#34;https://jquery.com/&#34;&gt;jQuery&lt;/a&gt;を使いたくなるが、これでリアルDOMを直接いじってしまってはReactを使う意味がない気がする。&lt;/p&gt;

&lt;h2 id=&#34;atomパッケージでreactを使う&#34;&gt;AtomパッケージでReactを使う&lt;/h2&gt;

&lt;p&gt;Reactは&lt;a href=&#34;https://www.npmjs.com/&#34;&gt;npm&lt;/a&gt;でも提供されていて、Atomパッケージの開発に簡単に使える。
パッケージの&lt;code&gt;package.json&lt;/code&gt;の&lt;code&gt;dependencies&lt;/code&gt;に&lt;a href=&#34;https://www.npmjs.com/package/react&#34;&gt;react&lt;/a&gt;と&lt;a href=&#34;https://www.npmjs.com/package/react-dom&#34;&gt;react-dom&lt;/a&gt;を入れておけば、パッケージコード中で以下の様に仮想DOMを作れるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var React = require(&#39;react&#39;);
var ReactDOM = require(&#39;react-dom&#39;);

class MyComponent extends React.Component {
  render() {
    return &amp;lt;div&amp;gt;Hello World&amp;lt;/div&amp;gt;;
  }
}

ReactDOM.render(&amp;lt;MyComponent /&amp;gt;, node);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;babelによるjsxの手動コンパイル&#34;&gt;BabelによるJSXの手動コンパイル&lt;/h2&gt;

&lt;p&gt;JSXのコンパイルには&lt;a href=&#34;https://babeljs.io/&#34;&gt;Babel&lt;/a&gt;を使うのがいい。
手動コンパイルにはBabelのコマンドラインツールが必要で、これはnpmで提供されている。
npmコマンドはAtomに同梱されているので別途インストールは不要。&lt;/p&gt;

&lt;p&gt;以下が手順の詳細。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Babelのコマンドラインツールのインストール&lt;/p&gt;

&lt;p&gt;任意の場所で、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm install -g babel-cli
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;を実行すると、Babelのコマンドラインツールがグローバルにインストールされ、任意の場所で&lt;code&gt;babel&lt;/code&gt;コマンドが使えるようになる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Babelの定義ファイル作成&lt;/p&gt;

&lt;p&gt;適当なフォルダ(プロジェクトのルートなど)に&lt;code&gt;.babelrc&lt;/code&gt;というBabelの定義ファイルを作り、以下を書いておく。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;presets&amp;quot;: [&amp;quot;react&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Reactプラグインのインストール&lt;/p&gt;

&lt;p&gt;&lt;code&gt;.babelrc&lt;/code&gt;に書いた&lt;code&gt;presets&lt;/code&gt;の値は、コンパイルにReactプラグインを使うという意味。
なので、以下のコマンドでReactプラグインを(ローカルに)インストールする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd &amp;lt;.babelrcを置いたフォルダ&amp;gt;
npm install babel-preset-react
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;コンパイル&lt;/p&gt;

&lt;p&gt;&lt;code&gt;babel&lt;/code&gt;コマンドでコンパイルを実行する。例えば以下を実行すると、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd &amp;lt;.babelrcを置いたフォルダ&amp;gt;
babel src -d lib
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;src/*.jsx&lt;/code&gt;がコンパイルされて、&lt;code&gt;lib/*.js&lt;/code&gt;に出力される。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;language-babelパッケージによるjsxの自動コンパイル&#34;&gt;language-babelパッケージによるJSXの自動コンパイル&lt;/h2&gt;

&lt;p&gt;上記Babelによるコンパイルは、Atomなら&lt;a href=&#34;https://atom.io/packages/language-babel&#34;&gt;language-babelパッケージ&lt;/a&gt;で自動化できる。&lt;/p&gt;

&lt;p&gt;以下、Atomパッケージの開発でlanguage-babelを利用する手順を書く。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;language-babelのインストール&lt;/p&gt;

&lt;p&gt;language-babelをAtomのSettingsなどからインストールして、language-babelのSettingsで、&lt;code&gt;Allow Local Override&lt;/code&gt;にチェックを付ける。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Babelの定義ファイル作成&lt;/p&gt;

&lt;p&gt;手動のと同じ内容の&lt;code&gt;.babelrc&lt;/code&gt;をパッケージプロジェクトのルートに置く。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;package.json編集&lt;/p&gt;

&lt;p&gt;パッケージプロジェクトの&lt;code&gt;package.json&lt;/code&gt;の&lt;code&gt;dependencies&lt;/code&gt;の下あたりに以下の定義を追加して、BabelとReactプラグインへの依存を張る。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;  &amp;quot;devDependencies&amp;quot;: {
    &amp;quot;babel-core&amp;quot;: &amp;quot;^6.1.2&amp;quot;,
    &amp;quot;babel-preset-react&amp;quot;: &amp;quot;^6.1.2&amp;quot;
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上記定義を追加したら、&lt;code&gt;apm install&lt;/code&gt;を実行して追加した依存をダウンロードする。&lt;/p&gt;

&lt;p&gt;因みに、&lt;code&gt;devDependencies&lt;/code&gt;は&lt;code&gt;dependencies&lt;/code&gt;と似てるけど、開発時だけに必要なモジュールを定義するプロパティ。
&lt;code&gt;devDependencies&lt;/code&gt;に書いたものは&lt;code&gt;apm install&lt;/code&gt;したときはダウンロードされるけど、パブリッシュされたものをインストールするときにはダウンロードされない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;language-babelの設定ファイル作成&lt;/p&gt;

&lt;p&gt;language-babelの設定は&lt;code&gt;.languagebabel&lt;/code&gt;というファイルにかく。
これに以下の様な内容を書いてパッケージプロジェクトのルートに置く。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;babelMapsPath&amp;quot;:                   &amp;quot;lib&amp;quot;,
  &amp;quot;babelMapsAddUrl&amp;quot;:                 false,
  &amp;quot;babelSourcePath&amp;quot;:                 &amp;quot;src&amp;quot;,
  &amp;quot;babelTranspilePath&amp;quot;:              &amp;quot;lib&amp;quot;,
  &amp;quot;createMap&amp;quot;:                       false,
  &amp;quot;createTargetDirectories&amp;quot;:         true,
  &amp;quot;createTranspiledCode&amp;quot;:            true,
  &amp;quot;disableWhenNoBabelrcFileInPath&amp;quot;:  false,
  &amp;quot;suppressSourcePathMessages&amp;quot;:      true,
  &amp;quot;suppressTranspileOnSaveMessages&amp;quot;: false,
  &amp;quot;transpileOnSave&amp;quot;:                 true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで、&lt;code&gt;&amp;lt;パッケージプロジェクトのルート&amp;gt;/src/*.jsx&lt;/code&gt;が、Atomで編集して保存したときにコンパイルされ、&lt;code&gt;&amp;lt;パッケージプロジェクトのルート&amp;gt;/lib/*.js&lt;/code&gt;に出力されるようになった。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;babelでjsxをコンパイルする場合の制限&#34;&gt;BabelでJSXをコンパイルする場合の制限&lt;/h2&gt;

&lt;p&gt;手動にしろ自動にしろ、JSXのコンパイルにBabelを使う場合、BabelがCoffeeScriptに対応していないので、CoffeeScript + JSXでは書けない。
JavaScript + JSXで書かないといけない。&lt;/p&gt;

&lt;h2 id=&#34;minified-exception&#34;&gt;Minified exception&lt;/h2&gt;

&lt;p&gt;React周りでバグを作りこんでエラーが発生した場合、コンソールに以下のようなエラーメッセージが出ることがある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Uncaught Error: Minified exception occured; use the non-minified dev environment for the full error message and additional helpful warnings.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これではエラーの詳細はわからない。詳細を見たい場合は、AtomをDev Modeで開いておく必要がある。
(e.g. Atomのメニューバーの[View]&amp;gt;[Developer]&amp;gt;[Open In Dev Mode]から開く。)&lt;/p&gt;
</description>
        </item>
      
    

  </channel>
</rss>
