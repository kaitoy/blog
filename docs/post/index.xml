<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>To Be Decided </title>
    <link>https://www.kaitoy.xyz/post/</link>
    <language>en-us</language>
    <author>Kaito Yamada</author>
    <rights>(C) 2018</rights>
    <updated>2018-11-07 23:41:30 &#43;0900 JST</updated>

    
      
        <item>
          <title>React &#43; Reduxアプリケーションプロジェクトのテンプレートを作る ― その10: Code Splitting、Flow、Jest、Enzyme</title>
          <link>https://www.kaitoy.xyz/2018/11/07/creating-react-redux-app-from-scratch-10/</link>
          <pubDate>Wed, 07 Nov 2018 23:41:30 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/11/07/creating-react-redux-app-from-scratch-10/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt;と&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;を学ぶために、開発環境というかプロジェクトテンプレートをスクラッチから作っている。
(最終的な成果は&lt;a href=&#34;https://github.com/kaitoy/react-redux-scaffold&#34;&gt;GitHub&lt;/a&gt;に置いた。)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/11/02/creating-react-redux-app-from-scratch-09/&#34;&gt;前回&lt;/a&gt;は&lt;a href=&#34;https://reacttraining.com/react-router/&#34;&gt;React Router&lt;/a&gt;をセットアップした。&lt;/p&gt;

&lt;p&gt;今回は残りの要素をまとめてかたづける。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;code-splitting&#34;&gt;Code Splitting&lt;/h1&gt;

&lt;p&gt;webpackでリソースをバンドルすると、一回の通信でアプリの要素全てをロードできるので効率いいような気がするけど、アプリの規模が大きくなってくるとバンドルサイズが大きくなって、初期ロード時間が長くなり、つまり初期画面の表示に時間がかかるようになってしまう。
そもそも、いつもアプリの全画面をみるとは限らないので、いつもアプリの全要素をロードするのは無駄。&lt;/p&gt;

&lt;p&gt;そんな問題に対応する技術が&lt;a href=&#34;https://webpack.js.org/guides/code-splitting/&#34;&gt;Code Splitting&lt;/a&gt;。
バンドルを分割し、(理想的には)必要な時に必要な分だけロードする技術。&lt;/p&gt;

&lt;p&gt;Code Splittingのやりかたはいくつかあるが、webpackのディレクティブを使った&lt;a href=&#34;https://webpack.js.org/guides/code-splitting/#prefetching-preloading-modules&#34;&gt;プリフェッチ&lt;/a&gt;を、フォントモジュールに適用してみる。&lt;/p&gt;

&lt;p&gt;src/index.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
 import ReactDOM from &#39;react-dom&#39;;
 import { Provider } from &#39;react-redux&#39;;
 import { ConnectedRouter } from &#39;connected-react-router&#39;;
 import App from &#39;./components/App&#39;;
 import configureStore from &#39;./configureStore&#39;;
 import configureStore, { history } from &#39;./configureStore&#39;;
-import &#39;./fonts.css&#39;;
+import(/* webpackPrefetch: true */ &#39;./fonts&#39;);

 const store = configureStore();
 const root = document.getElementById(&#39;root&#39;);

 if (root) {
   ReactDOM.render(
     &amp;lt;Provider store={store}&amp;gt;
       &amp;lt;ConnectedRouter history={history}&amp;gt;
         &amp;lt;App /&amp;gt;
       &amp;lt;/ConnectedRouter&amp;gt;
     &amp;lt;/Provider&amp;gt;,
     root,
   );
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コード変更はこれだけ。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;import()&lt;/code&gt;は&lt;a href=&#34;https://github.com/tc39/proposal-dynamic-import&#34;&gt;ダイナミックインポート&lt;/a&gt;という、ECMAScriptで現在策定中の機能。
これを使えるようにするためには、Babelのプラグインを追加する必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D babel-plugin-syntax-dynamic-import
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.babelrc&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; {
   &amp;quot;presets&amp;quot;: [&amp;quot;env&amp;quot;, &amp;quot;react&amp;quot;],
-  &amp;quot;plugins&amp;quot;: [&amp;quot;styled-components&amp;quot;]
+  &amp;quot;plugins&amp;quot;: [&amp;quot;styled-components&amp;quot;, &amp;quot;syntax-dynamic-import&amp;quot;]
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ダイナミックインポートの設定も完了。
これでフォントモジュールはメインのバンドルとは別ファイルになり、初期画面の表示時にはロードされず、ブラウザの空き時間に非同期にロードされるようになる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Code Splittingは&lt;a href=&#34;https://reactjs.org/docs/code-splitting.html&#34;&gt;Reactのドキュメント&lt;/a&gt;でも紹介されていて、そこにはReact特有のやり方も載っている。
&lt;a href=&#34;https://reactjs.org/docs/code-splitting.html#reactlazy&#34;&gt;React.lazy&lt;/a&gt;と&lt;a href=&#34;https://reactjs.org/docs/code-splitting.html#suspense&#34;&gt;Suspense&lt;/a&gt;を使うものがかなりナウい。&lt;/p&gt;

&lt;h1 id=&#34;flow&#34;&gt;Flow&lt;/h1&gt;

&lt;p&gt;Reactに限らない話だけど、JavaScriptは動的型付け言語なので、特に規模が大き目なアプリを開発するとなると保守性が悪くなりがちで辛い。
ので、できれば静的型付けでやりたい。&lt;/p&gt;

&lt;p&gt;JavaScriptを静的型付けにするには、&lt;a href=&#34;https://www.typescriptlang.org/&#34;&gt;TypeScript&lt;/a&gt;と&lt;a href=&#34;https://flow.org/&#34;&gt;Flow&lt;/a&gt;という二つの選択肢がある。
今回、FlowがReactと同じくFacebook製なので、Reactと相性がいいかと思ってFlowを選択したけど、人気やエコシステムの充実度から見るとTypeScriptのほうがよかった気がする。
ので、Flowについてはさらっと書く。&lt;/p&gt;

&lt;h2 id=&#34;flow導入&#34;&gt;Flow導入&lt;/h2&gt;

&lt;p&gt;Flowは、ソースに型情報を付けて静的型チェック可能にしつつ、実行時には型情報を取り去って普通のJavaScriptとして実行できるようにする仕組み。&lt;/p&gt;

&lt;p&gt;型チェックするツールは&lt;a href=&#34;https://www.npmjs.com/package/flow-bin&#34;&gt;flow-bin&lt;/a&gt;パッケージで配布されていて、型情報の除去は&lt;a href=&#34;https://www.npmjs.com/package/babel-preset-flow&#34;&gt;babel-preset-flow&lt;/a&gt;を使ってBabelでできる。
babel-preset-flowは、すでにインストールしたbabel-preset-reactに含まれてるので、敢えて入れる必要はない。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D flow-bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで、&lt;code&gt;yarn flow&lt;/code&gt;でFlowを実行できるようになった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ yarn flow version
yarn run v1.7.0
$ C:\Users\kaitoy\Desktop\bin\pleiades\workspace\react-redux-scaffold\node_modules\.bin\flow version
Flow, a static type checker for JavaScript, version 0.77.0
Done in 0.38s.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、&lt;code&gt;yarn flow init&lt;/code&gt;でFlowの設定ファイル&lt;code&gt;.flowconfig&lt;/code&gt;を生成して、型チェックしたいファイルの頭に&lt;code&gt;// @flow&lt;/code&gt;と書けばとりあえず機能する。&lt;/p&gt;

&lt;h2 id=&#34;flowの型アノテーション&#34;&gt;Flowの型アノテーション&lt;/h2&gt;

&lt;p&gt;それだけでもだいぶ型推論してくれてチェックが利くけど、&lt;a href=&#34;https://flow.org/en/docs/types/&#34;&gt;型アノテーション&lt;/a&gt;を書いていくとよりいい。
ただ、アノテートするとESLintとけんかするので、それ対策として&lt;a href=&#34;https://github.com/gajus/eslint-plugin-flowtype&#34;&gt;eslint-plugin-flowtype&lt;/a&gt;を入れる必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D babel-eslint eslint-plugin-flowtype
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;.eslintrc.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; module.exports = {
   env: {
     browser: true,
   },
+  parser: &#39;babel-eslint&#39;,
-  extends: [&#39;airbnb&#39;, &#39;prettier&#39;],
+  extends: [&#39;airbnb&#39;, &#39;plugin:flowtype/recommended&#39;, &#39;prettier&#39;],
+  plugins: [&#39;flowtype&#39;],
 };
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;例として、Reactコンポーネントのpropsに型を付けてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;// @flow

import React from &#39;react&#39;;
import Dialog from &#39;@material-ui/core/Dialog&#39;;
import DialogTitle from &#39;@material-ui/core/DialogTitle&#39;;
import PropTypes from &#39;prop-types&#39;;

// Propsという型の定義
// text(string型)とopen(boolean型)というプロパティを持つオブジェクト
type Props = {
  text: string,
  open: boolean,
};

// Props型を受け取る関数
const MyDialog = ({ text, open }: Props) =&amp;gt; (
  &amp;lt;Dialog open={open}&amp;gt;
    &amp;lt;DialogTitle&amp;gt;{text}&amp;lt;/DialogTitle&amp;gt;
  &amp;lt;/Dialog&amp;gt;
);

MyDialog.propTypes = {
  text: PropTypes.string.isRequired,
  open: PropTypes.bool.isRequired,
};

export default MyDialog;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じで型を付けておくと、MyDialogに渡すpropsを間違った場合にFlowがエラーにしてくれる。
prop-typesによる型定義と冗長な感じに見えるけど、Flowは静的に型チェックするのに対し、prop-typesはアプリの動作中に型チェックしてくれるので、両方書いておくのがよさそう。
(Flowの型定義からprop-typesの定義を生成してくれる&lt;a href=&#34;https://github.com/atlassian/babel-plugin-react-flow-props-to-prop-types&#34;&gt;babel-plugin-react-flow-props-to-prop-types&lt;/a&gt;というのがあるけど、サポートされていない型があるし、メンテされていないし、微妙。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;上のコードで、&lt;code&gt;type&lt;/code&gt;というキーワードで型を定義しているんだけど、Reactとかの3rdパーティライブラリの型情報(&lt;a href=&#34;https://flow.org/en/docs/libdefs/&#34;&gt;libdef&lt;/a&gt;と呼ばれるもの)は、ライブラリ開発者などが作ったものが公開されていて、インストールして利用できる。&lt;/p&gt;

&lt;p&gt;libdefはそれようの&lt;a href=&#34;https://github.com/flow-typed/flow-typed/tree/master/definitions&#34;&gt;リポジトリ&lt;/a&gt;で管理されていて、&lt;a href=&#34;https://github.com/flow-typed/flow-typed/blob/master/README.md&#34;&gt;flow-typed&lt;/a&gt;で引っ張れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D flow-typed
yarn flow-typed --ignoreDeps dev install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで、package.jsonに書かれている依存(devDependenciesを除く)を見て、必要なlibdefをダウンロードしてきて、プロジェクトルートの&lt;code&gt;flow-typed&lt;/code&gt;というディレクトリにインストールしてくれる。&lt;/p&gt;

&lt;p&gt;例えばさっきのReactコンポーネントのコードに、ReactのAPIの型の一つである&lt;code&gt;Node&lt;/code&gt;を書くと以下のようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; // @flow

 import React from &#39;react&#39;;
+import type { Node } from &#39;react&#39;;
 import Dialog from &#39;@material-ui/core/Dialog&#39;;
 import DialogTitle from &#39;@material-ui/core/DialogTitle&#39;;
 import PropTypes from &#39;prop-types&#39;;

 // Propsという型の定義
 // text(string型)とopen(boolean型)というプロパティを持つオブジェクト
 type Props = {
   text: string,
   open: boolean,
 };

 // Props型を受け取る関数
-const MyDialog = ({ text, open }: Props) =&amp;gt; (
+const MyDialog = ({ text, open }: Props): Node =&amp;gt; (
   &amp;lt;Dialog open={open}&amp;gt;
     &amp;lt;DialogTitle&amp;gt;{text}&amp;lt;/DialogTitle&amp;gt;
   &amp;lt;/Dialog&amp;gt;
 );

 MyDialog.propTypes = {
   text: PropTypes.string.isRequired,
   open: PropTypes.bool.isRequired,
 };

 export default MyDialog;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因みに&lt;code&gt;flow-typed&lt;/code&gt;ディレクトリの中身はコミットすることが推奨されている。
なんか違和感あるんだけど…&lt;/p&gt;

&lt;h1 id=&#34;jest&#34;&gt;Jest&lt;/h1&gt;

&lt;p&gt;Reactプロジェクトでユニットテストを書くなら、&lt;a href=&#34;https://jestjs.io/ja/&#34;&gt;Jest&lt;/a&gt;一択でいいっぽい。
JestもReactと開発元が同じFacebookで、Reactと相性がいいはずだし、Reactプロジェクト以外でもJestは人気。&lt;/p&gt;

&lt;p&gt;ゼロ設定で使えるように作られていて、導入の敷居が低いのが特徴。
また多機能で、アサーション、モック、カバレージ測定辺りは組み込まれていてすぐ使える。&lt;/p&gt;

&lt;p&gt;もともとは(今も?)&lt;a href=&#34;https://jasmine.github.io/&#34;&gt;Jasmine&lt;/a&gt;ベースで、APIが似た感じなので、Jasmineとか&lt;a href=&#34;https://mochajs.org/&#34;&gt;Mocha&lt;/a&gt;に慣れた人には特に使いやすい。&lt;/p&gt;

&lt;h2 id=&#34;jestインストール&#34;&gt;Jestインストール&lt;/h2&gt;

&lt;p&gt;ReactプロジェクトでJestを使うには以下のパッケージを入れる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.npmjs.com/package/jest&#34;&gt;jest&lt;/a&gt;: 本体&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.npmjs.com/package/babel-jest&#34;&gt;babel-jest&lt;/a&gt;: BabelでトランスパイルするコードをJestでテストするためのBabelプラグイン&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.npmjs.com/package/react-test-renderer&#34;&gt;react-test-renderer&lt;/a&gt;: ReactコンポーネントをピュアなJavaScriptオブジェクトにレンダリングするライブラリ。&lt;a href=&#34;https://jestjs.io/docs/en/snapshot-testing&#34;&gt;スナップショットテスト&lt;/a&gt;などに使う。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D jest babel-jest react-test-renderer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Jestはv23.4.2が入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;npm scriptにjestを追加しておくといい。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;package.json&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; (前略)
   &amp;quot;scripts&amp;quot;: {
     &amp;quot;format&amp;quot;: &amp;quot;prettier --write **/*.jsx **/*.js **/*.css&amp;quot;,
     &amp;quot;build&amp;quot;: &amp;quot;webpack --config webpack.prod.js&amp;quot;,
+    &amp;quot;test&amp;quot;: &amp;quot;jest&amp;quot;,
     &amp;quot;start&amp;quot;: &amp;quot;webpack-dev-server --hot --config webpack.dev.js&amp;quot;
   },
 (後略)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;jestセットアップ&#34;&gt;Jestセットアップ&lt;/h2&gt;

&lt;p&gt;Jestの設定ファイルである&lt;a href=&#34;https://jestjs.io/docs/en/configuration&#34;&gt;jest.config.js&lt;/a&gt;をプロジェクトルートに生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn test --init
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;プロンプトでいくつかのことを聞かれるが、「Choose the test environment that will be used for testing」に&lt;code&gt;jsdom&lt;/code&gt;で答えるのがポイント。ブラウザで動かすアプリなので。&lt;/p&gt;

&lt;p&gt;設定ファイルはとりあえずおおむね生成されたままでいいけど、一点、v23.4.2時点では、テスト実行時に「SecurityError: localStorage is not available for opaque origins」というエラーが出る&lt;a href=&#34;https://github.com/facebook/jest/issues/6769#issuecomment-408352345&#34;&gt;問題がある&lt;/a&gt;ので、testURLを「&lt;code&gt;http://localhost/&lt;/code&gt;」に設定しておく必要がある。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;jest.config.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;// For a detailed explanation regarding each configuration property, visit:
// https://jestjs.io/docs/en/configuration.html

module.exports = {
  // All imported modules in your tests should be mocked automatically
  // automock: false,

  // Stop running tests after the first failure
  // bail: false,

  // Respect &amp;quot;browser&amp;quot; field in package.json when resolving modules
  // browser: false,

  // The directory where Jest should store its cached dependency information
  // cacheDirectory: &amp;quot;C:\\Users\\kaitoy\\AppData\\Local\\Temp\\jest&amp;quot;,

  // Automatically clear mock calls and instances between every test
  // clearMocks: false,

  // Indicates whether the coverage information should be collected while executing the test
  // collectCoverage: false,

  // An array of glob patterns indicating a set of files for which coverage information should be collected
  // collectCoverageFrom: null,

  // The directory where Jest should output its coverage files
  coverageDirectory: &#39;coverage&#39;,

  // An array of regexp pattern strings used to skip coverage collection
  // coveragePathIgnorePatterns: [
  //   &amp;quot;\\\\node_modules\\\\&amp;quot;
  // ],

  // A list of reporter names that Jest uses when writing coverage reports
  // coverageReporters: [
  //   &amp;quot;json&amp;quot;,
  //   &amp;quot;text&amp;quot;,
  //   &amp;quot;lcov&amp;quot;,
  //   &amp;quot;clover&amp;quot;
  // ],

  // An object that configures minimum threshold enforcement for coverage results
  // coverageThreshold: null,

  // Make calling deprecated APIs throw helpful error messages
  // errorOnDeprecated: false,

  // Force coverage collection from ignored files usin a array of glob patterns
  // forceCoverageMatch: [],

  // A path to a module which exports an async function that is triggered once before all test suites
  // globalSetup: null,

  // A path to a module which exports an async function that is triggered once after all test suites
  // globalTeardown: null,

  // A set of global variables that need to be available in all test environments
  // globals: {},

  // An array of directory names to be searched recursively up from the requiring module&#39;s location
  // moduleDirectories: [
  //   &amp;quot;node_modules&amp;quot;
  // ],

  // An array of file extensions your modules use
  // moduleFileExtensions: [
  //   &amp;quot;js&amp;quot;,
  //   &amp;quot;json&amp;quot;,
  //   &amp;quot;jsx&amp;quot;,
  //   &amp;quot;node&amp;quot;
  // ],

  // A map from regular expressions to module names that allow to stub out resources with a single module
  // moduleNameMapper: {},

  // An array of regexp pattern strings, matched against all module paths before considered &#39;visible&#39; to the module loader
  // modulePathIgnorePatterns: [],

  // Activates notifications for test results
  // notify: false,

  // An enum that specifies notification mode. Requires { notify: true }
  // notifyMode: &amp;quot;always&amp;quot;,

  // A preset that is used as a base for Jest&#39;s configuration
  // preset: null,

  // Run tests from one or more projects
  // projects: null,

  // Use this configuration option to add custom reporters to Jest
  // reporters: undefined,

  // Automatically reset mock state between every test
  // resetMocks: false,

  // Reset the module registry before running each individual test
  // resetModules: false,

  // A path to a custom resolver
  // resolver: null,

  // Automatically restore mock state between every test
  // restoreMocks: false,

  // The root directory that Jest should scan for tests and modules within
  // rootDir: null,

  // A list of paths to directories that Jest should use to search for files in
  // roots: [
  //   &amp;quot;&amp;lt;rootDir&amp;gt;&amp;quot;
  // ],

  // Allows you to use a custom runner instead of Jest&#39;s default test runner
  // runner: &amp;quot;jest-runner&amp;quot;,

  // The paths to modules that run some code to configure or set up the testing environment before each test
  // setupFiles: [],

  // The path to a module that runs some code to configure or set up the testing framework before each test
  // setupTestFrameworkScriptFile: null,

  // A list of paths to snapshot serializer modules Jest should use for snapshot testing
  // snapshotSerializers: [],

  // The test environment that will be used for testing
  // testEnvironment: &amp;quot;jest-environment-jsdom&amp;quot;,

  // Options that will be passed to the testEnvironment
  // testEnvironmentOptions: {},

  // Adds a location field to test results
  // testLocationInResults: false,

  // The glob patterns Jest uses to detect test files
  // testMatch: [
  //   &amp;quot;**/__tests__/**/*.js?(x)&amp;quot;,
  //   &amp;quot;**/?(*.)+(spec|test).js?(x)&amp;quot;
  // ],

  // An array of regexp pattern strings that are matched against all test paths, matched tests are skipped
  // testPathIgnorePatterns: [
  //   &amp;quot;\\\\node_modules\\\\&amp;quot;
  // ],

  // The regexp pattern Jest uses to detect test files
  // testRegex: &amp;quot;&amp;quot;,

  // This option allows the use of a custom results processor
  // testResultsProcessor: null,

  // This option allows use of a custom test runner
  // testRunner: &amp;quot;jasmine2&amp;quot;,

  // This option sets the URL for the jsdom environment. It is reflected in properties such as location.href
  testURL: &#39;http://localhost/&#39;,

  // Setting this value to &amp;quot;fake&amp;quot; allows the use of fake timers for functions such as &amp;quot;setTimeout&amp;quot;
  // timers: &amp;quot;real&amp;quot;,

  // A map from regular expressions to paths to transformers
  // transform: null,

  // An array of regexp pattern strings that are matched against all source file paths, matched files will skip transformation
  // transformIgnorePatterns: [
  //   &amp;quot;\\\\node_modules\\\\&amp;quot;
  // ],

  // An array of regexp pattern strings that are matched against all modules before the module loader will automatically return a mock for them
  // unmockedModulePathPatterns: undefined,

  // Indicates whether each individual test should be reported during the run
  // verbose: null,

  // An array of regexp patterns that are matched against all source file paths before re-running tests in watch mode
  // watchPathIgnorePatterns: [],

  // Whether to use watchman for file crawling
  // watchman: true,
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;また、例によって、(主にJestのグローバル変数のために、)JestのテストコードとESLintがけんかするので、ESLintをなだめるために&lt;a href=&#34;https://www.npmjs.com/package/eslint-plugin-jest&#34;&gt;eslint-plugin-jest&lt;/a&gt;を入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D eslint-plugin-jest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;.eslintrc.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; module.exports = {
   env: {
     browser: true,
+    &#39;jest/globals&#39;: true,
   },
   parser: &#39;babel-eslint&#39;,
   extends: [&#39;airbnb&#39;, &#39;plugin:flowtype/recommended&#39;, &#39;prettier&#39;],
-  plugins: [&#39;flowtype&#39;],
+  plugins: [&#39;flowtype&#39;, &#39;jest&#39;],
 };
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;jestのテスト作成&#34;&gt;Jestのテスト作成&lt;/h2&gt;

&lt;p&gt;Jestのテストは、&lt;code&gt;jest.config.js&lt;/code&gt;の&lt;code&gt;testMatch&lt;/code&gt;にマッチするJavaScriptファイルに書く。
デフォルトでは&lt;code&gt;__test__&lt;/code&gt;ディレクトリ以下に置けばいい。&lt;/p&gt;

&lt;p&gt;テストコードはよくある感じの&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%93%E3%83%98%E3%82%A4%E3%83%93%E3%82%A2%E9%A7%86%E5%8B%95%E9%96%8B%E7%99%BA&#34;&gt;BDD&lt;/a&gt;風に書けばいいと思う。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/__tests__/reducers/reducers.test.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { hoge } from &#39;../../reducers/reducers&#39;;
import { hogeButtonClicked } from &#39;../../actions/actions&#39;;

const initialState = {
  clicked: false,
};

describe(&#39;reducers&#39;, () =&amp;gt; {
  describe(&#39;hoge()&#39;, () =&amp;gt; {
    test(&#39;returns a state with clicked:true when the action is HOGE_BUTTON_CLICKED&#39;, () =&amp;gt; {
      const state = hogeButtonClicked(initialState, hogeButtonClicked({}));
      expect(state.clicked).toBe(true);
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;スナップショットテスト&#34;&gt;スナップショットテスト&lt;/h2&gt;

&lt;p&gt;Jestの目玉のひとつは&lt;a href=&#34;https://jestjs.io/docs/ja/snapshot-testing&#34;&gt;スナップショットテスト&lt;/a&gt;。
Reactコンポーネントのレンダリング結果が以前と変わってないかをテストできる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/__tests__/components/HogeButton.test.jsx&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import React from &#39;react&#39;;
import renderer from &#39;react-test-renderer&#39;;
import HogeButton from &#39;../../components/HogeButton&#39;;

describe(&#39;components&#39;, () =&amp;gt; {
  describe(&#39;HogeButton&#39;, () =&amp;gt; {
    test(&#39;renders correctly&#39;, () =&amp;gt; {
      const tree = renderer.create(
        &amp;lt;HogeButton variant=&amp;quot;contained&amp;quot; onClick={() =&amp;gt; {}}&amp;gt;
          HOGE
        &amp;lt;/HogeButton&amp;gt;
      ).toJSON();
      expect(tree).toMatchSnapshot();
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このテストの初回実行時には、&lt;code&gt;src/__tests__/components/__snapshots__/HogeButton.test.jsx.snap&lt;/code&gt;というスナップショットファイルが生成される。
これはテキスト形式で、以下のような人が読み解ける内容。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/__tests__/components/__snapshots__/HogeButton.test.jsx.snap&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`components HogeButton renders correctly 1`] = `
&amp;lt;button
  className=&amp;quot;MuiButtonBase-root-25 MuiButton-root-1 MuiButton-contained-10 MuiButton-raised-13&amp;quot;
  disabled={false}
  onBlur={[Function]}
  onClick={[Function]}
  onFocus={[Function]}
  onKeyDown={[Function]}
  onKeyUp={[Function]}
  onMouseDown={[Function]}
  onMouseLeave={[Function]}
  onMouseUp={[Function]}
  onTouchEnd={[Function]}
  onTouchMove={[Function]}
  onTouchStart={[Function]}
  tabIndex=&amp;quot;0&amp;quot;
  type=&amp;quot;button&amp;quot;
&amp;gt;
  &amp;lt;span
    className=&amp;quot;MuiButton-label-2&amp;quot;
  &amp;gt;
    HOGE
  &amp;lt;/span&amp;gt;
  &amp;lt;span
    className=&amp;quot;MuiTouchRipple-root-28&amp;quot;
  /&amp;gt;
&amp;lt;/button&amp;gt;
`;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;スナップショットファイルはコミットしてバージョン管理して、変更があったときには差分を確認する。&lt;/p&gt;

&lt;h1 id=&#34;enzyme&#34;&gt;Enzyme&lt;/h1&gt;

&lt;p&gt;Reactのユニットテストをよりいい感じに書けるようにしてくれるユーティリティライブラリが&lt;a href=&#34;https://airbnb.io/enzyme/&#34;&gt;Enzyme&lt;/a&gt;。
Airbnb製。
Reactコンポーネントをレンダリングして、jQueryみたいなAPIで&lt;a href=&#34;https://airbnb.io/enzyme/docs/api/selector.html&#34;&gt;セレクタ&lt;/a&gt;を指定したりしてエレメントを取得し、アサートするようなテストが書ける。&lt;/p&gt;

&lt;p&gt;Enzymeによるレンダリングには以下の3種類があり、テスト内容によって使い分ける。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://airbnb.io/enzyme/docs/api/shallow.html&#34;&gt;Shallow Rendering&lt;/a&gt;: 浅くレンダリングして、子コンポーネントに影響を受けないテストができる。Reactの&lt;a href=&#34;https://reactjs.org/docs/state-and-lifecycle.html&#34;&gt;ライフサイクルメソッド&lt;/a&gt;も呼んでくれる。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://airbnb.io/enzyme/docs/api/mount.html&#34;&gt;Full Rendering&lt;/a&gt;: &lt;a href=&#34;https://github.com/jsdom/jsdom&#34;&gt;jsdom&lt;/a&gt;などを使って完全なDOMツリーとしてレンダリングする。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://airbnb.io/enzyme/docs/api/render.html&#34;&gt;Static Rendering&lt;/a&gt;: 静的なHTMLに出力して、それをパースする。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Enzymeはv3から本体とアダプタという構成になっていて、Reactのバージョンによってアダプタを使い分ける。
(&lt;a href=&#34;https://preactjs.com/&#34;&gt;preact&lt;/a&gt;とか&lt;a href=&#34;https://infernojs.org/&#34;&gt;Inferno&lt;/a&gt;のアダプタもある。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D enzyme enzyme-adapter-react-16
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Enzymeはv3.3.0が入った。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/FormidableLabs/enzyme-matchers/tree/master/packages/jest-enzyme&#34;&gt;jest-enzyme&lt;/a&gt;も入れるとアサーションがいい感じに書けてよりいいかもしれない。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Full Renderingをやってみる。&lt;/p&gt;

&lt;p&gt;ContainedButtonがクリックされたとき、&lt;code&gt;onClick&lt;/code&gt;に指定した関数が呼ばれることを確認するテストは以下のように書ける。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/__tests__/components/HogeButton.test.jsx&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
 import renderer from &#39;react-test-renderer&#39;;
+import Enzyme, { mount } from &#39;enzyme&#39;;
+import Adapter from &#39;enzyme-adapter-react-16&#39;;
 import HogeButton from &#39;../../components/HogeButton&#39;;

+beforeAll(() =&amp;gt; {
+  Enzyme.configure({ adapter: new Adapter() });
+});

 describe(&#39;components&#39;, () =&amp;gt; {
   describe(&#39;HogeButton&#39;, () =&amp;gt; {
     test(&#39;renders correctly&#39;, () =&amp;gt; {
       const tree = renderer.create(
         &amp;lt;HogeButton variant=&amp;quot;contained&amp;quot; onClick={() =&amp;gt; {}}&amp;gt;
           HOGE
         &amp;lt;/HogeButton&amp;gt;
       ).toJSON();
       expect(tree).toMatchSnapshot();
     });
+
+    test(&amp;quot;calls the passed handler when it&#39;s clicked&amp;quot;, () =&amp;gt; {
+      const handler = jest.fn();
+      const wrapper = mount(&amp;lt;HogeButton onClick={handler} /&amp;gt;);
+      wrapper.find(&#39;button&#39;).simulate(&#39;click&#39;);
+      expect(handler).toHaveBeenCalledTimes(1);
+    });
   });
 });
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;mount&lt;/code&gt;がFull RenderingのAPIで、内部で&lt;code&gt;react-test-renderer&lt;/code&gt;を使っているみたいなんだけど、&lt;code&gt;mount&lt;/code&gt;のために&lt;code&gt;react-test-renderer&lt;/code&gt;をimportする必要はない。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上で全10回に渡るReact―Redux環境のセットアップ体験記が完結。&lt;/p&gt;

&lt;p&gt;だらだら書いてるうちに、&lt;a href=&#34;https://babeljs.io/blog/2018/08/27/7.0.0&#34;&gt;Babelの7が出たり&lt;/a&gt;、&lt;a href=&#34;https://reactjs.org/docs/hooks-overview.html&#34;&gt;React Hooks&lt;/a&gt;とか&lt;a href=&#34;https://logmi.jp/tech/articles/302611&#34;&gt;React Suspense&lt;/a&gt;とかが出てきてて、また大きく変わってきそう…&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>React &#43; Reduxアプリケーションプロジェクトのテンプレートを作る ― その9: React Router</title>
          <link>https://www.kaitoy.xyz/2018/11/02/creating-react-redux-app-from-scratch-09/</link>
          <pubDate>Fri, 02 Nov 2018 13:45:56 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/11/02/creating-react-redux-app-from-scratch-09/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt;と&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;を学ぶために、開発環境というかプロジェクトテンプレートをスクラッチから作っている。
(最終的な成果は&lt;a href=&#34;https://github.com/kaitoy/react-redux-scaffold&#34;&gt;GitHub&lt;/a&gt;に置いた。)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/10/07/creating-react-redux-app-from-scratch-08/&#34;&gt;前回&lt;/a&gt;は&lt;a href=&#34;https://redux-saga.js.org/&#34;&gt;Redux Saga&lt;/a&gt;をセットアップした。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;フロントエンドのルーティング&#34;&gt;フロントエンドのルーティング&lt;/h1&gt;

&lt;p&gt;Webアプリケーションにおけるルーティングとは、クライアントがリクエストしたURLに対して、返すべきリソースを選択する処理。
昔はバックエンド(i.e. サーバサイド)でやってたけど、バックエンドでリソースを返すということは、ページ遷移が発生するということなので、ネイティブアプリケーションに比べてUXが落ちてしまう。&lt;/p&gt;

&lt;p&gt;一方、ページ遷移を発生させないようにAjaxでサーバとやりとりしつつ、ちまちまDOMをいじるのは大変。
DOMをごっそり書き換えて、ページ遷移なしに画面を切り替えることはできるけど、ナイーブにやると以下のような問題がある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;URLと画面の紐づけがなく、URLを指定して直接開けない&lt;/li&gt;
&lt;li&gt;ブラウザの進む、戻るが使えない&lt;/li&gt;
&lt;li&gt;宣言的に書けない&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;こういった問題に対応するため、フロントエンドでのルーティング技術が生まれた。&lt;/p&gt;

&lt;p&gt;フロントエンドのルーティングでは、URLが変わってもリクエストはサーバに飛ばない。
代わりに、フロントエンドフレームワークがそのURLを見て、適切な画面を選んでレンダリングする。&lt;/p&gt;

&lt;h2 id=&#34;ハッシュベースのルーティング&#34;&gt;ハッシュベースのルーティング&lt;/h2&gt;

&lt;p&gt;URLが変わってもリクエストがサーバに飛ばないとは何事か。&lt;/p&gt;

&lt;p&gt;それを実現するやりかたは2通りある。
古くはハッシュ(#、&lt;a href=&#34;https://en.wikipedia.org/wiki/Fragment_identifier&#34;&gt;フラグメント識別子&lt;/a&gt;)をつかったやり方。&lt;/p&gt;

&lt;p&gt;例えば、&lt;code&gt;http://example.com/&lt;/code&gt;でUIをサーブしているとすると、&lt;code&gt;http://example.com/#foo&lt;/code&gt;とか、&lt;code&gt;http://example.com/#bar&lt;/code&gt;で別々のページの状態を表現する。
ハッシュ以降が変わってもブラウザがサーバにリクエストを投げることはないので、クライアント側でハンドリングできる。
(因みに、ハッシュを含んだURLをブラウザのアドレスバーに入れても、ハッシュを除いたURLでリクエストが送られる。この挙動の根拠となる規格はRFCなどを調べても見つからなかったけど…)&lt;/p&gt;

&lt;p&gt;ハッシュの書き換えは、JavaScriptで以下のようにしてできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;location.hash = newHash;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こういう処理を、例えばWeb UIのボタンをクリックしたときなんかに実行してURLを変えて、その上で画面を更新してやればいい。&lt;/p&gt;

&lt;p&gt;そのあと、ブラウザの戻るボタンなんかを押されると書き換える前のURLにもどるわけだけど、これを検知するために&lt;code&gt;setInterval()&lt;/code&gt;とかで定期的に&lt;code&gt;location.hash&lt;/code&gt;を監視してたりした。&lt;/p&gt;

&lt;h2 id=&#34;history-apiによるルーティング&#34;&gt;History APIによるルーティング&lt;/h2&gt;

&lt;p&gt;ハッシュベースのルーティングは見るからにしょぼい。
URLのハッシュ以降しか使えないのもしょぼいし、内部の処理も泥臭い。&lt;/p&gt;

&lt;p&gt;これが、HTML 5で&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/History&#34;&gt;History API&lt;/a&gt;がでて変わった。
History APIはJavaScriptのAPIで、ブラウザの履歴を操作できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const state = { hoge: &amp;quot;hogeee&amp;quot; };
history.pushState(state, &amp;quot;&amp;quot;, &amp;quot;/foo/bar&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じのを実行すると、URLが&lt;code&gt;/foo/bar&lt;/code&gt;に変わる。(が、もちろんサーバにはリクエストは飛ばない。)
で、ブラウザの戻るボタンを押すと、&lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/Events/popstate&#34;&gt;popstate&lt;/a&gt;イベントが発生するので、それにイベントハンドラを登録しておけば、もとのURLに戻った時にも適時画面を書き換えられる。
popstateイベントからは、&lt;code&gt;pushState()&lt;/code&gt;に渡したstateオブジェクトを取得できる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ところで、ブラウザのアドレスバーに&lt;code&gt;/foo/bar&lt;/code&gt;を直打ちするとどうなるかというと、普通にWebサーバを設定しておくと、&lt;code&gt;/foo/bar/index.html&lt;/code&gt;を返そうとして、無いので404エラーになっちゃう。
ので、サーバ設定では、どのURLも同じリソース(e.g. &lt;code&gt;/index.html&lt;/code&gt;)をしといて、そこからJavaScriptを呼んで、URLを読み取って、画面を描いてやればいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;HTML 5が普及するにつれ、このようなHistory APIを使ったフロントエンドルーティングをするフレームワークやライブラリが色々出てきた。んだろうと思う。&lt;/p&gt;

&lt;h1 id=&#34;react-router&#34;&gt;React Router&lt;/h1&gt;

&lt;p&gt;Reactのエコシステムとしては、&lt;a href=&#34;https://reacttraining.com/react-router/&#34;&gt;React Router&lt;/a&gt;がフロントエンドルーティングを実現してくれる。&lt;/p&gt;

&lt;p&gt;React Routerは、宣言的にフロントエンドルーティングを実現できるReactコンポーネントのライブラリ。&lt;/p&gt;

&lt;p&gt;Reduxとともに使う場合は、&lt;a href=&#34;https://github.com/supasate/connected-react-router&#34;&gt;Connected React Router&lt;/a&gt;を使う。
Connected React Routerには&lt;a href=&#34;https://www.npmjs.com/package/history&#34;&gt;history&lt;/a&gt;が必要。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add react-router-dom connected-react-router history
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;React Routerはv4.3.1、Connected React Routerはv4.3.0が入った。&lt;/p&gt;

&lt;h1 id=&#34;connected-react-router導入&#34;&gt;Connected React Router導入&lt;/h1&gt;

&lt;p&gt;まずはConnected React Routerの&lt;a href=&#34;https://github.com/supasate/connected-react-router#usage&#34;&gt;Usage&lt;/a&gt;を参考に、ReduxのMiddlewareを追加して、historyのインスタンスをStoreとつなぐ。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/configureStore.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import { createStore, applyMiddleware } from &#39;redux&#39;;
 import createSagaMiddleware from &#39;redux-saga&#39;;
+import { createBrowserHistory } from &#39;history&#39;;
+import { connectRouter, routerMiddleware } from &#39;connected-react-router&#39;;
 import { logger } from &#39;redux-logger&#39;;
 import rootSaga from &#39;./sagas/rootSaga&#39;;
 import rootReducer from &#39;./reducers/rootReducer&#39;;

 const sagaMiddleware = createSagaMiddleware();
+export const history = createBrowserHistory();

 export default function configureStore(initialState = {}) {
   const middlewares = [];
   if (process.env.NODE_ENV === `development`) {
     middlewares.push(logger);
   }
+  middlewares.push(routerMiddleware(history));
   middlewares.push(sagaMiddleware);

   const store = createStore(
-    rootReducer,
+    connectRouter(history)(rootReducer),
     initialState,
     applyMiddleware(...middlewares),
   );
   sagaMiddleware.run(rootSaga);
   return store;
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、Connected React RouterのConnectedRouterコンポーネントを&lt;a href=&#34;https://www.kaitoy.xyz/2018/10/01/creating-react-redux-app-from-scratch-07/#provider&#34;&gt;React ReduxのProvider&lt;/a&gt;の下に追加する。&lt;/p&gt;

&lt;p&gt;src/index.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
 import ReactDOM from &#39;react-dom&#39;;
 import { Provider } from &#39;react-redux&#39;;
+import { ConnectedRouter } from &#39;connected-react-router&#39;;
 import App from &#39;./components/App&#39;;
-import configureStore from &#39;./configureStore&#39;;
+import configureStore, { history } from &#39;./configureStore&#39;;
 import &#39;./fonts.css&#39;;

 const store = configureStore();
 const root = document.getElementById(&#39;root&#39;);

 if (root) {
   ReactDOM.render(
-    &amp;lt;Provider store={store}&amp;gt;
-      &amp;lt;App /&amp;gt;
-    &amp;lt;/Provider&amp;gt;,
+    &amp;lt;Provider store={store}&amp;gt;
+      &amp;lt;ConnectedRouter history={history}&amp;gt;
+        &amp;lt;App /&amp;gt;
+      &amp;lt;/ConnectedRouter&amp;gt;
+    &amp;lt;/Provider&amp;gt;,
     root,
   );
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これだけ。
これで、Appコンポーネント以下でReact Routerのコンポーネントを使えるようになった。&lt;/p&gt;

&lt;h1 id=&#34;react-router導入&#34;&gt;React Router導入&lt;/h1&gt;

&lt;p&gt;React Routerの&lt;a href=&#34;https://reacttraining.com/react-router/core/api/Redirect&#34;&gt;Redirect&lt;/a&gt;コンポーネントと&lt;a href=&#34;https://reacttraining.com/react-router/core/api/Route&#34;&gt;Route&lt;/a&gt;コンポーネントを使って、&lt;code&gt;/&lt;/code&gt;にアクセスしたら&lt;code&gt;/home&lt;/code&gt;にリダイレクトして、&lt;code&gt;/home&lt;/code&gt;で今までと同じ画面をレンダリングするようにする。&lt;/p&gt;

&lt;p&gt;まず、App.jsxをHome.jsxにリネームして、Homeコンポーネントに変える。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;components/Home.jsx&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
 import styled from &#39;styled-components&#39;;
 import HogeButton from &#39;../containers/HogeButton&#39;;

 const Wrapper = styled.div`
   font-size: 5rem;
 `;

-const App = () =&amp;gt; (
+const Home = () =&amp;gt; (
   &amp;lt;Wrapper&amp;gt;
     &amp;lt;HogeButton variant=&amp;quot;contained&amp;quot;&amp;gt;
       HOGE
     &amp;lt;/HogeButton&amp;gt;
   &amp;lt;/Wrapper&amp;gt;
 );

-export default App;
+export default Home;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、App.jsxはルーティングを定義するコンポーネントとして作り直す。&lt;/p&gt;

&lt;p&gt;components/App.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import React from &#39;react&#39;;
import { Route, Redirect } from &#39;react-router-dom&#39;;
import Home from &#39;./Home&#39;;

const App = (): Node =&amp;gt; (
  &amp;lt;div&amp;gt;
    &amp;lt;Route exact path=&amp;quot;/&amp;quot; render={() =&amp;gt; &amp;lt;Redirect to=&amp;quot;/home&amp;quot; /&amp;gt;} /&amp;gt;
    &amp;lt;Route exact path=&amp;quot;/home&amp;quot; component={Home} /&amp;gt;
  &amp;lt;/div&amp;gt;
);

export default App;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じ。&lt;/p&gt;

&lt;h1 id=&#34;webpack-dev-serverのhistory-api-fallback&#34;&gt;webpack-dev-serverのHistory API Fallback&lt;/h1&gt;

&lt;p&gt;あとは、上に書いたような404エラーを防ぐために、webpack-dev-serverの&lt;a href=&#34;https://webpack.js.org/configuration/dev-server/#devserver-historyapifallback&#34;&gt;History API Fallback&lt;/a&gt;を有効にしてやる。&lt;/p&gt;

&lt;p&gt;webpack.dev.js&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; const path = require(&#39;path&#39;);
 const webpackMerge = require(&#39;webpack-merge&#39;);
 const webpackCommon = require(&#39;./webpack.common.js&#39;);

 module.exports = webpackMerge(webpackCommon, {
   mode: &#39;development&#39;,
   devServer: {
     contentBase: path.join(__dirname, &#39;public&#39;),
     compress: true,
     hot: true,
     port: 3000,
     publicPath: &#39;http://localhost:3000/&#39;,
+    historyApiFallback: true,
   },
 });
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こうしておくと、&lt;code&gt;/index.html&lt;/code&gt;以外にリクエストが来た場合、404エラーを返す代わりに&lt;code&gt;/index.html&lt;/code&gt;を返してくれるようになる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/11/07/creating-react-redux-app-from-scratch-10/&#34;&gt;次回&lt;/a&gt;はラストで、&lt;a href=&#34;https://webpack.js.org/guides/code-splitting/&#34;&gt;Code Splitting&lt;/a&gt;と&lt;a href=&#34;https://flow.org/&#34;&gt;Flow&lt;/a&gt;と&lt;a href=&#34;https://jestjs.io/ja/&#34;&gt;Jest&lt;/a&gt;と&lt;a href=&#34;https://airbnb.io/enzyme/&#34;&gt;Enzyme&lt;/a&gt;。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>React &#43; Reduxアプリケーションプロジェクトのテンプレートを作る ― その8: Redux-Saga</title>
          <link>https://www.kaitoy.xyz/2018/10/07/creating-react-redux-app-from-scratch-08/</link>
          <pubDate>Sun, 07 Oct 2018 13:26:22 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/10/07/creating-react-redux-app-from-scratch-08/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt;と&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;を学ぶために、開発環境というかプロジェクトテンプレートをスクラッチから作っている。
(最終的な成果は&lt;a href=&#34;https://github.com/kaitoy/react-redux-scaffold&#34;&gt;GitHub&lt;/a&gt;に置いた。)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/10/01/creating-react-redux-app-from-scratch-07/&#34;&gt;前回&lt;/a&gt;は&lt;a href=&#34;https://redux.js.org/basics/usagewithreact&#34;&gt;React Redux&lt;/a&gt;をセットアップした。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;reduxのmiddleware&#34;&gt;ReduxのMiddleware&lt;/h1&gt;

&lt;p&gt;Redux単体では同期的なデータフローしか実装できない。
つまり、Actionを発生させたら、即座にディスパッチされ、stateが更新される。
一方、非同期なフローとは、REST APIを呼んでその結果でstateを更新するような処理。
REST API呼び出しが非同期なわけだが、これをReduxのピュアなフローのどこで実行するのかというと、&lt;a href=&#34;https://redux.js.org/advanced/middleware&#34;&gt;Middleware&lt;/a&gt;で実行する。&lt;/p&gt;

&lt;p&gt;MiddlewareはStoreの&lt;code&gt;dispatch()&lt;/code&gt;をラップして、Actionをトラップして副作用を含む任意の処理をするための機能。
Middlewareの仕組みについては&lt;a href=&#34;https://qiita.com/pirosikick/items/d7f9e5e197a2e8aad62f&#34;&gt;この記事&lt;/a&gt;が分かりやすい。&lt;/p&gt;

&lt;p&gt;Middlewareには例えば、発生したActionの内容と、それによるstateの変化をログに出力する&lt;a href=&#34;https://github.com/evgenyrodionov/redux-logger&#34;&gt;redux-logger&lt;/a&gt;がある。
デバッグに有用そうなので入れておく。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add redux-logger
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;v3.0.6が入った。&lt;/p&gt;

&lt;p&gt;Middlewareは、Reduxの&lt;code&gt;applyMiddleware()&lt;/code&gt;というAPIを使って、&lt;code&gt;createStore()&lt;/code&gt;実行時に適用できる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/configureStore.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;-import { createStore } from &#39;redux&#39;;
+import { createStore, applyMiddleware } from &#39;redux&#39;;
+import { logger } from &#39;redux-logger&#39;;
 import rootReducer from &#39;./reducers/rootReducer&#39;;

 export default function configureStore(initialState = {}) {
+  const middlewares = [];
+  if (process.env.NODE_ENV === `development`) {
+    middlewares.push(logger);
+  }
+
   const store = createStore(
     rootReducer,
     initialState,
+    applyMiddleware(...middlewares),
   );
   return store;
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これだけ。
これで、HOGEボタンをクリックしたときにコンソールに以下のようなログが出るようになる。
(ログは&lt;code&gt;yarn start&lt;/code&gt;とかの開発モードの時だけでる。)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;action HOGE_BUTTON_CLICKED @ 23:19:35.190
 prev state Object { hoge: {…} }
 action Object { type: &amp;quot;HOGE_BUTTON_CLICKED&amp;quot;, payload: undefined }
 next state Object { hoge: {…} }
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;非同期処理&#34;&gt;非同期処理&lt;/h1&gt;

&lt;p&gt;非同期処理をするためのMiddlewareには&lt;a href=&#34;https://github.com/reduxjs/redux-thunk&#34;&gt;redux-thunk&lt;/a&gt;とか&lt;a href=&#34;https://github.com/redux-utilities/redux-promise&#34;&gt;redux-promise&lt;/a&gt;とかがあるけど、なかでもGitHubのスター数が一番多い&lt;a href=&#34;https://redux-saga.js.org/&#34;&gt;Redux Saga&lt;/a&gt;を使うことにする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add redux-saga
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;v0.16.0が入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;因みに次にスター数が多いのがredux-thunkで、これはActionをfunctionオブジェクトで書けるようにするMiddleware。
そのfunctionの中で非同期処理をすることで、非同期なReduxフローを実現できる。
redux-sagaはredux-thunkに比べて以下の特長を持つ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;コールバック地獄に悩まされることが無い&lt;/li&gt;
&lt;li&gt;Actionをプレーン且つピュアに保てるのでテストしやすい&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;redux-sagaの使い方&#34;&gt;Redux Sagaの使い方&lt;/h1&gt;

&lt;p&gt;Redux Sagaでは、非同期処理はSagaというコンポーネントに書く。
Sagaでは、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;ディスパッチされるActionをWatcherが監視し、&lt;/li&gt;
&lt;li&gt;特定のActionが来たらWorkerを起動し、&lt;/li&gt;
&lt;li&gt;Workerが非同期処理などのTaskを実行し、&lt;/li&gt;
&lt;li&gt;その結果を通知するActionをディスパッチする、&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;といった処理を実行する。&lt;/p&gt;

&lt;p&gt;これらの処理は、Saga Middlewareから呼ばれる&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Global_Objects/Generator&#34;&gt;ジェネレータ関数&lt;/a&gt;のなかで、EffectというオブジェクトをSaga Middlewareに返すことで、Saga Middlewareに指示して実行させる。
このEffectを生成する&lt;a href=&#34;https://redux-saga.js.org/docs/api/&#34;&gt;API&lt;/a&gt;がRedux Sagaからいろいろ提供されている。&lt;/p&gt;

&lt;p&gt;上記処理の1~4はそれぞれ以下のAPIで実装できる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;take(pattern)&lt;/code&gt;: ディスパッチされるActionを監視して、&lt;code&gt;pattern&lt;/code&gt;にマッチしたら取得するEffectを生成する。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fork(fn, ...args)&lt;/code&gt;: 渡された関数&lt;code&gt;fn&lt;/code&gt;をノンブロッキングで呼び出すEffectを生成する。&lt;code&gt;fn&lt;/code&gt;はジェネレータか&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Global_Objects/Promise&#34;&gt;Promise&lt;/a&gt;を返す関数。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;call(fn, ...args)&lt;/code&gt;: 渡された関数&lt;code&gt;fn&lt;/code&gt;を同期的に呼び出すEffectを生成する。&lt;code&gt;fn&lt;/code&gt;はジェネレータか&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Global_Objects/Promise&#34;&gt;Promise&lt;/a&gt;を返す関数。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;put(action)&lt;/code&gt;: Actionオブジェクトの&lt;code&gt;action&lt;/code&gt;をディスパッチするEffectを生成する。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;rest-api呼び出し&#34;&gt;REST API呼び出し&lt;/h1&gt;

&lt;p&gt;非同期実行で最もよくあるのがREST API呼び出しであろう。
REST API呼び出し処理は&lt;code&gt;call()&lt;/code&gt;で実行するわけだけど、&lt;code&gt;call()&lt;/code&gt;にはPromiseを返す必要があるので、使うライブラリはそこを考慮しないといけない。&lt;/p&gt;

&lt;p&gt;ざっと調べたところ、&lt;a href=&#34;https://www.npmjs.com/package/axios&#34;&gt;axios&lt;/a&gt;、&lt;a href=&#34;https://www.npmjs.com/package/superagent&#34;&gt;SuperAgent&lt;/a&gt;、&lt;a href=&#34;https://www.npmjs.com/package/r2&#34;&gt;r2&lt;/a&gt;あたりが選択肢。
最も人気のあるaxiosを使うことにする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add axios
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;v0.18.0が入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;REST API呼び出しのコードは&lt;code&gt;src/services/&lt;/code&gt;に置く。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/services/api.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import axios from &#39;axios&#39;;

export const HOGE_URL = &#39;https://httpbin.org/get&#39;;

export function getHoge() {
  return axios.get(HOGE_URL);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;getHoge()&lt;/code&gt;はGETリクエストを送ってPromiseオブジェクトを返す。
このPromiseオブジェクトはレスポンスボディやステータスコードを保持する&lt;a href=&#34;https://github.com/axios/axios#response-schema&#34;&gt;Response&lt;/a&gt;オブジェクトに解決される。&lt;/p&gt;

&lt;h1 id=&#34;rest-api呼び出しを表現するaction&#34;&gt;REST API呼び出しを表現するAction&lt;/h1&gt;

&lt;p&gt;REST API呼び出しをする場合、呼び出し開始、呼び出し成功、呼び出し失敗の3種類のActionで表現するのが一つの&lt;a href=&#34;https://redux.js.org/advanced/asyncactions&#34;&gt;プラクティス&lt;/a&gt;。
これら3種類を、同一のtypeのActionのプロパティ値を変えて表現するやりかたもあるけど、ここでは別々のtypeのアクションとする。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/actions/actionTypes.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; export const HOGE_BUTTON_CLICKED = &#39;HOGE_BUTTON_CLICKED&#39;;
+export const HOGE_FETCH_SUCCEEDED = &#39;HOGE_FETCH_SUCCEEDED&#39;;
+export const HOGE_FETCH_FAILED = &#39;HOGE_FETCH_FAILED&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;src/actions/actions.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import {
   HOGE_BUTTON_CLICKED,
+  HOGE_FETCH_SUCCEEDED,
+  HOGE_FETCH_FAILED,
 } from &#39;./actionTypes&#39;;

 export function hogeButtonClicked(payload) {
   return {
     type: HOGE_BUTTON_CLICKED,
     payload,
   };
 }
+
+export function hogeFetchSucceeded(payload, meta) {
+  return {
+    type: HOGE_FETCH_SUCCEEDED,
+    payload,
+    meta,
+  };
+}
+
+export function hogeFetchFailed(payload) {
+  return {
+    type: HOGE_FETCH_FAILED,
+    error: true,
+    payload,
+  };
+}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;sagaの実装&#34;&gt;Sagaの実装&lt;/h1&gt;

&lt;p&gt;Sagaのソースは&lt;code&gt;src/sagas/&lt;/code&gt;に置く。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;HOGE_BUTTON_CLICKED&lt;/code&gt;が来たら&lt;code&gt;getHoge()&lt;/code&gt;を実行するSagaは以下のような感じ。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/sagas/hoge.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { call, fork, put, take } from &#39;redux-saga/effects&#39;;
import { getHoge } from &#39;../services/apis&#39;;
import { HOGE_BUTTON_CLICKED } from &#39;../actions/actionTypes&#39;;
import { hogeFetchSucceeded, hogeFetchFailed } from &#39;../actions/actions&#39;;

// Task
function* fetchHoge() {
  try {
    const response = yield call(getHoge);
    const payload = response.data;
    const meta = { statusCode: response.status, statusText: response.statusText };
    yield put(hogeFetchSucceeded(payload, meta));
  } catch (ex) {
    yield put(hogeFetchFailed(ex));
  }
}

// Watcher
export function* watchHogeButtonClicked(): Generator&amp;lt;any, void, Object&amp;gt; {
  while (true) {
    const action = yield take(HOGE_BUTTON_CLICKED);
    yield fork(fetchHoge, action); // actionはfetchHogeの引数に渡される。使ってないけど…
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Watcherは&lt;code&gt;take&lt;/code&gt;して&lt;code&gt;fork&lt;/code&gt;するのを無限ループで回すのが常なので、これをもうちょっときれいに書けるAPIが用意されていて、以下のように書ける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { takeEvery } from &#39;redux-saga/effects&#39;

// Watcher
export function* watchHogeButtonClicked(): Generator&amp;lt;any, void, Object&amp;gt; {
  yield takeEvery(HOGE_BUTTON_CLICKED, fetchHoge)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この場合、&lt;code&gt;fetchHoge()&lt;/code&gt;の最後の引数に&lt;code&gt;take&lt;/code&gt;したActionオブジェクトが渡される。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、今後Watcherはモジュールを分けていくつも書いていくことになるので、それらをまとめて起動するためのモジュール&lt;code&gt;rootSaga.js&lt;/code&gt;を作って、そこで各Watcherを&lt;code&gt;import&lt;/code&gt;して&lt;code&gt;call()&lt;/code&gt;したい。
&lt;code&gt;call()&lt;/code&gt;はブロッキングなAPIなので、パラレルに実行するために&lt;code&gt;all()&lt;/code&gt;を使う。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/sagas/rootSaga.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { call, all } from &#39;redux-saga/effects&#39;;
import { watchHogeButtonClicked } from &#39;./hoge&#39;;

export default function* rootSaga() {
  yield all([
    call(watchHogeButtonClicked),
    // call(watchAnotherAction),
    // call(watchYetAnotherAction),
  ]);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そもそもブロッキングな&lt;code&gt;call()&lt;/code&gt;を使うのがだめなので、代わりに&lt;code&gt;fork()&lt;/code&gt;を使ってもいい。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/sagas/rootSaga.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { fork } from &#39;redux-saga/effects&#39;;
import { watchHogeButtonClicked } from &#39;./hoge&#39;;

export default function* rootSaga() {
  yield fork(watchHogeButtonClicked);
  // yield fork(watchAnotherAction);
  // yield fork(watchYetAnotherAction);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;どっちがいいんだろう。&lt;/p&gt;

&lt;h1 id=&#34;saga-middlewareの追加と起動&#34;&gt;Saga Middlewareの追加と起動&lt;/h1&gt;

&lt;p&gt;Saga Middlewareは以下のように追加して起動する。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/configureStore.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import { createStore, applyMiddleware } from &#39;redux&#39;;
+import createSagaMiddleware from &#39;redux-saga&#39;;
 import { logger } from &#39;redux-logger&#39;;
+import rootSaga from &#39;./sagas/rootSaga&#39;;
 import rootReducer from &#39;./reducers/rootReducer&#39;;

+const sagaMiddleware = createSagaMiddleware();

 export default function configureStore(initialState = {}) {
   const middlewares = [];
   if (process.env.NODE_ENV === `development`) {
     middlewares.push(logger);
   }
+  middlewares.push(sagaMiddleware);

   const store = createStore(
     rootReducer,
     initialState,
     applyMiddleware(...middlewares),
   );
+  sagaMiddleware.run(rootSaga);
   return store;
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/11/02/creating-react-redux-app-from-scratch-09/&#34;&gt;次回&lt;/a&gt;は&lt;a href=&#34;https://reacttraining.com/react-router/&#34;&gt;React Router&lt;/a&gt;。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>React &#43; Reduxアプリケーションプロジェクトのテンプレートを作る ― その7: React Redux</title>
          <link>https://www.kaitoy.xyz/2018/10/01/creating-react-redux-app-from-scratch-07/</link>
          <pubDate>Mon, 01 Oct 2018 07:54:53 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/10/01/creating-react-redux-app-from-scratch-07/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt;と&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;を学ぶために、開発環境というかプロジェクトテンプレートをスクラッチから作っている。
(最終的な成果は&lt;a href=&#34;https://github.com/kaitoy/react-redux-scaffold&#34;&gt;GitHub&lt;/a&gt;に置いた。)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/09/26/creating-react-redux-app-from-scratch-06/&#34;&gt;前回&lt;/a&gt;はReduxをセットアップした。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;react-redux&#34;&gt;React Redux&lt;/h1&gt;

&lt;p&gt;前回はReduxをセットアップして、ActionをStoreにディスパッチしてstateを更新できるようになった。
今回はこれをReactにつなぐ。&lt;/p&gt;

&lt;p&gt;使うのは&lt;a href=&#34;https://redux.js.org/basics/usagewithreact&#34;&gt;React Redux&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add react-redux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;v5.0.7が入った。&lt;/p&gt;

&lt;h1 id=&#34;presentational-components-と-container-components&#34;&gt;Presentational Components と Container Components&lt;/h1&gt;

&lt;p&gt;React Reduxの使い方を理解するには、&lt;a href=&#34;https://medium.com/@dan_abramov/smart-and-dumb-components-7ca2f9a7c7d0&#34;&gt;Presentational Components と Container Components&lt;/a&gt; という概念を知らないといけない。
これはReactコンポーネントを役割別に分ける考え方で、それぞれ以下のような特徴をもつ。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Presentational Components&lt;/th&gt;
&lt;th&gt;Container Components&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;主な役割&lt;/td&gt;
&lt;td&gt;DOMをレンダリングする&lt;/td&gt;
&lt;td&gt;データを取得したりstateを更新したりする(Reduxとつなぐ)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Reduxとの関連&lt;/td&gt;
&lt;td&gt;無し&lt;/td&gt;
&lt;td&gt;有り&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;データの読み込み&lt;/td&gt;
&lt;td&gt;propsから読む&lt;/td&gt;
&lt;td&gt;Reduxのstateオブジェクトから読む&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;データの更新&lt;/td&gt;
&lt;td&gt;propsで渡されたコールバックを呼ぶ&lt;/td&gt;
&lt;td&gt;ReduxのActionをディスパッチする&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;作り方&lt;/td&gt;
&lt;td&gt;自前で書く&lt;/td&gt;
&lt;td&gt;React Reduxで生成する&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;要するに、普通にReactで作ったUIコンポーネントを、React Reduxで生成するContainer ComponentでラップしてやることでReduxのStoreとつなぐことができる。&lt;/p&gt;

&lt;h1 id=&#34;connect&#34;&gt;connect()&lt;/h1&gt;

&lt;p&gt;Container Componentの生成にはReact Reduxの&lt;a href=&#34;https://github.com/reduxjs/react-redux/blob/master/docs/api.md#connectmapstatetoprops-mapdispatchtoprops-mergeprops-options&#34;&gt;connect()&lt;/a&gt;というAPIを使う。&lt;/p&gt;

&lt;p&gt;React Reduxを使う場合、Reduxのstateの更新に応じてReactコンポーネントに新しいpropsを渡して再レンダリングすることになるが、この新しいpropsを作ってコンポーネントに渡す処理を定義するのが&lt;code&gt;connect()&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;connect()&lt;/code&gt;の第一引数には、ReduxのstateのプロパティとReactコンポーネントのpropsのプロパティとのマッピングをする関数である&lt;code&gt;mapStateToProps()&lt;/code&gt;を渡す。
&lt;code&gt;mapStateToProps()&lt;/code&gt;はstateの更新に応じて呼び出され、引数にstate(と現在のprops)が渡される。
&lt;code&gt;mapStateToProps()&lt;/code&gt;が返すオブジェクトはReactコンポーネントに渡されるpropsにマージされる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;connect()&lt;/code&gt;の第二引数には、Storeの&lt;code&gt;dispatch()&lt;/code&gt;を呼び出す処理とReactコンポーネントのpropsのプロパティとのマッピングをする関数である&lt;code&gt;mapDispatchToProps()&lt;/code&gt;を渡す。
&lt;code&gt;mapDispatchToProps()&lt;/code&gt;の引数には&lt;code&gt;dispatch()&lt;/code&gt;が渡される。
&lt;code&gt;mapDispatchToProps()&lt;/code&gt;が返すオブジェクトはReactコンポーネントに渡されるpropsにマージされる。&lt;/p&gt;

&lt;p&gt;(&lt;code&gt;mapDispatchToProps()&lt;/code&gt;は第二引数に&lt;code&gt;props&lt;/code&gt;を受け取ることもできて、この場合、propsの更新に反応して呼び出されるコールバックになる。)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;connect()&lt;/code&gt;を実行すると関数が返ってくる。
この関数にReactコンポーネント(Presentational Component)を渡して実行すると、Storeに接続されたReactコンポーネント(Container Component)が返ってくる。&lt;/p&gt;

&lt;h2 id=&#34;connect-の使い方&#34;&gt;connect()の使い方&lt;/h2&gt;

&lt;p&gt;前回作ったStoreをHOGEボタン(これはPresentational Component)につなげるContainer Componentを書いてみる。
Container Componentのソースは&lt;code&gt;src/containers/&lt;/code&gt;に入れる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/containers/HogeButton.jsx&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import React from &#39;react&#39;;
import Button from &#39;@material-ui/core/Button&#39;;
import { connect } from &#39;react-redux&#39;;
import { hogeButtonClicked } from &#39;../actions/actions&#39;;

function mapStateToProps(state) {
  return {
    clicked: state.hoge.clicked
  };
}

function mapDispatchToProps(dispatch) {
  return {
    onClick: function() {
      dispatch(hogeButtonClicked());
    }
  };
}

const HogeButton = connect(
  mapStateToProps,
  mapDispatchToProps,
)(Button);

export default HogeButton;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じ。&lt;/p&gt;

&lt;p&gt;HOGEボタンをクリックすると、以下の流れで状態が遷移する。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;hogeButtonClicked()&lt;/code&gt;が呼ばれて&lt;code&gt;HOGE_BUTTON_CLICKED&lt;/code&gt;アクションが生成されてdispatchされる。&lt;/li&gt;
&lt;li&gt;Storeの中で&lt;code&gt;state.hoge.clicked&lt;/code&gt;が更新される。&lt;/li&gt;
&lt;li&gt;stateの更新に反応して&lt;code&gt;mapStateToProps()&lt;/code&gt;が呼び出され、その戻り値がpropsにマージされる。&lt;/li&gt;
&lt;li&gt;新しいpropsを使って、新たにHOGEボタンがレンダリングされる。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;connect-のシンプルな書き方&#34;&gt;connect()のシンプルな書き方&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;mapDispatchToProps&lt;/code&gt;は実はプレーンオブジェクトでもいい。
この場合、オブジェクトのキーと値はそれぞれ、propsのプロパティ名とAction Creatorにする。
(Action Creatorは&lt;code&gt;connect()&lt;/code&gt;が&lt;code&gt;dispatch()&lt;/code&gt;でラップしてくれる。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const mapDispatchToProps ⁼ {
  onClick: hogeButtonClicked,
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;また、&lt;code&gt;mapStateToProps&lt;/code&gt;と&lt;code&gt;mapDispatchToProps&lt;/code&gt;はexportするわけでも再利用するわけでもないので、&lt;code&gt;connect()&lt;/code&gt;の中に直接書いてしまってもいい。
この場合、&lt;code&gt;mapStateToProps&lt;/code&gt;はアロー関数で書いて、&lt;code&gt;return&lt;/code&gt;は省略してしまうのがいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const HogeButton = connect(
  (state) =&amp;gt; ({
    clicked: state.hoge.clicked
  }),
  {
    onClick: hogeButtonClicked,
  },
)(Button);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;さらに、&lt;code&gt;mapStateToProps&lt;/code&gt;が受け取る&lt;code&gt;state&lt;/code&gt;は、&lt;code&gt;hoge&lt;/code&gt;プロパティしか興味ないので、オブジェクト分割代入をするのがいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const HogeButton = connect(
  ({hoge}) =&amp;gt; ({
    clicked: hoge.clicked
  }),
  {
    onClick: hogeButtonClicked,
  },
)(Button);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;まとめると、以下のように書けるということ。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/containers/HogeButton.jsx&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import React from &#39;react&#39;;
import Button from &#39;@material-ui/core/Button&#39;;
import { connect } from &#39;react-redux&#39;;
import { hogeButtonClicked } from &#39;../actions/actions&#39;;

const HogeButton = connect(
  ({hoge}) =&amp;gt; ({
    clicked: hoge.clicked
  }),
  {
    onClick: hogeButtonClicked,
  },
)(Button);

export default HogeButton;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;参考: &lt;a href=&#34;https://qiita.com/taneba/items/4d45d1075137a7dae10e&#34;&gt;シンプルなreact-reduxのconnectの書き方&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;reselect&#34;&gt;reselect&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;mapStateToProps&lt;/code&gt;はstateが更新されるたびに呼ばれるので、中で複雑な計算してたりするとアプリ全体のパフォーマンスに影響を与える。&lt;/p&gt;

&lt;p&gt;このような問題に対応するため、stateの特定のサブツリーが更新された時だけ&lt;code&gt;mapStateToProps&lt;/code&gt;の先の計算を実行できるようにするライブラリがある。
それが&lt;a href=&#34;https://github.com/reduxjs/reselect&#34;&gt;relesect&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;reselectは重要なライブラリだとは思うけど、とりあえずほって先に進む。&lt;/p&gt;

&lt;h1 id=&#34;hogebuttonのアプリへの組み込み&#34;&gt;HogeButtonのアプリへの組み込み&lt;/h1&gt;

&lt;p&gt;作ったHogeButtonは、普通のコンポーネントと同じように使える。&lt;/p&gt;

&lt;p&gt;components/App.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
 import styled from &#39;styled-components&#39;;
-import Button from &#39;@material-ui/core/Button&#39;;
+import HogeButton from &#39;../containers/HogeButton&#39;;

 const Wrapper = styled.div`
   font-size: 5rem;
 `;

 const App = () =&amp;gt; (
   &amp;lt;Wrapper&amp;gt;
-    &amp;lt;Button variant=&amp;quot;contained&amp;quot;&amp;gt;
+    &amp;lt;HogeButton variant=&amp;quot;contained&amp;quot;&amp;gt;
       HOGE
-    &amp;lt;/Button&amp;gt;
+    &amp;lt;/HogeButton&amp;gt;
   &amp;lt;/Wrapper&amp;gt;
 );

 export default App;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;provider&#34;&gt;Provider&lt;/h1&gt;

&lt;p&gt;全てのContainer ComponentsがReduxのStoreの変更をサブスクライブする必要があるので、それらに&lt;a href=&#34;https://redux.js.org/basics/usagewithreact#passing-the-store&#34;&gt;Storeを渡してやらないといけない&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;Storeをpropsに渡して、子コンポーネントにバケツリレーさせたりして行きわたらせることも可能だけど面倒すぎる。
ので、React Reduxがもっと簡単にやる仕組みを提供してくれている。
それが&lt;a href=&#34;https://github.com/reduxjs/react-redux/blob/master/docs/api.md#provider&#34;&gt;Provider&lt;/a&gt;というコンポーネント。&lt;/p&gt;

&lt;p&gt;Providerの子コンポーネントはStoreにアクセスして&lt;code&gt;connect()&lt;/code&gt;を使えるようになる。
ざっくり全体をProviderで囲ってやるのがいい。&lt;/p&gt;

&lt;p&gt;src/index.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
 import ReactDOM from &#39;react-dom&#39;;
+import { Provider } from &#39;react-redux&#39;;
 import App from &#39;./components/App&#39;;
+import configureStore from &#39;./configureStore&#39;;
 import &#39;./fonts.css&#39;;

+const store = configureStore();
 const root = document.getElementById(&#39;root&#39;);

 if (root) {
   ReactDOM.render(
-    &amp;lt;App /&amp;gt;,
+    &amp;lt;Provider store={store}&amp;gt;
+      &amp;lt;App /&amp;gt;
+    &amp;lt;/Provider&amp;gt;,
     root,
   );
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/10/07/creating-react-redux-app-from-scratch-08/&#34;&gt;次回&lt;/a&gt;は、ReduxにMiddlewareを追加して、非同期処理を実装する。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>React &#43; Reduxアプリケーションプロジェクトのテンプレートを作る ― その6: Redux</title>
          <link>https://www.kaitoy.xyz/2018/09/26/creating-react-redux-app-from-scratch-06/</link>
          <pubDate>Wed, 26 Sep 2018 23:03:04 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/09/26/creating-react-redux-app-from-scratch-06/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt;と&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;を学ぶために、開発環境というかプロジェクトテンプレートをスクラッチから作っている。
(最終的な成果は&lt;a href=&#34;https://github.com/kaitoy/react-redux-scaffold&#34;&gt;GitHub&lt;/a&gt;に置いた。)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/09/06/creating-react-redux-app-from-scratch-05/&#34;&gt;前回&lt;/a&gt;はMaterial-UIをセットアップした。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;reactの状態管理&#34;&gt;Reactの状態管理&lt;/h1&gt;

&lt;p&gt;Reactによるプログラミングをするとき、小さいUIコンポーネントをたくさん作って、それらを組み合わせてVirtual DOMツリーを作っておいて、そこにpropsをほうりこんでレンダリングする、という感じになる。
また、レンダリングした後はコンポーネントのstateをいじって状態を変化させる。&lt;/p&gt;

&lt;p&gt;このpropsやstateの扱いをReactの状態管理という。
propsやstateを適当にアドホックに設定してると、結局jQuery使ってるのとそんなに変わらなくなって辛くなるので、Reactの開発元であるFacebookは&lt;a href=&#34;https://facebook.github.io/flux/&#34;&gt;Flux&lt;/a&gt;というアーキテクチャを提案している。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/facebook/flux/raw/master/docs/img/flux-diagram-white-background.png&#34; alt=&#34;Flux&#34; title=&#34;Flux&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Fluxでは、単一の(またはドメイン毎くらいの単位の)オブジェクトでアプリケーション全体の状態(state)を表し、これをStoreに保持する。
ReactはStoreが保持するstateを受け取り、それをもとにViewをレンダリングする。
Viewに対するユーザの操作(など)はActionというオブジェクトで表現され、Dispatcherに渡され、Dispatcherに登録されたcallbackを通してstateを変化させる。&lt;/p&gt;

&lt;p&gt;データが常に一方向に流れて見通しがよく、各コンポーネントの独立性が高いのが特徴。
各コンポーネントは、受け取ったデータをピュアに処理すればよく、リアクティブにファンクショナルに実装できる。&lt;/p&gt;

&lt;h1 id=&#34;redux&#34;&gt;Redux&lt;/h1&gt;

&lt;p&gt;Fluxの実装、というか発展形がRedux。&lt;/p&gt;

&lt;p&gt;ReduxではFluxのDispatcher辺りがReducerに置き換わっている。
ReducerはActionと現在のstateから次のstateを計算する純粋関数。&lt;/p&gt;

&lt;p&gt;また、ReduxからはViewが切り離されていて、Actionによってstateを更新する状態管理ライブラリの役割に徹している。
ReactコンポーネントのイベントハンドラからActionオブジェクトを生成したり、更新したstateをReactに渡したりするつなぎ目は、別途&lt;a href=&#34;https://github.com/reduxjs/react-redux&#34;&gt;React Redux&lt;/a&gt;というライブラリが担当する。&lt;/p&gt;

&lt;p&gt;ReduxとReact Reduxについては、Qiitaの「&lt;a href=&#34;https://qiita.com/mpyw/items/a816c6380219b1d5a3bf&#34;&gt;たぶんこれが一番分かりやすいと思います React + Redux のフロー図解&lt;/a&gt;」という記事が分かりやすい。&lt;/p&gt;

&lt;p&gt;今回はReduxを導入する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add redux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Redux v4.0.0が入った。&lt;/p&gt;

&lt;p&gt;以降、現時点で唯一のUIコンポーネントであるHOGEボタンの状態管理を実装してみる。&lt;/p&gt;

&lt;h2 id=&#34;action&#34;&gt;Action&lt;/h2&gt;

&lt;p&gt;まず&lt;a href=&#34;https://redux.js.org/basics/actions&#34;&gt;Action&lt;/a&gt;を実装する。&lt;/p&gt;

&lt;p&gt;Actionオブジェクトはどんな形式でもいいけど、普通は&lt;a href=&#34;https://github.com/redux-utilities/flux-standard-action&#34;&gt;Flux Standard Action&lt;/a&gt;(FSA)にする。
FSAは以下のプロパティを持つプレーンオブジェクト。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;type: Action種別を示す文字列定数。必須。&lt;/li&gt;
&lt;li&gt;payload: Actionの情報を示す任意の型の値。任意。&lt;/li&gt;
&lt;li&gt;error: Actionがエラーを表すものかを示す boolean プロパティ。エラーなら true にして、payload にエラーオブジェクトをセットする。任意。&lt;/li&gt;
&lt;li&gt;meta: その他の情報を入れる任意の型の値。任意。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Actionのコードは、Actionのtypeに入れる値を定義する&lt;code&gt;actionTypes.js&lt;/code&gt;と、Action Creator(i.e. Actionオブジェクトを生成する関数)を定義する&lt;code&gt;actions.js&lt;/code&gt;からなり、ともに&lt;code&gt;src/actions/&lt;/code&gt;に置く。&lt;/p&gt;

&lt;p&gt;HOGEボタンをクリックしたときのAction、&lt;code&gt;HOGE_BUTTON_CLICKED&lt;/code&gt;を定義してみる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/actions/actionTypes.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;export const HOGE_BUTTON_CLICKED = &#39;HOGE_BUTTON_CLICKED&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;src/actions/actions.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import {
  HOGE_BUTTON_CLICKED,
} from &#39;./actionTypes&#39;;

export function hogeButtonClicked(payload) {
  return {
    type: HOGE_BUTTON_CLICKED,
    payload,
  };
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じ。&lt;/p&gt;

&lt;h2 id=&#34;reducer&#34;&gt;Reducer&lt;/h2&gt;

&lt;p&gt;次は&lt;a href=&#34;https://redux.js.org/basics/reducers&#34;&gt;Reducer&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;Reducerは、上記Action Creatorが生成するActionオブジェクトに対応して起動し、Store(後述)から現在のstateオブジェクトを受け取って、Actionオブジェクトのpayloadの値(など)に応じて新しいstateオブジェクトを作る。&lt;/p&gt;

&lt;p&gt;Reducerを書く前に、stateオブジェクトの構造を設計しておくことが推奨されている。
UIコンポーネント毎にプロパティを分けて、コンポーネント構造と同様の階層構造にしておけばだいたいよさそう。&lt;/p&gt;

&lt;p&gt;HOGEボタンに一つ、クリックしたかどうかの状態(&lt;code&gt;clicked&lt;/code&gt;)を持たせるとすると、stateオブジェクトは以下のようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;{
  hoge: {
    clicked: false,
  },
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Reducerはピュアじゃないといけないので、内部で&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E5%89%AF%E4%BD%9C%E7%94%A8_(%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0&#34;&gt;副作用&lt;/a&gt;を起こしてはいけない。
副作用とは、具体的には以下のようなもの。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;引数で与えられたオブジェクトを変更する。&lt;/li&gt;
&lt;li&gt;REST APIへのリクエストを送る。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(ログの出力も厳密には副作用なんだろうけど、それは許されてる気がする。)&lt;/p&gt;

&lt;p&gt;また、ピュアであるためには&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E5%8F%82%E7%85%A7%E9%80%8F%E9%81%8E%E6%80%A7&#34;&gt;参照透過性&lt;/a&gt;を持たないといけなくて、つまり同じ引数に対しては同じ戻り値を返さないといけないので、内部で&lt;code&gt;Date.now()&lt;/code&gt;とか&lt;code&gt;Math.random()&lt;/code&gt;とかを呼ぶのもダメ。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Reducerのコードは&lt;code&gt;src/reducers/&lt;/code&gt;に置く。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;HOGE_BUTTON_CLICKED&lt;/code&gt;が発生したら、&lt;code&gt;hoge&lt;/code&gt;の&lt;code&gt;clicked&lt;/code&gt;を&lt;code&gt;true&lt;/code&gt;にするReducer(&lt;code&gt;hoge()&lt;/code&gt;)は以下の感じに書ける。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/reducers/reducers.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { HOGE_BUTTON_CLICKED } from &#39;../actions/actionTypes&#39;;

const initialState = {
  hoge: {
    clicked: false,
  },
};

export function hoge(state = initialState, action) {
  switch (action.type) {
    case HOGE_BUTTON_CLICKED:
      const newHoge = {
        hoge: {
          clicked: true,
        },
      };
      return Object.assign({}, state, newHoge);
    default:
      return state;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;hoge()&lt;/code&gt;のポイントはたくさんある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;state&lt;/code&gt;と&lt;code&gt;action&lt;/code&gt;を引数に取る。前者が現在の状態を表すstateオブジェクトで、後者がActionオブジェクト。&lt;/li&gt;
&lt;li&gt;戻り値は新しい状態を表すstateオブジェクト。&lt;/li&gt;
&lt;li&gt;actionオブジェクトはどのActionを表すものかは分からないので、&lt;code&gt;action.type&lt;/code&gt;を見て&lt;code&gt;HOGE_BUTTON_CLICKED&lt;/code&gt;だけを処理するようにする。

&lt;ul&gt;
&lt;li&gt;知らないActionだったら(i.e. &lt;code&gt;default&lt;/code&gt;句のなかに来たら)、受け取ったstateオブジェクトをそのまま返す。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;アプリケーションの初期化時には&lt;code&gt;state&lt;/code&gt;に&lt;code&gt;undefined&lt;/code&gt;が渡されるので、それに備え、初期状態である&lt;code&gt;initialState&lt;/code&gt;をデフォルト引数に設定する。&lt;/li&gt;
&lt;li&gt;渡されたstateオブジェクトを変更してはいけないので、&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Global_Objects/Object/assign&#34;&gt;Object.assgin()&lt;/a&gt;に空オブジェクト&lt;code&gt;{}&lt;/code&gt;とともに&lt;code&gt;state&lt;/code&gt;を渡してコピーする。

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Object.assgin()&lt;/code&gt;の代わりに&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment#%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E3%81%AE%E5%88%86%E5%89%B2%E4%BB%A3%E5%85%A5&#34;&gt;オブジェクト分割代入&lt;/a&gt;を使う方法も&lt;a href=&#34;https://redux.js.org/recipes/usingobjectspreadoperator&#34;&gt;ある&lt;/a&gt;。この場合&lt;a href=&#34;https://babeljs.io/docs/en/babel-plugin-transform-object-rest-spread&#34;&gt;babel-plugin-transform-object-rest-spread&lt;/a&gt;が必要。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Object.assign()&lt;/code&gt;の第三引数に&lt;code&gt;newHoge&lt;/code&gt;で上書きするようにしている。

&lt;ul&gt;
&lt;li&gt;今はstateオブジェクトのプロパティが&lt;code&gt;hoge&lt;/code&gt;一つだけなので単に&lt;code&gt;newHoge&lt;/code&gt;をreturnしても結果は一緒。なので無駄なことをしてるようにも見えるけど、stateオブジェクトのプロパティが増えた場合に&lt;code&gt;hoge&lt;/code&gt;以外に影響を与えないための計らい。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これはこれでいい感じに見えるけど、&lt;code&gt;hoge()&lt;/code&gt;が&lt;code&gt;hoge&lt;/code&gt;プロパティしか扱わないのに、stateオブジェクト全体を渡しているのがイケていない。
(まあ今はstateオブジェクトには&lt;code&gt;hoge&lt;/code&gt;プロパティしかないんだけど、他のプロパティが色々増えてくるとイケてない感が高まる。)
&lt;code&gt;hoge&lt;/code&gt;プロパティがstateオブジェクト構造のどこにあるかを&lt;code&gt;hoge()&lt;/code&gt;が気にしないといけないのもイケてない。
&lt;code&gt;hoge()&lt;/code&gt;には&lt;code&gt;hoge&lt;/code&gt;プロパティだけを見てほしい。&lt;/p&gt;

&lt;p&gt;ということで、普通はReducerは分割して書いて、それぞれのReducerにstateオブジェクトを分割して渡してやる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/reducers/reducers.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import { HOGE_BUTTON_CLICKED } from &#39;../actions/actionTypes&#39;;

-const initialState = {
-  hoge: {
-    clicked: false,
-  },
-};

-export function hoge(state = initialState, action) {
+export function hoge(state = { clicked: false }, action) {
   switch (action.type) {
     case HOGE_BUTTON_CLICKED:
       const newHoge = {
-        hoge: {
-          clicked: true,
-        },
+        clicked: true,
       };
       return Object.assign({}, state, newHoge);
     default:
       return state;
   }
 }

+export function rootReducer(state = {}, action) {
+  return {
+    hoge: hoge(state.hoge, action),
+  }
+}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じで、&lt;code&gt;rootReducer()&lt;/code&gt;がstateオブジェクトを分割して子Reducerを呼び出す。
孫Reducerとか曾孫Reducerとかがあってもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;rootReducer()&lt;/code&gt;は別のファイルに書くと見やすくなるし、Reduxの&lt;a href=&#34;https://redux.js.org/api/combinereducers&#34;&gt;combineReducers()&lt;/a&gt;というヘルパー関数を使うともっと楽に書ける。
上記&lt;code&gt;reducers.js&lt;/code&gt;からは&lt;code&gt;rootReducer()&lt;/code&gt;を削除して、&lt;code&gt;rootReducer.js&lt;/code&gt;に以下のように書く。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/reducers/rootReducer.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { combineReducers } from &#39;redux&#39;;
import hoge from &#39;./reducers&#39;;

const rootReducer = combineReducers({
  hoge,
});
export default rootReducer;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このように&lt;code&gt;combineReducers()&lt;/code&gt;で作った&lt;code&gt;rootReducer&lt;/code&gt;は、上で自前で書いた&lt;code&gt;rootReducer&lt;/code&gt;と全く同じ動きをする。&lt;/p&gt;

&lt;p&gt;さらに簡単に、以下のようにも書ける。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/reducers/rootReducer.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { combineReducers } from &#39;redux&#39;;
import * as reducers from &#39;./reducers&#39;;

const rootReducer = combineReducers(reducers);
export default rootReducer;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こうしておけば、Reducerの追加は&lt;code&gt;reducers.js&lt;/code&gt;に関数を追加するだけでよくなる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/redux-utilities/redux-actions&#34;&gt;redux-actions&lt;/a&gt;を使うとさらに記述を簡略化できるみたいだけど、逆に何が何だか分からなくなりそうだったので、慣れるまでは使わないでおく。&lt;/p&gt;

&lt;h2 id=&#34;store&#34;&gt;Store&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://redux.js.org/basics/store&#34;&gt;Store&lt;/a&gt;は以下のような特徴を持つオブジェクト。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;getState()&lt;/code&gt;でstateオブジェクトを返す。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dispatch(action)&lt;/code&gt;でActionをディスパッチできる。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;subscribe(listener)&lt;/code&gt;でActionのディスパッチをサブスクライブできる。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;StoreはrootReducerを&lt;a href=&#34;https://redux.js.org/api/createstore&#34;&gt;createStore()&lt;/a&gt;に渡すことで作れる。
&lt;code&gt;createStore()&lt;/code&gt;を呼ぶコードはモジュールにしておくのがいい。
後で膨らんでくるので。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/configureStore.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { createStore } from &#39;redux&#39;;
import rootReducer from &#39;./reducers/rootReducer&#39;;

export default function configureStore(initialState = {}) {
  const store = createStore(
    rootReducer,
    initialState,
  );
  return store;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これだけ。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でReduxのコンポーネントが一通りそろって、状態管理システムができた。
試しに動かしてみる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;src/try.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { hogeButtonClicked } from &#39;./actions/actions&#39;;
import configureStore from &#39;./configureStore&#39;;

const store = configureStore();
console.log(store.getState()); // =&amp;gt; { hoge: {clicked: false} }

store.subscribe(() =&amp;gt; {
  console.log(store.getState());
});

store.dispatch(hogeButtonClicked()); // =&amp;gt; { hoge: {clicked: true} }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;store.dispatch()&lt;/code&gt;するとReducer(&lt;code&gt;hoge()&lt;/code&gt;)が実行され、stateオブジェクトが更新されることが分かる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/10/01/creating-react-redux-app-from-scratch-07/&#34;&gt;次回&lt;/a&gt;は、今回作ったStoreをReactコンポーネントにつなぐ。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>React &#43; Reduxアプリケーションプロジェクトのテンプレートを作る ― その5: Material-UIとWebフォント</title>
          <link>https://www.kaitoy.xyz/2018/09/06/creating-react-redux-app-from-scratch-05/</link>
          <pubDate>Thu, 06 Sep 2018 23:33:31 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/09/06/creating-react-redux-app-from-scratch-05/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt;と&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;を学ぶために、開発環境というかプロジェクトテンプレートをスクラッチから作っている。
(最終的な成果は&lt;a href=&#34;https://github.com/kaitoy/react-redux-scaffold&#34;&gt;GitHub&lt;/a&gt;に置いた。)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/29/creating-react-redux-app-from-scratch-04/&#34;&gt;前回&lt;/a&gt;はCSS周りの処理系をセットアップした。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;既成reactコンポーネント&#34;&gt;既成Reactコンポーネント&lt;/h1&gt;

&lt;p&gt;前回まででHTMLもCSSもReactコンポーネント単位で書けるようになったんだけど、実際、自分で1からコンポーネントを書くのは、特にデザインセンスがない人にとっては辛い。
かっこいいUIコンポーネントを作りたいならデザイナーの協力が必要だけど、個人の開発などそれができない状況も多い。&lt;/p&gt;

&lt;p&gt;という問題を抱えた人たち向けなのかはわからないが、既成のReactコンポーネントセットが色々OSSで提供されている。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://material-ui.com/&#34;&gt;Material-UI&lt;/a&gt;: Googleの&lt;a href=&#34;https://material.io/design/&#34;&gt;マテリアルデザイン&lt;/a&gt;のReact実装。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://react.semantic-ui.com/&#34;&gt;Semantic UI React&lt;/a&gt;: &lt;a href=&#34;https://semantic-ui.com/&#34;&gt;Semantic UI&lt;/a&gt;のReactバインディング。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ant.design/docs/react/introduce&#34;&gt;antd&lt;/a&gt;: &lt;a href=&#34;https://ant.design/&#34;&gt;Ant Design&lt;/a&gt;のReact実装。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blueprintjs.com/&#34;&gt;Blueprint&lt;/a&gt;: 複雑でデータ量の多いUI向けに作られたReact UIツールキット。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://react-bootstrap.github.io/&#34;&gt;React-Bootstrap&lt;/a&gt;: &lt;a href=&#34;https://getbootstrap.com/&#34;&gt;Bootstrap&lt;/a&gt;のReactバインディング。現時点ではv4未対応。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://grommet.io/&#34;&gt;Grommet&lt;/a&gt;: HPEによるエンタープライズレディなデザインシステム。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/fabric#/components&#34;&gt;Office UI Fabric React&lt;/a&gt;: OfficeなどのMicrosoft製品に使われているReactコンポーネントセット。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今回はこの中でも圧倒的に人気なMaterial-UIを導入する。&lt;/p&gt;

&lt;h1 id=&#34;material-ui&#34;&gt;Material-UI&lt;/h1&gt;

&lt;p&gt;Material-UIは簡単に使える。
とりあえずコアパッケージをインストールする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add @material-ui/core
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;v1.4.1が入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あとはパッケージに入っている色々なコンポーネントをMaterial-UIのドキュメント見ながら使えばいいだけ。&lt;/p&gt;

&lt;p&gt;components/App.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
 import styled from &#39;styled-components&#39;;
+import Button from &#39;@material-ui/core/Button&#39;;

 const Wrapper = styled.div`
   font-size: 5rem;
 `;

 const App = () =&amp;gt; (
   &amp;lt;Wrapper&amp;gt;
-    HOGE
+    &amp;lt;Button variant=&amp;quot;contained&amp;quot;&amp;gt;
+      HOGE
+    &amp;lt;/Button&amp;gt;
   &amp;lt;/Wrapper&amp;gt;
 );

 export default App;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これでただのテキストがボタンになった。&lt;/p&gt;

&lt;h1 id=&#34;css-web-fonts&#34;&gt;CSS Web Fonts&lt;/h1&gt;

&lt;p&gt;前節でいちおうMaterial-UI使えたけど、フォントをケアしてやるともう少しかっこよくなる。
Material-UIは&lt;a href=&#34;https://fonts.google.com/specimen/Roboto&#34;&gt;Robotoフォント&lt;/a&gt;を想定して作られているが、これはブラウザにデフォルトで入ってはいないので、そのままだとArialとかにフォールバックされちゃう。
のでRobotoフォントを導入する。&lt;/p&gt;

&lt;p&gt;フォントは&lt;a href=&#34;https://www.w3schools.com/css/css3_fonts.asp&#34;&gt;CSS Web Fonts&lt;/a&gt;の機能である&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/@font-face&#34;&gt;@font-face&lt;/a&gt;で、フォントファイルをブラウザにロードさせることで導入できる。
&lt;code&gt;@font-face&lt;/code&gt;で読み込むフォントファイル(i.e. &lt;code&gt;url()&lt;/code&gt;関数で指定するファイル)はwebpackでバンドルできる。&lt;/p&gt;

&lt;p&gt;Robotoフォントのフォントファイルはnpmで配布されていて、Yarnでプロジェクトにインストールできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add typeface-roboto
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;フォントファイルの種類は、OTFとかTTFとかWOFFとかWOFF2とかいろいろあるけど、&lt;a href=&#34;https://www.6666666.jp/design/20160218/&#34;&gt;この記事&lt;/a&gt;などをみるに、WOFFだけ使えばよさげ。&lt;/p&gt;

&lt;p&gt;フォントファイルのバンドルは&lt;a href=&#34;https://github.com/webpack-contrib/url-loader&#34;&gt;url-loader&lt;/a&gt;を使う方法と&lt;a href=&#34;https://github.com/webpack-contrib/file-loader&#34;&gt;file-loader&lt;/a&gt;を使う方法とがある。&lt;/p&gt;

&lt;h2 id=&#34;url-loaderを使う方法&#34;&gt;url-loaderを使う方法&lt;/h2&gt;

&lt;p&gt;url-loaderを使う場合は、url-loaderとフォールバック用のfile-loaderをインストールする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;yarn add -D url-loader file-loader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;webpackのローダ設定は以下のようなのを追加すればいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;(前略)
   module: {
     rules: [
(中略)
-      }
+      },
+      {
+        test: /\.(png|woff|woff2|eot|ttf|svg)$/,
+        include: [path.resolve(__dirname, &#39;node_modules/typeface-roboto&#39;)],
+        loader: &#39;url-loader&#39;,
+        options: {
+          limit: 100000,
+        },
+      },
     ],
   },
(後略)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あとは、typeface-robotoパッケージ内のフォントファイルを指すようにCSSに@font-faceを書けばいい。
例えば、weightが300のWOFFファイルを読むなら以下のような感じ。&lt;/p&gt;

&lt;p&gt;src/fonts.css:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;@font-face {
  font-family: &#39;Roboto&#39;;
  font-style: normal;
  font-display: swap;
  font-weight: 300;
  src: local(&#39;Roboto Light &#39;), local(&#39;Roboto-Light&#39;),
    url(&#39;../node_modules/typeface-roboto/files/roboto-latin-300.woff&#39;) format(&#39;woff&#39;);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これをどこかのJavaScriptでインポートしてやればいい。&lt;/p&gt;

&lt;p&gt;src/index.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
 import ReactDOM from &#39;react-dom&#39;;
 import App from &#39;./components/App&#39;;
+import &#39;./fonts.css&#39;;

 const root = document.getElementById(&#39;root&#39;);

 if (root) {
   ReactDOM.render(
     &amp;lt;App /&amp;gt;,
     root,
   );
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;けど、styled-componentsを使っている場合はurl-loaderは使えないみたいで、代わりにfile-loaderを使う必要がある。&lt;/p&gt;

&lt;h2 id=&#34;file-loaderを使う方法-styled-components&#34;&gt;file-loaderを使う方法 (styled-components)&lt;/h2&gt;

&lt;p&gt;file-loaderを使う場合は、file-loaderだけインストールすればいい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;yarn add -D file-loader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;webpackのローダ設定は以下のようなのを追加すればいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;(前略)
   module: {
     rules: [
(中略)
-      }
+      },
+      {
+        test: /\.(png|woff|woff2|eot|ttf|svg)$/,
+        include: [path.resolve(__dirname, &#39;node_modules&#39;)],
+        loader: &#39;file-loader&#39;,
+      },
     ],
   },
(後略)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、&lt;a href=&#34;https://github.com/styled-components/styled-components/issues/233&#34;&gt;ここ&lt;/a&gt;にある通り、styled-componentsの&lt;a href=&#34;https://www.styled-components.com/docs/api#injectglobal&#34;&gt;injectGlobal&lt;/a&gt;というAPIを使って、以下のようにフォントファイルを読み込む。&lt;/p&gt;

&lt;p&gt;src/font.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { injectGlobal } from &#39;styled-components&#39;;
import roboto300 from &#39;../node_modules/typeface-roboto/files/roboto-latin-300.woff&#39;;

injectGlobal`
  /* roboto-300normal - latin */
  @font-face {
    font-family: &#39;Roboto&#39;;
    font-style: normal;
    font-display: swap;
    font-weight: 300;
    src:
      local(&#39;Roboto Light &#39;),
      local(&#39;Roboto-Light&#39;),
      url(&#39;${roboto300}&#39;) format(&#39;woff&#39;);
  }
`;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あとはこれをどこかのJavaScriptでインポートしてやればいい。&lt;/p&gt;

&lt;p&gt;src/index.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
 import ReactDOM from &#39;react-dom&#39;;
 import App from &#39;./components/App&#39;;
+import &#39;./fonts&#39;;

 const root = document.getElementById(&#39;root&#39;);

 if (root) {
   ReactDOM.render(
     &amp;lt;App /&amp;gt;,
     root,
   );
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/09/26/creating-react-redux-app-from-scratch-06/&#34;&gt;次回&lt;/a&gt;はようやくReduxを導入する。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>React &#43; Reduxアプリケーションプロジェクトのテンプレートを作る ― その4: CSS ModulesとPostCSSとstylelintとstyled-components</title>
          <link>https://www.kaitoy.xyz/2018/08/29/creating-react-redux-app-from-scratch-04/</link>
          <pubDate>Wed, 29 Aug 2018 23:50:53 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/08/29/creating-react-redux-app-from-scratch-04/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt;と&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;を学ぶために、開発環境というかプロジェクトテンプレートをスクラッチから作っている。
(最終的な成果は&lt;a href=&#34;https://github.com/kaitoy/react-redux-scaffold&#34;&gt;GitHub&lt;/a&gt;に置いた。)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/23/creating-react-redux-app-from-scratch-03/&#34;&gt;前回&lt;/a&gt;はPrettierとESLintをセットアップした。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;css&#34;&gt;CSS&lt;/h1&gt;

&lt;p&gt;前回までで作った環境で、Reactを使ってHTMLのDOMツリーを構築することができるようになったが、これは基本的にUIに表示する情報の構造しか定義しない。
UIの見た目(スタイル)を決めるのはCSSなので、それをアプリに組み込むことを考えないといけない。&lt;/p&gt;

&lt;p&gt;組み込み方には現時点で大きく3通りある。&lt;/p&gt;

&lt;h2 id=&#34;cssを別途設計する&#34;&gt;CSSを別途設計する&lt;/h2&gt;

&lt;p&gt;一つ目はCSSを別途設計する方法。&lt;/p&gt;

&lt;p&gt;Reactコンポーネントからレンダリングされる要素にclassが付くようにしておいて、設計したCSSをbundle.jsとは別途読み込んでスタイルを適用することにはる。&lt;/p&gt;

&lt;p&gt;この場合、CSSのスタイル定義はすべてグローバルなので、設計効率やメンテナンス効率を維持しつつ、各コンポーネントに意図したスタイルが適用されるようにするため、テクニックを凝らしてCSSクラスを設計する必要がある。
例えば&lt;a href=&#34;https://en.bem.info/&#34;&gt;BEM&lt;/a&gt; (2009年3月誕生)、&lt;a href=&#34;http://oocss.org/&#34;&gt;OOCSS&lt;/a&gt; (2009年3月誕生)、&lt;a href=&#34;https://smacss.com/ja&#34;&gt;SMACSS&lt;/a&gt; (2011年9月誕生)、&lt;a href=&#34;https://github.com/hiloki/flocss&#34;&gt;FLOCSS&lt;/a&gt; (2014年4月誕生)など。&lt;/p&gt;

&lt;p&gt;CSS自体は、素のCSSを書くことはあまりなく、普通は&lt;a href=&#34;https://sass-lang.com/&#34;&gt;Sass&lt;/a&gt;などのAltCSSや&lt;a href=&#34;https://postcss.org/&#34;&gt;PostCSS&lt;/a&gt;を使って書く。&lt;/p&gt;

&lt;p&gt;さらに、&lt;a href=&#34;https://github.com/stylelint/stylelint&#34;&gt;stylelint&lt;/a&gt;でリンティングすることで、CSSの品質を上げられる。
リンティングルールは、stylelintプロジェクトから提供されている&lt;a href=&#34;https://github.com/stylelint/stylelint-config-recommended&#34;&gt;stylelint-config-recommended&lt;/a&gt;か&lt;a href=&#34;https://github.com/stylelint/stylelint-config-standard&#34;&gt;stylelint-config-standard&lt;/a&gt;を使えば十分。
後者がGoogleやAirbnbのCSSスタイルガイドを反映していていい感じ。&lt;/p&gt;

&lt;p&gt;書いたCSSは、webpackの&lt;a href=&#34;https://github.com/webpack-contrib/css-loader&#34;&gt;css-loader&lt;/a&gt;で読み込める。
webpackはJavaScriptの&lt;code&gt;import &#39;./App.css&#39;;&lt;/code&gt;みたいなコードを見つけると、css-loaderに処理を渡す。
css-loaderは、&lt;code&gt;import&lt;/code&gt;文で指定されたCSSファイルだけでなく、&lt;code&gt;@import&lt;/code&gt;や&lt;code&gt;url()&lt;/code&gt;で定義される依存関係をたどって関連するCSSを一通り読み込む。&lt;/p&gt;

&lt;p&gt;読み込んだCSSは、webpackの&lt;a href=&#34;https://github.com/webpack-contrib/style-loader&#34;&gt;style-loader&lt;/a&gt;を使ってDOMに適用できる。
style-loaderは、読み込んだCSSを&lt;code&gt;&amp;lt;style&amp;gt;&lt;/code&gt;タグで囲ってHTMLのヘッダに挿入してくれる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;CSSの処理にはPostCSSを使うとして、プロジェクトに以下のパッケージを追加する。
(PostCSSについては&lt;a href=&#34;https://qiita.com/morishitter/items/4a04eb144abf49f41d7d&#34;&gt;Qiitaの記事&lt;/a&gt;が参考になった。)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;css-loader: CSSを読み込むためのwebpackのローダ。&lt;/li&gt;
&lt;li&gt;style-loader: CSSをDOMに追加するためのwebpackのローダ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/postcss/postcss-loader&#34;&gt;postcss-loader&lt;/a&gt;: PostCSSを実行するためのwebpackのローダ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://preset-env.cssdb.org/&#34;&gt;postcss-preset-env&lt;/a&gt;: CSSのエッジな機能を使うためのPostCSSプラグイン。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/postcss/autoprefixer&#34;&gt;autoprefixer&lt;/a&gt;: CSSプロパティにベンダプレフィックスを追加してくれるPostCSSプラグイン。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/luisrudge/postcss-flexbugs-fixes&#34;&gt;postcss-flexbugs-fixes&lt;/a&gt;: &lt;a href=&#34;https://www.w3schools.com/css/css3_flexbox.asp&#34;&gt;Flexbox&lt;/a&gt;のバグを修正してくれるPostCSSプラグイン。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cssnano/cssnano&#34;&gt;cssnano&lt;/a&gt;: CSSをミニファイしてくれるPostCSSプラグイン。&lt;/li&gt;
&lt;li&gt;stylelint: CSSのリンタ。&lt;/li&gt;
&lt;li&gt;stylelint-config-standard: stylelintのルール設定集。&lt;/li&gt;
&lt;li&gt;stylelint-config-prettier: &lt;a href=&#34;https://prettier.io/&#34;&gt;Prettier&lt;/a&gt;が施すコード整形とコンフリクトするルールを無効にするstylelintルール設定集。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D css-loader style-loader postcss-loader postcss-preset-env autoprefixer postcss-flexbugs-fixes cssnano stylelint stylelint-config-standard stylelint-config-prettier
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;PostCSSとstylelintの設定は、それぞれpostcss.config.jsとstylelint.config.jsを書いてプロジェクトルートに置けばいい。&lt;/p&gt;

&lt;p&gt;postcss.config.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;module.exports = {
  plugins: {
    stylelint: {},
    &#39;postcss-preset-env&#39;: {},
    autoprefixer: {},
    &#39;postcss-flexbugs-fixes&#39;: {},
    cssnano: {},
  },
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;stylelint.config.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;module.exports = {
  extends: [&#39;stylelint-config-standard&#39;, &#39;stylelint-config-prettier&#39;],
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;stylelintはPostCSSのプラグインとしてPostCSSから実行する構成。&lt;/p&gt;

&lt;p&gt;stylelint.config.jsで、stylelint-config-prettierはextendsの最後に書く必要があることに注意。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;webpackにもローダの設定を追加する。&lt;/p&gt;

&lt;p&gt;webpack.common.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; (前略)
       {
         test: /\.(js|jsx)$/,
         include: [path.resolve(__dirname, &#39;src&#39;)],
         loader: &#39;babel-loader&#39;,
       },
+      {
+        test: /\.css$/,
+        include: [path.resolve(__dirname, &#39;src&#39;)],
+        use: [
+          &#39;style-loader&#39;,
+          {
+            loader: &#39;css-loader&#39;,
+            options: {
+              importLoaders: 1,
+            },
+          },
+          &#39;postcss-loader&#39;,
+        ],
+      },
     ],
   },
 (後略)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここで追加した設定は、&lt;code&gt;&amp;lt;プロジェクトルート&amp;gt;/src&lt;/code&gt;ディレクトリ内の&lt;code&gt;.css&lt;/code&gt;ファイルが&lt;code&gt;import&lt;/code&gt;されたら、postcss-loader、css-loader、style-loaderの順にそのファイルを処理する、というもの。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;実際のCSSは普通に書いて、JavaScriptからimportしてやればいい。&lt;/p&gt;

&lt;p&gt;components/App.css:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.normal {
  font-size: 5rem;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;components/App.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
+import &#39;./App.css&#39;

 const App = () =&amp;gt; (
-  &amp;lt;div&amp;gt;
+  &amp;lt;div className=&amp;quot;normal&amp;quot;&amp;gt;
     HOGE
   &amp;lt;/div&amp;gt;
 );

 export default App;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;JSXでHTML要素にclass属性を付けるには、classNameプロパティを使うことに注意。&lt;/p&gt;

&lt;p&gt;これでHOGEに&lt;code&gt;font-size: 5rem&lt;/code&gt;が適用され、文字が大きくなる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でCSSを適用できた。&lt;/p&gt;

&lt;p&gt;これはこれで十分で柔軟なやりかただけど、BEMなどでCSSクラスの設計を頑張る手間がある。
UIコンポーネントの構造とスタイルの構造を1対1対応させるなら、もっと楽な方法がある。&lt;/p&gt;

&lt;h2 id=&#34;css-modules&#34;&gt;CSS Modules&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/css-modules/css-modules&#34;&gt;CSS Modules&lt;/a&gt;は2015年9月に&lt;a href=&#34;https://postd.cc/css-modules/&#34;&gt;発表&lt;/a&gt;された技術で、一つのCSSファイルを一つのモジュールと考え、モジュールごとにCSSクラス名の名前空間を自動生成し、スタイルの影響範囲をモジュールに閉じ込めてくれるもの。
(実際には、子要素に継承されるプロパティもあるので完全に閉じ込められるわけではない。)&lt;/p&gt;

&lt;p&gt;ReactによるUIコンポーネントごとにCSSモジュールを作り、コンポーネント単位でスタイリングすることを意図した技術であり、コンポーネント内で閉じたCSSクラス設計をすればいいだけになり、BEMとかを考えなくてよくなる。&lt;/p&gt;

&lt;p&gt;CSS Modulesを使うには、&lt;a href=&#34;https://github.com/gajus/babel-plugin-react-css-modules&#34;&gt;babel-plugin-react-css-modules&lt;/a&gt;というBabelのプラグインをセットアップすればいい。
まずはそれをプロジェクトにインストールする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D babel-plugin-react-css-modules
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Babelの設定を修正してインストールしたbabel-plugin-react-css-modulesを使うようにする。&lt;/p&gt;

&lt;p&gt;.babelrc&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; {
-  &amp;quot;presets&amp;quot;: [&amp;quot;env&amp;quot;, &amp;quot;react&amp;quot;]
+  &amp;quot;presets&amp;quot;: [&amp;quot;env&amp;quot;, &amp;quot;react&amp;quot;],
+  &amp;quot;plugins&amp;quot;: [&amp;quot;react-css-modules&amp;quot;]
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;webpackのcss-loaderのオプションを追加して、CSS Modulesを有効にする。&lt;/p&gt;

&lt;p&gt;webpack.common.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; (前略)
       {
         test: /\.css$/,
         include: [path.resolve(__dirname, &#39;src&#39;)],
         use: [
           &#39;style-loader&#39;,
           {
             loader: &#39;css-loader&#39;,
             options: {
               importLoaders: 1,
+              modules: true,
+              localIdentName: &#39;[path]___[name]__[local]___[hash:base64:5]&#39;,
             },
           },
           &#39;postcss-loader&#39;,
         ],
       },
 (後略)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;modules&lt;/code&gt;がCSS Modulesを有効化するスイッチ。
&lt;code&gt;localIdentName&lt;/code&gt;はモジュール化したCSSクラスの命名規則で、babel-plugin-react-css-modulesの設定と合っている必要がある。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あとは、コンポーネントの方で&lt;code&gt;className&lt;/code&gt;プロパティを&lt;code&gt;styleName&lt;/code&gt;プロパティに変えればいい。&lt;/p&gt;

&lt;p&gt;components/App.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
 import &#39;./App.css&#39;

 const App = () =&amp;gt; (
-  &amp;lt;div className=&amp;quot;normal&amp;quot;&amp;gt;
+  &amp;lt;div styleName=&amp;quot;normal&amp;quot;&amp;gt;
     HOGE
   &amp;lt;/div&amp;gt;
 );

 export default App;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でCSS Modulesの設定は完了。
App.cssに書いたクラス名はcss-loaderによって変換され、App.jsxに書いたstyleNameはbabel-plugin-react-css-modulesによって変換され、どちらも&lt;code&gt;src-components-___App__normal___1fxGx&lt;/code&gt;になるようになる。&lt;/p&gt;

&lt;h2 id=&#34;css-in-js&#34;&gt;CSS in JS&lt;/h2&gt;

&lt;p&gt;3つめはCSS in JS。&lt;/p&gt;

&lt;p&gt;これは2014年11月に&lt;a href=&#34;https://speakerdeck.com/vjeux/react-css-in-js&#34;&gt;提唱された&lt;/a&gt;技術で、UIコンポーネントとそのスタイルを両方一つのJavaScriptファイルに書いて、完全に一体化させるというもの。&lt;/p&gt;

&lt;p&gt;CSS in JSはCSS Modulesの陰でしばらく目立たなかったが、2016年に&lt;a href=&#34;https://www.styled-components.com/&#34;&gt;styled-components&lt;/a&gt;という実装がリリースされて注目され、その後いくつかの実装が生まれた。
styled-componentsは2017年ころからCSS Modulesに代わって人気になり、&lt;a href=&#34;https://postd.cc/stop-using-css-in-javascript-for-web-development-fa/&#34;&gt;CSS Modules陣営からの反撃&lt;/a&gt;もあったものの、今日まで支持を増やしている模様。
SassやPostCSSなど既存のCSSエコシステムを切り捨てているのと、React限定なのが気になるところではあるが、時流に乗って使ってみることにする。&lt;/p&gt;

&lt;p&gt;なお、CSS in JSはCSS Modulesとセットアップ方法がかなり異なるので、本稿前節までの変更はいったん全部破棄する。&lt;/p&gt;

&lt;p&gt;styled-componentsを使う場合、プロジェクトに追加する必要があるのは二つだけ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;styled-components: styled-components本体。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/styled-components/babel-plugin-styled-components&#34;&gt;babel-plugin-styled-components&lt;/a&gt;: styled-componentsのサポートを強化するBabelプラグイン。実際には必須ではないけど、バンドルサイズを削減出来たり、SSRしやすくなったりする。ベンダプレフィックスの付与とかミニファイもしてくれる。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add styled-components
yarn add -D babel-plugin-styled-components
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;styled-componentsはv3.4.4が入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Babelの設定は以下のように修正する。&lt;/p&gt;

&lt;p&gt;.babelrc&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; {
-  &amp;quot;presets&amp;quot;: [&amp;quot;env&amp;quot;, &amp;quot;react&amp;quot;]
+  &amp;quot;presets&amp;quot;: [&amp;quot;env&amp;quot;, &amp;quot;react&amp;quot;],
+  &amp;quot;plugins&amp;quot;: [&amp;quot;styled-components&amp;quot;]
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;App.jsxは、styled-componentsのstyledというAPIを使ってWrapperコンポーネント(スタイル付きdiv)を定義し、これをdivと置き換える。&lt;/p&gt;

&lt;p&gt;components/App.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; import React from &#39;react&#39;;
+import styled from &#39;styled-components&#39;;

+const Wrapper = styled.div`
+  font-size: 5rem;
+`;

 const App = () =&amp;gt; (
-  &amp;lt;div&amp;gt;
+  &amp;lt;Wrapper&amp;gt;
     HOGE
-  &amp;lt;/div&amp;gt;
+  &amp;lt;/Wrapper&amp;gt;
 );

 export default App;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これだけ。CSS Modulesに比べて大分シンプル。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;styled.div&lt;/code&gt;でスタイルを記述している部分は見慣れない構文だけど、ECMAScript 2015で追加されたタグ付きテンプレートリテラルという構文で、テンプレート文字列の一種。
ここに書くスタイルの構文はCSSと全く一緒。
JavaScriptの構文としては単なる文字列なので、変数を使ったり、if文とかで動的に変えたり、数値を計算したり、自由に書ける。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ややややこしいが、&lt;a href=&#34;https://www.styled-components.com/docs/tooling#stylelint&#34;&gt;stylelintによるリンティング&lt;/a&gt;もできる。
以下のパッケージをプロジェクトに追加する。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;stylelint: CSSのリンタ。(既出)&lt;/li&gt;
&lt;li&gt;stylelint-config-standard: stylelintのルール設定集。(既出)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/styled-components/stylelint-processor-styled-components&#34;&gt;stylelint-processor-styled-components&lt;/a&gt;: スタイル付きコンポーネントからスタイル定義を抽出するstylelintのカスタムプロセッサ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/styled-components/stylelint-config-styled-components&#34;&gt;stylelint-config-styled-components&lt;/a&gt;: stylelint-processor-styled-componentsを使うのに必要なstylelint設定集。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/emilgoldsmith/stylelint-custom-processor-loader&#34;&gt;stylelint-custom-processor-loader&lt;/a&gt;: stylelintでカスタムプロセッサを使う場合に必要なwebpackのローダ。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D stylelint stylelint-config-standard stylelint-processor-styled-components stylelint-config-styled-components stylelint-custom-processor-loader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;stylelintの設定は以下。&lt;/p&gt;

&lt;p&gt;stylelint.config.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;module.exports = {
  processors: [&#39;stylelint-processor-styled-components&#39;],
  extends: [&#39;stylelint-config-standard&#39;, &#39;stylelint-config-styled-components&#39;],
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;webpackの設定にstylelint-custom-processor-loaderの設定を追加する。&lt;/p&gt;

&lt;p&gt;webpack.common.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; (前略)
       {
         test: /\.(js|jsx)$/,
         include: [path.resolve(__dirname, &#39;src&#39;)],
         loader: &#39;babel-loader&#39;,
       },
+      {
+        test: /\.(js|jsx)$/,
+        include: [path.resolve(__dirname, &#39;src&#39;)],
+        enforce: &#39;pre&#39;,
+        loader: &#39;stylelint-custom-processor-loader&#39;,
+      },
     ],
   },
 (後略)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これでstyled-componentsにstylelintを適用できた。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/09/06/creating-react-redux-app-from-scratch-05/&#34;&gt;次回&lt;/a&gt;は&lt;a href=&#34;https://material-ui.com/&#34;&gt;Material-UI&lt;/a&gt;を導入する。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>React &#43; Reduxアプリケーションプロジェクトのテンプレートを作る ― その3: PrettierとESLint</title>
          <link>https://www.kaitoy.xyz/2018/08/23/creating-react-redux-app-from-scratch-03/</link>
          <pubDate>Thu, 23 Aug 2018 00:19:09 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/08/23/creating-react-redux-app-from-scratch-03/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt;と&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;を学ぶために、開発環境というかプロジェクトテンプレートをスクラッチから作っている。
(最終的な成果は&lt;a href=&#34;https://github.com/kaitoy/react-redux-scaffold&#34;&gt;GitHub&lt;/a&gt;に置いた。)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/22/creating-react-redux-app-from-scratch-02/&#34;&gt;前回&lt;/a&gt;はReactをセットアップした。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;フォーマッタとリンタ&#34;&gt;フォーマッタとリンタ&lt;/h1&gt;

&lt;p&gt;プロジェクトにフォーマッタとリンタを導入する。&lt;/p&gt;

&lt;p&gt;フォーマッタはソースの体裁を整えるツール。
フォーマッタを使うことで体裁が統一され、ソースが読みやすくなり、品質向上につながる。&lt;/p&gt;

&lt;p&gt;リンタはソースを静的解析して、潜在的なバグ、構造的な問題、体裁の問題を検出して警告してくれるツール。
フォーマッタは体裁だけ整えるのに対し、リンタは論理構造にも制約を課せるので、コーディングスタイルがより統一できたり、ミスをしやすい論理構造が無くなったりして、品質向上につながる。&lt;/p&gt;

&lt;p&gt;JavaScriptのような動的型付け言語では、実行時まで顕在化しないバグを作りこみやすく、また実行時エラーの原因解析が静的型付け言語に比べて難しいので、フォーマッタとリンタでプログラム実行前に問題をできるだけ取り除いておくのが重要。
またチーム開発では、コードレビューでコーディンスタイルを見る必要がなくなり、効率化につながる。&lt;/p&gt;

&lt;h2 id=&#34;prettier&#34;&gt;Prettier&lt;/h2&gt;

&lt;p&gt;フォーマッタには&lt;a href=&#34;https://prettier.io/&#34;&gt;Prettier&lt;/a&gt;を使う。&lt;/p&gt;

&lt;p&gt;Prettierは&lt;a href=&#34;https://jlongster.com/A-Prettier-Formatter&#34;&gt;2017年1月&lt;/a&gt;にリリースされた新しいツール。
構文解析をして&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E6%8A%BD%E8%B1%A1%E6%A7%8B%E6%96%87%E6%9C%A8&#34;&gt;AST&lt;/a&gt;を構築し、そこからフォーマット済みコードを出力するので、従来のツールよりも厳密な整形(e.g. 行の最大長を考慮した整形)ができる。&lt;/p&gt;

&lt;p&gt;また、opinionated(独断的)であることも特徴で、Prettierプロジェクトが推奨するフォーマットをほぼ強制し、設定がほとんどない。
このため導入が簡単だけど、かゆいところに手が届かないこともある。&lt;/p&gt;

&lt;p&gt;JavaScriptの他、JSX、CSS、Markdown、GraphQLのフォーマットにも対応している。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;まずプロジェクトにインストールする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D prettier
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;v1.14.0が入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://prettier.io/docs/en/options.html&#34;&gt;設定&lt;/a&gt;は&lt;code&gt;prettier.config.js&lt;/code&gt;という&lt;a href=&#34;https://prettier.io/docs/en/configuration.html&#34;&gt;ファイル&lt;/a&gt;を書いてプロジェクトルートに置けばいい。&lt;/p&gt;

&lt;p&gt;prettier.config.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;module.exports = {
  printWidth: 100, // 行の最大長
  tabWidth: 2, // インデント長
  singleQuote: true, // 文字列をシングルクオートで囲う
  trailingComma: &#39;all&#39;, // オブジェクトのプロパティとか関数の引数を複数行で書いたときに、全行の末尾にカンマをつける
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;また、フォーマット対象外のファイルを指定するファイルである&lt;code&gt;.prettierignore&lt;/code&gt;をプロジェクトルートに置く。&lt;/p&gt;

&lt;p&gt;.prettierignore:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;node_modules/
dist/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;node_modulesはnpmパッケージが入るディレクトリ。
実際はnode_modulesはデフォルトで無視されるから書かなくていいんだけど。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://prettier.io/docs/en/ignore.html&#34;&gt;prettier-ignoreコメント&lt;/a&gt;を書くことで、ソースを部分的にフォーマット対象外とすることもできる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;最後に、npmスクリプトを書く。&lt;/p&gt;

&lt;p&gt;package.json:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; (前略)
   &amp;quot;scripts&amp;quot;: {
+    &amp;quot;format&amp;quot;: &amp;quot;prettier --write **/*.jsx **/*.js **/*.css&amp;quot;,
     &amp;quot;build&amp;quot;: &amp;quot;webpack --config webpack.prod.js&amp;quot;,
     &amp;quot;start&amp;quot;: &amp;quot;webpack-dev-server --hot --config webpack.dev.js&amp;quot;
   },
 (後略)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで、&lt;code&gt;yarn format&lt;/code&gt;を実行するとプロジェクト内ソースを一通りフォーマットできる。&lt;/p&gt;

&lt;h2 id=&#34;eslint&#34;&gt;ESLint&lt;/h2&gt;

&lt;p&gt;リンタにはデファクトスタンダードの&lt;a href=&#34;https://eslint.org/&#34;&gt;ESLint&lt;/a&gt;を使う。&lt;/p&gt;

&lt;p&gt;ESLintは2013年6月にリリースされたそこそこ歴史のあるツール。
リンティングルールがプラガブルで、豊富なルールを細かく制御できるのが特徴。
フォーマッタとしての機能もあるけど、そこはPrettierにまかせることにする。&lt;/p&gt;

&lt;p&gt;JavaScriptもJSXもリンティングできる。&lt;/p&gt;

&lt;p&gt;リンティングルールはAirbnbによる&lt;a href=&#34;https://github.com/airbnb/javascript/tree/master/packages/eslint-config-airbnb&#34;&gt;eslint-config-airbnb&lt;/a&gt;が有名なのでこれを使う。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ESLintを導入するために、以下のパッケージをプロジェクトにインストールする。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;eslint: ESLint本体。&lt;/li&gt;
&lt;li&gt;eslint-loader: webpackからESLintを実行するやつ。&lt;/li&gt;
&lt;li&gt;eslint-config-airbnb: ESLintルール設定集。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/benmosher/eslint-plugin-import&#34;&gt;eslint-plugin-import&lt;/a&gt;: eslint-config-airbnbのピア依存。import文を処理するためのESLintプラグイン。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/evcohen/eslint-plugin-jsx-a11y&#34;&gt;eslint-plugin-jsx-a11y&lt;/a&gt;: eslint-config-airbnbのピア依存。JSXを処理するためのESLintプラグイン。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/yannickcr/eslint-plugin-react&#34;&gt;eslint-plugin-react&lt;/a&gt;: eslint-config-airbnbのピア依存。React特有のリンティングルールを追加するESLintプラグイン。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/prettier/eslint-config-prettier&#34;&gt;eslint-config-prettier&lt;/a&gt;: Prettierが施すコード整形とコンフリクトするルールを無効にするESLintルール設定集。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ピア依存をインストールするのにはちょっとコツがいるので、&lt;a href=&#34;https://github.com/airbnb/javascript/tree/master/packages/eslint-config-airbnb#eslint-config-airbnb-1&#34;&gt;eslint-config-airbnbのドキュメント&lt;/a&gt;を参照すべし。&lt;/p&gt;

&lt;p&gt;今回は以下のコマンドでインストールした。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D &amp;quot;eslint@&amp;gt;=1.6.0 &amp;lt;5.0.0&amp;quot; eslint-loader eslint-config-airbnb &amp;quot;eslint-plugin-import@^2.12.0&amp;quot; &amp;quot;eslint-plugin-jsx-a11y@^6.0.3&amp;quot; &amp;quot;eslint-plugin-react@^7.9.1&amp;quot; eslint-config-prettier
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ESlintはv4.19.1が入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://eslint.org/docs/user-guide/configuring&#34;&gt;ESlintの設定&lt;/a&gt;は、設定ファイルである&lt;code&gt;.eslintrc.js&lt;/code&gt;をプロジェクトルートに置けばいい。&lt;/p&gt;

&lt;p&gt;.eslintrc.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;module.exports = {
  env: {
    browser: true,
  },
  extends: [&#39;airbnb&#39;, &#39;prettier&#39;],
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;アプリの実行環境はブラウザなので&lt;code&gt;env.browser&lt;/code&gt;をtrueにしている。
これにより、ブラウザ環境でデフォルトで使えるグローバル変数(e.g. &lt;code&gt;document&lt;/code&gt;)を使うときにESLintに怒られないようになる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;extends&lt;/code&gt;は&lt;code&gt;eslint-config-airbnb&lt;/code&gt;と&lt;code&gt;eslint-config-prettier&lt;/code&gt;のルール設定を取り込むように書いている。
&lt;code&gt;prettier&lt;/code&gt;が最後でなければいけないことに注意。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;また、&lt;a href=&#34;https://eslint.org/docs/user-guide/configuring#ignoring-files-and-directories&#34;&gt;リンティング対象外のファイルを指定するファイル&lt;/a&gt;をプロジェクトルートに置く。&lt;/p&gt;

&lt;p&gt;.eslintignore:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;node_modules/*
dist/*
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;node_modulesはnpmパッケージが入るディレクトリ。
実際はnode_modulesはデフォルトで無視されるから書かなくていいんだけど。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://eslint.org/docs/user-guide/configuring#disabling-rules-with-inline-comments&#34;&gt;eslint-disableコメント&lt;/a&gt;を書くことで、ソースを部分的にリンティング対象外としたり、特定のルールを無効化することもできる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;webpackからESLintを実行し、エラーがなくならない限りビルド成功できないようにする。&lt;/p&gt;

&lt;p&gt;webpack.common.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; (前略)
   module: {
     rules: [
+      {
+        test: /\.(js|jsx)$/,
+        include: [path.resolve(__dirname, &#39;src&#39;)],
+        enforce: &#39;pre&#39;,
+        loader: &#39;eslint-loader&#39;,
+        options: {
+          configFile: &#39;./.eslintrc.js&#39;,
+          failOnError: true,
+        },
       },
       {
         test: /\.(js|jsx)$/,
         include: [path.resolve(__dirname, &#39;src&#39;)],
         loader: &#39;babel-loader&#39;,
       },
     ],
   },
 (後略)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あとはnpmスクリプト書くだけ。&lt;/p&gt;

&lt;p&gt;package.json:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; (前略)
   &amp;quot;scripts&amp;quot;: {
     &amp;quot;format&amp;quot;: &amp;quot;prettier --write **/*.jsx **/*.js **/*.css&amp;quot;,
+    &amp;quot;lint&amp;quot;: &amp;quot;eslint **/*.jsx **/*.js&amp;quot;,
     &amp;quot;build&amp;quot;: &amp;quot;webpack --config webpack.prod.js&amp;quot;,
     &amp;quot;start&amp;quot;: &amp;quot;webpack-dev-server --hot --config webpack.dev.js&amp;quot;
   },
 (後略)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで、&lt;code&gt;yarn lint&lt;/code&gt;を実行するとプロジェクト内ソースを一通りリンティングできる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上で、フォーマッタとリンタを導入できた。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/29/creating-react-redux-app-from-scratch-04/&#34;&gt;次回&lt;/a&gt;はCSS周りの処理系を追加する。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>React &#43; Reduxアプリケーションプロジェクトのテンプレートを作る ― その2: React</title>
          <link>https://www.kaitoy.xyz/2018/08/22/creating-react-redux-app-from-scratch-02/</link>
          <pubDate>Wed, 22 Aug 2018 08:21:28 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/08/22/creating-react-redux-app-from-scratch-02/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt;と&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;を学ぶために、開発環境というかプロジェクトテンプレートをスクラッチから作っている。
(最終的な成果は&lt;a href=&#34;https://github.com/kaitoy/react-redux-scaffold&#34;&gt;GitHub&lt;/a&gt;に置いた。)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/19/creating-react-redux-app-from-scratch-01/&#34;&gt;前回&lt;/a&gt;はNode.jsとYarnとBabelとwebpackをセットアップした。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;reactとは&#34;&gt;Reactとは&lt;/h1&gt;

&lt;p&gt;以前にも同じような事を書いたけど、改めてReactについて書く。
ちょっとコーディングの詳細にも触れながら。&lt;/p&gt;

&lt;p&gt;ReactはViewを記述するためのライブラリで、特徴は&lt;a href=&#34;https://reactjs.org/docs/faq-internals.html&#34;&gt;Virtual DOM&lt;/a&gt;と&lt;a href=&#34;https://reactjs.org/docs/introducing-jsx.html&#34;&gt;JSX&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;virtual-dom&#34;&gt;Virtual DOM&lt;/h2&gt;

&lt;p&gt;Virtual DOMはDOMを仮想化するもので、JavaScriptからVirtual DOMでUIを記述してやると、それが実DOMに効率的に反映されるようになっている。&lt;/p&gt;

&lt;h2 id=&#34;jsx&#34;&gt;JSX&lt;/h2&gt;

&lt;p&gt;Virtual DOMはJSXというHTMLみたいな言語で記述できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import React from &#39;react&#39;;
import ReactDOM from &#39;react-dom&#39;;

ReactDOM.render(
  &amp;lt;h1&amp;gt;Hello, world!&amp;lt;/h1&amp;gt;,
  document.getElementById(&#39;root&#39;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな風に書くと、idが&lt;code&gt;root&lt;/code&gt;であるHTML要素の中に、&lt;code&gt;&amp;lt;h1&amp;gt;Hello, world!&amp;lt;/h1&amp;gt;&lt;/code&gt;がレンダリングされる。
上記コードの&lt;code&gt;&amp;lt;h1&amp;gt;Hello, world!&amp;lt;/h1&amp;gt;&lt;/code&gt;の部分がJSX。&lt;/p&gt;

&lt;h2 id=&#34;コンポーネント&#34;&gt;コンポーネント&lt;/h2&gt;

&lt;p&gt;JSXではコンポーネントを定義して新たなタグとして使うことができるので、再利用できるコンポーネントを作って、それらを組み合わせてUIを構築することで、効率的な開発ができる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import React from &#39;react&#39;;
import ReactDOM from &#39;react-dom&#39;;

// Welcomeコンポーネントの定義
function Welcome() {
  return &amp;lt;h1&amp;gt;Hello, World&amp;lt;/h1&amp;gt;;
}

// Welcomeコンポーネントのレンダリング
ReactDOM.render(
  &amp;lt;Welcome /&amp;gt;,
  document.getElementById(&#39;root&#39;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上記コードではコンポーネントをfunctionで定義しているが、アロー関数で書いても全く一緒。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const Welcome = () =&amp;gt; (
  &amp;lt;h1&amp;gt;Hello, World&amp;lt;/h1&amp;gt;;
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;関数の代わりにclassで定義することもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;class Welcome extends React.Component {
  render() {
    return &amp;lt;h1&amp;gt;Hello, World&amp;lt;/h1&amp;gt;;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;関数による定義とclassによる定義はおおむね変わらないが、&lt;a href=&#34;https://reactjs.org/docs/state-and-lifecycle.html&#34;&gt;stateとライフサイクルメソッド&lt;/a&gt;を使いたいときはclassにする必要がある。&lt;/p&gt;

&lt;h2 id=&#34;props&#34;&gt;props&lt;/h2&gt;

&lt;p&gt;コンポーネントはレンダリングの際に&lt;code&gt;props&lt;/code&gt;というパラメータを受け取って使うことができるので、上手く設計すれば汎用的なコンポーネントが書ける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import React from &#39;react&#39;;
import ReactDOM from &#39;react-dom&#39;;

// Welcomeコンポーネントの定義 (props付き)
function Welcome(props) {
  return &amp;lt;h1&amp;gt;Hello, {props.name}&amp;lt;/h1&amp;gt;;
}

// Welcomeコンポーネントのレンダリング (props付き)
ReactDOM.render(
  &amp;lt;Welcome name=&amp;quot;Kaitoy&amp;quot; /&amp;gt;,
  document.getElementById(&#39;root&#39;)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;props&lt;/code&gt;はイミュータブルにしてコンポーネント内で変更しない(i.e. コンポーネントをpureにする)のが定石。&lt;/p&gt;

&lt;h2 id=&#34;prop-types&#34;&gt;prop-types&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/facebook/prop-types&#34;&gt;prop-types&lt;/a&gt;を使うと、コンポーネントに渡される&lt;code&gt;props&lt;/code&gt;に期待する型を定義することができる。&lt;/p&gt;

&lt;p&gt;前節で作ったWelcomeコンポーネントの&lt;code&gt;props&lt;/code&gt;の&lt;code&gt;name&lt;/code&gt;はStringオブジェクトを受け取ることを期待するので、prop-typesを以下のように定義する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;function Welcome(props) {
  return &amp;lt;h1&amp;gt;Hello, {props.name}&amp;lt;/h1&amp;gt;;
}

Welcome.propTypes = {
  name: PropTypes.string.isRequired,
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こうしておくと、実行時に型チェックが走り、型が合わないとコンソールに警告がでるようになる。&lt;/p&gt;

&lt;h1 id=&#34;reactのインストール&#34;&gt;Reactのインストール&lt;/h1&gt;

&lt;p&gt;上記のコードを実行するためのライブラリを一通りプロジェクトに追加する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add react react-dom prop-types
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Reactはv16.4.1が入った。&lt;/p&gt;

&lt;h1 id=&#34;ソース構成&#34;&gt;ソース構成&lt;/h1&gt;

&lt;p&gt;ソースを入れる&lt;code&gt;src&lt;/code&gt;ディレクトリの構成は、&lt;a href=&#34;https://qiita.com/numanomanu/items/af97312f34cf1388cee6#%E5%AE%9F%E9%9A%9B%E3%81%AE%E3%83%97%E3%83%AD%E3%83%80%E3%82%AF%E3%83%88%E3%81%AE%E3%83%95%E3%82%A9%E3%83%AB%E3%83%80%E6%A7%8B%E6%88%90&#34;&gt;Qiitaの記事&lt;/a&gt;を参考に以下のようにする。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;react-redux-scaffold/

&lt;ul&gt;
&lt;li&gt;src/

&lt;ul&gt;
&lt;li&gt;actions/&lt;/li&gt;
&lt;li&gt;components/&lt;/li&gt;
&lt;li&gt;containers/&lt;/li&gt;
&lt;li&gt;reducers/&lt;/li&gt;
&lt;li&gt;sagas/&lt;/li&gt;
&lt;li&gt;services/&lt;/li&gt;
&lt;li&gt;index.jsx&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今のところ使うのは&lt;code&gt;index.jsx&lt;/code&gt;と&lt;code&gt;components&lt;/code&gt;だけ。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;index.jsx&lt;/code&gt;は&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/19/creating-react-redux-app-from-scratch-01/#webpack%E8%A8%AD%E5%AE%9A%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB&#34;&gt;前回&lt;/a&gt;書いた通り、webpackが初めにロードするファイル。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;components&lt;/code&gt;にはReactのコンポーネントを入れる。&lt;/p&gt;

&lt;p&gt;その他のディレクトリについては追って説明する。&lt;/p&gt;

&lt;h1 id=&#34;reactコンポーネント作成&#34;&gt;Reactコンポーネント作成&lt;/h1&gt;

&lt;p&gt;最初のReactコンポーネントとして、適当なものを作る。&lt;/p&gt;

&lt;p&gt;components/App.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import React from &#39;react&#39;;

const App = () =&amp;gt; (
  &amp;lt;div&amp;gt;
    HOGE
  &amp;lt;/div&amp;gt;
);

export default App;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、これを&lt;code&gt;index.jsx&lt;/code&gt;でインポートしてレンダリングしてやる。&lt;/p&gt;

&lt;p&gt;src/index.jsx:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import React from &#39;react&#39;;
import ReactDOM from &#39;react-dom&#39;;
import App from &#39;./components/App&#39;;

const root = document.getElementById(&#39;root&#39;);

if (root) {
  ReactDOM.render(
    &amp;lt;App /&amp;gt;,
    root,
  );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで&lt;code&gt;yarn build&lt;/code&gt;すると&lt;code&gt;dist/bundle.js&lt;/code&gt;が生成される。&lt;/p&gt;

&lt;p&gt;実践的なコンポーネント構成の考え方については、公式の&lt;a href=&#34;https://reactjs.org/docs/thinking-in-react.html&#34;&gt;Thinking in React&lt;/a&gt;が参考になる。&lt;/p&gt;

&lt;h1 id=&#34;htmlファイル作成&#34;&gt;HTMLファイル作成&lt;/h1&gt;

&lt;p&gt;bundle.jsを読み込むHTMLファイルを作る。&lt;/p&gt;

&lt;p&gt;HTMLファイルを書くときは、「&lt;a href=&#34;https://hail2u.net/documents/html-best-practices.html&#34;&gt;普通のHTMLの書き方&lt;/a&gt;」の1～3章とか、「&lt;a href=&#34;https://qiita.com/miya0001/items/8fff46c201bf9eaeba4a&#34;&gt;フロントエンドチェックリスト&lt;/a&gt;」のHead、HTML辺りが参考になる。
まあ開発時にしか使わないだろうから実際は適当でいいし、なんなら&lt;a href=&#34;https://webpack.js.org/plugins/html-webpack-plugin/&#34;&gt;HtmlWebpackPlugin&lt;/a&gt;で自動生成してもいい。&lt;/p&gt;

&lt;p&gt;作るファイルは、&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/19/creating-react-redux-app-from-scratch-01/#webpack-dev-server%E8%A8%AD%E5%AE%9A&#34;&gt;webpackの設定に書いた&lt;/a&gt;通り、&lt;code&gt;public/index.html&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;内容は以下。&lt;/p&gt;

&lt;p&gt;public/index.html:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;!doctype html&amp;gt;
&amp;lt;html lang=&amp;quot;en&amp;quot;&amp;gt;
  &amp;lt;head&amp;gt;
    &amp;lt;meta charset=&amp;quot;utf-8&amp;quot; /&amp;gt;
    &amp;lt;meta http-equiv=&amp;quot;x-ua-compatible&amp;quot; content=&amp;quot;ie=edge&amp;quot;&amp;gt;
    &amp;lt;meta name=&amp;quot;viewport&amp;quot; content=&amp;quot;width=device-width, initial-scale=1&amp;quot;&amp;gt;
    &amp;lt;title&amp;gt;React Redux&amp;lt;/title&amp;gt;
    &amp;lt;meta name=&amp;quot;description&amp;quot; content=&amp;quot;React Redux Scaffold&amp;quot;&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
    &amp;lt;div id=&amp;quot;root&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
    &amp;lt;noscript&amp;gt;
      You need to enable JavaScript to run this app.
    &amp;lt;/noscript&amp;gt;
    &amp;lt;script src=&amp;quot;./bundle.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
  &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ポイントは2点。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;&amp;lt;body&amp;gt;&lt;/code&gt;の最初に&lt;code&gt;id=root&lt;/code&gt;の&lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt;を書く&lt;/p&gt;

&lt;p&gt;上で書いた&lt;code&gt;index.jsx&lt;/code&gt;で、&lt;code&gt;id&lt;/code&gt;が&lt;code&gt;root&lt;/code&gt;の要素を取得して&lt;code&gt;ReactDOM.render()&lt;/code&gt;に渡しているので、この&lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt;要素のなかに全てのWeb UIがレンダリングされることになる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;&amp;lt;body&amp;gt;&lt;/code&gt;の最後に&lt;code&gt;&amp;lt;script src=&amp;quot;./bundle.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;&lt;/code&gt;を書く&lt;/p&gt;

&lt;p&gt;この&lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;要素により、bundle.jsがWebサーバからダウンロードされて実行される。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でReactは一通り。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;yarn start&lt;/code&gt;してブラウザで&lt;code&gt;http://localhost:3000&lt;/code&gt;にアクセスするとHOGEと表示されるはず。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/23/creating-react-redux-app-from-scratch-03/&#34;&gt;次回&lt;/a&gt;はフォーマッタとリンタを導入する。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>React &#43; Reduxアプリケーションプロジェクトのテンプレートを作る ― その1: Node.jsとYarnとBabelとwebpack</title>
          <link>https://www.kaitoy.xyz/2018/08/19/creating-react-redux-app-from-scratch-01/</link>
          <pubDate>Sun, 19 Aug 2018 15:27:19 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/08/19/creating-react-redux-app-from-scratch-01/</guid>
          <description>

&lt;p&gt;昔、&lt;a href=&#34;https://dojotoolkit.org/&#34;&gt;Dojo Toolkit&lt;/a&gt;を使ってFlashなUIをJavaScriptに書き換えた時以来、仕事でWeb UIを触ることはなかったんだけど、最近になってWeb UIを書かなければいけなくなるような気がして再学習を始めた。&lt;/p&gt;

&lt;p&gt;題材は&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt; (と&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;)。
今一番人気のフロントエンドフレームワークで、&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/21/hello-react/&#34;&gt;昔触ったこともある&lt;/a&gt;ので。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/16/chronicle-of-frontend-2018/&#34;&gt;前回の記事でReactが生まれた経緯を学んだ&lt;/a&gt;ので、今回から実習に入る。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;プロジェクト作成&#34;&gt;プロジェクト作成&lt;/h1&gt;

&lt;p&gt;ちょっと&lt;a href=&#34;https://github.com/facebook/create-react-app&#34;&gt;Create React App&lt;/a&gt;を触ってみたけど使わないことにした。
すぐ開発始められるのはよかったんだけど、裏でなにが起こっているかわからな過ぎて肌に合わないし、使うライブラリが結構固定されちゃいそうだったし、トラブルシュート(特にライブラリのバグを踏んだ時)が大変そうだったので。&lt;/p&gt;

&lt;p&gt;代わりに、&lt;a href=&#34;https://reactjs.org/docs/create-a-new-react-app.html#creating-a-toolchain-from-scratch&#34;&gt;公式&lt;/a&gt;で紹介されているブログ記事である&lt;a href=&#34;https://blog.usejournal.com/creating-a-react-app-from-scratch-f3c693b84658&#34;&gt;Creating a React App… From Scratch.&lt;/a&gt;を見ながら、スクラッチからプロジェクトを作ることにした。&lt;/p&gt;

&lt;p&gt;環境はWindows 10 Home。&lt;/p&gt;

&lt;p&gt;最終的な成果は&lt;a href=&#34;https://github.com/kaitoy/react-redux-scaffold&#34;&gt;GitHub&lt;/a&gt;に置いた。&lt;/p&gt;

&lt;h2 id=&#34;node-jsインストール&#34;&gt;Node.jsインストール&lt;/h2&gt;

&lt;p&gt;なにはともあれ&lt;a href=&#34;https://nodejs.org/ja/&#34;&gt;Node.js&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;Node.jsのバージョン管理には以前は&lt;a href=&#34;https://github.com/marcelklehr/nodist&#34;&gt;nodist&lt;/a&gt;使っていたんだけど、こいつは2年ほど前に開発が止まっているので、代わりに&lt;a href=&#34;https://github.com/coreybutler/nvm-windows&#34;&gt;nvm for Windows&lt;/a&gt;を入れた。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;nvm install&lt;/code&gt;で任意のバージョンのNode.jsをインストール出来て、&lt;code&gt;nvm use&lt;/code&gt;で使うNode.jsのバージョンを切り替えられる。&lt;/p&gt;

&lt;p&gt;今回使うNode.jsのバージョンは、現時点でLTS版の最新である8.11.4にする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\&amp;gt;nvm install 8.11.4
Downloading node.js version 8.11.4 (64-bit)...
Complete
Creating C:\Users\kaitoy\AppData\Roaming\nvm\temp

Downloading npm version 5.6.0... Complete
Installing npm v5.6.0...

Installation complete. If you want to use this version, type

nvm use 8.11.4

C:\&amp;gt;nvm use 8.11.4
Now using node v8.11.4 (64-bit)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;yarnインストール&#34;&gt;Yarnインストール&lt;/h2&gt;

&lt;p&gt;パッケージマネージャには&lt;a href=&#34;https://yarnpkg.com/lang/ja/&#34;&gt;Yarn&lt;/a&gt;を使う。&lt;/p&gt;

&lt;p&gt;Yarnちょっとバギーだとか、npm 5がlockファイルをサポートしてYarnの優位性が減ったとか、&lt;a href=&#34;https://github.com/mixmaxhq/deyarn&#34;&gt;Yarnからnpmに戻るためのツール&lt;/a&gt;が出てきたりしてるけど、現時点では深く考えずにYarnでいいと思う。&lt;/p&gt;

&lt;p&gt;YarnはWindows環境ではMSIファイルを&lt;a href=&#34;https://yarnpkg.com/ja/docs/install#windows-stable&#34;&gt;ダウンロード&lt;/a&gt;して実行すればインストールできる。&lt;/p&gt;

&lt;p&gt;(npmでもインストールできるけど邪道。)&lt;/p&gt;

&lt;p&gt;Yarnはv1.7.0を使う。&lt;/p&gt;

&lt;h2 id=&#34;package-json生成&#34;&gt;package.json生成&lt;/h2&gt;

&lt;p&gt;プロジェクトの構成情報を記述するファイルであるpackage.jsonをYarnで生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\&amp;gt;mkdir react-redux-scaffold

C:\&amp;gt;cd react-redux-scaffold

C:\react-redux-scaffold&amp;gt;yarn init
yarn init v1.7.0
question name (react-redux-scaffold):
question version (1.0.0):
question description: React Redux Scaffold
question entry point (index.js): src/index.jsx
question repository url: https://github.com/kaitoy/react-redux-scaffold.git
question author: kaitoy
question license (MIT):
question private:
success Saved package.json
Done in 40.38s.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できたのがこれ。&lt;/p&gt;

&lt;p&gt;package.json:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;react-redux-scaffold&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;1.0.0&amp;quot;,
  &amp;quot;description&amp;quot;: &amp;quot;React Redux Scaffold&amp;quot;,
  &amp;quot;main&amp;quot;: &amp;quot;src/index.jsx&amp;quot;,
  &amp;quot;repository&amp;quot;: &amp;quot;https://github.com/kaitoy/react-redux-scaffold.git&amp;quot;,
  &amp;quot;author&amp;quot;: &amp;quot;kaitoy&amp;quot;,
  &amp;quot;license&amp;quot;: &amp;quot;MIT&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以降、カレントディレクトリは&lt;code&gt;C:\react-redux-scaffold&lt;/code&gt;として、プロンプト表示は省略する。&lt;/p&gt;

&lt;h1 id=&#34;ビルド環境セットアップ&#34;&gt;ビルド環境セットアップ&lt;/h1&gt;

&lt;p&gt;ビルド環境としてトランスパイラとかモジュールバンドラとかをセットアップする。&lt;/p&gt;

&lt;h2 id=&#34;babel&#34;&gt;Babel&lt;/h2&gt;

&lt;p&gt;トランスパイラはデファクトスタンダードの&lt;a href=&#34;https://babeljs.io/&#34;&gt;Babel&lt;/a&gt;を使う。&lt;/p&gt;

&lt;p&gt;Babelのプラグインはとりあえず最低限入れるとして、以下のnpmパッケージをプロジェクトにインストールする。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://babeljs.io/docs/en/babel-core&#34;&gt;babel-core&lt;/a&gt;: Babel本体。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://babeljs.io/docs/en/babel-preset-react&#34;&gt;babel-preset-react&lt;/a&gt;: Reactの&lt;a href=&#34;https://reactjs.org/docs/introducing-jsx.html&#34;&gt;JSX&lt;/a&gt;とか&lt;a href=&#34;https://flow.org/&#34;&gt;Flow&lt;/a&gt;とかを処理するプラグイン集。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://babeljs.io/docs/en/babel-preset-env&#34;&gt;babel-preset-env&lt;/a&gt;: ES 2015+をES 5にトランスパイルするプラグイン集。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;これらのパッケージは実行時には要らないので&lt;code&gt;yarn add -D&lt;/code&gt;コマンドで開発時依存としてインストールする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D babel-core babel-preset-react babel-preset-env
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Babelは6.26.3が入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、Babelの&lt;a href=&#34;https://babeljs.io/docs/en/babelrc&#34;&gt;設定ファイル&lt;/a&gt;を書いてプロジェクトルートに置いておく。&lt;/p&gt;

&lt;p&gt;.babelrc:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;presets&amp;quot;: [&amp;quot;env&amp;quot;, &amp;quot;react&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;polyfill&#34;&gt;Polyfill&lt;/h2&gt;

&lt;p&gt;BabelはES 2015+で追加された構文の変換はしてくれるけど、追加されたグローバルオブジェクト(e.g. &lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Global_Objects/Promise&#34;&gt;Promise&lt;/a&gt;)とかメソッド(e.g. Object.assignとかArray.prototype.includes)とかを補完してくれるわけではない。
そこを補完してくれるのが&lt;a href=&#34;https://en.wikipedia.org/wiki/Polyfill_%28programming%29&#34;&gt;Polyfill&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;少なくとも後で導入する&lt;a href=&#34;https://redux-saga.js.org/&#34;&gt;redux-saga&lt;/a&gt;が使う&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Statements/function*&#34;&gt;ジェネレータ&lt;/a&gt;がPolyfillを必要とする(ないと&lt;code&gt;ReferenceError: regeneratorRuntime is not defined&lt;/code&gt;というエラーが出る)ので、今の時点で入れておくことにする。&lt;/p&gt;

&lt;p&gt;Polyfillの実装はいくつかあるけど、定番っぽい&lt;a href=&#34;https://babeljs.io/docs/en/babel-polyfill/&#34;&gt;babel-polyfill&lt;/a&gt;を使う。
こちらは実行時依存としてインストールする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add babel-polyfill
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;webpack&#34;&gt;webpack&lt;/h2&gt;

&lt;p&gt;モジュールバンドラは現時点で一番人気の&lt;a href=&#34;https://webpack.js.org/&#34;&gt;webpack&lt;/a&gt;を使う。
(&lt;a href=&#34;https://parceljs.org/&#34;&gt;Parcel&lt;/a&gt;の方がナウいはナウいけど。)&lt;/p&gt;

&lt;p&gt;webpackは、タスクランナーの機能も備えたモジュールバンドラみたいな感じで、バンドルしたいファイルの形式とか実行したいタスクに応じた&lt;a href=&#34;https://webpack.js.org/loaders/&#34;&gt;ローダー&lt;/a&gt;を設定することでプロジェクトのビルドを定義できる。&lt;/p&gt;

&lt;p&gt;ちょっと古いけど&lt;a href=&#34;https://qiita.com/chuck0523/items/caacbf4137642cb175ec&#34;&gt;この記事&lt;/a&gt;を読むとwebpackの理解が深まる。&lt;/p&gt;

&lt;p&gt;こちらもとりあえず最低限のローダーをセットアップするとして、以下のnpmパッケージをプロジェクトにインストールする。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;webpack: webpack本体。&lt;/li&gt;
&lt;li&gt;webpack-cli: webpackのコマンドラインインターフェース。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/webpack/webpack-dev-server&#34;&gt;webpack-dev-server&lt;/a&gt;: webpackから起動できる開発用 HTTP サーバ。ライブリロードしてくれる。(&lt;a href=&#34;https://github.com/webpack-contrib/webpack-serve&#34;&gt;webpack-serve&lt;/a&gt;の方がモダンではある。)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://webpack.js.org/loaders/babel-loader/&#34;&gt;babel-loader&lt;/a&gt;: Babelを実行してくれるやつ。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D webpack webpack-cli webpack-dev-server babel-loader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;webpackはv4.16.0が入った。&lt;/p&gt;

&lt;h3 id=&#34;webpack設定ファイル&#34;&gt;webpack設定ファイル&lt;/h3&gt;

&lt;p&gt;webpackの設定は&lt;a href=&#34;https://webpack.js.org/configuration/&#34;&gt;設定ファイル&lt;/a&gt;を書いてプロジェクトルートに置けばいい。
設定は結構複雑だけど、v1の時よりかは若干書きやすくなったし、公式のマニュアルとかローダーのマニュアル見てれば書くのは難しくない。
&lt;a href=&#34;https://generatewebpackconfig.netlify.com/&#34;&gt;設定ファイルを生成してくれるサイト&lt;/a&gt;もある。&lt;/p&gt;

&lt;p&gt;とりあえず適当に書くとこんな感じ。&lt;/p&gt;

&lt;p&gt;webpack.config.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const path = require(&#39;path&#39;);
const packageJson = require(&#39;./package.json&#39;);

module.exports = {
  mode: &#39;development&#39;,
  entry: [&#39;babel-polyfill&#39;, `./${packageJson.main}`],
  output: {
    path: path.resolve(__dirname, &#39;dist&#39;),
    filename: &#39;bundle.js&#39;,
  },
  module: {
    rules: [
      {
        test: /\.(js|jsx)$/,
        include: [path.resolve(__dirname, &#39;src&#39;)],
        loader: &#39;babel-loader&#39;,
      },
    ],
  },
  resolve: {
    extensions: [&#39;*&#39;, &#39;.js&#39;, &#39;.jsx&#39;],
    modules: [&#39;node_modules&#39;],
  },
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この設定の意味は、&lt;code&gt;./src/index.jsx&lt;/code&gt;を読んで、&lt;code&gt;.js&lt;/code&gt;か&lt;code&gt;.jsx&lt;/code&gt;を拡張子としたファイルとかモジュールをロードするコードがあったら、babel-loaderでBabelを呼んでトランスパイルして、バンドルした結果は&lt;code&gt;&amp;lt;プロジェクトルート&amp;gt;/dist/bundle.js&lt;/code&gt;に吐き出す。
というだけ。
(&lt;a href=&#34;https://nodejs.org/docs/latest/api/modules.html#modules_dirname&#34;&gt;__dirname&lt;/a&gt;はNode.jsが値を入れてくれる変数で、webpack.config.jsのあるディレクトリの絶対パスが入ってる。)&lt;/p&gt;

&lt;p&gt;ファイルをロードするコードというのは、&lt;code&gt;import App from &#39;./components/App&#39;;&lt;/code&gt;みたいなやつ。
webpackはこのコードを読んだら、&lt;code&gt;./components&lt;/code&gt;ディレクトリのなかを見て、&lt;code&gt;App&lt;/code&gt;か&lt;code&gt;App.js&lt;/code&gt;か&lt;code&gt;App.jsx&lt;/code&gt;というファイルを探してロードする。
また、モジュールをロードするコードというのは&lt;code&gt;import React from &#39;react&#39;;&lt;/code&gt;みたいなやつで、webpackはこのコードを読んだら、プロジェクトの&lt;code&gt;node_modules/react/package.json&lt;/code&gt;の&lt;code&gt;main&lt;/code&gt;プロパティの値に書いてあるファイルをロードする。
という挙動が上記webpack.config.jsの&lt;code&gt;resolve&lt;/code&gt;に書いてあって、その詳細は&lt;a href=&#34;https://webpack.js.org/concepts/module-resolution/&#34;&gt;公式のドキュメントのModule Resolution&lt;/a&gt;に書いてある。&lt;/p&gt;

&lt;p&gt;webpack.config.jsの&lt;code&gt;entry&lt;/code&gt;には、最初に&lt;code&gt;babel-polyfill&lt;/code&gt;を書いておいて、bundle.jsの最初に一度だけPolyfillがロードされるようにしている。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;mode&lt;/code&gt;は後述。&lt;/p&gt;

&lt;h3 id=&#34;webpack-dev-server設定&#34;&gt;webpack-dev-server設定&lt;/h3&gt;

&lt;p&gt;webpack-dev-serverの設定もwebpack.config.jsに書く。&lt;/p&gt;

&lt;p&gt;以下を&lt;code&gt;resolve&lt;/code&gt;の次辺りに書き足せばいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;  devServer: {
    contentBase: path.join(__dirname, &#39;public&#39;),
    compress: true,
    hot: true,
    port: 3000,
    publicPath: &#39;http://localhost:3000/&#39;,
  },
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;この設定でwebpack-dev-serverを実行すると、&lt;code&gt;http://localhost:3000/&lt;/code&gt;へのアクセスに&lt;code&gt;public/index.html&lt;/code&gt;を返すWebサーバを起動できる。
Webサーバが起動するときにプロジェクトがインメモリでビルドされ、メモリからbundle.jsがサーブされる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;hot&lt;/code&gt;をtrueにしておくと&lt;a href=&#34;https://webpack.js.org/concepts/hot-module-replacement/&#34;&gt;Hot Module Replacement&lt;/a&gt;が有効になる。
これによって、webpack-dev-serverの起動中にソースを編集すると、自動で再ビルドし、動的にモジュール単位でロードし、ブラウザをリロードしてくれるようになる。
Hot Module Replacementを有効にするときは&lt;code&gt;publicPath&lt;/code&gt;をフルURLで書かないといけない。&lt;/p&gt;

&lt;p&gt;webpack-dev-serverの他の設定については&lt;a href=&#34;https://webpack.js.org/configuration/dev-server/&#34;&gt;公式のマニュアルのDevServer&lt;/a&gt;を見るべし。&lt;/p&gt;

&lt;h3 id=&#34;webpackのmode&#34;&gt;webpackのmode&lt;/h3&gt;

&lt;p&gt;webpackにはビルドの&lt;a href=&#34;https://webpack.js.org/concepts/#mode&#34;&gt;mode&lt;/a&gt;という概念があり、modeを切り替えることで適切な最適化を適用してくれる。&lt;/p&gt;

&lt;p&gt;modeにはdevelopmentとproduction(とnone)があり、productionにしておくと、&lt;a href=&#34;https://webpack.js.org/plugins/uglifyjs-webpack-plugin/&#34;&gt;UglifyJsPlugin&lt;/a&gt;とかを適用して、出力するバンドルファイルのサイズを小さくしてくれたりする。
(v1のころはUglifyJsPluginとかは全部自分でwebpack.config.jsに指定していた記憶があるので、楽になった。)&lt;/p&gt;

&lt;h3 id=&#34;webpack-config-jsの分割&#34;&gt;webpack.config.jsの分割&lt;/h3&gt;

&lt;p&gt;modeを切り替えるのにwebpack.config.jsを書き換えるのはイケてないので、developmentとproductionでファイルを分割して使い分けるようにする。&lt;/p&gt;

&lt;p&gt;developmentとproductionはほとんどが共通の設定なので、共通部分をwebpack.common.jsに書いて、developmentとproductionに固有な設定だけをそれぞれwebpack.dev.jsとwebpack.prod.jsに書く。
webpack.common.jsは、&lt;a href=&#34;https://github.com/survivejs/webpack-merge&#34;&gt;webpack-merge&lt;/a&gt;でwebpack.dev.jsとwebpack.prod.jsにマージする。
というのが&lt;a href=&#34;https://webpack.js.org/guides/production/&#34;&gt;公式&lt;/a&gt;で紹介されているプラクティス。&lt;/p&gt;

&lt;p&gt;まずwebpack-mergeをプロジェクトにインストール。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;yarn add -D webpack-merge
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;分割したファイルは以下の感じ。全部プロジェクトルートに置いておく。&lt;/p&gt;

&lt;p&gt;webpack.common.js&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const path = require(&#39;path&#39;);
const packageJson = require(&#39;./package.json&#39;);

module.exports = {
  entry: [&#39;babel-polyfill&#39;, `./${packageJson.main}`],
  output: {
    path: path.resolve(__dirname, &#39;dist&#39;),
    filename: &#39;bundle.js&#39;,
  },
  module: {
    rules: [
      {
        test: /\.(js|jsx)$/,
        include: [path.resolve(__dirname, &#39;src&#39;)],
        loader: &#39;babel-loader&#39;,
      },
    ],
  },
  resolve: {
    extensions: [&#39;*&#39;, &#39;.js&#39;, &#39;.jsx&#39;],
    modules: [&#39;node_modules&#39;],
  },
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;webpack.dev.js&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const path = require(&#39;path&#39;);
const webpackMerge = require(&#39;webpack-merge&#39;);
const webpackCommon = require(&#39;./webpack.common.js&#39;);

module.exports = webpackMerge(webpackCommon, {
  mode: &#39;development&#39;,
  devServer: {
    contentBase: path.join(__dirname, &#39;public&#39;),
    compress: true,
    hot: true,
    port: 3000,
    publicPath: &#39;http://localhost:3000/&#39;,
  },
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;webpack.prod.js&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const webpackMerge = require(&#39;webpack-merge&#39;);
const webpackCommon = require(&#39;./webpack.common.js&#39;);

module.exports = webpackMerge(webpackCommon, {
  mode: &#39;production&#39;,
});
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;npmスクリプト&#34;&gt;npmスクリプト&lt;/h3&gt;

&lt;p&gt;webpackによるビルドは次のコマンドで実行できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;node_modules\.bin\webpack --config webpack.prod.js
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、webpack-dev-serverは次のコマンドで起動できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;node_modules\.bin\webpack-dev-server --hot --config webpack.dev.js
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--hot&lt;/code&gt;はHot Module Replacementに必要なオプション。&lt;/p&gt;

&lt;p&gt;コマンドが長くて面倒なのは、&lt;a href=&#34;https://docs.npmjs.com/misc/scripts&#34;&gt;npmスクリプト&lt;/a&gt;で楽にできる。
package.jsonの&lt;code&gt;main&lt;/code&gt;の次辺りに以下を書き足せばいい。
(npmスクリプトは実行時に&lt;code&gt;node_modules\.bin&lt;/code&gt;にPATHを通してくれるので、それを省略できる。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;  &amp;quot;scripts&amp;quot;: {
    &amp;quot;build&amp;quot;: &amp;quot;webpack --config webpack.prod.js&amp;quot;,
    &amp;quot;start&amp;quot;: &amp;quot;webpack-dev-server --hot --config webpack.dev.js&amp;quot;
  },
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こうしておくと、&lt;code&gt;yarn build&lt;/code&gt;でビルド、&lt;code&gt;yarn start&lt;/code&gt;でwebpack-dev-server起動できる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でビルド環境セットアップはいったん完了とする。
&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/22/creating-react-redux-app-from-scratch-02/&#34;&gt;次回&lt;/a&gt;はReactが動くところらへんまで。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Webアプリケーションフロントエンド年代記 - 2018年夏編</title>
          <link>https://www.kaitoy.xyz/2018/08/16/chronicle-of-frontend-2018/</link>
          <pubDate>Thu, 16 Aug 2018 23:44:39 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/08/16/chronicle-of-frontend-2018/</guid>
          <description>

&lt;p&gt;Webアプリケーションの、主にフロントエンド周りに関連する歴史をまとめた。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;静的サイト&#34;&gt;静的サイト&lt;/h1&gt;

&lt;p&gt;まずは原初の話から。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1990年代前半&lt;/strong&gt;、まだWebアプリケーションという言葉が無かった時代。
静的にHTMLファイルを配信するだけのWebサイト(静的サイト)だけがあった。
静的サイトでは、HTTPサーバーに複数のHTMLファイルを置いておいて、クライアントのHTTPリクエストのURLのパスによって配信するHTMLファイルを変える。&lt;/p&gt;

&lt;p&gt;例えば、HTTPサーバーを&lt;a href=&#34;https://httpd.apache.org/&#34;&gt;httpd&lt;/a&gt;で立てて、ドキュメントルートを&lt;code&gt;/var/www/html&lt;/code&gt;に設定して、以下のようにファイルを配置したとする。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;/var/www/html/
    |
    +-- index.html
    |
    +-- sub/
          |
          +-- hoge.html
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;この場合、ブラウザで&lt;code&gt;http://&amp;lt;HTTPサーバアドレス&amp;gt;/index.html&lt;/code&gt;にアクセスすれば&lt;code&gt;/var/www/html/index.html&lt;/code&gt;が配信されてレンダリングされて表示される。
&lt;code&gt;http://&amp;lt;HTTPサーバアドレス&amp;gt;/sub/hoge.html&lt;/code&gt;にアクセスすれば&lt;code&gt;/var/www/html/sub/hoge.html&lt;/code&gt;が配信される。&lt;/p&gt;

&lt;p&gt;古のWebサイトは、こんな感じにコンテンツごとにHTMLファイルを書いてサーバに置いておいて、その間にリンクを張って辿れるようにすることで構成されていた。&lt;/p&gt;

&lt;p&gt;まあ今も大体そんな感じだけど。&lt;/p&gt;

&lt;h1 id=&#34;動的html生成-プログラムでhtmlを書き出す&#34;&gt;動的HTML生成 (プログラムでHTMLを書き出す)&lt;/h1&gt;

&lt;p&gt;静的サイトだと表現できることが非常に限られるので、クライアントからのリクエストの内容をサーバが解釈し、DBの情報やなんかをもとにサーバ側でHTMLドキュメントを動的に生成し、クライアントに返す、ということをするようになった。&lt;/p&gt;

&lt;p&gt;原始的(&lt;strong&gt;1990年代中盤から後半&lt;/strong&gt;)には、プログラム中で一連のHTMLドキュメントを出力する方法がとられた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void doGet(
  HttpServletRequest request, HttpServletResponse response
) throws IOException, ServletException {

  response.setContentType(&amp;quot;text/html;&amp;quot;);
  PrintWriter out = response.getWriter();

  out.println(&amp;quot;&amp;lt;html&amp;gt;&amp;quot;);
  out.println(&amp;quot;  &amp;lt;head&amp;gt;&amp;quot;);
  out.println(&amp;quot;    &amp;lt;title&amp;gt;Hoge&amp;lt;/title&amp;gt;&amp;quot;);
  out.println(&amp;quot;  &amp;lt;/head&amp;gt;&amp;quot;);
  out.println(&amp;quot;  &amp;lt;body&amp;gt;&amp;quot;);
  out.println(new java.util.Date());
  out.println(&amp;quot;  &amp;lt;/body&amp;gt;&amp;quot;);
  out.println(&amp;quot;&amp;lt;/html&amp;gt;&amp;quot;);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使われた技術は、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Common_Gateway_Interface&#34;&gt;CGI&lt;/a&gt; (Perl)とか、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Java_Servlet&#34;&gt;Java Servlet&lt;/a&gt;とか。
&lt;a href=&#34;http://jakarta.apache.org/ecs/index.html&#34;&gt;Jakarta ECS&lt;/a&gt;なんてのもあった。&lt;/p&gt;

&lt;h1 id=&#34;動的html生成-htmlにプログラムを埋め込む&#34;&gt;動的HTML生成 (HTMLにプログラムを埋め込む)&lt;/h1&gt;

&lt;p&gt;プログラムでHTMLを書き出すことにより、かなり動的な感じにはなったが、書き出す処理を書くのがめんどくさすぎるし、読みにくい。
そのため、&lt;strong&gt;1990年代後半から2000年代初頭&lt;/strong&gt; にかけ、HTMLを主体にして、そのなかの動的な部分だけにプログラムを埋め込む技術がいくつも生まれた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-jsp&#34;&gt;&amp;lt;%@ page contentType=&amp;quot;text/html %&amp;gt;

&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
    &amp;lt;title&amp;gt;Hoge&amp;lt;/title&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
    &amp;lt;%
    out.println(new java.util.Date());
    %&amp;gt;
  &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;HTMLドキュメントのひな型を作っておいて、その中にプログラムの処理結果を埋め込んでクライアントに返すため、テンプレートエンジンとか、テンプレートシステムとか呼ばれる。&lt;/p&gt;

&lt;p&gt;該当する技術は、&lt;a href=&#34;http://www.php.net/&#34;&gt;PHP&lt;/a&gt;とか、&lt;a href=&#34;https://ja.wikipedia.org/wiki/JavaServer_Pages&#34;&gt;JSP&lt;/a&gt;とか、&lt;a href=&#34;http://velocity.apache.org/&#34;&gt;Velocity&lt;/a&gt;とか、&lt;a href=&#34;https://ja.wikipedia.org/wiki/ERuby&#34;&gt;eRuby&lt;/a&gt;とか。&lt;/p&gt;

&lt;h1 id=&#34;dhtml&#34;&gt;DHTML&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;1990年代後半&lt;/strong&gt;、クライアントサイドのJavaScriptでHTMLドキュメントをいじって、多少の動的感・インタラクティブ感をだす技術は既に一応あって、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%80%E3%82%A4%E3%83%8A%E3%83%9F%E3%83%83%E3%82%AFHTML&#34;&gt;DHTML&lt;/a&gt;と呼ばれていた。&lt;/p&gt;

&lt;p&gt;DHTMLの肝はJavaScriptの&lt;a href=&#34;https://ja.wikipedia.org/wiki/Document_Object_Model&#34;&gt;DOM&lt;/a&gt; APIだ。
このAPIでは、HTML文書が各要素(タグなど)をノードとするツリー構造(DOMツリー)で表され、任意の要素を検索して取得したり、属性などを書き換えたり、要素の追加・削除ができる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;&amp;lt;!DOCTYPE HTML PUBLIC &amp;quot;-//W3C//DTD HTML 4.01 Transitional//EN&amp;quot; &amp;quot;http://www.w3.org/TR/html4/loose.dtd&amp;quot;&amp;gt;
&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
    &amp;lt;div id=&amp;quot;hogehoge&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
    &amp;lt;script type=&amp;quot;text/javascript&amp;quot;&amp;gt;
      // idがhogehogeの要素の子要素として「&amp;lt;p&amp;gt;HOGEEEEEEE&amp;lt;/p&amp;gt;」を追加。
      document.getElementById(&amp;quot;hogehoge&amp;quot;).innerHTML = &amp;quot;&amp;lt;p&amp;gt;HOGEEEEEEE&amp;lt;/p&amp;gt;&amp;quot;
    &amp;lt;/script&amp;gt;
  &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;しかし、このころのJavaScriptは、仕様・機能が貧弱だった上、ブラウザ間で挙動に差があったり、標準メソッドがブラウザ固有のメソッドで代替されていたりして開発体験が最悪だったためか、今日のようにWeb UIの中心的役割を果たすことはなく、補助的・装飾的機能の実装に使われることが多かったように思う。&lt;/p&gt;

&lt;p&gt;アクセスした日付を表示したり、背景に雪を降らせたり、マウスカーソルを目玉に追いかけさせたり。&lt;/p&gt;

&lt;h1 id=&#34;mvcアーキテクチャ&#34;&gt;MVCアーキテクチャ&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;2000年初頭&lt;/strong&gt;、&lt;a href=&#34;http://struts.apache.org/&#34;&gt;Struts&lt;/a&gt; (Struts1)というJavaのWebアプリケーションフレームワークが流行り、Controller (Java Servlet)がクライアントからリクエストを受け取り、Model (JavaBeans)がそれを処理して、View (JSP)がHTMLをレンダリングしてクライアントに返す、という、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Model_View_Controller&#34;&gt;MVCアーキテクチャ&lt;/a&gt;が流行った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/MVC-Process.svg/500px-MVC-Process.svg.png&#34; alt=&#34;MVC&#34; title=&#34;MVC&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Strutsに続いて&lt;a href=&#34;https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html&#34;&gt;Spring MVC&lt;/a&gt;、&lt;a href=&#34;https://rubyonrails.org/&#34;&gt;Ruby on Rails&lt;/a&gt;、&lt;a href=&#34;https://cakephp.org/jp&#34;&gt;CakePHP&lt;/a&gt;といったフレームワークが出てきて、MVCアーキテクチャによる開発効率や開発体験は洗練されていった。&lt;/p&gt;

&lt;h1 id=&#34;ajax&#34;&gt;Ajax&lt;/h1&gt;

&lt;p&gt;Strutsが全盛期の&lt;strong&gt;2005年&lt;/strong&gt;ころ、JavaScriptで非同期にサーバからデータを取得し、それをもとにクライアントサイドでHTMLを動的に編集するような技術に、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Ajax&#34;&gt;Ajax&lt;/a&gt;という名前が付いた。&lt;/p&gt;

&lt;p&gt;Ajaxは「Asynchronous JavaScript + XML」の略で、&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/XMLHttpRequest&#34;&gt;XMLHttpRequest&lt;/a&gt; (略してXHR)というJavaScriptのAPIで
、サーバにHTTPリクエストを送り、そのレスポンスを非同期に処理する技術。
レスポンスは、当時XMLが流行っていたので、その形式で送ることが想定されていたが、実際にはどんな形式でもいい。はず。
最近はJSONで送られることがほとんど。&lt;/p&gt;

&lt;p&gt;JavaScriptはシングルスレッドで動くわけだけど、XMLHttpRequestはレスポンスを非同期に処理するため、リクエスト送信からレスポンス受信までの間、クライアントがスタックせずに済む。
また、通常のHTTPリクエストは、完全なHTMLドキュメントを受信して画面全体をレンダリングしなおす(i.e. 画面遷移する)のに対して、Ajaxは受信したデータをもとに画面の一部だけを更新するので、ネイティブアプリケーションに近めなユーザエクスペリエンスを実現できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var xhr = new XMLHttpRequest();
xhr.open(&#39;GET&#39;, &#39;https://httpbin.org/get&#39;, true);
xhr.onreadystatechange = function() {
  if (xhr.readyState === 4 &amp;amp;&amp;amp; xhr.status === 200) {
    console.log(xhr.responseText);
    // DOMをいじる処理
    // …
  }
};
xhr.send(null);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ajaxは、GoogleがGoogle Mapsで活用して一気に注目を集めた。
地図データをサーバから非同期に先読みするなどして、マウスのドラッグによって地図を滑らかにスクロールして見せるそのUIは当時画期的で、それまでの、画面遷移中心のUIからの飛躍を感じさせた。&lt;/p&gt;

&lt;h1 id=&#34;prototypeとjquery&#34;&gt;PrototypeとjQuery&lt;/h1&gt;

&lt;p&gt;Ajaxの普及を後押ししたのが、&lt;a href=&#34;http://prototypejs.org/&#34;&gt;Prototype&lt;/a&gt;と&lt;a href=&#34;https://jquery.com/&#34;&gt;jQuery&lt;/a&gt;というJavaScriptライブラリの登場だった。&lt;/p&gt;

&lt;p&gt;PrototypeはRubyにインスパイアされて開発され、Ruby on Railsに採用されたことで&lt;strong&gt;2005年&lt;/strong&gt;ころから普及したライブラリで、JavaScriptの標準グローバルオブジェクトであるArrayとかElementに便利メソッドを生やしたり、独自のグローバルユーティリティオブジェクトを追加したりして、Ajax処理をしやすくしたり、JavaScriptの機能を拡張してくれたりする。&lt;/p&gt;

&lt;p&gt;特に、当時のプロトタイプベースで使いにくかったJavaScriptのオブジェクト指向を扱いやすくしてくれる&lt;a href=&#34;http://prototypejs.org/learn/class-inheritance&#34;&gt;Class&lt;/a&gt;や、配列の処理に便利なeachとかmapとかincludeとかのメソッドを追加する&lt;a href=&#34;http://api.prototypejs.org/language/Enumerable/&#34;&gt;Enumerable&lt;/a&gt;なんかが熱かったように思う。&lt;/p&gt;

&lt;p&gt;一方jQueryは、ファーストバージョンが&lt;strong&gt;2006年8月&lt;/strong&gt;にリリースされ、ブラウザ間の非互換性をほとんど気にすることなく、簡潔なコードでDOM操作やAjax通信ができるAPIを提供した。
Prototypeと比べて、標準オブジェクトやグローバル名前空間を汚さない点がよかったのか、&lt;strong&gt;2007年&lt;/strong&gt; ころにはPrototypeを抜いて猛烈に普及した。&lt;/p&gt;

&lt;p&gt;この頃からWebアプリケーションは、UIはクライアントサイドのJavaScriptでインタラクティブな感じに書いて、サーバサイドはXMLHttpRequestに対してJSONデータを返すAPIサーバとして働く、という感じのものが増えていったように思う。
またこの頃から、クライアントサイドの開発が量質ともに上がったために独立した仕事になり、サーバサイドと対比して、前者をフロントエンド、後者をバックエンドと呼ぶようになってきた。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;因みに、PrototypeやjQueryと同様というかもう少し高機能な&lt;a href=&#34;https://dojotoolkit.org/&#34;&gt;Dojo Toolkit&lt;/a&gt;というライブラリが&lt;strong&gt;2004年&lt;/strong&gt;ころからあったんだけど、あまり流行らなかった。
カスタムビルドという、モジュールを結合してminifyする&lt;a href=&#34;https://webpack.js.org/&#34;&gt;webpack&lt;/a&gt;みたいな機能を、&lt;a href=&#34;https://nodejs.org/ja/&#34;&gt;Node.js&lt;/a&gt;もない時代に実現していた先進的なライブラリだったんだけど、時代がついてこれなかったのかもしれない。&lt;/p&gt;

&lt;h1 id=&#34;ria-flashとか&#34;&gt;RIA (Flashとか)&lt;/h1&gt;

&lt;p&gt;WebアプリケーションにはAjaxと別の世界線もあった。&lt;/p&gt;

&lt;p&gt;そこでは&lt;strong&gt;1997年&lt;/strong&gt;ころに&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%AA%E3%83%83%E3%83%81%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%BC%E3%83%8D%E3%83%83%E3%83%88%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3&#34;&gt;RIA (Rich Internet Application)&lt;/a&gt;という言葉が生まれた。
これは、クライアントサイドの技術を駆使した、表現力やユーザビリティが高いWebアプリケーションのこと。&lt;/p&gt;

&lt;p&gt;(実際にはAjaxなアプリもこのくくりに入るが、ここでは非Web標準なクライアントサイド技術を使ったものの話を書く。)&lt;/p&gt;

&lt;p&gt;RIA技術の代表格である&lt;a href=&#34;https://ja.wikipedia.org/wiki/Adobe_Flash&#34;&gt;Flash&lt;/a&gt;は&lt;strong&gt;1996年&lt;/strong&gt;に生まれた。
このころはShockwave FlashとかMacromedia Flashとか呼ばれたが、開発元が&lt;strong&gt;2005年&lt;/strong&gt;にAdobeに買収されてAdobe Flashになり、そのあたりから&lt;strong&gt;2010年代前半&lt;/strong&gt;辺りまで最先端のWeb UI技術として甚だしく流行った。&lt;/p&gt;

&lt;p&gt;Flashは、&lt;a href=&#34;https://www.adobe.com/jp/products/flex.html&#34;&gt;Flex&lt;/a&gt;というフレームワーク(ツール?)のもと、&lt;a href=&#34;https://ja.wikipedia.org/wiki/ActionScript&#34;&gt;ActionScript&lt;/a&gt;というJavaScriptっぽいプログラミング言語と、&lt;a href=&#34;https://ja.wikipedia.org/wiki/MXML&#34;&gt;MXML&lt;/a&gt;というXMLなUI記述言語を駆使してWeb UIを開発できる技術。
WebブラウザにAdobe Flash PlayerとかAdobe AIRのプラグインを入れると表示できる。&lt;/p&gt;

&lt;p&gt;Flashの人気に触発されたのか、Microsoftが&lt;strong&gt;2007年&lt;/strong&gt;に&lt;a href=&#34;https://www.microsoft.com/silverlight/&#34;&gt;Silverlight&lt;/a&gt;というのをリリースした。
これは、&lt;a href=&#34;https://ja.wikipedia.org/wiki/.NET_Framework&#34;&gt;.NET Framework&lt;/a&gt;な言語(&lt;a href=&#34;https://docs.microsoft.com/ja-jp/dotnet/csharp/&#34;&gt;C#&lt;/a&gt;とか&lt;a href=&#34;https://msdn.microsoft.com/ja-jp/library/cc427807.aspx&#34;&gt;JScript&lt;/a&gt;とか)と、&lt;a href=&#34;https://docs.microsoft.com/ja-jp/dotnet/framework/wpf/advanced/xaml-overview-wpf&#34;&gt;XAML&lt;/a&gt;というHTMLっぽいUI記述言語を駆使してWeb UIを開発できる技術。
WebブラウザにMicrosoft Silverlightプラグインを入れると表示できる。&lt;/p&gt;

&lt;p&gt;また、Flashの誕生とほぼ同時期に、JavaでWebアプリケーションのUIを書く&lt;a href=&#34;https://ja.wikipedia.org/wiki/Java%E3%82%A2%E3%83%97%E3%83%AC%E3%83%83%E3%83%88&#34;&gt;Java Applet&lt;/a&gt;というのも生まれていた。が、初期のバージョンでロードに時間がかかったり動作が重かったりする問題があり、嫌厭されてFlashほど流行らなかった。
WebブラウザにJavaプラグインを入れると表示できる。
なぜか最近になって、&lt;strong&gt;2017年&lt;/strong&gt; 公開のマイナンバーのポータルサイトで採用されて話題になった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;こうした非Web標準技術を使ったRIAは、Ajaxに比べてリッチな表現ができたり、ブラウザ間の非互換性に悩まされないところに優位性があったが、以下のような問題があった。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;プロプライエタリな技術をベースにしていて、実装がブラックボックスだったり、仕様の方向性がベンダの都合に左右されたり、ベンダロックインされやすかったりする。&lt;/li&gt;
&lt;li&gt;ユーザがブラウザにプラグインをいれてないと表示されない。&lt;/li&gt;
&lt;li&gt;セキュリティ問題が見つかった場合、オープンな技術のものに比べて対策が遅い傾向があるし、ベンダによる実装しかないので替えが利かない。&lt;/li&gt;
&lt;li&gt;他ベンダの技術や標準技術との親和性が無かったり、連携が弱かったりする。&lt;/li&gt;
&lt;li&gt;ブラウザ内で文字列検索ができなかったり、検索エンジンにまともにクローリングしてもらえない。&lt;/li&gt;
&lt;li&gt;動作が重い。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;このような問題のためか、Web標準周辺技術の発展に伴い、一時期は隆盛を誇ったFlashなども次第に廃れていった。&lt;/p&gt;

&lt;p&gt;Flashは&lt;strong&gt;2020年&lt;/strong&gt;に、Silverlightは&lt;strong&gt;2021年&lt;/strong&gt;にサポート終了になり、Java Appletは&lt;strong&gt;2018年9月&lt;/strong&gt;に出るJava 11で廃止されることが決まっている。&lt;/p&gt;

&lt;h1 id=&#34;html-5とcss-3とecmascript-5&#34;&gt;HTML 5とCSS 3とECMAScript 5&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;2000年代中盤&lt;/strong&gt; から非Web標準なRIAが流行ったのは、そもそもWeb標準技術であるHTML、CSS、JavaScript(というかその標準仕様を定める&lt;a href=&#34;https://ja.wikipedia.org/wiki/ECMAScript&#34;&gt;ECMAScript&lt;/a&gt;)が、アプリケーションのUIを作るという目的で設計されているわけではなく、それらを使ってWeb UIを作ることに限界があったのが一因だったと思う。&lt;/p&gt;

&lt;p&gt;RIAの流行を受け、Web標準業界に危機感が募ったのか、&lt;strong&gt;2000年代後半&lt;/strong&gt; くらいからWeb標準技術にWeb UIを意識したバージョンアップの動きが始まった。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.w3schools.com/html/html5_intro.asp&#34;&gt;HTML 5&lt;/a&gt;の勧告 (&lt;strong&gt;2014年&lt;/strong&gt;)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;それまでの標準であるHTML 4.01の勧告が&lt;strong&gt;1999年&lt;/strong&gt;だったので、&lt;strong&gt;15年&lt;/strong&gt; ぶり。&lt;/li&gt;
&lt;li&gt;文書構造を表すタグの追加: &lt;code&gt;&amp;lt;header&amp;gt;&lt;/code&gt;とか&lt;code&gt;&amp;lt;footer&amp;gt;&lt;/code&gt;とか。&lt;/li&gt;
&lt;li&gt;図を表現するためのタグの追加: &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt;と&lt;code&gt;&amp;lt;canvas&amp;gt;&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;inputタイプの追加: &lt;code&gt;date&lt;/code&gt;、&lt;code&gt;range&lt;/code&gt;、&lt;code&gt;email&lt;/code&gt;とか。&lt;/li&gt;
&lt;li&gt;inputタグの属性の追加: &lt;code&gt;autocomplete&lt;/code&gt;、&lt;code&gt;pattern&lt;/code&gt;、&lt;code&gt;placeholder&lt;/code&gt;、&lt;code&gt;required&lt;/code&gt;とか。&lt;/li&gt;
&lt;li&gt;マルチメディアのためのタグの追加:&lt;code&gt;&amp;lt;audio&amp;gt;&lt;/code&gt;と&lt;code&gt;&amp;lt;video&amp;gt;&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;Webアプリケーション向けAPI追加: Drag and Drop、Local Storage、Web Workerとか。&lt;/li&gt;
&lt;li&gt;冗長だったり見た目に関するタグ・属性の削除: &lt;code&gt;&amp;lt;center&amp;gt;&lt;/code&gt;とか&lt;code&gt;&amp;lt;font&amp;gt;&lt;/code&gt;とか&lt;code&gt;border&lt;/code&gt;とか&lt;code&gt;color&lt;/code&gt;とか。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;data-*&lt;/code&gt;属性のサポート。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/CSS/CSS3&#34;&gt;CSS 3&lt;/a&gt;の勧告 (&lt;strong&gt;2011年&lt;/strong&gt;)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;それまでの標準であるCSS 2の勧告が&lt;strong&gt;1998年&lt;/strong&gt;だったので、&lt;strong&gt;13年&lt;/strong&gt; ぶり。&lt;/li&gt;
&lt;li&gt;角丸、シャドウ、グラデーションのサポート。&lt;/li&gt;
&lt;li&gt;セレクタの機能追加: 属性値の部分マッチ、nth-childなど。&lt;/li&gt;
&lt;li&gt;メディアクエリ。&lt;/li&gt;
&lt;li&gt;Flexboxレイアウト、Gridレイアウト。&lt;/li&gt;
&lt;li&gt;Webフォント。&lt;/li&gt;
&lt;li&gt;トランジション、トランスフォーム、アニメーション。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.w3schools.com/js/js_es5.asp&#34;&gt;ECMAScript 5&lt;/a&gt;の発行 (&lt;strong&gt;2009年&lt;/strong&gt;)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;それまでの標準であるECMAScript 3の勧告が&lt;strong&gt;1999年&lt;/strong&gt;だったので、&lt;strong&gt;10年&lt;/strong&gt; ぶり。&lt;/li&gt;
&lt;li&gt;strictモード。&lt;/li&gt;
&lt;li&gt;Arrayのメソッド追加: forEach、map、filterなど。&lt;/li&gt;
&lt;li&gt;Objectのメソッド追加: keys、freezeなど。&lt;/li&gt;
&lt;li&gt;グローバルオブジェクトにJSONが追加。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;javascriptフロントエンドフレームワーク-第1世代&#34;&gt;JavaScriptフロントエンドフレームワーク (第1世代)&lt;/h1&gt;

&lt;p&gt;Web標準技術が進化して表現力が上がり、ECMAScript 5やjQueryによってロジックを書きやすくなり、人々がWeb UIをバリバリ書けるようになり、RIAの影響もあってUIの複雑化が進んだ。&lt;/p&gt;

&lt;p&gt;UIが複雑化すると、ユーザ入力の処理、Ajaxによるサーバとのデータ通信、UIの状態の取得、DOMの操作なんかを、何の秩序も構造化もレイヤー分けもなくナイーブにコーディングするのが辛くなってきた。&lt;/p&gt;

&lt;p&gt;この辛みに対処すべく誕生してきたのが数多のJavaScriptフロントエンドフレームワーク。
&lt;strong&gt;2018年現在&lt;/strong&gt; まで続くフロントエンドフレームワーク戦国時代の幕開けである。&lt;/p&gt;

&lt;p&gt;フロントエンドフレームワークは大抵以下のような機能を提供してくれる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;UI(View)の記述を楽にする何か。テンプレートエンジンとか。&lt;/li&gt;
&lt;li&gt;Viewに表示しているデータとJavaScriptプログラムで保持しているデータを紐づける仕組み。(i.e. &lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%87%E3%83%BC%E3%82%BF%E3%83%90%E3%82%A4%E3%83%B3%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0&#34;&gt;データバインディング&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Ajaxユーティリティ。&lt;/li&gt;
&lt;li&gt;URLをViewやロジックと紐づける仕組み。(i.e. URLルーティング)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;フロントエンドフレームワーク戦国時代初期に生まれた主要なフロントエンドフレームワークを列挙する。&lt;/p&gt;

&lt;p&gt;(この記事では便宜上第1世代と呼ぶ。)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://knockoutjs.com/&#34;&gt;Knockout&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2010年&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/Model_View_ViewModel&#34;&gt;MVVMアーキテクチャ&lt;/a&gt;。

&lt;ul&gt;
&lt;li&gt;ModelがUIと独立してデータ(Ajaxでサーバから取ったものなど)を保持する。&lt;/li&gt;
&lt;li&gt;ViewModelがUIに紐づくデータとその操作を表現する。&lt;/li&gt;
&lt;li&gt;ViewはDOMツリー。ViewModelへの変更は自動でViewに反映されるし、その逆もしかり。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://backbonejs.org/&#34;&gt;Backbone.js&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2010年&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;主にModelとViewからなるMVC的アーキテクチャ。

&lt;ul&gt;
&lt;li&gt;Modelはデータとビジネスロジックを表現する。

&lt;ul&gt;
&lt;li&gt;サーバから取ってきたデータを保持。&lt;/li&gt;
&lt;li&gt;ビジネスロジックによってデータが変わると、イベントを生成。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ViewがModelをDOMに反映する。

&lt;ul&gt;
&lt;li&gt;ModelからのイベントをlistenしてDOMに反映。&lt;/li&gt;
&lt;li&gt;ユーザからの入力を取得して、Modelに渡す。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.emberjs.com/&#34;&gt;Ember.js&lt;/a&gt; v1&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2011年&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;MVVMアーキテクチャ。&lt;/li&gt;
&lt;li&gt;URLルーティングをコアとするコンセプトが特徴的。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://angularjs.org/&#34;&gt;AngularJS&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2012年&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;Google製。&lt;/li&gt;
&lt;li&gt;MVVMアーキテクチャ。&lt;/li&gt;
&lt;li&gt;DIやテストなどのサポートまであるフルスタックフレームワーク。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;第1世代は、フロントエンドの世界にMVCアーキテクチャ(とその派生)をもたらした。&lt;/p&gt;

&lt;p&gt;このMVCは、Struts時代のMVCとは違い、完全にクライアントサイドに閉じたアーキテクチャだ。
サーバ側はエントリーポイントとしてHTML(とCSSとJavaScript)をサーブするほかは、JSONを返すAPIサーバとしての役割に徹する。
このようなWebアプリケーションは、ページ遷移が発生せず、単一ページだけでUIが構成されるので、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%B7%E3%83%B3%E3%82%B0%E3%83%AB%E3%83%9A%E3%83%BC%E3%82%B8%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3&#34;&gt;Single Page Application (SPA)&lt;/a&gt;と呼ばれる。&lt;/p&gt;

&lt;p&gt;ModelとViewとの間でのデータの同期の仕方には以下のように2方向がある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;M⇒V: Modelを更新すると対応するViewが自動で更新される。&lt;/li&gt;
&lt;li&gt;V⇒M: Viewがユーザ入力などによって変更されるとModelが自動で更新される。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;前者だけをするのが1-wayバインディングで、両方するのが2-wayバインディング。
上に挙げた中では、Backbone.js以外が2-wayバインディング推しで、このころは2-wayバインディングが正義だったっぽい。&lt;/p&gt;

&lt;h1 id=&#34;commonjs-node-js-パッケージマネージャ-モジュールバンドラ-altjs-altcss-トランスパイラ-タスクランナー&#34;&gt;CommonJS、Node.js、パッケージマネージャ、モジュールバンドラ、AltJS、AltCSS、トランスパイラ、タスクランナー&lt;/h1&gt;

&lt;p&gt;第1世代のフロントエンドフレームワークが出始めたころ、JavaScriptの言語周りの環境にも大きな変化があった。
正直書くの辛くなってきたので、一気に片付ける。&lt;/p&gt;

&lt;h3 id=&#34;commonjs&#34;&gt;CommonJS&lt;/h3&gt;

&lt;p&gt;クライアントサイドでJavaScriptが盛り上がっているのを見て、もっとJavaScriptいろんなところで活用できるんじゃね?
となって、ブラウザの外でも普通のプログラミング言語としてJavaScriptを使うためには、どんな機能を追加すべきか、みたいな議論をするプロジェクトが&lt;strong&gt;2009年&lt;/strong&gt;に立ち上がった。
&lt;a href=&#34;http://www.commonjs.org/&#34;&gt;CommonJS&lt;/a&gt;である。&lt;/p&gt;

&lt;p&gt;CommonJSの最大の功績は多分、モジュールシステムを言語仕様でちゃんとサポートしよう、と言ったこと。
モジュールシステムは、Cでいうincludeとか、JavaやPythonのimportとか、そういう機能。
JavaScriptにはもともとそういうのが無くて、単にファイルを分割して個別にロードしていただけだったので、名前空間がコンフリクトしたりしなかったりしてた。&lt;/p&gt;

&lt;p&gt;因みに、JavaScriptのモジュールシステムには、CommonJSのやつ以外にも&lt;a href=&#34;https://en.wikipedia.org/wiki/Asynchronous_module_definition&#34;&gt;AMD&lt;/a&gt;というのがあったけど、そっちは盛り上がらなかった。&lt;/p&gt;

&lt;h3 id=&#34;node-js&#34;&gt;Node.js&lt;/h3&gt;

&lt;p&gt;CommonJSの流れを汲んで、サーバサイドのJavaScriptランタイムとして&lt;a href=&#34;https://nodejs.org/en/&#34;&gt;Node.js&lt;/a&gt;が&lt;strong&gt;2009年&lt;/strong&gt;にリリースされた。
これにより、ブラウザ外でJavaScriptを実行できるようになり、以降のJavaScript開発体験の劇的な改善につながった。&lt;/p&gt;

&lt;h3 id=&#34;パッケージマネージャ&#34;&gt;パッケージマネージャ&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;2010年&lt;/strong&gt; には、Node.jsにパッケージマネージャとして&lt;a href=&#34;https://www.npmjs.com/&#34;&gt;npm&lt;/a&gt;が同梱されるようになった。
これにより、モジュールを公開してシェアして再利用する文化が定着し、JavaScriptプログラムの開発効率や品質がかなり向上したはず。&lt;/p&gt;

&lt;p&gt;パッケージマネージャとしてはもうひとつ、&lt;a href=&#34;https://bower.io/&#34;&gt;Bower&lt;/a&gt;というのが&lt;strong&gt;2012年&lt;/strong&gt;に出た。
npmはサーバサイドのパッケージ、Bowerはクライアントサイドのパッケージ、みたいな住みわけが当初はあったが、最近は全部npmになってBower使ってるプロジェクトは見なくなった。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2016年10月&lt;/strong&gt; には、Facebookが&lt;a href=&#34;https://yarnpkg.com/lang/ja/&#34;&gt;Yarn&lt;/a&gt;というnpmを代替するツールを&lt;a href=&#34;https://code.fb.com/web/yarn-a-new-package-manager-for-javascript/&#34;&gt;発表&lt;/a&gt;。
パッケージバージョンのロック、&lt;a href=&#34;https://twitter.com/madbyk/status/988795520805203969?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E988795520805203969&amp;amp;ref_url=https%3A%2F%2Fblog.risingstack.com%2Fyarn-vs-npm-node-js-package-managers%2F&#34;&gt;CDN (CloudFlare)&lt;/a&gt;・キャッシュ・並列処理によるパッケージダウンロードの高速化、パッケージ間のバージョンの不整合解消(フラットモード)、といった機能により、発表直後から急速にシェアを伸ばした。&lt;/p&gt;

&lt;h3 id=&#34;モジュールバンドラ&#34;&gt;モジュールバンドラ&lt;/h3&gt;

&lt;p&gt;サーバサイドでモジュールシステムができたのはよかったけど、その仕様がブラウザでサポートされることは終ぞなかった。
ので、モジュールバンドラというものが生まれた。
これは、ソース中のモジュールインポート(requireとかimport)をたどって、モジュール分割されたソースをブラウザが読めるように一つに結合してくれるツール。&lt;/p&gt;

&lt;p&gt;モジュールバンドラのパイオニアが、&lt;strong&gt;2011年&lt;/strong&gt; にリリースされた&lt;a href=&#34;http://browserify.org/&#34;&gt;Browserify&lt;/a&gt;。
Browserifyは、モジュールの結合だけでなく、Node.js特有のAPIをある程度ブラウザでも動くようにしてくれるなど、魔法のようなツールだった。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2012年&lt;/strong&gt; には&lt;a href=&#34;https://webpack.js.org/&#34;&gt;webpack&lt;/a&gt;というモジュールバンドラが出て、後述のトランスパイラと上手く連携したり、JavaScriptだけでなくCSSもHTMLもフォントも画像ファイルもなんでもバンドルできる高機能により、Browserifyを食った。&lt;/p&gt;

&lt;p&gt;モジュールバンドルすると、ファイルサイズが大きくなって、ブラウザでロードするのに時間がかかって、初期画面の表示が遅くなる問題があった。
&lt;strong&gt;2015年&lt;/strong&gt;、その問題を軽減すべく、&lt;a href=&#34;https://rollupjs.org/guide/en&#34;&gt;Rollup&lt;/a&gt;というのが出てきた。
Rollupは、&lt;a href=&#34;https://rollupjs.org/guide/en#tree-shaking&#34;&gt;Tree-shaking&lt;/a&gt;という機能で、バンドル時に不要なコードを削除することでファイルサイズを小さくできることを売りにした。
が、webpackがバージョン2でTree-shakingをサポートしたため、使う理由がなくなった。&lt;/p&gt;

&lt;p&gt;webpackは機能的には最高にクールだったが、設定が複雑で設定ファイルが肥大化するという問題があった。
この問題を解消すべく、&lt;strong&gt;2017年末&lt;/strong&gt; に&lt;a href=&#34;https://parceljs.org/&#34;&gt;Parcel&lt;/a&gt;というモジュールバンドラがリリースされ、ゼロ設定で使えるということで人気を集めてきている。
今の時点でプロダクションレディなレベルなのかは疑問。&lt;/p&gt;

&lt;h3 id=&#34;altjs&#34;&gt;AltJS&lt;/h3&gt;

&lt;p&gt;上に書いた通り、&lt;strong&gt;2009年&lt;/strong&gt; にECMAScript 5が発行されて、JavaScriptは若干改善されたわけだけど、はっきり言ってまだまだ貧弱な言語だった。
そこに&lt;a href=&#34;https://coffeescript.org/&#34;&gt;CoffeeScript&lt;/a&gt;が登場。
&lt;strong&gt;2009年末&lt;/strong&gt; のことだった。&lt;/p&gt;

&lt;p&gt;CoffeeScriptは、RubyやPythonみたいな簡潔で機能的な構文を備えた生産性の高い言語で、JavaScriptにコンパイルできる。
クラス構文とか、アロー関数とか、配列内包表記とか、インデントによるブロック構造とかを実現してて書き心地がかなりよかったのと、Ruby on Railsに採用されたというのもあって、&lt;strong&gt;2010年代中盤&lt;/strong&gt; くらいまで結構流行った。&lt;/p&gt;

&lt;p&gt;CoffeeScriptのように、JavaScriptの代替として使い、JavaScriptに変換して実行するのを主なユースケースとする言語を、AltJS (Alternative JavaScript)と呼ぶ。
CoffeeScriptの最大の功績は、このAltJSという分野を切り開き、JavaScriptフロントエンドにコンパイルという概念を持ち込んだことだったと思う。&lt;/p&gt;

&lt;p&gt;CoffeeScript自体はその後、&lt;strong&gt;2015年&lt;/strong&gt; に発行されたECMAScript 2015がその仕様を取り込んだことで役目を終えた。
&lt;strong&gt;2017年9月&lt;/strong&gt; に&lt;a href=&#34;https://coffeescript.org/announcing-coffeescript-2/&#34;&gt;バージョン2をアナウンス&lt;/a&gt;して再起を図ったが、そのころすでに他に有力なAltJSが出てたし、ECMAScriptも結構成熟してきてたし、あまり注目されなかった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;AltJSには他に以下のようなものがあるが、ほぼTypeScriptしか使われてなさそう。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.typescriptlang.org/&#34;&gt;TypeScript&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2012年10月&lt;/strong&gt; 初版リリース。&lt;/li&gt;
&lt;li&gt;Microsoft製。&lt;/li&gt;
&lt;li&gt;静的型付けが最大の特徴で、他にもクラスやアロー関数やレキシカル変数などをサポート。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.purescript.org/&#34;&gt;PureScript&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2014年4月&lt;/strong&gt; 初版リリース。&lt;/li&gt;
&lt;li&gt;強い静的型付けの関数型言語。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.dartlang.org/&#34;&gt;Dart&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2011年10月&lt;/strong&gt; 初版リリース。&lt;/li&gt;
&lt;li&gt;Google製。&lt;/li&gt;
&lt;li&gt;全く流行らなかったし、Google自身も社内標準プログラミング言語にTypeScriptを採用したので、だれも使ってなくてよくわからない。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2018年8月&lt;/strong&gt; にバージョン2がリリースされ、再起を図ってはいる。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jsx.github.io/&#34;&gt;JSX&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;DeNA製。&lt;/li&gt;
&lt;li&gt;名前がReactの&lt;a href=&#34;https://reactjs.org/docs/introducing-jsx.html&#34;&gt;JSX&lt;/a&gt;と紛らわしい。&lt;/li&gt;
&lt;li&gt;誰も使ってないし、&lt;strong&gt;2014年&lt;/strong&gt; くらいから開発止まってる。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;altcss&#34;&gt;AltCSS&lt;/h3&gt;

&lt;p&gt;CSSにもalternativesがある。
というかAltJSよりも歴史が古い。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://sass-lang.com/&#34;&gt;Sass&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2006年&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;SASS記法とSCSS記法がある。&lt;/li&gt;
&lt;li&gt;AltCSSでは1番人気っぽい。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://lesscss.org/&#34;&gt;Less&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2009年&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;Sassに感銘を受けたけど、そのSASS記法がCSSと違いすぎてちょっと、と思った人がCSSに寄せて作った。けどSassもCSSに寄せたSCSS記法をサポートしたため食われた。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://stylus-lang.com/&#34;&gt;Stylus&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2010年&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://postcss.org/&#34;&gt;PostCSS&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2013年&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;正確にはAltCSSではなく、CSSを処理するツールをJavaScriptで開発できるフレームワーク。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://preset-env.cssdb.org/&#34;&gt;PostCSS Preset Env&lt;/a&gt;というプラグインとともに使うと、CSSのエッジな機能を使えるようになる。つまりどちらかといえば後述のトランスパイラに近い。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;トランスパイラ&#34;&gt;トランスパイラ&lt;/h3&gt;

&lt;p&gt;CoffeeScriptの流行などを受けて、ECMAScriptに再び改善の圧力がかかったのか、&lt;strong&gt;2011年後半&lt;/strong&gt; ころから次期ECMAScriptの議論が活発化した。
&lt;strong&gt;2015年&lt;/strong&gt; に満を持してECMAScript 6改めECMAScript 2015が発行された。&lt;/p&gt;

&lt;p&gt;ECMAScript 2015は、クラス構文、アロー関数、レキシカル変数、定数、関数のデフォルト引数、ジェネレータ、テンプレート文字列、モジュールシステムなどをサポートし、一気にまともなプログラミング言語になった。&lt;/p&gt;

&lt;p&gt;しかし、それらの新しい機能をアプリケーションに使うには、各社のブラウザのJavaScriptエンジンが実装して、さらにその実装したバージョンのブラウザがユーザに十分に行きわたるのを待たないといけない。
ECMAScriptの新機能は、正式に発行される前から仕様が公開され、ブラウザが先行して実装してはいくものの、&lt;a href=&#34;http://threevirtues.com/&#34;&gt;プログラマは短気&lt;/a&gt;なのでそんなの待ってられない。&lt;/p&gt;

&lt;p&gt;といった状況のなか、&lt;strong&gt;2014年10月&lt;/strong&gt; に&lt;a href=&#34;https://www.npmjs.com/package/6to5&#34;&gt;6to5&lt;/a&gt;というツールがnpmで公開された。
ECMAScript 6で書かれたコードをECMAScript 5なコードに変換してくれる、トランスパイラというツールだった。&lt;/p&gt;

&lt;p&gt;(実はトランスパイラとしては&lt;strong&gt;2013年3月&lt;/strong&gt;に公開されたGoogle製の&lt;a href=&#34;https://github.com/google/traceur-compiler&#34;&gt;Traceur&lt;/a&gt;とか、&lt;strong&gt;2014年4月&lt;/strong&gt; に公開されたEmber.jsチーム製の&lt;a href=&#34;https://esnext.github.io/esnext/&#34;&gt;esnext&lt;/a&gt;のほうが先駆けだったんだけど、6to5の開発スピードがとんでもなく早く、&lt;strong&gt;2015年1Q&lt;/strong&gt; には機能面で両者を抜いてしまったらしい。)&lt;/p&gt;

&lt;p&gt;6to5は&lt;strong&gt;2015年2月&lt;/strong&gt;に名前を&lt;a href=&#34;https://babeljs.io/&#34;&gt;Babel&lt;/a&gt;に&lt;a href=&#34;https://babeljs.io/blog/2015/02/15/not-born-to-die&#34;&gt;変えて&lt;/a&gt;、単に6to5という名前が示す機能だけでなく、JavaScript周りの様々なツールを開発・統合するためのプラットフォームとなった。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2018年現在&lt;/strong&gt;、Babel無しでフロントエンド開発をすることはほぼ無さそうな感じになってる。&lt;/p&gt;

&lt;h3 id=&#34;タスクランナー&#34;&gt;タスクランナー&lt;/h3&gt;

&lt;p&gt;モジュールバンドラやら、AltJSやら、AltCSSやらで、フロントエンドにコンパイルとかビルドとかいう作業が必要になって来たため、この業界にも必然的にタスクランナーが登場してきた。&lt;/p&gt;

&lt;p&gt;タスクランナーというのは、他業界ではビルドツールなどとも呼ばれているもので、Cとかで使われる&lt;a href=&#34;https://ja.wikipedia.org/wiki/Make&#34;&gt;Make&lt;/a&gt;とか、Javaの&lt;a href=&#34;https://ant.apache.org/&#34;&gt;Ant&lt;/a&gt;とか&lt;a href=&#34;https://maven.apache.org/&#34;&gt;Maven&lt;/a&gt;とか&lt;a href=&#34;https://gradle.org/&#34;&gt;Gradle&lt;/a&gt;とか、Googleの&lt;a href=&#34;https://bazel.build/&#34;&gt;Bazel&lt;/a&gt;とかと同様のもの。&lt;/p&gt;

&lt;p&gt;まず、&lt;strong&gt;2012年1月&lt;/strong&gt; に&lt;a href=&#34;https://gruntjs.com/&#34;&gt;Grunt&lt;/a&gt;がリリースされて人気を博した。
が、当時のGruntの設定ファイルがJSONで&lt;a href=&#34;http://monmon.hatenablog.com/entry/2013/12/20/151321&#34;&gt;書きにくい&lt;/a&gt;とか、処理がシーケンシャルで遅いとかいう不満が潜在的に溜まっていった。&lt;/p&gt;

&lt;p&gt;で、それらの問題を払拭する&lt;a href=&#34;https://gulpjs.com/&#34;&gt;gulp&lt;/a&gt;が&lt;strong&gt;2013年7月&lt;/strong&gt;に出て、Gruntを食った。&lt;/p&gt;

&lt;p&gt;けど結局、Gruntもgulpも、タスクの処理をどこかの馬の骨が作ったプラグインに頼っていて不安定で、またビルドツールというレイヤが増えたせいでビルドエラーのデバッグがし辛くなるという&lt;a href=&#34;https://qiita.com/chuck0523/items/dafdbd19c12efd40e2de&#34;&gt;根本的な問題が顕在化&lt;/a&gt;し、&lt;a href=&#34;https://docs.npmjs.com/misc/scripts&#34;&gt;npm-scripts&lt;/a&gt;でいいじゃん、ってなった。&lt;/p&gt;

&lt;p&gt;シンプルイズベスト。&lt;/p&gt;

&lt;h1 id=&#34;javascriptフロントエンドフレームワーク-第2世代&#34;&gt;JavaScriptフロントエンドフレームワーク (第2世代)&lt;/h1&gt;

&lt;p&gt;前章で書いたフロントエンド界の変容の後あたりに、当時の先端技術を取り入れて誕生したフロントエンドフレームワークを、この記事では第2世代と呼ぶ。&lt;/p&gt;

&lt;p&gt;第2世代は第1世代から正統な進化を遂げた感じで、あいかわらずMVW (i.e. MV*)だった。
主要なのは以下。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://vuejs.org/&#34;&gt;Vue.js&lt;/a&gt; v1&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2013年12月&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;Googleのエンジニア(個人)製。&lt;/li&gt;
&lt;li&gt;MVVMアーキテクチャ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mizchi.hatenablog.com/entry/2014/02/13/153742&#34;&gt;軽量AngularJS&lt;/a&gt;な感じらしい。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://aurelia.io/&#34;&gt;Aurelia&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2015年11月&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;AngularJSっぽいフルスタックフレームワークで、EcmaScript 2015+とかWeb Componentsとかの先端技術を取り入れていることが売り。&lt;/li&gt;
&lt;li&gt;2-wayバインディング推しで、あまり流行らなかった。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://riot.js.org/&#34;&gt;Riot&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2014年6月&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;AngularJSもReactも複雑すぎ。フロントエンド開発に必要十分なコンパクトな機能を提供するぜ、というフレームワーク。&lt;/li&gt;
&lt;li&gt;Aureliaよりかは使われていそう。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://angular.io/&#34;&gt;Angular&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2016年9月&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;AngularJSの後継。AngularJSとの互換性をばっさり切り捨てる代わりに、アーキテクチャを刷新し、性能面と機能面の&lt;a href=&#34;https://medium.com/@mnemon1ck/why-you-should-not-use-angularjs-1df5ddf6fc99&#34;&gt;色々な問題&lt;/a&gt;を克服したらしい。&lt;/li&gt;
&lt;li&gt;が、Reactが画期的過ぎてAngularJSの栄光は取り戻せなかった。&lt;/li&gt;
&lt;li&gt;最初2-wayバインディングまで切り捨てたが、あとで復活させた。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;react-virtual-dom&#34;&gt;React (Virtual DOM)&lt;/h1&gt;

&lt;p&gt;第1世代から流行っていた2-wayバインディングがちょっと&lt;a href=&#34;https://stackoverflow.com/questions/35379515/why-is-two-way-databinding-in-angularjs-an-antipattern&#34;&gt;辛みを帯びてきた&lt;/a&gt;。
というか、2-wayバインディングしかできないAngularJSが辛くなってきたということだったのかもしれない。&lt;/p&gt;

&lt;p&gt;2-wayバインディングには以下のような問題があった。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;変更をwatchするオブジェクトが増えて、性能が悪くなる。&lt;/li&gt;
&lt;li&gt;ModelとViewとの間の依存やデータの流れが複雑になって、コーディングやデバッグが難しくなる。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;これに異を唱えて登場してきたのがFacebookによる&lt;a href=&#34;https://reactjs.org/&#34;&gt;React&lt;/a&gt;。
&lt;strong&gt;2013年3月&lt;/strong&gt; のことであった。&lt;/p&gt;

&lt;p&gt;2-wayバインディングもMVCもテンプレートも要らんとして、代わりにReactが突きつけてきた&lt;a href=&#34;https://reactjs.org/docs/faq-internals.html&#34;&gt;Virtual DOM&lt;/a&gt;という解は、世界中の人々の&lt;a href=&#34;https://qiita.com/mizchi/items/4d25bc26def1719d52e6&#34;&gt;魂を震えさせた&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;Virtual DOMは、その名の通りDOMの仮想化であり、JavaScriptからReactのAPIを通してDOMのようなものを更新すると、Reactがいい感じに実DOMを更新してくれるというもの。
開発者は深く考えずに、イベントが発生するごとに、ページ全体を表すDOMツリーがどうなっているべきかをReactに教えるだけでいい。
あとはReactが、現在の実DOMとの差分を計算し、差分だけを性能よく更新してくれる。
これによって開発者は、DOMの状態やイベントの種類をみてアドホックに実DOMやModelの更新処理を書くという苦行から解放され、宣言的に&lt;a href=&#34;http://blog.neleid.com/2016/04/05/%E5%AF%8C%E8%B1%AA%E7%9A%84%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%E3%81%AF%E6%AD%BB%E8%AA%9E%E3%81%8B/&#34;&gt;富豪的に&lt;/a&gt;フロントエンドプログラミングができるようになった。&lt;/p&gt;

&lt;p&gt;さらに&lt;strong&gt;2014年5月&lt;/strong&gt;、Reactにベストマッチするアプリケーションアーキテクチャとして&lt;a href=&#34;https://facebook.github.io/flux/&#34;&gt;Flux&lt;/a&gt;が発表された。
これは単方向のデータフローが特徴のアーキテクチャで、斬新でかっこよくて未来だった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/facebook/flux/raw/master/docs/img/flux-diagram-white-background.png&#34; alt=&#34;Flux&#34; title=&#34;Flux&#34; /&gt;
&lt;/p&gt;

&lt;h1 id=&#34;javascriptフロントエンドフレームワーク-第3世代&#34;&gt;JavaScriptフロントエンドフレームワーク (第3世代)&lt;/h1&gt;

&lt;p&gt;React後、Virtual DOMの実装がいくつも出てきた。
&lt;a href=&#34;https://github.com/Matt-Esch/virtual-dom&#34;&gt;virtual-dom&lt;/a&gt;とか&lt;a href=&#34;https://maquettejs.org/&#34;&gt;Maquette&lt;/a&gt;とか&lt;a href=&#34;https://preactjs.com/&#34;&gt;Preact&lt;/a&gt;とか&lt;a href=&#34;https://infernojs.org/&#34;&gt;Inferno&lt;/a&gt;とか。&lt;/p&gt;

&lt;p&gt;Fluxの実装も、Facebook自身による&lt;a href=&#34;https://github.com/facebook/flux&#34;&gt;Flux&lt;/a&gt;のほか、&lt;a href=&#34;http://fluxxor.com/&#34;&gt;Fluxxor&lt;/a&gt;とか&lt;a href=&#34;https://redux.js.org/&#34;&gt;Redux&lt;/a&gt;とか&lt;a href=&#34;https://mobx.js.org/&#34;&gt;MobX&lt;/a&gt;とか沢山出た。&lt;/p&gt;

&lt;p&gt;で、React+Reduxがいい感じってなって、&lt;a href=&#34;https://medium.com/@TechMagic/reactjs-vs-angular5-vs-vue-js-what-to-choose-in-2018-b91e028fa91d&#34;&gt;世界の8割近くの人がReactで書くようになって&lt;/a&gt;、猫も杓子もVirtual DOMってなった辺りのフロントエンドフレームワークを第3世代と呼ぶことにする。&lt;/p&gt;

&lt;p&gt;第3世代としては以下が挙げられる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://grommet.io/&#34;&gt;Grommet&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2015年6月&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;HPE製。&lt;/li&gt;
&lt;li&gt;Reactと&lt;a href=&#34;https://github.com/inuitcss/inuitcss&#34;&gt;inuitcss&lt;/a&gt;によるフレームワーク。&lt;/li&gt;
&lt;li&gt;全然流行ってないけど&lt;a href=&#34;http://grommet.io/docs/components&#34;&gt;コンポーネント&lt;/a&gt;の取り揃えがよくて結構いいような気がする。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://emberjs.com/blog/2015/08/13/ember-2-0-released.html&#34;&gt;Ember.js v2&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2015年8月&lt;/strong&gt; リリース。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://glimmerjs.com/&#34;&gt;Glimmer&lt;/a&gt;というレンダリングエンジンを搭載。

&lt;ul&gt;
&lt;li&gt;Glimmerは、テンプレートをGlimmer VM上で動くバイトコードにコンパイルして、実DOMを速くレンダリングしてくれるもの。&lt;/li&gt;
&lt;li&gt;Virtual DOMとは違う感じだけど、実DOMの更新を開発者の代わりにやってくれるあたり、目指しているものは同じ。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://jp.vuejs.org/2016/10/01/here-2.0/&#34;&gt;Vue.js v2&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2016年10月&lt;/strong&gt; リリース。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/snabbdom/snabbdom&#34;&gt;snabbdom&lt;/a&gt;ベースのVirtual DOM実装を搭載。&lt;/li&gt;
&lt;li&gt;2017年頭位からかなりの勢いで流行ってきている。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://hyperapp.js.org/&#34;&gt;Hyperapp&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2017年1月&lt;/strong&gt; に誕生。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://qiita.com/&#34;&gt;Qiita&lt;/a&gt;で働いてるエンジニアが趣味で作ったフレームワークで、Qiitaに採用された。&lt;/li&gt;
&lt;li&gt;超軽量(1KB!)で、シンプルが売り。&lt;/li&gt;
&lt;li&gt;独自のVirtual DOM実装であるPicodom(現&lt;a href=&#34;https://github.com/jorgebucaran/superfine&#34;&gt;superfine&lt;/a&gt;)を搭載。&lt;/li&gt;
&lt;li&gt;JSXにも対応。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://dojo.io/&#34;&gt;Dojo&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2018年5月&lt;/strong&gt; 正式版リリース。&lt;/li&gt;
&lt;li&gt;Dojo Toolkitの後継。&lt;/li&gt;
&lt;li&gt;Virtual DomでTypeScriptでリアクティブでフルスタック。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;終わりに&#34;&gt;終わりに&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;2018年8月現在&lt;/strong&gt; では、React vs Vue.js vs Angularといった感じで、激動の時代が過ぎてやや落ち着いて来ている感があるが、油断はできない。
実際、最近&lt;a href=&#34;http://elm-lang.org/&#34;&gt;Elm&lt;/a&gt;という関数型AltJS兼Frontendフレームワークがじわじわ盛り上がってきている感じがあり、一波乱あるかもしれない。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;いろいろ書いたけど、&lt;a href=&#34;https://electronjs.org/&#34;&gt;Electron&lt;/a&gt;とか&lt;a href=&#34;https://facebook.github.io/react-native/&#34;&gt;React Native&lt;/a&gt;とか&lt;a href=&#34;https://nextjs.org&#34;&gt;Next.js&lt;/a&gt;とかの&lt;a href=&#34;https://jp.vuejs.org/v2/guide/ssr.html&#34;&gt;SSR&lt;/a&gt;とか&lt;a href=&#34;https://www.gatsbyjs.org/&#34;&gt;Gatsby.js&lt;/a&gt;とか&lt;a href=&#34;https://graphql.org/learn/&#34;&gt;GraphQL&lt;/a&gt;とか&lt;a href=&#34;https://developers.google.com/web/fundamentals/codelabs/your-first-pwapp/?hl=ja&#34;&gt;PWA&lt;/a&gt;とか&lt;a href=&#34;https://webassembly.org/&#34;&gt;WebAssembly&lt;/a&gt;とか&lt;a href=&#34;https://aws.amazon.com/jp/getting-started/serverless-web-app/&#34;&gt;サーバーレス&lt;/a&gt;とか&lt;a href=&#34;https://kuroeveryday.blogspot.com/2017/03/css-structure-and-rules.html&#34;&gt;CSS設計手法&lt;/a&gt;とかCSSフレームワークとかいろいろ書き漏れた。&lt;/p&gt;

&lt;p&gt;フロントエンドのユニットテストとかE2Eテストとかもいろいろあって面白い。
(E2Eテストは&lt;a href=&#34;https://www.kaitoy.xyz/2017/08/04/browser-test-framework/&#34;&gt;前に書いた&lt;/a&gt;。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;年表も気が向いたら追加したい。&lt;/p&gt;

&lt;p&gt;しかし&lt;a href=&#34;https://www.kaitoy.xyz/2018/08/19/creating-react-redux-app-from-scratch-01/&#34;&gt;React+Reduxに再入門したよ、っていう記事&lt;/a&gt;の前座として書くつもりだったのに、ずいぶん長編になってしまった…&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>PackerでESXiにVMを自動構築</title>
          <link>https://www.kaitoy.xyz/2018/06/30/packer-esxi/</link>
          <pubDate>Sat, 30 Jun 2018 16:56:34 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/06/30/packer-esxi/</guid>
          <description>

&lt;p&gt;前回「&lt;a href=&#34;https://www.kaitoy.xyz/2018/06/17/packer-k8s/&#34;&gt;Packer + Ansible on Windows 10でKubernetes 1.10のクラスタ on VirtualBoxを全自動構築&lt;/a&gt;」で、やったことをESXiでやっただけ。&lt;/p&gt;

&lt;p&gt;書いたコードは&lt;a href=&#34;https://github.com/kaitoy/packer-k8s&#34;&gt;GitHub&lt;/a&gt;に置いてある。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;前回との違い&#34;&gt;前回との違い&lt;/h2&gt;

&lt;p&gt;VirtualBoxとESXiとで変えないといけない部分は、主にPackerのbuilderの定義。
前回はvirtualbox-isoだったけど、今回は&lt;a href=&#34;https://www.packer.io/docs/builders/vmware-iso.html&#34;&gt;vmware-iso&lt;/a&gt;を使う。
それに伴ってパラメータが結構違ってくる。&lt;/p&gt;

&lt;p&gt;いっこトリッキーだったのが、&lt;code&gt;cdrom_adapter_type&lt;/code&gt;に&lt;code&gt;ide&lt;/code&gt;を明示的に指定しておかないと、CDロムドライブがSCSIになって、OSのインストールメディアのマウントか読み取り辺りでエラーになってしまったところ。
環境によっては指定しないでいいかも。&lt;/p&gt;

&lt;p&gt;また、&lt;code&gt;&amp;quot;vnc_disable_password&amp;quot;: &amp;quot;true&amp;quot;&lt;/code&gt;をbuilderに指定しておかないと、Packerが「Error handshaking with VNC: no suitable auth schemes found. server supported: []byte{0x1}」という&lt;a href=&#34;https://github.com/hashicorp/packer/issues/5939&#34;&gt;エラーを出す&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;あとは、Nested Virtualizationでやった(下記)ので、すごく遅くて、色々タイムアウトを伸ばしたりしてやる必要があった。&lt;/p&gt;

&lt;h2 id=&#34;esxi環境&#34;&gt;ESXi環境&lt;/h2&gt;

&lt;p&gt;ESXi(というかVMware vSphere Hypervisor)は、現時点での最新の6.7を使用。
自前のWindows 10 HomeのノートPC上で動くVMware Player 12で作ったVMにESXiをインストールして環境を作った。&lt;/p&gt;

&lt;p&gt;(因みにVirtualBoxにもインストールしてみたESXi上ではVM作成できなかった。VirtualBoxは今の時点でNested Virtualization未サポートで、サポートする予定もない模様。)&lt;/p&gt;

&lt;p&gt;Packerから操作するには、以下の設定をする必要がある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;静的IPアドレスを設定。Packerからの接続先に指定するので。&lt;/li&gt;
&lt;li&gt;SSH有効化。PackerがSSHで接続するので。

&lt;ul&gt;
&lt;li&gt;因みにSSHクライアントでESXiにつなぐときは、チャレンジ/レスポンス認証になる。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.packer.io/docs/builders/vmware-iso.html#building-on-a-remote-vsphere-hypervisor&#34;&gt;GuestIPHack の有効化&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;ESXiにSSHでログインして「&lt;code&gt;esxcli system settings advanced set -o /Net/GuestIPHack -i 1&lt;/code&gt;」&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ファイアウォール設定でVNCポート(TCP5900番台)を開ける。
これをしないとPackerが「Starting HTTP server on port xxxx」でハングする。
けどこれが一筋縄ではいかない。&lt;a href=&#34;https://kb.vmware.com/s/article/2008226?lang=ja&#34;&gt;この記事&lt;/a&gt;にあるように、&lt;code&gt;/etc/vmware/firewall/service.xml&lt;/code&gt;に設定を追加して「&lt;code&gt;esxcli network firewall refresh&lt;/code&gt;」してもいいんだけど、再起動するともとに戻ってしまう。&lt;/p&gt;

&lt;p&gt;ので、&lt;a href=&#34;https://kb.vmware.com/s/article/2043564&#34;&gt;この記事&lt;/a&gt;などを参考に、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;VNCポートの設定ファイルをデータストアに作成。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/vmfs/volumes/datastore1/svc/packer.xml&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;ConfigRoot&amp;gt;
  &amp;lt;service id=&amp;quot;1000&amp;quot;&amp;gt;
    &amp;lt;id&amp;gt;packer-vnc&amp;lt;/id&amp;gt;
    &amp;lt;rule id=&amp;quot;0000&amp;quot;&amp;gt;
      &amp;lt;direction&amp;gt;inbound&amp;lt;/direction&amp;gt;
      &amp;lt;protocol&amp;gt;tcp&amp;lt;/protocol&amp;gt;
      &amp;lt;porttype&amp;gt;dst&amp;lt;/porttype&amp;gt;
      &amp;lt;port&amp;gt;
        &amp;lt;begin&amp;gt;5900&amp;lt;/begin&amp;gt;
        &amp;lt;end&amp;gt;6000&amp;lt;/end&amp;gt;
      &amp;lt;/port&amp;gt;
    &amp;lt;/rule&amp;gt;
    &amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt;
    &amp;lt;required&amp;gt;true&amp;lt;/required&amp;gt;
  &amp;lt;/service&amp;gt;
&amp;lt;/ConfigRoot&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;設定ファイルをESXi起動時に読み込むスクリプトを記述。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/etc/rc.local.d/local.sh&lt;/code&gt;に以下を追記:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cp /vmfs/volumes/datastore1/svc/packer.xml /etc/vmware/firewall/
esxcli network firewall refresh
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;packer実行&#34;&gt;Packer実行&lt;/h2&gt;

&lt;p&gt;設定ファイルが出来てESXi環境が用意できれば、Packer実行は前回と一緒。&lt;/p&gt;

&lt;p&gt;ただ結局、環境が激遅なせいでところどころでタイムアウトしたり、OSインストール中にランダムにパニックになったり、PackerのBoot Commandの入力がランダムに失敗したりして、最後までビルド成功させる前に心折れた。
まあAnsibleのプロビジョニングの途中までは動いたので、だいたいよしとする。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Packer &#43; Ansible on Windows 10でKubernetes 1.10のクラスタ on VirtualBoxを全自動構築</title>
          <link>https://www.kaitoy.xyz/2018/06/17/packer-k8s/</link>
          <pubDate>Sun, 17 Jun 2018 23:22:33 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/06/17/packer-k8s/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2018/06/03/build-k8s-cluster-by-ansible/&#34;&gt;Kubernetes 1.10のクラスタを全手動で構築するのをAnsibleで全自動化した&lt;/a&gt;」の続きで、さらに&lt;a href=&#34;https://www.packer.io/&#34;&gt;Packer&lt;/a&gt;を組み合わせて、VM作成まで自動化した話。&lt;/p&gt;

&lt;p&gt;AnsibleをWindows(&lt;a href=&#34;https://www.msys2.org/&#34;&gt;MSYS2&lt;/a&gt;)で動かした話でもある。&lt;/p&gt;

&lt;p&gt;書いたPackerテンプレートは&lt;a href=&#34;https://github.com/kaitoy/packer-k8s&#34;&gt;GitHub&lt;/a&gt;に置いた。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;packerとは&#34;&gt;Packerとは&lt;/h2&gt;

&lt;p&gt;Packerは、様々な種類のVMを構築できるツール。
VagrantとかTerraformとかを開発している&lt;a href=&#34;https://www.hashicorp.com/&#34;&gt;HashiCorp&lt;/a&gt;が開発している。&lt;/p&gt;

&lt;p&gt;テンプレートと呼ばれるビルド定義をJSONファイルに書いて、ビルド、プロビジョニング、ポストプロセスを実行して、アーティファクトと呼ばれるビルドの成果物を生成する。&lt;/p&gt;

&lt;p&gt;ビルドのステップでは、VMを作成して、ハードウェア構成を設定したり、OSをインストールしたりする。&lt;/p&gt;

&lt;p&gt;以下のような環境でVMを作れる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;VirtualBox&lt;/li&gt;
&lt;li&gt;Hyper-V&lt;/li&gt;
&lt;li&gt;VMware Workstation&lt;/li&gt;
&lt;li&gt;VMware vSphere Hypervisor&lt;/li&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;li&gt;AWS EC2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;プロビジョニングのステップでは、ビルドで作ったVMのOS上で指定された操作を実行し、ソフトウェアのインストールなどのセットアップ処理をする。&lt;/p&gt;

&lt;p&gt;プロビジョニングには以下のようなツールを使える。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Shell&lt;/li&gt;
&lt;li&gt;PowerShell&lt;/li&gt;
&lt;li&gt;Ansible&lt;/li&gt;
&lt;li&gt;Chef&lt;/li&gt;
&lt;li&gt;Puppet&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;プロビジョニングが終わるとアーティファクト(VMイメージファイルや、AWS EC2のAMI IDとか)が出力される。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ポストプロセスのステップでは、アーティファクトを入力として何らかの処理をして、最終的なアーティファクトを生成する。&lt;/p&gt;

&lt;p&gt;ポストプロセスでは以下のような処理を実行できる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;アーカイブ&lt;/li&gt;
&lt;li&gt;VagrantBox生成&lt;/li&gt;
&lt;li&gt;AWS EC2へのインポート&lt;/li&gt;
&lt;li&gt;Docker push&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;PackerはGoで書かれていてビルド済みのバイナリが配布されているので、&lt;a href=&#34;https://www.packer.io/downloads.html&#34;&gt;ダウンロードページ&lt;/a&gt;から落として PATHの通ったところに置くだけでインストールできる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今回はPacker 1.2.4のWindows版をインストールした。&lt;/p&gt;

&lt;h2 id=&#34;packerの-テンプレート-https-www-packer-io-docs-templates-index-html-概要&#34;&gt;Packerの&lt;a href=&#34;https://www.packer.io/docs/templates/index.html&#34;&gt;テンプレート&lt;/a&gt;概要&lt;/h2&gt;

&lt;p&gt;Packerのテンプレートにはビルド、プロビジョニング、ポストプロセスの定義を複数かけて、複数環境のVM生成を1ファイルで定義できる。&lt;/p&gt;

&lt;p&gt;テンプレートには以下のプロパティを書く。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.packer.io/docs/templates/builders.html&#34;&gt;builders&lt;/a&gt;: ビルドの定義のリスト。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;description&lt;/code&gt;: テンプレートの説明。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;min_packer_version&lt;/code&gt;: Packer の最低バージョン指定。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.packer.io/docs/templates/post-processors.html&#34;&gt;post-processors&lt;/a&gt;: ポストプロセスの定義のリスト。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.packer.io/docs/templates/provisioners.html&#34;&gt;provisioners&lt;/a&gt;: プロビジョニングの定義のリスト。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.packer.io/docs/templates/user-variables.html&#34;&gt;variables&lt;/a&gt;: テンプレート内で使う変数の定義。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;_comment&lt;/code&gt;: コメントなどを書くためのプロパティ。実際はアンダースコアで始まればなんでもいい。JSON オブジェクトのルートレベルのみで使える。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;これらのうち、必須なのはbuildersだけ。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;一つのビルド定義には一つの&lt;a href=&#34;https://www.packer.io/docs/templates/communicator.html&#34;&gt;communicator&lt;/a&gt;を紐づける。
communicatorはビルド時にVMにつなぐための設定。
基本は&lt;a href=&#34;https://www.packer.io/docs/templates/communicator.html#ssh-communicator&#34;&gt;SSH&lt;/a&gt;だけど、WinRMとかもある。&lt;/p&gt;

&lt;h2 id=&#34;やりたいこと&#34;&gt;やりたいこと&lt;/h2&gt;

&lt;p&gt;Windows 10上でPackerとAnsibleを動かして、VirtualBoxのVMをOracle Linux 7.4で作って、Kubernetes 1.10をインストールしたい。
Windowsでやりたいのは、単にベアメタルのLinuxの環境が無いからってのもあるし、いずれHyper-VのVMも作りたいからってのもある。&lt;/p&gt;

&lt;p&gt;PackerはGo製で普通にWindowsで動くからいいけど、問題はAnsibleがPython製のくせにWindowsのPythonでは動かないこと。
AnsibleはWSLでは動くけど、VirtualBoxとかHyper-VはWindows上で動くから、PackerはWindows上で動かさないといけないはずで、そうなるとPackerから呼ばれるAnsibleもWindows上で動かさないといけない気がする。
のでWSLではだめな気がするし、そもそも実はWindows 7でも同じことやりたいのでWSLは無し。&lt;/p&gt;

&lt;p&gt;要はWindows上でLinuxのPythonを使ってAnsibleを動かしたい。
ならばCygwinかMSYS2+MinGW-w64かGit Bashか。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://superuser.com/questions/1255634/install-ansible-in-windows-using-git-bash&#34;&gt;ここ&lt;/a&gt;にAnsibleはCygwinでもGit Bashでも動かすの難しいと書いてあって、逆に&lt;a href=&#34;http://itsp0.blogspot.com/2017/03/ansible-msys2-ansible.html&#34;&gt;MSYS2でAnsible動かした記事&lt;/a&gt;はあったので、安直にMSYS2でやることにした。&lt;/p&gt;

&lt;h2 id=&#34;msys2インストール&#34;&gt;MSYS2インストール&lt;/h2&gt;

&lt;p&gt;MSYS2は、&lt;a href=&#34;http://www.msys2.org/&#34;&gt;公式サイト&lt;/a&gt;からx86_64のインストーラ(msys2-x86_64-20180531.exe)をダウンロードして実行して普通にインストールしただけ。&lt;/p&gt;

&lt;h2 id=&#34;ansibleインストール&#34;&gt;Ansibleインストール&lt;/h2&gt;

&lt;p&gt;MSYS2でのパッケージ管理にはpacmanを使う。&lt;/p&gt;

&lt;p&gt;何はともあれPythonを入れる。3系でいい。
&lt;code&gt;MSYS2 MSYS&lt;/code&gt;のショートカット(&lt;code&gt;MSYS2 MinGW 64-bit&lt;/code&gt;じゃだめ)からターミナルを開いて、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ pacman -S python
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、Python 3.6.2が入った。&lt;/p&gt;

&lt;p&gt;次に、Ansible(の依存)のビルドに必要なパッケージを入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ pacman -S gcc
$ pacman -S make
$ pacman -S libffi-devel
$ pacman -S openssl-devel
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;さらに、AnsibleからのSSH接続で(鍵ではなくて)パスワードを使う場合に必要なパッケージも入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ pacman -S sshpass
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;sshpassの依存としてopensshも入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Ansibleはpipでインストールするんだけど、pacmanで入れたPython 3にはpipが付いてなかったので、&lt;a href=&#34;https://pip.pypa.io/en/stable/installing/&#34;&gt;別途入れる&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ curl https://bootstrap.pypa.io/get-pip.py -LO
$ python get-pip.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(ちょっと古いけどpipは&lt;code&gt;pacman python3-pip&lt;/code&gt;でも入る。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、ようやくAnsibleインストール。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ export CFLAGS=-I/usr/lib/libffi-3.2.1/include
$ pip install ansible
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;依存するPyNaClのビルドに20分くらいかかるのでゆっくり待つと、インストール完了するはず。&lt;/p&gt;

&lt;p&gt;今回はAnsible 2.5.4がインストールされた。&lt;/p&gt;

&lt;p&gt;AnsibleでJinja2のipaddrフィルターを使うために、もう一つPyPiパッケージ入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ pip install netaddr
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;packerテンプレート作成&#34;&gt;Packerテンプレート作成&lt;/h2&gt;

&lt;p&gt;ビルドは、OSインストールメディアのISOファイルを使うVirtualBoxのビルダである&lt;a href=&#34;https://www.packer.io/docs/builders/virtualbox-iso.html&#34;&gt;virtualbox-iso&lt;/a&gt;を指定して書いた。&lt;/p&gt;

&lt;p&gt;OSのインストールは、&lt;a href=&#34;https://www.packer.io/docs/builders/virtualbox-iso.html#boot-command&#34;&gt;Boot Command&lt;/a&gt;をテンプレートに書くことで、インストーラのGUIを操作してやることもできるけど、RHEL系なら&lt;a href=&#34;https://access.redhat.com/documentation/ja-jp/red_hat_enterprise_linux/7/html/installation_guide/chap-kickstart-installations&#34;&gt;Kickstart&lt;/a&gt;を使うのが楽。&lt;/p&gt;

&lt;p&gt;Kickstartの定義ファイルは、普通に手動でOSをインストールした後、&lt;code&gt;/root/anaconda-ks.cfg&lt;/code&gt;を採取して、必要に応じて編集して作る。
今回作ったのは&lt;a href=&#34;https://github.com/kaitoy/packer-k8s/blob/fc530d94a04c15c97986e73d2c190e659ee0ddc0/http/ks.cfg&#34;&gt;これ&lt;/a&gt;で、&lt;a href=&#34;https://www.centos.org/forums/viewtopic.php?t=47262&#34;&gt;このスレ&lt;/a&gt;を参考に、Minimalインストールから、Wifiのファームウェアとか要らないのを抜いてる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;プロビジョニングは、「&lt;a href=&#34;https://www.kaitoy.xyz/2018/06/03/build-k8s-cluster-by-ansible/&#34;&gt;Kubernetes 1.10のクラスタを全手動で構築するのをAnsibleで全自動化した&lt;/a&gt;」ときのPlaybookを実行するやつを&lt;a href=&#34;https://www.packer.io/docs/provisioners/ansible.html&#34;&gt;公式マニュアル&lt;/a&gt;見ながら適当に書いて、ポストプロセスも適当に書いて、できたのが&lt;a href=&#34;https://github.com/kaitoy/packer-k8s/blob/fc530d94a04c15c97986e73d2c190e659ee0ddc0/k8s_single_node_cluster-vb.json&#34;&gt;これ&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ansible_env_vars&lt;/code&gt;で&lt;code&gt;ANSIBLE_SSH_ARGS&lt;/code&gt;に&lt;code&gt;-o ControlMaster=no&lt;/code&gt;を入れているのは、&lt;a href=&#34;https://github.com/geerlingguy/JJG-Ansible-Windows/issues/6&#34;&gt;この問題&lt;/a&gt;に対応するため。&lt;/p&gt;

&lt;h2 id=&#34;ビルド実行&#34;&gt;ビルド実行&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;MSYS2 MSYS&lt;/code&gt;のショートカットからターミナルを開いて、Packerを実行してみたら以下のエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ packer build -var-file=variables.json k8s_single_node_cluster-vb.json
bash: packer: コマンドが見つかりません
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;WindowsのPathが通ったところにPackerバイナリを置いておいてもMSYS2からは見えない。
のでpackerバイナリのフルパス(今回は&lt;code&gt;C:\Users\kaitoy\Desktop\bin\&lt;/code&gt;にインストールしてたのでそのパス)を指定してやる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ /c/Users/kaitoy/Desktop/bin/packer.exe build -var-file=variables.json k8s_single_node_cluster-vb.json
k8s-single-node-cluster output will be in this color.

1 error(s) occurred:

* Error running &amp;quot;ansible-playbook --version&amp;quot;: exec: &amp;quot;ansible-playbook&amp;quot;: executable file not found in %PATH%
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;と、今度は、ansible-playbookが無いと言われる。
ansible-playbookはansibleパッケージに入っていて/usr/bin/にインストールされているんだけど、Windows界で動いているPackerからはLinuxのPATHが見えないので、見つけられない。&lt;/p&gt;

&lt;p&gt;さらに、AnsibleのPlaybookのパスなど、Packerが妙な気を利かせてWindowsのフルパスにしてansible-playbookに渡してくれちゃうので、それをLinuxなパスに変換してやる必要がある。&lt;/p&gt;

&lt;p&gt;ということで、以下のようなラッパスクリプトを書いて、カレントディレクトリに置くことにした。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bat&#34;&gt;@echo off
setlocal enabledelayedexpansion

for %%f in (%*) do (
  if !key_file! == 1 (
    rem The value of ansible_ssh_private_key_file is the path to
    rem a key file in Windows TMP directory from MSYS2 point of view.
    set arg=/%tmp:\=/%
    set arg=!arg::=!
    set args=!args!=!arg!/%%~nxf
    set key_file=0
  ) else if %%~xf == .yml (
    rem Convert the passed Playbook path to relative one.
    set arg=%%f
    set arg=!arg:%CD%=!
    set arg=!arg:\=/!
    set args=!args! !arg:~1!
  ) else (
    rem Add other args as they are
    set args=!args! %%f
  )
  if %%f == ansible_ssh_private_key_file (
    rem The next arg will be the value of ansible_ssh_private_key_file
    set key_file=1
  )
)

echo args: %args%
C:\msys64\usr\bin\python C:\msys64\usr\bin\ansible-playbook -v %args%
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でちゃんと実行できるようになった。&lt;/p&gt;

&lt;p&gt;まとめると、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Windows 10に、&lt;/li&gt;
&lt;li&gt;VirtualBox 5.1.28をインストールして、&lt;/li&gt;
&lt;li&gt;Packer 1.2.4のWindows版をインストールして、&lt;/li&gt;
&lt;li&gt;MSYS2をインストールして、&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MSYS2 MSYS&lt;/code&gt;のターミナルでPython 3.6.2とAnsible 2.5.4とか(とGit)をインストールして、&lt;/li&gt;

&lt;li&gt;&lt;p&gt;以下を実行すればいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ git clone --recursive https://github.com/kaitoy/packer-k8s.git
$ cd packer-k8s
$ /c/Users/kaitoy/Desktop/bin/packer.exe build -var-file=variables.json k8s_single_node_cluster-vb.json
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code&gt;packer.exe build&lt;/code&gt;に&lt;code&gt;-debug&lt;/code&gt;を渡すと、内部の処理ステップごとに停止するようになり、デバッグしやすい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;一回実行したらゴミができて、次回実行時にエラーになるので、以下でクリーンアップする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ rm -rf /tmp/ansible
$ rm -f ~/.ssh/known_hosts
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因みに、上記known_hostsを消し忘れると以下のようなエラーになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; k8s-single-node-cluster: fatal: [k8s_master]: UNREACHABLE! =&amp;gt; {&amp;quot;changed&amp;quot;: false, &amp;quot;msg&amp;quot;: &amp;quot;Failed to connect to the host via ssh: @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\r\n@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @\r\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\r\nIT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\r\nSomeone could be eavesdropping on you right now (man-in-the-middle attack)!\r\nIt is also possible that a host key has just been changed.\r\nThe fingerprint for the ECDSA key sent by the remote host is\nSHA256:JNs/ZY38VpIuBE3QEzLHyLFGYe+Qg+bEWi8BOzgSNc0.\r\nPlease contact your system administrator.\r\nAdd correct host key in /home/kaitoy/.ssh/known_hosts to get rid of this message.\r\nOffending ECDSA key in /home/kaitoy/.ssh/known_hosts:1\r\nPassword authentication is disabled to avoid man-in-the-middle attacks.\r\nKeyboard-interactive authentication is disabled to avoid man-in-the-middle attacks.\r\nroot@127.0.0.1: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\r\n&amp;quot;, &amp;quot;unreachable&amp;quot;: true}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetes 1.10のクラスタを全手動で構築するのをAnsibleで全自動化した</title>
          <link>https://www.kaitoy.xyz/2018/06/03/build-k8s-cluster-by-ansible/</link>
          <pubDate>Sun, 03 Jun 2018 17:14:07 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/06/03/build-k8s-cluster-by-ansible/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/&#34;&gt;Kubernetes 1.10をスクラッチから全手動で構築&lt;/a&gt;」、「&lt;a href=&#34;https://www.kaitoy.xyz/2018/05/04/kubernetes-with-weave-net/&#34;&gt;Kubernetes 1.10のクラスタにWeave Netをデプロイする&lt;/a&gt;」、「&lt;a href=&#34;https://www.kaitoy.xyz/2018/05/05/kubernetes-kubelet-config-and-pod-sec-policy/&#34;&gt;Kubernetes 1.10のkubeletの起動オプションをKubelet ConfigファイルとPodSecurityPolicyで置き換える&lt;/a&gt;」のまとめとして、Kubernetes 1.10のクラスタを構築するAnsible Playbookを書いた。&lt;/p&gt;

&lt;p&gt;書いたものは&lt;a href=&#34;https://github.com/kaitoy/ansible-k8s&#34;&gt;GitHub&lt;/a&gt;に置いた。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;ansibleとは&#34;&gt;Ansibleとは&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.ansible.com/&#34;&gt;Ansible&lt;/a&gt;は、Ansible社が開発したOSSのIT自動化ツール。
Ansible社は2015年10月にRedHatが買収したので、現在はRedHatが開発している。
似たようなツールに&lt;a href=&#34;https://puppet.com/&#34;&gt;Puppet&lt;/a&gt;や&lt;a href=&#34;https://www.chef.io/&#34;&gt;Chef&lt;/a&gt;があるが、最近はAnsibleが最も支持されている気がする。&lt;/p&gt;

&lt;p&gt;構成管理ツールと紹介されることが多い気がするが、2014年末位からはIT自動化ツールを自称していて、構成管理は実現するユースケースの一つという位置づけになっているので、そろそろ認識を改めてあげたい。&lt;/p&gt;

&lt;p&gt;ユースケースは以下のようなもの。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ansible.com/use-cases/provisioning&#34;&gt;プロビジョニング&lt;/a&gt; (ベアメタル、VM、クラウドインスタンス)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ansible.com/use-cases/configuration-management&#34;&gt;構成管理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ansible.com/use-cases/application-deployment&#34;&gt;アプリケーションデプロイメント&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ansible.com/use-cases/continuous-delivery&#34;&gt;CI/CD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ansible.com/use-cases/security-and-compliance&#34;&gt;セキュリティ・コンプライアンス管理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ansible.com/use-cases/orchestration&#34;&gt;オーケストレーション&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以下のような特徴を持つ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Python(とPowerShell)で作られてる。

&lt;ul&gt;
&lt;li&gt;昔はPython 2じゃないと動かなかったけど、2.2から&lt;a href=&#34;https://docs.ansible.com/ansible/2.3/python_3_support.html&#34;&gt;Python 3でも動くようになった&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;YAMLで書いた定義(Playbook)に従って処理を実行する。&lt;/li&gt;
&lt;li&gt;シンプルで簡便であることを売りにしている。

&lt;ul&gt;
&lt;li&gt;多数のモジュールがビルトインされていて、様々な操作を簡潔な定義で宣言的に実行できる。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;エージェントレスで、SSH(等)で対象のサーバにつないで処理を実行する。&lt;/li&gt;
&lt;li&gt;処理を冪等にできるような仕組みが備わっていて、特にビルトインモジュールを活用すると簡単に冪等性を持たせられる。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Pythonで書かれているのでどこでも動くかと思いきや、&lt;a href=&#34;https://docs.python.jp/3/library/fcntl.html&#34;&gt;fcntl&lt;/a&gt;とか&lt;a href=&#34;https://docs.python.jp/3/library/grp.html&#34;&gt;grp&lt;/a&gt;やらUnix特有のモジュールを使っているため、WindowsのPythonでは動かない。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://kzlog.picoaccel.com/post-935/&#34;&gt;MSYS2&lt;/a&gt;とか&lt;a href=&#34;https://qiita.com/comefigo/items/f2b42c22e903f43e136e&#34;&gt;WSL&lt;/a&gt;では動く模様。
(&lt;a href=&#34;https://superuser.com/questions/1255634/install-ansible-in-windows-using-git-bash&#34;&gt;Git Bashでは動かない…&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今回使ったのは最新版の2.5.3。&lt;/p&gt;

&lt;h2 id=&#34;ansibleインストール&#34;&gt;Ansibleインストール&lt;/h2&gt;

&lt;p&gt;AnsibleはYUMとかpipとかでインストールできる。&lt;/p&gt;

&lt;p&gt;今回はOracle Linux 7.4で動かすため、以下のようにインストールした。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;AnsibleのYUMリポジトリ追加&lt;/p&gt;

&lt;p&gt;以下の内容を&lt;code&gt;/etc/yum.repos.d/&lt;/code&gt;の適当な&lt;code&gt;.repo&lt;/code&gt;ファイルに書く。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;[ansible]
name=Ansible
baseurl=http://releases.ansible.com/ansible/rpm/release/epel-7-x86_64/
gpgcheck=0
enabled=1
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;依存するPythonパッケージのYUMリポジトリを有効化&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/etc/yum.repos.d/public-yum-ol7.repo&lt;/code&gt;を編集して、&lt;code&gt;ol7_openstack30&lt;/code&gt;セクションの&lt;code&gt;enabled&lt;/code&gt;を1にする。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;インストール&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# yum install -y ansible
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;playbookの書き方&#34;&gt;Playbookの書き方&lt;/h2&gt;

&lt;p&gt;Playbookの書き方は他にたくさん情報があるし、どうせすぐに陳腐化するのでここには書かない。&lt;/p&gt;

&lt;p&gt;以下を参照して書いた。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.ansible.com/ansible/latest/user_guide/playbooks_best_practices.html#how-to-differentiate-staging-vs-production&#34;&gt;公式のBest Practices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.ansible.com/ansible/latest/modules/modules_by_category.html&#34;&gt;公式マニュアルのモジュール編&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html&#34;&gt;公式マニュアルの変数編&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.ansible.com/ansible/latest/user_guide/playbooks_loops.html&#34;&gt;公式マニュアルのループ編&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://jinja.pocoo.org/docs/2.10/&#34;&gt;Jinja2のマニュアル&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://openedx.atlassian.net/wiki/spaces/OpenOPS/pages/26837527/Ansible+Code+Conventions&#34;&gt;edXのAnsibleコーディング規約&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;一つ他にあまりなかった情報を書く:&lt;/p&gt;

&lt;p&gt;タスクをループするとき、&lt;code&gt;with_items&lt;/code&gt;プロパティを書くのはもう古くて、バージョン2.5以降では&lt;code&gt;loop&lt;/code&gt;プロパティを使う。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;書いたPlaybookで構築できるのは以下のようなKubernetesクラスタ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Kubernetes: バージョン1.10.1

&lt;ul&gt;
&lt;li&gt;単一ノード&lt;/li&gt;
&lt;li&gt;全コンポーネント(kubelet、kube-proxy、kube-apiserver、kube-controller-manager、kube-scheduler、etcd)をsystemdで起動 (i.e. 非コンテナ)

&lt;ul&gt;
&lt;li&gt;kubeletとkube-proxy以外は非rootユーザ&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;コンポーネント間通信とkubectlの通信をTLSで暗号化&lt;/li&gt;
&lt;li&gt;コンポーネント間通信とkubectlの通信の認証は&lt;a href=&#34;https://kubernetes.io/docs/admin/authentication/#x509-client-certs&#34;&gt;x509クライアント証明書&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TLS Bootstrapping

&lt;ul&gt;
&lt;li&gt;Bootstrap token使用&lt;/li&gt;
&lt;li&gt;CSR自動承認&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tls/certificate-rotation/&#34;&gt;Certificate Rotation&lt;/a&gt;有効&lt;/li&gt;
&lt;li&gt;etcd 3.1.12&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.weave.works/oss/net/&#34;&gt;Weave Net&lt;/a&gt; 2.3.0&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/coredns/coredns&#34;&gt;CoreDNS&lt;/a&gt; 1.1.3&lt;/li&gt;
&lt;li&gt;SERVICE_CLUSTER_IP_RANGE (Serviceに割り当てるIPの範囲) は10.0.0.0/16&lt;/li&gt;
&lt;li&gt;CLUSTER_CIDR (Podに割り当てるIPの範囲) は10.32.0.0/16&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies&#34;&gt;Proxyモード&lt;/a&gt;はiptables。&lt;/li&gt;
&lt;li&gt;PodSecurityPolicy有効。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/&#34;&gt;KubeletConfiguration&lt;/a&gt;、&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/apis/kubeproxyconfig/v1alpha1/types.go&#34;&gt;KubeProxyConfiguration&lt;/a&gt;、&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/master/pkg/apis/componentconfig/v1alpha1/types.go&#34;&gt;KubeSchedulerConfiguration&lt;/a&gt;を使用。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;開発ツール付き

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/c-bata/kube-prompt&#34;&gt;kube-prompt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/moncho/dry&#34;&gt;dry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ansibleの変数をいじればある程度違う構成もできる。
複数ノードや、マスターコンポーネントの冗長化や、etcdが別サーバの構成もできそうな感じにはRoleを分けて書いたけど、試してはいない。&lt;/p&gt;

&lt;h2 id=&#34;kubespray&#34;&gt;kubespray&lt;/h2&gt;

&lt;p&gt;一通り作った後で、&lt;a href=&#34;https://github.com/kubernetes-incubator/kubespray&#34;&gt;kubespray&lt;/a&gt;というものを知った。
これ使うと、Ansibleでマルチノードのk8sクラスタ作れて、ネットワークプロバイダ切り替えたり、&lt;a href=&#34;https://istio.io/&#34;&gt;istio&lt;/a&gt;とか&lt;a href=&#34;https://helm.sh/&#34;&gt;Helm&lt;/a&gt;とかDocker Registryとか簡単にデプロイできたり、AWSやAzureにクラスタ作れたり、すごい。&lt;/p&gt;

&lt;p&gt;あ、いや、けどこれOracle Linuxサポートしてないし…&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetes 1.10のkubeletの起動オプションをKubelet ConfigファイルとPodSecurityPolicyで置き換える</title>
          <link>https://www.kaitoy.xyz/2018/05/05/kubernetes-kubelet-config-and-pod-sec-policy/</link>
          <pubDate>Sat, 05 May 2018 21:54:30 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/05/05/kubernetes-kubelet-config-and-pod-sec-policy/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/&#34;&gt;Kubernetes 1.10をスクラッチから全手動で構築&lt;/a&gt;」、「&lt;a href=&#34;https://www.kaitoy.xyz/2018/05/04/kubernetes-with-weave-net/&#34;&gt;Kubernetes 1.10のクラスタにWeave Netをデプロイする&lt;/a&gt;」の続き。&lt;/p&gt;

&lt;p&gt;kubeletの起動オプションの代わりに、Kubelet ConfigファイルとPodSecurityPolicyを使うように変更した話。&lt;/p&gt;

&lt;p&gt;ついでにkube-proxyとkube-schedulerもConfigファイルを使うようにした。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;kubelet-configファイル&#34;&gt;Kubelet Configファイル&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;journalctl -u kubelet&lt;/code&gt;すると、以下の警告が出ている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Apr 28 15:31:39 k8s-master kubelet[1370]: Flag --address has been deprecated, This parameter should be set via the config file specified by the Kubelet&#39;s -
-config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 28 15:31:40 k8s-master kubelet[1370]: Flag --pod-manifest-path has been deprecated, This parameter should be set via the config file specified by the K
ubelet&#39;s --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 28 15:31:40 k8s-master kubelet[1370]: Flag --cluster-dns has been deprecated, This parameter should be set via the config file specified by the Kubelet
&#39;s --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 28 15:31:40 k8s-master kubelet[1370]: Flag --cluster-domain has been deprecated, This parameter should be set via the config file specified by the Kube
let&#39;s --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 28 15:31:40 k8s-master kubelet[1370]: Flag --authorization-mode has been deprecated, This parameter should be set via the config file specified by the
Kubelet&#39;s --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 28 15:31:40 k8s-master kubelet[1370]: Flag --client-ca-file has been deprecated, This parameter should be set via the config file specified by the Kube
let&#39;s --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 28 15:31:40 k8s-master kubelet[1370]: Flag --cgroup-driver has been deprecated, This parameter should be set via the config file specified by the Kubel
et&#39;s --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 28 15:31:40 k8s-master kubelet[1370]: Flag --tls-min-version has been deprecated, This parameter should be set via the config file specified by the Kubelet&#39;s --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 28 15:31:40 k8s-master kubelet[1370]: Flag --allow-privileged has been deprecated, will be removed in a future version
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;kubeletのいくつかのオプションは、&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/&#34;&gt;https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/&lt;/a&gt; を参照してKubelet Configファイルのほうに書けとある。&lt;/p&gt;

&lt;p&gt;参照先のマニュアルには現時点でほぼ何も書いてないし、ググっても情報が無いので、&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/release-1.10/pkg/kubelet/apis/kubeletconfig/v1beta1/types.go&#34;&gt;ソース&lt;/a&gt;を見てそれっぽく書いてみた。&lt;/p&gt;

&lt;p&gt;将来的に調整しそうなパラメータは、Kubelet Configファイルにデフォルト値とともにコメントとして書き出している。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# DNS_SERVER_IP=10.0.0.10
# DNS_DOMAIN=&amp;quot;cluster.local&amp;quot;
# cat &amp;gt; /etc/kubernetes/kubelet.conf &amp;lt;&amp;lt; EOF
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
featureGates:
  RotateKubeletServerCertificate: true
address: &amp;quot;0.0.0.0&amp;quot;
staticPodPath: &amp;quot;/etc/kubernetes/manifests&amp;quot;
clusterDNS: [&amp;quot;${DNS_SERVER_IP}&amp;quot;]
clusterDomain: &amp;quot;${DNS_DOMAIN}&amp;quot;
authorization:
  mode: Webhook
  webhook:
    cacheAuthorizedTTL: &amp;quot;5m0s&amp;quot;
    cacheUnauthorizedTTL: &amp;quot;30s&amp;quot;
authentication:
  x509:
    clientCAFile: &amp;quot;/etc/kubernetes/pki/ca.crt&amp;quot;
  webhook:
    enabled: false
    cacheTTL: &amp;quot;0s&amp;quot;
  anonymous:
    enabled: false
cgroupDriver: &amp;quot;cgroupfs&amp;quot;
tlsMinVersion: &amp;quot;VersionTLS12&amp;quot;
tlsCipherSuites:
- &amp;quot;TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256&amp;quot;
- &amp;quot;TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384&amp;quot;
- &amp;quot;TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256&amp;quot;
- &amp;quot;TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384&amp;quot;
readOnlyPort: 0
# port: 10250
# containerLogMaxSize: &amp;quot;10Mi&amp;quot;
# containerLogMaxFiles: 5
# evictionHard:
#   imagefs.available: &amp;quot;15%&amp;quot;
#   memory.available: &amp;quot;100Mi&amp;quot;
#   nodefs.available: &amp;quot;10%&amp;quot;
#   nodefs.inodesFree: &amp;quot;5%&amp;quot;
# evictionMaxPodGracePeriod: 0
# evictionPressureTransitionPeriod: &amp;quot;5m0s&amp;quot;
# fileCheckFrequency: &amp;quot;20s&amp;quot;
# imageGCHighThresholdPercent: 85
# imageGCLowThresholdPercent: 80
# maxOpenFiles: 1000000
# maxPods: 110
# imageMinimumGCAge: &amp;quot;2m0s&amp;quot;
# nodeStatusUpdateFrequency: &amp;quot;10s&amp;quot;
# runtimeRequestTimeout: &amp;quot;2m0s&amp;quot;
# streamingConnectionIdleTimeout: &amp;quot;4h0m0s&amp;quot;
# syncFrequency: &amp;quot;1m0s&amp;quot;
# volumeStatsAggPeriod: &amp;quot;1m0s&amp;quot;
EOF
# PAUSE_IMAGE=k8s.gcr.io/pause-amd64:3.1
# cat &amp;gt; /etc/systemd/system/kubelet.service &amp;lt;&amp;lt; EOF
[Unit]
Description=Kubernetes Kubelet
Documentation=https://github.com/kubernetes/kubernetes
After=docker.service
Requires=docker.service

[Service]
User=root
Group=root
ExecStart=/usr/bin/kubelet \\
  --allow-privileged=true \\
  --config=/etc/kubernetes/kubelet.conf \\
  --bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \\
  --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \\
  --network-plugin=cni \\
  --cni-conf-dir=/etc/cni/net.d \\
  --cni-bin-dir=/opt/cni/bin \\
  --cert-dir=/etc/kubernetes/pki \\
  --rotate-certificates=true \\
  --v=2 \\
  --pod-infra-container-image=${PAUSE_IMAGE}
Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl restart kubelet
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--allow-privileged&lt;/code&gt;だけは、警告が出てるけどKubelet Configファイルで設定できない。&lt;/p&gt;

&lt;h2 id=&#34;podsecuritypolicy&#34;&gt;PodSecurityPolicy&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;--allow-privileged&lt;/code&gt;は非推奨。
どうも代わりに&lt;a href=&#34;https://kubernetes.io/docs/concepts/policy/pod-security-policy/&#34;&gt;PodSecurityPolicy&lt;/a&gt;で制御しろということのようだ。&lt;/p&gt;

&lt;p&gt;PodSecurityPolicyを使うにはまず、kube-apiserverの起動オプションの&lt;code&gt;--enable-admission-plugins&lt;/code&gt;に&lt;code&gt;PodSecurityPolicy&lt;/code&gt;を追加する必要がある。&lt;/p&gt;

&lt;p&gt;で、privilegedななんでもできるPodSecurityPolicyと、それを使うロールを作成する。
因みにPodSecurityPolicyは名前空間に属さない。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl create -f- &amp;lt;&amp;lt;EOF
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: privileged
spec:
  privileged: true
  hostIPC: true
  hostPID: true
  hostNetwork: true
  hostPorts:
  - min: 0
    max: 65535
  volumes:
  - &amp;quot;*&amp;quot;
  fsGroup:
    rule: &amp;quot;RunAsAny&amp;quot;
  runAsUser:
    rule: &amp;quot;RunAsAny&amp;quot;
  supplementalGroups:
    rule: &amp;quot;RunAsAny&amp;quot;
  allowPrivilegeEscalation: true
  allowedCapabilities:
  - &amp;quot;*&amp;quot;
  seLinux:
    rule: &amp;quot;RunAsAny&amp;quot;
EOF
# kubectl -n kube-system create role psp:privileged --verb=use --resource=podsecuritypolicy --resource-name=privileged
# kubectl -n weave create role psp:privileged --verb=use --resource=podsecuritypolicy --resource-name=privileged
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今のところ、privilegedなPodSecurityPolicyが必要なService AccountはWeave Netのkube-system:weave-netと、Weave Scopeのweave:weave-scopeとweave:default。
こいつらに上記ロールをバインドする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl -n kube-system create rolebinding weave-net:psp:privileged --role=psp:privileged --serviceaccount=kube-system:weave-net
# kubectl -n weave create rolebinding weave-scope:psp:privileged --role=psp:privileged --serviceaccount=weave:weave-scope
# kubectl -n weave create rolebinding weave-default:psp:privileged --role=psp:privileged --serviceaccount=weave:default
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あと、CoreDNS用のPodSecurityPolicyとロールを作ってバインドする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl apply -f- &amp;lt;&amp;lt;EOF
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: coredns
spec:
  privileged: false
  hostIPC: false
  hostPID: false
  hostNetwork: false
  hostPorts:
  - min: 0
    max: 65535
  volumes:
  - &amp;quot;configMap&amp;quot;
  - &amp;quot;secret&amp;quot;
  fsGroup:
    rule: &amp;quot;RunAsAny&amp;quot;
  runAsUser:
    rule: &amp;quot;RunAsAny&amp;quot;
  supplementalGroups:
    rule: &amp;quot;RunAsAny&amp;quot;
  allowPrivilegeEscalation: true
  seLinux:
    rule: &amp;quot;RunAsAny&amp;quot;
EOF
# kubectl -n kube-system create role psp:coredns --verb=use --resource=podsecuritypolicy --resource-name=coredns
# kubectl -n kube-system create rolebinding coredns:psp:coredns --role=psp:coredns --serviceaccount=kube-system:coredns
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで晴れてkubeletから&lt;code&gt;--allow-privileged&lt;/code&gt;を外せる、と思ったら、外したら動かなかった。
どうも現時点では&lt;a href=&#34;https://github.com/kubernetes/kubernetes/issues/58010&#34;&gt;kubeletとPodSecurityPolicyが連携できていない&lt;/a&gt;らしく、&lt;code&gt;--allow-privileged&lt;/code&gt;は付けとかないといけないようだ。
付けといても、PodSecurityPolicyでprivilegedをtrueにしないとprivilegedが許可されないので、動きとしては問題ない。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--allow-privileged&lt;/code&gt;はKubernetes 1.12で廃止される予定なので、それまでにはなんとかなるだろう。&lt;/p&gt;

&lt;h2 id=&#34;kube-proxy-configファイル&#34;&gt;Kube Proxy Configファイル&lt;/h2&gt;

&lt;p&gt;kube-proxyも&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/apis/config/types.go&#34;&gt;Kube Proxy Config&lt;/a&gt;というのがある。
&lt;a href=&#34;https://github.com/kubernetes/kubernetes/issues/50041&#34;&gt;ドキュメントには載ってない&lt;/a&gt;けど、使わないと警告が出るので適当に書いてみた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# CLUSTER_CIDR=&amp;quot;10.32.0.0/16&amp;quot;
# cat &amp;gt; /etc/kubernetes/kube-proxy.conf &amp;lt;&amp;lt; EOF
kind: KubeProxyConfiguration
apiVersion: kubeproxy.config.k8s.io/v1alpha1
featureGates:
  RotateKubeletServerCertificate: true
bindAddress: &amp;quot;0.0.0.0&amp;quot;
clientConnection:
  kubeconfig: &amp;quot;/etc/kubernetes/kube-proxy.kubeconfig&amp;quot;
clusterCIDR: &amp;quot;${CLUSTER_CIDR}&amp;quot;
EOF
# cat &amp;gt; /etc/systemd/system/kube-proxy.service &amp;lt;&amp;lt; EOF
[Unit]
Description=Kubernetes Kube Proxy
Documentation=https://github.com/kubernetes/kubernetes
After=network.target

[Service]
User=root
Group=root
ExecStart=/usr/bin/kube-proxy \\
  --config=/etc/kubernetes/kube-proxy.conf \\
  --v=2
Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl restart kube-proxy
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;kube-scheduler-confファイル&#34;&gt;Kube Scheduler Confファイル&lt;/h2&gt;

&lt;p&gt;kube-schedulerも&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/master/pkg/apis/componentconfig/v1alpha1/types.go&#34;&gt;Kube Scheduler Conf&lt;/a&gt;というのがある。
例によってドキュメントには載ってないけど、使わないと警告が出るので適当に書いてみた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# cat &amp;gt; /etc/kubernetes/kube-scheduler.conf &amp;lt;&amp;lt; EOF
kind: KubeSchedulerConfiguration
apiVersion: componentconfig/v1alpha1
featureGates:
  RotateKubeletServerCertificate: true
healthzBindAddress: &amp;quot;0.0.0.0&amp;quot;
clientConnection:
  kubeconfig: &amp;quot;/etc/kubernetes/kube-scheduler.kubeconfig&amp;quot;
EOF
# cat &amp;gt; /etc/systemd/system/kube-scheduler.service &amp;lt;&amp;lt; EOF
[Unit]
Description=Kubernetes Scheduler
Documentation=https://github.com/kubernetes/kubernetes
After=network.target

[Service]
User=kubernetes
Group=kubernetes
ExecStart=/usr/bin/kube-scheduler \\
  --config=/etc/kubernetes/kube-scheduler.conf \\
  --v=2
Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl restart kube-scheduler
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetes 1.10のクラスタにWeave Netをデプロイする</title>
          <link>https://www.kaitoy.xyz/2018/05/04/kubernetes-with-weave-net/</link>
          <pubDate>Fri, 04 May 2018 11:14:33 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/05/04/kubernetes-with-weave-net/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/&#34;&gt;Kubernetes 1.10をスクラッチから全手動で構築&lt;/a&gt;」で、Kubernetes 1.10のクラスタに、ネットワークプロバイダとして&lt;a href=&#34;https://github.com/coreos/flannel&#34;&gt;flannel&lt;/a&gt;をデプロイしたけど、flannelは&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/network-policies/&#34;&gt;Network Policy&lt;/a&gt;をサポートしていないので、代わりに&lt;a href=&#34;https://www.weave.works/oss/net/&#34;&gt;Weave Net&lt;/a&gt;をデプロイしてみた話。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;weave-netにした理由&#34;&gt;Weave Netにした理由&lt;/h1&gt;

&lt;p&gt;Network Policyをサポートしているネットワークプロバイダには現時点で以下のものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.projectcalico.org/&#34;&gt;Calico&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cilium/cilium&#34;&gt;Cilium&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kube-router.io/&#34;&gt;Kube-router&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/romana/romana&#34;&gt;Romana&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Weave Net&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;このなかで、よく名前を聞くのがCalicoとWeave Net。
GitHubのスター数が圧倒的に多いのがWeave Net。
&lt;a href=&#34;https://engineering.skybettingandgaming.com/2017/02/03/overlay-network-performance-testing/&#34;&gt;性能が比較的いい&lt;/a&gt;のがWeave Net。&lt;/p&gt;

&lt;p&gt;ということでWeave Netにした。&lt;/p&gt;

&lt;h1 id=&#34;weave-netデプロイ&#34;&gt;Weave Netデプロイ&lt;/h1&gt;

&lt;p&gt;以下を参考に設定してデプロイする。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.weave.works/docs/net/latest/kubernetes/kube-addon/&#34;&gt;https://www.weave.works/docs/net/latest/kubernetes/kube-addon/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.weave.works/docs/net/latest/install/installing-weave/&#34;&gt;https://www.weave.works/docs/net/latest/install/installing-weave/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/weaveworks/weave/blob/master/prog/weave-kube/launch.sh&#34;&gt;https://github.com/weaveworks/weave/blob/master/prog/weave-kube/launch.sh&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;kubernetesマニフェスト&#34;&gt;Kubernetesマニフェスト&lt;/h2&gt;

&lt;p&gt;Weave NetをKubernetesクラスタにデプロイするためのマニフェストは、&lt;a href=&#34;https://github.com/weaveworks/weave/releases&#34;&gt;GitHub Releases&lt;/a&gt;か&lt;code&gt;https://cloud.weave.works&lt;/code&gt;からダウンロードできる。
今回は後者にする。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;https://cloud.weave.works&lt;/code&gt;を使う場合、Kubernetesのバージョンなどのパラメータは&lt;a href=&#34;https://www.weave.works/docs/net/latest/kubernetes/kube-addon/#-changing-configuration-options&#34;&gt;クエリストリングで指定できる&lt;/a&gt;。
主なパラメータは以下。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;k8s-version: Kubernetesのバージョン。指定しないとlatest。&lt;/li&gt;
&lt;li&gt;password-secret: ノード間の&lt;a href=&#34;https://www.weave.works/docs/net/latest/concepts/encryption/&#34;&gt;Weave Net通信の暗号化&lt;/a&gt;に使うパスワードを保持するSecret名。指定しないと平文。(参考: &lt;a href=&#34;https://www.weave.works/docs/net/latest/tasks/manage/security-untrusted-networks/&#34;&gt;https://www.weave.works/docs/net/latest/tasks/manage/security-untrusted-networks/&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;IPALLOC_RANGE: Podに割り当てるIPアドレスの範囲。指定しないと10.32.0.0/12。&lt;/li&gt;
&lt;li&gt;CHECKPOINT_DISABLE: Weave Netのアップデートを&lt;a href=&#34;https://www.weave.works/docs/net/latest/install/installing-weave/#checkpoint&#34;&gt;定期的にチェック&lt;/a&gt;する機能の無効化オプション。&lt;/li&gt;
&lt;li&gt;WEAVE_MTU: MTUを指定するオプション。&lt;a href=&#34;https://www.weave.works/docs/net/latest/tasks/manage/fastdp/#packet-size-mtu&#34;&gt;デフォルトで1376バイト&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;WEAVE_MTUはとりあえずデフォルトにしておいて、IPALLOC_RANGEもデフォルトにして、通信暗号化して、CHECKPOINT_DISABLEをtrueにするとすると、マニフェストは以下のようにダウンロードできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# curl -fsSLo weave-daemonset.yaml &amp;quot;https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d &#39;\n&#39;)&amp;amp;env.CHECKPOINT_DISABLE=1&amp;amp;password-secret=weave-passwd&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(通信暗号化は単一ノードなら不要だと思うけどとりあえず設定しておく。)&lt;/p&gt;

&lt;h2 id=&#34;kubernetesコンポーネントの起動オプション&#34;&gt;Kubernetesコンポーネントの起動オプション&lt;/h2&gt;

&lt;p&gt;kube-controller-managerの起動オプションの&lt;code&gt;--cluster-cidr&lt;/code&gt;はIPALLOC_RANGEと同じにする必要がある。
今回は10.32.0.0/12を指定する。&lt;/p&gt;

&lt;p&gt;また、kube-proxyの起動オプションの&lt;a href=&#34;https://www.weave.works/docs/net/latest/kubernetes/kube-addon/#-things-to-watch-out-for&#34;&gt;要件&lt;/a&gt;は以下。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--masquerade-all&lt;/code&gt;を指定してはいけない。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--cluster-cidr&lt;/code&gt;を指定する場合、IPALLOC_RANGEと同じにする必要がある。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;また、kube-apiserverとkube-controller-managerの起動オプションに&lt;code&gt;--allow-privileged&lt;/code&gt;を付ける必要があるはず。&lt;/p&gt;

&lt;h2 id=&#34;secret作成&#34;&gt;Secret作成&lt;/h2&gt;

&lt;p&gt;password-secretに渡すSecretは以下のように作成できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# WEAVE_PASSWORD=$(echo -n &#39;your_secure_password&#39; | base64)
# cat &amp;lt;&amp;lt;EOF | kubectl create -f -
apiVersion: v1
kind: Secret
metadata:
  namespace: kube-system
  name: weave-passwd
type: Opaque
data:
  weave-passwd: ${WEAVE_PASSWORD}
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで準備完了。&lt;/p&gt;

&lt;h2 id=&#34;マニフェスト適用&#34;&gt;マニフェスト適用&lt;/h2&gt;

&lt;p&gt;以下のコマンドでマニフェストを適用し、Weave Netをデプロイできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl apply -f weave-daemonset.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;weaveworks/weave-kube:2.3.0&lt;/code&gt;と&lt;code&gt;weaveworks/weave-npc:2.3.0&lt;/code&gt;がpullされる。
前者が本体で、後者がNetwork Policy Controller。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;マスタノード上で以下のコマンドを実行すると、Weave NetのAPIを叩いて状態を確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# curl http://localhost:6784/status
        Version: 2.3.0 (version check update disabled)

        Service: router
       Protocol: weave 1..2
           Name: 92:44:35:3d:f8:d8(k8s-master)
     Encryption: enabled
  PeerDiscovery: enabled
        Targets: 1
    Connections: 1 (1 failed)
          Peers: 1
 TrustedSubnets: none

        Service: ipam
         Status: ready
          Range: 10.32.0.0/12
  DefaultSubnet: 10.32.0.0/12
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetes 1.10をスクラッチから全手動で構築</title>
          <link>https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/</link>
          <pubDate>Tue, 17 Apr 2018 00:31:48 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/</guid>
          <description>

&lt;p&gt;Oracle Linux 7.4.0のVMでKubernetes1.10.0のクラスタをスクラッチから全手動で作った。
参考にしたのは主に以下。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://nixaid.com/deploying-kubernetes-cluster-from-scratch/&#34;&gt;https://nixaid.com/deploying-kubernetes-cluster-from-scratch/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.10.md&#34;&gt;https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.10.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/getting-started-guides/scratch/&#34;&gt;https://kubernetes.io/docs/getting-started-guides/scratch/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/reference/setup-tools/kubeadm/implementation-details/&#34;&gt;https://kubernetes.io/docs/reference/setup-tools/kubeadm/implementation-details/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ulam.io/blog/kubernetes-scratch/&#34;&gt;https://ulam.io/blog/kubernetes-scratch/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/virtualization/windowscontainers/kubernetes/creating-a-linux-master&#34;&gt;https://docs.microsoft.com/en-us/virtualization/windowscontainers/kubernetes/creating-a-linux-master&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;構成&#34;&gt;構成&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;マシン: Windows 10 Homeのラップトップの上のVMware PlayerのVM

&lt;ul&gt;
&lt;li&gt;CPU: 2コア&lt;/li&gt;
&lt;li&gt;メモリ: 4GB&lt;/li&gt;
&lt;li&gt;NIF: NATのを一つ&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;OS: Oracle Linux 7.4.0

&lt;ul&gt;
&lt;li&gt;Minimalインストール&lt;/li&gt;
&lt;li&gt;IPアドレス: 192.168.171.200、静的割り当て&lt;/li&gt;
&lt;li&gt;ホスト名: k8s-master (hostsで解決)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Docker: Oracle Container Runtime for Docker (docker-engine) 17.06.2&lt;/li&gt;
&lt;li&gt;Kubernetes: バージョン1.10.0

&lt;ul&gt;
&lt;li&gt;単一ノード&lt;/li&gt;
&lt;li&gt;全コンポーネント(kubelet、kube-proxy、kube-apiserver、kube-controller-manager、kube-scheduler、etcd)をsystemdで起動 (i.e. 非コンテナ)

&lt;ul&gt;
&lt;li&gt;kubeletとkube-proxy以外は非rootユーザ&lt;/li&gt;
&lt;li&gt;kubeletは&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.10.2/cmd/kubelet/app/server.go#L388&#34;&gt;現時点でrootで動かす必要がある&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;kube-proxyはiptableいじったりする都合上rootで動かす必要があるっぽい。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;コンポーネント間通信とkubectlの通信をTLSで暗号化

&lt;ul&gt;
&lt;li&gt;TLS 1.2&lt;/li&gt;
&lt;li&gt;セキュアなCipher Suites&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;コンポーネント間通信とkubectlの通信の認証は&lt;a href=&#34;https://kubernetes.io/docs/admin/authentication/#x509-client-certs&#34;&gt;x509クライアント証明書&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TLS Bootstrapping

&lt;ul&gt;
&lt;li&gt;Bootstrap token使用&lt;/li&gt;
&lt;li&gt;CSR自動承認&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tls/certificate-rotation/&#34;&gt;Certificate Rotation&lt;/a&gt;有効&lt;/li&gt;
&lt;li&gt;etcd 3.1.12&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/coreos/flannel&#34;&gt;flannel&lt;/a&gt; 0.10.0&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/coredns/coredns&#34;&gt;CoreDNS&lt;/a&gt; 1.1.1&lt;/li&gt;
&lt;li&gt;SERVICE_CLUSTER_IP_RANGE (Serviceに割り当てるIPの範囲) は10.0.0.0/16

&lt;ul&gt;
&lt;li&gt;kube-apiserverのIPはこの範囲の最初のIP(i.e. 10.0.0.1)になる。&lt;/li&gt;
&lt;li&gt;ホストネットワークや、CLUSTER_CIDRと範囲が被らないようにする必要がある。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;CLUSTER_CIDR (Podに割り当てるIPの範囲) は10.244.0.0/16

&lt;ul&gt;
&lt;li&gt;flannelの要件に合わせている。&lt;/li&gt;
&lt;li&gt;ホストネットワークや、SERVICE_CLUSTER_IP_RANGEと範囲が被らないようにする必要がある。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies&#34;&gt;Proxyモード&lt;/a&gt;はiptables。

&lt;ul&gt;
&lt;li&gt;ipvsのほうが速いけど、flannelとかがサポートしているかよくわからないので。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;kubeletの動作条件にあるので、swapをoffにする。
Oracle Linuxにログインして、&lt;code&gt;/etc/fstab&lt;/code&gt;のswapの行を削除して、以下のコマンドを実行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# swapoff -a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;SELinuxはちゃんと設定すればKubernetes動かせるはずだけど、面倒なのでとりあえず無効にする。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/etc/selinux/config&lt;/code&gt;を編集して、&lt;code&gt;SELINUX&lt;/code&gt;を&lt;code&gt;permissive&lt;/code&gt;にして、以下のコマンドを実行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# setenforce 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ファイアウォールもちゃんと設定すればいいんだけど面倒なのでとりあえず無効にする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# systemctl stop firewalld
# systemctl disable firewalld
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで準備完了。&lt;/p&gt;

&lt;h2 id=&#34;クラスタ構築手順&#34;&gt;クラスタ構築手順&lt;/h2&gt;

&lt;p&gt;おおむね、k8sコンポーネント間の通信の暗号化に使う鍵と証明書の生成、各コンポーネント用kubeconfigの生成、etcdのデプロイ、k8sコンポーネントのデプロイ、fannelデプロイ、CoreDNSデプロイ、という流れ。
ついでに最後に&lt;a href=&#34;https://github.com/weaveworks/scope&#34;&gt;Weave Scope&lt;/a&gt;をデプロイしてみる。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Bridge netfilterとIP forwardingを設定&lt;/p&gt;

&lt;p&gt;まず、Bridge netfilterモジュールをロードする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# modprobe br_netfilter
# echo &amp;quot;br_netfilter&amp;quot; &amp;gt; /etc/modules-load.d/br_netfilter.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Bridge netfilterとIP forwardingを有効化する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# cat &amp;gt; /etc/sysctl.d/kubernetes.conf &amp;lt;&amp;lt; EOF
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward = 1
EOF
# sysctl -p /etc/sysctl.d/kubernetes.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;設定確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# lsmod |grep br_netfilter
# sysctl -a | grep -E &amp;quot;net.bridge.bridge-nf-call-|net.ipv4.ip_forward&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;x509証明書生成&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;opensslの設定作成&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# mkdir -p /etc/kubernetes/pki
# HOSTNAME=k8s-master
# K8S_SERVICE_IP=10.0.0.1
# MASTER_IP=192.168.171.200
# cat &amp;gt; /etc/kubernetes/pki/openssl.cnf &amp;lt;&amp;lt; EOF
[ req ]
distinguished_name = req_distinguished_name
[req_distinguished_name]
[ v3_ca ]
basicConstraints = critical, CA:TRUE
keyUsage = critical, digitalSignature, keyEncipherment, keyCertSign
[ v3_req_client ]
basicConstraints = CA:FALSE
keyUsage = critical, digitalSignature, keyEncipherment
extendedKeyUsage = clientAuth
[ v3_req_apiserver ]
basicConstraints = CA:FALSE
keyUsage = critical, digitalSignature, keyEncipherment
extendedKeyUsage = serverAuth
subjectAltName = @alt_names_cluster
[ v3_req_etcd ]
basicConstraints = CA:FALSE
keyUsage = critical, digitalSignature, keyEncipherment
extendedKeyUsage = serverAuth
subjectAltName = @alt_names_etcd
[ alt_names_cluster ]
DNS.1 = kubernetes
DNS.2 = kubernetes.default
DNS.3 = kubernetes.default.svc
DNS.4 = kubernetes.default.svc.cluster.local
DNS.5 = ${HOSTNAME}
IP.1 = ${MASTER_IP}
IP.2 = ${K8S_SERVICE_IP}
[ alt_names_etcd ]
DNS.1 = ${HOSTNAME}
IP.1 = ${MASTER_IP}
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kubernetes CA証明書生成&lt;/p&gt;

&lt;p&gt;以降で生成する証明書に署名するための証明書。
後述のTLS Bootstrappingでの証明書生成にも使う。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# groupadd -r kubernetes
# adduser -r -g kubernetes -M -s /sbin/nologin kubernetes
# CA_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/ca.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/ca.key
# chmod 0600 /etc/kubernetes/pki/ca.key
# openssl req -x509 -new -sha256 -nodes -key /etc/kubernetes/pki/ca.key -days $CA_DAYS -out /etc/kubernetes/pki/ca.crt -subj &amp;quot;/CN=kubernetes-ca&amp;quot;  -extensions v3_ca -config /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kube-apiserver証明書生成&lt;/p&gt;

&lt;p&gt;kube-apiserverのサーバ証明書。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# APISERVER_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/kube-apiserver.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/kube-apiserver.key
# chmod 0600 /etc/kubernetes/pki/kube-apiserver.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/kube-apiserver.key -subj &amp;quot;/CN=kube-apiserver&amp;quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/kube-apiserver.crt -days $APISERVER_DAYS -extensions v3_req_apiserver -extfile /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kube-apiserver-kubelet証明書生成&lt;/p&gt;

&lt;p&gt;kube-apiserverが&lt;a href=&#34;https://kubernetes.io/docs/concepts/architecture/master-node-communication/#apiserver-kubelet&#34;&gt;kubeletのAPIにアクセス&lt;/a&gt;するときのクライアント証明書。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# APISERVER_KUBELET_CLIENT_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/apiserver-kubelet-client.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/apiserver-kubelet-client.key
# chmod 0600 /etc/kubernetes/pki/apiserver-kubelet-client.key
# openssl req -new -key /etc/kubernetes/pki/apiserver-kubelet-client.key -subj &amp;quot;/CN=kube-apiserver-kubelet-client/O=system:masters&amp;quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/apiserver-kubelet-client.crt -days $APISERVER_KUBELET_CLIENT_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;adminクライアント証明書生成&lt;/p&gt;

&lt;p&gt;kubectlがkube-apiserverのAPIにアクセスするときのクライアント証明書。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# groupadd -r kube-admin
# adduser -r -g kube-admin -M -s /sbin/nologin kube-admin
# ADMIN_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/admin.key
# chown kube-admin:kube-admin /etc/kubernetes/pki/admin.key
# chmod 0600 /etc/kubernetes/pki/admin.key
# openssl req -new -key /etc/kubernetes/pki/admin.key -subj &amp;quot;/CN=kubernetes-admin/O=system:masters&amp;quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/admin.crt -days $ADMIN_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kube-controller-managerのクライアント証明書生成&lt;/p&gt;

&lt;p&gt;kube-controller-managerがkube-apiserverに接続するときのクライアント証明書。
この証明書に対応する秘密鍵と公開鍵はそれぞれ、kube-controller-managerがService Accountトークンに署名するとき、kube-apiserverがトークンの署名を確認するときにも使う。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# CONTROLLER_MANAGER_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/kube-controller-manager.key
# openssl ec -in /etc/kubernetes/pki/kube-controller-manager.key -outform PEM -pubout -out /etc/kubernetes/pki/kube-controller-manager.pub
# chown kubernetes:kubernetes /etc/kubernetes/pki/kube-controller-manager.key
# chmod 0600 /etc/kubernetes/pki/kube-controller-manager.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/kube-controller-manager.key -subj &amp;quot;/CN=system:kube-controller-manager&amp;quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/kube-controller-manager.crt -days $CONTROLLER_MANAGER_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kube-schedulerクライアント証明書生成&lt;/p&gt;

&lt;p&gt;kube-schedulerがkube-apiserverにリクエストするときに使うクライアント証明書。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# SCHEDULER_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/kube-scheduler.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/kube-scheduler.key
# chmod 0600 /etc/kubernetes/pki/kube-scheduler.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/kube-scheduler.key -subj &amp;quot;/CN=system:kube-scheduler&amp;quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/kube-scheduler.crt -days $SCHEDULER_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kube-proxyクライアント証明書生成&lt;/p&gt;

&lt;p&gt;kube-proxyがkube-apiserverにリクエストするときに使うクライアント証明書。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# PROXY_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/kube-proxy.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/kube-proxy.key
# chmod 0600 /etc/kubernetes/pki/kube-proxy.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/kube-proxy.key -subj &amp;quot;/CN=system:kube-proxy&amp;quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/kube-proxy.crt -days $PROXY_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;front proxy CA証明書生成&lt;/p&gt;

&lt;p&gt;front proxyの証明書に署名するのにつかう証明書。
front proxyは&lt;a href=&#34;https://github.com/kubernetes/community/blob/master/contributors/design-proposals/api-machinery/aggregated-api-servers.md&#34;&gt;API Aggregation&lt;/a&gt;のためのもの。
API Aggregationは、kube-apiserverを変更することなく、別途作られた&lt;a href=&#34;https://kubernetes.io/docs/tasks/access-kubernetes-api/setup-extension-api-server/&#34;&gt;Extension API Server&lt;/a&gt;でKubernetesのAPIを拡張できるようにする機能。
API Aggregationは現時点では&lt;a href=&#34;https://kubernetes.io/docs/concepts/api-extension/apiserver-aggregation/#overview&#34;&gt;kube-apiserverの一機能として実装されていて&lt;/a&gt;、将来的には&lt;a href=&#34;https://github.com/kubernetes/kube-aggregator&#34;&gt;kubernetes-aggregator&lt;/a&gt;という別のコンポーネントで実現される。&lt;/p&gt;

&lt;p&gt;API AggregationしないならこのCA証明書と次のクライアント証明書はいらないはず。
今回はしないけど、とりあえず作って設定したおく。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# FRONT_PROXY_CA_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/front-proxy-ca.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/front-proxy-ca.key
# chmod 0600 /etc/kubernetes/pki/front-proxy-ca.key
# openssl req -x509 -new -sha256 -nodes -key /etc/kubernetes/pki/front-proxy-ca.key -days $FRONT_PROXY_CA_DAYS -out /etc/kubernetes/pki/front-proxy-ca.crt -subj &amp;quot;/CN=front-proxy-ca&amp;quot; -extensions v3_ca -config /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;front proxyクライアント証明書&lt;/p&gt;

&lt;p&gt;Extension API ServerのAPIへのリクエストは、いったんkube-apiserverが受け取ってExtension API Serverに転送される。(多分。)
この転送の暗号化と認証にTLSが使われていて、ここではそのクライアント証明書を生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# FRONT_PROXY_CLIENT_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/front-proxy-client.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/front-proxy-client.key
# chmod 0600 /etc/kubernetes/pki/front-proxy-client.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/front-proxy-client.key -subj &amp;quot;/CN=front-proxy-client&amp;quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/front-proxy-ca.crt -CAkey /etc/kubernetes/pki/front-proxy-ca.key -CAcreateserial -out /etc/kubernetes/pki/front-proxy-client.crt -days $FRONT_PROXY_CLIENT_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;etcd CA証明書&lt;/p&gt;

&lt;p&gt;以降で生成するetcdの証明書に署名するための証明書。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# groupadd -r etcd
# adduser -r -g etcd -M -s /sbin/nologin etcd
# ETCD_CA_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/etcd-ca.key
# chown etcd:etcd /etc/kubernetes/pki/etcd-ca.key
# chmod 0600 /etc/kubernetes/pki/etcd-ca.key
# openssl req -x509 -new -sha256 -nodes -key /etc/kubernetes/pki/etcd-ca.key -days $ETCD_CA_DAYS -out /etc/kubernetes/pki/etcd-ca.crt -subj &amp;quot;/CN=etcd-ca&amp;quot; -extensions v3_ca -config /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;etcd証明書&lt;/p&gt;

&lt;p&gt;etcdのサーバ証明書。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# ETCD_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/etcd.key
# chown etcd:etcd /etc/kubernetes/pki/etcd.key
# chmod 0600 /etc/kubernetes/pki/etcd.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/etcd.key -subj &amp;quot;/CN=etcd&amp;quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/etcd-ca.crt -CAkey /etc/kubernetes/pki/etcd-ca.key -CAcreateserial -out /etc/kubernetes/pki/etcd.crt -days $ETCD_DAYS -extensions v3_req_etcd -extfile /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;etcdクライアント証明書&lt;/p&gt;

&lt;p&gt;etcdのクライアント証明書。
kube-apiserverだけがetcdと話すので、kube-apiserverだけが使う。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# ETCD_CLIENT_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/etcd-client.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/etcd-client.key
# chmod 0600 /etc/kubernetes/pki/etcd-client.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/etcd-client.key -subj &amp;quot;/CN=kube-apiserver&amp;quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/etcd-ca.crt -CAkey /etc/kubernetes/pki/etcd-ca.key -CAcreateserial -out /etc/kubernetes/pki/etcd-client.crt -days $ETCD_CLIENT_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;etcd peer証明書&lt;/p&gt;

&lt;p&gt;etcdサーバが冗長構成のとき、サーバ間の通信の暗号化に使う証明書。
マスタが一つなら要らないはずだけど、今回とりあえず作って設定しておく。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# ETCD_PEER_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/etcd-peer.key
# chown etcd:etcd /etc/kubernetes/pki/etcd-peer.key
# chmod 0600 /etc/kubernetes/pki/etcd-peer.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/etcd-peer.key -subj &amp;quot;/CN=etcd-peer&amp;quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/etcd-ca.crt -CAkey /etc/kubernetes/pki/etcd-ca.key -CAcreateserial -out /etc/kubernetes/pki/etcd-peer.crt -days $ETCD_PEER_DAYS -extensions v3_req_etcd -extfile /etc/kubernetes/pki/openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;確認&lt;/p&gt;

&lt;p&gt;以上で生成した証明書の内容を確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# for i in /etc/kubernetes/pki/*crt; do
  echo $i:;
  openssl x509 -subject -issuer -noout -in $i;
  echo;
done
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kubernetesバイナリインストール&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/getting-started-guides/scratch/#selecting-images&#34;&gt;公式ドキュメント&lt;/a&gt;によると、Docker、kubelet、kube-proxyはコンテナ外で動かして、etcd、kube-apiserver、kube-controller-manager、kube-schedulerはコンテナで動かすのが推奨されている。
けど、とりあえずは簡単に全部コンテナ外でやる。&lt;/p&gt;

&lt;p&gt;(Oracle Linux用には、各コンポのコンテナイメージ詰め合わせがOracle Container Services for use with Kubernetesという名前で配布されているけど、現時点で1.9までしかないので使わない。)&lt;/p&gt;

&lt;p&gt;バイナリは以下URLからダウンロードできる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;全部入り: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/kubernetes-server-linux-amd64.tar.gz&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/kubernetes-server-linux-amd64.tar.gz&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;kube-apiserver

&lt;ul&gt;
&lt;li&gt;バイナリ: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-apiserver&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-apiserver&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;コンテナ: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-apiserver.tar&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-apiserver.tar&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;kube-controller-manager

&lt;ul&gt;
&lt;li&gt;バイナリ: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-controller-manager&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-controller-manager&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;コンテナ: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-controller-manager.tar&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-controller-manager.tar&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;kube-scheduler

&lt;ul&gt;
&lt;li&gt;バイナリ: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-scheduler&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-scheduler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;コンテナ: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-scheduler.tar&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-scheduler.tar&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;kube-proxy

&lt;ul&gt;
&lt;li&gt;バイナリ: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-proxy&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-proxy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;コンテナ: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-proxy.tar&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-proxy.tar&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;kubelet: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubelet&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubelet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;kubectl: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubectl&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubectl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;kubeadm: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubeadm&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubeadm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;hyperkube: &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/hyperkube&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/hyperkube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最後のhyperkubeは、各種Kubernetesバイナリのごった煮。
ファイル名によって動作が変わる。
簡単のためこれを使うけど、個別のバイナリ使ったほうがメモリ使用量などで有利そう。&lt;/p&gt;

&lt;p&gt;hyperkubeとkubeadmのバイナリを&lt;code&gt;/usr/bin/&lt;/code&gt;において、以下のコマンドを実行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# ln -s /usr/bin/hyperkube /usr/bin/kube-apiserver
# ln -s /usr/bin/hyperkube /usr/bin/kube-controller-manager
# ln -s /usr/bin/hyperkube /usr/bin/kube-scheduler
# ln -s /usr/bin/hyperkube /usr/bin/kube-proxy
# ln -s /usr/bin/hyperkube /usr/bin/kubelet
# ln -s /usr/bin/hyperkube /usr/bin/kubectl
# chmod +x /usr/bin/kube*
# mkdir -p /var/lib/{kubelet,kube-proxy}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kubeconfigファイル生成&lt;/p&gt;

&lt;p&gt;kubectlとマスタコンポーネントがkube-apiserverと話すときに使うkubeconfigファイルを生成する。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;kube-controller-managerのkubeconfig&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# MASTER_IP=192.168.171.200
# KUBERNETES_PUBLIC_ADDRESS=$MASTER_IP
# CLUSTER_NAME=&amp;quot;k8s&amp;quot;
# KCONFIG=/etc/kubernetes/kube-controller-manager.kubeconfig
# KUSER=&amp;quot;system:kube-controller-manager&amp;quot;
# kubectl config set-cluster ${CLUSTER_NAME} --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 --kubeconfig=${KCONFIG}
# kubectl config set-credentials ${KUSER} --client-certificate=/etc/kubernetes/pki/kube-controller-manager.crt --client-key=/etc/kubernetes/pki/kube-controller-manager.key --embed-certs=true --kubeconfig=${KCONFIG}
# kubectl config set-context ${KUSER}@${CLUSTER_NAME} --cluster=${CLUSTER_NAME} --user=${KUSER} --kubeconfig=${KCONFIG}
# kubectl config use-context ${KUSER}@${CLUSTER_NAME} --kubeconfig=${KCONFIG}
# chown kubernetes:kubernetes ${KCONFIG}
# chmod 0600 ${KCONFIG}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;設定確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl config view --kubeconfig=${KCONFIG}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kube-schedulerのkubeconfig&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# MASTER_IP=192.168.171.200
# KUBERNETES_PUBLIC_ADDRESS=$MASTER_IP
# CLUSTER_NAME=&amp;quot;k8s&amp;quot;
# KCONFIG=/etc/kubernetes/kube-scheduler.kubeconfig
# KUSER=&amp;quot;system:kube-scheduler&amp;quot;
# kubectl config set-cluster ${CLUSTER_NAME} --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 --kubeconfig=${KCONFIG}
# kubectl config set-credentials ${KUSER} --client-certificate=/etc/kubernetes/pki/kube-scheduler.crt --client-key=/etc/kubernetes/pki/kube-scheduler.key --embed-certs=true --kubeconfig=${KCONFIG}
# kubectl config set-context ${KUSER}@${CLUSTER_NAME} --cluster=${CLUSTER_NAME} --user=${KUSER} --kubeconfig=${KCONFIG}
# kubectl config use-context ${KUSER}@${CLUSTER_NAME} --kubeconfig=${KCONFIG}
# chown kubernetes:kubernetes ${KCONFIG}
# chmod 0600 ${KCONFIG}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;設定確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl config view --kubeconfig=${KCONFIG}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;adminのkubeconfig&lt;/p&gt;

&lt;p&gt;kubectl用。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# MASTER_IP=192.168.171.200
# KUBERNETES_PUBLIC_ADDRESS=$MASTER_IP
# CLUSTER_NAME=&amp;quot;k8s&amp;quot;
# KCONFIG=/etc/kubernetes/admin.kubeconfig
# KUSER=&amp;quot;kubernetes-admin&amp;quot;
# kubectl config set-cluster ${CLUSTER_NAME} --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 --kubeconfig=${KCONFIG}
# kubectl config set-credentials ${KUSER} --client-certificate=/etc/kubernetes/pki/admin.crt --client-key=/etc/kubernetes/pki/admin.key --embed-certs=true --kubeconfig=${KCONFIG}
# kubectl config set-context ${KUSER}@${CLUSTER_NAME} --cluster=${CLUSTER_NAME} --user=${KUSER} --kubeconfig=${KCONFIG}
# kubectl config use-context ${KUSER}@${CLUSTER_NAME} --kubeconfig=${KCONFIG}
# chown kube-admin:kube-admin ${KCONFIG}
# chmod 0600 ${KCONFIG}
# ln -s ${KCONFIG} ~/.kube/config
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;設定確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl config view --kubeconfig=${KCONFIG}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;etcdデプロイ&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/coreos/etcd/releases/download/v3.1.12/etcd-v3.1.12-linux-amd64.tar.gz&#34;&gt;https://github.com/coreos/etcd/releases/download/v3.1.12/etcd-v3.1.12-linux-amd64.tar.gz&lt;/a&gt;
からアーカイブをダウンロードして、中のetcdとetcdctlを&lt;code&gt;/usr/bin/&lt;/code&gt;にいれて、以下のコマンドを実行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# chown root:root /usr/bin/etcd*
# chmod 0755 /usr/bin/etcd*
# mkdir -p /var/lib/etcd
# chown etcd:etcd /var/lib/etcd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、systemdのユニットファイルを書いてサービス化。&lt;/p&gt;

&lt;p&gt;(参考: &lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/&#34;&gt;Kubernetesドキュメント&lt;/a&gt;、&lt;a href=&#34;https://github.com/coreos/etcd/blob/master/Documentation/op-guide/security.md&#34;&gt;etcdドキュメント&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# MASTER_IP=192.168.171.200
# ETCD_MEMBER_NAME=etcd1
# CLUSTER_NAME=&amp;quot;k8s&amp;quot;
# ETCD_TOKEN=$(openssl rand -hex 5)
# ETCD_CLUSTER_TOKEN=$CLUSTER_NAME-$ETCD_TOKEN
# cat &amp;gt; /etc/systemd/system/etcd.service &amp;lt;&amp;lt; EOF
[Unit]
Description=etcd
Documentation=https://coreos.com/etcd/docs/latest/
After=network.target


[Service]
Type=notify
NotifyAccess=all
User=etcd
Group=etcd
ExecStart=/usr/bin/etcd \\
  --name ${ETCD_MEMBER_NAME} \\
  --listen-client-urls https://${MASTER_IP}:2379 \\
  --advertise-client-urls https://${MASTER_IP}:2379 \\
  --data-dir=/var/lib/etcd \\
  --cert-file=/etc/kubernetes/pki/etcd.crt \\
  --key-file=/etc/kubernetes/pki/etcd.key \\
  --peer-cert-file=/etc/kubernetes/pki/etcd-peer.crt \\
  --peer-key-file=/etc/kubernetes/pki/etcd-peer.key \\
  --trusted-ca-file=/etc/kubernetes/pki/etcd-ca.crt \\
  --peer-trusted-ca-file=/etc/kubernetes/pki/etcd-ca.crt \\
  --peer-client-cert-auth \\
  --client-cert-auth \\
  --initial-advertise-peer-urls https://${MASTER_IP}:2380 \\
  --listen-peer-urls https://${MASTER_IP}:2380 \\
  --initial-cluster-token ${ETCD_CLUSTER_TOKEN} \\
  --initial-cluster ${ETCD_MEMBER_NAME}=https://${MASTER_IP}:2380 \\
  --initial-cluster-state new
Restart=always
RestartSec=10s


[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable etcd
# systemctl start etcd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# systemctl status etcd -l
# MASTER_IP=192.168.171.200
# etcdctl --endpoints https://${MASTER_IP}:2379 --ca-file=/etc/kubernetes/pki/etcd-ca.crt --cert-file=/etc/kubernetes/pki/etcd-client.crt --key-file=/etc/kubernetes/pki/etcd-client.key cluster-health
# etcdctl --endpoints https://${MASTER_IP}:2379 --ca-file=/etc/kubernetes/pki/etcd-ca.crt --cert-file=/etc/kubernetes/pki/etcd-client.crt --key-file=/etc/kubernetes/pki/etcd-client.key member list
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;マスタコンポーネントデプロイ。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;kube-apiserver&lt;/p&gt;

&lt;p&gt;systemdのユニットファイルを書いてサービス化。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;d&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# mkdir -p /var/log/kubernetes
# chown kubernetes:kubernetes /var/log/kubernetes
# chmod 0700 /var/log/kubernetes
# MASTER_IP=192.168.171.200
# SERVICE_CLUSTER_IP_RANGE=&amp;quot;10.0.0.0/16&amp;quot;
# SECRET_ENC_KEY=$(echo -n &#39;your_32_bytes_secure_private_key&#39; | base64)
# cat &amp;gt; /etc/kubernetes/encryption.conf &amp;lt;&amp;lt; EOF
kind: EncryptionConfig
apiVersion: v1
resources:
  - resources:
    - secrets
    providers:
    - aescbc:
        keys:
        - name: key1
          secret: ${SECRET_ENC_KEY}
    - identity: {}
EOF
# cat &amp;gt; /etc/kubernetes/audit-policy.conf &amp;lt;&amp;lt; EOF
apiVersion: audit.k8s.io/v1beta1
kind: Policy
# Don&#39;t generate audit events for all requests in RequestReceived stage.
omitStages:
  - &amp;quot;RequestReceived&amp;quot;
rules:
  # Log pod changes at RequestResponse level
  - level: RequestResponse
    resources:
    - group: &amp;quot;&amp;quot;
      # Resource &amp;quot;pods&amp;quot; doesn&#39;t match requests to any subresource of pods,
      # which is consistent with the RBAC policy.
      resources: [&amp;quot;pods&amp;quot;]
  # Log &amp;quot;pods/log&amp;quot;, &amp;quot;pods/status&amp;quot; at Metadata level
  - level: Metadata
    resources:
    - group: &amp;quot;&amp;quot;
      resources: [&amp;quot;pods/log&amp;quot;, &amp;quot;pods/status&amp;quot;]


  # Don&#39;t log requests to a configmap called &amp;quot;controller-leader&amp;quot;
  - level: None
    resources:
    - group: &amp;quot;&amp;quot;
      resources: [&amp;quot;configmaps&amp;quot;]
      resourceNames: [&amp;quot;controller-leader&amp;quot;]


  # Don&#39;t log watch requests by the &amp;quot;system:kube-proxy&amp;quot; on endpoints or services
  - level: None
    users: [&amp;quot;system:kube-proxy&amp;quot;]
    verbs: [&amp;quot;watch&amp;quot;]
    resources:
    - group: &amp;quot;&amp;quot; # core API group
      resources: [&amp;quot;endpoints&amp;quot;, &amp;quot;services&amp;quot;]


  # Don&#39;t log authenticated requests to certain non-resource URL paths.
  - level: None
    userGroups: [&amp;quot;system:authenticated&amp;quot;]
    nonResourceURLs:
    - &amp;quot;/api*&amp;quot; # Wildcard matching.
    - &amp;quot;/version&amp;quot;


  # Log the request body of configmap changes in kube-system.
  - level: Request
    resources:
    - group: &amp;quot;&amp;quot; # core API group
      resources: [&amp;quot;configmaps&amp;quot;]
    # This rule only applies to resources in the &amp;quot;kube-system&amp;quot; namespace.
    # The empty string &amp;quot;&amp;quot; can be used to select non-namespaced resources.
    namespaces: [&amp;quot;kube-system&amp;quot;]


  # Log configmap and secret changes in all other namespaces at the Metadata level.
  - level: Metadata
    resources:
    - group: &amp;quot;&amp;quot; # core API group
      resources: [&amp;quot;secrets&amp;quot;, &amp;quot;configmaps&amp;quot;]


  # Log all other resources in core and extensions at the Request level.
  - level: Request
    resources:
    - group: &amp;quot;&amp;quot; # core API group
    - group: &amp;quot;extensions&amp;quot; # Version of group should NOT be included.


  # A catch-all rule to log all other requests at the Metadata level.
  - level: Metadata
    # Long-running requests like watches that fall under this rule will not
    # generate an audit event in RequestReceived.
    omitStages:
      - &amp;quot;RequestReceived&amp;quot;
EOF
# cat &amp;gt; /etc/systemd/system/kube-apiserver.service &amp;lt;&amp;lt; EOF
[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/kubernetes/kubernetes
After=network.target


[Service]
User=kubernetes
Group=kubernetes
ExecStart=/usr/bin/kube-apiserver \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --apiserver-count=1 \\
  --allow-privileged=true \\
  --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,NodeRestriction,DenyEscalatingExec,StorageObjectInUseProtection \\
  --authorization-mode=Node,RBAC \\
  --bind-address=0.0.0.0 \\
  --advertise-address=${MASTER_IP} \\
  --client-ca-file=/etc/kubernetes/pki/ca.crt \\
  --etcd-cafile=/etc/kubernetes/pki/etcd-ca.crt \\
  --etcd-certfile=/etc/kubernetes/pki/etcd-client.crt \\
  --etcd-keyfile=/etc/kubernetes/pki/etcd-client.key \\
  --etcd-servers=https://${MASTER_IP}:2379 \\
  --service-account-key-file=/etc/kubernetes/pki/kube-controller-manager.pub \\
  --service-cluster-ip-range=${SERVICE_CLUSTER_IP_RANGE} \\
  --tls-cert-file=/etc/kubernetes/pki/kube-apiserver.crt \\
  --tls-private-key-file=/etc/kubernetes/pki/kube-apiserver.key \\
  --kubelet-certificate-authority=/etc/kubernetes/pki/ca.crt \\
  --enable-bootstrap-token-auth=true \\
  --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt \\
  --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key \\
  --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname \\
  --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt \\
  --requestheader-username-headers=X-Remote-User \\
  --requestheader-group-headers=X-Remote-Group \\
  --requestheader-allowed-names=front-proxy-client \\
  --requestheader-extra-headers-prefix=X-Remote-Extra- \\
  --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt \\
  --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key \\
  --experimental-encryption-provider-config=/etc/kubernetes/encryption.conf \\
  --v=2 \\
  --tls-min-version=VersionTLS12 \\
  --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 \\
  --anonymous-auth=false \\
  --audit-log-format=json \\
  --audit-log-maxage=30 \\
  --audit-log-maxbackup=3 \\
  --audit-log-maxsize=100 \\
  --audit-log-path=/var/log/kubernetes/kube-audit.log \\
  --audit-policy-file=/etc/kubernetes/audit-policy.conf
Restart=always
RestartSec=10s


[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable kube-apiserver
# systemctl start kube-apiserver
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--allow-privileged&lt;/code&gt;はflannelなどに必要。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--enable-admission-plugins&lt;/code&gt;には&lt;a href=&#34;https://kubernetes.io/docs/admin/admission-controllers/#is-there-a-recommended-set-of-admission-controllers-to-use&#34;&gt;公式推奨のプラグイン&lt;/a&gt;に加えて、後述のTLS BootstrappingのためのNodeRestrictionを指定。
また、&lt;code&gt;--allow-privileged&lt;/code&gt;の効果を軽減するため、DenyEscalatingExecも追加で指定。
また、使われているPersistent VolumeやPersistent Volume Claimが誤って消されることを防ぐ&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/#storage-object-in-use-protection&#34;&gt;StorageObjectInUseProtection&lt;/a&gt;も追加で指定。
因みに、プラグインを指定する順番はKubernetes 1.10からは気にしなくてよくなった。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--authorization-mode&lt;/code&gt;にはRBACを指定するのが標準。
後述のTLS Bootstrappingをするなら、Nodeも要る。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--experimental-encryption-provider-config&lt;/code&gt;は&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/&#34;&gt;Secretを暗号化する&lt;/a&gt;ための設定。
暗号化のキーをローテーションすることもできるけど、それはやってない。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--tls-min-version&lt;/code&gt;と&lt;code&gt;--tls-cipher-suites&lt;/code&gt;は&lt;a href=&#34;https://www.lambdanote.com/blogs/news/openssl-cookbook&#34;&gt;OpenSSLクックブック&lt;/a&gt;と&lt;a href=&#34;https://golang.org/pkg/crypto/tls/#pkg-constants&#34;&gt;Goのtlsパッケージドキュメント&lt;/a&gt;を参考に設定。
RSA鍵交換はNG、RC4と3DESもNG、AESの鍵長は128ビット以上、SHA1はNG。&lt;/p&gt;

&lt;p&gt;また、(&amp;ndash;tls-min-versionをVersionTLS12にする場合?)TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256が必須で、CBCモードがNG。(参照: &lt;a href=&#34;https://github.com/golang/go/blob/release-branch.go1.9/src/net/http/h2_bundle.go&#34;&gt;https://github.com/golang/go/blob/release-branch.go1.9/src/net/http/h2_bundle.go&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--anonymous-auth=false&lt;/code&gt;はセキュリティのため設定。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--requestheader-*&lt;/code&gt;と&lt;code&gt;--proxy-client-*&lt;/code&gt;は上記API Aggregationのための設定。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--audit-*&lt;/code&gt;は監査ログ設定。
100MB3面のログを30日間保持する。
ログポリシーは&lt;a href=&#34;https://kubernetes.io/docs/tasks/debug-application-cluster/audit/&#34;&gt;公式のサンプル&lt;/a&gt;そのまま。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--feature-gates&lt;/code&gt;でRotateKubeletServerCertificateを有効にして、kubeletのサーバ証明書を自動更新するようにしている。
因みに、クライアント証明書を自動更新するRotateKubeletClientCertificateはデフォルトで有効。
これらがCertificate Rotationと呼ばれる機能。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--feature-gates&lt;/code&gt;は全Kubernetesコンポーネントで同じ値を指定するのがよさそう。&lt;/p&gt;

&lt;p&gt;確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# systemctl status kube-apiserver -l
# journalctl -u kube-apiserver
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kube-controller-manager&lt;/p&gt;

&lt;p&gt;systemdのユニットファイルを書いてサービス化。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# CLUSTER_CIDR=&amp;quot;10.244.0.0/16&amp;quot;
# SERVICE_CLUSTER_IP_RANGE=&amp;quot;10.0.0.0/16&amp;quot;
# CLUSTER_NAME=&amp;quot;k8s&amp;quot;
# cat &amp;gt; /etc/systemd/system/kube-controller-manager.service &amp;lt;&amp;lt; EOF
[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/kubernetes/kubernetes
After=network.target


[Service]
User=kubernetes
Group=kubernetes
ExecStart=/usr/bin/kube-controller-manager \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig \\
  --bind-address=0.0.0.0 \\
  --controllers=*,bootstrapsigner,tokencleaner \\
  --service-account-private-key-file=/etc/kubernetes/pki/kube-controller-manager.key \\
  --allocate-node-cidrs=true \\
  --cluster-cidr=${CLUSTER_CIDR} \\
  --node-cidr-mask-size=24 \\
  --cluster-name=${CLUSTER_NAME} \\
  --service-cluster-ip-range=${SERVICE_CLUSTER_IP_RANGE} \\
  --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt \\
  --cluster-signing-key-file=/etc/kubernetes/pki/ca.key \\
  --root-ca-file=/etc/kubernetes/pki/ca.crt \\
  --use-service-account-credentials=true \\
  --v=2 \\
  --experimental-cluster-signing-duration=8760h0m0s
Restart=always
RestartSec=10s


[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable kube-controller-manager
# systemctl start kube-controller-manager
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;期限の切れたBootstrap token(後述)を消すためにtokencleanerを有効にしている。&lt;/p&gt;

&lt;p&gt;bootstrapsignerは後述のcluster-infoにBootstrap tokenで署名するためのコントローラ。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/#approval-controller&#34;&gt;csrapproving&lt;/a&gt;というコントローラがデフォルトで有効になっていて、後述のTLS BootstrapppingやCertificate Rotationの時に作られるCSRを自動で承認する。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--cluster-cidr&lt;/code&gt;で指定するネットワークは、後述のネットワークプロバイダの設定と合っている必要がある。
&lt;code&gt;--allocate-node-cidrs&lt;/code&gt;は&lt;code&gt;--cluster-cidr&lt;/code&gt;の前提。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--node-cidr-mask-size&lt;/code&gt;は、ノードに使うネットワークのサイズを指定するオプションで、&lt;code&gt;--cluster-cidr&lt;/code&gt;で指定したネットワークの一部になるようにする。
&lt;code&gt;--cluster-cidr&lt;/code&gt;で&lt;code&gt;/16&lt;/code&gt;を指定した場合、半分の&lt;code&gt;/24&lt;/code&gt;にするのが普通。
つまり256ノードまで作れて、それぞれ254個のPodをホストできるような構成。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--experimental-cluster-signing-duration&lt;/code&gt;は、Certificate Rotationのための設定で、自動発行する証明書の期限を1年に指定している。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--use-service-account-credentials&lt;/code&gt;をつけると、&lt;a href=&#34;https://kubernetes.io/docs/admin/authorization/rbac/#controller-roles&#34;&gt;各コントローラが別々のService Accountで動く&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--secure-port&lt;/code&gt;や&lt;code&gt;--tls-*&lt;/code&gt;は、ヘルスチェックAPIをHTTPSにするだけで意味が無いし、設定すると&lt;code&gt;kubectl get componentstatuses&lt;/code&gt;でエラーが出るようになるので、設定しないほうがいい。&lt;/p&gt;

&lt;p&gt;確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# systemctl status kube-controller-manager -l
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kube-scheduler&lt;/p&gt;

&lt;p&gt;systemdのユニットファイルを書いてサービス化。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# cat &amp;gt; /etc/systemd/system/kube-scheduler.service &amp;lt;&amp;lt; EOF
[Unit]
Description=Kubernetes Scheduler
Documentation=https://github.com/kubernetes/kubernetes
After=network.target


[Service]
User=kubernetes
Group=kubernetes
ExecStart=/usr/bin/kube-scheduler \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --kubeconfig=/etc/kubernetes/kube-scheduler.kubeconfig \\
  --address=0.0.0.0 \\
  --v=2
Restart=always
RestartSec=10s


[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable kube-scheduler
# systemctl start kube-scheduler
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# systemctl status kube-scheduler -l
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;マスタコンポーネント状態確認&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl version
# kubectl get componentstatuses
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/&#34;&gt;TLS Bootstrapping&lt;/a&gt;の設定&lt;/p&gt;

&lt;p&gt;TLS Bootstrappingは、Kubernetesクラスタのコンポーネント間の通信がTLSで暗号化されている環境で、ノードが新たにクラスタに参加するとき、自動的にセキュアに&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E8%A8%BC%E6%98%8E%E6%9B%B8%E7%BD%B2%E5%90%8D%E8%A6%81%E6%B1%82&#34;&gt;CSR&lt;/a&gt;を処理する仕組み。&lt;/p&gt;

&lt;p&gt;TLS Bootstrappingでは、kubeletは起動時にBootstrap kubeconfigを読んで、kubeletとノード用のCSRを生成し、それらがkube-controller-managerに承認されると、kubelet用のクライアント証明書と秘密鍵を生成する。
その証明書と鍵を使ってkubeconfigを生成し、以降のクラスタへの接続に使う。&lt;/p&gt;

&lt;p&gt;Bootstrap時の認証には&lt;a href=&#34;https://kubernetes.io/docs/admin/bootstrap-tokens/&#34;&gt;Bootstrap Tokens&lt;/a&gt;か&lt;a href=&#34;https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/#token-authentication-file&#34;&gt;Token authentication file&lt;/a&gt;を使うことが推奨されていて、今回は前者を使う。&lt;/p&gt;

&lt;p&gt;(後者については&lt;a href=&#34;https://medium.com/@toddrosner/kubernetes-tls-bootstrapping-cf203776abc7&#34;&gt;この記事&lt;/a&gt;に詳しい。)&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Bootstrap TokenのSecret生成&lt;/p&gt;

&lt;p&gt;以下のように生成できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# TOKEN_PUB=$(openssl rand -hex 3)
# TOKEN_SECRET=$(openssl rand -hex 8)
# BOOTSTRAP_TOKEN=&amp;quot;${TOKEN_PUB}.${TOKEN_SECRET}&amp;quot;
# kubectl -n kube-system create secret generic bootstrap-token-${TOKEN_PUB} --type &#39;bootstrap.kubernetes.io/token&#39; --from-literal description=&amp;quot;cluster bootstrap token&amp;quot; --from-literal token-id=${TOKEN_PUB} --from-literal token-secret=${TOKEN_SECRET} --from-literal usage-bootstrap-authentication=true --from-literal usage-bootstrap-signing=true --from-literal auth-extra-groups=system:bootstrappers:worker,system:bootstrappers:ingress
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;けど、&lt;a href=&#34;https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-token/#cmd-token-generate&#34;&gt;kubeadm&lt;/a&gt;でも生成出来てこっちのほうが楽なので、それで。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# BOOTSTRAP_TOKEN=$(kubeadm token create --kubeconfig /etc/kubernetes/admin.kubeconfig)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;BOOTSTRAP_TOKENの値はあとで使う。&lt;/p&gt;

&lt;p&gt;expirationは指定できなくて、1日で期限切れになっちゃうけど、クラスタにノードを追加するときに有効であればいいのでまあいい。&lt;/p&gt;

&lt;p&gt;確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# TOKEN_PUB=$(echo $BOOTSTRAP_TOKEN | sed -e s/\\..*//)
# kubectl -n kube-system get secret/bootstrap-token-${TOKEN_PUB} -o yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Bootstrap kubeconfig作成&lt;/p&gt;

&lt;p&gt;Bootstrap時は&lt;code&gt;kubelet-bootstrap&lt;/code&gt;というユーザでkube-apiserverに接続する。
&lt;code&gt;kubelet-bootstrap&lt;/code&gt;は&lt;code&gt;system:node-bootstrapper&lt;/code&gt;ロールを持って&lt;code&gt;system:bootstrappers&lt;/code&gt;に属しているユーザとして認証される必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# mkdir -p /etc/kubernetes/manifests
# MASTER_IP=192.168.171.200
# KUBERNETES_PUBLIC_ADDRESS=$MASTER_IP
# CLUSTER_NAME=&amp;quot;k8s&amp;quot;
# KCONFIG=&amp;quot;/etc/kubernetes/bootstrap.kubeconfig&amp;quot;
# KUSER=&amp;quot;kubelet-bootstrap&amp;quot;
# kubectl config set-cluster ${CLUSTER_NAME} --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 --kubeconfig=${KCONFIG}
# kubectl config set-context ${KUSER}@${CLUSTER_NAME} --cluster=${CLUSTER_NAME} --user=${KUSER} --kubeconfig=${KCONFIG}
# kubectl config use-context ${KUSER}@${CLUSTER_NAME} --kubeconfig=${KCONFIG}
# chown kubernetes:kubernetes ${KCONFIG}
# chmod 0600 ${KCONFIG}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl config view --kubeconfig=${KCONFIG}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;CA証明書とbootstrap kubeconfigをConfigMap(cluster-info)で公開&lt;/p&gt;

&lt;p&gt;kubeletはこのConfigMapを見てクラスタに参加する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl -n kube-public create configmap cluster-info --from-file /etc/kubernetes/pki/ca.crt --from-file /etc/kubernetes/bootstrap.kubeconfig
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;anonymousユーザにcluster-infoへのアクセスを許可する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl -n kube-public create role system:bootstrap-signer-clusterinfo --verb get --resource configmaps
# kubectl -n kube-public create rolebinding kubeadm:bootstrap-signer-clusterinfo --role system:bootstrap-signer-clusterinfo --user system:anonymous
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;system:bootstrappersグループにsystem:node-bootstrapperロールを紐づける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl create clusterrolebinding kubeadm:kubelet-bootstrap --clusterrole system:node-bootstrapper --group system:bootstrappers
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;bootstrap.kubeconfigにトークンを追記&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl config set-credentials kubelet-bootstrap --token=${BOOTSTRAP_TOKEN} --kubeconfig=/etc/kubernetes/bootstrap.kubeconfig
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Docker、CNI、kubeletインストール&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Docker&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/install/linux/docker-ce/centos/#set-up-the-repository&#34;&gt;https://docs.docker.com/install/linux/docker-ce/centos/#set-up-the-repository&lt;/a&gt;
に従ってDocker CEをインストール。
ストレージドライバにはoverlay2をつかうので、device-mapper-persistent-dataとlvm2は入れない。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# yum install -y yum-utils
# yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
# yum install -y docker-ce
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;18.03.0-ceが入った。&lt;/p&gt;

&lt;p&gt;が、よくみたらDocker CEはOracle Linuxをサポートしていないので、Docker CEはアンインストールして、代わりに&lt;a href=&#34;https://docs.oracle.com/cd/E77565_01/E87205/html/section_install_upgrade_yum_docker.html&#34;&gt;Oracle Container Runtime for Docker&lt;/a&gt; (aka docker-engine)を入れる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/etc/yum.repos.d/public-yum-ol7.repo&lt;/code&gt;の&lt;code&gt;ol7_addons&lt;/code&gt;の&lt;code&gt;enabled&lt;/code&gt;を1にして、以下のコマンドでdocker-engineをインストール。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# yum install -y docker-engine
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;docker-engine 17.06.2が入った。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/etc/sysconfig/docker&lt;/code&gt;に以下を追記して、 Dockerがオープンできる最大ファイル数を増やす。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DOCKER_NOFILE=1000000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kubernetes環境ではiptablesはkube-proxyが操作するので、Dockerには操作させないようにするため、&lt;code&gt;/etc/sysconfig/docker&lt;/code&gt;の&lt;code&gt;OPTIONS&lt;/code&gt;に&lt;code&gt;--iptables=false&lt;/code&gt;を追加。
(これをすると、&lt;code&gt;--icc=false&lt;/code&gt;は設定できなくなる(不要になる)。)&lt;/p&gt;

&lt;p&gt;また、Podの&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/security-context/&#34;&gt;allowPrivilegeEscalation&lt;/a&gt;をfalseにできない&lt;a href=&#34;https://github.com/coreos/bugs/issues/1796&#34;&gt;問題&lt;/a&gt;に対処するため、&lt;code&gt;/etc/sysconfig/docker&lt;/code&gt;の&lt;code&gt;OPTIONS&lt;/code&gt;から&lt;code&gt;--selinux-enabled&lt;/code&gt;を消す。&lt;/p&gt;

&lt;p&gt;で、起動。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# systemctl daemon-reload
# systemctl enable docker
# systemctl start docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# cat /proc/$(pidof dockerd)/environ
# systemctl status docker -l
# docker version
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;CNI&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# mkdir -p /etc/cni/net.d /opt/cni/bin/
# cd /tmp
# curl -OL https://github.com/containernetworking/cni/releases/download/v0.6.0/cni-amd64-v0.6.0.tgz
# curl -OL https://github.com/containernetworking/plugins/releases/download/v0.7.1/cni-plugins-amd64-v0.7.1.tgz
# cd /opt/cni/bin
# tar zxf /tmp/cni-amd64-v0.6.0.tgz
# tar zxf /tmp/cni-plugins-amd64-v0.7.1.tgz
# chmod +x /opt/cni/bin/*
# cat &amp;gt;/etc/cni/net.d/99-loopback.conf &amp;lt;&amp;lt;EOF
{
  &amp;quot;type&amp;quot;: &amp;quot;loopback&amp;quot;
}
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kubelet&lt;/p&gt;

&lt;p&gt;前提コマンド(conntrack)インストール。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# yum -y install conntrack-tools
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;systemdのユニットファイルを書いてサービス化。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# DNS_SERVER_IP=10.0.0.10
# PAUSE_IMAGE=k8s.gcr.io/pause-amd64:3.1
# DNS_DOMAIN=&amp;quot;cluster.local&amp;quot;
# cat &amp;gt; /etc/systemd/system/kubelet.service &amp;lt;&amp;lt; EOF
[Unit]
Description=Kubernetes Kubelet
Documentation=https://github.com/kubernetes/kubernetes
After=docker.service
Requires=docker.service


[Service]
User=root
Group=root
ExecStart=/usr/bin/kubelet \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --address=0.0.0.0 \\
  --bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \\
  --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \\
  --pod-manifest-path=/etc/kubernetes/manifests \\
  --network-plugin=cni \\
  --cni-conf-dir=/etc/cni/net.d \\
  --cni-bin-dir=/opt/cni/bin \\
  --cluster-dns=${DNS_SERVER_IP} \\
  --cluster-domain=${DNS_DOMAIN} \\
  --authorization-mode=Webhook \\
  --client-ca-file=/etc/kubernetes/pki/ca.crt \\
  --cert-dir=/etc/kubernetes/pki \\
  --rotate-certificates=true \\
  --v=2 \\
  --cgroup-driver=cgroupfs \\
  --pod-infra-container-image=${PAUSE_IMAGE} \\
  --tls-min-version=VersionTLS12 \\
  --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 \\
  --allow-privileged=true \\
  --anonymous-auth=false
Restart=always
RestartSec=10s


[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable kubelet
# systemctl start kubelet
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(実際は、systemctl start kubeletするまえに、後述のNode CSR自動承認設定をすべし。)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--allow-privileged&lt;/code&gt;はflannelなどに必要。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--pod-infra-container-image&lt;/code&gt;では&lt;a href=&#34;https://github.com/kubernetes/kubernetes/tree/master/build/pause&#34;&gt;pause&lt;/a&gt;コンテナイメージを指定する。
このコンテナはPod毎に起動され、Podネットワークの名前空間を保持するために使われるらしい。
今回使った&lt;code&gt;k8s.gcr.io/pause-amd64:3.1&lt;/code&gt;はKubernetesチームが配布しているものだけど、Oracleが配布しているものもあり、そちらを使うには、Oracle Linux 7.4のダウンロード媒体リストに含まれるOracle Container Services for use with Kubernetes 1.1.9.1に入っているpause-amd64.tarを&lt;code&gt;docker load&lt;/code&gt;しておいて、そのイメージ名を&lt;code&gt;--pod-infra-container-image&lt;/code&gt;に渡せばいい。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--bootstrap-kubeconfig&lt;/code&gt;で指定したkubeconfigでTLS Bootstrapして、&lt;code&gt;--cert-dir&lt;/code&gt;で指定したディレクトリに証明書と鍵を生成して、&lt;code&gt;--kubeconfig&lt;/code&gt;で指定したパスに以降使うkubeconfigを生成する。
この証明書を自動更新(i.e. Certificate Rotation)するオプションが&lt;code&gt;--rotate-certificates&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--pod-manifest-path&lt;/code&gt;で指定したディレクトリはkubeletに定期的にスキャンされ、そこに置いたKubernetesマニフェスト(ドットで始まるもの以外)が読まれる。
(参照: &lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/static-pod/&#34;&gt;Static Pods&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--pod-cidr&lt;/code&gt;は指定しない。
これはkube-controller-managerに渡した&lt;code&gt;--cluster-cidr&lt;/code&gt;と&lt;code&gt;--node-cidr-mask-size&lt;/code&gt;から計算されるので。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--anonymous-auth=false&lt;/code&gt;は&lt;a href=&#34;https://kubernetes.io/docs/admin/kubelet-authentication-authorization/&#34;&gt;セキュリティのために推奨されたオプション&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--authorization-mode=Webhook&lt;/code&gt;も&lt;a href=&#34;https://kubernetes.io/docs/admin/kubelet-authentication-authorization/&#34;&gt;セキュリティのために推奨されたオプション&lt;/a&gt;で、認可処理をkube-apiserverに移譲する設定。&lt;/p&gt;

&lt;p&gt;本当は&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/&#34;&gt;Kubelet Configファイル&lt;/a&gt;を使ったほうがいいみたいなので、いずれそれに対応する。
(対応した: 「&lt;a href=&#34;https://www.kaitoy.xyz/2018/05/05/kubernetes-kubelet-config-and-pod-sec-policy/&#34;&gt;Kubernetes 1.10のkubeletの起動オプションをKubelet ConfigファイルとPodSecurityPolicyで置き換える&lt;/a&gt;」)&lt;/p&gt;

&lt;p&gt;起動確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# systemctl status kubelet -l
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Node CSR手動承認&lt;/p&gt;

&lt;p&gt;TLS Bootstrappingで生成されたCSRを手動で承認する。&lt;/p&gt;

&lt;p&gt;CSRは以下のコマンドで見れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl get csr
NAME                                                   AGE       REQUESTOR                 CONDITION
csr-cf9hm                                              24m       system:node:k8s-master  Pending
node-csr-Vcw_4HioW1CI96eDH29RMKPrOchEN133053wm6DCXUk   24m       system:bootstrap:itacbw   Pending
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;node-csr-…&lt;/code&gt;がクライアント証明書のためのCSRで、&lt;code&gt;csr-…&lt;/code&gt;がサーバ証明書の。
これらを承認する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl certificate approve node-csr-Vcw_4HioW1CI96eDH29RMKPrOchEN133053wm6DCXUk
# kubectl certificate approve csr-cf9hm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(因みに否認するときは&lt;code&gt;kubectl certificate deny&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;これでクラスタにノードが追加されたはず。
確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl get node
NAME         STATUS    ROLES     AGE       VERSION
k8s-master   Ready     &amp;lt;none&amp;gt;    36s       v1.10.0
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Node CSR自動承認設定&lt;/p&gt;

&lt;p&gt;前節でやった手動承認はcsrapprovingが自動でやってくれる。&lt;/p&gt;

&lt;p&gt;新規ノード参加時のCSRを承認するClusterRoleとして&lt;code&gt;system:certificates.k8s.io:certificatesigningrequests:nodeclient&lt;/code&gt;が自動生成されているので、これを&lt;code&gt;system:bootstrappers&lt;/code&gt;グループにバインドしてやると、自動承認が有効になる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;s&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# cat &amp;lt;&amp;lt;EOF | kubectl create -f -
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: auto-approve-csrs-for-group
subjects:
- kind: Group
  name: system:bootstrappers
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: system:certificates.k8s.io:certificatesigningrequests:nodeclient
  apiGroup: rbac.authorization.k8s.io
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、kubeletのクライアント証明書を自動更新(i.e. RotateKubeletClientCertificate)するときのCSRを承認するClusterRoleとして&lt;code&gt;system:certificates.k8s.io:certificatesigningrequests:selfnodeclient&lt;/code&gt;が自動生成されていて、これをノード毎のユーザにバインドしてやると、自動承認が有効になる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# HOSTNAME=k8s-master
# cat &amp;lt;&amp;lt;EOF | kubectl create -f -
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: ${HOSTNAME}-node-client-cert-renewal
subjects:
- kind: User
  name: system:node:${HOSTNAME}
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient
  apiGroup: rbac.authorization.k8s.io
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;kubeletのサーバ証明書を自動更新(i.e. RotateKubeletServerCertificate)するときのCSRを承認するClusterRoleは現時点で自動生成されないので、自分で作ってノード毎のユーザにバインドして、自動承認を有効にする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# cat &amp;lt;&amp;lt;EOF | kubectl create -f -
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: approve-node-server-renewal-csr
rules:
- apiGroups: [&amp;quot;certificates.k8s.io&amp;quot;]
  resources: [&amp;quot;certificatesigningrequests/selfnodeserver&amp;quot;]
  verbs: [&amp;quot;create&amp;quot;]
EOF
# HOSTNAME=k8s-master
# cat &amp;lt;&amp;lt;EOF | kubectl create -f -
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: ${HOSTNAME}-server-client-cert-renewal
subjects:
- kind: User
  name: system:node:${HOSTNAME}
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: approve-node-server-renewal-csr
  apiGroup: rbac.authorization.k8s.io
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kube-proxy、オーバレイネットワーク、DNSのデプロイ&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;kube-proxy&lt;/p&gt;

&lt;p&gt;kube-proxyのkubeconfigを作成。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# MASTER_IP=192.168.171.200
# KUBERNETES_PUBLIC_ADDRESS=$MASTER_IP
# CLUSTER_NAME=&amp;quot;k8s&amp;quot;
# KCONFIG=&amp;quot;/etc/kubernetes/kube-proxy.kubeconfig&amp;quot;
# KUSER=&amp;quot;system:kube-proxy&amp;quot;
# kubectl config set-cluster ${CLUSTER_NAME} --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 --kubeconfig=${KCONFIG}
# kubectl config set-credentials ${KUSER} --client-certificate=/etc/kubernetes/pki/kube-proxy.crt --client-key=/etc/kubernetes/pki/kube-proxy.key --embed-certs=true --kubeconfig=${KCONFIG}
# kubectl config set-context ${KUSER}@${CLUSTER_NAME} --cluster=${CLUSTER_NAME} --user=${KUSER} --kubeconfig=${KCONFIG}
# kubectl config use-context ${KUSER}@${CLUSTER_NAME} --kubeconfig=${KCONFIG}
# chown kubernetes:kubernetes ${KCONFIG}
# chmod 0600 ${KCONFIG}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl config view --kubeconfig=${KCONFIG}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Service Accountのkube-proxyに&lt;code&gt;system:node-proxier&lt;/code&gt;というClusterRoleを付ける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl create clusterrolebinding kubeadm:node-proxier --clusterrole system:node-proxier --serviceaccount kube-system:kube-proxy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;systemdのユニットファイルを書いてサービス化。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# CLUSTER_CIDR=&amp;quot;10.244.0.0/16&amp;quot;
# cat &amp;gt; /etc/systemd/system/kube-proxy.service &amp;lt;&amp;lt; EOF
[Unit]
Description=Kubernetes Kube Proxy
Documentation=https://github.com/kubernetes/kubernetes
After=network.target


[Service]
User=root
Group=root
ExecStart=/usr/bin/kube-proxy \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --bind-address 0.0.0.0 \\
  --cluster-cidr=${CLUSTER_CIDR} \\
  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig \\
  --v=2
Restart=always
RestartSec=10s


[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable kube-proxy
# systemctl start kube-proxy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# systemctl status kube-proxy -l
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ネットワークプロバイダ (flannel)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/coreos/flannel/blob/master/Documentation/kubernetes.md&#34;&gt;flannelのドキュメント&lt;/a&gt;を参考に。&lt;/p&gt;

&lt;p&gt;flannelをデプロイするには、kube-apiserverとkube-controller-managerの起動オプションに&lt;code&gt;--allow-privileged&lt;/code&gt;を付ける必要がある。&lt;/p&gt;

&lt;p&gt;また、公式が配布しているKubernetesマニフェストを使う場合、kube-controller-managerの起動オプションの&lt;code&gt;--cluster-cidr&lt;/code&gt;で&lt;code&gt;10.244.0.0/16&lt;/code&gt;を指定する必要がある。&lt;/p&gt;

&lt;p&gt;デプロイ自体は以下のコマンドを実行するだけ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このKubernetesマニフェストでは、quay.ioから&lt;code&gt;quay.io/coreos/flannel:v0.10.0-amd64&lt;/code&gt;というコンテナイメージがpullされる。&lt;/p&gt;

&lt;p&gt;Oracleもflannelのコンテナイメージを配布していて、そちらを使うには、Oracle Linux 7.4のダウンロード媒体リストに含まれるOracle Container Services for use with Kubernetes 1.1.9.1に入っているflannel.tarを&lt;code&gt;docker load&lt;/code&gt;しておいて、そのイメージを使うようにマニフェストを書きかえればいい。&lt;/p&gt;

&lt;p&gt;起動確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl -n kube-system get po
NAME                    READY     STATUS    RESTARTS   AGE
kube-flannel-ds-gkcqd   1/1       Running   0          1m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;flannelは&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/network-policies/&#34;&gt;Network Policy&lt;/a&gt;をサポートしていないので、&lt;a href=&#34;https://www.projectcalico.org/&#34;&gt;Calico&lt;/a&gt;か&lt;a href=&#34;https://www.weave.works/oss/net/&#34;&gt;Weave Net&lt;/a&gt;あたりにすればよかったかも。
(やった: 「&lt;a href=&#34;https://www.kaitoy.xyz/2018/05/04/kubernetes-with-weave-net/&#34;&gt;Kubernetes 1.10のクラスタにWeave Netをデプロイする&lt;/a&gt;」)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;CoreDNS&lt;/p&gt;

&lt;p&gt;Kubernetes 1.10からは、サービスディスカバリに(kube-dnsの代わりに)CoreDNSを使うのが標準になった。&lt;/p&gt;

&lt;p&gt;以下を参考にCoreDNSをデプロイする:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/coredns/&#34;&gt;https://kubernetes.io/docs/tasks/administer-cluster/coredns/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://coredns.io/2018/01/29/deploying-kubernetes-with-coredns-using-kubeadm/&#34;&gt;https://coredns.io/2018/01/29/deploying-kubernetes-with-coredns-using-kubeadm/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/coredns/deployment/tree/master/kubernetes&#34;&gt;https://github.com/coredns/deployment/tree/master/kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# cd /tmp
# curl -LO https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/coredns.yaml.sed
# curl -LO https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/deploy.sh
# chmod +x deploy.sh
# DNS_SERVER_IP=&amp;quot;10.0.0.10&amp;quot;
# SERVICE_CLUSTER_IP_RANGE=&amp;quot;10.0.0.0/16&amp;quot;
# DNS_DOMAIN=&amp;quot;cluster.local&amp;quot;
# ./deploy.sh -r $SERVICE_CLUSTER_IP_RANGE -i $DNS_SERVER_IP -d $DNS_DOMAIN &amp;gt; coredns.yaml
# kubectl apply -f coredns.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このKubernetesマニフェストではDocker Hubから&lt;code&gt;coredns/coredns:1.1.1&lt;/code&gt;というイメージがpullされる。&lt;/p&gt;

&lt;p&gt;起動確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl -n kube-system get pods -o wide | grep coredns
coredns-8459d9f654-b585f   1/1       Running   0          48s       10.244.0.3        k8s-master
coredns-8459d9f654-x7drc   1/1       Running   0          48s       10.244.0.2        k8s-master
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;起動確認時にCoreDNSのIPアドレスを確認して、動作確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# dig @10.244.0.3 kubernetes.default.svc.cluster.local +noall +answer


; &amp;lt;&amp;lt;&amp;gt;&amp;gt; DiG 9.9.4-RedHat-9.9.4-61.el7 &amp;lt;&amp;lt;&amp;gt;&amp;gt; @10.244.0.3 kubernetes.default.svc.cluster.local +noall +answer
; (1 server found)
;; global options: +cmd
kubernetes.default.svc.cluster.local. 5 IN A    10.0.0.1
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kubernetesアプリデプロイ&lt;/p&gt;

&lt;p&gt;前節まででKubernetesクラスタの構築は完了。
試しにKubernetesアプリをひとつデプロイしてみる。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/weaveworks/scope&#34;&gt;Weave Scope&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.weave.works/docs/scope/latest/installing/#k8s&#34;&gt;ドキュメント&lt;/a&gt;を参考に。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# cd /tmp
# curl -sSL -o scope.yaml https://cloud.weave.works/k8s/scope.yaml?k8s-service-type=NodePort
# kubectl apply -f scope.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このKubernetesマニフェストではDocker Hubから&lt;code&gt;weaveworks/scope:1.8.0&lt;/code&gt;というイメージがpullされる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl -n weave get svc/weave-scope-app&lt;/code&gt;でポート調べて、&lt;code&gt;http://k8s-master:&amp;lt;ポート&amp;gt;/&lt;/code&gt;をブラウザ開くとWeave ScopeのGUIが見れる。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Skaffoldを触ってみた</title>
          <link>https://www.kaitoy.xyz/2018/04/01/hello-skaffold/</link>
          <pubDate>Sun, 01 Apr 2018 09:59:43 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/04/01/hello-skaffold/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/skaffold#run-a-deployment-pipeline-once&#34;&gt;Skaffold&lt;/a&gt;を試してみた話。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;skaffoldとは&#34;&gt;Skaffoldとは&lt;/h2&gt;

&lt;p&gt;Googleが開発している、Kubernetesアプリケーションを快適に開発するためのツール。
アプリケーションのソースを監視し、変更が入ると、自動的にコンテナイメージをビルドしてKubernetesクラスタにデプロイしてくれる。&lt;/p&gt;

&lt;p&gt;2018/3/16に&lt;a href=&#34;https://cloudplatform.googleblog.com/2018/03/introducing-Skaffold-Easy-and-repeatable-Kubernetes-development.html&#34;&gt;発表&lt;/a&gt;された新しいツールで、触った感じではまだこれからといった感じだった。&lt;/p&gt;

&lt;p&gt;Goで書かれていて、Linux、OS X、Windows用のバイナリが提供されている。&lt;/p&gt;

&lt;p&gt;似たツールにはMicrosoftの&lt;a href=&#34;https://draft.sh/&#34;&gt;Draft&lt;/a&gt;がある。&lt;/p&gt;

&lt;p&gt;また、Gitのコミットを自動デプロイしてくれるものに、&lt;a href=&#34;https://gitkube.sh/&#34;&gt;Gitkube&lt;/a&gt;、&lt;a href=&#34;http://jenkins-x.io/&#34;&gt;Jenkins X (エックス)&lt;/a&gt;がある。&lt;/p&gt;

&lt;h2 id=&#34;windows版を試す&#34;&gt;Windows版を試す&lt;/h2&gt;

&lt;p&gt;自PCがWindowsなのでWindows版を試す。
会社で使ってるのもWindowsだし。&lt;/p&gt;

&lt;p&gt;Skaffoldを使うには、Skaffoldの実行バイナリ、Kubernetesクラスタ、そのクラスタをコンテクストに設定したkubectl、Dockerが必要。&lt;/p&gt;

&lt;p&gt;まずWindows版Skaffoldをインストールする。
&lt;a href=&#34;https://github.com/GoogleCloudPlatform/skaffold/releases&#34;&gt;GitHubのリリースページ&lt;/a&gt;からWindowsバイナリをダウンロードして、skaffold.exeにリネームしてPATHの通ったところに置くだけ。
Skaffoldのバージョンは0.3.0。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Kubernetesクラスタは、Windows 10 Home上にminikube 0.22.2で作ったKubernetes 1.7.0のクラスタ。
minikubeは&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/&#34;&gt;以前&lt;/a&gt;インストールしたものを使う。&lt;/p&gt;

&lt;p&gt;minikubeを起動。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;&amp;gt; minikube start --kubernetes-version v1.7.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;kubectlもminikubeと一緒にインストール済み。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Dockerについては、デーモンはminikube上のを使えばいいとして、クライアント(Docker Client)はskaffoldコマンドから実行するのでWindows上にないとだめはなず。&lt;/p&gt;

&lt;p&gt;WindowsでDockerと言えば今なら&lt;a href=&#34;https://www.docker.com/docker-windows&#34;&gt;Docker for Windows&lt;/a&gt;だけど、これはWindows 10 Proじゃないと使えなかったはずなので、&lt;a href=&#34;https://docs.docker.com/toolbox/&#34;&gt;Docker Toolbox&lt;/a&gt;でクライアントをいれた。&lt;/p&gt;

&lt;p&gt;このクライアントはデフォルトではローカルのデーモンを見てるので、minikubeのデーモンを見させる。
そのための設定はminikubeのコマンドで分かるようになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;&amp;gt; minikube docker-env
SET DOCKER_TLS_VERIFY=1
SET DOCKER_HOST=tcp://192.168.99.100:2376
SET DOCKER_CERT_PATH=C:\Users\kaitoy\.minikube\certs
SET DOCKER_API_VERSION=1.23
REM Run this command to configure your shell:
REM @FOR /f &amp;quot;tokens=*&amp;quot; %i IN (&#39;minikube docker-env&#39;) DO @%i
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これに従って以下のコマンドを実行するとクライアントの設定完了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;&amp;gt; @FOR /f &amp;quot;tokens=*&amp;quot; %i IN (&#39;minikube docker-env&#39;) DO @%i
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで準備完了。&lt;/p&gt;

&lt;p&gt;Skaffoldの&lt;a href=&#34;https://github.com/GoogleCloudPlatform/skaffold/tree/10d56cf0fd3c253b0716a084419b5833e53d9870#getting-started-with-local-tooling&#34;&gt;Getting Started&lt;/a&gt;をやってみる。&lt;/p&gt;

&lt;p&gt;Skaffoldのリポジトリをcloneして、コマンドプロンプト開いて、&lt;code&gt;examples/getting-started&lt;/code&gt;にcdして、以下のコマンドを実行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;&amp;gt; skaffold dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;エラーで終わった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[31mERRO[0m[0047] run: running skaffold steps: starting watch on file C:\Users\kaitoy\Desktop\skaffold\examples\getting-started\Dockerfile: adding watch for C:\Users\kaitoy\Desktop\skaffold\examples\getting-started\Dockerfile: The parameter is incorrect.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;MinGW(Git Bash)でやっても同じ結果。
&lt;a href=&#34;https://github.com/GoogleCloudPlatform/skaffold/issues/287&#34;&gt;Issuesに登録されているやつ&lt;/a&gt;と同じ問題っぽい。&lt;/p&gt;

&lt;p&gt;対応を待つしかない。&lt;/p&gt;

&lt;h2 id=&#34;linux版を試す&#34;&gt;Linux版を試す&lt;/h2&gt;

&lt;p&gt;Linux版も試してみる。
minikubeのVMがLinux(Boot2Docker)なので、そこで動かす。
&lt;a href=&#34;https://ja.wikipedia.org/wiki/Windows_Subsystem_for_Linux&#34;&gt;WSL&lt;/a&gt;は試さない。
会社のPCがWindows 7で使えないので。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;SkaffoldのLinux版バイナリをダウンロードしてskaffoldにリネームして、minikubeのBoot2DockerにSSHでログインして、PATHの通ったところに置く。
因みにminikubeのBoot2Dockerは、ユーザdockerパスワードtcuserでログインできる。&lt;/p&gt;

&lt;p&gt;kubectlのLinux版バイナリもダウンロードしてPATHに入れたら準備完了。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;examples/getting-started&lt;/code&gt;にcdして&lt;code&gt;skaffold dev&lt;/code&gt;したらエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ERRO[0001] run: getting skaffold config: getting k8s client: Error creating kubeConfig: invalid configuration: no configuration has been provided
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちょっと調べたら、kubectlのコンテクストが設定されていないのがだめっぽい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# kubectl config current-context
error: current-context is not set
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Windows上のkubectlに設定されたコンテクストを参考に、以下の内容を&lt;code&gt;~/.kube/config&lt;/code&gt;に。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
clusters:
- cluster:
    certificate-authority: /c/Users/kaitoy/.minikube/ca.crt
    server: https://localhost:8443
  name: minikube
contexts:
- context:
    cluster: minikube
    user: minikube
  name: minikube
current-context: minikube
kind: Config
preferences: {}
users:
- name: minikube
  user:
    client-certificate: /c/Users/kaitoy/.minikube/client.crt
    client-key: /c/Users/kaitoy/.minikube/client.key
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;再度&lt;code&gt;skaffold dev&lt;/code&gt;したら違うエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;WARN[0002] run: build: build step: running build: read auth configs: docker config: opening docker config: open /home/docker/.docker/config.json: no such file or directory
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;.docker/config.json&lt;/code&gt;は&lt;code&gt;docker login&lt;/code&gt;すると生成されるものらしい。
SkaffoldのREADME.mdにはminikube使うならDocker image registry要らないって書いてあるんだけど…&lt;/p&gt;

&lt;p&gt;色々あって、ファイルがあればいいだけっぽいので、以下で良し。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# echo {} &amp;gt; ~/.docker/config.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;再度&lt;code&gt;skaffold dev&lt;/code&gt;したら動いた。
Dockerビルドが走り、minikubeにPodがデプロイされた。&lt;/p&gt;

&lt;p&gt;Getting Startedのサンプルは、一秒ごとに「[getting-started] Hello world!」というメッセージをコンソールに表示する。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;examples/getting-started/main.go&lt;/code&gt;の&lt;code&gt;fmt.Println(&amp;quot;Hello world!&amp;quot;)&lt;/code&gt;のとこをいじってメッセージを変えたら、自動で再Dockerビルドしてデプロイされて、新しいメッセージを表示し始めた。
便利。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;examples/getting-started/skaffold.yaml&lt;/code&gt;がSkaffoldの設定ファイルで、ここに定義されたKubernetesマニフェストをデプロイしてくれるっぽい。
watchするファイルはどう決めているんだろうか。
Dockerfileとmain.goはwatchしてるけど、新しいファイルを作ってもDockerビルド走らなかった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ひとつ問題は、Linuxファイルシステム上で編集しないと変更を検知してくれない。&lt;/p&gt;

&lt;p&gt;minikubeのVMには&lt;code&gt;C:\Users&lt;/code&gt;がマウントされてるので、最初はWindows上にcloneしたサンプルをSkaffoldで実行しつつ、Windows上でmain.goを編集してみたんだけど、それだとダメだった。&lt;/p&gt;

&lt;p&gt;やはりWindows版Skaffoldの修正が待たれる。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>機械学習のHello World: MNISTの分類モデルをKerasで作ってみた</title>
          <link>https://www.kaitoy.xyz/2018/03/25/hello-world-to-ml-with-keras/</link>
          <pubDate>Sun, 25 Mar 2018 22:43:27 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/03/25/hello-world-to-ml-with-keras/</guid>
          <description>

&lt;p&gt;機械学習のHello Worldとしてよくやられる&lt;a href=&#34;http://yann.lecun.com/exdb/mnist/&#34;&gt;MNIST&lt;/a&gt;の分類モデルを&lt;a href=&#34;https://keras.io/ja/&#34;&gt;Keras&lt;/a&gt; on &lt;a href=&#34;https://www.tensorflow.org/&#34;&gt;TensorFlow&lt;/a&gt;で作ってみた話。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;mnistとは&#34;&gt;MNISTとは&lt;/h2&gt;

&lt;p&gt;手書き数字画像のラベル付きデータセット。
6万個の訓練データと1万個のテストデータからなる。
&lt;a href=&#34;https://creativecommons.org/licenses/by-sa/3.0/&#34;&gt;CC BY-SA 3.0&lt;/a&gt;で&lt;a href=&#34;http://www.pymvpa.org/datadb/mnist.html&#34;&gt;配布されているっぽい&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;一つの画像は28×28ピクセルの白黒画像で、0から9のアラビア数字が書かれている。&lt;/p&gt;

&lt;p&gt;画像とラベルがそれぞれ独特な形式でアーカイブされていて、画像一つ、ラベル一つ取り出すのも一苦労する。&lt;/p&gt;

&lt;h2 id=&#34;kerasとは&#34;&gt;Kerasとは&lt;/h2&gt;

&lt;p&gt;Pythonのニューラルネットワークライブラリ。
バックエンドとしてTensorFlowかCNTKかTheanoを使う。
今回はTensorFlowを使った。&lt;/p&gt;

&lt;h2 id=&#34;やったこと&#34;&gt;やったこと&lt;/h2&gt;

&lt;p&gt;KerasのMNISTの&lt;a href=&#34;https://keras.io/ja/datasets/#mnist&#34;&gt;API&lt;/a&gt;とか&lt;a href=&#34;https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py&#34;&gt;コードサンプル&lt;/a&gt;とかがあけどこれらはスルー。&lt;/p&gt;

&lt;p&gt;MNISTのサイトにあるデータセットをダウンロードしてきて、サイトに書いてあるデータ形式の説明を見ながらサンプルを取り出すコードを書いた。
で、KerasでVGGっぽいCNNを書いて、学習させてモデルをダンプして、ダンプしたモデルをロードしてテストデータで評価するコードを書いた。
コードは&lt;a href=&#34;https://github.com/kaitoy/ml-mnist&#34;&gt;GitHub&lt;/a&gt;に。&lt;/p&gt;

&lt;h2 id=&#34;ネットワークアーキテクチャ&#34;&gt;ネットワークアーキテクチャ&lt;/h2&gt;

&lt;p&gt;入力画像のサイズに合わせてVGGを小さくした感じのCNNを作った。&lt;/p&gt;

&lt;p&gt;VGGは2014年に発表されたアーキテクチャで、各層に同じフィルタを使い、フィルタ数を線形増加させるシンプルな構造でありながら、性能がよく、今でもよく使われるっぽい。&lt;/p&gt;

&lt;p&gt;VGGを図にすると以下の構造。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/hello-world-to-ml-with-keras/vgg16.png&#34; alt=&#34;vgg16.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;実際はバッチ正規化とかDropoutもやるのかも。
プーリング層は数えないで16層なので、VGG-16とも呼ばれる。
パラメータ数は1億3800万個くらいで、結構深めなアーキテクチャ。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;VGG-16は244×244×3の画像を入力して1000クラスに分類するのに対し、MNISTは28×28×1を入れて10クラスに分類するので、以下のような7層版を作った。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/hello-world-to-ml-with-keras/vgg7.png&#34; alt=&#34;vgg7.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;これでパラメータ数は27万個くらい。
訓練データのサンプル数が6万個なので、パラメータ数が大分多い感じではある。&lt;/p&gt;

&lt;p&gt;コードは以下。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;inputs: Tensor = Input(shape=(IMAGE_NUM_ROWS, IMAGE_NUM_COLS, 1))

x: Tensor = Conv2D(filters=8, kernel_size=(2, 2), padding=&#39;same&#39;, activation=&#39;relu&#39;)(inputs)
x = Conv2D(filters=8, kernel_size=(2, 2), padding=&#39;same&#39;, activation=&#39;relu&#39;)(x)
x = MaxPooling2D(pool_size=(2, 2))(x)

x = Conv2D(filters=16, kernel_size=(2, 2), padding=&#39;same&#39;, activation=&#39;relu&#39;)(x)
x = Conv2D(filters=16, kernel_size=(2, 2), padding=&#39;same&#39;, activation=&#39;relu&#39;)(x)
x = Conv2D(filters=16, kernel_size=(2, 2), padding=&#39;same&#39;, activation=&#39;relu&#39;)(x)
x = MaxPooling2D(pool_size=(2, 2))(x)

x = Flatten()(x)
x = Dense(units=256, activation=&#39;relu&#39;)(x)
x = Dense(units=256, activation=&#39;relu&#39;)(x)
predictions: Tensor = Dense(NUM_CLASSES, activation=&#39;softmax&#39;)(x)

model: Model = Model(inputs=inputs, outputs=predictions)
model.compile(optimizer=&#39;adam&#39;, loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;訓練-評価&#34;&gt;訓練・評価&lt;/h2&gt;

&lt;p&gt;上記モデルを6万個のサンプルでバッチサイズ512で一周(1エポック)学習させると、Intel Core i5-6300HQプロセッサー、メモリ16GBのノートPCで28秒前後かかる。&lt;/p&gt;

&lt;p&gt;とりあえず3エポック学習させてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;(ml-mnist) C:\workspace\ml-mnist&amp;gt;python bin\ml_mnist.py train
Using TensorFlow backend.
Epoch 1/3
60000/60000 [==============================] - 28s 465us/step - loss: 0.7813 - acc: 0.7702
Epoch 2/3
60000/60000 [==============================] - 27s 453us/step - loss: 0.1607 - acc: 0.9496
Epoch 3/3
60000/60000 [==============================] - 27s 448us/step - loss: 0.1041 - acc: 0.9681
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ロスが0.1041で正答率が96.81%という結果になった。&lt;/p&gt;

&lt;p&gt;このモデルをテストデータで評価する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;(ml-mnist) C:\workspace\ml-mnist&amp;gt;python bin\ml_mnist.py eval
Using TensorFlow backend.
10000/10000 [==============================] - 2s 165us/step
loss: 0.08780829641819, acc: 0.9717000002861023
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正答率97.17%。
そんなに良くないけど、過学習はしていない模様。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次に10エポック学習させて評価してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;(ml-mnist) C:\workspace\ml-mnist&amp;gt;python bin\ml_mnist.py train
Using TensorFlow backend.
Epoch 1/10
60000/60000 [==============================] - 29s 486us/step - loss: 0.5814 - acc: 0.8297
Epoch 2/10
60000/60000 [==============================] - 28s 470us/step - loss: 0.1130 - acc: 0.9651
Epoch 3/10
60000/60000 [==============================] - 28s 469us/step - loss: 0.0711 - acc: 0.9777
Epoch 4/10
60000/60000 [==============================] - 28s 468us/step - loss: 0.0561 - acc: 0.9821
Epoch 5/10
60000/60000 [==============================] - 28s 469us/step - loss: 0.0476 - acc: 0.9852
Epoch 6/10
60000/60000 [==============================] - 28s 473us/step - loss: 0.0399 - acc: 0.9879
Epoch 7/10
60000/60000 [==============================] - 28s 467us/step - loss: 0.0338 - acc: 0.9892
Epoch 8/10
60000/60000 [==============================] - 28s 467us/step - loss: 0.0283 - acc: 0.9909
Epoch 9/10
60000/60000 [==============================] - 29s 490us/step - loss: 0.0230 - acc: 0.9925
Epoch 10/10
60000/60000 [==============================] - 28s 471us/step - loss: 0.0223 - acc: 0.9928

(ml-mnist) C:\workspace\ml-mnist&amp;gt;python bin\ml_mnist.py eval
Using TensorFlow backend.
10000/10000 [==============================] - 2s 171us/step
loss: 0.040611953073740006, acc: 0.9866999998092651
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;テストデータでの正答率98.67%。
ちょっと改善した。&lt;/p&gt;

&lt;h2 id=&#34;モデル改善&#34;&gt;モデル改善&lt;/h2&gt;

&lt;p&gt;試しにバッチ正規化層を入れてみる。
ReLUの前に入れるべきという情報があったけど、それだとちょっと修正が面倒なので、単にプーリング層の後に入れてみた。&lt;/p&gt;

&lt;p&gt;3エポックで学習・評価。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;(ml-mnist) C:\workspace\ml-mnist&amp;gt;python bin\ml_mnist.py train
Using TensorFlow backend.
Epoch 1/3
60000/60000 [==============================] - 45s 746us/step - loss: 0.2157 - acc: 0.9336
Epoch 2/3
60000/60000 [==============================] - 44s 737us/step - loss: 0.0513 - acc: 0.9838
Epoch 3/3
60000/60000 [==============================] - 47s 777us/step - loss: 0.0340 - acc: 0.9896

(ml-mnist) C:\workspace\ml-mnist&amp;gt;python bin\ml_mnist.py eval
Using TensorFlow backend.
10000/10000 [==============================] - 2s 246us/step
loss: 0.051704482543468475, acc: 0.9844999995231628
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;98.45%。
1エポックの学習時間は45秒前後に伸びたけど、速く学習できるようにはなった。&lt;/p&gt;

&lt;p&gt;10エポックではどうか。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;(ml-mnist) C:\workspace\ml-mnist&amp;gt;python bin\ml_mnist.py train
Using TensorFlow backend.
Epoch 1/10
60000/60000 [==============================] - 47s 776us/step - loss: 0.2318 - acc: 0.9265
Epoch 2/10
60000/60000 [==============================] - 47s 790us/step - loss: 0.0596 - acc: 0.9811
Epoch 3/10
60000/60000 [==============================] - 47s 778us/step - loss: 0.0370 - acc: 0.9884
Epoch 4/10
60000/60000 [==============================] - 48s 801us/step - loss: 0.0259 - acc: 0.9917
Epoch 5/10
60000/60000 [==============================] - 47s 785us/step - loss: 0.0182 - acc: 0.9942
Epoch 6/10
60000/60000 [==============================] - 48s 794us/step - loss: 0.0132 - acc: 0.9961
Epoch 7/10
60000/60000 [==============================] - 46s 765us/step - loss: 0.0108 - acc: 0.9965
Epoch 8/10
60000/60000 [==============================] - 45s 751us/step - loss: 0.0107 - acc: 0.9965
Epoch 9/10
60000/60000 [==============================] - 45s 749us/step - loss: 0.0055 - acc: 0.9984
Epoch 10/10
60000/60000 [==============================] - 45s 754us/step - loss: 0.0035 - acc: 0.9991

(ml-mnist) C:\workspace\ml-mnist&amp;gt;python bin\ml_mnist.py eval
Using TensorFlow backend.
10000/10000 [==============================] - 2s 243us/step
loss: 0.034382903814315795, acc: 0.9893999994277954
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;98.94%。
バッチ正規化無し版よりも0.27%改善してるけど、誤差の範囲かも。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;MNISTのサイトに載ってるので一番いいのが99.77%。
どうしたらそんなによくなるのか。&lt;/p&gt;

&lt;h2 id=&#34;エラー分析&#34;&gt;エラー分析&lt;/h2&gt;

&lt;p&gt;一番正答率が高かったモデルについて、エラー分析をしてみた。&lt;/p&gt;

&lt;p&gt;まず、エラーが多かった数字を調べる。
数字をエラー数順に並べると、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ラベル: エラー数
9: 18
7: 18
5: 15
4: 14
6: 14
3: 8
8: 8
2: 7
1: 2
0: 2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;9と7が一番分類むずくて、4、5、6がそれらに次いでむずいことがわかる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次にエラーのパターンを見てみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(予測した数字, ラベル): 出現数
(9, 4): 10
(3, 5): 9
(1, 7): 7
(2, 7): 6
(7, 9): 6
(9, 7): 5
(7, 2): 4
(8, 5): 4
(1, 6): 4
(1, 9): 4
(0, 6): 4
(8, 9): 3
(9, 3): 3
(4, 9): 3
(8, 3): 2
(2, 4): 2
(2, 8): 2
(1, 2): 2
(8, 4): 2
(5, 3): 2
(5, 9): 2
(8, 6): 2
(2, 6): 2
(5, 6): 1
(1, 8): 1
(6, 8): 1
(0, 8): 1
(2, 3): 1
(4, 6): 1
(2, 1): 1
(3, 8): 1
(8, 1): 1
(7, 0): 1
(4, 8): 1
(6, 0): 1
(5, 8): 1
(6, 5): 1
(9, 2): 1
(0, 5): 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4を9と、5を3と、7を1か2と、9を7と間違えたパターンが多い。
特に4と7がむずい模様。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次に、実際に間違えた画像を見てみる。
多かったパターンについて見てみる。&lt;/p&gt;

&lt;p&gt;4を9と間違えたパターン:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/hello-world-to-ml-with-keras/9-4.png&#34; alt=&#34;9-4.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;なんだこれは。
これはかなり9にも見える。
ちょっと角ばってるとこと、線が右にはみ出しているとこで判断するのか。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;5を3と間違えたパターン:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/hello-world-to-ml-with-keras/3-5.png&#34; alt=&#34;3-5.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;これはもうちょっとモデルに頑張ってほしい。
これを3としてしまうのは残念。
なにがだめだったのかは分からないけど。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;7を1と間違えたパターン:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/hello-world-to-ml-with-keras/1-7.png&#34; alt=&#34;1-7.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;これは1でもいいような…&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;7を2と間違えたパターン:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/hello-world-to-ml-with-keras/2-7.png&#34; alt=&#34;2-7.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;これはちょっと面白い。
7の真ん中に線をいれるパターンを訓練データに足せば対応できそう。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;9を7と間違えたパターン:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/hello-world-to-ml-with-keras/7-9.png&#34; alt=&#34;7-9.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;これもモデルに頑張ってほしかったパターン。
左上のごみが悪さしたんだろうか。
ごみがあるパターンを訓練データに増やすと対応できるかも。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あと、ちょっと噴いたやつ:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/hello-world-to-ml-with-keras/2-4.png&#34; alt=&#34;2-4.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;これは4。
モデルは2と間違えた。
むずい。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/hello-world-to-ml-with-keras/2-8.png&#34; alt=&#34;2-8.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;これは8。
モデルは2と間違えた。
こんなのテストデータにいれないで…&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>オープンデータメモ</title>
          <link>https://www.kaitoy.xyz/2018/03/04/open-data/</link>
          <pubDate>Sun, 04 Mar 2018 16:22:46 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/03/04/open-data/</guid>
          <description>&lt;p&gt;機械学習の勉強に使えそうなオープンデータのメモ。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;テキスト

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://wordnet.princeton.edu/&#34;&gt;WordNet&lt;/a&gt;: 英語の語彙データベース。名詞、動詞、形容詞、副詞ごとに階層的にグルーピングされたDBが提供されている。ライセンスは&lt;a href=&#34;http://wordnet.princeton.edu/wordnet/license/&#34;&gt;WordNet License&lt;/a&gt;で、著作権表示さえしておけば、目的の制限なく、使用、複製、改変、再配布を無料でできる。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://compling.hss.ntu.edu.sg/wnja/index.ja.html&#34;&gt;日本語ワードネット&lt;/a&gt;: 日本語版WordNet。ライセンスは&lt;a href=&#34;http://compling.hss.ntu.edu.sg/wnja/license.txt&#34;&gt;Japanese WordNetライセンス&lt;/a&gt;で、著作権表示さえしておけば、目的の制限なく、使用、複製、改変、再配布を無料でできる。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;画像

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://image-net.org/index&#34;&gt;ImageNet&lt;/a&gt;: WordNetの名詞の階層構造に従ってラベル付けされた1400万個以上の画像データ。バウンディングボックスも付いてる。画像はFlickrとかに上がっているもので、そこから自分で無料でダウンロードできる。非商用(研究か教育)目的ならImageNetのサイトから画像をダウンロードできる。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/openimages/dataset&#34;&gt;Open Images&lt;/a&gt;: 900万個の画像に数千クラスのラベルとバウンディングボックスを付けたデータ。ライセンスはCreative Commons BY 4.0。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://yann.lecun.com/exdb/mnist/&#34;&gt;MNIST&lt;/a&gt;: 手書き数字のラベル付きデータセット。訓練データとテストデータ合わせて7万個。機械学習のHello Worldに使われる。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;動画

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://research.google.com/youtube8m/&#34;&gt;YouTube-8M&lt;/a&gt;: 800万個のYouTube動画を4800クラスでラベル付けしたデータ。ライセンスはCreative Commons BY 4.0。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://research.google.com/youtube-bb/&#34;&gt;YouTube-Bounding Boxes&lt;/a&gt;: 24万個のYouTube動画に23クラスのラベルと560万個のバウンディングボックスを付けたデータ。ライセンスはCreative Commons BY 4.0。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://research.google.com/ava/&#34;&gt;Atomic Visual Actions(AVA)&lt;/a&gt;: 5.76万個のYouTube動画を、80種の動作についてラベル付けしたデータ。ライセンスはCreative Commons BY 4.0。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;音声

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz&#34;&gt;Speech Commands Datase&lt;/a&gt;: 6.5万個の1秒音声データで、30種の言葉を数千人が発音してる。ライセンスはCreative Commons BY 4.0。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://research.google.com/audioset/&#34;&gt;AudioSet&lt;/a&gt;: 200万個の10秒音声データで、527クラスでラベル付けされてる。ライセンスはCreative Commons BY 4.0。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;データカタログサイト

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.data.go.jp/&#34;&gt;DATA GO JP&lt;/a&gt;: 日本政府が公開してる公共データ集。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://archive.ics.uci.edu/ml/index.php&#34;&gt;UCI Machine Learning Repository&lt;/a&gt;: 現時点で426のデータセットが配布されている。有名なアヤメのデータセットのソースはここ。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;単語ベクトル

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bizreach/ai/tree/master/word2vec&#34;&gt;HR領域の単語ベクトル&lt;/a&gt;: 約9.95億個の日本語のHR系の単語からWord2Vecで学習した単語ベクトル。ベクトル長は100か200。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;学習済みモデル

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://caffe.berkeleyvision.org/model_zoo.html&#34;&gt;Caffe Model Zoo&lt;/a&gt;: Caffe用のモデル集。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/Detectron/blob/master/MODEL_ZOO.md&#34;&gt;Detectron Model Zoo&lt;/a&gt;: Facebookが開発した物体検知モデルの学習済みモデル。Caffe2。ライセンスはCC BY-SA 3.0。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CourseraのDeep Learning SpecializationのSequence Modelsコースを修了した</title>
          <link>https://www.kaitoy.xyz/2018/02/27/coursera-deep-learning-sequence-models/</link>
          <pubDate>Tue, 27 Feb 2018 00:49:05 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/02/27/coursera-deep-learning-sequence-models/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/02/06/coursera-deep-learning-convolutional-neural-networks/&#34;&gt;CourseraのDeep Learning SpecializationのConvolutional Neural Networksコースを修了した&lt;/a&gt;のに続き、&lt;a href=&#34;https://www.coursera.org/learn/nlp-sequence-models&#34;&gt;Sequence Modelsコース&lt;/a&gt;を修了した。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;このコースは、RNNの原理、代表的なアーキテクチャ、自然言語処理などについて学べる3週間のコース。
生成モデルが色々出てきて面白い。
動画は今のところ全部英語。&lt;/p&gt;

&lt;p&gt;2018/2/6に始めて、2/27に完了。
22日間かかった。
修了したらまた&lt;a href=&#34;https://www.coursera.org/account/accomplishments/certificate/NCW69X7UASJ6&#34;&gt;Certifacate&lt;/a&gt;もらえた。&lt;/p&gt;

&lt;p&gt;また、これでDeep Learning Specializationのすべてのコースを修了したので、全部まとめた&lt;a href=&#34;https://www.coursera.org/account/accomplishments/specialization/certificate/4487DSN9ARXN&#34;&gt;Certifacate&lt;/a&gt;ももらえた。
結局2ヶ月ほどかかり、1万円以上課金してしまった…&lt;/p&gt;

&lt;p&gt;以下、3週分の内容をメモ程度に書いておく。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;p&gt;連続データを扱うシーケンス(Sequence)モデルについて学ぶ。
RNN、LSTM、GRU、BRNN。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;再帰型ニューラルネットワーク(Recurrent Neural Network)&lt;/p&gt;

&lt;p&gt;シーケンスモデルにはRNNなどがあって、音声認識(Speech recognition)や自然言語処理(Natural language processing)に使われる。
音楽生成(Music generation)、感情分類(Sentiment classification)、DNA解析(DNA sequence analysis)、動画行動認識(Video Activity Recognition)、固有表現抽出(Named entity recognition)なんてのも。&lt;/p&gt;

&lt;p&gt;入力だけが連続データだったり、出力だけが連続データだったり、両方だったり。&lt;/p&gt;

&lt;p&gt;自然言語処理では、ボキャブラリ(Vocabulary)を使って単語をone hotベクトルにして扱う。
ボキャブラリは普通5万次元くらいのベクトル。
ボキャブラリにない単語はそれ用(unknown)の次元に割り当てる。&lt;/p&gt;

&lt;p&gt;入力や出力の次元がサンプルごとに違うので、普通のNNは使えない。
また、普通のNNだと、文のある個所から学んだ特徴を他の箇所と共有しない。
また、普通のNNだと、入力サイズが大きすぎて、パラメータが多くなりすぎる。
RNNはこうした問題を持たない。&lt;/p&gt;

&lt;p&gt;RNNは、最初の単語xを受け取り、層で計算し、最初の出力yとアクティベーションaを出し、そのaと次のxを同じ層で受け取り、次のyとaをだす、ということを繰り返す。
xにかける重みをWax、aにかける重みをWaa、yにかける重みをWyaと呼ぶ。
あとaとyを計算するときに足すバイアスがあって、それぞれba、by。
あるxの計算をするときに、その前のxも使うので、連続データ処理に向いてる。
けど、後のxを考慮しないところが欠点。
この欠点に対処したのがBRNN(Bidirectional RNN)。&lt;/p&gt;

&lt;p&gt;RNNのaの活性化関数にはtanhがよく使われる。
ReLUもあり。
yには二値分類だったらシグモイドだし、そうでなければソフトマックスとか。&lt;/p&gt;

&lt;p&gt;損失関数は普通に交差エントロピーでいいけど、yがベクトルなので、その各要素について交差エントロピーを計算して、足し合わせたものが損失になる。
ここから逆伝播するんだけど、その際に連続データを過去にさかのぼるので、時をかける逆伝播(BPTT: Backpropagation through time)と呼ばれる。&lt;/p&gt;

&lt;p&gt;上で説明したRNNは、入力と出力が同じ長さだけど、そうでない問題のほうが多い。
感情分類なんかは、任意の長さの文を入力して、5段階評価とかするので、最後のxまで入力した後で一つだけyを出すようにする。
音楽生成なんかは入力が一つで出力が多いので、入力がない部分は前の出力を代わりに入力する。
翻訳みたいに入力と出力の長さが違うときは、前半入力だけして、後半出力だけする。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;言語モデル(Language model)&lt;/p&gt;

&lt;p&gt;ある文のあとに、どんな分が続くかを確率で示してくれるモデル。&lt;/p&gt;

&lt;p&gt;訓練データは、文をトークンに分解してone-hotベクトルにして、最後にEOSトークンを加えて作る。&lt;/p&gt;

&lt;p&gt;モデルは、RNNの出力をボキャブラリと同じサイズのソフトマックスにして、どの単語の確率が高いかを出力させる。
最初に0ベクトルを入力し、その出力を次の入力にして、それを繰り返す。&lt;/p&gt;

&lt;p&gt;単語じゃなくて文字単位でやるモデルもあるけど、あんまり使われない。&lt;/p&gt;

&lt;p&gt;このモデルを使うと、学習した文章に似た雰囲気の分を生成できる。
このとき、出力したベクトルから、各単語の確率にしたがって単語をサンプリングし、それを次の入力にする。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;RNNの勾配消失&lt;/p&gt;

&lt;p&gt;英語の文だと、主語が単数だと動詞の形が変わるんだけど、主語と動詞がすごい離れていることがありうる。
最初のほうの単語である主語は浅い層(初期のステップ)で処理されて、一方動詞は深い層(あとのほうのステップ)で処理されることになる。
すると、勾配消失により、深い層の単語が浅い層から受ける影響が小さくなってしまって、動詞の形をいい感じに学習できない。
これがナイーブなRNNの欠点。&lt;/p&gt;

&lt;p&gt;勾配爆発も起こり得るけど、Gradient clipping、つまり勾配の値を計算した後に値が閾値を超えていたら修正する手法を使えば比較的簡単に回避できるので、勾配消失が深刻。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;GRU(Gated Recurrent Unit)&lt;/p&gt;

&lt;p&gt;RNNにMemory cell&amp;copy;というアイデアを加えたもの。
cは浅い層の情報を深い層に伝える役目をして、勾配消失問題を緩和する。
cの候補は毎回、前回のcとxの線形変換をtanhに入れたものとして生成され、それを、0か1を返すゲートΓu(シグモイドな感じの関数)で実際にcとして使うかを決めて、cを更新していく。
このゲートを更新ゲート(Update gate)という。
cはソフトマックスに入れてyを出力したり、次のステップのaにする。&lt;/p&gt;

&lt;p&gt;実際には、もう一つ関連ゲート(Relevance gate)Γrってのがあって、cの候補を計算するときに前回のcに掛ける。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;LSTM(Long short term memory)&lt;/p&gt;

&lt;p&gt;RNNの勾配消失に対処するまた別のアイデア。
GRUよりパワフル。
けどGRUより古くからあるもので、GRUがそれのシンプル版という関係。&lt;/p&gt;

&lt;p&gt;LSTMの論文はかなりむずい。&lt;/p&gt;

&lt;p&gt;GRUと比べると、まずΓrはない。&lt;/p&gt;

&lt;p&gt;で、GRUはΓuが1だったらcを更新して、0だったら前のを保持するという感じだったけど、LSTMでは忘却ゲート(Forget gate)Γfに前回のcをかけて、捨てるかどうかを決める。&lt;/p&gt;

&lt;p&gt;また、出力ゲート(Output gate)Γoが追加されて、単にcを次のaにするんじゃなくて、&lt;code&gt;Γo*c&lt;/code&gt;をaにする。&lt;/p&gt;

&lt;p&gt;各ゲートは前のaと今回のxの線型結合にバイアスを加えたものをシグモイドして計算する。
ゲートの計算にcもいれることがあって、のぞき穴接続 (Peephole connection)と呼ばれる。&lt;/p&gt;

&lt;p&gt;基本的にはLSTM使えばいいけど、GRUのほうが計算コストが少なくて大きなネットワーク作りやすいから、GRUのほうがいいこともある。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;BRNN(Bidirectional RNN)&lt;/p&gt;

&lt;p&gt;普通にRNNやった後、後ろの入力から順番に逆向きにRNNする。
yは、順向きのaと逆向きのaとバイアスを線形計算して非線形変換したものになる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Deep RNN&lt;/p&gt;

&lt;p&gt;単にyを出力するんじゃなくて、そのyを入力とする別のRNNを積み上げていくとdeepになる。
RNNは時間軸の方向にすでに深いので、出力方向には普通は2、3個だけ積み上げる。&lt;/p&gt;

&lt;p&gt;出力方向にRNNを積み上げる代わりに、出力を普通のNNにいれるってのもある。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;p&gt;3つもある…&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ベーシックRNNとLSTMの順伝播をNumPyで実装&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;恐竜の名前を生成する言語モデルをNumPyで実装&lt;/p&gt;

&lt;p&gt;Gradient clippingとサンプリングを実装して、モデルを訓練しながら、恐竜の名前をいい感じに生成できるようになっていく様を観察する。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;LSTMの音楽生成モデルをKerasで実装&lt;/p&gt;

&lt;p&gt;Jazzの曲の断片を学習させて、それっぽい曲を生成してみる。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;p&gt;自然言語処理。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;単語埋め込み(Word embedding)&lt;/p&gt;

&lt;p&gt;1週目でやったように、単語をone-hotベクトルで表すと、単語同士の積が0になって、単語間の関係(距離)が表せられない。
代わりに、単語を特徴のベクトルにして、各次元に特徴量をもたせる、特徴付き表現(Featurized representation)がある。&lt;/p&gt;

&lt;p&gt;単語の特徴は数百とかにするけど、可視化するために2Dにすることがある。
このための代表的なアルゴリズムがt-SNE。
t-SNEは複雑で非線形な処理をするので、後述の類推には使えないけど、似たような単語のクラスタを観察できる。&lt;/p&gt;

&lt;p&gt;特徴の分布を表すN次元の空間に単語を埋め込むため、単語埋め込みという。
このN次元ベクトルを単語の数だけ結合したものをEで表す。&lt;/p&gt;

&lt;p&gt;この表現形式にすると、大量の適当なテキストデータで学習させたり、学習済みのモデルをダウンロードしたりしたあと、特定のタスクのために転移学習させることができる。&lt;/p&gt;

&lt;p&gt;また、類推(Analogical reasoning)が可能になる。
単語のペアが二つあって、ペア内の単語ベクトル間の差を計算して、ペア間でその値が近ければ、それらのペアは同じような関係の組み合わせだと言える。
例えば、&lt;code&gt;男 - 女&lt;/code&gt;は&lt;code&gt;王 - 女王&lt;/code&gt;に近くなる。
類似度の計算にはコサイン類似度(Cosine similarity)がよく使われる。
ユークリッド距離(Euclidean distance)でもいいけど、コサイン類似度のほうが一般的。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;単語埋め込みの学習&lt;/p&gt;

&lt;p&gt;Eにone-hotベクトルをかけると、そのone-hotベクトルが表す単語の特徴ベクトルが得られる。&lt;/p&gt;

&lt;p&gt;数単語の後に続く単語を予測するニューラル言語モデルを考えると、与えられたそれぞれの単語を表すone-hotベクトルを入力して、Eをかける層があって、その結果を全結合層にいれて、その結果をボキャブラリサイズのベクトルを出力するソフトマックス層にいれる。
ソフトマックス層の出力で、一番大きい値の単語が予測する単語になる。
Eをパラメータにしておくと、このモデルを訓練するとEが学習される。
予測精度自体はそんなによくならなくても問題ない。&lt;/p&gt;

&lt;p&gt;予測する単語の前だけじゃなくて、前後の単語を使って学習させたりも。
1単語だけで予測しても結構いい結果になる。&lt;/p&gt;

&lt;p&gt;上記のモデルはSkip-Gramモデルと呼ばれる。
実際には、文の中からターゲット単語を選び、前後ウィンドウサイズ(5とか)以内のコンテクスト単語を一つ選び、それらをペアにして一つの訓練データを作る。
コンテクスト単語は完全にランダムに選ぶと、aとかtheとかofとかが多くなっちゃうので、ヒューリスティックにバランスよく選ぶ必要がある。&lt;/p&gt;

&lt;p&gt;ソフトマックス層は、ボキャブラリサイズのベクトルを出力するため、計算コストがでかい。
その対策として、階層的ソフトマックス(Hierarchical softmax)ってのがあって、これは木構造で分類を表す手法。
もう一つ負例サンプリング(Negative sampling)という手法があって、こっちのほうがシンプルで効果的。&lt;/p&gt;

&lt;p&gt;Skip-Gramモデルのほか、CBOW(Continuous Bag Of Words)というモデルもある。
これはターゲット単語とその前後数単語を訓練データにするもの。
これらのモデルをWord2Vecモデルといったり、それを使ってEを学習する手法をWord2Vecアルゴリズムといったりする。&lt;/p&gt;

&lt;p&gt;負例サンプリングではまず、コンテクスト単語に対して別の単語を与え、ターゲット単語なら1、違うなら0というラベル付き訓練データを作る。
ターゲット単語とコンテクスト単語の組はSkip-Gramと同様に選んで、0になる単語はランダムに選ぶ。
コンテクスト単語一つに対し、yが1になるデータを一つ、0になるデータをk個(2～20くらい)作る。
kはデータセットが大きいほど少なくする。
で、Skip-Gramモデルのソフトマックス層を、ボキャブラリの数だけの二値分類ノードに変える。
これらのノードは毎回全部計算するんじゃなくて、k+1個だけを計算するので計算コストが小さい。&lt;/p&gt;

&lt;p&gt;単語埋め込みの学習アルゴリズムとして、Word2Vecじゃないものだと、GloVe(Global Vectors)アルゴリズムってのがある。
GloVeでは、単語iと単語jが近くに現れることが何回あるかをxijで表す。
xijをボキャブラリのすべての単語の組み合わせで数えて、それらと何かの二乗誤差にヒューリスティックな重み付けをしたコスト関数を作って最適化して単語埋め込みを学習させる。
細かいことはよくわからなかった…&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;感情分類&lt;/p&gt;

&lt;p&gt;Yelpみたいなサービスで、コメントから星の数を推定する。&lt;/p&gt;

&lt;p&gt;感情分類は、教師データがあまり得られないことが多いのが課題だけど、よく訓練したEがあれば上手く分類できる。&lt;/p&gt;

&lt;p&gt;コメントを単語に分解したら、それぞれのone-hotベクトルをEとかけて単語ベクトルを作って、単語間の平均を計算して、ソフトマックス層に入れて、出力を星の数だけ作る。
というのがシンプルなモデル。
これだと語順を考慮しないので、RNNに単語ごとに入力して、最後の出力をソフトマックスするといい感じになる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;単語埋め込みからのバイアス除去(Debias)&lt;/p&gt;

&lt;p&gt;単語埋め込みに性別とか人種のバイアスがかかってると、いいモデルができない。
例えば、&lt;code&gt;プログラマ - 男 + 女 = 主婦&lt;/code&gt;みたいになってるとまずい。
こういうバイアスは、学習データのテキストのバイアス、つまりそれを書いた人のバイアスからくる。&lt;/p&gt;

&lt;p&gt;単語空間のバイアスの方向を調べるには、例えば性別のバイアスなら、&lt;code&gt;he - she&lt;/code&gt;とか&lt;code&gt;male - female&lt;/code&gt;とかの平均をとる。
するとある1次元のベクトルが得られて、これがバイアスの方向になる。
この上にある値を他の次元の射影に変換することでバイアスを削減(Neutralize)できる。&lt;/p&gt;

&lt;p&gt;実際には、特異値分解(SVD: Singular Value Decomposition)でもっとシステマチックにバイアスを計算する。
バイアスも数次元のベクトルになりうる。&lt;/p&gt;

&lt;p&gt;Neutralizeしたらさらに、バイアスをなくす方向に単語の組の位置をずらす(Equalize pairs)。
例えば、男と女の組を、ベビーシッターからの距離に差がなくなるようにずらす。&lt;/p&gt;

&lt;p&gt;Neutralizeすべき単語は、線形分類で決めることができる(?)。
Equalizeすべき単語は手で選ぶ。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;訓練済みのGloVeの単語埋め込みをロードして、コサイン類似度計算を実装して、類推を実行。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;NeutralizationとEqualizationを実装。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;感情分類(文に自動で絵文字を付ける)の、シンプルな実装と2層LSTMでの実装。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;3週目&lt;/p&gt;

&lt;p&gt;連続データを入力して連続データを出力するRNNアーキテクチャを学ぶ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Sequence to sequence(Seq2Seq)モデル&lt;/p&gt;

&lt;p&gt;翻訳などに使うモデル。
エンコーダ(encoder)ネットワークで元の単語を読み込み、デコーダ(decoder)ネットワークが翻訳を吐き出す。&lt;/p&gt;

&lt;p&gt;画像を読んでその説明文(caption)を吐くのにもつかわれる。
この場合、CNNで画像を読んで、最後の全結合層の出力をRNNに入れる。&lt;/p&gt;

&lt;p&gt;小説を生成するような言語モデルと異なるのは、ランダムに生成してほしいのではなくて、ベストな結果を生成してほしいところ。
デコーダネットワークの部分は言語モデルと一緒。
入力がエンコーダネットワークの出力か0ベクトルかの違いだけ。
このようなのを条件付き言語モデル(Conditional language model)と呼ぶ。&lt;/p&gt;

&lt;p&gt;言語モデルだと、次に出力する単語をランダムで選んでたけど、翻訳ではそうはいかない。
貪欲法(Greedy algorithm)みたいに、毎回一番確率が高いものを選んでもうまくいかない。
最終的に出力する全単語の確率の掛け合わせが最大になるやつを選びたい。&lt;/p&gt;

&lt;p&gt;ビームサーチ(Beam search)を代わりに使う。
ビーム幅(Beamwidth)Bを決めて、最初にBの数だけ単語の候補を確率の高い順に選ぶ。
で、それらを次の入力にしてB個の出力ベクトルを得たら、最初の単語の確立をそれらのベクトルの各要素にかけて、大きい順にまたB個単語を選ぶ。
あとはこれの繰り返し。&lt;/p&gt;

&lt;p&gt;ビームサーチをもう少し改良できる。
その一つが長さ正規化(Length normalization)。
条件付確率を計算するときに、単語が増えてくると1未満の数を何回もかけることになり、アンダーフローや丸め誤差が発生してしまう。
ので、各単語の確率をかけ合わせる代わりに、各確率のlogを足し合わせる。
これだとまだ、確率が1未満なのでlogは常に負の値になり、単語の数が少ない程総和は大きくなるので、翻訳結果に短い文が選ばれがちになっちゃう。
ので単語数で割る。
または単語数をα(0～1)乗したもので割る。
この式(目的関数)をNormalized log probability objectiveとかNormalized log likelihood objectiveとか呼ぶ。&lt;/p&gt;

&lt;p&gt;Bはどう選ぶか。
Bが小さいと計算コストが低く、最適解を見つける可能性が低い。
Bが大きいとその逆。
プロダクション環境では、10～100くらいが一般的。
研究では数千とかも。
試行錯誤していい値を見つけるしかない。&lt;/p&gt;

&lt;p&gt;深さ優先探索(DFS: Depth First Search)、幅優先探索(BFS: Breadth First Search)に比べて、ビームサーチは最適解を見つけられないかもしれないけど、リーズナブル。&lt;/p&gt;

&lt;p&gt;ビームサーチはヒューリスティックなアルゴリズムなので、いつもいい結果を出すとは限らない。
だめだったときはエラー分析をする。
ダメな翻訳が出力されたとき、RNNの訓練が足らないのか、ビームサーチのBが小さすぎるのかを切り分けたい。&lt;/p&gt;

&lt;p&gt;まずは、翻訳中のある単語について、期待する出力とモデルの出力の確率をそれぞれ見てみる。
前者が大きければ、モデルは正しい出力してるけど、ビームサーチが間違ったものを選択している。
逆ならモデルに問題がある。
(長さ正規化してたらその目的関数を比べる。)
これを色んなサンプルで試して、より多くのサンプルでダメだったほうの改善に努めるべし。&lt;/p&gt;

&lt;p&gt;いい感じの訳が複数あったらどうする?
Bleu(BiLingual Evaluation Understudy)スコアで評価する。
Bleuスコアは、生成した訳が期待する訳(リファレンス)のいずれかに近ければ高くなる。&lt;/p&gt;

&lt;p&gt;precisionは、生成した訳の単語のいくつが、リファレンスにも出現するかを示す。
これだと、例えば&lt;code&gt;the the the is the the&lt;/code&gt;みたいな訳で高い値(&lt;code&gt;6/6&lt;/code&gt;)をとれちゃう。
のでmodified precisionを代わりに使う。
modified precisionでは、それぞれの単語について、一つのリファレンスに最大何回出現するかをcreditと定義する。
で、&lt;code&gt;the&lt;/code&gt;のcreditが2、&lt;code&gt;is&lt;/code&gt;のcreditが1なら、上記訳のmodified precisionは&lt;code&gt;3/6&lt;/code&gt;になる。&lt;/p&gt;

&lt;p&gt;Bleuスコアは、Nグラム(N-Gram)についてmodified precisionを計算する。
あるN-Gramについてのmodified precisionをPn、N-Gramの数をNとすると、Bleuスコアは&lt;code&gt;exp((ΣPn)/N) * BP&lt;/code&gt;。
BPはbrevity penaltyで、短い訳で高いスコアを簡単に取れないようにするためのもの。
出力長がリファレンス長より長ければ1で、そうでなければ&lt;code&gt;exp(1 - 出力長 / リファレンス長)&lt;/code&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Attentionモデル&lt;/p&gt;

&lt;p&gt;Seq2Seqを改良したもの。&lt;/p&gt;

&lt;p&gt;長い文の場合でも、Seq2Seqは原文を全部読んで、それをactivationに記憶して、そこから翻訳を出力する。
けど人が翻訳するときは、短い文や節に区切って出力していく。
実際、長い原文を記憶するのは難しく、原文の単語数が増えていくにしたがってSeq2Seqは性能が落ちる。
Attentionモデルは人と同様な翻訳の仕方をするので、原文の単語数が増えても性能を保てる。&lt;/p&gt;

&lt;p&gt;Attentionモデルでは、エンコーダはBRNN。
で、エンコーダはデコーダに対し、t番目の出力に際してどの入力単語に注目すべきかという重みづけαから生成するコンテクストcを入力する。
エンコーダの順方向と逆方向のアクティベーションを結合したものをaとすると、&lt;code&gt;c = Σαa&lt;/code&gt;。
デコーダはそのcと、1ステップ前のアクティベーションsを使って一単語を出力する。
1ステップ前のsとaを小さいシンプルなNNにいれて入力単語ごとに計算したeを、入力単語に渡って足すと1になるようにスケールしたものがα。&lt;/p&gt;

&lt;p&gt;Attentionモデルは、画像を読んで説明文を出力するときにも使われる。
説明文は画像の特定の箇所に注目した説明の集まりなので。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;音声認識(Speech recognition)&lt;/p&gt;

&lt;p&gt;Seq2Seqモデルで、音声データを読んで字幕を出力する。
従来、音声を音素(Phoneme)に分解して処理していたが、深層学習ではその必要が無い。
但し300～100000時間くらいの音声データが要る。&lt;/p&gt;

&lt;p&gt;普通に音声データをエンコーダに時系列に従って入力してデコーダに文字を出力させてもいいけど、それだと、入力データのステップ数は出力ステップ数よりはるかに大きくなっちゃう。
ので、CTC(Connectionist temporal classification)モデルは、RNNに入力と同じだけ出力をさせて、その出力を圧縮して最終的な字幕を生成する。
例えば&lt;code&gt;the&lt;/code&gt;について、&lt;code&gt;ttt_h_eee___&lt;/code&gt;みたいな出力をさせる。
&lt;code&gt;_&lt;/code&gt;はブランクという特殊な出力で、単語の切れ目のスペースとはまた別のもの。&lt;/p&gt;

&lt;p&gt;「OK Google」みたいなトリガーワードを識別するシステムに使うアルゴリズムはまだ発展途上で、これといったものはない。
例えば、トリガーワードを含む音声を入力して、トリガーワードの終わりの部分の出力を1、それ以外を0として学習させる方法がある。
終わりの瞬間だけ1にすると0ばっかりになっちゃうので、終わりから一定時間1にする。
トリガーワードを聞いた瞬間に検知するようにしたいので、BRNNじゃなくて単方向のRNNを使う。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Kerasで日付を特定のフォーマットに変換するAttentionモデルを作る。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;トリガーワード検知システムを作る。&lt;/p&gt;

&lt;p&gt;トリガーワードとそれ以外の言葉とノイズを別々に録音して、合成してラベルを付けて訓練データを作る。
で、Kerasで1D畳み込み層がひとつ、GRUが2層のDeep RNNモデルを作って学習させる。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CourseraのDeep Learning SpecializationのConvolutional Neural Networksコースを修了した</title>
          <link>https://www.kaitoy.xyz/2018/02/06/coursera-deep-learning-convolutional-neural-networks/</link>
          <pubDate>Tue, 06 Feb 2018 00:37:11 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/02/06/coursera-deep-learning-convolutional-neural-networks/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/01/16/coursera-deep-learning-ml-strategy/&#34;&gt;CourseraのDeep Learning SpecializationのStructuring Machine Learning Projectsコースを修了した&lt;/a&gt;のに続き、&lt;a href=&#34;https://www.coursera.org/learn/convolutional-neural-networks&#34;&gt;Convolutional Neural Networksコース&lt;/a&gt;を修了した。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;このコースは、CNNの原理、代表的なアーキテクチャ、応用などについて学べる4週間のコース。
動画は今のところ全部英語。
プログラミング課題は初のKeras。&lt;/p&gt;

&lt;p&gt;このコースは結構難しくて、特に3週目と4週目は理解に苦しんだ。
というか理解しきれなかったような。
けどNST面白かった。&lt;/p&gt;

&lt;p&gt;2018/1/16に始めて、2/6に完了。
22日間かかった。
修了したらまた&lt;a href=&#34;https://www.coursera.org/account/accomplishments/certificate/MVNK5ZA5CDKA&#34;&gt;Certifacate&lt;/a&gt;もらえた。&lt;/p&gt;

&lt;p&gt;以下、4週分の内容をメモ程度に書いておく。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;p&gt;畳み込みニューラルネットワーク(CNN: Convolutional neural network)の基本。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;畳み込み計算&lt;/p&gt;

&lt;p&gt;画像認識でよく使われるNNのアーキテクチャ。&lt;/p&gt;

&lt;p&gt;低層ではエッジを検出し、層が進むにつれて複雑な特徴を学習する。&lt;/p&gt;

&lt;p&gt;画像を特定の行列(普通は奇数の正方行列。3×3が多い。)で畳み込むことで、特定の方向のエッジを検出できる。
この行列をフィルタ(filter)という。カーネルと呼ばれることもある。
例えば縦なら以下。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[[1, 0, -1],
 [1, 0, -1],
 [1, 0, -1]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;縦でもいろいろフィルタはあって、以下はSobelフィルタというもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[[1, 0, -1],
 [2, 0, -2],
 [1, 0, -1]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下はScharrフィルタ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[[ 3, 0,  -3],
 [10, 0, -10],
 [ 3, 0,  -3]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;縦のフィルタを90度回転すると横のフィルタになる。&lt;/p&gt;

&lt;p&gt;深層学習では、フィルタもパラメータとして学習させる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;パディング(Padding)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;n×n&lt;/code&gt;の行列を&lt;code&gt;f×f&lt;/code&gt;のフィルタで畳み込むと&lt;code&gt;n-f+1×n-f+1&lt;/code&gt;の行列になる。
つまり畳み込めば畳み込むほど画像が小さくなってしまう。
また、画像の端のほうはフィルタにかかる割合が小さいので、情報量が小さくなってしまう。
これらを解決するテクニックがパディング(Padding)。
行列の周囲を0でパディングして、サイズを大きくしてから畳み込む。
パディングがないのをValidな畳み込み、出力が入力と同じサイズになるようにパディングするのをSameな畳み込みという。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Strided畳み込み&lt;/p&gt;

&lt;p&gt;畳み込むときにフィルタをずらす幅を1より大きくする。
パディングサイズがpでストライドがsのとき、&lt;code&gt;n×n&lt;/code&gt;の行列を&lt;code&gt;f×f&lt;/code&gt;のフィルタで畳み込むと&lt;code&gt;(n+2p-f)/s+1×(n+2p-f)/s+1&lt;/code&gt;の行列になる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;3次元(カラー画像)の畳み込み&lt;/p&gt;

&lt;p&gt;カラー画像は3次元の行列、つまり&lt;code&gt;n×n×c&lt;/code&gt;の行列で、それを畳み込むのは&lt;code&gt;f×f×c&lt;/code&gt;のフィルタで、出力は&lt;code&gt;n-f+1×n-f+1&lt;/code&gt;の行列になる。
チャネルごとにフィルタを設定して、色ごとにエッジ検出できる。
フィルタごとの出力は全部スタックして、最終的な出力は3次元になる。&lt;/p&gt;

&lt;p&gt;畳み込み層はフィルタの要素数がパラメータ数になる。
入力画像の大きさに依存しないので、パラメータ数が少なくて済み、過学習しにくい。&lt;/p&gt;

&lt;p&gt;入力を複数の畳み込み層に通したら、最終的に3次元の出力をなべてベクトルにして、後ろの層に渡す。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プーリング層(Pooling layer)&lt;/p&gt;

&lt;p&gt;計算量を減らすため、また特徴の抽出のために、畳み込み層のあとに使われる層。
基本Max poolingが使われるけど、Average poolingというのもある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Max pooling: フィルタをかけた部分を畳み込む代わりに、最大値を出力とする。大きな値が特徴が大きく出ているところだから、特徴を凝縮するイメージだけど、経験的にこれで上手くいくことが分かっているだけで、なぜ上手くいくかは判明していない。この層はパラメータを持たない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Average pooling: フィルタをかけた部分を畳み込む代わりに、平均を出力とする。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;プーリング層のフィルタは大抵、サイズが&lt;code&gt;2×2&lt;/code&gt;でパディングが0でストライドは2。&lt;/p&gt;

&lt;p&gt;普通、畳み込み層とプーリング層とセットで1層と数える。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;全結合層(Fully connected layer)&lt;/p&gt;

&lt;p&gt;全ノードがメッシュ状につながった普通の層。
畳み込み層とプーリング層のセットがいくつかあって、その出力をベクトルになべて、全結合層につなぐ。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;一般的なCNN&lt;/p&gt;

&lt;p&gt;畳み込み層は、普通nhとnwを縮め、ncを増やす。
また、全体として、層が浅くなるほど出力が減るのが多い。&lt;/p&gt;

&lt;p&gt;CNNはハイパーパラメータが多すぎるので、アーキテクチャは自分で考えるんではなく、論文呼んで自分の問題に合いそうなのを探すべし。&lt;/p&gt;

&lt;p&gt;畳み込み層は全結合層に比べてパラメータ数がかなり少なくて済むのがいいところ。
これはパラメーター共有(Parameter sharing)という、画像のある個所で上手く動いたフィルタ(e.g. 縦エッジ検出器)は、その画像の他の箇所でも上手く働くという考え方がベース。&lt;/p&gt;

&lt;p&gt;また、層間の接続がまばらなのもパラメータを減らす要因。
つまり出力のあるピクセルは、入力のうちフィルタ分のサイズのピクセルとしか関連していない。&lt;/p&gt;

&lt;p&gt;CNNは空間変化の不変性(Translation invariance)に強い。
つまり画像の中の物体の位置が変わってもよく検出できる。
これは同じフィルタを画像全体に適用するから。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;p&gt;CNNの順伝播をNumPyで実装。&lt;/p&gt;

&lt;p&gt;CNNによる画像の分類をTensorFlowで実装。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ケーススタディ&lt;/p&gt;

&lt;p&gt;畳み込み層とかプーリング層をどう組み合わせるといいかは、事例を見ていくことで雰囲気をつかめる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;古いやつ&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;LeNet-5&lt;/p&gt;

&lt;p&gt;1980年代にできたふるいやつ。
モノクロ画像(32×32)の手書き数字認識。&lt;/p&gt;

&lt;p&gt;当時はソフトマックスもReLUもなかった。
けど、畳み込み層とプーリング層のセットを繰り返して入力をチャネル方向に引き伸ばし、全結合層に流し込むアーキテクチャは、モダンなCNNにも通じる。&lt;/p&gt;

&lt;p&gt;5層(内2層が全結合層)の浅いネットワークで、比較的パラメータが少なく、6万個くらい。
モダンなのだとこの1000倍くらいあるのが普通。&lt;/p&gt;

&lt;p&gt;LeNet-5は、チャネルごとに違うフィルタを使っているが、今日では普通同じのを使う。&lt;/p&gt;

&lt;p&gt;また、プーリング層のあとに活性化関数(シグモイド)かけてるのも特殊。
(モダンなアーキテクチャではプーリング層の前にかける?)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;AlexNet&lt;/p&gt;

&lt;p&gt;227×227×3のカラー画像
8層(内3層が全結合層)でパラメータは6千万個くらい。
活性化関数にReLU。&lt;/p&gt;

&lt;p&gt;Local Response Normalizationという正規化層がある。
昨今ではあまり使われない。&lt;/p&gt;

&lt;p&gt;論文が比較的読みやすい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;VGG-16&lt;/p&gt;

&lt;p&gt;2014年に発表。&lt;/p&gt;

&lt;p&gt;各層に同じフィルタを使い、フィルタ数も線形増加させるシンプルなアーキテクチャ。
16層(内2層が全結合層)で、1億3800万個のパラメータ。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;モダンなやつ&lt;/p&gt;

&lt;p&gt;理論的にはネットワークを深くすると精度が高くなるけど、現実的にそうはいかない。
深いネットワークは勾配消失や勾配爆発で訓練しにくいので。
モダンなアーキテクチャはこの問題に対応。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ResNet(Residual Network)&lt;/p&gt;

&lt;p&gt;残差ブロック(Residual block)を持つ。
このブロックでは、浅い層からの出力を深い層のReLUの入力に足し合わせる。
この深い層からの依存はショートカット(short cut)とかskip connectionとか呼ばれる。&lt;/p&gt;

&lt;p&gt;ショートカットのおかげで深い層の学習が効率的になり、層を152まで深くできた。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Network in Network&lt;/p&gt;

&lt;p&gt;畳み込み層に1×1のフィルタを使う。
1×1畳み込み(one by one convolution)、またはNetwork in Networkと呼ばれる。&lt;/p&gt;

&lt;p&gt;これを使うと、入力のhとwを変えずに、チャネル数を減らして計算量を減らしたり、非線形性を追加することができる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Inception Network (GoogleNet)&lt;/p&gt;

&lt;p&gt;フィルタのサイズや畳み込みかプーリングかを考えるのが難しいので、1層内で複数のフィルタサイズで畳み込みやプーリングして、スタックしたものを出力する手法がある。
これをする部分をInception moduleという。
計算コストが大きくなるので、最初に1×1畳み込みで圧縮してからその後の畳み込みをする。
1×1畳み込みの部分でデータがいったん小さくなるので、そこをボトルネック層(Bottleneck layer)と呼ぶ。&lt;/p&gt;

&lt;p&gt;ボトルネック層によって、精度に影響が出ることはない。&lt;/p&gt;

&lt;p&gt;Inception moduleを組み合わせたネットワークをInception Networkという。
Inception Networkの例の一つがGoogLeNet。
GoogLeNetは中間層から全結合層・ソフトマックス層につなげる支流をもっていて、中間層まででうまく学習できているかを見れて、過学習を防げるようになっている。&lt;/p&gt;

&lt;p&gt;因みにInceptionという名前は映画のInceptionから来ている。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;実践&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;既存の実装の利用&lt;/p&gt;

&lt;p&gt;モダンなCNNは複雑すぎて、エキスパートが論文を読み込んでも再現することが難しい。
が、普通は論文の著者がOSSで実装を公開するのでそれを使ったりベースにしたりすべし。&lt;/p&gt;

&lt;p&gt;学習済みのモデルもあることがあるので、転移学習にも使える。
ソフトマックス層だけ入れ替えて、そこのWだけ学習させて自分の問題に使うなど。
色んな深層学習フレームワークが転移学習をサポートしてる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;データ合成(Data augmentation)&lt;/p&gt;

&lt;p&gt;画像認識の分野では基本的にデータが沢山要るけどデータが手に入りにくい。
ので合成するのが効果的。&lt;/p&gt;

&lt;p&gt;左右判定とか、切り抜きとか、回したり、歪めたりとかは、有効だけどあんまりやられない。
若干編集が複雑なので。&lt;/p&gt;

&lt;p&gt;色相を変える(Color shifting)のがよくやられる。赤味を増やしたり。
色を選ぶときには主成分分析(PCA)が使える。(PCA Color Augmentation)&lt;/p&gt;

&lt;p&gt;一つのCPUスレッドに元画像のロードと合成をやらせて、別のスレッドで並列に学習を処理するのが一般的な実装。&lt;/p&gt;

&lt;p&gt;データ合成するにも、どの程度変化させるかというハイパーパラメータが付きまとうので、既存の実装やアイデアを使うのがいい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;画像認識の現状&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;データ vs hand engineering&lt;/p&gt;

&lt;p&gt;データが沢山ある分野の問題だと、でかいネットワークを適当に組んで学習させれば上手く解ける。
データがあんまりないと、色々工夫(hand engineering)が必要になってくる。
特徴量を選んだり、アーキテクチャを工夫したり。
例えば物体検知は画像認識よりかなりデータが少ない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ベンチマークやコンペで上手くやるコツ&lt;/p&gt;

&lt;p&gt;研究者は、論文を通しやすくするため、ベンチマークやコンペのデータに対して頑張る。
ベンチマークに対して上手くやるコツ:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;アンサンブル(Ensembling)&lt;/p&gt;

&lt;p&gt;複数のNNを独立に訓練して、それらの出力の平均を使う。
1,2%の性能向上が見込める。
けど計算コストが高いので、普通プロダクションでは使わない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Multi-crop at test time&lt;/p&gt;

&lt;p&gt;テスト時にテストデータを色んな感じに切り抜いて、それらに対する予測値を平均する。
10-crop。
アンサンブルに比べ、訓練時の計算コストが少ないし、予測時に1つのモデルを保持すればいいのでメモリ使用量が少ない。
若干の性能向上が見込め、プロダクションでも使われることがある。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;オープンソースコードの利用&lt;/p&gt;

&lt;p&gt;だれかが考えたアーキテクチャを使え。&lt;/p&gt;

&lt;p&gt;OSS実装を使え。&lt;/p&gt;

&lt;p&gt;なんなら訓練済みモデルを使え。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Kerasのチュートリアル&lt;/p&gt;

&lt;p&gt;というほど解説してくれるわけではないけど。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kerasで50層のResNetを実装&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;3週目&lt;/p&gt;

&lt;p&gt;物体認識(Object detection)。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;位置特定(Localization)&lt;/p&gt;

&lt;p&gt;画像を与えられて単にラベルを付けるのは分類。
ラベルの物体の位置を示すのが位置特定。
分類したあとさらに位置特定したい。&lt;/p&gt;

&lt;p&gt;分類する画像は、普通一つの画像の中に一つの物体が大きく映っている。
一方、物体認識は、一つの画像の中に複数の物体があったりする、もう少し複雑な問題。&lt;/p&gt;

&lt;p&gt;位置特定するには、ソフトマックス層に、クラス以外に4つの出力をさせる。
すなわち物体の中心点のx座標、y座標、それと物体を囲む枠の高さ、幅。
それぞれ0～1の値で、画像全体に対する割合を示す。&lt;/p&gt;

&lt;p&gt;また、物体があるかないかという予測値Pcも出力する。
この予測値が0のときは、損失関数でそれいがいの出力を計算に入れない。&lt;/p&gt;

&lt;p&gt;より一般的には、物体の位置を示す任意の数のランドマーク(Landmark)の座標を出力させる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;物体認識&lt;/p&gt;

&lt;p&gt;スライディングウィンドウ認識(Sliding windows detection)する。
すなわち、小さい枠をずらしながら画像の切り抜きをたくさん作って、それぞれ分類する。
ウィンドウサイズを変えてもやる。
計算コストがかかる。&lt;/p&gt;

&lt;p&gt;のでCNNでやる。&lt;/p&gt;

&lt;p&gt;まず、全結合層は、数学的に等価な畳み込み層で置き換えられる。
5×5×16の入力を受け取って、5×5の400個のフィルタで畳み込むと、
1×1×400の出力が得られ、これは400ノードの全結合層と一緒。
最後に1×1の4個のフィルタで畳み込むと、4つの出力をするソフトマックス層みたいになる。
こういう、全部畳み込み層のNNをFCN(Fully Convolutional Networks)という。&lt;/p&gt;

&lt;p&gt;で、入力のサイズ(高さと幅)を広げてやると、中間層と出力もちょっと広がる。
このCNNは、入力の一部を5×5のウィンドウで切り抜いた部分の分類結果が、出力の1ピクセルに対応するようなものになる。
なので一回CNNに通せば、一回の計算でスライディングウィンドウできる。&lt;/p&gt;

&lt;p&gt;けどこれは、物体を囲む枠が正確でないという欠点がある。
実際は長方形であるべきだったりするので。
これを解決するのがYOLO(You Only Look Once)アルゴリズム。&lt;/p&gt;

&lt;p&gt;YOLOでは、まず入力画像をグリッド状に分割して、それぞれについて分類と位置特定する。
複数のセルに物体がまたがっている場合は、物体の中心があるセルだけにあるものとする。
それぞれのセルの出力をスタックして、3次元の出力にする。
つまり、グリッドが3×3なら、3×3×(もとのyベクトルの次元)とする。
(普通はもっと細かいグリッドにする。)
で、CNNをこういう形の出力をするように組む。&lt;/p&gt;

&lt;p&gt;YOLOの論文はかなりむずい。&lt;/p&gt;

&lt;p&gt;位置特定の評価をするのに、IoU(Intersection over Union)という指標がある。
これは、2つの領域の重なり具合を示すもので、2つの領域が重なった部分の面積を、2つの領域全体の面積で割った値。
モデルが特定した枠と期待する枠とで、IoUが0.5以上だとよしとすることが多い。&lt;/p&gt;

&lt;p&gt;YOLOを使うと、複数のセルで同じ物体を認識してしまうことが多い。
これを一つに絞るのがNMS(Non-max suppression)。
ざっくり言うと、それぞれのセルの確度(Pc)を見て、一番でかいの以外を無効化する。&lt;/p&gt;

&lt;p&gt;詳しく言うとまず、Pcがある閾値(e.g.0.6)以下のものを無効化する。
で、残ったものの中から、最大のPcを選び、それとおおきくかぶっている枠(IoUが0.5以上など)を無効化する。
で、また残ったのものの中から最大のPcを選び、同じことを繰り返していく。
クラスが複数あったら、これをクラスごとにやる。&lt;/p&gt;

&lt;p&gt;一つのセルに複数の物体があったらどうか。
境界ボックス(Anchor box)を使う。
事前に複数の形の枠(境界ボックス)を用意しておいて、それぞれについての予測を出力ベクトルに並べる。
で、一番IoUが高い境界ボックスを採用する。&lt;/p&gt;

&lt;p&gt;境界ボックスは手動で作ったり、k平均法で作ったりする。&lt;/p&gt;

&lt;p&gt;スライディングウィンドウは、明らかに何もない部分の計算もしちゃうのでちょっと無駄。
なので、そういう部分はスキップしようというのがR-CNN(Regions with CNN)。
これはRegion proposalsとCNNを組み合わせたもの。
Region proposalsは、セグメンテーション(Segmentation)アルゴリズムで画像をざっくり区分けして、それっぽい部分を処理対象にするもの。&lt;/p&gt;

&lt;p&gt;R-CNNはすごく遅いので、あまり使われていないし、Andrew先生も好んで使わない。
Fast R-CNN、Faster R-CNNってのもあるけど、まだ遅い。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;KerasでYOLOv2モデルを実装。&lt;/p&gt;

&lt;p&gt;CNN部分は訓練済みのモデルを使って、出力をフィルタリングする部分を作る。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;4週目&lt;/p&gt;

&lt;p&gt;顔認識(Face recognition)とNeural style transfer。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;顔認識&lt;/p&gt;

&lt;p&gt;顔認証(Face authentication)には、顔認識と、生きた人間かの判定(Liveness detection)が要るけど、前者を主に学ぶ。&lt;/p&gt;

&lt;p&gt;顔認識は顔検証(Face verification)の難しい版。
後者は顔画像と名前を与えて、正しい組み合わせかを判定する。
前者は顔画像を与えて、DBからその人を探す。&lt;/p&gt;

&lt;p&gt;顔認識は一般的に、One-shot learning問題に対応する必要がある。
つまり一つの訓練データから学習しないといけない。
DBに一人のひとについて何個も画像があるというケースは少ない。&lt;/p&gt;

&lt;p&gt;CNNに顔画像を入力して、ソフトマックス層で分類するのは、訓練データが少なすぎるのでうまくいかない。
代わりに類似関数(Similarity function)を学習する。
つまり、二つの画像を入力として、異なる度合いを出力するもの。
で、その出力が閾値以下だったら同一人物と判定する。
これをDBに入っている画像それぞれについてやる。&lt;/p&gt;

&lt;p&gt;類似関数にはシャム(Siamese)ネットワークをつかう。&lt;/p&gt;

&lt;p&gt;CNNの最後の全結合層の出力ベクトルは、入力画像をエンコードしたものだと考えられる。
二つの画像を、別々に同じCNNにいれて、二つの出力ベクトルを得たら、それらのユークリッド距離の二乗を差として出力する。
これがシャムネットワーク。
二つの画像が同一人物ならユークリッド距離が小さくなるように、違うなら大きくなるように訓練する。&lt;/p&gt;

&lt;p&gt;損失関数にはTriplet loss関数を使う。
同一人物を比較するとき、Anchor画像とPositive画像の比較、違う人物の比較はAnchor画像とNegative画像の比較と呼ぶ。
AnchorとPositiveのユークリッド距離がAnchorとNegativeのユークリッド距離以下になってほしい。
つまり前者マイナス後者がゼロ以下になって欲しい。
ただこれだと、CNNが全ての画像について同じ出力をするように学習してしまうかもしれないので、&lt;code&gt;0-α&lt;/code&gt;以下になるように訓練する。
αはマージンと呼ばれるハイパーパラメータ。&lt;/p&gt;

&lt;p&gt;AnchorとPositiveとNegativeの一組をTripletと呼ぶ。
Negativeをランダムに選ぶと、全然違う顔の組み合わせが多くなって、類似関数があまり学習しない。
ので、似てるひとを組み合わせたTripletを多く作ってやると効率よく学習する。&lt;/p&gt;

&lt;p&gt;シャムネットワークの二つの出力ベクトルをロジスティック回帰ユニットに入れて、同一人物か否かの二値分類する方法もある。
ベクトル間の距離も、ユークリッド距離の他、カイ二乗値(χ square similarity)ってのもある。&lt;/p&gt;

&lt;p&gt;DBには、顔画像そのものよりも、エンコードしたベクトルを入れておくと計算量を省けるし、DBサイズも抑えられる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ニューラル画風変換(NST: Neural style transfer)&lt;/p&gt;

&lt;p&gt;Content画像&amp;copy;とStyle画像(S)から、あらたな画像(G)を生成するCNN。
(CNNは別途訓練済みのものを使うので、転移学習の一種。)&lt;/p&gt;

&lt;p&gt;CNNの可視化ができる。
画像の一部を入力して、ある層の一つのユニットの出力が最大になるものを選んで集めると、そのユニットがどのような特徴を抽出しているかがわかる。
深い層ほど広い範囲を見て、複雑なパターンを学ぶ。&lt;/p&gt;

&lt;p&gt;コスト関数&lt;code&gt;J(G)&lt;/code&gt;を最小化する。
&lt;code&gt;J(G)&lt;/code&gt;はコンテントコスト&lt;code&gt;Jcontent(C, G)×α&lt;/code&gt;とスタイルコスト&lt;code&gt;Jstyle(S, G)×β&lt;/code&gt;の和。
前者はCとGの類似関数で、後者はSとGの類似関数。
αとβはハイパーパラメータ。
Gをランダムに初期化して、最急降下法でGを調整していく。&lt;/p&gt;

&lt;p&gt;訓練済みのCNN(VGGなど)を使って、中間層lを選ぶ。
Cを入力してlから出てきた値と、Gを入力してlから出てきた値が似てたら、CとGを似ているとする。
つまりそれらをベクトルにアンロールしたものの二乗誤差が&lt;code&gt;Jcontent(C, G)&lt;/code&gt;。
lが浅ければ浅いほど、CとGは似たものになる。&lt;/p&gt;

&lt;p&gt;スタイルは、ある層lの出力のx座標とy座標の各点について、チャネル間で値の関連性を見る。
あるチャネルのあるニューロンが縦縞を検出していて、ほかのチャネルのあるニューロンがオレンジ色を検出していたとしたら、画像にオレンジの縦縞がよく現れるなら両者は関連が高く、そうでなければ低い。
SとGとの間でこの関連性が似てれば、スタイルが似ていると言える。&lt;/p&gt;

&lt;p&gt;スタイル行列(Style matrix)で表す。
ある層のスタイル行列は&lt;code&gt;nc×nc&lt;/code&gt;で、チャネル間の関連度を表す。
行列の一つの値は、二つのチャネルの各アクティベーションの掛け合わせものの合計。
関連性が強いとこの掛け合わせは大きくなる。
(対角成分は同じチャネル同士の積になって、そのスタイルがどれだけ全体的に出ているかを示す。)
この行列は代数学ではグラム行列(Gram matrix)と呼ばれる。&lt;/p&gt;

&lt;p&gt;このスタイル行列をSとGで計算して、それらの二乗誤差をl層のスタイルコストとする。
で、これにハイパーパラメータλlをかけたものを層ごとに計算して、足し合わせたものを全体のスタイルコストとする。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2D以外の画像の処理&lt;/p&gt;

&lt;p&gt;心電図のデータとかの1Dデータや、CTスキャンみたいな3Dデータでも、それに合わせた次元のフィルタを使えば畳み込める。
1DデータはRNNでもできるけど、CNNでもできて、それぞれメリットデメリットがある。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;TensorFlowでニューラル画風変換を実装&lt;/p&gt;

&lt;p&gt;VGG-19をImageNetのデータで訓練したものを使う。
ルーブル美術館の写真をContent画像に、モネの絵をStyle画像に使って画像を生成。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kerasで顔認識モデルを実装&lt;/p&gt;

&lt;p&gt;現時点でtriplet_lossの採点にバグがある。
対策はフォーラム参照。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CourseraのDeep Learning SpecializationのStructuring Machine Learning Projectsコースを修了した</title>
          <link>https://www.kaitoy.xyz/2018/01/16/coursera-deep-learning-ml-strategy/</link>
          <pubDate>Tue, 16 Jan 2018 07:56:43 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/01/16/coursera-deep-learning-ml-strategy/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/01/12/coursera-deep-learning-improving-deep-neural-networks/&#34;&gt;CourseraのDeep Learning SpecializationのImproving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimizationコースを修了した&lt;/a&gt;のに続き、&lt;a href=&#34;https://www.coursera.org/learn/machine-learning-projects&#34;&gt;Structuring Machine Learning Projectsコース&lt;/a&gt;を修了した。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;このコースは、深層学習プロジェクトの進め方のコツや問題への対処方法などについて学べる2週間のコース。
今回はプログラミング課題がない。
動画は今のところ全部英語。&lt;/p&gt;

&lt;p&gt;ちょっと動画編集ミスが多かった。
同じことを二回言ったり、無音無絵の時間があったり、マイクテストしてたり。&lt;/p&gt;

&lt;p&gt;2018/1/13に始めて、1/15に完了。
3日間かかった。
修了したらまた&lt;a href=&#34;https://www.coursera.org/account/accomplishments/certificate/7MHFMLHP67C4&#34;&gt;Certifacate&lt;/a&gt;もらえた。&lt;/p&gt;

&lt;p&gt;以下、2週分の内容をメモ程度に書いておく。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;p&gt;モデルの改善をするのに、データを増やしたりハイパーパラメータを変えたり色々な手法がある。
一つを試すのに下手すると数か月とかかかるので、効率よく手法の取捨選択し、モデルを改善していくための戦略について学ぶ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;直交化(Orthogonalization)&lt;/p&gt;

&lt;p&gt;一つの要素で複数の制御をしようとすると難しいので、一つの制御だけするようにする。
具体的には、以下のことを別々に扱う。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;訓練データに目標の精度までフィットさせる。&lt;/li&gt;
&lt;li&gt;devデータに目標の精度までフィットさせる。&lt;/li&gt;
&lt;li&gt;テストデータに目標の精度までフィットさせる。&lt;/li&gt;
&lt;li&gt;現実のデータでうまく動くようにする。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;それぞれの目的について、チューニングすべき要素は別々になる。&lt;/p&gt;

&lt;p&gt;早期終了は直行化の原則に反しているので、ほかの方法があるならそっちをやったほうがいい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;指標(Goal)の設定&lt;/p&gt;

&lt;p&gt;モデルの改善はイテレーティブなプロセスなので、サイクルを速く回したい。
そのため、モデルを評価する単一の数値があるといい。
F1スコアとか。平均とか&lt;/p&gt;

&lt;p&gt;単一の指標にまとめるのがむずいときもある。
精度と速さとか。
そんなときは一つ以外の指標を足切りだけに使う。
ある閾値以上の速さが出てるもののなかで精度をくらべるなど。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;データの分け方&lt;/p&gt;

&lt;p&gt;devデータとテストデータの分布(と評価指標)は同じ感じにしないといけない。
そのために、いったん全データをシャッフルしてから分割する。
訓練データの分布は異なってても問題ない。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;訓練:テスト = 70:30&lt;/code&gt;とか、&lt;code&gt;訓練:dev:テスト = 60:20:20&lt;/code&gt;とかいう比率は、1万くらいのデータなら適当。
けど100万くらいなら、98:1:1くらいが妥当。&lt;/p&gt;

&lt;p&gt;テストデータはモデルの最終評価をするためのものなので、どれだけ評価したいかによってサイズを変える。
0もありがちだけど、非推奨。&lt;/p&gt;

&lt;p&gt;猫の画像のなかにエロ画像が混じっちゃうようなモデルはだめ。
猫判定率が多少下がっても、エロ画像が含まれないほうがまし。
こういう場合は評価指標を変える必要がある。
エロ画像を猫と判定した場合にペナルティを大きくするなど。&lt;/p&gt;

&lt;p&gt;直行化の観点で言うと、指標を決めるのと、その指標に従って最適化するのは、別のタスクとして扱うべき。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;人並性能(Human-level performance)との比較&lt;/p&gt;

&lt;p&gt;人並性能とは、人が手動で達成できる精度。そのエラー率、つまり人並誤差(Human-level error)はベイズ誤差(Bayes optimal error)に近い。&lt;/p&gt;

&lt;p&gt;モデルを改良していくと、人並性能を超え、その後改善速度は鈍化し、人並誤差はベイズ誤差に漸近していく。
鈍化する理由は、人並性能がベイズ誤差に近いのと、人以上の精度に人がチューニングするのが無理があるから。
人手でラベル付きデータを作れないし、エラー分析もできなくなるので。&lt;/p&gt;

&lt;p&gt;人並誤差より訓練データでのエラー率が結構高いなら、高バイアス対策をする。
人並誤差と訓練データでのエラー率が近くて、devデータでのエラー率が結構高いなら、高バリアンス対策をする。
人並誤差と訓練データでのエラー率との差ををAndrew先生は可避バイアス(Avoidable bias)と名付けた。&lt;/p&gt;

&lt;p&gt;人並誤差はベイズ誤差の近似として使える。
人並誤差は、ある判別問題に関して、その道のエキスパート達が議論して解を出すみたいな、人類が全力を尽くしたうえでの誤差とする。
人並誤差が分かれば、訓練データとdevデータのエラー率を見て、高バイアスか高バリアンス化を判別できる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;モデルの性能改善手順&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;訓練データにフィットさせ、可避バイアスを最小化する。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;モデルを大きくする。&lt;/li&gt;
&lt;li&gt;最適化アルゴリズムを高度なものにするか、長く訓練する。&lt;/li&gt;
&lt;li&gt;NNのレイヤを深くしたり隠れ層のノードを増やしたり、CNNとかRNNとかの高度なアーキテクチャにする。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;dev・テストデータで評価し、バリアンスを下げる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;データを増やす。&lt;/li&gt;
&lt;li&gt;正則化する。&lt;/li&gt;
&lt;li&gt;ハイパーパラメータをいじる。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Andrej Karpathyへのインタビュー&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;エラー分析&lt;/p&gt;

&lt;p&gt;エラー率が高いときに、エラーが起きたdevデータのサンプルを見て原因を分析する。
天井分析(Ceiling analysis)も併せてやる。
例えば、猫判定器で、犬を猫と判定したサンプルがあったとして、犬の問題に取り組むかどうかは、全体のエラーサンプル数に対する犬のエラーサンプル数の割合を見て、その取り組みで最大どれだけの効果を得るかを分析する。&lt;/p&gt;

&lt;p&gt;天井分析を複数の問題点に対してやれば、どれに時間をかける価値があるかの指標を得られる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ラベリングミスへの対処&lt;/p&gt;

&lt;p&gt;ディープラーニングは、ランダムエラーに対して堅牢で、訓練データに多少のラベリングミスがあっても問題なく動く。&lt;/p&gt;

&lt;p&gt;devデータにミスがあった場合、エラー分析の際にそれも数えておいて、対処すべきかどうかを判断する。
他の問題によるエラーの割合と比べて、ラベリングミスによるものの割合が大きければ対処すればいいし、そうでなければほっておく。
また、エラー全体に対するラベリングミスの割合が大きくなると、モデルの性能比較に支障が出てくるので、そうなったらラベリングミスに対処する必要が高まってくる。&lt;/p&gt;

&lt;p&gt;devデータのラベリングミスを直すときは、テストデータも同時に直し、分布に違いが出ないようにする。
また、エラーなサンプルだけじゃなく、正答したサンプルも見直すべし。
けど、訓練データは直さなくてもいい。数も多いし、devデータと分布が違っていても問題ないし。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;新しいディープラーニングシステムを作るときのガイドライン&lt;/p&gt;

&lt;p&gt;あまり経験のない分野のシステムを新たに作るなら、早く立ち上げてイテレーションを回すべし。
具体的には、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;dev・テストデータと、指標を用意する。&lt;/li&gt;
&lt;li&gt;さっさとシステムを実装する。&lt;/li&gt;
&lt;li&gt;バイアス/バリアンス分析やエラー分析をして、次のアクションを決める。&lt;/li&gt;
&lt;li&gt;システムを改善する。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;というのを速く回す。
経験が深かったり、確かな研究結果がすでにあったりするなら、最初から凝ったシステムにしてもいい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;訓練データとdev・テストデータの分布のミスマッチ&lt;/p&gt;

&lt;p&gt;ディープラーニングでは訓練データは大抵不足するから、現実的に、訓練データはいろんなデータのかき集めで、dev・テストデータとは分布が異なってくる。&lt;/p&gt;

&lt;p&gt;例えば、実際のデータが10000個で、かき集めのが200000個あったら、全部合わせてシャッフルしてデータ分割するのは、dev・テストデータの質が悪くなるのでダメ。
dev・テストデータには実際のデータだけ使って、かき集めのは全部訓練データに使うべし。&lt;/p&gt;

&lt;p&gt;分布がミスマッチになると、バイアス/バリアンス分析がむずくなる。
devデータでエラーが増えても、単にdevデータのほうが判別が難しいデータなのかもしれない。&lt;/p&gt;

&lt;p&gt;分析をしやすくするため、訓練devデータを作る。
これは、訓練データと同じ分布のデータで訓練に使わないデータ。訓練データのサブセット。&lt;/p&gt;

&lt;p&gt;訓練データと訓練devデータのエラー率の差が大きければオーバーフィット。
訓練データと訓練devデータのエラー率の差が小さくて、devデータのエラー率が高いなら、データミスマッチ問題(Data missmatch problem)。&lt;/p&gt;

&lt;p&gt;あんまり発生しないけど、devデータよりテストデータのエラー率が結構大きいなら、devデータにオーバーフィットしてるので、devデータサイズを増やしたりする必要がある。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;データミスマッチ問題への対応&lt;/p&gt;

&lt;p&gt;データミスマッチ問題が発覚したら、訓練データをdevデータに近づけたり、devデータに近いものを訓練データに加えたりすることを考える。
例えば、車内の音声認識のためのモデルを開発していて、devデータに車の雑音が入っていることが分かったら、訓練データにそういう雑音を合成してやるなど。
ただし、その場合、同じ雑音をすべての訓練データに適用すると、その雑音にモデルがオーバーフィットするリスクがあるので注意。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;転移学習(Transfer learning)&lt;/p&gt;

&lt;p&gt;ある問題に対して作ったモデルを、別の問題に再利用する。
(但し入力は同種のデータ。画像なら画像、音声なら音声。)
その際、NNの、出力層だけのパラメータをランダム初期化したり、層を足したりして、あたらしい訓練データで学習させる。
新たな訓練データが少ない場合は、後ろの1,2層だけを再学習させ、データがたくさんあったら全体を再学習させる。&lt;/p&gt;

&lt;p&gt;最初の学習を事前学習(Pre-training)、新たなデータでの学習をファインチューニング(Fine tuning)という。
画像認識の分野でよく使われる。NNの浅い層のほうが、汎用的な特徴(エッジ検出など)を学習するので再利用できると考えられているが、詳しい原理は判明していない。&lt;/p&gt;

&lt;p&gt;事前学習するデータより、ファインチューニングに使えるデータが少ないときに効果的。
データ量が同じくらいだったり、後者のほうが多い場合は、最初から目的のデータで学習させたほうがいい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;マルチタスク学習(Multi-task learning)&lt;/p&gt;

&lt;p&gt;一度に複数の判別をさせるモデルをつくる。
ソフトマックス層つかった多クラス分類に似てるけど、一つのサンプルから複数のクラスを検出する。
例えば車と歩行者と標識など。
物体検知によく使われる。&lt;/p&gt;

&lt;p&gt;一つ一つのクラスのデータが少なくても低層が学んだ共通特徴を活用できるので、一つのタスクをするNNを複数訓練するより性能が良くなることがある。&lt;/p&gt;

&lt;p&gt;ラベルが歯抜けでも学習できる。&lt;/p&gt;

&lt;p&gt;複数タスクをこなすため、大き目なネットワークにする必要がある。&lt;/p&gt;

&lt;p&gt;それぞれのクラスのデータが十分あるときはあまり使われない手法。
目的のクラスのデータが少ないとき、転移学習のほうがよく使われる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;End-to-end学習&lt;/p&gt;

&lt;p&gt;従来、ある入力から解となる出力を得るのに、パイプラインで複数の処理をしていたが、これを全部一つのNNで処理する手法。
データ量が多いと上手くいく。&lt;/p&gt;

&lt;p&gt;例えば、人の認識をするときパイプラインでは、顔検出して、拡大してクロップしてからNNにかける。
こっちのほうが個々のタスクがシンプルで、それぞれのデータも手に入りやすいので性能を出しやすい。
けどもし、end-to-endのラベル付きデータが十分にあればend-to-end学習でもいける。&lt;/p&gt;

&lt;p&gt;翻訳タスクの場合、現実的に大量のデータが手に入るので、end-to-endで上手くいく。&lt;/p&gt;

&lt;p&gt;データさえたくさんあれば、パイプラインのコンポーネント的なところも勝手に学んでくれるので、ヒトが考え付くよりもいい特徴を学んでくれるかもしれない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Ruslan Salakhutdinovへのインタビュー&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CourseraのDeep Learning SpecializationのImproving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimizationコースを修了した</title>
          <link>https://www.kaitoy.xyz/2018/01/12/coursera-deep-learning-improving-deep-neural-networks/</link>
          <pubDate>Fri, 12 Jan 2018 23:41:57 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/01/12/coursera-deep-learning-improving-deep-neural-networks/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/01/05/coursera-deep-learning-neural-networks-and-deep-learning/&#34;&gt;CourseraのDeep Learning SpecializationのNeural Networks and Deep Learningコースを修了した&lt;/a&gt;のに続き、&lt;a href=&#34;https://www.coursera.org/learn/deep-neural-network&#34;&gt;Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimizationコース&lt;/a&gt;を修了した。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;このコースは、ディープニューラルネットワークのチューニングなどについて学べる3週間のコース。
今のところ全部英語。&lt;/p&gt;

&lt;p&gt;2018/1/5に始めて、1/12に完了。
8日間かかった。
修了したらまた&lt;a href=&#34;https://www.coursera.org/account/accomplishments/certificate/5VS9EJJ6TJ3A&#34;&gt;Certifacate&lt;/a&gt;もらえた。&lt;/p&gt;

&lt;p&gt;以下、3週分の内容をメモ程度に書いておく。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;p&gt;OverfittingやUnderfittingを防ぐテクニックについて。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;データ分割&lt;/p&gt;

&lt;p&gt;深層学習のモデル構築は、検討(Idea)、実装(Code)、検証(Experiment)というサイクルの繰り返し(Iterative process)。
取り組む課題、課題のドメイン、データ量、マシンの構成などにより、ハイパーパラメータは変わるので、経験をもって事前に予測することは無理なので、サイクルをどれだけ速く回せるかが鍵。&lt;/p&gt;

&lt;p&gt;データは、訓練データ(Training set)、Devデータ(Development set))(a.k.a. Cross-validation set)、テストデータ(Test set)に分割する。
訓練データで学習し、Devデータでハイパーパラメータを評価し、テストデータで最終的な評価と性能見積をする。
テストデータは無くてもいい。&lt;/p&gt;

&lt;p&gt;サンプル数が1万くらいだった時代は、6:2:2くらいで分割してたけど、近年は数百万とかのデータを扱い、交差検証データやテストデータの割合はもっと小さくするのがトレンド。
98:1:1など。&lt;/p&gt;

&lt;p&gt;Devデータとテストデータは同じようなものを使うべき。
訓練データは必ずしも同様でなくてもいい。訓練データは沢山要るので、別のデータソースからとることもある。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;バイアス vs バリアンス&lt;/p&gt;

&lt;p&gt;でかいネットワークで正則化して大量データで学習させるのが吉。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;正則化&lt;/p&gt;

&lt;p&gt;過学習(Overfitting)を防ぐため、コスト関数を正則化(Regularization)すべし。&lt;/p&gt;

&lt;p&gt;ロジスティック回帰ではL2ノルム(L2 norm)を使ったL2正則化が一般的。
L1正則化はあまり使われない。
L1正則化をすると、wがスパース行列になってモデルを圧縮できると言われることがあるが、経験上その効果はほとんどない。&lt;/p&gt;

&lt;p&gt;正則化パラメータλはハイパーパラメータで、Devデータで評価する。&lt;/p&gt;

&lt;p&gt;ニューラルネットワークでは正則化項にフロベニウスノルム(Frobenius norm)を使う。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dropout(Inverted Dropout)&lt;/p&gt;

&lt;p&gt;ランダムにノードを無効化しながら学習することで過学習を防ぐ。
画像処理の分野では、特徴量の数が多く学習データが少ない傾向があるので、ほぼ常に使われる。&lt;/p&gt;

&lt;p&gt;コスト関数が計算できなくなるのが欠点。
計算する必要があるときにはDropoutを無効化する。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;データ拡張(Data augmentation)&lt;/p&gt;

&lt;p&gt;データを加工して増やせば、高バリアンス対策になる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;早期終了(Early stopping)&lt;/p&gt;

&lt;p&gt;過学習するまえに学習を止めるテクニック。
訓練データとDevデータについてコストをプロットして、Devデータのものが上がる前に止める。&lt;/p&gt;

&lt;p&gt;これは、直交化(Orthogonalization)の原則、つまり一度に一つのことを考慮すべきという原則に反していて、コストを最小化するという問題と、過学習を避けるという問題に同時に対処することになるので微妙。&lt;/p&gt;

&lt;p&gt;普通は代わりにL2正則化使えばいいけど、λを最適化する手間を省きたいときには選択肢になりうる、というか実現場ではちょくちょく選択肢になる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;訓練データの正規化(Normalization)&lt;/p&gt;

&lt;p&gt;訓練データの各特徴量について平均を0にして分散を1にすると学習が速くなる。&lt;/p&gt;

&lt;p&gt;訓練データを正規化したらテストデータも正規化する。
その際、正規化パラメータは訓練データのものを使う。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;勾配消失(Vanishing gradient)、勾配爆発(Exploding gradient)&lt;/p&gt;

&lt;p&gt;ニューラルネットワークの層が深くなると、層の出力や勾配が指数関数的に大きくなったり小さくなったりして、学習が難しくなる問題。
長年ディープニューラルネットワークの発展を妨げてきた問題。&lt;/p&gt;

&lt;p&gt;パラメータのランダム初期化をすると防げる。
ガウス分布で作ったパラメータに特定の値を掛けてを分散が1/n(ReLUの時は2/n)になるように調整して、活性化関数に入力する値を約1に抑える。
掛ける値は活性化関数ごとにだいたい決まっていて((e.g. Xavier Initialization)、その値をハイパーパラメータとして調整するのはそれほど優先度は高くない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Gradient checking&lt;/p&gt;

&lt;p&gt;順伝播・逆伝播が正確に実装できているかを、数値計算手法で概算した勾配と逆伝播で出した勾配を比べてチェックするテクニック。
計算コストが高くなるので、デバッグ時にのみ使う。&lt;/p&gt;

&lt;p&gt;Dropoutしてるときには使えない。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;初期化&lt;/p&gt;

&lt;p&gt;ゼロ初期化、大きい値でのランダム初期化、He初期化(Xavier初期化っぽいやつ)を実装して性能を比べる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;正則化&lt;/p&gt;

&lt;p&gt;正則化無し、L2正則化、Dropoutの実装と比較。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Gradient checking&lt;/p&gt;

&lt;p&gt;Gradient checkingの実装と、その結果を利用した逆伝播のデバッグ。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Yoshua Bengioへのインタビュー&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;p&gt;学習を速くするテクニックについて。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ミニバッチ勾配降下法(Mini-batch gradient descent)&lt;/p&gt;

&lt;p&gt;普通の勾配降下法(i.e. バッチ勾配降下法)よりかなり速いので、大規模データでよく使われるテクニック。
学習回数に対するコストのプロットはノイジーになる。&lt;/p&gt;

&lt;p&gt;ミニバッチサイズというハイパーパラメータが増える。
ミニバッチサイズがmならバッチ勾配降下法、1なら確率的勾配降下法(Stochastic gradient descent)になる。&lt;/p&gt;

&lt;p&gt;ミニバッチ勾配降下法と確率的勾配降下法は収束しない。&lt;/p&gt;

&lt;p&gt;バッチ勾配降下法は遅すぎる。
確率的勾配降下法はベクトル化の恩恵がなくなるという欠点がある。
ので、適当なミニバッチサイズにするのがよく、それが一番速い。&lt;/p&gt;

&lt;p&gt;2000個くらいのデータならバッチ勾配降下法。
それより多ければ、64～512位のミニバッチサイズがいい。
メモリ効率を考えると2の累乗数がいいし、CPU/GPUメモリサイズに乗るサイズにすべし。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;指数加重移動平均 (EWMA: Exponentially Weighted Moving Average)&lt;/p&gt;

&lt;p&gt;ノイズのあるデータから、よりスムーズなプロットを書く手法。
過去数日の平均をもとにプロットする。&lt;/p&gt;

&lt;p&gt;この手法だと、最初の方のデータが不当に小さくなってしまう。
これが問題になるなら、バイアス補正(Bias correction)をかける。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;モーメンタム(Momentum)付き勾配降下法&lt;/p&gt;

&lt;p&gt;パラメータを更新するときに、勾配そのままではなく、勾配の指数加重移動平均を使う手法。
勾配降下を滑らかに速くできる。
慣性(勢い)をつけて走り抜ける感じ。&lt;/p&gt;

&lt;p&gt;指数加重移動平均を計算するときのβが新たなハイパーパラメータになる。
普通0.9。この場合バイアス補正はそんなに効果ないので普通かけない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;RMSprop&lt;/p&gt;

&lt;p&gt;パラメータを更新するときに、勾配そのままではなく、勾配の二乗平均平方根(RMS: Root Mean Square)を使う手法。
学習率を上げつつ、勾配降下を滑らかに速くできる。&lt;/p&gt;

&lt;p&gt;二乗平均平方根を計算するときのβと、ゼロ除算を防ぐためのεが新たなハイパーパラメータになる。
提唱者は、&lt;code&gt;β=0.999&lt;/code&gt;、&lt;code&gt;ε=10^-8&lt;/code&gt;を推奨しているし、これらをチューニングすることはあまりない。&lt;/p&gt;

&lt;p&gt;Couseraが広めたことで、よく使われるようになった。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Adam(Adaptive Moment Estimation)&lt;/p&gt;

&lt;p&gt;モーメンタムとRMSpropとバイアス補正を組み合わせた最適化アルゴリズム。
これをミニバッチ勾配降下法と一緒に使えばだいたい上手くいく。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;学習率減衰(Learning rate decay)&lt;/p&gt;

&lt;p&gt;ミニバッチ勾配降下を収束させるために、学習率を徐々に小さくする手法。
エポックごとに学習率を下げる。&lt;/p&gt;

&lt;p&gt;学習率αが、α0と 減衰率(Decay rate)とエポック番号から計算されるようになるので、α0と減衰率がハイパーパラメータ。&lt;/p&gt;

&lt;p&gt;学習率の計算方法にはいくつかある。
指数関数的に下げたり、階段状に下げたり。&lt;/p&gt;

&lt;p&gt;Andrew先生はあまり使わない手法。
学習率をよくチューニングすれば十分。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;局所最適解(Local optima)&lt;/p&gt;

&lt;p&gt;かつて、勾配が0になる点は、コストの谷、つまり局所最適解だと考えられていて、そこに嵌ることが問題だった。&lt;/p&gt;

&lt;p&gt;けど、ディープニューラルネットワークでは多くは尾根的なもの。
鞍の上みたいな部分なので鞍点(Saddle point)と呼ばれる。
特徴量が沢山あるので、ちょっと動かすとどれかの勾配は負になる。&lt;/p&gt;

&lt;p&gt;よって局所最適解はあまり恐れなくていい。
代わりに、鞍点の台地みたいな部分では勾配が小さいので学習効率が悪くなる。
ここを勢いよく抜けたいので、モーメンタムやRMSpropやAdamが有効になる。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ミニバッチ勾配降下法実装&lt;/p&gt;

&lt;p&gt;訓練データをシャッフルして、ミニバッチサイズに分割して(余りは余りでミニバッチにする)、forループで回す。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;モーメンタムとAdam実装&lt;/p&gt;

&lt;p&gt;単なるミニバッチ勾配降下法とモーメンタム付きとAdamを比較。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Yuanqing Linへのインタビュー&lt;/p&gt;

&lt;p&gt;中国の国立深層学習研究所のトップ。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;p&gt;ハイパーパラメータのチューニング方法、バッチ正規化、ソフトマックス回帰、TensorFlow。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ハイパーパラメータのチューニング&lt;/p&gt;

&lt;p&gt;一番重要なのは学習率。
次はモーメンタムのβとかミニバッチサイズとか隠れ層のノード数。
その次がレイヤ数とか学習率減衰率。&lt;/p&gt;

&lt;p&gt;チューニングの際は、かつてはグリッドサーチ(Grid search)がよく使われたけど、これはハイパーパラメータが多くなるとつらい。
ランダムサーチ(Randomized search)がより効率的。&lt;/p&gt;

&lt;p&gt;グリッドサーチだとあるパラメータを固定して別のパラメータを変化させるけど、変化させたパラメータがどうでもいいものだった場合、その試行がほとんど無駄になるので。&lt;/p&gt;

&lt;p&gt;粗くランダムサーチして当たりをつけ、範囲を絞って細かいランダムサーチする。&lt;/p&gt;

&lt;p&gt;ランダムといってもいろいろあって、ユニット数なんかは一様にランダムでいいけど、学習率なんかはlogスケールの上でランダムにしたほうがいい。&lt;/p&gt;

&lt;p&gt;実運用では、計算リソースが少ない場合に採るパンダアプローチと、潤沢なリソースで複数のモデルを同時に訓練するキャビアアプローチがある。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;バッチ正規化(Batch normalization)&lt;/p&gt;

&lt;p&gt;深層学習の実用化において最も重要なアルゴリズムの一つ。
ハイパーパラメータの選定を簡単にして、ディープニューラルネットワークの訓練を簡単にする。&lt;/p&gt;

&lt;p&gt;バッチ正規化では、各層の入力を正規化する。
ミニバッチごとに平均を0、分散を1に正規化した後、βとγというパラメータでそれぞれを調整する。
aよりz(i.e. 活性化関数適用前)を正規化するのが普通。&lt;/p&gt;

&lt;p&gt;(ハイパーではない)パラメータとしてβとγが層ごとに増える。
これらもWとともに学習する。
βがbの役割をするので、bはいらなくなる。&lt;/p&gt;

&lt;p&gt;バッチ正規化は共変量シフト(Covariate shift)という問題に対応するもの。
共変量シフトは、訓練した後で入力の分散が変わると、また訓練しなおさないといけないという問題。
ニューラルネットワークの内部では、前のほうの層のWが学習を進めるたびに変わり、その層の出力が変わる。
つまり後のほうの層への入力が変わるので、後のほうの層の学習が進みにくい。
バッチ正規化は、この後のほうの層への入力の分散を一定範囲に抑えることで、後のほうの層の学習を効率化する。&lt;/p&gt;

&lt;p&gt;Dropoutと同様な論理(ノードへの依存が分散される)で正則化の効果もややある。&lt;/p&gt;

&lt;p&gt;訓練が終わったら、最後のミニバッチの平均μと分散σ^2を保存しておいて、予測時に使う。
μとσ^2は訓練データ全体から再計算してもよさそうだけど、普通はやらない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ソフトマックス回帰(Softmax regression)&lt;/p&gt;

&lt;p&gt;ニューラルネットワークで多値分類(Multi-class classification)するアルゴリズム。
出力層(ソフトマックス層)のノード数をクラス数にして、活性化関数にソフトマックス関数を使う。
出力層の各ノードは、サンプルが各クラスに属する確率を出力する。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;TensorFlow&lt;/p&gt;

&lt;p&gt;ディープラーニングフレームワークはいろいろある: Caffe/Caffe2、CNTK、DL2J、Keras、Lasagne、mxnet、PaddlePaddle、TensorFlow、Theano、Torch。
プログラミングしやすいこと、訓練性能がいいこと、オープンであることが重要。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;TensorFlowの基本&lt;/p&gt;

&lt;p&gt;TensorFlowでのプログラムはだいたい以下のような手順で書く。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;テンソル(tensor)をつくる。これはまだ評価されない。&lt;/li&gt;
&lt;li&gt;テンソル間の計算式(計算グラフ)を書く。&lt;/li&gt;
&lt;li&gt;テンソルを初期化する。&lt;/li&gt;
&lt;li&gt;セッションを作る。&lt;/li&gt;
&lt;li&gt;セッションを実行する。ここで計算が実行される。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;後で(セッション実行時に)値を入れたい場合はプレースホルダ(placeholder)を使う。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;TensorFlowでのニューラルネットワーク実装&lt;/p&gt;

&lt;p&gt;画像を読み込んで多クラス分類するNNを作る。
以下、今回使った関数の一部。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;シグモイド関数: &lt;code&gt;tf.sigmoid(x)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;エントロピーコスト: &lt;code&gt;tf.nn.sigmoid_cross_entropy_with_logits(logits, labels)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;One-hotエンコーディング: &lt;code&gt;tf.one_hot(labels, depth, axis)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;最急降下法: &lt;code&gt;tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CourseraのDeep Learning SpecializationのNeural Networks and Deep Learningコースを修了した</title>
          <link>https://www.kaitoy.xyz/2018/01/05/coursera-deep-learning-neural-networks-and-deep-learning/</link>
          <pubDate>Fri, 05 Jan 2018 15:20:23 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/01/05/coursera-deep-learning-neural-networks-and-deep-learning/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2017/12/22/coursera-machine-learning/&#34;&gt;CourseraのMachine Learningコース&lt;/a&gt;に続いて、同じくAndrew先生による&lt;a href=&#34;https://www.coursera.org/specializations/deep-learning&#34;&gt;Deep Learning Specialization&lt;/a&gt;を受講中。&lt;/p&gt;

&lt;p&gt;これは深層学習の基本を学べるもので、以下の5つのコースからなる。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Neural Networks and Deep Learning&lt;/li&gt;
&lt;li&gt;Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization&lt;/li&gt;
&lt;li&gt;Structuring Machine Learning Projects&lt;/li&gt;
&lt;li&gt;Convolutional Neural Networks&lt;/li&gt;
&lt;li&gt;Sequence Models&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;この内、最初のNeural Networks and Deep Learningを修了したので、記念にブログしておく。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;deep-learning-specializationとは&#34;&gt;Deep Learning Specializationとは&lt;/h1&gt;

&lt;p&gt;Deep Learning Specializationは&lt;a href=&#34;https://learner.coursera.help/hc/en-us/articles/208280296&#34;&gt;Coursera Specialization&lt;/a&gt;のひとつ。
Coursera Specializationはサブスクリプションモデルで、つまりあるSpecializationのサブスクリプションを購入すると、受講完了するまで毎月定額の料金を支払うことになる。&lt;/p&gt;

&lt;p&gt;Deep Learning Specializationは月$49で、5コース合わせて16週分の内容。
最初の7日間はトライアルで無料なので、この間に全部終わらせられればタダ。
無理だけど。&lt;/p&gt;

&lt;p&gt;Deep Learning Specializationでは、PythonとTensorFlowでディープニューラルネットワーク、CNN、RNN、LSTM、Adam、Dropout、バッチ正規化、Xavier/He initializationなどを学べる。
Machine Learningコースと同じく、5分～15分くらいの動画による講義と、小テストと、プログラミング課題から構成されている。&lt;/p&gt;

&lt;p&gt;プログラミング課題は、coursera hubという、ホステッドJupyter Notebookで解いて提出できるので楽。&lt;/p&gt;

&lt;h1 id=&#34;neural-networks-and-deep-learningコースとは&#34;&gt;Neural Networks and Deep Learningコースとは&lt;/h1&gt;

&lt;p&gt;ディープニューラルネットワークの仕組みを学んで実装する4週間のコース。
また、深層学習の偉い人へのインタビューを見れる。
Machine Learningコースと被っている内容が少なくなく、かなり楽だったが、結構ペースが速いので、Machine Learningコースをやっていなかったら辛かったと思う。&lt;/p&gt;

&lt;p&gt;動画は大抵日本語字幕が付いている。
日本語字幕が付いていない奴は、英語字幕が機械生成したっぽいもので見辛い。&lt;/p&gt;

&lt;p&gt;2018/1/1に始めて、1/5に完了。
5日間かかった。
修了したら&lt;a href=&#34;https://www.coursera.org/account/accomplishments/certificate/G77XMU9TNEKX&#34;&gt;Certifacate&lt;/a&gt;もらえた。&lt;/p&gt;

&lt;p&gt;以下、4週分の内容をキーワードレベルで書いておく。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;深層学習(Deep Learning)概要&lt;/p&gt;

&lt;p&gt;AIは次世代の電気。産業革命を起こす。
AIで今一番熱い分野が深層学習。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ニューラルネットワーク(Neural Network)。&lt;/li&gt;
&lt;li&gt;畳み込みニューラルネットワーク(CNN: Convolutional Neural Network)。&lt;/li&gt;
&lt;li&gt;再帰型ニューラルネットワーク(RNN: Recurrent Neural Network)。&lt;/li&gt;
&lt;li&gt;深層学習の適用分野・例。&lt;/li&gt;
&lt;li&gt;深層学習が実用化した背景。&lt;/li&gt;
&lt;li&gt;シグモイド関数(Sigmoid function) vs ReLU(Rectified Linear Unit)関数。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;深層学習のゴッドファーザー、Geoffrey Hintonへのインタビュー。&lt;/p&gt;

&lt;p&gt;ニューラルネットワークの黎明期を支え、ReLU関数の有効性を証明したりボルツマンマシンを発明したりした人。
自身が歩んできた深層学習の歴史や今取り組んでいる・注目している理論について、
高尚な話をしていたようだったが、高尚すぎてよくわからなかった。&lt;/p&gt;

&lt;p&gt;今日成果を出しているのは教師あり学習だけど、教師無し学習のほうが重要と考えているとのこと。&lt;/p&gt;

&lt;p&gt;これから機械学習に取り組む人へ、以下のアドバイスをしていた。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;文献を読みすぎるな。&lt;/li&gt;
&lt;li&gt;文献を読んで、間違っていると感じるところをみつけて、それに取り組め。&lt;/li&gt;
&lt;li&gt;人から何を言われても気にせず、自分の信念に従って研究しろ。&lt;/li&gt;
&lt;li&gt;誰かに無意味なことをしていると指摘されたら、むしろ価値のあることをしていると思え。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ニューラルネットワークプログラミングの基礎&lt;/p&gt;

&lt;p&gt;ロジスティック回帰は小さい(1層1ノード)ニューラルネットワーク。
ロジスティック回帰の微分を逆伝播で計算する。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;二値分類(Binary classification)、ロジスティック回帰(Logistic regression)。&lt;/li&gt;
&lt;li&gt;損失関数(Loss function)、交差エントロピー(Cross entropy)、目的関数(Cost function)。&lt;/li&gt;
&lt;li&gt;最急降下法(Gradient descent)。&lt;/li&gt;
&lt;li&gt;微分(Derivatives)。&lt;/li&gt;
&lt;li&gt;逆伝播(Backpropagation)、計算グラフ(Computation graph)、連鎖律(Chain rule)。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Pythonとベクトル化(Vectorization)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;forループ vs ベクトル化。&lt;/li&gt;
&lt;li&gt;Jupyter Notebook、NumPy、ブロードキャスト(Broadcasting)。&lt;/li&gt;
&lt;li&gt;ロジスティック回帰のベクトル化。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ロジスティック回帰で猫の画像の判別。&lt;/li&gt;
&lt;li&gt;NumPy、h5py、Matplotlib、PIL、SciPy。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;深層学習とロボットの研究者、Pieter Abbeelへのインタビュー&lt;/p&gt;

&lt;p&gt;深層強化学習の有名な研究者。DQN。&lt;/p&gt;

&lt;p&gt;かつて、機械学習で成果を出すためには、取り組んでいる課題特有の分野の知識が必要だったが、2012年にGeoffreyが発表したAlexNetがそれを覆した。
Pieterはそのアイデアを深層強化学習に適用し発展させた。&lt;/p&gt;

&lt;p&gt;強化学習は、どこからデータ収集するのか、報酬の分配はどうするかといったところに課題がある。
また、安全性にも課題。学習の過程で失敗を繰り返すので、自動運転などをどう学習させるか、またどう学び続けさせるか。
ネガティブデータを集めるのがむずい。&lt;/p&gt;

&lt;p&gt;短時間の実験でうまくいっても、長時間の稼働でうまくいくとも限らない。&lt;/p&gt;

&lt;p&gt;強化学習は複雑すぎるので、アルゴリズム自体を学習できるようにしたい。
プログラムを自動で変更しながら学習するなど。&lt;/p&gt;

&lt;p&gt;強化学習は、アルゴリズムを変更しなくても様々なことを学べる。
けど、ゼロから学ぶと時間がかかるので、以前学んだことを活かして次の課題に取り組めるようにするのが最先端の研究。&lt;/p&gt;

&lt;p&gt;まずは教師あり学習で人の代わりができるようになり、その後目的を与えて、強化学習で改善していく、っていう感じのことができるとうれしい。&lt;/p&gt;

&lt;p&gt;これから機械学習に取り組む人へ、以下のアドバイスをしていた。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;需要が高まっているので、AIを始めるにはよい時期。&lt;/li&gt;
&lt;li&gt;オンライン講座がたくさんあるので、学びやすい。自分で試したり再現したりしてみることが重要。&lt;/li&gt;
&lt;li&gt;TensorFlow、Chainer、Theano、PyTorchなど、手軽に試せるツールが色々ある。&lt;/li&gt;
&lt;li&gt;専門的な教育を受けなくても、自己学習でトップクラスになれる。&lt;/li&gt;
&lt;li&gt;機械学習を学ぶのに、大学で研究すべきか大企業で仕事を得るべきかについては、どれくらいの指導を受けれるかによる。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;3週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;浅いニューラルネットワーク&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ロジスティック回帰を多重にして2層のニューラルネットワーク化。&lt;/li&gt;
&lt;li&gt;ニューラルネットワークアルゴリズムのベクトル化。&lt;/li&gt;
&lt;li&gt;活性化関数(Activation function)の選択: シグモイド vs tanh vs ReLU vs Leaky ReLU vs 線形活性化関数(Linear activation function)。&lt;/li&gt;
&lt;li&gt;順伝播(Forward propagation)、逆伝播(Backpropagation)。&lt;/li&gt;
&lt;li&gt;ランダム初期化(Random initialization)。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;二値分類するニューラルネットワークを実装。&lt;/li&gt;
&lt;li&gt;scikit-learn。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;GAN(Generative Adversarial Network)の発明者、Ian Goodfellowへのインタビュー&lt;/p&gt;

&lt;p&gt;GANは生成モデル(学習したデータに似たデータを生成するモデル)。
バーで飲んでいるときに思いつき、一晩で実装した。&lt;/p&gt;

&lt;p&gt;GANは今は繊細過ぎるのが課題で、安定性の向上に今取り組んでいる。&lt;/p&gt;

&lt;p&gt;機械学習のセキュリティにも興味がある。モデルをだまして想定外の動作をさせるような攻撃への対策など。&lt;/p&gt;

&lt;p&gt;これから機械学習に取り組む人へ、以下のアドバイスをしていた。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;機械学習のアルゴリズムよりも、線形代数や確率といった数学の基礎を習得することが重要。&lt;/li&gt;
&lt;li&gt;AIの道を進むのに、近年では博士号は必ずしも要らない。コードを書いてGitHubに上げろ。自身も実際に、オープンソース活動をしているひとの貢献を見て興味をもって採用したことがある。&lt;/li&gt;
&lt;li&gt;論文を公開するとよりいいけど、コードのほうが楽。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;4週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;深いニューラルネットワーク&lt;/p&gt;

&lt;p&gt;3層以上のニューラルネットワーク。その実装方法と有効性について。
ハイパーパラメータ(Hyperparameters): 学習率(Learning rate)、学習回数、レイヤ数、ノード数、活性化関数、等。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ディープニューラルネットワークの実装。&lt;/li&gt;
&lt;li&gt;再度猫画像の判別。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CourseraのMachine Learningコースを修了した</title>
          <link>https://www.kaitoy.xyz/2017/12/22/coursera-machine-learning/</link>
          <pubDate>Fri, 22 Dec 2017 10:20:44 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/12/22/coursera-machine-learning/</guid>
          <description>

&lt;p&gt;機械学習の入門教材として有名な&lt;a href=&#34;https://www.coursera.org/learn/machine-learning&#34;&gt;CourseraのMachine Learningコース&lt;/a&gt;を修了した記念日記。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;courseraとは&#34;&gt;Courseraとは&lt;/h2&gt;

&lt;p&gt;Courseraは、2012年にスタンフォード大学のコンピュータ工学科の2人の教授によって設立されたサービスで、世界トップクラスの大学の講座をオンラインで受けることができるもの。
東京大学とも提携している。&lt;/p&gt;

&lt;p&gt;講座の一部は無料で受けることができる。&lt;/p&gt;

&lt;h2 id=&#34;courseraのmachine-learningコースとは&#34;&gt;CourseraのMachine Learningコースとは&lt;/h2&gt;

&lt;p&gt;Machine Learningコースは、Courseraの設立者の一人であるAndrew Ngによる、機械学習の基礎から実践まで浅く広く(?)学べる世界的に有名な講座。
Andrew先生は一時期Googleで働き、&lt;a href=&#34;https://en.wikipedia.org/wiki/Google_Brain&#34;&gt;Google Brain&lt;/a&gt;というDeep Learningのプロジェクトをリードしていたこともある機械学習のエキスパートで、さらにスタンフォードの教授だっただけあって教え方が非常にうまくてわかりやすい。&lt;/p&gt;

&lt;p&gt;この講座は主に、5分～15分くらいの動画による講義と、小テストと、プログラミング課題から構成されている。
1週間分の内容が、1.5時間分くらいの動画と、15分くらいでできる小テストと、2、3時間で終わるプログラミング課題で、全体で11週間分やれば修了できる。
1、10、11週目はプログラミング課題が無くてすぐ終わる一方、3～5週目辺りは結構ハード。&lt;/p&gt;

&lt;p&gt;私は2017/10/30に始めて、2017/12/19に完了したので、ちょうど50日かかったことになる。&lt;/p&gt;

&lt;p&gt;動画は当然英語だが、有志により英語や日本語の字幕が付けられてるので聞き取れなくても問題はあまりない。
ただ、1～4週目くらいまでは、日本語の字幕がずれている動画が少なくなく、それらは英語の字幕でみる必要がある。
1つだけ英語の字幕もダメなものがあって、それだけは字幕なしで見た。&lt;/p&gt;

&lt;p&gt;プログラミング課題は、&lt;a href=&#34;https://www.gnu.org/software/octave/&#34;&gt;Octave&lt;/a&gt;というオープンソースの数値解析言語で解く。
聞いたことない言語だったが、&lt;a href=&#34;https://jp.mathworks.com/programs/trials/trial_request.html?ref=ggl&amp;amp;s_eid=ppc_30300738322&amp;amp;q=matlab&#34;&gt;MATLAB&lt;/a&gt;との互換性維持を重視して開発されている言語なので、まあ覚えておいて損はない。
Octaveグラフ描画APIは、MATLABのグラフ描画APIをまねていて、MATLABのグラフ描画APIは、Pythonでよく使われるグラフ描画ライブラリである&lt;a href=&#34;https://matplotlib.org/&#34;&gt;Matplotlib&lt;/a&gt;がまねていて、つまりOctaveやってるとMatplotlibの勉強にもなる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以下、11週間分の内容を、キーワードレベルで書いておく。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;機械学習の概要&lt;/p&gt;

&lt;p&gt;背景、歴史、活用例。
教師あり学習(Supervised learning) vs 教師なし(Unsupervised learning)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;線形単回帰(Linear regression with one variable)&lt;/p&gt;

&lt;p&gt;仮説関数(Hypothesis)、目的関数(Cost function)、平均二乗誤差(Mean squared error)、最小二乗法(Least squares method)、最急降下法(Gradient descent)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;行列&lt;/p&gt;

&lt;p&gt;行列(Matrix)とベクトル(Vector)。
行列演算。
逆行列(Inverse)、転置行列(Transpose)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;線形重回帰(Linear regression with multiple variables)&lt;/p&gt;

&lt;p&gt;特徴量のスケーリング(Feature scaling)、平均正則化(Mean normalization)。
学習率(Learning rate)。
多項式回帰(Polynomial regression)。
正規方程式(Normal equation)、特異行列(singular matrix)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Octaveチュートリアル&lt;/p&gt;

&lt;p&gt;基本操作、データロード・セーブ、データ計算、描画、制御構文、ベクトル化。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;3週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ロジスティック回帰(Logistic regression)&lt;/p&gt;

&lt;p&gt;二値分類(Binary classification)。
シグモイド関数(Sigmoid function)。
決定境界(Decision boundary)。
共役勾配法(Conjugate gradient)、BFGS、L-BFGS。
多値分類(Multi-class classification)、1対その他(One-vs-all)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;過学習(Overfitting)&lt;/p&gt;

&lt;p&gt;正則化(Regularization)、未学習(Underfitting)。
バイアス(Bias)、バリアンス(Variance)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;4週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ニューラルネットワーク(Neural Network)&lt;/p&gt;

&lt;p&gt;入力層(Input layer)、隠れ層(Hidden layer)、出力層(Output layer)。
ユニット(Unit)、バイアスユニット(Bias unit)、重み(Weight)。
活性化関数(Activation function)。
順伝播(Forward propagation)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;5週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ニューラルネットワーク続き&lt;/p&gt;

&lt;p&gt;逆伝播(Backpropagation)。
Gradient checking。
対称性破壊(Symmetry breaking)、ランダム初期化(Random initialization)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;6週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;機械学習へのアドバイス&lt;/p&gt;

&lt;p&gt;訓練データ(Training set)、テストデータ(Test set)、交差検証データ(Cross-validation set)。
一般化エラー(Generalization error)。
高バイアス(High bias)、高バリアンス(High variance)。
学習曲線(Learning curve)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;機械学習システムの設計&lt;/p&gt;

&lt;p&gt;実装の優先度付け。
スパム分類器(Spam classifier)。
エラー分析(Error analysis)。
歪んだクラス(Skewed classes)。
真陽性(True positive)、偽陽性(False positive)、真陰性(True negative)、偽陰性(False negative)。
適合率(Precision)、再現率(Recall)、F値(F1 score)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;7週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;サポートベクタマシン(SVM: Support Vector Machine)&lt;/p&gt;

&lt;p&gt;マージン(Margin)。
線形カーネル(Linear kernel)、ガウスカーネル(Gaussian kernel)、多項式カーネル(Polynomial kernel)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;8週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;K平均法(K-means algorithm)&lt;/p&gt;

&lt;p&gt;クラスタリング(Clustering)。
ランダム初期化(Random initialization)、局所最適解(Local optima)。
エルボー法(Elbow method)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;主成分分析(PCA: Principal Component Analysis)&lt;/p&gt;

&lt;p&gt;データ圧縮(Data compression)、データ可視化(Data visualization)、次元削減(Dimensionality Reduction)、データ復元(Reconstruction from compressed representation)。
投影誤差(Projection error)、分散(Variance)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;9週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;異常検知(Anomaly detection)&lt;/p&gt;

&lt;p&gt;密度推定(Density estimation)。
ガウス分布(Gaussian distribution)、正規分布(Normal distribution)。
異常検知 vs 教師あり学習。
多変量ガウス分布(Multivariate gaussian distribution)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;レコメンダシステム(Recommender system)&lt;/p&gt;

&lt;p&gt;映画レーティング(Movie rating)。
コンテンツベース(Content-­based recommendation)、協調フィルタリング(Collaborative filtering)。
低ランク行列因子分解(Low-rank matrix factorization)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;10週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;大規模機械学習&lt;/p&gt;

&lt;p&gt;バッチ勾配降下法(Batch gradient descent)、確率的勾配降下法(Stochastic gradient descent)、ミニバッチ勾配降下法(Mini-batch gradient descent)。
オンライン学習(Online learning)。
Map­‐reduce、データ並列性(Data parallelism)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;11週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;写真OCR(Photo OCR)&lt;/p&gt;

&lt;p&gt;写真OCRパイプライン(Photo OCR pipeline)、テキスト検出(Text detection)、文字分割(character segmentation)、文字認識(character recognition)。
スライディングウィンドウ(Sliding window)。
人工データ合成(Artificial data synthesis)、歪曲収差(Distortion)。
天井分析(Ceiling analysis)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次は&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873117584/&#34;&gt;ゼロから作るDeep Learning&lt;/a&gt;かな。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetes 1.8のアクセス制御について。あとDashboard。</title>
          <link>https://www.kaitoy.xyz/2017/10/31/retry-dashboard-on-k8s-cluster-by-kubeadm/</link>
          <pubDate>Tue, 31 Oct 2017 16:57:04 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/10/31/retry-dashboard-on-k8s-cluster-by-kubeadm/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/21/build-kubernetes-cluster-by-kubeadm/&#34;&gt;Kubernetes1.8のクラスタを構築する。kubeadmで。&lt;/a&gt;」で、Dashboardがうまく動かない問題が発生したんだけど、それを解決した話。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;問題の現象&#34;&gt;問題の現象&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/kubeadm/&#34;&gt;kubeadm&lt;/a&gt;でKubernetesクラスタを組んで、自前のアプリ(&lt;a href=&#34;https://www.kaitoy.xyz/2016/12/11/goslings-development-memo0-intro-design/&#34;&gt;Goslings&lt;/a&gt;)のデプロイまではうまくできたんだけど、&lt;a href=&#34;https://github.com/kubernetes/dashboard&#34;&gt;Dashboard&lt;/a&gt;をデプロイしたら動かず、Web UIに&lt;code&gt;kubectl proxy&lt;/code&gt;経由でつないでもタイムアウトしてしまった。&lt;/p&gt;

&lt;h2 id=&#34;対策&#34;&gt;対策&lt;/h2&gt;

&lt;p&gt;なんとなく、クラスタ内部での名前解決には&lt;a href=&#34;https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/dns&#34;&gt;kube-dns&lt;/a&gt;によるDNSサービスが使われているっぽいので、&lt;code&gt;/etc/hosts&lt;/code&gt;に余計な事書いたのがいけなかったと思った。&lt;/p&gt;

&lt;p&gt;ので、&lt;code&gt;/etc/hosts&lt;/code&gt;からk8s-masterとk8s-nodeのエントリを削除してから、&lt;code&gt;kubeadm init&lt;/code&gt;からやり直してみた。&lt;/p&gt;

&lt;h2 id=&#34;結果&#34;&gt;結果&lt;/h2&gt;

&lt;p&gt;したらちゃんと動いた。&lt;/p&gt;

&lt;p&gt;VMのホストで&lt;code&gt;kubectl proxy&lt;/code&gt;して、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop&amp;gt;kubectl proxy
Starting to serve on 127.0.0.1:8001
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/&lt;/code&gt;にブラウザでつないだらサインイン画面が表示された。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/retry-dashboard-on-k8s-cluster-by-kubeadm/dashboard.png&#34; alt=&#34;dashboard&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Dashboardのサインイン処理はKubernetes(というかkube-apiserver)のそれに移譲している。
Dashboardはそこで認証されたユーザでクラスタのリソースにアクセスし、情報を取得して表示する。多分。&lt;/p&gt;

&lt;p&gt;Dashboardへのサインイン方法は&lt;a href=&#34;https://github.com/kubernetes/dashboard/wiki/Access-control&#34;&gt;いくつかある&lt;/a&gt;が、それらを理解するにはKubernetesのアクセス制御について学ぶことを推奨とあったのでちょっと&lt;a href=&#34;https://kubernetes.io/docs/admin/accessing-the-api/&#34;&gt;Kubernetesのドキュメント&lt;/a&gt;を読んだ。&lt;/p&gt;

&lt;h2 id=&#34;kubernetesのアクセス制御&#34;&gt;Kubernetesのアクセス制御&lt;/h2&gt;

&lt;p&gt;Kubernetesクラスタのエンドポイントはkube-apiserverであり、クラスタのリソースへのアクセス制御もkube-apiserverがやる。
クライアントとkube-apiserverとのTLSセッションが確立した後、HTTP層のデータを見てアクセス制御をするんだけど、その処理は&lt;a href=&#34;https://kubernetes.io/docs/admin/authentication/&#34;&gt;Authentication&lt;/a&gt;(認証)、&lt;a href=&#34;https://kubernetes.io/docs/admin/authorization/&#34;&gt;Authorization&lt;/a&gt;(認可)、&lt;a href=&#34;https://kubernetes.io/docs/admin/admission-controllers/&#34;&gt;Admission&lt;/a&gt;(許可)の三段階からなる。&lt;/p&gt;

&lt;h3 id=&#34;authentication&#34;&gt;Authentication&lt;/h3&gt;

&lt;p&gt;第一段階がAuthentication。
ここでは、kube-apiserverに仕込まれたAuthenticatorモジュールがユーザ認証をする。&lt;/p&gt;

&lt;p&gt;Kubernetesが認証するユーザには、Kubernetesが管理するService Accountと、クラスタ外部で管理される通常ユーザの二通りがある。
Service AccountはPodがkube-apiserverと話すためのユーザで、通常ユーザは主に人がkubectlとかでkube-apiserverと話すためのユーザ。(匿名で話すこともできる。)
前者はServiceAccountオブジェクトで定義されるけど、後者用のオブジェクトはない。&lt;/p&gt;

&lt;p&gt;ServiceAccountはNamespaceと関連付き(つまりnamespace毎にユニーク)、Secretに紐づく。
Secretオブジェクトはクレデンシャルのセットを定義し、Podにマウントされる。
ServiceAccountとSecretは、ふつうは自動で作られ、Podに割り当てられる。&lt;/p&gt;

&lt;p&gt;kube-apiserverには一つ以上のAuthenticatorモジュールを設定できて、どれかで認証できれば次の段階に進める。
認証失敗するとHTTPステータスコード401が返る。&lt;/p&gt;

&lt;p&gt;Authenticatorモジュールには以下のようなものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authentication/#x509-client-certs&#34;&gt;クライアント証明書&lt;/a&gt;: X.509のディジタル証明書を使うモジュール。kube-apiserver起動時に&lt;code&gt;--client-ca-file&lt;/code&gt;オプションで証明書ファイルを渡してやると有効になる。証明書のCommon Nameがユーザ名になり、Organizationがグループになる。クライアント側は、その証明書と対応する秘密鍵をクレデンシャルとして指定する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authentication/#putting-a-bearer-token-in-a-request&#34;&gt;Bearer Token&lt;/a&gt;: 無記名トークンを使うモジュール。kube-apiserver起動時に&lt;code&gt;--token-auth-file&lt;/code&gt;オプションでトークン情報を渡してやると有効になる。トークン情報はCSVで、「&lt;code&gt;token,user,uid,&amp;quot;group1,group2,group3&amp;quot;&lt;/code&gt;」という形式で書く。クライアント側は、トークン文字列をクレデンシャルとして指定する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authentication/#static-password-file&#34;&gt;ベーシック認証&lt;/a&gt;: ユーザ名とパスワードで認証するモジュール。kube-apiserver起動時に&lt;code&gt;--basic-auth-file&lt;/code&gt;オプションでユーザ名とパスワードのリストを渡してやると有効になる。このリストはCSVで、「&lt;code&gt;password,user,uid,&amp;quot;group1,group2,group3&amp;quot;&lt;/code&gt;」という形式で書く。クライアント側は、ユーザ名とパスワードをクレデンシャルとして指定する。HTTPクライアントの時はAuthorizationヘッダが使える。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authentication/#service-account-tokens&#34;&gt;Service Account Token&lt;/a&gt;: Service Accountを署名付きBearer Tokenで認証するモジュール。デフォルトで有効になる。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;このあたり、Qiitaの「&lt;a href=&#34;https://qiita.com/hiyosi/items/43465d4fc501c2044d01#x509-client-certs&#34;&gt;kubernetesがサポートする認証方法の全パターンを動かす&lt;/a&gt;」という記事をみると理解が深まる。&lt;/p&gt;

&lt;h3 id=&#34;authorization&#34;&gt;Authorization&lt;/h3&gt;

&lt;p&gt;Authenticationをパスすると、クライアントのユーザ(とグループ)が認証され、第二段階のAuthorizationモジュールの処理に移る。
ここでは、リクエストの内容(操作対象、操作種別(メソッド)等)を見て、それがユーザに許されたものなら認可する。
何を許すかは事前にクラスタにポリシーを定義しておく。&lt;/p&gt;

&lt;p&gt;kube-apiserver起動時に&lt;code&gt;--authorization-mode&lt;/code&gt;オプションで一つ以上のAuthenticatorモジュールを指定できて、どれかで認可されれば次の段階に進める。
さもなくばHTTPステータスコード403が返る。&lt;/p&gt;

&lt;p&gt;Authorizationモジュールには以下のようなものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authorization/node/&#34;&gt;Node&lt;/a&gt;: kubeletからのリクエストを認可する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authorization/abac/&#34;&gt;ABAC Mode&lt;/a&gt;: Attribute-based Access Control。リクエストに含まれる属性とPolicyオブジェクトを比較して、マッチするものがあれば認可。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authorization/rbac/&#34;&gt;RBAC Mode&lt;/a&gt;: Role-Based Access Control。RoleオブジェクトやClusterRoleオブジェクトでロールを作成し、アクセスできるリソースや許可する操作を定義して、RoleBindingオブジェクトやClusterRoleBindingオブジェクトでユーザ名やグループと紐づける。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/admin/authorization/webhook/&#34;&gt;Webhook Mode&lt;/a&gt;: リクエストの内容を示すSubjectAccessReviewオブジェクトをシリアライズしたJSONデータをHTTPでPOSTして、そのレスポンスによって認可可否を決める。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;admission-control&#34;&gt;Admission Control&lt;/h3&gt;

&lt;p&gt;Authorizationをパスすると、第三段階のAdmission Controlモジュールの処理に移る。
ここでは、オブジェクトの作成、削除、更新などのリクエストをインターセプトして、オブジェクトの永続化前にそのオブジェクトを確認して、永続化を許可するかを決める。
リクエストされたオブジェクトやそれに関連するオブジェクトを永続化前にいじって、デフォルト値を設定したりもできる。
読み取りリクエストの場合は実行されない。&lt;/p&gt;

&lt;p&gt;kube-apiserver起動時に&lt;code&gt;--admission-control&lt;/code&gt;オプションで複数のAdmission Controlモジュールを指定できて、全てが許可しないとリクエストが却下される。&lt;/p&gt;

&lt;p&gt;Admission Controlモジュールは色々あるんだけど、Kubernetes 1.6以降では&lt;code&gt;--admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,DefaultStorageClass,ResourceQuota,DefaultTolerationSeconds&lt;/code&gt;と指定するのが強く推奨されている。
ここで指定している&lt;a href=&#34;https://kubernetes.io/docs/admin/admission-controllers/#serviceaccount&#34;&gt;ServiceAccountモジュール&lt;/a&gt;は、kube-controller-managerに含まれるServiceAccountControllerとTokenControllerと協調し、Service Account周りの処理を&lt;a href=&#34;https://kubernetes.io/docs/admin/service-accounts-admin/#service-account-automation&#34;&gt;自動化&lt;/a&gt;してくれるもの。&lt;/p&gt;

&lt;p&gt;ServiceAccountControllerは、各Namespaceに&lt;code&gt;default&lt;/code&gt;という名前のService Accountを作る。&lt;/p&gt;

&lt;p&gt;ServiceAccountが作成されるとTokenControllerが動き、対応したSecretとトークンを生成して紐づける。&lt;/p&gt;

&lt;p&gt;ServiceAccountモジュールは、Podの作成や更新時に動き、以下の処理をする。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;PodにServiceAccountが設定されていなければ、&lt;code&gt;default&lt;/code&gt;を設定する。&lt;/li&gt;
&lt;li&gt;Podに設定されたServiceAccountが存在していることを確認し、存在していなければリクエストを却下する。&lt;/li&gt;
&lt;li&gt;PodがImagePullSecretsを含んでいなければ、ServiceAccountのImagePullSecretsをPodに追加する。&lt;/li&gt;
&lt;li&gt;トークンを含んだVolumeをPodに追加する。&lt;/li&gt;
&lt;li&gt;Pod内の各コンテナの&lt;code&gt;/var/run/secrets/kubernetes.io/serviceaccount&lt;/code&gt;にそのVolumeをマウントさせる。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;dashboardへbearer-tokenでサインイン&#34;&gt;DashboardへBearer Tokenでサインイン&lt;/h2&gt;

&lt;p&gt;Dashboardの話に戻る。
とりあえず&lt;a href=&#34;https://github.com/kubernetes/dashboard/wiki/Access-control#bearer-token&#34;&gt;Bearer Tokenでのサインイン&lt;/a&gt;を試す。&lt;/p&gt;

&lt;p&gt;クラスタにはデフォルトで色んなService Accountが作られていて、異なる権限を持っている。
そのいずれかのSecretのTokenを使ってDashboardへサインインできるらしい。&lt;/p&gt;

&lt;p&gt;以下のコマンドで&lt;code&gt;kube-system&lt;/code&gt;というNamespaceのSecretを一覧できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl -n kube-system get secret
NAME                                     TYPE                                  DATA      AGE
attachdetach-controller-token-skzmj      kubernetes.io/service-account-token   3         18m
bootstrap-signer-token-mhqfh             kubernetes.io/service-account-token   3         18m
bootstrap-token-2964e0                   bootstrap.kubernetes.io/token         7         18m
certificate-controller-token-fvrgm       kubernetes.io/service-account-token   3         18m
cronjob-controller-token-hmrdm           kubernetes.io/service-account-token   3         18m
daemon-set-controller-token-vqz85        kubernetes.io/service-account-token   3         18m
default-token-h987g                      kubernetes.io/service-account-token   3         18m
deployment-controller-token-86bp9        kubernetes.io/service-account-token   3         18m
disruption-controller-token-6mskg        kubernetes.io/service-account-token   3         18m
endpoint-controller-token-d4wz6          kubernetes.io/service-account-token   3         18m
generic-garbage-collector-token-smfgq    kubernetes.io/service-account-token   3         18m
horizontal-pod-autoscaler-token-wsbn9    kubernetes.io/service-account-token   3         18m
job-controller-token-fttt2               kubernetes.io/service-account-token   3         18m
kube-dns-token-sn5qq                     kubernetes.io/service-account-token   3         18m
kube-proxy-token-w96xd                   kubernetes.io/service-account-token   3         18m
kubernetes-dashboard-certs               Opaque                                2         7m
kubernetes-dashboard-key-holder          Opaque                                2         6m
kubernetes-dashboard-token-gtppc         kubernetes.io/service-account-token   3         7m
namespace-controller-token-5kksd         kubernetes.io/service-account-token   3         18m
node-controller-token-chpwt              kubernetes.io/service-account-token   3         18m
persistent-volume-binder-token-d5x49     kubernetes.io/service-account-token   3         18m
pod-garbage-collector-token-l8sct        kubernetes.io/service-account-token   3         18m
replicaset-controller-token-njjwr        kubernetes.io/service-account-token   3         18m
replication-controller-token-qrr5h       kubernetes.io/service-account-token   3         18m
resourcequota-controller-token-dznjm     kubernetes.io/service-account-token   3         18m
service-account-controller-token-99nh8   kubernetes.io/service-account-token   3         18m
service-controller-token-9cw7k           kubernetes.io/service-account-token   3         18m
statefulset-controller-token-8z8w9       kubernetes.io/service-account-token   3         18m
token-cleaner-token-cxbkc                kubernetes.io/service-account-token   3         18m
ttl-controller-token-k7gh7               kubernetes.io/service-account-token   3         18m
weave-net-token-lqdgm                    kubernetes.io/service-account-token   3         17m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、適当にそれっぽいSecret、&lt;code&gt;deployment-controller-token-86bp9&lt;/code&gt;を選んで、&lt;code&gt;kubectl describe&lt;/code&gt;したらTokenが見れた。
(Dataセクションの&lt;code&gt;token&lt;/code&gt;のとこ。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl -n kube-system describe secret deployment-controller-token-86bp9
Name:         deployment-controller-token-86bp9
Namespace:    kube-system
Labels:       &amp;lt;none&amp;gt;
Annotations:  kubernetes.io/service-account.name=deployment-controller
              kubernetes.io/service-account.uid=17fc5207-b627-11e7-9867-000c2938deae

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkZXBsb3ltZW50LWNvbnRyb2xsZXItdG9rZW4tODZicDkiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGVwbG95bWVudC1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMTdmYzUyMDctYjYyNy0xMWU3LTk4NjctMDAwYzI5MzhkZWFlIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRlcGxveW1lbnQtY29udHJvbGxlciJ9.ZGV9XDd-GQjAwRuLKpdsWL_dTeF0Mr_2gF117OW4BhEuLwPujnsfOuysAQ-DUtNOp1NHKGitlfxjh6fKo4tFsdwLVJWrRK6i4YH1Mm2No7Sheks7IQn1FnwSmr7yCuvjlHD2e4RpZH0wupOFoY7FHntilhOWbXTJzJzi7TozLX02EKbkVGAsvch3LZ6p8jmUH5hr8DdKc4jbmTRp86SOiFS4_-TJ3RtAHCxiioAuKzXm3-rAWdeGLLcKrM2pAFSAGaBNu8MO5BZlAi6h3Xt4x-8-1ZXs4mudtJiECvjB-XIwiwzhpq8wIPZvvQQ-f1khixOyk1RfIXRJhIE5Gqvi8g
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;サインイン画面でTokenを選択し、
この、&lt;code&gt;eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkZXBsb3ltZW50LWNvbnRyb2xsZXItdG9rZW4tODZicDkiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGVwbG95bWVudC1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMTdmYzUyMDctYjYyNy0xMWU3LTk4NjctMDAwYzI5MzhkZWFlIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRlcGxveW1lbnQtY29udHJvbGxlciJ9.ZGV9XDd-GQjAwRuLKpdsWL_dTeF0Mr_2gF117OW4BhEuLwPujnsfOuysAQ-DUtNOp1NHKGitlfxjh6fKo4tFsdwLVJWrRK6i4YH1Mm2No7Sheks7IQn1FnwSmr7yCuvjlHD2e4RpZH0wupOFoY7FHntilhOWbXTJzJzi7TozLX02EKbkVGAsvch3LZ6p8jmUH5hr8DdKc4jbmTRp86SOiFS4_-TJ3RtAHCxiioAuKzXm3-rAWdeGLLcKrM2pAFSAGaBNu8MO5BZlAi6h3Xt4x-8-1ZXs4mudtJiECvjB-XIwiwzhpq8wIPZvvQQ-f1khixOyk1RfIXRJhIE5Gqvi8g&lt;/code&gt;を入力したらサインインできて、GoslingsのDeploymentの情報が見れた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/retry-dashboard-on-k8s-cluster-by-kubeadm/deploy.png&#34; alt=&#34;deploy&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Podも見れる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/retry-dashboard-on-k8s-cluster-by-kubeadm/pods.png&#34; alt=&#34;pods&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;けどServiceは見れない。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/retry-dashboard-on-k8s-cluster-by-kubeadm/service.png&#34; alt=&#34;service&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;各画面でオレンジ色のワーニングも出ていて、&lt;code&gt;deployment-controller&lt;/code&gt;ユーザで見れる範囲はあまり広くないことが分かる。&lt;/p&gt;

&lt;h2 id=&#34;dashboardへadmin権限でサインイン&#34;&gt;DashboardへAdmin権限でサインイン&lt;/h2&gt;

&lt;p&gt;DashboardのPodのService Accountである&lt;code&gt;kubernetes-dashboard&lt;/code&gt;にAdmin権限を付けてやって、サインイン画面でSKIPを押すとなんでも見れるようになる。セキュリティリスクがあるので本番ではNG設定だけど。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;cluster-admin&lt;/code&gt;というClusterRoleがあって、これを&lt;code&gt;kubernetes-dashboard&lt;/code&gt;にバインドするClusterRoleBindingを作ってやればいい。&lt;/p&gt;

&lt;p&gt;ので、以下のようなYAMLファイルを書いて、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: kubernetes-dashboard
  labels:
    k8s-app: kubernetes-dashboard
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: kubernetes-dashboard
  namespace: kube-system
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;kubectl&lt;/code&gt;で投げる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop&amp;gt;kubectl create -f dashboard-admin.yml
clusterrolebinding &amp;quot;kubernetes-dashboard&amp;quot; created
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;したらServiceも見えるようになった。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/retry-dashboard-on-k8s-cluster-by-kubeadm/service-admin.png&#34; alt=&#34;service-admin&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ついでにHWリソース情報も見れた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/retry-dashboard-on-k8s-cluster-by-kubeadm/resources.png&#34; alt=&#34;resources&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;満足した。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetes1.8のクラスタを構築する。kubeadmで。</title>
          <link>https://www.kaitoy.xyz/2017/10/21/build-kubernetes-cluster-by-kubeadm/</link>
          <pubDate>Sat, 21 Oct 2017 10:42:46 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/10/21/build-kubernetes-cluster-by-kubeadm/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/&#34;&gt;Kubernetes 1.8が出たので、Minikubeを触ってみる&lt;/a&gt;」でMinikubeをやったんだけど、もう一歩ステップアップすべく、&lt;a href=&#34;https://kubernetes.io/docs/admin/kubeadm/&#34;&gt;kubeadm&lt;/a&gt;でKubernetesクラスタを組んでみた話。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;kubeadmとは&#34;&gt;kubeadmとは&lt;/h2&gt;

&lt;p&gt;kubeadm(キューブアダム)はKubernetesに含まれるコマンドで、Kubernetesクラスタを簡単に構築するツール。
Kubernetes 1.4で追加され、Kubernetes 1.8の時点でまだベータで、本番環境には使わないでとなっている。
Qiitaの「&lt;a href=&#34;https://qiita.com/helix_kaz/items/9c4a83532f949d8a94ef&#34;&gt;kubeadmが何をやっているのかみてみた&lt;/a&gt;」という記事が、中でどんな動作をしてるかを解説していて参考になる。&lt;/p&gt;

&lt;p&gt;コマンドの使用感からすると、&lt;a href=&#34;https://docs.docker.com/engine/swarm/&#34;&gt;DockerのSwarmモード&lt;/a&gt;でのクラスタ構築の容易さをKubernetesに取り込むことを目指して開発されている気がした。&lt;/p&gt;

&lt;p&gt;ネットで見かけた評判だと、確かに簡単にクラスタ構築できて素晴らしいけど、TLSの証明書生成など、細かく制御できなくて困るところがあって、やはり本番に使えるレベルではないとのこと。&lt;/p&gt;

&lt;p&gt;まあとにかく試してみる価値はあろう。&lt;/p&gt;

&lt;h2 id=&#34;kubeadmインストール&#34;&gt;kubeadmインストール&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/setup/independent/install-kubeadm/&#34;&gt;Kubernetesのドキュメント&lt;/a&gt;に従ってkubeadmをインストールする。
バージョンは最新版の1.8.1。&lt;/p&gt;

&lt;h3 id=&#34;vm作成&#34;&gt;VM作成&lt;/h3&gt;

&lt;p&gt;kubeadmのサポートOSは、Ubuntu 16.04+、Debian 9、CentOS 7、RHEL 7、Fedora 25/26、HypriotOS v1.0.1+となっている。
慣れているCentOS 7を使うことにする。
(HypriotOSってなんだろう?)&lt;/p&gt;

&lt;p&gt;自前のノートPCのWindows 10 x64 Home Edition上のVMware Player 12のVMにCentOS 7を入れた。
メモリは1GB以上が要件なので、味を付けて1.4GBで。
VM間で通信できることって要件があったけど、インターネット接続も必要なはずなので、NICはNATのやつで。&lt;/p&gt;

&lt;p&gt;このVMはMasterになる。&lt;/p&gt;

&lt;h3 id=&#34;os設定&#34;&gt;OS設定&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/setup/independent/install-kubeadm/#check-required-ports&#34;&gt;Kubernetesが使うポート&lt;/a&gt;をいろいろ開けなければいけないんだけど、めんどいのでfirewalldを無効にする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@localhost ~]# systemctl stop firewalld
[root@localhost ~]# systemctl disable firewalld
Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.
Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;なんとなくIPアドレスをDHCPから静的割り当てに。(192.168.171.200)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# nmcli c modify ens33 ipv4.method manual
[root@k8s-master ~]# nmcli c modify ens33 ipv4.addresses 192.168.171.200/24
[root@k8s-master ~]# nmcli c modify ens33 ipv4.dns 192.168.171.2
[root@k8s-master ~]# nmcli c modify ens33 ipv4.gateway 192.168.171.2
[root@k8s-master ~]# systemctl restart network
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ホスト名をlocalhost.localdomainからk8s-masterに変更。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@localhost ~]# hostnamectl set-hostname k8s-master
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ログアウトログインで反映。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/etc/hosts&lt;/code&gt;を編集して、k8s-masterのエントリを追加。
あとで作るもう一つのVM、k8s-nodeのほうもエントリを追加。
(これはだめだったっぽい。詳細は後述。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;クラスタを構成するノードは、一意のMACアドレスとproduct_uuidを持っていないといけない。
Kubernetesがそれらでクラスタ内のノードを区別してるので。&lt;/p&gt;

&lt;p&gt;MACアドレスは&lt;code&gt;ip link&lt;/code&gt;コマンドなどで確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# ip link
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT qlen 1
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: ens33: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT qlen 1000
    link/ether 00:0c:29:38:de:ae brd ff:ff:ff:ff:ff:ff
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;product_uuidは、&lt;a href=&#34;https://ja.wikipedia.org/wiki/SMBIOS&#34;&gt;SMBIOS&lt;/a&gt;という、PC固有のデータを保存・参照するための仕様があって、それに従って保存されたシステムの識別子らしい。
product_uuidは&lt;code&gt;dmidecode&lt;/code&gt;コマンドなどで確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# dmidecode -s system-uuid
58114D56-A744-3610-C3C5-9B15A838DEAE
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;kubeletがちゃんと動くためにはswapを無効にする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# swapoff -a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(このコマンドはよくなかった。詳細は後述。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ebtablesとethtoolを入れる必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# yum install -y ebtables ethtool
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Dockerも入れないと。
v1.12が推奨で、v1.11かv1.13でもいい。
適当に入れたらv1.12.6だった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# yum install -y docker
[root@k8s-master ~]# systemctl enable docker &amp;amp;&amp;amp; systemctl start docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Podネットワークなどが機能する要件として、コンテナがホストファイルシステムにアクセスできる必要があるが、そのためには現状、SELinuxを無効化する必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# setenforce 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(このコマンドもよくなかった。詳細は後述。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;RHEL系の場合、iptablesがバイパスされてトラフィックが変にルーティングされる問題があるため、&lt;code&gt;net.bridge.bridge-nf-call-iptables&lt;/code&gt;を1にセットしておく必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# cat &amp;lt;&amp;lt;EOF &amp;gt;  /etc/sysctl.d/k8s.conf
&amp;gt; net.bridge.bridge-nf-call-ip6tables = 1
&amp;gt; net.bridge.bridge-nf-call-iptables = 1
&amp;gt; EOF
[root@k8s-master ~]# sysctl --system
* Applying /usr/lib/sysctl.d/00-system.conf ...
net.bridge.bridge-nf-call-ip6tables = 0
net.bridge.bridge-nf-call-iptables = 0
net.bridge.bridge-nf-call-arptables = 0
* Applying /usr/lib/sysctl.d/10-default-yama-scope.conf ...
kernel.yama.ptrace_scope = 0
* Applying /usr/lib/sysctl.d/50-default.conf ...
kernel.sysrq = 16
kernel.core_uses_pid = 1
net.ipv4.conf.default.rp_filter = 1
net.ipv4.conf.all.rp_filter = 1
net.ipv4.conf.default.accept_source_route = 0
net.ipv4.conf.all.accept_source_route = 0
net.ipv4.conf.default.promote_secondaries = 1
net.ipv4.conf.all.promote_secondaries = 1
fs.protected_hardlinks = 1
fs.protected_symlinks = 1
* Applying /usr/lib/sysctl.d/99-docker.conf ...
fs.may_detach_mounts = 1
* Applying /etc/sysctl.d/99-sysctl.conf ...
* Applying /etc/sysctl.d/k8s.conf ...
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
* Applying /etc/sysctl.conf ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Cgroup Driverを、Dockerとkubeletとの間で一致させておく必要がある。
以下のようにして確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# cat /etc/systemd/system/kubelet.service.d/10-kubeadm.conf | grep KUBELET_CGROUP_ARGS
Environment=&amp;quot;KUBELET_CGROUP_ARGS=--cgroup-driver=systemd&amp;quot;
ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_SYSTEM_PODS_ARGS $KUBELET_NETWORK_ARGS $KUBELET_DNS_ARGS $KUBELET_AUTHZ_ARGS $KUBELET_CADVISOR_ARGS $KUBELET_CGROUP_ARGS $KUBELET_CERTIFICATE_ARGS $KUBELET_EXTRA_ARGS
[root@k8s-master ~]# docker info |grep -i cgroup
 WARNING: Usage of loopback devices is strongly discouraged for production use. Use `--storage-opt dm.thinpooldev` to specify a custom block storage device.
Cgroup Driver: systemd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;どっちもsystemdだったので問題なし。
(違ってたら&lt;a href=&#34;https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#troubleshooting&#34;&gt;&lt;code&gt;KUBELET_CGROUP_ARGS&lt;/code&gt;を変更する必要がある&lt;/a&gt;。)&lt;/p&gt;

&lt;h3 id=&#34;kubelet-kubeadm-kubectlインストール&#34;&gt;kubelet、kubeadm、kubectlインストール&lt;/h3&gt;

&lt;p&gt;ここでやっとkubeadmのインストール。
kubeletとkubectlも一緒にインストールする。&lt;/p&gt;

&lt;p&gt;まずYUMリポジトリを追加して、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/yum.repos.d/kubernetes.repo
&amp;gt; [kubernetes]
&amp;gt; name=Kubernetes
&amp;gt; baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
&amp;gt; enabled=1
&amp;gt; gpgcheck=1
&amp;gt; repo_gpgcheck=1
&amp;gt; gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
&amp;gt;         https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
&amp;gt; EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;インストール。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# yum install kubelet kubeadm kubectl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、kubeletをサービス登録。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# systemctl enable kubelet &amp;amp;&amp;amp; systemctl start kubelet
Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /etc/systemd/system/kubelet.service.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ここでVMのスナップショットをとっておいて、後でNodeを追加するときに使う。&lt;/p&gt;

&lt;h2 id=&#34;master構築&#34;&gt;Master構築&lt;/h2&gt;

&lt;p&gt;Masterは&lt;code&gt;kubeadm init&lt;/code&gt;で構築できる。
&lt;code&gt;--apiserver-advertise-address&lt;/code&gt;でkube-apiserverがlistenするIPアドレスを指定すべし。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubeadm init --apiserver-advertise-address=192.168.171.200
[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
[init] Using Kubernetes version: v1.8.1
[init] Using Authorization modes: [Node RBAC]
[preflight] Running pre-flight checks
[preflight] WARNING: Running with swap on is not supported. Please disable swap or set kubelet&#39;s --fail-swap-on flag to false.
[kubeadm] WARNING: starting in 1.8, tokens expire after 24 hours by default (if you require a non-expiring token use --token-ttl 0)
[certificates] Generated ca certificate and key.
[certificates] Generated apiserver certificate and key.
[certificates] apiserver serving cert is signed for DNS names [k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.171.200]
[certificates] Generated apiserver-kubelet-client certificate and key.
[certificates] Generated sa key and public key.
[certificates] Generated front-proxy-ca certificate and key.
[certificates] Generated front-proxy-client certificate and key.
[certificates] Valid certificates and keys now exist in &amp;quot;/etc/kubernetes/pki&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;admin.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;kubelet.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;controller-manager.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;scheduler.conf&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-apiserver to &amp;quot;/etc/kubernetes/manifests/kube-apiserver.yaml&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-controller-manager to &amp;quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-scheduler to &amp;quot;/etc/kubernetes/manifests/kube-scheduler.yaml&amp;quot;
[etcd] Wrote Static Pod manifest for a local etcd instance to &amp;quot;/etc/kubernetes/manifests/etcd.yaml&amp;quot;
[init] Waiting for the kubelet to boot up the control plane as Static Pods from directory &amp;quot;/etc/kubernetes/manifests&amp;quot;
[init] This often takes around a minute; or longer if the control plane images have to be pulled.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz&#39; failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz&#39; failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz&#39; failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz/syncloop&#39; failed with error: Get http://localhost:10255/healthz/syncloop: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz/syncloop&#39; failed with error: Get http://localhost:10255/healthz/syncloop: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz/syncloop&#39; failed with error: Get http://localhost:10255/healthz/syncloop: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz&#39; failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz/syncloop&#39; failed with error: Get http://localhost:10255/healthz/syncloop: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn&#39;t running or healthy.
[kubelet-check] The HTTP call equal to &#39;curl -sSL http://localhost:10255/healthz&#39; failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.

Unfortunately, an error has occurred:
        timed out waiting for the condition

This error is likely caused by that:
        - The kubelet is not running
        - The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)
        - There is no internet connection; so the kubelet can&#39;t pull the following control plane images:
                - gcr.io/google_containers/kube-apiserver-amd64:v1.8.1
                - gcr.io/google_containers/kube-controller-manager-amd64:v1.8.1
                - gcr.io/google_containers/kube-scheduler-amd64:v1.8.1

You can troubleshoot this for example with the following commands if you&#39;re on a systemd-powered system:
        - &#39;systemctl status kubelet&#39;
        - &#39;journalctl -xeu kubelet&#39;
couldn&#39;t initialize a Kubernetes cluster
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なんか失敗した。
&lt;code&gt;getsockopt: connection refused.&lt;/code&gt;ってのがたくさん出てる。
ググると、swapがあやしい。
確認してみたら、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# swapon -s
Filename                                Type            Size    Used    Priority
/dev/dm-1                               partition       2097148 0       -1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;無効になってない。
&lt;code&gt;swapoff -a&lt;/code&gt;でswap無効にしても、OS再起動したらもとに戻ってしまうのか。&lt;/p&gt;

&lt;p&gt;永続的に無効にするため、&lt;code&gt;/etc/fstab&lt;/code&gt;を編集して、以下の行を削除した。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/dev/mapper/centos-swap swap                    swap    defaults        0 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、OSリブート。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;kubeadm initをやり直す前に、いったん&lt;code&gt;kubeadm reset&lt;/code&gt;して初期化する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubeadm reset
[preflight] Running pre-flight checks
[reset] Stopping the kubelet service
[reset] Unmounting mounted directories in &amp;quot;/var/lib/kubelet&amp;quot;
[reset] Removing kubernetes-managed containers
[reset] Deleting contents of stateful directories: [/var/lib/kubelet /etc/cni/net.d /var/lib/dockershim /var/run/kubernetes /var/lib/etcd]
[reset] Deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki]
[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;2回目の&lt;code&gt;kubeadm init&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubeadm init --apiserver-advertise-address=192.168.171.200
[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
[init] Using Kubernetes version: v1.8.1
[init] Using Authorization modes: [Node RBAC]
[preflight] Running pre-flight checks
[preflight] Starting the kubelet service
[kubeadm] WARNING: starting in 1.8, tokens expire after 24 hours by default (if you require a non-expiring token use --token-ttl 0)
[certificates] Generated ca certificate and key.
[certificates] Generated apiserver certificate and key.
[certificates] apiserver serving cert is signed for DNS names [k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.171.200]
[certificates] Generated apiserver-kubelet-client certificate and key.
[certificates] Generated sa key and public key.
[certificates] Generated front-proxy-ca certificate and key.
[certificates] Generated front-proxy-client certificate and key.
[certificates] Valid certificates and keys now exist in &amp;quot;/etc/kubernetes/pki&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;admin.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;kubelet.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;controller-manager.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;scheduler.conf&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-apiserver to &amp;quot;/etc/kubernetes/manifests/kube-apiserver.yaml&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-controller-manager to &amp;quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-scheduler to &amp;quot;/etc/kubernetes/manifests/kube-scheduler.yaml&amp;quot;
[etcd] Wrote Static Pod manifest for a local etcd instance to &amp;quot;/etc/kubernetes/manifests/etcd.yaml&amp;quot;
[init] Waiting for the kubelet to boot up the control plane as Static Pods from directory &amp;quot;/etc/kubernetes/manifests&amp;quot;
[init] This often takes around a minute; or longer if the control plane images have to be pulled.

Unfortunately, an error has occurred:
        timed out waiting for the condition

This error is likely caused by that:
        - The kubelet is not running
        - The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)
        - There is no internet connection; so the kubelet can&#39;t pull the following control plane images:
                - gcr.io/google_containers/kube-apiserver-amd64:v1.8.1
                - gcr.io/google_containers/kube-controller-manager-amd64:v1.8.1
                - gcr.io/google_containers/kube-scheduler-amd64:v1.8.1

You can troubleshoot this for example with the following commands if you&#39;re on a systemd-powered system:
        - &#39;systemctl status kubelet&#39;
        - &#39;journalctl -xeu kubelet&#39;
couldn&#39;t initialize a Kubernetes cluster
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また違う感じのエラー。
エラーメッセージに従って、&lt;code&gt;journalctl -xeu kubelet&lt;/code&gt;でログを見てみたら、以下のようなエラーが。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Post https://192.168.171.200:6443/api/v1/nodes: dial tcp 192.168.171.200:6443: getsockopt: connection refused
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/kubeadm/issues/228&#34;&gt;kubeadmにIssue&lt;/a&gt;にこのエラーが載っている。
原因はいろいろあるっぽいけど、そのひとつにSELinuxがあったので確認してみたら、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# getenforce
Enforcing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SELinuxが有効になっていた。
&lt;code&gt;setenforce 0&lt;/code&gt;もOS再起動で元に戻ってしまった模様。&lt;/p&gt;

&lt;p&gt;永続的にSELinuxを無効にするため、&lt;code&gt;/etc/selinux/config&lt;/code&gt;を編集して、&lt;code&gt;SELINUX&lt;/code&gt;を&lt;code&gt;disabled&lt;/code&gt;にして、OS再起動した。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、&lt;code&gt;kubeadm reset&lt;/code&gt;したら3回目の&lt;code&gt;kubeadm init&lt;/code&gt;する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubeadm init --apiserver-advertise-address=192.168.171.200
[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
[init] Using Kubernetes version: v1.8.1
[init] Using Authorization modes: [Node RBAC]
[preflight] Running pre-flight checks
[kubeadm] WARNING: starting in 1.8, tokens expire after 24 hours by default (if you require a non-expiring token use --token-ttl 0)
[certificates] Generated ca certificate and key.
[certificates] Generated apiserver certificate and key.
[certificates] apiserver serving cert is signed for DNS names [k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.171.200]
[certificates] Generated apiserver-kubelet-client certificate and key.
[certificates] Generated sa key and public key.
[certificates] Generated front-proxy-ca certificate and key.
[certificates] Generated front-proxy-client certificate and key.
[certificates] Valid certificates and keys now exist in &amp;quot;/etc/kubernetes/pki&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;admin.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;kubelet.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;controller-manager.conf&amp;quot;
[kubeconfig] Wrote KubeConfig file to disk: &amp;quot;scheduler.conf&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-apiserver to &amp;quot;/etc/kubernetes/manifests/kube-apiserver.yaml&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-controller-manager to &amp;quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&amp;quot;
[controlplane] Wrote Static Pod manifest for component kube-scheduler to &amp;quot;/etc/kubernetes/manifests/kube-scheduler.yaml&amp;quot;
[etcd] Wrote Static Pod manifest for a local etcd instance to &amp;quot;/etc/kubernetes/manifests/etcd.yaml&amp;quot;
[init] Waiting for the kubelet to boot up the control plane as Static Pods from directory &amp;quot;/etc/kubernetes/manifests&amp;quot;
[init] This often takes around a minute; or longer if the control plane images have to be pulled.
[apiclient] All control plane components are healthy after 99.510003 seconds
[uploadconfig]?Storing the configuration used in ConfigMap &amp;quot;kubeadm-config&amp;quot; in the &amp;quot;kube-system&amp;quot; Namespace
[markmaster] Will mark node k8s-master as master by adding a label and a taint
[markmaster] Master k8s-master tainted and labelled with key/value: node-role.kubernetes.io/master=&amp;quot;&amp;quot;
[bootstraptoken] Using token: 957b7b.eaaf0cb656edba7b
[bootstraptoken] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstraptoken] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstraptoken] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstraptoken] Creating the &amp;quot;cluster-info&amp;quot; ConfigMap in the &amp;quot;kube-public&amp;quot; namespace
[addons] Applied essential addon: kube-dns
[addons] Applied essential addon: kube-proxy

Your Kubernetes master has initialized successfully!

To start using your cluster, you need to run (as a regular user):

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run &amp;quot;kubectl apply -f [podnetwork].yaml&amp;quot; with one of the options listed at:
  http://kubernetes.io/docs/admin/addons/

You can now join any number of machines by running the following on each node
as root:

  kubeadm join --token 957b7b.eaaf0cb656edba7b 192.168.171.200:6443 --discovery-token-ca-cert-hash sha256:7d16ade2b651ebac573368b1b4db5c0f1236979584e61833efe90a96ff34ae2e
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できた。
このメッセージの最後に書かれたコマンドを、後でNodeを追加するときに使う。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;kubectlがこのVM上のkube-apiserverと話せるように、コンテキストを設定する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# mkdir -p $HOME/.kube
[root@k8s-master ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
[root@k8s-master ~]# chown $(id -u):$(id -g) $HOME/.kube/config
[root@k8s-master ~]# kubectl get nodes
NAME         STATUS     ROLES     AGE       VERSION
k8s-master   NotReady   master    16m       v1.8.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;podネットワークアドオンインストール&#34;&gt;Podネットワークアドオンインストール&lt;/h3&gt;

&lt;p&gt;Podネットワークはアプリのデプロイの前にセットアップしておく必要がある。&lt;/p&gt;

&lt;p&gt;多くの選択肢があるなか、有名な&lt;a href=&#34;https://github.com/coreos/flannel&#34;&gt;Flannel&lt;/a&gt;にしようと思ったけど、Flannelを使うには
&lt;code&gt;kubeadm init&lt;/code&gt;時に&lt;code&gt;--pod-network-cidr=10.244.0.0/16&lt;/code&gt;を渡さないといけなかった。
やり直すのは面倒なので代わりに&lt;a href=&#34;https://www.weave.works/docs/net/latest/kube-addon/&#34;&gt;Weave Net&lt;/a&gt;にする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# export kubever=$(kubectl version | base64 | tr -d &#39;\n&#39;)
[root@k8s-master ~]# kubectl apply -f &amp;quot;https://cloud.weave.works/k8s/net?k8s-version=$kubever&amp;quot;
serviceaccount &amp;quot;weave-net&amp;quot; created
clusterrole &amp;quot;weave-net&amp;quot; created
clusterrolebinding &amp;quot;weave-net&amp;quot; created
daemonset &amp;quot;weave-net&amp;quot; created
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これでPodネットワークアドオンインストール完了。
しばらくして、&lt;code&gt;kube-dns&lt;/code&gt;のPodが起動していれば(i.e. STATUSがRunningになってれば)OK。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubectl get pods --all-namespaces
NAMESPACE     NAME                                 READY     STATUS    RESTARTS   AGE
kube-system   etcd-k8s-master                      1/1       Running   0          1m
kube-system   kube-apiserver-k8s-master            1/1       Running   0          1m
kube-system   kube-controller-manager-k8s-master   1/1       Running   0          1m
kube-system   kube-dns-545bc4bfd4-xtlnh            3/3       Running   0          6m
kube-system   kube-proxy-922wk                     1/1       Running   0          6m
kube-system   kube-scheduler-k8s-master            1/1       Running   0          1m
kube-system   weave-net-s2kkw                      2/2       Running   0          2m
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;masterにpodをデプロイさせる設定&#34;&gt;MasterにPodをデプロイさせる設定&lt;/h3&gt;

&lt;p&gt;デフォルトでは、セキュリティの都合でMasterコンポーネントが動くNodeにはPodがデプロイされない。
けど、VM2個でPodを分散デプロイしてみたいので、この縛りを外しておく。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubectl taint nodes --all node-role.kubernetes.io/master-
node &amp;quot;k8s-master&amp;quot; untainted
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でMasterのセットアップは完了。&lt;/p&gt;

&lt;h2 id=&#34;node追加&#34;&gt;Node追加&lt;/h2&gt;

&lt;p&gt;次にNodeをひとつ追加する。&lt;/p&gt;

&lt;p&gt;k8s-masterで&lt;code&gt;kubeadm init&lt;/code&gt;するまえに撮ったスナップショットをクローンして、ホスト名とIPアドレスを変更し、これを追加するNodeのマシン(k8s-node)にする。
クローンしたらMACアドレスもproduct_uuidも変わったので、問題なく使えそう。&lt;/p&gt;

&lt;p&gt;k8s-nodeをクラスタに追加するには、このVM上で、&lt;code&gt;kubeadm init&lt;/code&gt;成功時のメッセージの最後に表示されたコマンド(i.e. &lt;code&gt;kubeadm join&lt;/code&gt;)を実行するだけ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-node ~]# kubeadm join --token 957b7b.eaaf0cb656edba7b 192.168.171.200:6443 --discovery-token-ca-cert-hash sha256:7d16ade2b651ebac573368b1b4db5c0f1236979584e61833efe90a96ff34ae2e
[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
[preflight] Running pre-flight checks
[discovery] Trying to connect to API Server &amp;quot;192.168.171.200:6443&amp;quot;
[discovery] Created cluster-info discovery client, requesting info from &amp;quot;https://192.168.171.200:6443&amp;quot;
[discovery] Requesting info from &amp;quot;https://192.168.171.200:6443&amp;quot; again to validate TLS against the pinned public key
[discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server &amp;quot;192.168.171.200:6443&amp;quot;
[discovery] Successfully established connection with API Server &amp;quot;192.168.171.200:6443&amp;quot;
[bootstrap] Detected server version: v1.8.1
[bootstrap] The server supports the Certificates API (certificates.k8s.io/v1beta1)

Node join complete:
* Certificate signing request sent to master and response
  received.
* Kubelet informed of new secure connection details.

Run &#39;kubectl get nodes&#39; on the master to see this machine join.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できた。
k8s-masterでNodeの状態を確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@k8s-master ~]# kubectl get nodes
NAME         STATUS    ROLES     AGE       VERSION
k8s-master   Ready     master    42m       v1.8.1
k8s-node     Ready     &amp;lt;none&amp;gt;    45s       v1.8.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;k8s-masterもk8s-nodeもReady。&lt;/p&gt;

&lt;h2 id=&#34;vmホストのkubectlの設定&#34;&gt;VMホストのkubectlの設定&lt;/h2&gt;

&lt;p&gt;kubectlはkube-apiserverのWeb APIを呼ぶコマンドなので、接続先さえちゃんと設定すればMasterのマシン上でなくても使える。
VMのホスト(i.e. Windows 10 PC)で使えるようにしたい。&lt;/p&gt;

&lt;p&gt;kubectlの接続先情報は、&lt;code&gt;kubeadm init&lt;/code&gt;時に生成された&lt;code&gt;/etc/kubernetes/admin.conf&lt;/code&gt;に書かれているので、これをホストに持ってきてkubectlに渡してやればいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf get nodes
NAME         STATUS    ROLES     AGE       VERSION
k8s-master   Ready     master    51m       v1.8.1
k8s-node     Ready     &amp;lt;none&amp;gt;    10m       v1.8.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できた。&lt;/p&gt;

&lt;p&gt;admin.confを&lt;code&gt;%UserProfile%\.kube\&lt;/code&gt;の下に&lt;code&gt;config&lt;/code&gt;という名前で置いてやると、&lt;code&gt;--kubeconfig&lt;/code&gt;で指定しなくても読んでくれる。&lt;/p&gt;

&lt;h2 id=&#34;goslingsデプロイ&#34;&gt;Goslingsデプロイ&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/11/goslings-on-kubernetes-cont/#%E7%95%AA%E5%A4%96%E7%B7%A82-%E5%91%BD%E4%BB%A4%E7%9A%84%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E8%A8%AD%E5%AE%9A&#34;&gt;「Kubernetesのチュートリアルをやる」の番外編&lt;/a&gt;で作ったオブジェクト定義ファイルを使って、今回作ったクラスタに&lt;a href=&#34;https://www.kaitoy.xyz/2016/12/11/goslings-development-memo0-intro-design/&#34;&gt;Goslings&lt;/a&gt;をデプロイしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf create -f deploy_goslings.yml
deployment &amp;quot;goslings-sample&amp;quot; created

C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf create -f service_goslings.yml
service &amp;quot;goslings-sample&amp;quot; created

C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf get po -o wide
NAME                              READY     STATUS    RESTARTS   AGE       IP           NODE
goslings-sample-dfd84c69c-4mgh9   1/1       Running   0          12m       10.244.1.3   k8s-node
goslings-sample-dfd84c69c-cd5mm   1/1       Running   0          12m       10.244.0.3   k8s-master
goslings-sample-dfd84c69c-nwwh7   1/1       Running   0          12m       10.244.1.2   k8s-node

C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf get svc
NAME              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
goslings-sample   NodePort    10.109.174.204   &amp;lt;none&amp;gt;        8080:30004/TCP   7m
kubernetes        ClusterIP   10.96.0.1        &amp;lt;none&amp;gt;        443/TCP          1h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;普通にデプロイできた。
レプリカ3つがちゃんと2つのNodeに分散されてる。&lt;/p&gt;

&lt;p&gt;k8s-masterのIPアドレス( &lt;a href=&#34;http://192.168.171.200:30004/&#34;&gt;http://192.168.171.200:30004/&lt;/a&gt; )でもk8s-nodeのIPアドレス( &lt;a href=&#34;http://192.168.171.201:30004/&#34;&gt;http://192.168.171.201:30004/&lt;/a&gt; )でもGoslingsにつなげた。
普通はMasterのIPアドレスを使うらしい。
そりゃそうか。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/build-kubernetes-cluster-by-kubeadm/goslings.png&#34; alt=&#34;goslings&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;試しにk8s-nodeのVMを落としてみる。
k8s-node上のPodがk8s-masterに移動してくれることを期待してたけど、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf get po -o wide
NAME                              READY     STATUS    RESTARTS   AGE       IP           NODE
goslings-sample-dfd84c69c-4mgh9   1/1       Running   0          55m       10.244.1.3   k8s-node
goslings-sample-dfd84c69c-cd5mm   1/1       Running   0          55m       10.244.0.3   k8s-master
goslings-sample-dfd84c69c-nwwh7   1/1       Running   0          55m       10.244.1.2   k8s-node
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なんかk8s-nodeで動き続けていることになってる。&lt;/p&gt;

&lt;p&gt;クラスタうまく動いていないんだろうか…&lt;/p&gt;

&lt;h2 id=&#34;ダッシュボードデプロイ&#34;&gt;ダッシュボードデプロイ&lt;/h2&gt;

&lt;p&gt;Kubernetesクラスタの状態をWeb UIで確認できる、&lt;a href=&#34;https://github.com/kubernetes/dashboard&#34;&gt;Dashboard&lt;/a&gt;をデプロイしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop&amp;gt;kubectl --kubeconfig admin.conf apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml
secret &amp;quot;kubernetes-dashboard-certs&amp;quot; created
serviceaccount &amp;quot;kubernetes-dashboard&amp;quot; created
role &amp;quot;kubernetes-dashboard-minimal&amp;quot; created
rolebinding &amp;quot;kubernetes-dashboard-minimal&amp;quot; created
deployment &amp;quot;kubernetes-dashboard&amp;quot; created
service &amp;quot;kubernetes-dashboard&amp;quot; created
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できた。&lt;/p&gt;

&lt;p&gt;Dashboardが起動するまでしばらくまってから、&lt;code&gt;kubectl proxy&lt;/code&gt;して、
&lt;code&gt;http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/&lt;/code&gt;にブラウザでつなげばGUIが開くはずなんだけど、タイムアウトしてつながらなかった。&lt;/p&gt;

&lt;p&gt;クラスタうまく動いていないんだろうか…&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;NICがNATなのがだめだったかもと思い、ブリッジにしてみたけど同じ結果だった。
PodのフェールオーバーもしないしDashboardも開けない。&lt;/p&gt;

&lt;p&gt;ちゃんと一つ一つ自分で構築しないとよく分からないな。&lt;/p&gt;

&lt;p&gt;(後日&lt;a href=&#34;https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/&#34;&gt;全手動で構築した&lt;/a&gt;。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あとでふと思い立って、&lt;code&gt;/etd/hosts&lt;/code&gt;をいじったらDashboardは動いた。
それについてはまた&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/31/retry-dashboard-on-k8s-cluster-by-kubeadm/&#34;&gt;別の記事&lt;/a&gt;で。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetesのチュートリアルをやる</title>
          <link>https://www.kaitoy.xyz/2017/10/11/goslings-on-kubernetes-cont/</link>
          <pubDate>Wed, 11 Oct 2017 23:48:40 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/10/11/goslings-on-kubernetes-cont/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/&#34;&gt;Kubernetes 1.8が出たので、Minikubeを触ってみる&lt;/a&gt;」の続き。
Minikubeのセットアップまではできたので、&lt;a href=&#34;https://kubernetes.io/docs/tutorials/kubernetes-basics/&#34;&gt;Kubernetes Basics&lt;/a&gt;というチュートリアルをやりながら、&lt;a href=&#34;https://kaitoy.github.io/goslings/&#34;&gt;Goslings&lt;/a&gt;をデプロイする。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;kubernetes-basics-概要&#34;&gt;Kubernetes Basics - 概要&lt;/h2&gt;

&lt;p&gt;Kubernetes Basicsは、公式のチュートリアルで、Kubernetesクラスタのオーケストレーションの基本を学ぶことができるもの。
以下の6つのモジュールからなる。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Kubernetesクラスタを作る&lt;/li&gt;
&lt;li&gt;アプリをデプロイする&lt;/li&gt;
&lt;li&gt;アプリを調査する&lt;/li&gt;
&lt;li&gt;アプリを公開する&lt;/li&gt;
&lt;li&gt;アプリをスケールする&lt;/li&gt;
&lt;li&gt;アプリをアップデートする&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;チュートリアルで使うのは&lt;a href=&#34;https://github.com/kubernetes/minikube&#34;&gt;Minikube&lt;/a&gt;だけど、自分でセットアップする必要はない。
&lt;a href=&#34;https://www.katacoda.com/&#34;&gt;Katacoda&lt;/a&gt;という、ブラウザ上でIT技術を学べるプラットフォームがあり、Kubernetes Basicsはそれを利用して、ブラウザ上のターミナルからホステッドMinikubeを操作できるようにしている。&lt;/p&gt;

&lt;p&gt;が、&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/&#34;&gt;前回の記事&lt;/a&gt;で自PC上にMinikubeをセットアップしたので、そちらを使うことにする。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;kubernetes-basics-モジュール-1-kubernetesクラスタを作る&#34;&gt;Kubernetes Basics - モジュール 1: Kubernetesクラスタを作る&lt;/h2&gt;

&lt;p&gt;Minikubeを起動してkubectlでクラスタの状態をみるだけのモジュール。&lt;/p&gt;

&lt;p&gt;これは&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/&#34;&gt;前回の記事&lt;/a&gt;でカバーしている。&lt;/p&gt;

&lt;h2 id=&#34;kubernetes-basics-モジュール-2-アプリをデプロイする&#34;&gt;Kubernetes Basics - モジュール 2: アプリをデプロイする&lt;/h2&gt;

&lt;p&gt;アプリ(i.e. コンテナ)をデプロイするにはDeploymentオブジェクトを作る。
MasterはDeploymentのspecに従って各ノードにアプリのインスタンスをスケジューリングする。
Deploymentは、アプリが落ちたら再起動してくれる、つまりself-healingも実現する。&lt;/p&gt;

&lt;p&gt;Deploymentオブジェクトを作るコマンドは&lt;code&gt;kubectl run &amp;lt;オブジェクト名&amp;gt; --image=&amp;lt;Dockerイメージ名&amp;gt;&lt;/code&gt;。
Goslingsをこれでデプロイする。&lt;/p&gt;

&lt;p&gt;Goslingsコンテナは3つの引数を受け取り、指定したポートでWebサーバを起動する。
&lt;code&gt;--port&lt;/code&gt;オプションでそのポートをexposeするようにして、&lt;code&gt;--&lt;/code&gt;の後にコンテナに渡す引数を記述する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl run goslings --image=kaitoy/goslings:latest --port 8080 -- 8080 /tmp https://github.com/kaitoy/
deployment &amp;quot;goslings&amp;quot; created

C:\Users\kaitoy&amp;gt;kubectl get deployment
NAME       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
goslings   1         1         1            1           27s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;デプロイできた。
裏でPodも作られていて、アプリが起動されている。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get pods
NAME                        READY     STATUS              RESTARTS   AGE
goslings-1210510689-6w5tf   0/1       ContainerCreating   0          1m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(&lt;code&gt;kubectl get&lt;/code&gt;に指定するのは、省略形の&lt;code&gt;deploy&lt;/code&gt;とか&lt;code&gt;po&lt;/code&gt;でもいい。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Podは隔離されたネットワークで動くので、そのままではPod同士は通信できるけど、外からはアクセスできない。
kubectlでプロキシを作ってやることで、外からアクセスできるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl proxy
Starting to serve on 127.0.0.1:8001
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで、kube-apiserverへのプロキシがローカルホストで起動した。
この状態で&lt;code&gt;http://localhost:8001&lt;/code&gt;を開くと、kube-apiserverのAPI一覧が見れる。
例えば、&lt;code&gt;http://localhost:8001/version&lt;/code&gt;にアクセスすると、以下のJSONデータが返ってくる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;major&amp;quot;: &amp;quot;1&amp;quot;,
  &amp;quot;minor&amp;quot;: &amp;quot;7&amp;quot;,
  &amp;quot;gitVersion&amp;quot;: &amp;quot;v1.7.0&amp;quot;,
  &amp;quot;gitCommit&amp;quot;: &amp;quot;d3ada0119e776222f11ec7945e6d860061339aad&amp;quot;,
  &amp;quot;gitTreeState&amp;quot;: &amp;quot;dirty&amp;quot;,
  &amp;quot;buildDate&amp;quot;: &amp;quot;2017-10-04T09:25:40Z&amp;quot;,
  &amp;quot;goVersion&amp;quot;: &amp;quot;go1.8.3&amp;quot;,
  &amp;quot;compiler&amp;quot;: &amp;quot;gc&amp;quot;,
  &amp;quot;platform&amp;quot;: &amp;quot;linux/amd64&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;各Podへも以下のURLでアクセスできる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://localhost:8001/api/v1/proxy/namespaces/default/pods/&amp;lt;Pod名&amp;gt;/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Pod名の部分は&lt;code&gt;kubectl get&lt;/code&gt;で確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get po
NAME                        READY     STATUS    RESTARTS   AGE
goslings-1210510689-6w5tf   1/1       Running   0          24m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実際に、&lt;code&gt;http://localhost:8001/api/v1/proxy/namespaces/default/pods/goslings-1210510689-6w5tf/&lt;/code&gt;をブラウザで開いたら、GoslingsのGUIが出た。
ヒュー。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-on-kubernetes-cont/goslings-proxy.png&#34; alt=&#34;goslings-proxy&#34; /&gt;
&lt;/p&gt;

&lt;h2 id=&#34;kubernetes-basics-モジュール-3-アプリを調査する&#34;&gt;Kubernetes Basics - モジュール 3: アプリを調査する&lt;/h2&gt;

&lt;p&gt;以下のコマンドで、アプリの状態を調査するモジュール。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;kubectl get: リソースをリスト表示する。&lt;/li&gt;
&lt;li&gt;kubectl describe: リソースの詳細情報を表示する。&lt;/li&gt;
&lt;li&gt;kubectl logs: コンテナのログを表示する。&lt;code&gt;docker logs&lt;/code&gt;的な。&lt;/li&gt;
&lt;li&gt;kubectl exec: コンテナ内でコマンドを実行する。&lt;code&gt;docker exec&lt;/code&gt;的な。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl get&lt;/code&gt;はさんざんやったので飛ばして、&lt;code&gt;kubectl describe&lt;/code&gt;してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl describe po
Name:           goslings-1210510689-6w5tf
Namespace:      default
Node:           minikube/192.168.99.100
Start Time:     Tue, 10 Oct 2017 21:51:48 +0900
Labels:         pod-template-hash=1210510689
                run=goslings
Annotations:    kubernetes.io/created-by={&amp;quot;kind&amp;quot;:&amp;quot;SerializedReference&amp;quot;,&amp;quot;apiVersion&amp;quot;:&amp;quot;v1&amp;quot;,&amp;quot;reference&amp;quot;:{&amp;quot;kind&amp;quot;:&amp;quot;ReplicaSet&amp;quot;,&amp;quot;namespace&amp;quot;:&amp;quot;default&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;goslings-1210510689&amp;quot;,&amp;quot;uid&amp;quot;:&amp;quot;c74b6518-adb9-11e7-88a0-08002798178d...
Status:         Running
IP:             172.17.0.2
Created By:     ReplicaSet/goslings-1210510689
Controlled By:  ReplicaSet/goslings-1210510689
Containers:
  goslings:
    Container ID:       docker://ce90460886c9555f7748bf59e8d9892f05c05020e7841154ee85713d6d9b0c2d
    Image:              kaitoy/goslings:latest
    Image ID:           docker-pullable://kaitoy/goslings@sha256:a587e3c5f202cdaa6d4d5a9c4f6a01ba6f4782e00277c3a18c77dd034daa0109
    Port:               8080/TCP
    Args:
      8080
      C:/Users/kaitoy/AppData/Local/Temp
    State:              Running
      Started:          Tue, 10 Oct 2017 21:55:54 +0900
    Ready:              True
    Restart Count:      0
    Environment:        &amp;lt;none&amp;gt;
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-cqq59 (ro)
Conditions:
  Type          Status
  Initialized   True
  Ready         True
  PodScheduled  True
Volumes:
  default-token-cqq59:
    Type:       Secret (a volume populated by a Secret)
    SecretName: default-token-cqq59
    Optional:   false
QoS Class:      BestEffort
Node-Selectors: &amp;lt;none&amp;gt;
Tolerations:    &amp;lt;none&amp;gt;
Events:
  FirstSeen     LastSeen        Count   From                    SubObjectPath                   Type            Reason
                Message
  ---------     --------        -----   ----                    -------------                   --------        ------
                -------
  45m           45m             1       default-scheduler                                       Normal          Scheduled               Successfully assigned goslings-1210510689-6w5tf to minikube
  45m           45m             1       kubelet, minikube                                       Normal          SuccessfulMountVolume   MountVolume.SetUp succeeded for volume &amp;quot;default-token-cqq59&amp;quot;
  45m           45m             1       kubelet, minikube       spec.containers{goslings}       Normal          Pulling
                pulling image &amp;quot;kaitoy/goslings:latest&amp;quot;
  41m           41m             1       kubelet, minikube       spec.containers{goslings}       Normal          Pulled
                Successfully pulled image &amp;quot;kaitoy/goslings:latest&amp;quot;
  41m           41m             1       kubelet, minikube       spec.containers{goslings}       Normal          Created
                Created container
  41m           41m             1       kubelet, minikube       spec.containers{goslings}       Normal          Started
                Started container
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Podの詳細な情報が出た。
EventsのとこにKubernetesの頑張りが見えて面白い。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次は&lt;code&gt;kubectl logs&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl logs goslings-1210510689-6w5tf

  .   ____          _            __ _ _
 /\\ / ___&#39;_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | &#39;_ | &#39;_| | &#39;_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  &#39;  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v1.4.3.RELEASE)

2017-10-10 12:56:02.498  INFO 6 --- [           main] c.g.kaitoy.goslings.server.Application   : Starting Application on goslings-1210510689-6w5tf with PID 6 (/usr/local/src/goslings/goslings-server/build/libs/goslings-server-0.0.1.jar started by root in /usr/local/src/goslings)
(snip)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Goslingsは&lt;a href=&#34;https://projects.spring.io/spring-boot/&#34;&gt;Spring Boot&lt;/a&gt;でできてるので、そのログが出てる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次は&lt;code&gt;kubectl exec&lt;/code&gt;を試す。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl exec goslings-1210510689-6w5tf env
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=goslings-1210510689-6w5tf
KUBERNETES_PORT_443_TCP=tcp://10.0.0.1:443
KUBERNETES_PORT_443_TCP_PROTO=tcp
KUBERNETES_PORT_443_TCP_PORT=443
KUBERNETES_PORT_443_TCP_ADDR=10.0.0.1
KUBERNETES_SERVICE_HOST=10.0.0.1
KUBERNETES_SERVICE_PORT=443
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBERNETES_PORT=tcp://10.0.0.1:443
LANG=C.UTF-8
JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
JAVA_VERSION=8u111
JAVA_DEBIAN_VERSION=8u111-b14-2~bpo8+1
CA_CERTIFICATES_JAVA_VERSION=20140324
HOME=/root
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;env&lt;/code&gt;コマンドを実行し、コンテナ内の環境変数一覧を出せた。
Kubernetes関係の変数が定義されていることが分かる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker exec&lt;/code&gt;と同様に、&lt;code&gt;-it&lt;/code&gt;オプションを付ければ、コンテナ内に「入る」こともできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl exec -it goslings-1210510689-6w5tf sh
# ls
Dockerfile  _config.yml  build.log     goslings-server  gradle.properties  gradlew.bat
# exit

C:\Users\kaitoy&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;kubernetes-basics-モジュール-4-アプリを公開する&#34;&gt;Kubernetes Basics - モジュール 4: アプリを公開する&lt;/h2&gt;

&lt;p&gt;Serviceオブジェクト扱うモジュール。&lt;/p&gt;

&lt;p&gt;例えば、以下のような状況にあるとする。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;PodがあるNodeで動いていたんだけど、そのNodeが死んだので、Kubernetesが別のNodeにPodを起動しなおしてくれた。&lt;/li&gt;
&lt;li&gt;同じコンテナイメージを3つのPodで動かして、負荷分散させたい。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;こういう場合、KubernetesはPod毎に固有のIPアドレスを割り当てるので、Podにアクセスするユーザはアクセス先が不安定でめんどいことになる。
この問題を解決してくれるのがServiceで、こいつは、Podを抽象化して、安定したIPアドレスを公開してくれる。
しかもそれはクラスタ外からアクセスできる。&lt;/p&gt;

&lt;p&gt;PodとServiceの紐づけには、&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/&#34;&gt;ラベルとセレクタ&lt;/a&gt;というものが使われる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Serviceの情報はDeploymentとかと同様に&lt;code&gt;kubectl get&lt;/code&gt;で見れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get svc
NAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   10.0.0.1     &amp;lt;none&amp;gt;        443/TCP   1d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここで出ているkubernetesというのは、Minikubeがデフォルトで作るService。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Serviceオブジェクトは、&lt;code&gt;kubectl expose&lt;/code&gt;で作ることができる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;goslings&lt;/code&gt;という名のDeploymentに対し、NodePortのServiceを作り、コンテナの8080ポートを公開するコマンドは以下のようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl expose deploy/goslings --type=NodePort --port 8080
service &amp;quot;goslings&amp;quot; exposed

C:\Users\kaitoy&amp;gt;kubectl get services
NAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE
goslings     10.0.0.69    &amp;lt;nodes&amp;gt;       8080:32406/TCP   11s
kubernetes   10.0.0.1     &amp;lt;none&amp;gt;        443/TCP          1d

C:\Users\kaitoy&amp;gt;kubectl describe services/goslings
Name:                   goslings
Namespace:              default
Labels:                 run=goslings
Annotations:            &amp;lt;none&amp;gt;
Selector:               run=goslings
Type:                   NodePort
IP:                     10.0.0.69
Port:                   &amp;lt;unset&amp;gt; 8080/TCP
NodePort:               &amp;lt;unset&amp;gt; 32406/TCP
Endpoints:              172.17.0.2:8080
Session Affinity:       None
Events:                 &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;goslingsという名前のServiceができた。
上記&lt;code&gt;kubectl describe&lt;/code&gt;の出力のNodePortのとこに書いてあるのが外部にさらされたポート。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;minikube ip&lt;/code&gt;を実行すると、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube ip
192.168.99.100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;MinikubeのVMのIPアドレスも分かるので、NodePortのポートと合わせて、&lt;code&gt;http://192.168.99.100:32406&lt;/code&gt;にブラウザでアクセスしたら、GoslingsのGUI見れた。
ヒュー。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-on-kubernetes-cont/goslings-service.png&#34; alt=&#34;goslings-service&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ところで、上記&lt;code&gt;kubectl describe&lt;/code&gt;の出力を見ると、特に指定はしなかったが、Podに&lt;code&gt;run=goslings&lt;/code&gt;というLabelが付いていることが分かる。
Serviceのdescribeを見ると、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl describe svc goslings
Name:                   goslings
Namespace:              default
Labels:                 run=goslings
Annotations:            &amp;lt;none&amp;gt;
Selector:               run=goslings
Type:                   NodePort
IP:                     10.0.0.69
Port:                   &amp;lt;unset&amp;gt; 8080/TCP
NodePort:               &amp;lt;unset&amp;gt; 32406/TCP
Endpoints:              172.17.0.2:8080
Session Affinity:       None
Events:                 &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;run=goslings&lt;/code&gt;というSelectorがServiceに紐づいている。
つまり、ServiceとPodが、&lt;code&gt;run=goslings&lt;/code&gt;で紐づいているというわけだ。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Labelはクエリ時のフィルタとかにも使える。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get po -l run=goslings
NAME                        READY     STATUS    RESTARTS   AGE
goslings-1210510689-6w5tf   1/1       Running   0          1h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;後からラベル付けることもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl label pod goslings-1210510689-6w5tf ver=1.2.3
pod &amp;quot;goslings-1210510689-6w5tf&amp;quot; labeled
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;kubernetes-basics-モジュール-5-アプリをスケールする&#34;&gt;Kubernetes Basics - モジュール 5: アプリをスケールする&lt;/h2&gt;

&lt;p&gt;アプリのスケールアウト・スケールインを学ぶモジュール。&lt;/p&gt;

&lt;p&gt;Deploymentの定義でPodのレプリカ数を変えると、その数に合わせてKubernetesがPodを起動したり止めたりしてくれてスケールできる仕組み。
レプリカを作っておくとローリングアップデートできるのも利点。
&lt;a href=&#34;http://kubernetes.io/docs/user-guide/horizontal-pod-autoscaling/&#34;&gt;オートスケール機能&lt;/a&gt;もあるけど、それはチュートリアルでは扱われない。&lt;/p&gt;

&lt;p&gt;複数のPodで負荷分散するということなので、Serviceでロードバランシングするのが前提。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;現在のDeploymentの状態をみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get deploy
NAME       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
goslings   1         1         1            1           1h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Podのレプリカ数は、期待してる(DESIRED)のが1で、今(CURRENT)も1。&lt;/p&gt;

&lt;p&gt;スケールアウトするには、&lt;code&gt;kubectl scale&lt;/code&gt;コマンドでレプリカ数を増やしてやる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl scale deploy/goslings --replicas=3
deployment &amp;quot;goslings&amp;quot; scaled

C:\Users\kaitoy&amp;gt;kubectl get deploy
NAME       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
goslings   3         3         3            3           1h

C:\Users\kaitoy&amp;gt;kubectl get po -o wide
NAME                       READY     STATUS    RESTARTS   AGE       IP           NODE
goslings-442066424-jn1lw   1/1       Running   0          1h        172.17.0.2   minikube
goslings-442066424-rdw4k   1/1       Running   0          1m        172.17.0.3   minikube
goslings-442066424-rwwjw   1/1       Running   0          1m        172.17.0.4   minikube
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;レプリカが3個になった。&lt;/p&gt;

&lt;p&gt;スケールインするには、&lt;code&gt;kubectl scale&lt;/code&gt;コマンドでレプリカ数を減らす。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl scale deploy/goslings --replicas=2
deployment &amp;quot;goslings&amp;quot; scaled

C:\Users\kaitoy&amp;gt;kubectl get po
NAME                       READY     STATUS        RESTARTS   AGE
goslings-442066424-0mv4x   1/1       Terminating   0          1m
goslings-442066424-34h1f   1/1       Running       0          1m
goslings-442066424-kmn3p   1/1       Running       0          17m

C:\Users\kaitoy&amp;gt;kubectl get po
NAME                       READY     STATUS    RESTARTS   AGE
goslings-442066424-34h1f   1/1       Running   0          1m
goslings-442066424-kmn3p   1/1       Running   0          17m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;kubectl scale&lt;/code&gt;直後の&lt;code&gt;kubectl get po&lt;/code&gt;では、一つのPodを停止している最中の様子が見えていて、再度の&lt;code&gt;kubectl get po&lt;/code&gt;ではレプリカが2個になったのが確認できた。&lt;/p&gt;

&lt;p&gt;この状態がKubernetes Basicsで作るクラスタの最終形で、図にすると以下の感じ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-on-kubernetes-cont/objects.png&#34; alt=&#34;objects&#34; /&gt;
&lt;/p&gt;

&lt;h2 id=&#34;kubernetes-basics-モジュール-6-アプリをアップデートする&#34;&gt;Kubernetes Basics - モジュール 6: アプリをアップデートする&lt;/h2&gt;

&lt;p&gt;デプロイしたアプリのアップデート(i.e. コンテナイメージの変更)を学ぶモジュール。&lt;/p&gt;

&lt;p&gt;Deploymentの定義をいじってコンテナイメージを変えてやると、その中のPodを新しいイメージで順次(デフォルトだと一つ一つ)起動しなおしてくれる。&lt;/p&gt;

&lt;p&gt;アプリのアップデートはバージョン管理もされて、ロールバックもできる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;コンテナイメージを変更するには、&lt;code&gt;kubectl set image&lt;/code&gt;コマンドを使う。
&lt;code&gt;goslings&lt;/code&gt;という名のDeployment内の、&lt;code&gt;goslings&lt;/code&gt;という名のContainerのイメージを&lt;code&gt;kaitoy/goslings:hoge&lt;/code&gt;に変更するコマンドは以下。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl set image deploy/goslings goslings=kaitoy/goslings:hoge
deployment &amp;quot;goslings&amp;quot; image updated
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実際には&lt;code&gt;kaitoy/goslings:hoge&lt;/code&gt;というイメージはないので、イメージのPullに失敗したというエラー(ErrImagePull)になる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get po
NAME                       READY     STATUS         RESTARTS   AGE
goslings-274047280-jxmmh   0/1       ErrImagePull   0          9s
goslings-274047280-rgg2v   0/1       ErrImagePull   0          8s
goslings-442066424-34h1f   1/1       Terminating    0          1h
goslings-442066424-kmn3p   1/1       Running        0          1h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;イメージ変更前に戻すには、&lt;code&gt;kubectl rollout undo&lt;/code&gt;する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl rollout undo deploy/goslings
deployment &amp;quot;goslings&amp;quot; rolled back

C:\Users\kaitoy&amp;gt;kubectl rollout status deploy/goslings
deployment &amp;quot;goslings&amp;quot; successfully rolled out

C:\Users\kaitoy&amp;gt;kubectl get po
NAME                       READY     STATUS    RESTARTS   AGE
goslings-442066424-kmn3p   1/1       Running   0          1h
goslings-442066424-m3873   1/1       Running   0          5s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;無事に戻った。&lt;/p&gt;

&lt;h2 id=&#34;番外編1-3つのオブジェクト管理手法&#34;&gt;番外編1 - 3つのオブジェクト管理手法&lt;/h2&gt;

&lt;p&gt;Kubernetesオブジェクトを管理する手法は&lt;a href=&#34;https://kubernetes.io/docs/tutorials/object-management-kubectl/object-management/&#34;&gt;大きく3つある&lt;/a&gt;。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;管理手法&lt;/th&gt;
&lt;th&gt;いじる対象&lt;/th&gt;
&lt;th&gt;難易度&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;命令的コマンド&lt;/td&gt;
&lt;td&gt;生のオブジェクト&lt;/td&gt;
&lt;td&gt;簡単&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;命令的オブジェクト設定&lt;/td&gt;
&lt;td&gt;個々のファイル&lt;/td&gt;
&lt;td&gt;普通&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;宣言的オブジェクト設定&lt;/td&gt;
&lt;td&gt;ディレクトリに入ったファイル群&lt;/td&gt;
&lt;td&gt;難しい&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Kubernetes Basicsでやってた手法は一番上の命令的コマンド。
これは簡単で分かりやすい。
けど、何度も同じようなデプロイするならコマンドを毎回打つのが面倒だし、作成されるオブジェクトは明示的じゃないし、変更管理もできない。
この手法は主に開発中に使う。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;二つ目の手法の命令的オブジェクト設定では、YAML(かJSON)ファイルにオブジェクト定義を書いておいて、kubectlに渡す。
この手法だと、定義ファイルをオブジェクトのテンプレートとして使えるし、Gitとかのリポジトリに入れることでバージョン管理・変更管理できる。
けど、Kubernetesのオブジェクトモデルを理解しないと使えない。
(オブジェクト定義の詳細は&lt;a href=&#34;https://kubernetes.io/docs/api-reference/v1.8/&#34;&gt;APIリファレンス&lt;/a&gt;を参照。)&lt;/p&gt;

&lt;p&gt;命令的オブジェクト設定は以下のような形でやる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ kubectl create -f nginx.yaml
$ kubectl delete -f nginx.yaml -f redis.yaml
$ kubectl replace -f nginx.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;三つ目の手法の宣言的オブジェクト設定では、設定フォルダに定義ファイル群を置く。
ユーザは明示的にcreateとかupdateとか指示する必要が無く、kubectlが勝手に判断してくれる。
生のオブジェクトを直接いじった後、同じオブジェクトの設定を設定ファイルで変更しても、
両者の変更が上手くマージされる。&lt;/p&gt;

&lt;p&gt;なんかすごいけど、上手くいかなかったときのデバッグがむずい。&lt;/p&gt;

&lt;p&gt;宣言的オブジェクト設定は以下のような形でやる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ kubectl apply -R -f configs/
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;番外編2-命令的オブジェクト設定&#34;&gt;番外編2 - 命令的オブジェクト設定&lt;/h2&gt;

&lt;p&gt;3つの手法の内、命令的オブジェクト設定でGoslingsをMinikubeにデプロイしてみる。&lt;/p&gt;

&lt;p&gt;まず、Kubernetes Basicsで作ったオブジェクトを消すため、MinikubeのVMを作り直す。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube stop
Stopping local Kubernetes cluster...
Machine stopped.

C:\Users\kaitoy&amp;gt;minikube delete
Deleting local Kubernetes cluster...
Machine deleted.

C:\Users\kaitoy&amp;gt;minikube start --vm-driver virtualbox --kubernetes-version v1.7.0
Starting local Kubernetes v1.7.0 cluster...
Starting VM...
Getting VM IP address...
Moving files into cluster...
Setting up certs...
Connecting to cluster...
Setting up kubeconfig...
Starting cluster components...
Kubectl is now configured to use the cluster.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次に定義ファイルを書いていく。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://v1-7.docs.kubernetes.io/docs/api-reference/v1.7/#deployment-v1beta1-apps&#34;&gt;APIリファレンスのDeploymentのとこ&lt;/a&gt;をみると、Kubernetes Basicsの最終形と同じようなDeploymentを作る定義は以下のように書ける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: goslings-sample
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: goslings
        ver: latest
    spec:
      containers:
        - name: goslings
          image: kaitoy/goslings:latest
          ports:
            - name: http
              containerPort: 8080
          args:
            - &#39;8080&#39;
            - /tmp
            - https://github.com/kaitoy/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同様に、Serviceは、&lt;a href=&#34;https://v1-7.docs.kubernetes.io/docs/api-reference/v1.7/#service-v1-core&#34;&gt;APIリファレンスのServiceのとこ&lt;/a&gt;みると以下のように書ける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;kind: Service
apiVersion: v1
metadata:
  name: goslings-sample
spec:
  ports:
    - name: http
      port: 8080
      targetPort: 8080
  selector:
    app: goslings
  type: NodePort
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、それぞれのYAMLファイルを&lt;code&gt;kubectl create&lt;/code&gt;に渡してやると、Goslingsデプロイ完了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\kubeTest&amp;gt;kubectl create -f deploy_goslings.yml
deployment &amp;quot;goslings-sample&amp;quot; created

C:\Users\kaitoy\kubeTest&amp;gt;kubectl create -f service_goslings.yml
service &amp;quot;goslings-sample&amp;quot; created
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;オブジェクトの種類もパラメータも大量にあるので、使いこなすのは難しそう。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Kubernetes 1.8が出たので、Minikubeを触ってみる</title>
          <link>https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/</link>
          <pubDate>Tue, 10 Oct 2017 00:10:59 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt;1.8のリリースが話題になっていたので、ちょっと触って見たという話。
(1.8を触ったとは言っていない。)&lt;/p&gt;

&lt;p&gt;具体的には、&lt;a href=&#34;https://kubernetes.io/docs/tutorials/kubernetes-basics/&#34;&gt;Kubernetes Basics&lt;/a&gt;というチュートリアルをやりながら、&lt;a href=&#34;https://github.com/kubernetes/minikube&#34;&gt;Minikube&lt;/a&gt;に&lt;a href=&#34;https://kaitoy.github.io/goslings/&#34;&gt;Goslings&lt;/a&gt;をデプロイしたんだけど、この記事ではMinikubeをセットアップしたところまで。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;kubernetesとは&#34;&gt;Kubernetesとは&lt;/h2&gt;

&lt;p&gt;KubernetesはOSSのコンテナオーケストレーションツール。
英語だとクーバネティスみたいに発音する。
Googleが自身のコンテナ技術である&lt;a href=&#34;https://research.google.com/pubs/pub43438.html&#34;&gt;Borg&lt;/a&gt;の運用で培ったノウハウを活かして開発したもの。
2014年ころに開発が始まり、2015年夏にv1がリリースされたということで、かなり新しいツール。
よく比べられるものには&lt;a href=&#34;https://docs.docker.com/engine/swarm/&#34;&gt;DockerのSwarmモード&lt;/a&gt;や&lt;a href=&#34;http://mesos.apache.org/&#34;&gt;Apache Mesos&lt;/a&gt;があるが、何が違うのかは調べてないので知らない。
ただ、Dockerコンテナ管理ツールとしてはKubernetesが一番勢いがある雰囲気を感じる。&lt;/p&gt;

&lt;p&gt;(2017/10/18追記: &lt;a href=&#34;http://www.publickey1.jp/blog/17/dockerkubernetesdockercon_eu_2017.html&#34;&gt;DockerがKubernetesとの統合を発表&lt;/a&gt;した。KubernetesはDockerネイティブなツールになり、Dockerとともにインストールされ、Docker ComposeのConposeファイルでデプロイできるようになったりする。Kubernetesの大勝利っぽい。)&lt;/p&gt;

&lt;p&gt;Kubernetesを使うと、複数の物理マシンからなるHAクラスタ(Kubernetesクラスタ)を構成し、その上にコンテナをデプロイして管理できる。
Kubernetesクラスタは、一組のMasterコンポーネント群(a.k.a. Kubernetes Control Plane、または単にMaster)と一つ以上のNode(昔はMinionと呼ばれてたもの)で構成される。
Nodeは、Masterの管理下でコンテナを実行する機能を備えた、一台のVMや物理マシン。
MasterはNode上で動き、クラスタを管理し、コンテナのスケジューリング、状態管理、スケーリング、アップデートなどを担う。&lt;/p&gt;

&lt;p&gt;Kubernetesの&lt;a href=&#34;https://github.com/kubernetes/community/blob/master/contributors/design-proposals/architecture/architecture.md&#34;&gt;アーキテクチャ&lt;/a&gt;を図にすると以下の感じ。
矢印の向きとかはちょっと間違ってるかも。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-on-kubernetes/architecture.png&#34; alt=&#34;architecture&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;ごちゃごちゃするので省いたけど、図の下部のNode内のコンポーネントは、他のNode内でも動いている。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Masterには&lt;a href=&#34;https://kubernetes.io/docs/admin/kube-apiserver/&#34;&gt;kube-apiserver&lt;/a&gt;が含まれていて、&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/kubernetes-api/&#34;&gt;Kubernetes API&lt;/a&gt;というREST APIを公開する。
このAPIを通して&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/&#34;&gt;Kubernetesオブジェクト&lt;/a&gt;を定義したりすることで、宣言的にコンテナの管理ができる仕組み。
ユーザは普通、&lt;a href=&#34;https://kubernetes.io/docs/user-guide/kubectl/&#34;&gt;kubectl&lt;/a&gt;(キューブシーティーエル)というコマンドでkube-apiserverとやり取りする。&lt;/p&gt;

&lt;p&gt;KubernetesオブジェクトはMasterの&lt;a href=&#34;https://github.com/coreos/etcd&#34;&gt;etcd&lt;/a&gt;によって分散キーバリューストアに永続化され、そのストアを&lt;a href=&#34;https://kubernetes.io/docs/admin/kube-controller-manager/&#34;&gt;kube-controller-manager&lt;/a&gt;と&lt;a href=&#34;https://kubernetes.io/docs/admin/kube-scheduler/&#34;&gt;kube-scheduler&lt;/a&gt;が(kube-apiserver経由で)watchしてて、変更に応じた処理をする。&lt;/p&gt;

&lt;p&gt;kube-controller-managerは、ノードの管理や、オブジェクトのライフサイクルの管理や、コンテナのスケーリングなど、クラスタレベルの機能を実行する。
(よくわからない。)&lt;/p&gt;

&lt;p&gt;kube-schedulerは、コンテナを実行するホストを選出し、コンテナのスケジューリングをする。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;一方、各Nodeでは、&lt;a href=&#34;https://kubernetes.io/docs/admin/kubelet/&#34;&gt;kubelet&lt;/a&gt;(キューブレット)というMasterのエージェントになるプロセスが動く。&lt;/p&gt;

&lt;p&gt;kubeletはkube-apiserverからの指示で、コンテナイメージを取得してコンテナを起動したり監視したり止めたりする。&lt;/p&gt;

&lt;p&gt;kubeletがコンテナを扱うためのコンテナランタイムは、普通は&lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt;だけど、&lt;a href=&#34;https://coreos.com/rkt/&#34;&gt;rkt&lt;/a&gt;とか&lt;a href=&#34;https://github.com/kubernetes-incubator/cri-o&#34;&gt;cri-o&lt;/a&gt;とか&lt;a href=&#34;https://github.com/kubernetes/frakti&#34;&gt;frakti&lt;/a&gt;とかも使える。&lt;a href=&#34;https://github.com/opencontainers/runc&#34;&gt;runc&lt;/a&gt;や&lt;a href=&#34;https://github.com/oracle/railcar&#34;&gt;RailCar&lt;/a&gt;はどうなんだろう。&lt;/p&gt;

&lt;p&gt;コンテナはデフォルトではクラスタ内のプライベートネットワークにつながるので、そこで動いているアプリにユーザからアクセスするには、何らかの形でトラフィックを中継してやる必要がある。
これをするのが&lt;a href=&#34;https://kubernetes.io/docs/admin/kube-proxy/&#34;&gt;kube-proxy&lt;/a&gt;。
ロードバランシングもしてくれる。&lt;/p&gt;

&lt;h2 id=&#34;kubernetesオブジェクトとは&#34;&gt;Kubernetesオブジェクトとは&lt;/h2&gt;

&lt;p&gt;Kubernetesオブジェクトは、Kubernetesクラスタ上で機能する構成要素を表現するもの。
オブジェクトは&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/#object-spec-and-status&#34;&gt;specとstatus&lt;/a&gt;を持ち、オブジェクトに期待する状態やふるまい(spec)を定義しておくと、Kubernetesが実際の状態(status)をそれに合わせてくれる。
宣言的。&lt;/p&gt;

&lt;p&gt;オブジェクトには以下のようなものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/&#34;&gt;Pod&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;デプロイの最小単位。
一つ(またはリソースを共有する複数)のコンテナと、ストレージ、ネットワークなどを内包する。
一つのPodには一つのIPアドレスが付く。&lt;/p&gt;

&lt;p&gt;kubeletはPodの定義に従ってコンテナを起動する。&lt;/p&gt;

&lt;p&gt;因みに、etcd以外のMasterコンポーネントもPodとしてデプロイされる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/&#34;&gt;Service&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Podの論理グループ。
PodのIPアドレスは外部に公開されないので、外とのやり取りをするためにServiceがある。
kube-proxyはこいつの定義に従って働く。&lt;/p&gt;

&lt;p&gt;Serviceには複数のEndpoint(i.e. Pod等)が紐づき、外部からのトラフィックをラウンドロビンでルーティングするので、冗長化やロードバランサ的な働きもする。
ServiceはPodを抽象化するので、Podが死んだり入れ替わったりしても外に影響が見えにくくなる。&lt;/p&gt;

&lt;p&gt;Serviceには以下のtypeがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ClusterIP (デフォルト): Kubernetesクラスタ内からだけアクセスできる内部IPアドレスだけをもつ。&lt;/li&gt;
&lt;li&gt;NodePort: ClusterIPの拡張。内部IPアドレスに加え、クラスタ外からアクセスできるポートを一つ持つ。&lt;/li&gt;
&lt;li&gt;LoadBalancer: NodePortの拡張。外部ロードバランサを作って、固定の外部IPアドレスを付けて、内部IPアドレスへルーティングする。&lt;/li&gt;
&lt;li&gt;ExternalName: 抽象名をもつサービス。Kubernetes DNS serverで名前解決する。&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/&#34;&gt;詳細&lt;/a&gt;は読んでないので知らない。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/volumes/&#34;&gt;Volume&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;永続化やPod内でのファイル共有のためのオブジェクト。
Podとともに作られ、Podとともに破棄される。
実態はファイルシステム上のディレクトリ。
hostPathとか、nfsとか、awsElasticBlockStoreとかの種類があるらしい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/&#34;&gt;Namespace&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;仮想クラスタを表すオブジェクト。
これを定義すると、ひとつの物理クラスタを複数の仮想クラスタに分割できる。
大規模ユーザ・プロジェクト向け機能。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Controller&lt;/p&gt;

&lt;p&gt;Podを管理するオブジェクト。レプリケーションしたり、スケーリングや自動再起動したり。&lt;/p&gt;

&lt;p&gt;以下のようなものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&#34;&gt;Deployment&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Podのデプロイを管理するオブジェクト。
PodとReplicaSetの宣言的な生成・更新を実現する。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/&#34;&gt;ReplicaSet&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;指定した数のPodのレプリカを維持してくれる。
基本はDeploymentから作られて、Podの作成・削除・更新をオーケストレイトする。
&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller/&#34;&gt;ReplicationController&lt;/a&gt;というのもあるけど、今はReplicaSetが推奨。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/&#34;&gt;StatefulSet&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ステートフルなアプリを管理するオブジェクト。
現時点でのKubernetes最新版の1.8でまだベータ。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/&#34;&gt;DaemonSet&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;全てのノードで動くアプリを実現するオブジェクト。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/&#34;&gt;Job&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ジョブを表すオブジェクト。
指定された回数、Podを成功で完了させる。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;オブジェクトには&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/&#34;&gt;ラベル&lt;/a&gt;というキーバリューな属性を付けることができ、PodとServiceの紐づけや、オブジェクト検索時のフィルタとかに使える。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今回Goslingsを動かすのに使ったのは、Pod、Deployment、ReplicaSet、Service (NodePort)。&lt;/p&gt;

&lt;h2 id=&#34;podネットワーク&#34;&gt;Podネットワーク&lt;/h2&gt;

&lt;p&gt;ちょっと細かい話だけど、Pod間の通信はどうなっているかという話についてちょっと調べたのでざっくり書いておく。&lt;/p&gt;

&lt;p&gt;普通の&lt;a href=&#34;https://www.kaitoy.xyz/2015/07/25/how-to-capture-packets-on-a-local-network-with-pcap4j-container/#docker-network&#34;&gt;Dockerネットワーク&lt;/a&gt;だと、コンテナはdocker0という仮想ブリッジ上のプライベートネットワークで動くため、同じホスト上のコンテナ間は通信できるけど、別のホスト上のコンテナ通信させたい場合は、ホストのIPアドレスのポートを割り当ててやらなければいけない。&lt;/p&gt;

&lt;p&gt;これはめんどいので、Kubernetesは、各Podに一意なIPアドレスを与え、Podがどのホストにいるかにかかわらず、NAT無しで相互に通信できる&lt;a href=&#34;https://kubernetes.io/docs/concepts/cluster-administration/networking/&#34;&gt;ネットワーク&lt;/a&gt;を提供する。
これがPodネットワークとか呼ばれ、その仕様は&lt;a href=&#34;https://github.com/containernetworking/cni&#34;&gt;CNI&lt;/a&gt;でオープンに定められていて、以下のような実装がある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.projectcalico.org/v2.6/getting-started/kubernetes/installation/hosted/kubeadm/&#34;&gt;Calico&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/projectcalico/canal/tree/master/k8s-install&#34;&gt;Canal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/coreos/flannel&#34;&gt;Flannel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudnativelabs/kube-router/blob/master/Documentation/kubeadm.md&#34;&gt;Kube-router&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/romana/romana/tree/master/containerize#using-kubeadm&#34;&gt;Romana&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.weave.works/docs/net/latest/kube-addon/&#34;&gt;Weave Net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;minikubeとは&#34;&gt;Minikubeとは&lt;/h2&gt;

&lt;p&gt;Kubernetesクラスタを構築する方法は&lt;a href=&#34;https://kubernetes.io/docs/setup/pick-right-solution/&#34;&gt;いくつかある&lt;/a&gt;が、中でももっとも簡単な方法がMinikube。&lt;/p&gt;

&lt;p&gt;Minikubeは、単一NodeのKubernetesクラスタを詰めたVMをダウンロードして起動して、ローカルのkubectlから使えるようにしてくれるツール。
Linux、Windows、OS Xで動き、開発やテスト用途のKubernetes環境として使われる。&lt;/p&gt;

&lt;p&gt;ちょっと&lt;a href=&#34;https://www.vagrantup.com/&#34;&gt;Vagrant&lt;/a&gt;っぽい感じ。Kubernetes専用の。&lt;/p&gt;

&lt;h2 id=&#34;minikubeインストール&#34;&gt;Minikubeインストール&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-minikube/&#34;&gt;Kubernetesのドキュメント&lt;/a&gt;にしたがって、Minikubeをインストールする。
環境はWindows 10 Home x64。&lt;/p&gt;

&lt;p&gt;まず、MinikubeのVMを動かす仮想化ツールを入れる。
今のところMinikubeがサポートしてるのは、Windowsだと&lt;a href=&#34;https://www.virtualbox.org/&#34;&gt;VirtualBox&lt;/a&gt;か&lt;a href=&#34;https://docs.microsoft.com/ja-jp/virtualization/hyper-v-on-windows/quick-start/enable-hyper-v&#34;&gt;Hyper-V&lt;/a&gt;。
Windows 10 HomeだとHyper-Vが使えないので、VirtualBox一択。
VirtualBoxは、適当にVT-xを有効にして(してあった)、インストーラダウンロードしてインストールしただけ。
バージョンは5.1.28。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次に、minikubeコマンドを入れる。
このコマンドはGoで書かれていて、各プラットフォーム用にビルドされたバイナリがGitHubのプロジェクトページの&lt;a href=&#34;https://github.com/kubernetes/minikube/releases&#34;&gt;Releases&lt;/a&gt;に上がってるので、ダウンロードしてPathの通ったとこに置くだけ。
今回ダウンロードしたのはv0.22.2のminikube-windows-amd64で、これをminikube.exeにリネームして配置した。&lt;/p&gt;

&lt;p&gt;で、minikubeがサポートしているKubernetesのバージョンを調べると、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube get-k8s-versions
The following Kubernetes versions are available:
        - v1.7.5
        - v1.7.4
        - v1.7.3
        - v1.7.2
        - v1.7.0
        (snip)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1.8はまだサポートされていない…&lt;/p&gt;

&lt;p&gt;1.7.5が最新なのでそれでやることにする。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ということで、kubectlの1.7.5をインストールする。
kubectlもGoで書かれているので、以下のアドレスからWindowsバイナリをダウンロードしてPathの通ったところに置くだけ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;https://storage.googleapis.com/kubernetes-release/release/v1.7.5/bin/windows/amd64/kubectl.exe
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でMinikubeの環境ができた。
簡単。&lt;/p&gt;

&lt;h2 id=&#34;minikube起動&#34;&gt;Minikube起動&lt;/h2&gt;

&lt;p&gt;Minikubeは、&lt;code&gt;minikube start&lt;/code&gt;で起動することができ、Minikubeが起動したらすぐにKubernetesをいじれるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube start --vm-driver virtualbox --kubernetes-version v1.7.5
Starting local Kubernetes v1.7.5 cluster...
Starting VM...
Downloading Minikube ISO
 106.37 MB / 106.37 MB [============================================] 100.00% 0s
Getting VM IP address...
Moving files into cluster...
Setting up certs...
Connecting to cluster...
Setting up kubeconfig...
Starting cluster components...
Kubectl is now configured to use the cluster.

C:\Users\kaitoy&amp;gt;minikube status
minikube: Running
cluster: Running
kubectl: Correctly Configured: pointing to minikube-vm at 192.168.99.100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;起動した。
VirtualBoxのGUIを見ると、minikubeというVMが起動しているのが分かる。
この中でKubernetesクラスタが動いているはずだ。&lt;/p&gt;

&lt;p&gt;このVMには、&lt;code&gt;minikube ssh&lt;/code&gt;でログインできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube ssh
                         _             _
            _         _ ( )           ( )
  ___ ___  (_)  ___  (_)| |/&#39;)  _   _ | |_      __
/&#39; _ ` _ `\| |/&#39; _ `\| || , &amp;lt;  ( ) ( )| &#39;_`\  /&#39;__`\
| ( ) ( ) || || ( ) || || |\`\ | (_) || |_) )(  ___/
(_) (_) (_)(_)(_) (_)(_)(_) (_)`\___/&#39;(_,__/&#39;`\____)

$ uname -a
Linux minikube 4.9.13 #1 SMP Fri Sep 15 23:35:16 UTC 2017 x86_64 GNU/Linux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;すごくVagrantっぽい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Minikubeを起動すると、kubectlのコンテキストがminikubeというものに設定され、kubectlコマンドの接続先がMinikubeのKubernetesになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl config current-context
minikube
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、kubectlでクラスタの状態とかを見てみようと思ったら、なんか様子が変。
なしのつぶて。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;kubectl get nodes
Unable to connect to the server: dial tcp 192.168.99.100:8443: connectex: No connection could be made because the target machine actively refused it.

C:\Users\kaitoy&amp;gt;kubectl cluster-info dump
Unable to connect to the server: dial tcp 192.168.99.100:8443: connectex: No connection could be made because the target machine actively refused it.

C:\Users\kaitoy&amp;gt;minikube dashboard
Could not find finalized endpoint being pointed to by kubernetes-dashboard: Error validating service: Error getting service kubernetes-dashboard: Get https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kubernetes-dashboard: dial tcp 192.168.99.100:8443: connectex: No connection could be made because the target machine actively refused it.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再度&lt;code&gt;minikube status&lt;/code&gt;してみたら、クラスタが落ちていた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube status
minikube: Running
cluster: Stopped
kubectl: Correctly Configured: pointing to minikube-vm at 192.168.99.100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;minikube logs&lt;/code&gt;でログを見てみると、エラーがたくさん出ていた。
以下のようなログが最初のほうに出てたので、認証系がだめで、サービス間でやり取りができなかったんじゃないかという感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Oct 04 23:08:43 minikube localkube[2783]: W1004 23:08:43.599396    2783 authentication.go:368] AnonymousAuth is not allowed with the AllowAll authorizer.  Resetting AnonymousAuth to false. You should use a different authorizer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;エラーの原因はよくわからないので、Kubernetesのバージョンをちょっと古いの(1.7.0)変えてみる。&lt;/p&gt;

&lt;p&gt;kubectlの1.7.0をPathに置いて、Minikubeを1.7.0で再起動する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube stop
Stopping local Kubernetes cluster...
Machine stopped.

C:\Users\kaitoy&amp;gt;minikube start --vm-driver virtualbox --kubernetes-version v1.7.0
Starting local Kubernetes v1.7.0 cluster...
Starting VM...
Getting VM IP address...
Kubernetes version downgrade is not supported. Using version: v1.7.5
Moving files into cluster...
Setting up certs...
Connecting to cluster...
Setting up kubeconfig...
Starting cluster components...
Kubectl is now configured to use the cluster.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kubernetesのダウングレードはサポートされてないと言われた。
ので一回VMを消してからやりなおす。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube stop
Stopping local Kubernetes cluster...
Machine stopped.

C:\Users\kaitoy&amp;gt;minikube delete
Deleting local Kubernetes cluster...
Machine deleted.

C:\Users\kaitoy&amp;gt;minikube start --vm-driver virtualbox --kubernetes-version v1.7.0
Starting local Kubernetes v1.7.0 cluster...
Starting VM...
Getting VM IP address...
Moving files into cluster...
Setting up certs...
Connecting to cluster...
Setting up kubeconfig...
Starting cluster components...
Kubectl is now configured to use the cluster.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1.7.0で動いた。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;様子はどうか。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy\Desktop\bin\pleiades\workspace\blog&amp;gt;minikube status
minikube: Running
cluster: Running
kubectl: Correctly Configured: pointing to minikube-vm at 192.168.99.100

C:\Users\kaitoy\Desktop\bin\pleiades\workspace\blog&amp;gt;kubectl get nodes
NAME       STATUS    AGE       VERSION
minikube   Ready     22s       v1.7.0

C:\Users\kaitoy\Desktop\bin\pleiades\workspace\blog&amp;gt;kubectl version
Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;7&amp;quot;, GitVersion:&amp;quot;v1.7.0&amp;quot;, GitCommit:&amp;quot;d3ada0119e776222f11ec7945e6d860061339aad&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, BuildDate:&amp;quot;2017-06-29T23:15:59Z&amp;quot;, GoVersion:&amp;quot;go1.8.3&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;windows/amd64&amp;quot;}
Server Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;7&amp;quot;, GitVersion:&amp;quot;v1.7.0&amp;quot;, GitCommit:&amp;quot;d3ada0119e776222f11ec7945e6d860061339aad&amp;quot;, GitTreeState:&amp;quot;dirty&amp;quot;, BuildDate:&amp;quot;2017-10-04T09:25:40Z&amp;quot;, GoVersion:&amp;quot;go1.8.3&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;linux/amd64&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちゃんと動いているっぽい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ダッシュボードだけはなぜか相変わらず開けないけどまあいいか。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;minikube dashboard
Could not find finalized endpoint being pointed to by kubernetes-dashboard: Error validating service: Error getting service kubernetes-dashboard: services &amp;quot;kubernetes-dashboard&amp;quot; not found
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;続きはまた&lt;a href=&#34;https://www.kaitoy.xyz/2017/10/11/goslings-on-kubernetes-cont/&#34;&gt;別の記事&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;因みに、ベーシック認証ありのプロキシ環境でMinikube on Windowsする場合は、まず以下の環境変数を設定:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;NO_PROXY&lt;/code&gt;: 192.168.99.100&lt;/li&gt;
&lt;li&gt;&lt;code&gt;http_proxy&lt;/code&gt;: username:password@domain.com:port&lt;/li&gt;
&lt;li&gt;&lt;code&gt;https_proxy&lt;/code&gt;: username:password@domain.com:port&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;NO_PROXY&lt;/code&gt;の値は&lt;code&gt;minikube ip&lt;/code&gt;の値。
で、&lt;/p&gt;

&lt;p&gt;&lt;code&gt;minikube start --docker-env HTTP_PROXY=http://%http_proxy% --docker-env HTTPS_PROXY=https://%https_proxy% --docker-env NO_PROXY=%NO_PROXY%&lt;/code&gt;みたいにすればできる。&lt;/p&gt;

&lt;p&gt;はず。(参考: &lt;a href=&#34;https://github.com/kubernetes/minikube/issues/530&#34;&gt;https://github.com/kubernetes/minikube/issues/530&lt;/a&gt;)&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>スタートアップはReactを使うべきではない (BSD &#43; patentsライセンスを考慮して) — もし、いつか大企業に買収されたいと望むなら</title>
          <link>https://www.kaitoy.xyz/2017/08/25/if-youre-a-startup-you-should-not-use-react-reflecting-on-the-bsd-patents-license/</link>
          <pubDate>Fri, 25 Aug 2017 00:29:39 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/08/25/if-youre-a-startup-you-should-not-use-react-reflecting-on-the-bsd-patents-license/</guid>
          <description>

&lt;p&gt;このエントリでは、Raúl Kripalaniによる記事、&lt;a href=&#34;https://medium.com/@raulk/if-youre-a-startup-you-should-not-use-react-reflecting-on-the-bsd-patents-license-b049d4a67dd2&#34;&gt;If you’re a startup, you should not use React (reflecting on the BSD + patents license)&lt;/a&gt;を紹介する。
(Raúlから和訳と転載の許可は得た。)
以下はその全文の和訳だが、意訳超訳が混じっているので、もとのニュアンスを知りたければ元記事を読んでもいいし、読まなくてもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;2017/9/23追記: React、Jest、Flow、Immutable.jsが&lt;a href=&#34;https://code.facebook.com/posts/300798627056246/relicensing-react-jest-flow-and-immutable-js/&#34;&gt;MITにリライセンスされる&lt;/a&gt;というアナウンスがFacebookからあった。
コミュニティの大勝利だ。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;現在オープンソースコミュニティで起こっていることには落胆させられる。&lt;/strong&gt;
特に、オープンソースのおかげで多くのスタートアップやビジネスが存在することを認識したときは。
独占的なソフトウェアのために法外なライセンス料を払わなければならないとしたら、それらは存続できない。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;オープンソースとは、より良いソフトウェアをみんなで構築するためのコミュニティをつくることだ。
それを、— Facebookが意図しているような — 人々の権利を交換するための市場として決して使用すべきではない。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Facebookは「BSD + patents」というライセンスモデルを推進している。
広く人気のあるReactを含む、すべてのプロジェクトで。&lt;/p&gt;

&lt;p&gt;基本的に、「BSD + patents」はコードが(誰でも参照し利用できるように)公開されていることを意味するが、しかしそれは常にFacebookの著作物でもある。
そして彼らは、&lt;strong&gt;君がFacebookを特許侵害で訴えないで&lt;/strong&gt; 仲良くやっている限り、君に特許ライセンスを与える。&lt;/p&gt;

&lt;p&gt;Facebookを訴えた瞬間、Reactの他、君の使っているあらゆるFacebookの「オープンソース」技術の特許権は自動的に取り消されてしまう。&lt;/p&gt;

&lt;p&gt;アディオス、バイバイ、どこかへ行ってしまう。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://cdn-images-1.medium.com/max/800/1*crzf_h-aHXU-g3J0W6Ryig.png&#34; alt=&#34;React PATENTS&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;(&lt;a href=&#34;https://github.com/facebook/react/blob/b8ba8c83f318b84e42933f6928f231dc0918f864/PATENTS&#34;&gt;https://github.com/facebook/react/blob/b8ba8c83f318b84e42933f6928f231dc0918f864/PATENTS&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;この問題は、Apache Software Foundationによって&lt;a href=&#34;https://github.com/facebook/react/issues/10191#issuecomment-323486580&#34;&gt;衆目にさらされることとなった&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;この制限は広大で、残忍だ。&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;・・・&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;その知的財産がReactを使用しているドメインと関連しているかどうかは関係ない。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;君がReactを使うなら、Facebookが保持する特許に逆らうことはできない。
いつまでも。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;言い換えれば、代償。&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Facebook、それが君らの考えるオープンソースなのか?&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;・・・&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;fridgebook-inc&#34;&gt;Fridgebook Inc.&lt;/h2&gt;

&lt;p&gt;例として、君の会社「Fridgebook Inc.」はインテリジェントな冷蔵庫を販売しているとしよう。
君の冷蔵庫にはスクリーンが付いていて、独自のアプリケーションを実行していて、そのUIにはReactが使われている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://cdn-images-1.medium.com/max/800/1*vfurq6EY120rZCwkaVtsCg.png&#34; alt=&#34;Fridge&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;突然、Facebookは冷蔵庫業界への進出を決め、新製品「FBfridge」をわずか1週間後に世界中でローンチすると発表した。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;仮に、Facebookがあなたの特許の一部を「FBfridge」で露骨に侵害していた場合、どうすればいい?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;そう、&lt;strong&gt;君は即座に彼らを訴えることはできない。&lt;/strong&gt;
君は顧客が使うアプリにReactを使っている、だろ?&lt;/p&gt;

&lt;p&gt;もし他のもの(&lt;a href=&#34;https://vuejs.org/&#34;&gt;vue.js&lt;/a&gt;とか)に移行せずに訴えたら、Reactのために与えられたライセンスを即座に失い、思いがけず君自身が違反している状態になり、&lt;strong&gt;ソフトウェア不正使用の訴訟を約5000億ドルの会社から起こされる可能性と戦うことになる。&lt;/strong&gt;
君だけで。&lt;/p&gt;

&lt;p&gt;もちろん、君は顧客サービスを中断したくはない。&lt;/p&gt;

&lt;p&gt;だから、もし彼らを訴えたい、もしくは少なくともそれをするための効力を保持したいのであれば、&lt;strong&gt;記録的な期間でReactから移行できる解決策を見つける必要がある&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;それが君の陥るひどい窮地だ。そうだろ?
それはほとんど致命的な状況だ。
&lt;strong&gt;回避策?
最初からReactを使わないことだ。&lt;/strong&gt;
そうすれば権利を主張する自由を維持できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;注: 私は特許に支持も反対もしない。私はこの問題について明確な立場を持っていない。
ここでは私は単にギブアンドテイクのバランスを分析しているだけだ。
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;facebookの釈明&#34;&gt;Facebookの釈明&lt;/h2&gt;

&lt;p&gt;私が最後に見たとき、オープンソースの哲学は、よりよいソフトウェアを構築し、技術をより先に推し進めるために、有能な人々が砂粒に貢献するコミュニティを主要なテーマとしていた。&lt;/p&gt;

&lt;p&gt;それが、Apache Software FoundationやLinux Foundationなどの、&lt;strong&gt;オープンソース界の主要な基準組織の精神だ&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;それで、なぜ特許をオープンソースに持ち込んだのか?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Facebookは&lt;a href=&#34;https://code.facebook.com/posts/112130496157735/explaining-react-s-license/&#34;&gt;正式な釈明&lt;/a&gt;を発表した。
短く要約すると次のようなものだ:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Facebookは、多くのメリットのない特許請求を受けている。
それらに対抗すると多くのリソースを無駄にする。
そこで、(Reactのなどの)オープンソースプロジェクトの成功を利用して、ユーザが理論上メリットのない特許請求を提起するのを阻止するトロイの木馬を導入することに決めた。
彼らはこの制限を交換しない。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;しかしここに重要な部分がある&lt;/strong&gt;。
彼らは、オープンソースソフトウェアをリリースする他のすべての企業が同じことを &lt;em&gt;すべきだと主張している&lt;/em&gt; 。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;残念ながら、これはうまくいかず、以下のような要因により、いずれ再び業界のクローズドソース化を招くだろう：&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;それは市場最大級のプレーヤー間のコンセンサスを必要とする。
&lt;strong&gt;彼らは競合他社に対抗する力として実際の特許兵器(下の画像参照)を保有している。&lt;/strong&gt;
突然、これらの兵器の価値が$0になってしまう。&lt;/li&gt;
&lt;li&gt;そのコンセンサスに達するまず不可能だ。
参加しない悪徳企業が1つでもあれば、残りの企業は「守備/特許兵器」を維持する必要がある。&lt;/li&gt;
&lt;li&gt;すべての巨人達が「BSD + patents」スキームに基づくオープンソースに合意した場合でも、&lt;strong&gt;相互採用はしだいに無くなるだろう。
なぜかって?&lt;/strong&gt;
GoogleがProject Xを「BSD + patents」でリリースし、Amazonがそれを本当に気に入ったら、それを採用してGoogleに特許訴訟をする権利を永久に失うよりは、&lt;strong&gt;それを見限って自分たちで作ってしまうだろう。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;これは、そうした製品の周りにコミュニティが形成されないことを意味する。
コミュニティは、オープンソース製品の燃料でありインセンティブだ。
&lt;strong&gt;コミュニティに着火するチャンスがないならば、オープンソースにする理由はない。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;やがて、上記の状況が何度も繰り返されるにつれ、巨人達は製品をオープンソース化することに価値を見出さなくなり、業界は結局クローズドソースモデルに陥る。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://cdn-images-1.medium.com/max/800/1*VL9qHHrYQ_HMiShoNO4qeg.png&#34; alt=&#34;patent arsenals&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;(2012) &lt;a href=&#34;http://www.droid-life.com/2012/01/24/web-of-tech-patent-lawsuits-infographic/&#34;&gt;http://www.droid-life.com/2012/01/24/web-of-tech-patent-lawsuits-infographic/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;facebookによるオープンソース哲学の非倫理的な利用&#34;&gt;Facebookによるオープンソース哲学の非倫理的な利用&lt;/h2&gt;

&lt;p&gt;特許はアイデアや発明を保護する。
ほとんどの場合特許主張裁判は、白黒が付くのではなく、勝ち負けになる。
&lt;strong&gt;侵害の評価は複雑でコストがかかる。&lt;/strong&gt;
ひとつの訴訟を提起して遂行するのに、何十万か何百万ドルもかかり得る。
FBが君の特許を侵害したという85％の確信を持っていたとしても、それを追求するのに多額の費用がかかるだろう。&lt;/p&gt;

&lt;p&gt;それに加え、まずは別のフロントエンドフレームワークへの移行に投資し、&lt;strong&gt;さらにすべての顧客が新しいバージョンの製品を使用していることを確認する必要がある。&lt;/strong&gt;
(React Nativeを使用していたとするとどうなる? ユーザは一斉にはアプリをアップグレードしてくれないかもしれない!)
そうしなければ、訴訟を起こすことさえできない。
これがオープンソース哲学の誠実で倫理的な利用法だと思うか?&lt;/p&gt;

&lt;p&gt;要点:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;オープンソースは、「代償」取引ではない。
オープンソースは、よりよいソフトウェアを一緒に構築するためのコミュニティをつくることだ。
権利を交換するための市場として使用されるべきではない。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;君はどう思う?&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;・・・&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;なぜスタートアップはreactを避けるべきなのか&#34;&gt;なぜスタートアップはReactを避けるべきなのか&lt;/h2&gt;

&lt;p&gt;君がスタートアップを立ち上げているなら、君と君の投資家は、いつかは百万ドルの価値のある出口に到達することを望んでいるんだろう?&lt;/p&gt;

&lt;p&gt;君は、すべての買収元、特にApple、Microsoft、Google、Amazonなどの大企業に扉を開いておきたい。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;そうした企業は、Facebookに対抗して特許兵器を保有している可能性が高いし、そうでなかったとしても、いざという時にFacebookを訴える権利を放棄したくはない。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;君の製品がReactで構築されている場合、君を買収することはその権利を失うことを意味し、これは恐らく彼らが覚悟できていないことだ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;基本的に、もし君を買収することがFacebookの特許侵害を訴える権利を永久に放棄することを意味するなら、
潜在的なバイヤーは10フィートの棒で君を触らない。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;よって、選択肢を残しておきたいのであれば…&lt;/p&gt;

&lt;h2 id=&#34;悪いことは言わない-reactを使うのをやめろ&#34;&gt;悪いことは言わない、Reactを使うのをやめろ&lt;/h2&gt;

&lt;p&gt;私は特に&lt;a href=&#34;https://github.com/developit/preact&#34;&gt;Preact&lt;/a&gt;が好きだが、FacebookにVirtual DOMやReact APIのソフトウェア特許を持っているかは定かではない。&lt;/p&gt;

&lt;p&gt;もし持っていたら、Preactはそれらの特許を侵害しているかもしれないので、&lt;a href=&#34;https://vuejs.org/&#34;&gt;vue.js&lt;/a&gt;や&lt;a href=&#34;https://cycle.js.org/&#34;&gt;cycle.js&lt;/a&gt;も見てみるといい。&lt;/p&gt;

&lt;p&gt;いずれ、知的財産の観点でPreactと&lt;a href=&#34;https://github.com/infernojs/inferno&#34;&gt;Inferno&lt;/a&gt;(もうひとつの軽量なReactの代替品)がどうなのかをコミュニティが明確にできることを願う。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上がRaúlの記事。&lt;/p&gt;

&lt;p&gt;Facebookの「BSD + Patents」への流れは、2015年4月に書かれた&lt;a href=&#34;https://code.facebook.com/posts/1639473982937255/updating-our-open-source-patent-grant/&#34;&gt;Updating Our Open Source Patent Grant&lt;/a&gt;というブログ記事でのアナウンスから始まったようだ。&lt;/p&gt;

&lt;p&gt;Reactのコミットログを見てみると、2014年10月、v16.0.0のアルファ版で「Apache License Version 2.0」から「BSD + Patents」に変わったことが以下のコミットからわかる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/facebook/react/commit/dcf415c2b91ce52fd5d4dd02b70875ba9d33290f&#34;&gt;BSD + PATENTS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;そのPATENTSの部分をより明確にしたのが2015年4月の以下のコミット。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/facebook/react/commit/b8ba8c83f318b84e42933f6928f231dc0918f864&#34;&gt;Update Patent Grant&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;このPATENTSの条項をApache Software Foundationが問題視し、2017年7月に、Apache Software Foundationは自身の全プロジェクトで「BSD + Patents」なOSSの使用を禁止した。
で、Reactのライセンスを「Apache License Version 2.0」に戻せと言ったのをFacebookがごね、ついには、2017/8/19に公式に&lt;a href=&#34;https://code.facebook.com/posts/112130496157735/explaining-react-s-license/&#34;&gt;「BSD + Patents」と心中する&lt;/a&gt;という声明を出して炎上した、というのが今までの流れ。&lt;/p&gt;

&lt;p&gt;Reactのほか、Jest、Flow、Immutable.js、GraphQLなんかもアウト。
うちのプロジェクトでちょっとJestとFlow使いたいと思ってたけど様子見だな。&lt;/p&gt;

&lt;p&gt;Facebookの、みんなもそうすべきだという思惑に反し、今のところはPalantirという企業だけが同様のライセンスを採用しているらしい。&lt;/p&gt;

&lt;p&gt;因みに、たまにBSD + patentsライセンスが&lt;a href=&#34;http://www.opensource.jp/osd/osd-japanese.html&#34;&gt;オープンソースの定義(OSD)&lt;/a&gt;に違反しているので、ReactはOSSですらないという主張があるが、これは間違いであるというのが大方の見方だ。
この主張は、&lt;a href=&#34;https://www.elcaminolegal.com/single-post/2016/10/04/Facebook-Reactjs-License&#34;&gt;Robert Pierceによる記事&lt;/a&gt;が多分発端で、OSDの第一条「再頒布の自由」で、ソフトウェアの再配布に関して報酬(fee)を要求してはいけないとしている部分に、BSD + patentsライセンスが違反しているというもの。
すなわち、Facebookを訴えないという報酬を要求しているという主張だが、この解釈は法律家によって&lt;a href=&#34;http://lu.is/blog/2016/10/31/reacts-license-necessary-and-open/&#34;&gt;否定されている&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;また、OSDの第五条「個人やグループに対する差別の禁止」に違反しているからという主張もあるが、これも微妙。
この主張はつまり、Facebookを訴えていないグループと比較して、訴えたグループを差別しているという主張だろうが、Apache License 2.0、EPL、MPL 2.0といったメジャーなライセンスでも、そのような「差別」をする(i.e. 訴えたら特許使用権を剥奪する)条項がある。
これらのライセンスは、OSDをメンテしている組織であるOSIに&lt;a href=&#34;https://opensource.org/licenses/alphabetical&#34;&gt;承認されている&lt;/a&gt;ので、そうした差別がOSDに決定的に違反することではないことは明らか。
(&lt;a href=&#34;https://lists.opensource.org/pipermail/license-discuss/2016-December/thread.html&#34;&gt;この議論&lt;/a&gt;を見るに、厳密には違反しているけど、原理主義よりも現実主義であるべきなので、受け入れるべきといった雰囲気。)
BSD + patentsライセンスによる「差別」のような条項が、特別なものでも新しいものでもないことは&lt;a href=&#34;https://opensource.org/node/862&#34;&gt;OSI自身も言及している&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;FacebookのBSD + patentsライセンスが特別なのは、その「差別」の範囲が広いことだ。
Apache License 2.0なんかは、訴えた特許を含むソフトウェアだけが使えなくなるが、Facebookのは、Facebookに対するいかなる特許訴訟でもひとたび起こせば、Facebookが提供する広範囲の(全ての?)OSSが使えなくなるというもので、これはあまりにジャイアン的だということで炎上した。&lt;/p&gt;

&lt;p&gt;Facebookはこの炎上をどう収めるつもりなんだろう。
これをきっかけにReactが廃れ、Vue.jsとかに行ってしまうんだろうか。
結局フロントエンドフレームワークは何を学べばいいの?
Angular?&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>WebdriverIOとChromeのヘッドレスモードで自動ブラウザテストするDockerイメージ: webdriverio-chrome</title>
          <link>https://www.kaitoy.xyz/2017/08/14/webdriverio-chrome/</link>
          <pubDate>Mon, 14 Aug 2017 10:53:17 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/08/14/webdriverio-chrome/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/08/04/browser-test-framework/&#34;&gt;2017年夏、ブラウザテストフレームワーク&lt;/a&gt;」の続き。
&lt;a href=&#34;https://www.servicenow.com/ja&#34;&gt;ServiceNow&lt;/a&gt;アプリケーションのブラウザテストをしたくて色々調べている。
前回は、フレームワークに&lt;a href=&#34;http://webdriver.io/&#34;&gt;WebdriverIO&lt;/a&gt;を使うと決めたところまで書いた。&lt;/p&gt;

&lt;p&gt;今回、最終的に、&lt;a href=&#34;http://webdriver.io/&#34;&gt;WebdriverIO&lt;/a&gt;、&lt;a href=&#34;http://webdriver.io/guide/testrunner/gettingstarted.html&#34;&gt;WDIO&lt;/a&gt;、&lt;a href=&#34;https://github.com/vvo/selenium-standalone&#34;&gt;selenium-standalone&lt;/a&gt;、&lt;a href=&#34;https://jasmine.github.io/&#34;&gt;Jasmine&lt;/a&gt;と、Chromeのヘッドレスモードを使って、Dockerコンテナ(&lt;a href=&#34;https://alpinelinux.org/&#34;&gt;Alpine Linux&lt;/a&gt;)上でテストスクリプトを実行して、ServiceNowのログイン画面のスクリーンショットが取れるところまでできた。&lt;/p&gt;

&lt;p&gt;そのコンテナイメージのDockerfileは&lt;a href=&#34;https://github.com/kaitoy/webdriverio-chrome&#34;&gt;GitHubに置いた&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;とりあえずalpine-linux&#34;&gt;とりあえずAlpine Linux&lt;/h2&gt;

&lt;p&gt;テスト環境の作成は自宅でやってるけど、DockerイメージにしてDocker Hubとかに上げておけば、社内でダウンロードしてそのまま再現できる。
ダウンロードに係る社内手続きも、Dockerイメージだけに対してやればいいので、中に何を詰め込んでも、後でライブラリとか追加しても、一回こっきりで済む。&lt;/p&gt;

&lt;p&gt;というわけでWebdriverIO環境をDockerコンテナとしてつくることにする。
とりあえず、自PC(Windows 10 Home x64)に入ってるVMware Workstation Player 12.5.5でCentOS 7 x64のVMを作り、そこにDockerをインストールした。&lt;/p&gt;

&lt;p&gt;次に、そのDockerを使って、WebdriverIO環境のベースにするAlpine Linuxをpullする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ docker pull alpine:edge
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Alpine Linuxは&lt;a href=&#34;https://busybox.net/&#34;&gt;BusyBox&lt;/a&gt;と&lt;a href=&#34;https://www.musl-libc.org/&#34;&gt;musl libc&lt;/a&gt;で構成された軽量な Linuxディストリビューション。
2016年2月に&lt;a href=&#34;https://www.brianchristner.io/docker-is-moving-to-alpine-linux/&#34;&gt;すべてのオフィシャルDockerイメージがAlpine Linuxベースになる&lt;/a&gt;というアナウンスがあったし、他にそれっぽいものもなかったので、これをベースに環境を作ることにした。
&lt;a href=&#34;https://www.gnu.org/software/libc/&#34;&gt;glibc&lt;/a&gt;じゃないのがちょっと気になるけど、まあ問題ないか。&lt;/p&gt;

&lt;p&gt;現在、&lt;a href=&#34;https://pkgs.alpinelinux.org/package/edge/community/x86_64/chromium&#34;&gt;Chrome 59&lt;/a&gt;のAlpine Linuxパッケージはedgeブランチ(i.e. 開発ブランチ)でしか作られていない。
pullするタグをedgeにしたのはそのため。
(因みに現時点でAlpine Linuxのlatestは3.6。)&lt;/p&gt;

&lt;p&gt;で、起動。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ docker run -it alpine:edge sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;chrome-chromium-インストール&#34;&gt;Chrome(Chromium)インストール&lt;/h2&gt;

&lt;p&gt;まずはChrome(がAlpine Linuxパッケージにはないので、実際にはChromium)と、ついでにChromeDriverをインストールする。
Alpine Linux独自のパッケージマネージャーである&lt;a href=&#34;https://wiki.alpinelinux.org/wiki/Alpine_Linux_package_management&#34;&gt;apk&lt;/a&gt;を使う。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/ # apk add --update chromium chromium-chromedriver
/ # chromium-browser -version
Chromium 59.0.3071.115
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;無事インストールできた。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://bufferings.hatenablog.com/entry/2017/05/03/181713&#34;&gt;この記事&lt;/a&gt;を参考にヘッドレスモードで実行してみる。
ヘッドレスモードにするために&lt;code&gt;--headless&lt;/code&gt;を付けて、一時的な制限事項で&lt;code&gt;--disable-gpu&lt;/code&gt;を付ける必要があって、コンテナの権限不足を回避するために&lt;code&gt;--no-sandbox&lt;/code&gt;を付ける。
(コンテナの権限不足回避には他に、&lt;code&gt;docker run&lt;/code&gt;に&lt;code&gt;--privileged&lt;/code&gt;や&lt;code&gt;--cap-add=SYS_ADMIN&lt;/code&gt;付ける&lt;a href=&#34;https://github.com/yukinying/chrome-headless-browser-docker&#34;&gt;方法がある&lt;/a&gt;。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/ # chromium-browser --headless --no-sandbox --disable-gpu https://example.com/
[0811/145902.894023:WARNING:dns_config_service_posix.cc(326)] Failed to read DnsConfig.
[0811/145902.906137:FATAL:udev_loader.cc(38)] Check failed: false.
Received signal 6
  r8: 0000000000000061  r9: 00007fe3fe01c066 r10: 0000000000000008 r11: 0000000000000246
 r12: 00007fe3fe01bed0 r13: 00007fe3fe01be80 r14: 0000000000000000 r15: 0000000000000000
  di: 0000000000000002  si: 00007fe3fe01bda0  bp: 00007fe3fe01bda0  bx: 0000000000000006
  dx: 0000000000000000  ax: 0000000000000000  cx: ffffffffffffffff  sp: 00007fe3fe01bd88
  ip: 00007fe412a2f769 efl: 0000000000000246 cgf: 0000000000000033 erf: 0000000000000000
 trp: 0000000000000000 msk: 0000000000000000 cr2: 0000000000000000
[end of stack trace]
Calling _exit(1). Core file will not be generated.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;エラーになった。&lt;/p&gt;

&lt;p&gt;最初のWARNINGは置いといて、FATALのほうは、udev_loader.ccというのでエラーになってる。&lt;/p&gt;

&lt;p&gt;エラーメッセージでググったら、&lt;a href=&#34;http://qiita.com/dd511805/items/dfe03c5486bf1421875a&#34;&gt;Qiitaに同じエラーを解決している記事&lt;/a&gt;が。
よくわからないが、&lt;a href=&#34;https://pkgs.alpinelinux.org/package/v3.5/main/x86_64/udev&#34;&gt;udev&lt;/a&gt;と&lt;a href=&#34;https://pkgs.alpinelinux.org/package/v3.6/main/x86_64/ttf-freefont&#34;&gt;ttf-freefont&lt;/a&gt;を入れればいいらしい。
深く考えずにそれに従うことにする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/ # apk add udev ttf-freefont
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、再度実行。
(ちゃんと動いてるか分かりやすくするために&lt;code&gt;--dump-dom&lt;/code&gt;も付けた。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/ # chromium-browser --headless --no-sandbox --disable-gpu --dump-dom https://example.com/
[0811/151303.698629:WARNING:dns_config_service_posix.cc(326)] Failed to read DnsConfig.
&amp;lt;body&amp;gt;
&amp;lt;div&amp;gt;
    &amp;lt;h1&amp;gt;Example Domain&amp;lt;/h1&amp;gt;
    &amp;lt;p&amp;gt;This domain is established to be used for illustrative examples in documents. You may use this
    domain in examples without prior coordination or asking for permission.&amp;lt;/p&amp;gt;
    &amp;lt;p&amp;gt;&amp;lt;a href=&amp;quot;http://www.iana.org/domains/example&amp;quot;&amp;gt;More information...&amp;lt;/a&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;


&amp;lt;/body&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;動いた!&lt;/p&gt;

&lt;h2 id=&#34;フォント追加&#34;&gt;フォント追加&lt;/h2&gt;

&lt;p&gt;前節で参考にした&lt;a href=&#34;http://qiita.com/dd511805/items/dfe03c5486bf1421875a&#34;&gt;Qiitaの記事&lt;/a&gt;に、文字化け対策としてフォントを追加する手順も書いてあったのでそれもやる。&lt;/p&gt;

&lt;p&gt;まず試しに、何もしないでスクリーンショットを撮ってみる。
&lt;code&gt;--screenshot&lt;/code&gt;オプションで。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/ # chromium-browser --headless --no-sandbox --disable-gpu --screenshot https://www.google.co.jp/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;するとやはり文字化けしている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/webdriverio-chrome/garblings.png&#34; alt=&#34;garblings.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.google.com/get/noto/&#34;&gt;Google Noto Fonts&lt;/a&gt;を入れて対応する。
(因みにNotoはNo Tofuの略で、文字化けした時に出る、クエスチョンマークが乗った豆腐の撲滅を目指して開発されたフォント。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/ # apk add curl
/ # cd /tmp/
/tmp # curl https://noto-website.storage.googleapis.com/pkgs/NotoSansCJKjp-hinte
/tmp # unzip NotoSansCJKjp-hinted.zip
/tmp # mkdir -p /usr/share/fonts/noto
/tmp # cp *.otf /usr/share/fonts/noto
/tmp # chmod 644 -R /usr/share/fonts/noto/
/tmp # fc-cache -fv
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;後半に実行してるコマンドの詳細はよくわからないが、文字化けは直った。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/webdriverio-chrome/garblings_fixed.png&#34; alt=&#34;garblings_fixed.png&#34; /&gt;
&lt;/p&gt;

&lt;h2 id=&#34;webdriverioインストール&#34;&gt;WebdriverIOインストール&lt;/h2&gt;

&lt;p&gt;次にWebdriverIOをインストールする。
&lt;a href=&#34;https://yarnpkg.com/lang/en/&#34;&gt;Yarn&lt;/a&gt;でインストールして&lt;a href=&#34;https://nodejs.org/ja/&#34;&gt;Node.js&lt;/a&gt;で動かすので、まずそれらをapkで入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/tmp # apk add nodejs yarn
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、プロジェクトを作ってWebdriverIOを追加。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;/tmp # mkdir /root/webdriverio-chrome
/tmp # cd /root/webdriverio-chrome
~/webdriverio-chrome # yarn init
~/webdriverio-chrome # yarn add webdriverio --dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;package.jsonのscriptsを編集して、WebdriverIO付属のテストランナであるWDIOを使えるようにする。&lt;/p&gt;

&lt;p&gt;package.json:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;webdriverio-chrome&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.0.1&amp;quot;,
  &amp;quot;description&amp;quot;: &amp;quot;Browser test stack with WebdriverIO and headless Chrome&amp;quot;,
  &amp;quot;scripts&amp;quot;: {
    &amp;quot;test&amp;quot;: &amp;quot;wdio&amp;quot;
  },
  &amp;quot;author&amp;quot;: &amp;quot;Kaito Yamada&amp;quot;,
  &amp;quot;license&amp;quot;: &amp;quot;MIT&amp;quot;,
  &amp;quot;devDependencies&amp;quot;: {
    &amp;quot;webdriverio&amp;quot;: &amp;quot;^4.8.0&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;wdioの設定ファイル生成&#34;&gt;WDIOの設定ファイル生成&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://webdriver.io/guide/testrunner/gettingstarted.html&#34;&gt;WDIOのconfigコマンド&lt;/a&gt;でWDIO Configuration Helperを起動し、設定ファイルwdio.conf.jsをインタラクティブに生成する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # yarn test -- config
yarn test v0.27.5
$ wdio &amp;quot;config&amp;quot;

=========================
WDIO Configuration Helper
=========================

? Where do you want to execute your tests? On my local machine
? Which framework do you want to use? jasmine
? Shall I install the framework adapter for you? No
? Where are your test specs located? ./test/specs/**/*.js
? Which reporter do you want to use?  spec - https://github.com/webdriverio/wdio-spec-reporter
? Shall I install the reporter library for you? No
? Do you want to add a service to your test setup?  selenium-standalone - https://github.com/webdriverio/wdio-selenium-standalone-service
? Shall I install the services for you? No
? Level of logging verbosity verbose
? In which directory should screenshots gets saved if a command fails? ./errorShots/
? What is the base url? http://localhost

Configuration file was created successfully!
To run your tests, execute:

$ wdio wdio.conf.js

Done in 53.58s.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;WDIO Configuration Helperで、テストフレームワークは&lt;a href=&#34;https://mochajs.org/&#34;&gt;Mocha&lt;/a&gt;か&lt;a href=&#34;https://jasmine.github.io/&#34;&gt;Jasmine&lt;/a&gt;か&lt;a href=&#34;https://cucumber.io/&#34;&gt;Cucumber&lt;/a&gt;から&lt;a href=&#34;http://webdriver.io/guide/testrunner/frameworks.html&#34;&gt;選択できる&lt;/a&gt;。
ServiceNowのテストフレームワーク(ATF)がJasmine使ってるので、一応それに合わせてJasmineにした。
ATFは今のところ使うつもりはないけど。&lt;/p&gt;

&lt;p&gt;レポータ(標準出力へテスト結果を出力するコンポーネント)は妙に色々ある中から、雰囲気で&lt;a href=&#34;http://webdriver.io/guide/reporters/spec.html&#34;&gt;spec&lt;/a&gt;を選択。&lt;/p&gt;

&lt;p&gt;サービス(テスト実行に必要な準備などをしてくれるコンポーネント)には&lt;a href=&#34;http://webdriver.io/guide/services/selenium-standalone.html&#34;&gt;selenium-standalone&lt;/a&gt;を選択。
こいつは、テスト実行前に、npmパッケージの&lt;a href=&#34;https://www.npmjs.com/package/selenium-standalone&#34;&gt;selenium-standalone&lt;/a&gt;を使って&lt;a href=&#34;http://docs.seleniumhq.org/download/&#34;&gt;Selenium Server&lt;/a&gt;をダウンロードして起動したり、WebDriverをセットアップしてくれたりする。&lt;/p&gt;

&lt;p&gt;因みにサービスには他に、&lt;a href=&#34;http://webdriver.io/guide/services/browserstack.html&#34;&gt;browserstack&lt;/a&gt;とか&lt;a href=&#34;http://webdriver.io/guide/services/appium.html&#34;&gt;appium&lt;/a&gt;とか&lt;a href=&#34;http://webdriver.io/guide/services/phantomjs.html&#34;&gt;phantomjs&lt;/a&gt;とかがある。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Shall I install …&lt;/code&gt;という質問には全てnoで回答した。
でないとWDIOがnpm installしようとして、npmが無くて以下のようなエラーになるので。
(apkでは、npmは&lt;a href=&#34;https://pkgs.alpinelinux.org/package/edge/main/x86_64/nodejs&#34;&gt;nodejs&lt;/a&gt;パッケージに入ってなくて、&lt;a href=&#34;https://pkgs.alpinelinux.org/package/edge/main/x86_64/nodejs-npm&#34;&gt;nodejs-npm&lt;/a&gt;に入ってる。)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Installing wdio packages:
/root/webdriverio-chrome/node_modules/webdriverio/build/lib/cli.js:278
                    throw err;
                    ^

Error: Command failed: npm i -D wdio-jasmine-framework
/bin/sh: npm: not found

    at ChildProcess.exithandler (child_process.js:204:12)
    at emitTwo (events.js:106:13)
    at ChildProcess.emit (events.js:191:7)
    at maybeClose (internal/child_process.js:891:16)
    at Socket.&amp;lt;anonymous&amp;gt; (internal/child_process.js:342:11)
    at emitOne (events.js:96:13)
    at Socket.emit (events.js:188:7)
    at Pipe._handle.close [as _onclose] (net.js:497:12)
error Command failed with exit code 1.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;生成された設定ファイルは以下の感じ。(コメントは省略してる。)&lt;/p&gt;

&lt;p&gt;wdio.conf.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;exports.config = {
    specs: [
        &#39;./test/specs/**/*.js&#39;
    ],
    exclude: [
        // &#39;path/to/excluded/files&#39;
    ],
    maxInstances: 10,
    capabilities: [{
        maxInstances: 5,
        browserName: &#39;firefox&#39;,
    }],

    sync: true,
    logLevel: &#39;verbose&#39;,
    coloredLogs: true,
    bail: 0,
    screenshotPath: &#39;./errorShots/&#39;,
    baseUrl: &#39;http://localhost&#39;,
    waitforTimeout: 10000,
    connectionRetryTimeout: 90000,
    connectionRetryCount: 3,

    services: [&#39;selenium-standalone&#39;],

    framework: &#39;jasmine&#39;,
    reporters: [&#39;spec&#39;],
    jasmineNodeOpts: {
        defaultTimeoutInterval: 50000,
        expectationResultHandler: function(passed, assertion) {
            // do something
        }
    },
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;npmパッケージとjava追加&#34;&gt;npmパッケージとJava追加&lt;/h2&gt;

&lt;p&gt;WDIO Configuration Helperの&lt;code&gt;Shall I install …&lt;/code&gt;でnoした分は自分でインストールしておく。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # yarn add wdio-jasmine-framework wdio-spec-reporter wdio-selenium-standalone-service selenium-standalone --dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;したらエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;error /root/webdriverio-chrome/node_modules/fibers: Command failed.
Exit code: 127
Command: sh
Arguments: -c node build.js || nodejs build.js
Directory: /root/webdriverio-chrome/node_modules/fibers
Output:
`linux-x64-48` exists; testing
Problem with the binary; manual build incoming
node-gyp not found! Please ensure node-gyp is in your PATH--
Try running: `sudo npm install -g node-gyp`
sh: nodejs: not found
spawn node-gyp ENOENT
info Visit https://yarnpkg.com/en/docs/cli/add for documentation about this command.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/nodejs/node-gyp&#34;&gt;node-gyp&lt;/a&gt;が無いと。
では追加する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # yarn global add node-gyp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;node-gypのREADME.md読むと、PythonとmakeとC/C++コンパイラが要るとあるので、それも入れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # apk add python make gcc g++
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;で、再度、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # yarn add wdio-jasmine-framework wdio-spec-reporter wdio-selenium-standalone-service selenium-standalone --dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;したら入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あと、Selenium ServerがJavaで動くので、Javaも入れておく。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # apk add openjdk8
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;wdio-conf-jsの修正&#34;&gt;wdio.conf.jsの修正&lt;/h2&gt;

&lt;p&gt;生成されたwdio.conf.jsはFirefoxを使うようになっているなどの問題があるので修正する。
参考にしたのは&lt;a href=&#34;https://stackoverflow.com/questions/42303119/selenium-webdriverio-chrome-headless&#34;&gt;Stack Overflowの回答&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;     capabilities: [{
     maxInstances: 5,
-        browserName: &#39;firefox&#39;
+        browserName: &#39;chrome&#39;,
+        chromeOptions: {
+            binary: &#39;/usr/bin/chromium-browser&#39;,
+            args: [
+                &#39;headless&#39;,
+                &#39;disable-gpu&#39;,
+                &#39;no-sandbox&#39;,
+            ],
+        },
     }],
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;browserName&lt;/code&gt;を&lt;code&gt;firefox&lt;/code&gt;から&lt;code&gt;chrome&lt;/code&gt;に変えて、ヘッドレスモードで動かすためのオプションを指定している。
また、普通のChromeとは実行ファイルの名前が違うので、&lt;code&gt;binary&lt;/code&gt;で指定している。&lt;/p&gt;

&lt;h2 id=&#34;テスト作成と実行&#34;&gt;テスト作成と実行&lt;/h2&gt;

&lt;p&gt;テストはとりあえず&lt;a href=&#34;http://blog.asial.co.jp/1484&#34;&gt;この記事&lt;/a&gt;を参考に以下のようなものを書いた。&lt;/p&gt;

&lt;p&gt;test-sample.js:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;describe(&#39;Sample&#39;, function() {
    it(&amp;quot;takes a screenshot of www.google.co.jp&amp;quot;, function() {
        browser.url(&#39;https://www.google.co.jp/&#39;);
        browser.saveScreenshot(&#39;./screenshots/google.png&#39;);
    });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを実行すると、&lt;code&gt;https://www.google.co.jp/&lt;/code&gt;をブラウザで開いて、スクリーンショットを撮る。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これを&lt;code&gt;~/webdriverio-chrome/test/specs/&lt;/code&gt;において、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # yarn test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;でテスト実行。
したらエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # yarn test
yarn test v0.27.5
$ wdio
[06:43:04]  COMMAND     POST     &amp;quot;/wd/hub/session&amp;quot;
[06:43:04]  DATA                {&amp;quot;desiredCapabilities&amp;quot;:{&amp;quot;javascriptEnabled&amp;quot;:true,&amp;quot;locationContextEnabled&amp;quot;:true,&amp;quot;handlesAlerts&amp;quot;:true,&amp;quot;rotatable&amp;quot;:true,&amp;quot;maxInstances&amp;quot;:5,&amp;quot;browserName&amp;quot;:&amp;quot;chrome&amp;quot;,&amp;quot;chromeOptions&amp;quot;:{&amp;quot;binary&amp;quot;:&amp;quot;/usr/bin/chromium-browser&amp;quot;,&amp;quot;args&amp;quot;:[&amp;quot;headless&amp;quot;,&amp;quot;disable-gpu&amp;quot;,&amp;quot;no-sandbox&amp;quot;]},&amp;quot;loggingPrefs&amp;quot;:{&amp;quot;browser&amp;quot;:&amp;quot;ALL&amp;quot;,&amp;quot;driver&amp;quot;:&amp;quot;ALL&amp;quot;},&amp;quot;requestOrigins&amp;quot;:{&amp;quot;url&amp;quot;:&amp;quot;http://webdriver.io&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;4.6.2&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;webdriverio&amp;quot;}}}
ERROR: An unknown server-side error occurred while processing the command. (UnknownError:13)
chrome
Error: An unknown server-side error occurred while processing the command. (UnknownError:13)

error Command failed with exit code 1.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;サーバサイドでよくわからないエラーが起きたとのこと。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;試しに手動でSelenium Serverを起動してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # node ./node_modules/.bin/selenium-standalone start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正常に起動する。&lt;/p&gt;

&lt;p&gt;ChromeDriverはどうか。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # /usr/bin/chromedriver
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これも起動する。はて。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/webdriverio/wdio-selenium-standalone-service/blob/v0.0.9/lib/launcher.js&#34;&gt;wdio-selenium-standalone-serviceのソース&lt;/a&gt;を見てみたら、selenium-standaloneの&lt;code&gt;install&lt;/code&gt;を呼んでいた。
これはSelenium ServerとChromeDriverをダウンロードする機能だ。
コンテナ内を確認したら、&lt;code&gt;node_modules/selenium-standalone/.selenium/chromedrive
r/2.31-x64-chromedriver&lt;/code&gt;というのが出来てた。
これがselenium-standaloneがダウンロードしたChromeDriverだろうが、Apline Linux用ではないので、&lt;code&gt;ldd&lt;/code&gt;してやるとたくさんエラーが出る。
selenium-standaloneがこれを実行しようとしたせいでテスト実行がエラーになったんだろう。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.com/@jlchereau/how-to-configure-webdrivier-io-with-selenium-standalone-and-additional-browsers-9369d38bc4d1&#34;&gt;Mediumの記事&lt;/a&gt;などを参考にして、wdio.conf.jsを以下のように修正して、ChromeDriverのバイナリを指定してやったら動いた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;     services: [&#39;selenium-standalone&#39;],
+    seleniumArgs: {
+        javaArgs: [
+            &#39;-Dwebdriver.chrome.driver=/usr/bin/chromedriver&#39;
+        ]
+    },
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;プロキシ対策&#34;&gt;プロキシ対策&lt;/h2&gt;

&lt;p&gt;社内で使うには、ベーシック認証付きのプロキシを突破しないといけない。&lt;/p&gt;

&lt;p&gt;今回作った環境をクールな図にするとこんな↓感じ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/webdriverio-chrome/internet_accesses.png&#34; alt=&#34;internet_accesses.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;なので、二か所あるインターネッツアクセスをプロキシ対応させる必要がある。
図の左のアクセスについては、&lt;a href=&#34;https://github.com/webdriverio/wdio-selenium-standalone-service/blob/master/lib/launcher.js&#34;&gt;wdio-selenium-standalone-serviceのソース&lt;/a&gt;を見たりして、wdio.conf.jsを次のように修正すればいいことが分かった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;     services: [&#39;selenium-standalone&#39;],
     seleniumArgs: {
         javaArgs: [
             &#39;-Dwebdriver.chrome.driver=/usr/bin/chromedriver&#39;,
         ],
     },
+    seleniumInstallArgs: {
+        proxy: &#39;http://userId:password@proxy.com:8080&#39;,
+    },
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;図の右のアクセスについては、プロキシのベーシック認証のクレデンシャルを指定するオプションがChromeにないので、&lt;a href=&#34;https://github.com/sjitech/proxy-login-automator&#34;&gt;proxy-login-automator&lt;/a&gt;を使うことにして、wdio.conf.jsには次のように追記しておく。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;         chromeOptions: {
             binary: &#39;/usr/bin/chromium-browser&#39;,
             args: [
                 &#39;headless&#39;,
                 &#39;disable-gpu&#39;,
                 &#39;no-sandbox&#39;,
+                &#39;proxy-server=localhost:18080&#39;,
             ],
         },
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで、テスト実行前に、以下みたいにproxy-login-automatorを起動しておけばいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;~/webdriverio-chrome # node node_modules/.bin/proxy-login-automator.js -local_port 18080 -remote_host proxy.com -remote_port 8080 -usr userId -pwd password`
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;以上の操作をまとめたDockerfileが以下。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-dockerfile&#34;&gt;From alpine:edge

ADD package.json wdio.conf.js yarn.lock test-sample.js /root/webdriverio-chrome/

RUN apk add --update --no-cache \
            udev \
            ttf-freefont \
            chromium \
            chromium-chromedriver \
            openjdk8 \
            nodejs \
            yarn \
            make gcc g++ python \
            curl &amp;amp;&amp;amp; \
    cd /tmp &amp;amp;&amp;amp; \
    curl https://noto-website.storage.googleapis.com/pkgs/NotoSansCJKjp-hinted.zip -O &amp;amp;&amp;amp; \
    unzip NotoSansCJKjp-hinted.zip &amp;amp;&amp;amp; \
    mkdir -p /usr/share/fonts/noto &amp;amp;&amp;amp; \
    cp *.otf /usr/share/fonts/noto &amp;amp;&amp;amp; \
    chmod 644 -R /usr/share/fonts/noto/ &amp;amp;&amp;amp; \
    fc-cache -fv &amp;amp;&amp;amp; \
    cd /root/webdriverio-chrome/ &amp;amp;&amp;amp; \
    yarn global add node-gyp &amp;amp;&amp;amp; \
    yarn &amp;amp;&amp;amp; \
    mkdir -p test/specs &amp;amp;&amp;amp; \
    mv test-sample.js test/specs/ &amp;amp;&amp;amp; \
    mkdir screenshots &amp;amp;&amp;amp; \
    yarn global remove node-gyp &amp;amp;&amp;amp; \
    rm -rf /root/.node-gyp &amp;amp;&amp;amp; \
    rm -rf /tmp/* &amp;amp;&amp;amp; \
    yarn cache clean &amp;amp;&amp;amp; \
    apk del --purge make gcc g++ python curl

WORKDIR /root/webdriverio-chrome
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できるイメージを小さくするため、レイヤを減らしたり、ビルド用パッケージを消したりしてる。
&lt;a href=&#34;http://qiita.com/minamijoyo/items/711704e85b45ff5d6405&#34;&gt;Multi-Stage build&lt;/a&gt;が&lt;a href=&#34;https://hub.docker.com/&#34;&gt;Docker Hub&lt;/a&gt;のAutomated Buildで&lt;a href=&#34;https://github.com/docker/hub-feedback/issues/1039&#34;&gt;もうすぐサポートされる&lt;/a&gt;ので、そしたらもう少しきれいに書き直せるはず。&lt;/p&gt;

&lt;p&gt;(後日書き直して&lt;a href=&#34;https://github.com/kaitoy/webdriverio-chrome/blob/master/Dockerfile&#34;&gt;きれいになった&lt;/a&gt;。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;最終的なpackage.jsonは&lt;a href=&#34;https://github.com/kaitoy/webdriverio-chrome/blob/v0.0.3/package.json&#34;&gt;これ&lt;/a&gt;。
wdio.conf.jsは&lt;a href=&#34;https://github.com/kaitoy/webdriverio-chrome/blob/v0.0.3/wdio.conf.js&#34;&gt;これ&lt;/a&gt;。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>2017年夏、ブラウザテストフレームワーク</title>
          <link>https://www.kaitoy.xyz/2017/08/04/browser-test-framework/</link>
          <pubDate>Fri, 04 Aug 2017 15:29:37 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/08/04/browser-test-framework/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/07/12/2017-selenium-headless-browsers/&#34;&gt;2017年夏、Selenium、ヘッドレスブラウザ&lt;/a&gt;」の続き。
&lt;a href=&#34;https://www.servicenow.com/ja&#34;&gt;ServiceNow&lt;/a&gt;アプリケーションのブラウザテストをしたくて色々調べている。
前回は、Selenium(WebDriver)とChromeのヘッドレスモードを使うのがよさそうというところまで書いた。&lt;/p&gt;

&lt;p&gt;この記事では、ブラウザテストフレームワークを選ぶ。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;ブラウザ操作ツールとかブラウザテストフレームワークとか&#34;&gt;ブラウザ操作ツールとかブラウザテストフレームワークとか&lt;/h2&gt;

&lt;p&gt;Seleniumを直接使って、&lt;a href=&#34;http://junit.org/junit4/&#34;&gt;JUnit&lt;/a&gt;なんかのテストフレームワークでブラウザテストを書くこともできるけど、それは結構つらい。
Seleniumは低レベルなブラウザ操作APIを提供するので、単純にテスト書き辛いし、動的サイトを扱うときには、かなり気を使ってwait処理を入れていかないとテストが安定しない。
テスト前に、WebDriverの準備をしないといけなかったりするのも面倒。&lt;/p&gt;

&lt;p&gt;なので、昨今はもう少し高級なツールやフレームワークを使うのが普通な模様。
あまり知らなかったので色々記事を読んだ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://qiita.com/cognitom/items/27b7375bea653b414c8f&#34;&gt;Seleniumアレルギーのための処方箋&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://qiita.com/cognitom/items/6cce719b57341769c14d&#34;&gt;ブラウザテストツール総まとめ・2016年夏版&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://postd.cc/a-complete-guide-to-testing-javascript-in-2017/&#34;&gt;2017年JavaScriptのテスト概論&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;結果、ブラウザ操作ツールやブラウザテストフレームワークには以下のようなものがあることが分かった。
(SeleniumやWebDriver系じゃないのも含む。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://nightwatchjs.org/&#34;&gt;Nightwatch.js&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は6835。&lt;/p&gt;

&lt;p&gt;JavaScriptでブラウザテストを書けるフレームワーク。
WebDriverプロトコルに対応していて、Seleniumと異なる独自のクライアントAPIを実装。
つまり使えるブラウザの幅が広い。&lt;/p&gt;

&lt;p&gt;テストフレームワークは独自のもの。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://webdriver.io/&#34;&gt;WebdriverIO&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は3217。&lt;/p&gt;

&lt;p&gt;JavaScriptでブラウザを操作できるツール。
WebDriverプロトコルに対応していて、Seleniumと異なる独自のクライアントAPI(ラッパ?)を実装。
つまり使えるブラウザの幅が広い。&lt;/p&gt;

&lt;p&gt;独自のテストランナである&lt;a href=&#34;http://webdriver.io/guide/testrunner/gettingstarted.html&#34;&gt;WDIO&lt;/a&gt;付きで、テストフレームワークに&lt;a href=&#34;https://mochajs.org/&#34;&gt;Mocha&lt;/a&gt;、&lt;a href=&#34;https://jasmine.github.io/&#34;&gt;Jasmine&lt;/a&gt;、&lt;a href=&#34;https://cucumber.io/&#34;&gt;Cucumber&lt;/a&gt;など、いろいろ利用できる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.protractortest.org/#/&#34;&gt;Protractor&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は6801。&lt;/p&gt;

&lt;p&gt;JavaScriptでブラウザテストを書けるフレームワーク。
WebDriverプロトコルに対応していて、&lt;a href=&#34;https://github.com/SeleniumHQ/selenium/wiki/WebDriverJs&#34;&gt;selenium-webdriver&lt;/a&gt;をラップしたAPIを提供する。
WebDriverなのでブラウザはなんでも。&lt;/p&gt;

&lt;p&gt;テストフレームワークは、Jasmine、Mocha、Cucumberのほか、いろいろ選べる模様。&lt;/p&gt;

&lt;p&gt;AngularとAngularJS向けだけどそれ以外にも使える。
Google製なので信頼感があるし、ドキュメントもコミュニティもしっかりしてる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://casperjs.org/&#34;&gt;Casper.js&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は6337。&lt;/p&gt;

&lt;p&gt;JavaScriptでブラウザテストを書けるフレームワーク。
使えるブラウザは&lt;a href=&#34;http://phantomjs.org/&#34;&gt;PhantomJS&lt;/a&gt;か&lt;a href=&#34;https://slimerjs.org/&#34;&gt;SlimerJS&lt;/a&gt;だけで、多分WebDriver使ってない。&lt;/p&gt;

&lt;p&gt;テストフレームワークは独自のもの。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.nightmarejs.org/&#34;&gt;Nightmare&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は12964。&lt;/p&gt;

&lt;p&gt;JavaScriptでブラウザを操作できるツール。
ブラウザは、昔の1系はPhantomJSを使ってたけど、今の2系は&lt;a href=&#34;https://electron.atom.io/&#34;&gt;Electron&lt;/a&gt;。
WebDriverは使ってないはず。&lt;/p&gt;

&lt;p&gt;テストフレームワーク機能は付いてないけど、同じ作者の&lt;a href=&#34;https://open.segment.com/niffy&#34;&gt;Niffy&lt;/a&gt;というNightmareベースのツールがちょっとそれっぽい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://devexpress.github.io/testcafe/&#34;&gt;TestCafe&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は3029。&lt;/p&gt;

&lt;p&gt;JavaScriptでブラウザテストを書けるフレームワーク。
すごい多機能っぽいし、TypeScriptやasync/awaitをサポートしててなんかモダン。
WebDriverは使ってないっぽいけど、Chrome、Firefox、IE、Edge、Safariなど、一通りのブラウザが使える。
なぜかリモートテストもできる。&lt;/p&gt;

&lt;p&gt;どうもSelenium 1みたいにJavaScriptコードを挿入してテスト実行するらしいんだけど、よくわからない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://zombie.js.org/&#34;&gt;Zombie.js&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は4608。&lt;/p&gt;

&lt;p&gt;JavaScriptでjsdomを操作できるツール。
なぜか妙にアサーション機能に凝っている。&lt;/p&gt;

&lt;p&gt;WebDriverは使ってないはず。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleChrome/puppeteer&#34;&gt;Puppeteer&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は29068。&lt;/p&gt;

&lt;p&gt;Chromeを&lt;a href=&#34;https://chromedevtools.github.io/devtools-protocol/&#34;&gt;DevToolsプロトコル&lt;/a&gt;で操作するJavaScript(Node)ライブラリ。&lt;/p&gt;

&lt;p&gt;Chrome開発チームが開発している。&lt;/p&gt;

&lt;p&gt;WebDriverは使ってない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/OnetapInc/chromy&#34;&gt;Chromy&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は294。&lt;/p&gt;

&lt;p&gt;JavaScriptでChromeを操作できるツール。
&lt;a href=&#34;https://github.com/cyrus-and/chrome-remote-interface&#34;&gt;chrome-remote-interface&lt;/a&gt;をラップして、
NightmareっぽいAPIを提供する。&lt;/p&gt;

&lt;p&gt;WebDriverは使ってない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://codeception.com/&#34;&gt;Codeception&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は2900。&lt;/p&gt;

&lt;p&gt;PHPUnitとSeleniumをラップして、ユーザ視点のブラウザテスト(受入テスト)をPHPで書けるフレームワーク。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://teamcapybara.github.io/capybara/&#34;&gt;Capybara&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は7937。&lt;/p&gt;

&lt;p&gt;Seleniumをラップして、ブラウザテスト(受入テスト)をRubyで書けるフレームワーク。
テストフレームワークはRack::Testを始め、いろいろ選べる模様。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.gebish.org/&#34;&gt;Geb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は759。&lt;/p&gt;

&lt;p&gt;Seleniumをラップして、 JUnitやTestNGと連携して、ブラウザテストをGroovyで書けるフレームワーク。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://selenide.org/&#34;&gt;Selenide&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GitHubの★は555。&lt;/p&gt;

&lt;p&gt;Seleniumをラップして、ブラウザテストをJavaで書けるフレームワーク。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これらよりさらに高級なツールに、&lt;a href=&#34;http://codecept.io/&#34;&gt;CodeceptJS&lt;/a&gt;というのがあって、これはJavaScriptでユーザ視点のブラウザテスト(受入テスト)を書けるフレームワーク。
基本的にはMochaとWebdriverIOをラップして、より抽象的なAPIを提供する。
WebdriverIOをProtractorとかNightmareとか&lt;a href=&#34;http://appium.io/&#34;&gt;Appium&lt;/a&gt;に代えられて、色んな環境のテストが統一的なAPIで書ける。
すごいけどバグを踏んだ時辛そう。&lt;/p&gt;

&lt;p&gt;また、ブラウザテストの文脈でよく名前が出る&lt;a href=&#34;http://karma-runner.github.io/1.0/index.html&#34;&gt;Karma&lt;/a&gt;は、テストフレームワークではなくて、HTTPサーバを起動して、テストを実行するためのHTMLを生成して、ブラウザを起動してそれを読み込んでくれたりするツール(i.e. テストランナ)。
主にユニットテストを色んなブラウザで実行するためのもので、ServiceNowのようなSaaSのテストには使えないはず。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;どれを使うか。&lt;/p&gt;

&lt;p&gt;ServiceNowアプリの開発がJavaScriptなので、テストもJavaScriptで書いてユニバーサルな感じにしたい。
のでCodeceptionとCapybaraとGebとSelenideは無し。&lt;/p&gt;

&lt;p&gt;テストのリモート実行やクロスブラウザテストを見据えてWebDriver使ってたほうがよさそうなので、
NightmareとCasper.jsとZombie.jsとPuppeteerとChromyも無し。&lt;/p&gt;

&lt;p&gt;TestCafeはWebDriverにこだわらなければよさそうだけど、今回はWebDriverで行きたい気分なのでパス。&lt;/p&gt;

&lt;p&gt;Protractorはよさそうだったけど、Angularで開発してるわけではないので、利用するのはちょっと違和感が。&lt;/p&gt;

&lt;p&gt;Nightwatch.jsは、全部メソッドチェーンでつなげる形で書くので、ブラウザ操作とアサーションがごっちゃになるのがちょっと見にくそう。
テストフレームワークは自分の好みで選びたい。&lt;/p&gt;

&lt;p&gt;ということで残ったのがWebdriverIO。
ややドキュメントが少なそうなのと、★が比較的少ないのが懸念。
ProtractorかNightwatch.jsにしとけばよかったってなりそうではある。&lt;/p&gt;

&lt;p&gt;むしろクロスブラウザを捨ててPuppeteerでもよかったかな…&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2017/08/14/webdriverio-chrome/&#34;&gt;WebdriverIOの環境を構築した記事&lt;/a&gt;を書いた。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>2017年夏、Selenium、ヘッドレスブラウザ</title>
          <link>https://www.kaitoy.xyz/2017/07/12/2017-selenium-headless-browsers/</link>
          <pubDate>Wed, 12 Jul 2017 22:36:22 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/07/12/2017-selenium-headless-browsers/</guid>
          <description>

&lt;p&gt;現在仕事で&lt;a href=&#34;https://www.servicenow.com/ja&#34;&gt;ServiceNow&lt;/a&gt;上で動くアプリケーションを開発していて、それのブラウザテストをどうやろうかというのを少し考えたので、書き残しておく。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;servicenowとは&#34;&gt;ServiceNowとは&lt;/h1&gt;

&lt;p&gt;本題とほとんど関係ないけど、一応ServiceNowに簡単に触れる。&lt;/p&gt;

&lt;p&gt;ServiceNowはITサービス管理のSaaS。
世界的にはITサービス管理のデファクトスタンダードとなっているが、日本ではこれから盛り上がりそうといった感じ。&lt;/p&gt;

&lt;p&gt;アプリケーションを開発するプラットフォームとしての側面もあり、JavaScript(ブラウザ側とサーバ側両方)でServiceNowの機能を拡張し、他システムと連携させたり処理を自動化したりできる。&lt;/p&gt;

&lt;p&gt;アプリケーションがServiceNowプラットフォームで動くので、テスト方法が悩ましい。
&lt;a href=&#34;https://docs.servicenow.com/bundle/istanbul-release-notes/page/release-notes/servicenow-platform/automated-test-framework-rn.html&#34;&gt;Automated Test Framework&lt;/a&gt;というテストフレームワークが提供されてはいるが、2017年1月にリリースされたばかりということもあるのか、機能がしょぼく、大したことはできない。
これが自前でブラウザテスト環境を作ろうと思った理由。&lt;/p&gt;

&lt;p&gt;アプリケーションがJavaScriptなので、テストもJavaScriptで書きたい。&lt;/p&gt;

&lt;h1 id=&#34;ブラウザテストとは&#34;&gt;ブラウザテストとは&lt;/h1&gt;

&lt;p&gt;ここでブラウザテストとは、稼働しているWebアプリケーションに、HTTPクライアントで接続して、レンダリングされたWebページを操作して実行する自動E2Eテストのこととする。
HTTPでWebコンテンツを取得して、HTML・CSSをパースしてレンダリングして、JavaScriptを実行するツール、つまりWebブラウザを何にするかというのと、それを自動で操作するのをどうするかというのと、テストどう書くのかということと、書いたテストをどう実行するかということと、テスト結果をどう集計してレポートするかといった辺りを考える必要がある。&lt;/p&gt;

&lt;p&gt;Qiitaの記事「&lt;a href=&#34;http://qiita.com/cognitom/items/6cce719b57341769c14d&#34;&gt;ブラウザテストツール総まとめ・2016年夏版&lt;/a&gt;」にブラウザテストのためのツールが色々載っている。
レイヤや目的が異なるツールがちょっとごっちゃになってる気がするけど。&lt;/p&gt;

&lt;h1 id=&#34;seleniumとかwebdriverとか&#34;&gt;SeleniumとかWebDriverとか&lt;/h1&gt;

&lt;p&gt;ブラウザテストはWebDriver抜きでは語れないので、とりあえずそれについて書く。
それにはまず&lt;a href=&#34;http://www.seleniumhq.org/&#34;&gt;Selenium&lt;/a&gt;について語らなければなるまい。&lt;/p&gt;

&lt;p&gt;ブラウザテスト創世記にはこうある。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;神は「光あれ」と言われた。
するとSeleniumがあった。&lt;/p&gt;

&lt;p&gt;神はその光を見て、良しとされた。
神はその光と闇とを分けられた。&lt;/p&gt;

&lt;p&gt;神は光を&lt;a href=&#34;http://www.seleniumhq.org/projects/remote-control/&#34;&gt;Selenium RC&lt;/a&gt; (aka Selenium 1)と名づけ、
闇 を&lt;a href=&#34;http://www.seleniumhq.org/projects/webdriver/&#34;&gt;Selenium WebDriver&lt;/a&gt; (aka Selenium 2)と名づけられた。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(Seleniumの歴史をもっとちゃんと知りたければ&lt;a href=&#34;http://blog.trident-qa.com/2013/05/so-many-seleniums/&#34;&gt;この記事&lt;/a&gt;を読むべし。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;要は、今ブラウザテストと言ったらSelenium、Seleniumと言ったらSelenium WebDriverというわけだ。&lt;/p&gt;

&lt;p&gt;Selenium WebDriverは、WebDriver APIでブラウザやDOMエレメントを操作するツール。
このAPIを実装したクライアントライブラリが各言語(Java、Ruby、Python、JavaScriptなど)で提供されていて、テストコードから利用できる。&lt;/p&gt;

&lt;p&gt;APIの裏ではドライバなるものが暗躍していて、OSやブラウザのネイティブAPIを使ってブラウザを操作している。
このドライバはブラウザごと(Chrome、Firefox、IEなど)に用意されていて、その実装形式がドライバ毎に割と違っている。
例えばFirefox用のやつ(&lt;a href=&#34;https://github.com/SeleniumHQ/selenium/wiki/FirefoxDriver&#34;&gt;Firefox Driver&lt;/a&gt;)はFirefox のアドオンを使うし、Chrome用のやつ(&lt;a href=&#34;https://github.com/SeleniumHQ/selenium/wiki/ChromeDriver&#34;&gt;ChromeDriver&lt;/a&gt;)は独立したネイティブアプリを介してブラウザを操作する。&lt;/p&gt;

&lt;p&gt;ドライバは(基本的に)ブラウザと同じマシンにある必要があり、実行するテストコードとも(基本的に)同居している必要がある。
テストを実行するマシンとは別のマシンのブラウザでテストしたければ&lt;a href=&#34;http://docs.seleniumhq.org/download/&#34;&gt;Selenium Server&lt;/a&gt; (aka Selenium Standalone Server)を使う。
Selenium Serverはブラウザとドライバと同じマシンで動き、テストコードから送信されたブラウザ操作コマンドを受信してドライバに伝える、プロキシ的な働きをしてくれる。&lt;/p&gt;

&lt;p&gt;Selenium Serverを使えば、クライアントライブラリが対応していないドライバでも利用できるというメリットもある。
Selenium Serverを使うと、オーバーヘッドはあるけどメリットが多いので、とりあえず使うようにしておけば間違いなさそう。&lt;/p&gt;

&lt;p&gt;Selenium Serverが受け取るブラウザ操作コマンドは、HTTPでJSONデータとして送信される。
この辺りの通信は、もともと&lt;a href=&#34;https://github.com/SeleniumHQ/selenium/wiki/JsonWireProtocol&#34;&gt;JsonWireProtocol&lt;/a&gt; (aka WebDriver Wire Protocol)で規定されていた。
JsonWireProtocolを&lt;a href=&#34;https://en.wikipedia.org/wiki/World_Wide_Web_Consortium&#34;&gt;W3C&lt;/a&gt;が国際標準規格化したのが&lt;a href=&#34;https://www.w3.org/TR/webdriver/&#34;&gt;WebDriver&lt;/a&gt;というプロトコル。
このWebDriverプロトコルは、ユーザエージェントとDOMエレメントをリモートコントロールするためのインターフェースを定めている。
現在、JsonWireProtocolは廃止扱いで、Selenium WebDriverはWebDriverプロトコルを実装している。&lt;/p&gt;

&lt;p&gt;この辺り、&lt;a href=&#34;https://app.codegrid.net/entry/selenium-1&#34;&gt;この記事&lt;/a&gt;が図解してて分かりやすい。&lt;/p&gt;

&lt;p&gt;ChromeDriverはWebDriverプロトコルを実装してるので、Selenium Server無しでもリモート実行できるけど、それでもやはりSelenium Serverを介したほうが、ドライバを簡単に切り替えられそうでよさそう。&lt;/p&gt;

&lt;p&gt;Selenium ServerとかChromeDriverのようにWebDriverプロトコルのサーバ機能を実装したものは&lt;a href=&#34;https://github.com/SeleniumHQ/selenium/wiki/RemoteWebDriverServer&#34;&gt;RemoteWebDriverServer&lt;/a&gt;と呼ばれることもある。
それにアクセスするクライアントは&lt;a href=&#34;https://github.com/SeleniumHQ/selenium/wiki/RemoteWebDriver&#34;&gt;RemoteWebDriver&lt;/a&gt;とかRemoteWebDriverクライアントとか呼ばれる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ということで、色々ややこしい(公式も自分でややこしいと言ってる)が、結局WebDriverは何かと言えば、普通は上記ドライバそのものを指す。
ので、以下においても、WebDriverと書いたらそれを指すこととする。&lt;/p&gt;

&lt;h1 id=&#34;ヘッドレス&#34;&gt;ヘッドレス&lt;/h1&gt;

&lt;p&gt;もう一つブラウザテストの文脈で重要なのが、&lt;a href=&#34;https://en.wikipedia.org/wiki/Headless_software&#34;&gt;ヘッドレス&lt;/a&gt;という概念なので、ここでちょっと触れる。&lt;/p&gt;

&lt;p&gt;ヘッドレスとは、ソフトウェアがGUIなしで動く性質とか機能のこと。&lt;/p&gt;

&lt;p&gt;ブラウザテストは、テスト実行時にブラウザを起動するわけだが、ブラウザってのは普通GUIが付いていて、Windowsだったらログインしてないと動かせないし、LinuxだったらXの起動も必要だ。
これだと、テストを定期的に自動実行したり、CIしたりするのが難しい。
また、GUIは動作が遅く、テストに時間がかかる。&lt;/p&gt;

&lt;h3 id=&#34;ヘッドレスブラウザ&#34;&gt;ヘッドレスブラウザ&lt;/h3&gt;

&lt;p&gt;こうした問題を解決するため、ヘッドレスブラウザというものが開発された。
ヘッドレスブラウザには以下のようなものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://phantomjs.org/&#34;&gt;PhantomJS&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;多分一番有名なヘッドレスブラウザ。
JavaScriptとC++などで書かれていて、JavaScriptから操作できる。
2011年にリリースされ、まだ開発が続いている。
レンダリングエンジンはWebKitで、JavaScriptエンジンはWebKitに組み込みの&lt;a href=&#34;https://trac.webkit.org/wiki/JavaScriptCore&#34;&gt;JavaScriptCore&lt;/a&gt;で、
Windows、OS X、Linuxなどで動く。
WebDriver有り。(&lt;a href=&#34;https://github.com/detro/ghostdriver&#34;&gt;Ghost Driver&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://htmlunit.sourceforge.net/&#34;&gt;HtmlUnit&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Chrome、Firefox、IEをシミュレートできるJava製のツールで、
JavaのAPIで操作できる。
2002年にリリースされ、まだ開発が続いている。
レンダリングエンジンは(多分)自前で、JavaScriptエンジンはRhino。
WebDriver有り。(&lt;a href=&#34;https://github.com/SeleniumHQ/htmlunit-driver&#34;&gt;HtmlUnitDriver&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://scrapinghub.com/splash/&#34;&gt;Splash&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Python製。2013年に開発がスタートし、現在も鋭意開発中。
LinuxとOS Xをサポートしてて、Windowsでは(多分)動かない。
HTTP APIにJSONをPOSTして操作するもので、&lt;a href=&#34;https://www.lua.org/&#34;&gt;Lua&lt;/a&gt;のクライアントライブラリが提供されている。
レンダリングエンジンはWebKitで、JavaScriptエンジンはWebKitに組み込みのJavaScriptCore。
WebDriverなさげ。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://triflejs.org/&#34;&gt;TrifleJS&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;JavaScriptとC#(.NET 4.0)で書かれていて、Windowsでしか動かない。
 レンダリングエンジンはTridentで、IEをエミュレートする。
 JavaScriptエンジンはV8。PhantomJSと同じAPIを実装していて、JavaScriptから操作できる。
 2013年に開発がスタートし、ベータ版のまま開発中断してしまった模様。
 WebDriverは、ロードマップにはあるけどまだ実装されてない。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;あと、似たようなものに&lt;a href=&#34;https://slimerjs.org/index.html&#34;&gt;SlimerJS&lt;/a&gt;と&lt;a href=&#34;https://electron.atom.io/&#34;&gt;Electron&lt;/a&gt;と&lt;a href=&#34;https://github.com/tmpvar/jsdom&#34;&gt;jsdom&lt;/a&gt;がある。&lt;/p&gt;

&lt;p&gt;SlimerJSは、GeckoとSpiderMonkeyの上に開発された、スクリプトから操作できるテスト用途向けブラウザだけど、ヘッドレスではない。&lt;/p&gt;

&lt;p&gt;ElectronはJavaScriptでデスクトップアプリケーションを開発するためのフレームワーク。
&lt;a href=&#34;https://www.chromium.org/Home&#34;&gt;Chromium&lt;/a&gt;というブラウザを積んでいて、それをElectron APIでプログラマティックに操作できるらしく、ブラウザテストにも使われる。
(&lt;a href=&#34;http://qiita.com/hiroshitoda/items/288706978cd4c6df0f5f&#34;&gt;Seleniumでも操作できる&lt;/a&gt;。)
けどこれもヘッドレスではない。&lt;/p&gt;

&lt;p&gt;jsdomはDOMツリーとそれに対する操作をエミュレートするツールで、そもそもブラウザではないはずなんだけど、HTTPでWebコンテンツダウンロードして解析もできるし、すごくヘッドレスブラウザっぽい。
けどちゃんとブラウザしてるかが怪しく、UIテストには使われてもブラウザテストにはあまり使われないっぽい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ヘッドレスブラウザにも色々あるが結局、テスト用に作られたブラウザであって、実際に多くのエンドユーザに使われて揉まれているGUI有りブラウザに比べて、品質が悪かったり動きが違ったりする(らしい)。
JavaScriptのバージョンのキャッチアップが遅かったりも。&lt;/p&gt;

&lt;h3 id=&#34;xvfb&#34;&gt;Xvfb&lt;/h3&gt;

&lt;p&gt;ヘッドレスブラウザの問題は、実際のブラウザではないということに尽きる。
実際のブラウザをヘッドレスで使えたら万事が上手くいくわけだが、実はこれがLinuxでなら出来る。
&lt;a href=&#34;https://www.x.org/releases/X11R7.7/doc/man/man1/Xvfb.1.xhtml&#34;&gt;Xvfb&lt;/a&gt;というツールを使って。
(Xvfbはあまりメンテされてなくて&lt;a href=&#34;https://xpra.org/trac/wiki/Xdummy&#34;&gt;Xdummy&lt;/a&gt;が代わりに最近熱いみたいだけど。)&lt;/p&gt;

&lt;p&gt;Xvfbはフレームバッファをエミュレートし、ディスプレイが無い環境でも動くヘッドレスXサーバ。
これを使うと、GUIのある普通のブラウザでもヘッドレス環境で動かせる。&lt;/p&gt;

&lt;p&gt;Xvfbについては&lt;a href=&#34;http://blog.amedama.jp/entry/2016/01/03/115602&#34;&gt;この記事&lt;/a&gt;が分かりやすい。&lt;/p&gt;

&lt;h3 id=&#34;chrome-59&#34;&gt;Chrome 59&lt;/h3&gt;

&lt;p&gt;Xvfbを使えば大分幸せになりそうだが、ブラウザ以外のツールを起動しなければいけなかったり、Windowsで使えなかったり、まだちょっと不満が残る。&lt;/p&gt;

&lt;p&gt;そんななか、2017年6月、Chrome 59がリリースされ、ヘッドレスモードを搭載した。
Windowsは現時点で未対応だけど、すぐに対応されるはずだ。
ほかの実ブラウザもこの流れに乗ってヘッドレスモードを実装したら、最高に幸せな世界になるではないか。&lt;/p&gt;

&lt;p&gt;Chromeのヘッドレスモード搭載を受け、&lt;a href=&#34;https://www.infoq.com/jp/news/2017/04/Phantomjs-future-uncertain&#34;&gt;PhantomJSは開発停止&lt;/a&gt;した。
もうヘッドレスブラウザはその役目を終えつつあるということなのだろう。&lt;/p&gt;

&lt;p&gt;Chrome 59のヘッドレスモードの使い方は&lt;a href=&#34;https://developers.google.com/web/updates/2017/04/headless-chrome?hl=ja&#34;&gt;この記事&lt;/a&gt;が分かりやすい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;
&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上のような感じのことが調べて分かって、SeleniumとChromeのヘッドレスモードを使いたいと思ったところで、
続きはまた&lt;a href=&#34;https://www.kaitoy.xyz/2017/08/04/browser-test-framework/&#34;&gt;別の記事&lt;/a&gt;。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>git rebaseを図解する</title>
          <link>https://www.kaitoy.xyz/2017/06/10/git-rebase/</link>
          <pubDate>Sat, 10 Jun 2017 00:00:17 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/06/10/git-rebase/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;この記事&lt;/a&gt;を読んだ、またはGitのオブジェクトモデルを理解していることを前提に、&lt;a href=&#34;https://git-scm.com/&#34;&gt;&lt;strong&gt;Git&lt;/strong&gt;&lt;/a&gt;の &lt;code&gt;git rebase&lt;/code&gt; というコマンドについて説明する。&lt;/p&gt;

&lt;p&gt;このコマンドは、コミット履歴を改変できるGit特有のコマンドで、&lt;a href=&#34;http://qiita.com/kaitoy/items/ed22474837b943eb6d97&#34;&gt;分かり辛いGitコマンド&lt;/a&gt;の中でも最も分かり辛い部類のものだ。
Gitの最後の関門と言えよう。
けど、それだけに使いこなせばとても便利なものでもある。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;git-rebaseがもつたった一つの機能&#34;&gt;git rebaseがもつたった一つの機能&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;git rebase&lt;/code&gt;にはいろんなオプションがあって、ちょっと調べただけだと、コミットを移動する機能とコミットを修正する機能の二つがあるように見えるかもしれないが、実際は単一の機能しかないシンプルなコマンドだ。&lt;/p&gt;

&lt;p&gt;その機能とは、指定した範囲のコミットが含む変更を、別に指定したコミットのコードベースに適用するというもの。&lt;/p&gt;

&lt;p&gt;コマンドの基本形は次のようなものだ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ git rebase --onto master dev bugfix
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このコマンドは、&lt;code&gt;bugfix&lt;/code&gt;から辿れるコミット群から、&lt;code&gt;dev&lt;/code&gt;から辿れるコミット群を除いたコミット群が含む変更を、&lt;code&gt;master&lt;/code&gt;のコードベースに適用する。&lt;/p&gt;

&lt;p&gt;と書いても分からないので図解する。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase/スライド6.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;このスライドを見ると、&lt;code&gt;git rebase&lt;/code&gt;に指定した3つのブランチのそれぞれの使われ方が分かるはず。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git rebase --onto master dev bugfix&lt;/code&gt;が実行する処理をもっと正確に言うと、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;bugfix&lt;/code&gt;を&lt;code&gt;checkout&lt;/code&gt;して(i.e. &lt;code&gt;HEAD&lt;/code&gt;を&lt;code&gt;bugfix&lt;/code&gt;にして)、&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dev..HEAD&lt;/code&gt;のコミット群が含む変更を、それぞれ仮領域にパッチとして保存して、&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git reset --hard master&lt;/code&gt;して、&lt;/li&gt;
&lt;li&gt;仮領域に保存した変更を、&lt;code&gt;HEAD&lt;/code&gt;が指すコミットのコードベースにひとつひとつ順番に適用する。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;上記コマンドで&lt;code&gt;bugfix&lt;/code&gt;のところを省略すると、ステップ1の&lt;code&gt;checkout&lt;/code&gt;が省略される。
言い換えると、上記コマンドは次の二つのコマンドに分解できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ git checkout bugfix
$ git rebase --onto master dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;さらに、&lt;code&gt;--onto master&lt;/code&gt;を省略すると、ステップ3の&lt;code&gt;reset&lt;/code&gt;先が変わり、&lt;code&gt;dev&lt;/code&gt;になる。
このときのコマンドの形は、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ git rebase dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;という見慣れたものになるが、これが最初に挙げた基本形の省略形だと認識しておくと応用が利く。&lt;/p&gt;

&lt;p&gt;以下に&lt;code&gt;git rebase dev&lt;/code&gt;の動きを細かめに図解する。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド6.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_short/スライド7.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;インタラクティブモード&#34;&gt;インタラクティブモード&lt;/h2&gt;

&lt;p&gt;前節のスライドに書いたパッチの適用をカスタマイズできるのがインタラクティブモードで、これは&lt;code&gt;-i&lt;/code&gt;オプションで有効にできる。
インタラクティブモードを使うと、パッチをスキップしたり、順番を変えたり、まとめたり、分割したり、編集したりでき、またパッチとパッチの間に任意のコマンドを実行でき、例えばパッチごとにユニットテストを実行できたりする。&lt;/p&gt;

&lt;p&gt;インタラクティブモードの使い方についてはググればたくさん出てくるのでここには書かない。
&lt;a href=&#34;http://tkengo.github.io/blog/2013/05/16/git-rebase-reference/&#34;&gt;この記事&lt;/a&gt;辺りがわかりやすい。&lt;/p&gt;

&lt;p&gt;インタラクティブモードのユースケースとしてよく紹介されるのが、&lt;code&gt;git rebase -i HEAD^^&lt;/code&gt;で直近の二つのコミットを変更するといったものだが、これを図解すると以下のようになる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド6.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド7.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド8.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-rebase/git_rebase_interactive/スライド9.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;このスライドを見ると、&lt;code&gt;git rebase dev&lt;/code&gt;と&lt;code&gt;git rebase -i HEAD^^&lt;/code&gt;は、パッチの適用がインタラクティブかどうか以外は同じ処理をしていることがわかる。
見た目の違いに惑わされないようにしたい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git rebase&lt;/code&gt;はブランチを複数指定したりして分かり辛いコマンドであることは確かだけど、上記の基本形を押さえておけばすんなり理解できるはず。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Elasticsearch、Logstash、Filebeat、elasticsearch-headでログを見てみた</title>
          <link>https://www.kaitoy.xyz/2017/04/04/elasticsearch-in-nnmi-log/</link>
          <pubDate>Tue, 04 Apr 2017 09:24:12 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/04/04/elasticsearch-in-nnmi-log/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://www8.hp.com/jp/ja/software-solutions/network-node-manager-i-network-management-software/&#34;&gt;NNMi&lt;/a&gt;ログを&lt;a href=&#34;https://www.elastic.co/jp/products/beats/filebeat&#34;&gt;Filebeat&lt;/a&gt;で集めて&lt;a href=&#34;https://www.elastic.co/jp/products/logstash&#34;&gt;Logstash&lt;/a&gt;で構造化して&lt;a href=&#34;https://www.elastic.co/jp/products/elasticsearch&#34;&gt;Elasticsearch&lt;/a&gt;に入れて&lt;a href=&#34;https://mobz.github.io/elasticsearch-head/&#34;&gt;elasticsearch-head&lt;/a&gt;で見てみたけど、ログ量が少なかったせいかあんまり恩恵が感じられなかった話。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;elasticsearchとは&#34;&gt;Elasticsearchとは&lt;/h1&gt;

&lt;p&gt;Elasticsearchは&lt;a href=&#34;https://www.elastic.co/&#34;&gt;Elastic社&lt;/a&gt;が開発している&lt;a href=&#34;https://www.elastic.co/products&#34;&gt;Elastic Stack&lt;/a&gt;(旧ELK Stack)というオープンソースなデータ収集分析ツール群のコア製品。
内部で&lt;a href=&#34;https://lucene.apache.org/core/&#34;&gt;Lucene&lt;/a&gt;を使っていて、そのためJava製。
「分散型RESTful検索/分析エンジン」と自称しているが、スキーマレスでNoSQLなドキュメント指向分散データベース管理システムとも見れる。&lt;/p&gt;

&lt;p&gt;Elasticsearchインスタンスはノードと呼ばれ、単一または複数のノードによるシステムはクラスタと呼ばれる。
同一ネットワークに複数のノードを立ち上げると自動で相互検出してクラスタを構成してくれ、そこにデータを入れると自動で冗長化して分散配置してくれるので、堅牢でレジリエントでスケーラブルなシステムが簡単に構築できる。&lt;/p&gt;

&lt;p&gt;Elasticsearchが管理するデータの最小単位はドキュメントと呼ばれ、これはひとつのJSONオブジェクトで、RDBにおける行にあたる。
つまり、JSONオブジェクトの各フィールドがRDBにおける列にあたる。
同種のドキュメントの集まりはインデックスと呼ばれ、これはRDBにおけるテーブルにあたる。
テーブルのスキーマにあたるものはマッピングと呼ばれ、ドキュメントのフィールドの型情報(e.g. string, integer)などを含み、Elasticsearchが自動で生成してくれる。(指定もできる、というかすべきらしい。)
インデックス内ではさらにタイプという属性でドキュメントをカテゴライズできる、が、マニュアルからはタイプはあまり&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.2/general-recommendations.html#_avoid_types&#34;&gt;使ってほしくない&lt;/a&gt;雰囲気が感じられる。&lt;/p&gt;

&lt;p&gt;(2018/4/25追記: 6.0で、一つのインデックスに複数のタイプを作ることができなくなり、7.0では完全に&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/6.x/removal-of-types.html&#34;&gt;タイプが廃止される&lt;/a&gt;ことになった。)&lt;/p&gt;

&lt;p&gt;因みに、インデックスがRDBのデータベースでタイプがRDBのテーブルと説明されることもあるが、これは古いたとえで、&lt;a href=&#34;https://www.elastic.co/blog/index-vs-type&#34;&gt;公式が間違いだったとしている&lt;/a&gt;ので忘れてあげたい。&lt;/p&gt;

&lt;p&gt;インデックスは分散処理のために分割でき、分割した各部分はシャードと呼ばれる。
シャードを冗長化のためにコピーしたものはレプリカシャードと呼ばれ、レプリカシャードにより成るインデックスはレプリカと呼ばれる。
デフォルトでは、ひとつのインデックスは5つのシャードに分割され、1つのレプリカが作成される。&lt;/p&gt;

&lt;p&gt;インターフェースはREST APIだけ。
REST APIに検索したいドキュメントを投げると、ドキュメントのフィールド毎に自動で形態素解析とかして&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E8%BB%A2%E7%BD%AE%E3%82%A4%E3%83%B3%E3%83%87%E3%83%83%E3%82%AF%E3%82%B9&#34;&gt;転置インデックス&lt;/a&gt;作って保管してくれる。
検索もJSONで表現したクエリをREST APIに投げることで結果をJSONで受け取ることができる。
検索は転置インデックスや分散処理のおかげで速く、また&lt;a href=&#34;http://qiita.com/r4-keisuke/items/d653d26b6fc8b7955c05#%E3%82%B9%E3%82%B3%E3%82%A2%E3%83%AA%E3%83%B3%E3%82%B0&#34;&gt;スコアリング&lt;/a&gt;によってより適切な結果が得られるようになっている。&lt;/p&gt;

&lt;p&gt;今回使ったのはv5.2.1。&lt;/p&gt;

&lt;h1 id=&#34;logstashとは&#34;&gt;Logstashとは&lt;/h1&gt;

&lt;p&gt;LogstashはElastic Stackに含まれる製品で、データ収集エンジンであり、データの受け取り、解析/加工、出力の三つの機能を持つリアルタイムパイプラインを構成する。
この三つの機能はそれぞれ&lt;a href=&#34;https://www.elastic.co/guide/en/logstash/5.2/input-plugins.html&#34;&gt;インプットプラグイン&lt;/a&gt;、&lt;a href=&#34;https://www.elastic.co/guide/en/logstash/5.2/filter-plugins.html&#34;&gt;フィルタプラグイン&lt;/a&gt;、&lt;a href=&#34;https://www.elastic.co/guide/en/logstash/5.2/output-plugins.html&#34;&gt;アウトプットプラグイン&lt;/a&gt;で提供されていて、プラグインの組み合わせにより様々なパイプラインを構成できる。&lt;/p&gt;

&lt;p&gt;インプットプラグインは単位データ(一回分のログなど)を受け取り、タイムスタンプなどのメタデータを付けたりパースしたりしてイベントを生成し、パイプラインに流す。
フィルタプラグインはインプットプラグインからイベントを受け取り、設定されたルールに従って情報を拡充したり変更したり構造化したり秘匿情報を消したりしてアウトプットプラグインに渡す。
アウトプットプラグインは指定されたディスク上のパスやデータベースやアプリやサービスにイベントを書き込んだり送信したりする。&lt;/p&gt;

&lt;p&gt;名前の通りもともとログ収集ツールだったが、今では様々なデータに対応していて、テキストログファイルの他にsyslog、HTTPリクエストやJDBCなんかの入力を受けることもできる。&lt;/p&gt;

&lt;p&gt;Ruby(とJava)で書かれている。&lt;/p&gt;

&lt;p&gt;今回使ったのはv5.2.2で、プラグインは以下を使った。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;インプット: &lt;a href=&#34;https://www.elastic.co/guide/en/logstash/5.2/plugins-inputs-beats.html&#34;&gt;beats&lt;/a&gt; 3.1.12: Beats(後述)からデータを受け取るプラグイン。&lt;a href=&#34;https://github.com/logstash-plugins/logstash-input-beats/blob/v3.1.12/PROTOCOL.md&#34;&gt;Lumberjack&lt;/a&gt;というElastic社が開発しているプロトコルを使い、TCPネットワーク上でデータを受信する。&lt;/li&gt;
&lt;li&gt;フィルタ: &lt;a href=&#34;https://www.elastic.co/guide/en/logstash/5.2/plugins-filters-grok.html&#34;&gt;grok&lt;/a&gt; 3.3.1: 正規表現でパターンマッチして非構造化データを構造化するプラグイン。ログ解析の定番で、例えば、ログからタイムスタンプ、クラス名、ログメッセージを抽出したりする。&lt;a href=&#34;https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns&#34;&gt;組み込みのパターン&lt;/a&gt;が120個くらいあり、&lt;a href=&#34;https://httpd.apache.org/&#34;&gt;Apache HTTP Server&lt;/a&gt;やsyslogのログであれば自分で正規表現を書く必要はない。&lt;/li&gt;
&lt;li&gt;アウトプット: &lt;a href=&#34;https://www.elastic.co/guide/en/logstash/5.2/plugins-outputs-elasticsearch.html&#34;&gt;elasticsearch&lt;/a&gt; 6.2.6: Elasticsearchにイベントをポストするプラグイン。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;beatsとは&#34;&gt;Beatsとは&lt;/h1&gt;

&lt;p&gt;BeatsもElastic Stackに含まれる製品で、データを採取してLogstashやElasticsearchに送信する製品群の総称。
&lt;a href=&#34;https://github.com/elastic/beats/tree/master/libbeat&#34;&gt;libbeat&lt;/a&gt;というGoのライブラリを使って作られていて、以下のようなものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/elastic/beats/tree/master/filebeat&#34;&gt;Filebeat&lt;/a&gt;: ログファイルからログを取得する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/elastic/beats/tree/master/heartbeat&#34;&gt;Heartbeat&lt;/a&gt;: リモートサービスをpingして生死監視する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/elastic/beats/tree/master/metricbeat&#34;&gt;Metricbeat&lt;/a&gt;: OSとその上のサービスやアプリから稼動情報を取得する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/elastic/beats/tree/master/packetbeat&#34;&gt;Packetbeat&lt;/a&gt;: パケットキャプチャしてネットワークのトラフィックを監視する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/elastic/beats/tree/master/winlogbeat&#34;&gt;Winlogbeat&lt;/a&gt;: Windowsのイベントログを取得する。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;今回使ったのはFilebeat 5.2.2。&lt;/p&gt;

&lt;p&gt;Filebeatは指定したログファイルを監視し、変更を検知してリアルタイムにログを送信してくれる。
FilebeatとLogstashが仲良くやってくれて、バッファがあふれるなどすることによるログの損失が起きないようにしてくれるらしい。
Logstashが単位データを受け取るので、ログファイルからひとつひとつのログを切り出すのはFilebeatの責務。
一行一ログなら何も考えなくていいけど、大抵複数行のログがあるのでなんとかする必要がある。&lt;/p&gt;

&lt;h1 id=&#34;elasticsearch-headとは&#34;&gt;elasticsearch-headとは&lt;/h1&gt;

&lt;p&gt;elasticsearch-headは3rdパーティ製(個人製?)のElasticsearchのWeb UI。
ElasticsearchのUIはREST APIしかないのでこういうものを使わないと辛い。&lt;/p&gt;

&lt;p&gt;ElasticsearchのGUIとしてはElastic Stackの&lt;a href=&#34;https://www.elastic.co/jp/products/kibana&#34;&gt;Kibana&lt;/a&gt;が有名だけど、これは大量のログから統計的な情報を見るのに便利そうなものであって、今回やりたかった障害原因調査のためにログを細かく追うのには向いてなさそうだったので使わなかった。&lt;/p&gt;

&lt;h1 id=&#34;実験環境&#34;&gt;実験環境&lt;/h1&gt;

&lt;p&gt;今回は単にログがどんな感じに見えるか試したかっただけなので、全部ローカルで動かして、ローカルに置いた静的なログファイルを読むだけ。
環境はWindows 7のノートPC。&lt;/p&gt;

&lt;p&gt;ログファイルは&lt;code&gt;C:\Users\Kaito\Desktop\logs\&lt;/code&gt;においた&lt;code&gt;nnm-trace.log&lt;/code&gt;と&lt;code&gt;nnm-trace.log.1&lt;/code&gt;。
これらはNNMiのメインログで、&lt;a href=&#34;https://docs.oracle.com/javase/8/docs/api/java/util/logging/package-summary.html&#34;&gt;JUL&lt;/a&gt;で出力されたもの。
NNMiは無料のコミュニティエディションのv10.00をVMのCentOSに適当に入れて採った。&lt;/p&gt;

&lt;p&gt;ログはだいたい以下の様な一行のもの。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2017-03-15 19:09:55.896 INFO  [com.hp.ov.nms.spi.common.deployment.deployers.ExtensionServicesDeployer] (Thread-2) Deploying arris-device
2017-03-15 19:09:55.923 WARNING [com.hp.ov.nms.topo.spi.server.concurrent.NmsTimerTaskImpl] (NmsWorkManager Scheduler) Skipping task execution because previous execution has not completed: com.hp.ov.nnm.im.NnmIntegrationModule$EnablerTask@3abdac77
2017-03-15 19:09:56.120 INFO  [com.hp.ov.nms.disco.spi.DiscoExtensionNotificationListener] (Thread-2) Disco deployed mapping rules: META-INF/disco/rules/cards/ArrisCard.xml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;たまに複数行のものがある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2017-03-15 19:13:30.872 INFO  [com.hp.ov.nms.trapd.narrowfilter.NarrowTrapAnalysis] (pool-1-thread-18)
***** Hosted Object Trap Rate Report *****
Hosted object trap storm detection and suppression stage started: Wed Mar 15, 2017 19:09:00.746 PM.

***** General Statistics *****
Hosted Object trap rate threshold: 10 traps/sec.
Average trap rate: 0 traps/sec.
Total traps received: 0.
Total traps received without configuration: 0.
Total traps suppressed: 0.
Number of trap configurations: 1.


***** END Hosted object trap storm report END *****
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ログレベルの部分(e.g. INFO、WARNING)はロケールによって日本語になったりする。&lt;/p&gt;

&lt;p&gt;スレッド名の部分(e.g. pool-1-thread-18)は丸括弧で囲われているが、丸括弧を含むことがある。&lt;/p&gt;

&lt;p&gt;クラス名の部分(e.g. com.hp.ov.nms.trapd.narrowfilter.NarrowTrapAnalysis)は、パッケージ名がついていないこともある。デフォルトパッケージってこともないだろうに。&lt;/p&gt;

&lt;h1 id=&#34;elastic-stackのインストールと設定&#34;&gt;Elastic Stackのインストールと設定&lt;/h1&gt;

&lt;p&gt;Elastic Stackの三つはどれも、サイトからアーカイブをダウンロードして展開すればインストール完了。&lt;/p&gt;

&lt;p&gt;Filebeatの設定は、展開したディレクトリのトップにある&lt;code&gt;filebeat.yml&lt;/code&gt;に以下を書いた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;filebeat.prospectors:

- input_type: log
  paths:
    - C:\Users\Kaito\Desktop\logs\*

  multiline.pattern: &#39;^[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9]{3} &#39;
  multiline.negate: true
  multiline.match: after

output.logstash:
  hosts: [&amp;quot;localhost:5043&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;paths&lt;/code&gt;でログファイルを指定して、&lt;code&gt;hosts&lt;/code&gt;でログの送信先を指定している。
また、複数行のログに対応するため、&lt;code&gt;multiline&lt;/code&gt;という設定を書いていて、タイムスタンプで始まらない行は前の行の続きになるようにしている。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Logstashの設定は、展開したディレクトリのトップに&lt;code&gt;pipeline.conf&lt;/code&gt;というファイルを作ってそこに以下を書いた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;input {
    beats {
        port =&amp;gt; &amp;quot;5043&amp;quot;
    }
}
filter {
    grok {
        match =&amp;gt; { &amp;quot;message&amp;quot; =&amp;gt; &amp;quot;%{TIMESTAMP_ISO8601:timestamp} (?&amp;lt;log_level&amp;gt;[^ ]+) +\[(?:%{JAVACLASS:class}|(?&amp;lt;class&amp;gt;[A-Za-z0-9_]+))\] \((?&amp;lt;thread&amp;gt;.+(?=\) ))\) (?&amp;lt;log_message&amp;gt;.*)&amp;quot;}
    }
}
output {
    elasticsearch {
        hosts =&amp;gt; [ &amp;quot;localhost:9200&amp;quot; ]
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;input&lt;/code&gt;と&lt;code&gt;output&lt;/code&gt;の部分は単にbeatsプラグインとelasticsearchプラグイン使うようにして送受信先を指定しているだけ。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;filter&lt;/code&gt;の部分は、grokプラグインを使うようにしつつそのパターンマッチングを指定している。
FilebeatがJSONオブジェクトの&lt;code&gt;message&lt;/code&gt;というフィールドに一回分のログを入れて送ってくるので、そこからタイムスタンプ、ログレベル、クラス、スレッド、ログメッセージを抽出し、それぞれ&lt;code&gt;timestamp&lt;/code&gt;、&lt;code&gt;log_level&lt;/code&gt;、&lt;code&gt;class&lt;/code&gt;、&lt;code&gt;thread&lt;/code&gt;、&lt;code&gt;log_message&lt;/code&gt;というフィールドに入れるように設定。
&lt;code&gt;TIMESTAMP_ISO8601&lt;/code&gt;と&lt;code&gt;JAVACLASS&lt;/code&gt;が組み込みのパターンで、それぞれタイムスタンプとJavaのクラス名にマッチする。
けど&lt;code&gt;JAVACLASS&lt;/code&gt;がパッケージ名の付いてないクラス名にマッチしないのでちょっと細工している。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Elasticsearchの設定は、展開したディレクトリ内の&lt;code&gt;config/elasticsearch.yml&lt;/code&gt;に以下を書いた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;http.cors.enabled: true
http.cors.allow-origin: &amp;quot;*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これは、elasticsearch-headがWebアプリなので、そこからElasticsearchにアクセスできるように&lt;a href=&#34;https://en.wikipedia.org/wiki/Cross-origin_resource_sharing&#34;&gt;CORS&lt;/a&gt;を有効にする設定。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで設定は終わり。&lt;/p&gt;

&lt;h1 id=&#34;各製品の起動&#34;&gt;各製品の起動&lt;/h1&gt;

&lt;p&gt;Filebeatは普通はサービスとして起動するみたいだけど、今回はコマンドラインで起動する。&lt;/p&gt;

&lt;p&gt;展開したディレクトリで以下のコマンドを実行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;filebeat.exe -e -c filebeat.yml -d &amp;quot;publish&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Logstashは展開したディレクトリで以下のコマンド。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;bin\logstash.bat -f pipeline.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Elasticsearchは展開したディレクトリで以下のコマンド。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;bin\elasticsearch.bat
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;しばらく待つと起動完了し、&lt;code&gt;localhost:9200&lt;/code&gt;でHTTPリクエストを待ち始める。
試しにブラウザで&lt;code&gt;http://localhost:9200/_cluster/health&lt;/code&gt;にアクセスすると、以下の様にElasticsearchクラスタのステータスがJSONで返ってきた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{&amp;quot;cluster_name&amp;quot;:&amp;quot;elasticsearch&amp;quot;,&amp;quot;status&amp;quot;:&amp;quot;yellow&amp;quot;,&amp;quot;timed_out&amp;quot;:false,&amp;quot;number_of_nodes&amp;quot;:1,&amp;quot;number_of_data_nodes&amp;quot;:1,&amp;quot;active_primary_shards&amp;quot;:5,&amp;quot;active_shards&amp;quot;:5,&amp;quot;relocating_shards&amp;quot;:0,&amp;quot;initializing_shards&amp;quot;:0,&amp;quot;unassigned_shards&amp;quot;:5,&amp;quot;delayed_unassigned_shards&amp;quot;:0,&amp;quot;number_of_pending_tasks&amp;quot;:0,&amp;quot;number_of_in_flight_fetch&amp;quot;:0,&amp;quot;task_max_waiting_in_queue_millis&amp;quot;:0,&amp;quot;active_shards_percent_as_number&amp;quot;:50.0}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上でElastic Stackが起動し、Elasticsearchにログが読み込まれた。&lt;/p&gt;

&lt;h1 id=&#34;elasticsearch-headでログを見る&#34;&gt;elasticsearch-headでログを見る&lt;/h1&gt;

&lt;p&gt;elasticsearch-headは&lt;code&gt;git clone https://github.com/mobz/elasticsearch-head.git&lt;/code&gt;してその中の&lt;code&gt;index.html&lt;/code&gt;をブラウザで開けば動く。組み込みのWebサーバを起動する手順もあるけど。&lt;/p&gt;

&lt;p&gt;開くと&lt;code&gt;http://localhost:9200/&lt;/code&gt;(i.e. Elasticsearch)にアクセスしてGUIに情報を表示してくれる。
Overviewタブには以下の様に、&lt;code&gt;logstash-2017.03.17&lt;/code&gt;というインデックスが作られていて、それに対して5つのシャードとレプリカシャードが作られている様が表示される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/elasticsearch-in-nnmi-log/overview.png&#34; alt=&#34;overview.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Browserタブではざっくりとログの一覧が見れる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/elasticsearch-in-nnmi-log/browser.png&#34; alt=&#34;browser.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Structured Queryタブでは条件を指定してログを表示できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/elasticsearch-in-nnmi-log/query.png&#34; alt=&#34;query.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;ここでは2017/3/15 19:09:50から2017/3/15 19:10:00の間のINFOレベルのDiscoExtensionNotificationListenerクラスのログを10件表示した。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;不要な列を非表示にできないし、ソートもできないし、ログメッセージ見難くくて全く使えない。
もう少しいいGUIがあれば使えるのか、そもそもElasticsearchを使うのが間違っているのか。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Firedrop(プライベートベータ)が全く期待外れだった件</title>
          <link>https://www.kaitoy.xyz/2017/03/05/firedrop-private-beta/</link>
          <pubDate>Sun, 05 Mar 2017 23:28:03 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/03/05/firedrop-private-beta/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://firedrop.ai/&#34;&gt;Firedrop&lt;/a&gt;という現在開発中のサービスがある。
WebサイトのデザインをAIがサポートしてくれるサービスだ。&lt;/p&gt;

&lt;p&gt;2016年夏の&lt;a href=&#34;https://bita.jp/dml/dwango_dennosho2-1&#34;&gt;ニュース&lt;/a&gt;を見たとき、AIがテキストコンテンツを解析してサイトを自動構成してくれ、さらにA/Bテストなどを自動でやってサイトを継続的に改善すると言う衝撃的なふれこみだったので、即座にアーリーアクセスに登録した。&lt;/p&gt;

&lt;p&gt;それからしばらく忘れていたが、3月2日にプライベートベータへの招待メールが来たので早速試してみたら、かなりのスモールスタートをしたようで全く期待外れだった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h1 id=&#34;firedrop-プライベートベータ-の機能&#34;&gt;Firedrop(プライベートベータ)の機能&lt;/h1&gt;

&lt;p&gt;Firedrop(プライベートベータ)では、SachaというAIがWebサイトの構築をサポートしてくれる。
こいつが実のところほとんど知性を感じない単なるチャットボットで、なるほどこれは見事な&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%84%A1%E8%84%B3&#34;&gt;人工無脳&lt;/a&gt;だと感心してしまうほどだ。&lt;/p&gt;

&lt;p&gt;Firedropのアカウントを作るとまず、Sachaとチャットしながらサイトの概要(タイトル、概要、画像など)を教えることになる。
するとSachaがざっくりとシングルページのサイトを作ってくれるので、それをまたSachaとのチャットで調整したりコンテンツ追加したりする。&lt;/p&gt;

&lt;p&gt;チャットと言っても、基本はこちらは5,6個ある選択肢の中からセリフを選ぶサウンドノベル方式で、一応任意の文章も入力できるがあいさつするくらいしか使い道がない。&lt;/p&gt;

&lt;p&gt;追加コンテンツはテキストと画像を渡すと自動でレイアウトしてくれるが、すごくいい感じにしてくれるというわけでもないし、むしろ画像が見切れたりするし、細かい調整はできないので、妥協できるレイアウトになるまでチェンジを繰り返すデリヘル方式を採ることになる。
デリヘルなんて利用したことないけど。&lt;/p&gt;

&lt;p&gt;画像は自分でアップロードもできるけどFiredropが提供しているものもあって、後者のやつはSachaにキーワードを伝えるとそれっぽい画像を探してくれるあたりに唯一知性を感じる。&lt;/p&gt;

&lt;p&gt;デザインができたらSachaに頼むと&lt;code&gt;firedrop.me&lt;/code&gt;ドメインで公開してくれる。&lt;/p&gt;

&lt;p&gt;(FiredropのUIのスクリーンショットを載せようかと思ったけど、プライベートベータの規約を読んだ感じだめそうだったので載せない。)&lt;/p&gt;

&lt;h1 id=&#34;実際に作ってみた&#34;&gt;実際に作ってみた&lt;/h1&gt;

&lt;p&gt;今回実際にFiredropで&lt;a href=&#34;https://www.kaitoy.xyz/2016/12/11/goslings-development-memo0-intro-design/&#34;&gt;Goslings&lt;/a&gt;のサイトを作ってみて、できたのが&lt;a href=&#34;https://quvoi3op.firedrop.me/&#34;&gt;これ&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;ひどい。&lt;/p&gt;

&lt;p&gt;そもそも当初のテキストコンテンツを解析してサイトを自動構成というコンセプトはどこへ行ったのか。
GoslingsのReadmeを入力したらシャレオツなサイトをささっと作ってくれるイメージだったんだけど。&lt;/p&gt;

&lt;p&gt;まだまだ開発中の機能がたくさんあるそうなので、GAまでにはもうちょっとなんとかなるんだろう。
あまり期待はしない。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Hibernateはどのようにして私のキャリアを破滅寸前にしたか</title>
          <link>https://www.kaitoy.xyz/2017/02/23/how-hibernate-ruined-my-career/</link>
          <pubDate>Thu, 23 Feb 2017 00:25:03 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/02/23/how-hibernate-ruined-my-career/</guid>
          <description>

&lt;p&gt;このエントリでは、Grzegorz Gajosによる記事、&lt;a href=&#34;http://ggajos.com/how-hibernate-ruined-my-career/&#34;&gt;How Hibernate Almost Ruined My Career&lt;/a&gt;を紹介する。
(Grzegorzから和訳と転載の許可は得た。)
以下はその全文の和訳だが、意訳超訳が混じっているので、もとのニュアンスを知りたければ元記事を読んでもいいし、読まなくてもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;想像してくれ。
君はJava開発者で、次のビッグプロジェクトを開始しようとしているところだ。
君は、そのプロジェクト全体に影響する根本的な決断をする必要がある。
君の柔軟なデータモデルをオブジェクト指向で抽象化するベストな方法を選択したい。生のSQLを扱いたくはないからね。
どんな種類のデータもサポートしたいし、理想では全種のデータベースをサポートしたい。&lt;/p&gt;

&lt;p&gt;すぐに思いつくのは、単にHibernateを使うという解だ。そうだろ？
Javaディベロッパの90%は君に同意するだろう。
しかし、それって正しい決断になっているだろうか？&lt;/p&gt;

&lt;p&gt;Hibernateが一般に受け入れられているスタンダードだからといって盲目的に採用してしまうと、どんな問題が発生するかを見てみよう。&lt;/p&gt;

&lt;p&gt;モニカというJava開発者がいるとしよう。
モニカは最近出世してアーキテクトの役職に就き、会社の新製品のための技術スタックを選定する責任者になった。
彼女は、Javaの世界にはデータベースとのやり取りを扱うたった一つの適切なツールがあることを知っている。Hibernateだ。
Hibernateは良く知られ支持されているJPAのスタンダードではあるが、プロジェクト開始前に多少のチェックをするのが定跡だ。
幸いにも、同僚のベンが適任者を知っている。&lt;/p&gt;

&lt;h1 id=&#34;4年前-hibernateは銀の弾丸かのように見えた&#34;&gt;4年前、Hibernateは銀の弾丸かのように見えた&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;ベン: やあモニカ。ジョンを紹介させてくれ。彼はHibernateの達人だ。君の助けになるはずだ。&lt;/li&gt;
&lt;li&gt;モニカ: ジョン、時間を取ってくれてありがとう。
今、私たちが次なる目玉製品を開発しようとしてるのは知ってる？
次のFacebookやGoogleになるつもりなの。
忙しくなるわ。巨大なものになる。
本当にすてき！
みんなとても興奮してる！
私はアーキテクトの役に就いたから、とりあえず採用する技術スタックを選定しなければいけないの。
ひとつだけまだ欠けてるのが永続化なんだけど…&lt;/li&gt;
&lt;li&gt;ジョン: Hibernate！&lt;/li&gt;
&lt;li&gt;モニカ: そう！そのとおり！
わたしもそう考えていたの！
それならわたしたちにぴったりで上手く行きそうでしょう。
マーケットと豊富な実績に裏付けられた、真の業務問題のための真の業務ソリューション。
とてもたくさんのポジティブな経験談を聞いたことがあるわ。
けど、一つ問題があって、チームメンバのひとりがそれに絶対反対してるの。
アプリケーションとデータベースの間に別のレイヤを加えるのを気にして。
彼はすごく頭がいいから、これが良い決断だと納得させるには本当にしっかりした根拠が必要なの。
助けてくれる？&lt;/li&gt;
&lt;li&gt;ジョン: もちろん、よろこんで！
Hibernateは、実際、すばらしいツールです。
銀行といった、大きな真の業務ソリューションで広く使われています。
それを使って失敗するということはありえません。
永続化ときたらHibernate。
Javaで書いているならそれが完全に正しい選択ですし、さらには他の言語への移植もあります。
どれだけ多くの職務記述書がそれを要求しているか！&lt;/li&gt;
&lt;li&gt;モニカ: 全く同感！
同じことを感じていたわ。
前のプロジェクトで、ほとんどのところで生のJDBCからSQLを使っていたんだけど、ばかげてた！
そうでしょ！
けど、実は、ほんとに優秀なSQL屋がチームにいて、Hibernateが生成したSQLを見て神経質になってるの。
きたなくて読みにくいって。
これって将来問題になりそう？&lt;/li&gt;
&lt;li&gt;ジョン: 気を付けてください。DBA屋ってのは違ったものの見方をします。
彼らはプロジェクトにおける自分の立場をHibernateに奪われるのではないかと危惧しています。
さらに、データベースには組み込みのクエリ最適化機構があるので、クエリの実際の見た目がどんなかは気にする必要はありません。
データベースが最適化してくれます。
それが高速開発ってものです。
SQLにはまねできません。&lt;/li&gt;
&lt;li&gt;モニカ: ほんとに？
もうSQLを触らなくていいの？
すごい！
この前DBAがクエリの最適化に数週間かけていたわ。
数週間！
あぁ、こんなこと言うのは恥ずかしいんだけど、わたしたちが何を使っていたか分かる？
…ストアドプロシージャ(笑)
もうくちゃくちゃだった。
そのプロジェクト、まだそれ使ってるって信じられる？
そこの人たちほんとに気の毒だわ。
未だにあんな退屈なコードを何度も何度も書かないといけないなんて。
あれってJavaというかもうSQLプロジェクトじゃない？&lt;/li&gt;
&lt;li&gt;ジョン: それはまさにオブジェクト指向とリレーショナルのアプローチの違いです。
いわゆるオブジェクト指向インピーダンスミスマッチですね。
Hibernateはその溝を埋めてくれます。
開発者はビジネスロジックの構築に専念できます。
ステークホルダもマネージメント全体も幸せになれます。
最も重要となることをしましょう。ビジネスです！
ボイラープレートの多くは消え去り、魔法のようで目には見えませんが、ロジックとデータとの間にしっかりとしたコネクションができるのです。&lt;/li&gt;
&lt;li&gt;モニカ: 相互協調。充実したシナジー。
まるでデータベースが最初から言語の一部だったかのよう。
信念の技術的飛躍の指導者になれてとても幸せ。
ソフトウェアという旅路でワープスピードに乗ったみたい。&lt;/li&gt;
&lt;li&gt;ジョン: そう！その調子！&lt;/li&gt;
&lt;li&gt;モニカ: わーい！すごーい！
わくわくしてきた！たーのしー！
ありがとうジョン。
準備万端！&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;3年前-柔軟性のないソリューションとともに大きくなる苦悩&#34;&gt;3年前、柔軟性のないソリューションとともに大きくなる苦悩&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;モニカ: ねえジョン、去年話したプロジェクト覚えてる？&lt;/li&gt;
&lt;li&gt;ジョン: もちろん。調子はどうですか？&lt;/li&gt;
&lt;li&gt;モニカ: もうすぐリリースするわ。
全て順調。だけどいくつか疑問がわいてきたの。&lt;/li&gt;
&lt;li&gt;ジョン: いいですよ。聞いてください。&lt;/li&gt;
&lt;li&gt;モニカ: ええと、もうデータベーススキーマを一から生成することはできないんだけど、データロスのないスキーマ変更をサポートするにはどうするのが一番いい？&lt;/li&gt;
&lt;li&gt;ジョン: えぇ、まず、Hibernateはプロダクション環境での移行ツールとして使われることを想定していません。
FlywayDBやLiquibaseといったものを使うべきです。
結構簡単ですよ。移行スクリプトを書いて、それでエンティティモデルを更新しつつ、Hibernateのマッピングも直して、
実際のデータベース構造と同期するようにしてください。&lt;/li&gt;
&lt;li&gt;モニカ: ふーん、分かった。前のプロジェクトでは単に生のSQLで移行してた。&lt;/li&gt;
&lt;li&gt;ジョン: それでもいいと思います。エンティティモデルとスキーマが同期してさえいれば、好きなやり方でやってください。&lt;/li&gt;
&lt;li&gt;モニカ: そうね。
もう一つ、わたしたちいつも遅延フェッチと即時フェッチの問題と戦ってるの。
ある時、全部を即時でやることに決めたんだけど、それって最適じゃないでしょ？
それに、たまにセッションが残ってないせいかなにかで、フィールドにアクセスできないことがあるの。
それって普通？&lt;/li&gt;
&lt;li&gt;ジョン: もっとHibernateについて学ぶ必要があります。
データベースとのマッピングは単純ではありません。
複数のやりかたがあるのが普通です。
その中から自分に合ったものを選ぶのです。
遅延フェッチはオブジェクトを必要なときにロードできるようにしますが、アクティブなセッションの中で実行しないといけません。&lt;/li&gt;
&lt;li&gt;モニカ: わたしたちはまだ最終的なデプロイでどのデータベースエンジンを使うべきか迷ってるの。
Hibernateってポータブルだと思ってたけど、MS SQLの魔法を使うためにちょっとネイティブクエリを使ってて、実際にはプロダクション環境ではMySQLで行きたいんだけど。&lt;/li&gt;
&lt;li&gt;ジョン: HibernateはdetachedなCriteriaクエリかHQLを使っている限りは柔軟です。
ネイティブクエリを使ったらそのデータベースにソリューションが固定されちゃいますよ。&lt;/li&gt;
&lt;li&gt;モニカ: それならMS SQL専用にしないとダメみたいね。
最後の質問。チームメンバからHQLには「limit」キーワードがないと聞いたわ。
冗談かと思ったけど、わたしも見つけられなかった。
バカな質問で申し訳ないんだけど…&lt;/li&gt;
&lt;li&gt;ジョン: 確かに。HQLには「limit」はありません。
クエリオブジェクトでコントロールすることはできます。
データベースベンダ依存のものなので。&lt;/li&gt;
&lt;li&gt;モニカ: 他の要素は全部HQLにあるのに変ね。
まあ気にしないで。
時間取ってくれてありがとう！&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;2年前-わたしたちは今再びsqlでソリューションをハックしている&#34;&gt;2年前、わたしたちは今再びSQLでソリューションをハックしている&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;モニカ: ジョン、最初わたしたちSQLを触らないつもりだったけど、今はその必要があると感じてる。
要件が大きくなってきていて、それを避ける手立てはないみたいなの。
間違ったことをしているかもしれないけど、またSQLを毎日のように使い始めたわ。&lt;/li&gt;
&lt;li&gt;ジョン: いえ、それは間違っていません。
最初期にはデータベースを気に掛ける必要はありませんでしたが、プロジェクトが進んだ今では、SQLを使ってパフォーマンスの最適化に取り組むのはいいことです。&lt;/li&gt;
&lt;li&gt;モニカ: ときどきエラーを調査するのに数日かかるの。
なぜ期待通りに動かないのか、なぜ思いがけない結果が出力されるのかが全く分からないから、Hibernateが生成したSQLを解析しないといけないみたい。
Hibernateのバグトラッカーに載ってる有名な問題に当たったこともある。
それだけじゃない。エンティティモデルの同期を保ったまま適切な移行処理を書くのは難しいの。
Hibernateの内部をよく調査して、どう動くのかを予測する必要があって、時間を取られてしまう。&lt;/li&gt;
&lt;li&gt;ジョン: 学習曲線というのは常にあります。
たくさんの記述はいりませんが、どう動くかは知っておく必要があります。&lt;/li&gt;
&lt;li&gt;モニカ: 大きなデータセットを扱うのも厄介。
最近データベースに大量のインポートをしたんだけど、あまりにも遅かった。
あとで、速くするにはセッションをクリアする必要があったって分かったんだけど、それでもまだ全然遅い。
だから生のSQLで書き直すことにしたの。
笑ったわ。生のSQLを書くのが実際最速の方法だったから。
だから最後の選択肢としてそうすることに決めたの。&lt;/li&gt;
&lt;li&gt;ジョン: インポートはオブジェクト指向な処理ではないです。
Hibernateはオブジェクト指向設計に焦点を当てています。
ネイティブクエリという選択肢を忘れてはいけません。&lt;/li&gt;
&lt;li&gt;モニカ: Hibernateのキャッシュがどう動くか知りたいんだけど、教えてくれる？
ちょっと分からないの。
一次キャッシュとか二次キャッシュとかあるけど、どういうものなの？&lt;/li&gt;
&lt;li&gt;ジョン: もちろんです。
それはいわゆる永続データのトランザクションレベルキャッシュです。
クラスタやJVMレベルで、クラス毎やコレクション毎のキャッシュを設定できます。
クラスタキャッシュを組み込むことさえできます。
しかし、キャッシュは他のアプリケーションが永続化領域に加えた変更については関知しないことを覚えておいてください。
期限切れのキャッシュデータを定期的に消すように設定することはできますが。&lt;/li&gt;
&lt;li&gt;モニカ: ごめん。気分が悪くなってきた。
もう少し説明してくれる？&lt;/li&gt;
&lt;li&gt;ジョン: はい。
&lt;code&gt;save&lt;/code&gt;とか&lt;code&gt;update&lt;/code&gt;とか&lt;code&gt;saveOrUpdate&lt;/code&gt;にオブジェクトを渡したり、&lt;code&gt;load&lt;/code&gt;、&lt;code&gt;get&lt;/code&gt;、&lt;code&gt;list&lt;/code&gt;、&lt;code&gt;iterate&lt;/code&gt;、&lt;code&gt;scroll&lt;/code&gt;でオブジェクトを取得するときは常に、そのオブジェクトはセッションの内部キャッシュに追加されます。
一次キャッシュからオブジェクトやそのコレクションを削除することもできます。&lt;/li&gt;
&lt;li&gt;モニカ: あぁ…&lt;/li&gt;
&lt;li&gt;ジョン: さらに、キャッシュモードを制御することもできます。
&lt;code&gt;normal&lt;/code&gt;モードでは読み込みと書き込みで二次キャッシュを使います。
&lt;code&gt;get&lt;/code&gt;モードでは二次から読みますがライトバックはできません。
&lt;code&gt;put&lt;/code&gt;は&lt;code&gt;get&lt;/code&gt;と同じですが二次から読むことはできません。
&lt;code&gt;refresh&lt;/code&gt;モードもあります。
これは二次に書き込みますが、そこからは読み込まず、&lt;code&gt;use minimal puts&lt;/code&gt;プロパティを無視し、データベースからの全ての読み込み時に二次キャッシュを強制リフレッシュします。&lt;/li&gt;
&lt;li&gt;モニカ: いいわ。わかった。
ちょっと考えさせて。
もう遅いわ。行かなきゃ。
説明ありがとう！&lt;/li&gt;
&lt;li&gt;ジョン: どういたしまして！&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;2週間前-hibernateをあきらめる&#34;&gt;2週間前、Hibernateをあきらめる&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;モニカ: ジョン、わたしソフトウェア開発の新時代に入ろうとしてるんだと思ってた。
一光年の飛躍をしてるんだと思ってた。
けど、4年たった今も、わたしたちは同じ問題に対応してるみたい。単に違う方向から。
私はHibernateのアーキテクチャ、設定、ロギング、ネーミング戦略、Tuplizer、エンティティ名リゾルバ、拡張IDジェネレータ、IDジェネレータ最適化、ユニオンサブクラス、XDocletマークアップ、インデックス付きコレクションの双方向関連、3項関連、idbag、暗黙的ポリモーフィズムと他の継承マッピングの組み合わせ、二つの異なるデータストア間でのオブジェクトレプリケーション、detachedオブジェクトと自動バージョニング、コネクション開放モード、ステートレスセッションインターフェース、コレクション永続化の分類法、キャッシュレベル、遅延/即時フェッチ、他にもいろんなことを学ばなければならなかった。
わたしの知ってる全てがあっても、ひどい失敗になっていたと思う。
ソフトウェアの出来損ないだわ！
究極の失敗！
大参事！
アルマゲドン！&lt;/li&gt;
&lt;li&gt;ジョン: 待ってください！なにがあったんですか？&lt;/li&gt;
&lt;li&gt;モニカ: わたしたち行き詰ったの。
わたしたちのアプリケーションの性能はばかばかしいほど遅い！
レポートを取得するのに二日も待たないといけない！
二日でやっと顧客にダッシュボードを生成して見せられるの。
つまり毎日計算処理を開始させなければならない上に、ダッシュボードの情報はどんどん遅れてしまう。
うちのDBAエキスパートがクエリ最適化に2か月取り組んでるけど、データベース構造がめちゃくちゃで。
それを手伝ってる開発者もいるけど、困ったことに、DBAはSQLで考えているから、開発者はそれをdetached CriteriaかHQLに翻訳しようと何日も費やしてしまうの。
今となっては性能がかなり重要だから、できるだけネイティブSQLを使おうとしてるわ。
なんにせよ、データベーススキーマがはっきり間違っちゃってるから大したことはできない。
オブジェクト指向な視点ではそれでいいと感じていたけど、リレーショナルな視点では最悪だったみたい。
どうしてこうなっちゃったんだろう？
開発者はエンティティ構造を変えるのはかなりの労力になると言うから、それをする余裕はないし。
前のプロジェクトは乱雑ではあったけど、そんな窮地には陥らなかった。
既存のデータを処理する完全に別のアプリケーションを書くこともできた。
今は、生成されたテーブルを変えるのは危険だわ。
エンティティモデルが完全に正しく動くことを保証するのは本当に難しいもの。
けどこれさえも最悪な点ってわけではないわ！
性能改善するには、データベース問題だけでなく、データベースとアプリケーションの間のレイヤ全体の問題も解決しないといけない。
それが圧倒的！
この新しく加わった人たちはね、コンサルタントなの。
彼らはデータを抽出して、なにか別のストレージに入れて、外側から計算を実行しようとしてる。
どれも時間かかりすぎ！&lt;/li&gt;
&lt;li&gt;ジョン: なんと言っていいか分かりません。&lt;/li&gt;
&lt;li&gt;モニカ: いいのよジョン、あなたを責めはしないわ。
わたしはHibernateを選択して全ての問題を解決しようとしたけど、今ではそれが銀の弾丸ではないと分かる。
もうダメージは負ったし、それをなかったことにはできない。
実は、あなたにお願いしたいことがあるの。
わたしはこの4年間のキャリアをHibernateのあれこれとの戦いに費やしてしまったわ。
もう今の会社でわたしに未来はないみたい。
助けてくれない？&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;今日-学んだ教訓は&#34;&gt;今日、学んだ教訓は？&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;ジョン: やあピーター、モニカを紹介するよ。&lt;/li&gt;
&lt;li&gt;ピーター: やあモニカ！
わたしたちは新しい次なる目玉を開発しようとしてるんだけどね。
巨大なものになりそうだよ！
Uberみたいになりたいんだ！
永続化について何か知って…&lt;/li&gt;
&lt;li&gt;モニカ: Hibernateはダメ！&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;まとめ&#34;&gt;まとめ&lt;/h1&gt;

&lt;p&gt;モニカはHibernateのエキスパートだ。
しかし、この例ではHibernateは間違った選択だった。
彼女のソリューションが以前より大きな問題に変化したと気付いたときには、プロジェクト全体を脅かす最大の脅威になってしまっていた。&lt;/p&gt;

&lt;p&gt;データはアプリケーションの目的の中心で、好むと好まざるにかかわらず、アーキテクチャ全体に影響する。
このストーリーから学んだとおり、アプリケーションがデータベースを使うからとか、&lt;a href=&#34;http://d.hatena.ne.jp/keyword/%A5%BD%A1%BC%A5%B7%A5%E3%A5%EB%A5%D7%A5%EB%A1%BC%A5%D5&#34;&gt;ソーシャルプルーフ&lt;/a&gt;があるからというだけの理由でHibernateを選択してはいけない。
柔軟性をもつソリューションを選ぶべきだ。
堅牢なJDBCラッパには&lt;a href=&#34;http://docs.spring.io/spring/docs/current/javadoc-api/org/springframework/jdbc/core/JdbcTemplate.html&#34;&gt;JdbcTemplate&lt;/a&gt;や&lt;a href=&#34;http://jdbc.jcabi.com/&#34;&gt;Fluent JDBC Wrapper&lt;/a&gt;といった多くの選択肢がある。
あるいは他にも、&lt;a href=&#34;http://www.jooq.org/&#34;&gt;jOOQ&lt;/a&gt;といった強力なソリューションがある。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上がGrzegorzの記事。&lt;/p&gt;

&lt;p&gt;ジョンにそそのかされて、Hibernateへの期待が高まるあまり一時けもの並の知能になったモニカが、4年の間に現実を知り絶望していくさまが生々しく怖い話だ。
オブジェクト指向の都合だけでデータベーススキーマを決めてしまった辺りが一番の失敗だったんだろうか。
SQL中心に考えつつHibernateでORマッピングやスキーマを構築することも、HibernateとSQL両方熟知してればできるんだろうか。&lt;/p&gt;

&lt;p&gt;なんにせよ、Hibernateが忌み嫌われるようになった理由がよくわかる面白い記事だった。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ブログアドレスを変更したときにやったこと</title>
          <link>https://www.kaitoy.xyz/2017/02/14/change-subdomain/</link>
          <pubDate>Tue, 14 Feb 2017 09:51:42 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/02/14/change-subdomain/</guid>
          <description>

&lt;p&gt;このブログの閲覧数がそこそこの規模になってきたので、&lt;a href=&#34;https://www.google.co.jp/adsense/start/&#34;&gt;Google AdSense&lt;/a&gt;で小遣い稼ぎを始めようとしたら、最近サブドメインが&lt;code&gt;www&lt;/code&gt;じゃないとできないようになったようだったので、サブドメインを&lt;code&gt;tbd&lt;/code&gt;から&lt;code&gt;www&lt;/code&gt;に変更した話。&lt;/p&gt;

&lt;p&gt;変更自体はそんなに難しくなかったけど、Googleの検索順位を保つためにいろいろ気を使う必要があった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;ブログアドレスの変更&#34;&gt;ブログアドレスの変更&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/08/28/using-hugo/&#34;&gt;以前&lt;/a&gt;にも書いたが、このブログは&lt;a href=&#34;https://gohugo.io/&#34;&gt;&lt;strong&gt;Hugo&lt;/strong&gt;&lt;/a&gt;で作って&lt;a href=&#34;https://pages.github.com/&#34;&gt;&lt;strong&gt;GitHub Pages&lt;/strong&gt;&lt;/a&gt;でカスタムドメインで公開している。&lt;/p&gt;

&lt;p&gt;コメント欄を設けるために&lt;a href=&#34;https://disqus.com/&#34;&gt;&lt;strong&gt;Disqus&lt;/strong&gt;&lt;/a&gt;を使っている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cloudflare.com/&#34;&gt;&lt;strong&gt;Cloudflare&lt;/strong&gt;&lt;/a&gt;を使って&lt;a href=&#34;https://www.kaitoy.xyz/2016/07/01/https-support-by-cloudflare/&#34;&gt;全体をHTTPS化&lt;/a&gt;していて、その関係で&lt;code&gt;kaitoy.xyz&lt;/code&gt;ドメインの名前解決にはCloudflareのDNSを使っている。&lt;/p&gt;

&lt;p&gt;アクセス解析などのために&lt;a href=&#34;https://analytics.google.com/&#34;&gt;&lt;strong&gt;Google Analytics&lt;/strong&gt;&lt;/a&gt;と&lt;a href=&#34;https://www.google.com/webmasters/tools/home&#34;&gt;&lt;strong&gt;Google Search Console&lt;/strong&gt;&lt;/a&gt;を使ってる。&lt;/p&gt;

&lt;p&gt;この構成で、ブログアドレスの変更に必要だった修正を列挙する。(この順にやったわけではない。)&lt;/p&gt;

&lt;h4 id=&#34;1-ブログソース修正&#34;&gt;1. ブログソース修正&lt;/h4&gt;

&lt;p&gt;Hugoの設定ファイルである&lt;code&gt;config.toml&lt;/code&gt;に書いてある&lt;code&gt;baseurl&lt;/code&gt;の値を&lt;code&gt;https://tbd.kaitoy.xyz&lt;/code&gt;から&lt;code&gt;https://www.kaitoy.xyz&lt;/code&gt;に変え、また、各記事の内部リンクのURLも&lt;code&gt;www&lt;/code&gt;のに変えた。&lt;/p&gt;

&lt;p&gt;あと&lt;code&gt;robots.txt&lt;/code&gt;の&lt;code&gt;Sitemap&lt;/code&gt;のURLも&lt;code&gt;https://www.kaitoy.xyz/sitemap.xml&lt;/code&gt;に更新した。&lt;/p&gt;

&lt;h4 id=&#34;2-github-pagesの設定変更&#34;&gt;2. GitHub Pagesの設定変更&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kaitoy/blog&#34;&gt;ブログリポジトリ&lt;/a&gt;に行って、&lt;code&gt;Settings&lt;/code&gt;の&lt;code&gt;GitHub Pages&lt;/code&gt;欄の&lt;code&gt;Custom domain&lt;/code&gt;の値を&lt;code&gt;https://www.kaitoy.xyz&lt;/code&gt;に変えた。&lt;/p&gt;

&lt;p&gt;ついでにブログリポジトリのトップに表示される&lt;code&gt;Description&lt;/code&gt;の&lt;code&gt;Website&lt;/code&gt;の値も新しいURLに変更した。&lt;/p&gt;

&lt;p&gt;この変更によりありがたい副作用もあった。
GitHub Pagesは&lt;code&gt;www&lt;/code&gt;というサブドメインを特別扱いしていて、以下の恩恵を受けられるのだ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;wwwを省略したURL(apex domain)でアクセスすると、GitHub Pagesサーバがwww付きのURLに&lt;a href=&#34;https://help.github.com/articles/setting-up-an-apex-domain-and-www-subdomain/&#34;&gt;リダイレクトしてくれる&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://help.github.com/articles/about-supported-custom-domains/#www-subdomains&#34;&gt;安定していて速い&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;3-cloudflareのdns設定変更&#34;&gt;3. CloudflareのDNS設定変更&lt;/h4&gt;

&lt;p&gt;CloudflareのDNSで、もともと&lt;code&gt;CNAME&lt;/code&gt;レコードで&lt;code&gt;kaitoy.github.io&lt;/code&gt;(GitHub Pagesのデフォルトのドメイン)のエイリアスを&lt;code&gt;tbd&lt;/code&gt;にしていたのを&lt;code&gt;www&lt;/code&gt;に変更した。&lt;/p&gt;

&lt;p&gt;また、上記の通りapex domainでGitHub Pagesにアクセスしても上手いことやってくれるようになったので、&lt;code&gt;www.kaitoy.xyz&lt;/code&gt;のエイリアスを&lt;code&gt;kaitoy.xyz&lt;/code&gt;とする&lt;code&gt;CNAME&lt;/code&gt;レコードを追加した。
CloudflareのDNSはapex domain(i.e. &lt;code&gt;kaitoy.xyz&lt;/code&gt;)に対する&lt;code&gt;CNAME&lt;/code&gt;レコード設定を&lt;a href=&#34;https://support.cloudflare.com/hc/en-us/articles/200169056-CNAME-Flattening-RFC-compliant-support-for-CNAME-at-the-root&#34;&gt;サポートしている&lt;/a&gt;ので、これで&lt;code&gt;www.kaitoy.xyz&lt;/code&gt;でも&lt;code&gt;kaitoy.xyz&lt;/code&gt;でもGitHub Pagesにルーティングされるようになった。&lt;/p&gt;

&lt;h4 id=&#34;4-disqusの設定変更&#34;&gt;4. Disqusの設定変更&lt;/h4&gt;

&lt;p&gt;ホームの右上の歯車アイコンから&lt;code&gt;Admin&lt;/code&gt;を開いて、ヘッダの&lt;code&gt;Settings&lt;/code&gt;からブログのURLを選んでその設定画面を開き、&lt;code&gt;Website URL&lt;/code&gt;を&lt;code&gt;https://www.kaitoy.xyz&lt;/code&gt;に変更した。&lt;/p&gt;

&lt;h4 id=&#34;5-google-analyticsの設定変更&#34;&gt;5. Google Analyticsの設定変更&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;管理&lt;/code&gt;タブの&lt;code&gt;プロパティ設定&lt;/code&gt;の&lt;code&gt;デフォルトの URL&lt;/code&gt;を&lt;code&gt;https://www.kaitoy.xyz&lt;/code&gt;に変更しただけ。&lt;/p&gt;

&lt;h1 id=&#34;googleのページランクを保つためのあれこれ&#34;&gt;Googleのページランクを保つためのあれこれ&lt;/h1&gt;

&lt;p&gt;以前もどこかに書いたが、どんなにすばらしい内容の記事を書いてもGoogle検索結果の2,3ページくらいまでに出てこないんであれば誰も読んでくれない。
このブログのいくつかの記事はそれなりにいいキーワードでいい検索順位になっていたので、サブドメイン変更によってページランクに悪影響が出るのはなるべく避けたかった。&lt;/p&gt;

&lt;p&gt;調べたら、&lt;a href=&#34;https://support.google.com/webmasters/answer/6033049?hl=ja&amp;amp;ref_topic=6033084&#34;&gt;Google Search Consoleのヘルプ&lt;/a&gt;にまさにその悪影響を防ぐ方法が載っていたので、これに従ってあれこれした。&lt;/p&gt;

&lt;h4 id=&#34;1-自身を参照する-rel-canonical-リンクタグを付ける&#34;&gt;1. 自身を参照する &lt;code&gt;rel=&amp;quot;canonical&amp;quot;&lt;/code&gt;リンクタグを付ける&lt;/h4&gt;

&lt;p&gt;ブログの全てのページのヘッダに以下の様な移転先アドレスを指すlinkタグを付け、変更後のアドレスが正式なアドレスであることをGooglebotに教えてやる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;link rel=&amp;quot;canonical&amp;quot; href=&amp;quot;https://www.kaitoy.xyz/2015/07/18/first-post/&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hugoのソースでいうと以下の感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;link rel=&amp;quot;canonical&amp;quot; href=&amp;quot;{{ .Permalink }}&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;2-http-301リダイレクトを設定&#34;&gt;2. HTTP 301リダイレクトを設定&lt;/h4&gt;

&lt;p&gt;多分これが一番重要なんじゃなかろうか。&lt;/p&gt;

&lt;p&gt;HTTPステータスコードの&lt;a href=&#34;https://support.google.com/webmasters/answer/93633&#34;&gt;301&lt;/a&gt;はサイトのコンテンツが別のURLに恒久的に移転したことを示すもので、移転前のURLにアクセスしたクライアントに301を移転先のURLとともに返してやることで、HTTPレベルでのリダイレクトをさせることができる。&lt;/p&gt;

&lt;p&gt;GooglebotもこのステータスコードでブログURLの変更を知ることができるので、検索結果をよしなに移行してくれるはず。&lt;/p&gt;

&lt;p&gt;301を返すサーバには&lt;a href=&#34;https://www.xrea.com/&#34;&gt;XREA&lt;/a&gt;の無料サーバを使った。
このブログのドメインは&lt;a href=&#34;https://www.value-domain.com/&#34;&gt;バリュードメイン&lt;/a&gt;で買ったもので、ここがXREAと提携していたので無料サーバも合わせて確保していたもののほとんど使っていなかったので調度よかった。
調べたらこのサーバで、&lt;a href=&#34;https://httpd.apache.org/&#34;&gt;Apache HTTP Server&lt;/a&gt;の設定ファイルである&lt;code&gt;.htaccess&lt;/code&gt;が使えることが分かったので、以下の内容で作って&lt;code&gt;/public_html/&lt;/code&gt;に置いた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;Files ~ &amp;quot;^\.ht&amp;quot;&amp;gt;
deny from all
&amp;lt;/Files&amp;gt;

# Redirect
Redirect permanent / https://www.kaitoy.xyz/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、サーバの管理ページからドメインウェブ設定画面に行き、Mainのドメイン名を&lt;code&gt;tbd.kaitoy.xyz&lt;/code&gt;に設定。&lt;/p&gt;

&lt;p&gt;あとはCloudflareのDNS設定で、&lt;code&gt;tbd&lt;/code&gt;を上記XREAサーバのIPアドレスに解決する&lt;code&gt;A&lt;/code&gt;レコードを追加して完了。&lt;/p&gt;

&lt;h4 id=&#34;3-google-search-consoleのアドレス変更ツール実行&#34;&gt;3. Google Search Consoleのアドレス変更ツール実行&lt;/h4&gt;

&lt;p&gt;最後の仕上げとして、Google Search Consoleの&lt;a href=&#34;https://support.google.com/webmasters/answer/83106&#34;&gt;アドレス変更ツール&lt;/a&gt;を使ってGooglebotにアドレス変更を通知した。&lt;/p&gt;

&lt;p&gt;このツールはGoogle Search Consoleの管理サイトごとのページの右上の歯車アイコンから&lt;code&gt;アドレス変更&lt;/code&gt;を選択すると開け、以下のようなものが表示される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/change-subdomain/change_address.png&#34; alt=&#34;change_address.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;このウィザードに従って、移転先URL(プロパティ)の追加、301リダイレクトの動作確認、サイトの存在確認をして、アドレス変更のリクエストを送信するだけ。&lt;/p&gt;

&lt;p&gt;最後に、追加したプロパティの&lt;code&gt;クロール&lt;/code&gt;の&lt;code&gt;サイトマップ&lt;/code&gt;から、移転先サイトのサイトマップを送信して完了。
サイトマップはHugoがビルド時に生成してくれたやつ。&lt;/p&gt;

&lt;p&gt;今&lt;a href=&#34;https://support.google.com/webmasters/answer/6033049?hl=ja&amp;amp;ref_topic=6033084&#34;&gt;Google Search Consoleのヘルプ&lt;/a&gt;を見直したら移転前のサイトマップも送信しろと書いてあるのに気付いた。
これはやらなかったけど、やった方がよかったのかも。&lt;/p&gt;

&lt;p&gt;ともあれ、移転後一時的に検索順位が大きく落ちたものの、1,2週間位でもとにもどったので、この移転は概ね成功だったと思う。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goslings開発メモ - その5: Spring Boot最終編 (静的リソース処理)</title>
          <link>https://www.kaitoy.xyz/2017/01/24/goslings-development-memo5-spring-boot-static-resources/</link>
          <pubDate>Tue, 24 Jan 2017 09:01:49 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/01/24/goslings-development-memo5-spring-boot-static-resources/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/17/goslings-development-memo4-spring-boot-logging/&#34;&gt;Goslings開発メモ - その4: Spring Boot続続続編 (ロギング)&lt;/a&gt;」の続き。&lt;/p&gt;

&lt;p&gt;Spring Boot最終編で、静的リソース処理について。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;spring-boot-spring-mvc-での静的リソース処理&#34;&gt;Spring Boot(Spring MVC)での静的リソース処理&lt;/h1&gt;

&lt;p&gt;この時点でのGoslingsは単なるREST APIサーバで、アクセスしてもJSONを返すだけだ。
アプリとしての体を成すためには、そのAPIを利用するクライアントコード、つまりHTMLドキュメントやCSSファイルやJavaScriptファイル(静的リソース)も返すようにしないといけない。
HTMLドキュメントを返す場合、普通はなんらかの&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%86%E3%83%B3%E3%83%97%E3%83%AC%E3%83%BC%E3%83%88%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%B3&#34;&gt;テンプレートエンジン&lt;/a&gt;を使うものだが、Goslingsは本当に単純なGUIなので、サーバに置いたHTMLファイルをそのまま返したい。&lt;/p&gt;

&lt;p&gt;「Getting Started Guides」には&lt;a href=&#34;https://spring.io/guides/gs/serving-web-content/&#34;&gt;Serving Web Content with Spring MVC&lt;/a&gt;というのが乗っているが、これは&lt;a href=&#34;http://www.thymeleaf.org/&#34;&gt;Thymeleaf&lt;/a&gt;というテンプレートエンジンを使うものなのでちょっと違う。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/htmlsingle/#boot-features-spring-mvc-static-content&#34;&gt;Spring Bootリファレンスガイド&lt;/a&gt;によると、クラスパス(または&lt;code&gt;ServletContext&lt;/code&gt;のルート)の&lt;code&gt;/static/&lt;/code&gt;、&lt;code&gt;/public/&lt;/code&gt;、&lt;code&gt;/resources/&lt;/code&gt;、&lt;code&gt;/META-INF/resources/&lt;/code&gt;のいずれかに静的リソースを置けば、特にコードを書かなくてもクライアントからアクセスできるらしい。
(逆に、一般的に静的リソースを置く場所である、プロジェクトの&lt;code&gt;src/main/webapp/&lt;/code&gt;には置くべきでないとのこと。これは、jarにパッケージングするときにビルドツールに無視されることが多いため。)&lt;/p&gt;

&lt;p&gt;この仕組みについて、&lt;a href=&#34;https://spring.io/blog/2013/12/19/serving-static-web-content-with-spring-boot&#34;&gt;この記事&lt;/a&gt;を参考にちょろっとソースを見た感じでは、これらのパスは&lt;a href=&#34;https://github.com/spring-projects/spring-boot/blob/v1.4.3.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/ResourceProperties.java#L44&#34;&gt;&lt;code&gt;ResourceProperties&lt;/code&gt;の&lt;code&gt;CLASSPATH_RESOURCE_LOCATIONS&lt;/code&gt;&lt;/a&gt;に定義されていて、これを&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/api/org/springframework/boot/autoconfigure/web/WebMvcAutoConfiguration.html&#34;&gt;&lt;code&gt;WebMvcAutoConfiguration&lt;/code&gt;&lt;/a&gt;が&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/config/annotation/ResourceHandlerRegistry.html&#34;&gt;&lt;code&gt;ResourceHandlerRegistry&lt;/code&gt;&lt;/a&gt;で&lt;a href=&#34;https://github.com/spring-projects/spring-boot/blob/v1.4.3.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/WebMvcAutoConfiguration.java#L291&#34;&gt;リソースロケーションとして登録する&lt;/a&gt;ことで静的リソース置き場たらしめている模様。
(この&lt;code&gt;ResourceHandlerRegistry&lt;/code&gt;は&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/ResourceHttpRequestHandler.html&#34;&gt;&lt;code&gt;ResourceHttpRequestHandler&lt;/code&gt;&lt;/a&gt;を設定するファサード的なものっぽい。)&lt;/p&gt;

&lt;p&gt;で、&lt;code&gt;@SpringBootApplication&lt;/code&gt;(&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/&#34;&gt;その1&lt;/a&gt;参照)が付いているクラスがあって、&lt;code&gt;spring-webmvc.jar&lt;/code&gt;がクラスパスにあると、&lt;a href=&#34;http://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/config/annotation/EnableWebMvc.html&#34;&gt;&lt;code&gt;@EnableWebMvc&lt;/code&gt;&lt;/a&gt;がSpring Bootによって付けられ、そこからごにょごにょして上記&lt;code&gt;WebMvcAutoConfiguration&lt;/code&gt;が実行される。
&lt;code&gt;spring-webmvc.jar&lt;/code&gt;は&lt;code&gt;spring-boot-starter-web.jar&lt;/code&gt;(&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/&#34;&gt;その1&lt;/a&gt;参照)が引っ張ってくる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;なお、Spring MVCの静的リソース処理の全体の流れについては
、ちょっと古いけど「&lt;a href=&#34;https://spring.io/blog/2014/07/24/spring-framework-4-1-handling-static-web-resources&#34;&gt;handling static web resources&lt;/a&gt;」という記事が分かりやすい。
要は、URLに指定されたパスからサーバ上のリソースを探し当てる&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/ResourceResolver.html&#34;&gt;&lt;code&gt;ResourceResolver&lt;/code&gt;&lt;/a&gt;というものが優先度順に連なっているリゾルバチェイン(&lt;a href=&#34;http://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/ResourceResolverChain.html&#34;&gt;&lt;code&gt;ResourceResolverChain&lt;/code&gt;&lt;/a&gt;)があって、まずこいつがリソースを取得する。
次に、そのリソースを加工するトランスフォーマチェイン(&lt;a href=&#34;http://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/ResourceTransformerChain.html&#34;&gt;&lt;code&gt;ResourceTransformerChain&lt;/code&gt;&lt;/a&gt;)というものに通し、その結果をクライアントに返す。
トランスフォーマチェインは&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/ResourceTransformer.html&#34;&gt;&lt;code&gt;ResourceTransformer&lt;/code&gt;&lt;/a&gt;が連なったもの。
リゾルバチェインとトランスフォーマチェインは上記&lt;code&gt;ResourceHttpRequestHandler&lt;/code&gt;に設定される。&lt;/p&gt;

&lt;p&gt;リゾルバには以下の様なものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/PathResourceResolver.html&#34;&gt;&lt;code&gt;PathResourceResolver&lt;/code&gt;&lt;/a&gt;: &lt;code&gt;ResourceHttpRequestHandler&lt;/code&gt;に設定されたリソースロケーションからリソースを単純に検索するリゾルバ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/CachingResourceResolver.html&#34;&gt;&lt;code&gt;CachingResourceResolver&lt;/code&gt;&lt;/a&gt;: キャッシュからリソースを検索するリゾルバ。テンプレートエンジンの処理結果のキャッシュとかが返るのは多分ここから。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/GzipResourceResolver.html&#34;&gt;&lt;code&gt;GzipResourceResolver&lt;/code&gt;&lt;/a&gt;: &lt;a href=&#34;https://ja.wikipedia.org/wiki/Gzip&#34;&gt;gzip&lt;/a&gt;で圧縮されたリソース、つまりURLで指定されたパスに&lt;code&gt;.gz&lt;/code&gt;という拡張子を付けたリソースを検索するリゾルバ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/VersionResourceResolver.html&#34;&gt;&lt;code&gt;VersionResourceResolver&lt;/code&gt;&lt;/a&gt;: &lt;a href=&#34;https://spring.io/blog/2014/07/24/spring-framework-4-1-handling-static-web-resources#resource-versioning&#34;&gt;リソースバージョニング&lt;/a&gt;を実現するためのリゾルバ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/WebJarsResourceResolver.html&#34;&gt;&lt;code&gt;WebJarsResourceResolver&lt;/code&gt;&lt;/a&gt;: &lt;a href=&#34;http://www.webjars.org/&#34;&gt;WebJars&lt;/a&gt;のjarファイル内のリソースを検索するリゾルバ。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;リゾルバの設定などについてはQiitaの&lt;a href=&#34;http://qiita.com/kazuki43zoo/items/e12a72d4ac4de418ee37&#34;&gt;この記事&lt;/a&gt;ががよくまとまっている。
凝ったことをしたいときは参照しよう。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;トランスフォーマには以下の様なものがある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/CssLinkResourceTransformer.html&#34;&gt;&lt;code&gt;CssLinkResourceTransformer&lt;/code&gt;&lt;/a&gt;: CSSファイル内のリンクをクライアントがアクセスできるURLに変換する。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/CachingResourceTransformer.html&#34;&gt;&lt;code&gt;CachingResourceTransformer&lt;/code&gt;&lt;/a&gt;: 変換したリソースをキャッシュする。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/servlet/resource/AppCacheManifestTransformer.html&#34;&gt;&lt;code&gt;AppCacheManifestTransformer&lt;/code&gt;&lt;/a&gt;: HTML5のAppCacheマニフェスト内のリソースを扱うトランスフォーマ。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;デフォルトで&lt;code&gt;ResourceHttpRequestHandler&lt;/code&gt;には&lt;code&gt;PathResourceResolver&lt;/code&gt;だけが設定されている。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上をまとめると、クライアントからGetリクエストが来ると、&lt;code&gt;WebMvcAutoConfiguration&lt;/code&gt;が設定したリソースロケーション(e.g. &lt;code&gt;/static/&lt;/code&gt;)を&lt;code&gt;PathResourceResolver&lt;/code&gt;が検索して、そこに置いてあるHTMLファイルとかをクライアントに返してくれる、ということであろう。&lt;/p&gt;

&lt;p&gt;Javaのコードを全く書かなくていいので楽。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Javaのコードを書いて静的リソースファイルを明示することもできる。
&lt;a href=&#34;http://qiita.com/tag1216/items/3680b92cf96eb5a170f0&#34;&gt;Qiitaの記事&lt;/a&gt;によれば、&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Controller.html&#34;&gt;&lt;code&gt;@Controller&lt;/code&gt;&lt;/a&gt;を付けたクラスのリクエストハンドラで以下の様にファイルへのパスを返せばいいらしい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@RequestMapping(&amp;quot;/hoge&amp;quot;)
public String hoge() {
    return &amp;quot;/hoge.html&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;単純な静的リソースに対してこれをやるユースケースはあまりなさそう。
テンプレートエンジンを使っていてパラメータを渡したいときにはこういうリクエストハンドラを書くことになる。&lt;/p&gt;

&lt;h1 id=&#34;spring-bootのウェルカムページとファビコン&#34;&gt;Spring Bootのウェルカムページとファビコン&lt;/h1&gt;

&lt;p&gt;Spring Bootは&lt;code&gt;index.html&lt;/code&gt;と&lt;code&gt;favicon.ico&lt;/code&gt;という名のファイルを特別扱いする。
前者がウェルカムページで後者がファビコン。&lt;/p&gt;

&lt;h4 id=&#34;ウェルカムページ&#34;&gt;ウェルカムページ&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/htmlsingle/#boot-features-spring-mvc-static-content&#34;&gt;Spring Bootのリファレンスガイド&lt;/a&gt;にもちらっとかいてあるけど、リソースロケーションに&lt;code&gt;index.html&lt;/code&gt;というファイルを置いておくと、それがウェルカムページとして設定され、URLのパスにルート(e.g. &lt;code&gt;http://localhost:8080/&lt;/code&gt;)を指定したときにクライアントに返るようになる。&lt;/p&gt;

&lt;p&gt;ソースを見ると、上記&lt;code&gt;WebMvcAutoConfiguration&lt;/code&gt;の&lt;a href=&#34;https://github.com/spring-projects/spring-boot/blob/v1.4.3.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/WebMvcAutoConfiguration.java#L297&#34;&gt;ここ&lt;/a&gt;でそのための設定している。
&lt;code&gt;/META-INF/resources/index.html&lt;/code&gt;、&lt;code&gt;/resources/index.html&lt;/code&gt;、&lt;code&gt;/static/index.html&lt;/code&gt;、&lt;code&gt;/public/index.html&lt;/code&gt;の順に探すようで、複数個所に&lt;code&gt;index.html&lt;/code&gt;を置いた場合は最初に見つかったものがウェルカムページになる。(そんなことする意味はないが。)&lt;/p&gt;

&lt;h4 id=&#34;ファビコン&#34;&gt;ファビコン&lt;/h4&gt;

&lt;p&gt;ファビコンについてはSpring Bootの現時点でリリース済みバージョンのリファレンスガイドにはほとんど情報がないが、&lt;code&gt;1.5.0.BUILD-SNAPSHOT&lt;/code&gt;のリファレンスガイドには以下の様に書いてある。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;27.1.6 Custom Favicon&lt;/p&gt;

&lt;p&gt;Spring Boot looks for a favicon.ico in the configured static content locations and the root of &amp;gt; the classpath (in that order). If such file is present, it is automatically used as the favicon &amp;gt; of the application.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;つまり、リソースロケーションかクラスパスのルートに&lt;code&gt;favicon.ico&lt;/code&gt;というファイルを置いておくと、それをファビコンとしてクライアントに返してくれる。&lt;/p&gt;

&lt;p&gt;これもやっぱり&lt;code&gt;WebMvcAutoConfiguration&lt;/code&gt;が&lt;a href=&#34;https://github.com/spring-projects/spring-boot/blob/v1.4.3.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/WebMvcAutoConfiguration.java#L319&#34;&gt;設定する&lt;/a&gt;。&lt;/p&gt;

&lt;h1 id=&#34;goslingsの静的リソース&#34;&gt;Goslingsの静的リソース&lt;/h1&gt;

&lt;p&gt;Goslingsの静的リソースは&lt;code&gt;favicon.ico&lt;/code&gt;以外は&lt;code&gt;/static/&lt;/code&gt;に全部直接置くことにした。
&lt;code&gt;favicon.ico&lt;/code&gt;はクラスパスのルートに。
プロジェクトのソースツリーで言うと、&lt;code&gt;src/main/resources/static/&lt;/code&gt;に&lt;code&gt;index.html&lt;/code&gt;やら&lt;code&gt;goslings.css&lt;/code&gt;やらのクライアントファイルを置いて、あとは&lt;code&gt;src/main/resources/favicon.ico&lt;/code&gt;があるという形。
こうしておけば、GradleのJavaプラグインの&lt;code&gt;processResources&lt;/code&gt;タスクによってjar内の適切な場所に取り込まれる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;index.html&lt;/code&gt;には&lt;code&gt;http://&amp;lt;Goslingsサーバ&amp;gt;/&lt;/code&gt;でアクセスできるし、&lt;code&gt;goslings.css&lt;/code&gt;も&lt;code&gt;index.html&lt;/code&gt;に&lt;code&gt;&amp;lt;link rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;goslings.css&amp;quot;&amp;gt;&lt;/code&gt;みたいに書けば取得できる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今日はここまで。
次回からはクライアントサイドの話。&lt;/p&gt;

&lt;p&gt;と思ったけど、たいして書くことないのでこれで終わりにする。
&lt;a href=&#34;http://qiita.com/kaitoy/items/91585ba1a3081ffd2111&#34;&gt;Qiita&lt;/a&gt;のほうにちょっと書いたし。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goslings開発メモ - その4: Spring Boot続続続編 (ロギング)</title>
          <link>https://www.kaitoy.xyz/2017/01/17/goslings-development-memo4-spring-boot-logging/</link>
          <pubDate>Tue, 17 Jan 2017 00:15:25 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/01/17/goslings-development-memo4-spring-boot-logging/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/13/goslings-development-memo3-spring-boot-exception/&#34;&gt;Goslings開発メモ - その3: Spring Boot続続編 (例外処理)&lt;/a&gt;」の続き。&lt;/p&gt;

&lt;p&gt;Spring Boot続続続編で、ロギングについて。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;spring-bootアプリにおけるロギング&#34;&gt;Spring Bootアプリにおけるロギング&lt;/h1&gt;

&lt;p&gt;Spring Bootアプリにおけるロギングについては公式の&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/boot-features-logging.html&#34;&gt;マニュアル&lt;/a&gt;と&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/howto-logging.html&#34;&gt;How-toガイド&lt;/a&gt;を読むべし。
この記事にはこれらの内容をまとめておく。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Spring Bootは内部でのロギングにApacheの&lt;a href=&#34;https://commons.apache.org/proper/commons-logging/&#34;&gt;Commons Logging&lt;/a&gt;を使っている。&lt;/p&gt;

&lt;p&gt;Commons Loggingはファサードライブラリだ。
つまり、Commons LoggingはロギングAPIだけをアプリケーションに提供し、実際のログ出力処理をするロギング実装ライブラリへの橋渡しとして機能する。
ロギング実装ライブラリには色々な選択肢があるが、Spring Bootは&lt;a href=&#34;https://docs.oracle.com/javase/jp/8/docs/api/java/util/logging/package-summary.html&#34;&gt;JUL&lt;/a&gt;、 &lt;a href=&#34;http://logging.apache.org/log4j/2.x/&#34;&gt;Log4j 2&lt;/a&gt;、&lt;a href=&#34;http://logback.qos.ch/&#34;&gt;Logback&lt;/a&gt;用のデフォルト設定を備えているので、これらのいずれかを使うのが楽であろう。&lt;/p&gt;

&lt;p&gt;全てのスターターは&lt;code&gt;spring-boot-starter-logging&lt;/code&gt;というロギングスターターに依存していて、これがLogbackを使うので、普通はそのままLogbackを使うことになる。
&lt;code&gt;spring-boot-starter-logging&lt;/code&gt;は、JUL、Commons Logging、Log4j、&lt;a href=&#34;https://www.slf4j.org/&#34;&gt;SLF4J&lt;/a&gt;によるログ出力をLogbackにルーティングするため、アプリ側や他の依存ライブラリがこれらを使っていてもLogbackに一本化できる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;spring-boot-starter-logging&lt;/code&gt;の代わりに&lt;code&gt;spring-boot-starter-log4j2&lt;/code&gt;に依存し、Log4j 2を使う&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/howto-logging.html#howto-configure-log4j-for-logging&#34;&gt;方法もある&lt;/a&gt;が、Goslingsには普通に&lt;code&gt;spring-boot-starter-logging&lt;/code&gt;を使った。&lt;/p&gt;

&lt;p&gt;また、Goslings本体のログ出力には、プレースホルダを使いたかったのでSLF4Jを使った。&lt;/p&gt;

&lt;h1 id=&#34;spring-bootアプリにおけるロギング設定&#34;&gt;Spring Bootアプリにおけるロギング設定&lt;/h1&gt;

&lt;p&gt;Spring Bootが備えているデフォルトのロギング設定は、&lt;code&gt;ERROR&lt;/code&gt;、&lt;code&gt;WARN&lt;/code&gt;、&lt;code&gt;INFO&lt;/code&gt;レベルのログをいい感じにフォーマットしてコンソールに吐くというものになっている。&lt;/p&gt;

&lt;p&gt;以下この設定の変更方法などを書く。&lt;/p&gt;

&lt;h4 id=&#34;ファイルへのログ出力&#34;&gt;ファイルへのログ出力&lt;/h4&gt;

&lt;p&gt;ログをファイルにも吐くようにするには、&lt;code&gt;logging.file&lt;/code&gt;というプロパティでファイルパスを指定するか、&lt;code&gt;logging.path&lt;/code&gt;というプロパティでディレクトリパスを指定すればいい。
(後者の場合ログファイル名は&lt;code&gt;spring.log&lt;/code&gt;になる。)&lt;/p&gt;

&lt;p&gt;Spring Bootアプリでプロパティを指定する方法は色々あり(&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/htmlsingle/#boot-features-external-config&#34;&gt;ここ&lt;/a&gt;とか&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/howto-properties-and-configuration.html&#34;&gt;ここ&lt;/a&gt;参照)、大抵は&lt;code&gt;application.properties&lt;/code&gt;で指定するんだろうけど、手軽にコマンドラインで以下の様に指定することもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;java -jar build/libs/goslings-0.0.1.jar --logging.file=build/hoge.log
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ログファイルはデフォルトで10MBでローテーションする。&lt;/p&gt;

&lt;h4 id=&#34;ログレベル&#34;&gt;ログレベル&lt;/h4&gt;

&lt;p&gt;ログレベルには重大度の低い方から&lt;code&gt;TRACE&lt;/code&gt;、&lt;code&gt;DEBUG&lt;/code&gt;、&lt;code&gt;INFO&lt;/code&gt;、&lt;code&gt;WARN&lt;/code&gt;、&lt;code&gt;ERROR&lt;/code&gt;、&lt;code&gt;FATAL&lt;/code&gt;の6段階があり、指定したログレベル以上のログが出力される。(&lt;code&gt;OFF&lt;/code&gt;というログ出力を止めるものもある。)
つまりSpring Bootのデフォルトのログレベルは&lt;code&gt;INFO&lt;/code&gt;だということだ。(Logbackには&lt;code&gt;FATAL&lt;/code&gt;がなく&lt;code&gt;ERROR&lt;/code&gt;として出力される。)&lt;/p&gt;

&lt;p&gt;ログレベルは&lt;code&gt;logging.level.&amp;lt;ロガー名&amp;gt;&lt;/code&gt;という形式のプロパティで指定できる。
例えばコマンドラインから指定するなら以下の感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;java -jar build/libs/goslings-0.0.1.jar --logging.level.org.springframework.web=DEBUG
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;全ロガーのログレベルは&lt;code&gt;logging.level.root&lt;/code&gt;で指定できる。&lt;/p&gt;

&lt;h4 id=&#34;ロギング実装ライブラリの設定&#34;&gt;ロギング実装ライブラリの設定&lt;/h4&gt;

&lt;p&gt;ロギング実装ライブラリの設定ファイルをカスタマイズして、より詳細な設定をすることもできる。&lt;/p&gt;

&lt;p&gt;Logbackの場合、クラスパスのルートに置かれた&lt;code&gt;logback-spring.xml&lt;/code&gt;か&lt;code&gt;logback.xml&lt;/code&gt;がロードされる。
設定ファイルの二重初期化を防いだり&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/boot-features-logging.html#boot-features-logback-extensions&#34;&gt;Spring Boot拡張設定&lt;/a&gt;を利用可能にするために、前者のファイル名が推奨されている。
(Groovyが使える環境なら&lt;code&gt;logback-spring.groovy&lt;/code&gt;でもいい。)&lt;/p&gt;

&lt;p&gt;いつものようにjavaコマンドでアプリを起動する場合は&lt;code&gt;-jar&lt;/code&gt;オプションを使うため、&lt;code&gt;-cp&lt;/code&gt;オプションでクラスパスを指定しても無視されてしまうので、基本は&lt;code&gt;logback-spring.xml&lt;/code&gt;はjarの中に入れることになる。
プロジェクトのリソースディレクトリのトップ(デフォルトでは&lt;code&gt;src/main/resources/&lt;/code&gt;)に&lt;code&gt;logback-spring.xml&lt;/code&gt;を置いておけば、GradleのJavaプラグインの&lt;code&gt;processResources&lt;/code&gt;タスクによってjar内の適切な場所に取り込まれる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;logging.config&lt;/code&gt;プロパティで設定ファイルのパスを指定することもできる。
例えばコマンドラインから指定するなら以下の感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;java -jar build/libs/goslings-0.0.1.jar --logging.config=logback-spring.xml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;logback-spring.xml&lt;/code&gt;の中身は、例えば以下の様に書くとコンソール出力をなくしてファイル出力だけにできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;configuration&amp;gt;
  &amp;lt;include resource=&amp;quot;org/springframework/boot/logging/logback/defaults.xml&amp;quot; /&amp;gt;
  &amp;lt;property name=&amp;quot;LOG_FILE&amp;quot; value=&amp;quot;${LOG_FILE:-${LOG_PATH:-${LOG_TEMP:-${java.io.tmpdir:-/tmp}}/}spring.log}&amp;quot;/&amp;gt;
  &amp;lt;include resource=&amp;quot;org/springframework/boot/logging/logback/file-appender.xml&amp;quot; /&amp;gt;
  &amp;lt;root level=&amp;quot;INFO&amp;quot;&amp;gt;
    &amp;lt;appender-ref ref=&amp;quot;FILE&amp;quot; /&amp;gt;
  &amp;lt;/root&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここで注目すべきは2点。&lt;/p&gt;

&lt;p&gt;まずは&lt;code&gt;include&lt;/code&gt;している&lt;code&gt;defaults.xml&lt;/code&gt;と&lt;code&gt;file-appender.xml&lt;/code&gt;だ。
これらはSpring Bootのコアライブラリである&lt;code&gt;spring-boot.jar&lt;/code&gt;に含まれるファイル。
&lt;code&gt;spring-boot.jar&lt;/code&gt;には他にも&lt;code&gt;base.xml&lt;/code&gt;と&lt;code&gt;console-appender.xml&lt;/code&gt;が含まれている。
これらは、前節までに書いたSpring Bootのロギング挙動を実現している設定ファイルなので、これらを&lt;code&gt;include&lt;/code&gt;して利用すれば自分のカスタム設定ファイルが簡単に書ける。&lt;/p&gt;

&lt;p&gt;もう一点は&lt;code&gt;LOG_FILE&lt;/code&gt;といったプロパティ。
これらはSpring Bootが設定してくれるプロパティで、詳細は&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/boot-features-logging.html#boot-features-custom-log-configuration&#34;&gt;ここ&lt;/a&gt;に。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今日はここまで。
&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/24/goslings-development-memo5-spring-boot-static-resources/&#34;&gt;次回&lt;/a&gt;もまたSpring Bootで、静的リソース処理について。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goslings開発メモ - その3: Spring Boot続続編 (例外処理)</title>
          <link>https://www.kaitoy.xyz/2017/01/13/goslings-development-memo3-spring-boot-exception/</link>
          <pubDate>Fri, 13 Jan 2017 14:01:01 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/01/13/goslings-development-memo3-spring-boot-exception/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/10/goslings-development-memo2-spring-boot-di/&#34;&gt;Goslings開発メモ - その2: Spring Boot続編 (DI)&lt;/a&gt;」の続き。&lt;/p&gt;

&lt;p&gt;Spring Boot続続編で、例外処理について。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;spring-mvcアプリにおける例外処理&#34;&gt;Spring MVCアプリにおける例外処理&lt;/h1&gt;

&lt;p&gt;Goslingsは&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/&#34;&gt;前々回&lt;/a&gt;書いたように&lt;code&gt;spring-boot-starter-web&lt;/code&gt;というスターターを使っていて、つまりSpring MVCアプリだ。&lt;/p&gt;

&lt;p&gt;Spring MVCアプリにおける例外処理についてはちょっと古いが&lt;a href=&#34;https://spring.io/blog/2013/11/01/exception-handling-in-spring-mvc&#34;&gt;この記事&lt;/a&gt;に詳しい。&lt;/p&gt;

&lt;p&gt;まず、Goslingsの構成で例外処理を何も書かなかった場合、コントローラのリクエストハンドラから例外が投げられると、ログにスタックトレースが出力され、クライアントにはHTTPステータスコード&lt;code&gt;500 (Internal Server Error)&lt;/code&gt;とともに以下の様なデフォルトのエラーページが返る。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-development-memo3-spring-boot-exception/err_page.png&#34; alt=&#34;err_page.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;なんだかこれでも十分な気がするが、実際にはちゃんと明示的に例外処理をしたほうがいいだろう。
エラー時に返すHTTPステータスコードをカスタマイズしたり、遷移するページを変えたりしたくなるだろうから。&lt;/p&gt;

&lt;p&gt;記事によれば、リクエストハンドラ内で例外をキャッチして処理するのはイケてなくて、関心事の分離のために別の場所に処理を書くのが良いらしい。&lt;/p&gt;

&lt;p&gt;Spring MVCアプリにおける例外処理には以下の3つの段階がある。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;投げる例外をカスタマイズする&lt;/li&gt;
&lt;li&gt;例外クラス毎の例外ハンドラをコントローラに実装する&lt;/li&gt;
&lt;li&gt;コントローラ間で共用する例外ハンドラクラスを作る&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;以下それぞれについて書く。&lt;/p&gt;

&lt;h4 id=&#34;1-投げる例外をカスタマイズする&#34;&gt;1. 投げる例外をカスタマイズする&lt;/h4&gt;

&lt;p&gt;リクエストハンドラから投げる例外に&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/ResponseStatus.html&#34;&gt;&lt;code&gt;@ResponseStatus&lt;/code&gt;&lt;/a&gt;をつけることで、クライアントに返すHTTPステータスコード(とリーズンフレーズ)をカスタマイズできる。&lt;/p&gt;

&lt;p&gt;例えば以下のような例外を投げると、HTTPステータスコード&lt;code&gt;500 (Internal Server Error)&lt;/code&gt;の代わりに&lt;code&gt;400 (Bad Request)&lt;/code&gt;がクライアントに返る。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@ResponseStatus(HttpStatus.BAD_REQUEST)
public final class BadRequestException extends RuntimeException {
  // 省略
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;2-例外クラス毎の例外ハンドラをコントローラに実装する&#34;&gt;2. 例外クラス毎の例外ハンドラをコントローラに実装する&lt;/h4&gt;

&lt;p&gt;コントローラのメソッドに&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/ExceptionHandler.html&#34;&gt;&lt;code&gt;@ExceptionHandler&lt;/code&gt;&lt;/a&gt;をつけてやると、そのメソッドは例外ハンドラになり、そのコントローラのリクエストハンドラから特定の例外が投げられたときの処理を書くことができる。
さらに例外ハンドラに&lt;code&gt;@ResponseStatus&lt;/code&gt;をつければ、HTTPステータスコードをカスタマイズできる。
例外ハンドラの戻り値はリクエストハンドラのと同様に処理されるので、遷移するページ等も自由にカスタマイズできる。&lt;/p&gt;

&lt;p&gt;Goslingsでは、上記&lt;code&gt;BadRequestException&lt;/code&gt;からは&lt;code&gt;@ResponseStatus&lt;/code&gt;を削除したうえで、&lt;code&gt;RestApiV1Controller&lt;/code&gt;に以下の様に例外ハンドラを書いた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public final class RestApiV1Controller {

  // 例外ハンドラ
  @ResponseStatus(HttpStatus.BAD_REQUEST)
  @ExceptionHandler(BadRequestException.class)
  ErrorInfo handleBadRequestException(HttpServletRequest req, Exception ex) {
    return new ErrorInfo(req.getRequestURL().toString(), ex);
  }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(RestApiV1Controller.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/controller/RestApiV1Controller.java&#34;&gt;こちら&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;こう書くと、&lt;code&gt;RestApiV1Controller&lt;/code&gt;の任意のリクエストハンドラから&lt;code&gt;BadRequestException&lt;/code&gt;が投げられると、&lt;code&gt;handleBadRequestException&lt;/code&gt;が呼び出され、HTTPステータスコード&lt;code&gt;400 (Bad Request)&lt;/code&gt;とともにクライアントにHTTPレスポンスが返る。
&lt;code&gt;RestApiV1Controller&lt;/code&gt;はREST APIコントローラなので、このHTTPレスポンスのボディは、&lt;code&gt;handleBadRequestException&lt;/code&gt;の戻り値である&lt;code&gt;ErrorInfo&lt;/code&gt;オブジェクトをJSONに変換したものになる。&lt;/p&gt;

&lt;p&gt;例外ハンドラの仮引数は、上のコードに書いたもののほか、サーブレット関係のクラスなど(e.g. &lt;code&gt;HttpServletResponse&lt;/code&gt;や&lt;code&gt;HttpSession&lt;/code&gt;。詳しくは&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/ExceptionHandler.html&#34;&gt;Javadoc&lt;/a&gt;参照)を適当に書いておくとSpring MVCがよしなに渡してくれる。&lt;/p&gt;

&lt;p&gt;冒頭に貼った記事には例外ハンドラは&lt;code&gt;Model&lt;/code&gt;を受け取れないとあるが、これは古い情報で、今は受け取れるっぽい。&lt;/p&gt;

&lt;h4 id=&#34;3-コントローラ間で共用する例外ハンドラクラスを作る&#34;&gt;3. コントローラ間で共用する例外ハンドラクラスを作る&lt;/h4&gt;

&lt;p&gt;コントローラから例外処理を完全に分離したい場合や、複数のコントローラで例外ハンドラを共有したい場合は、コントローラアドバイスクラスを書けばいい。&lt;/p&gt;

&lt;p&gt;コントローラアドバイスクラスは&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/ControllerAdvice.html&#34;&gt;&lt;code&gt;@ControllerAdvice&lt;/code&gt;&lt;/a&gt;を付けて定義したクラスで、このクラスに例外ハンドラを書いておくと複数のコントローラで有効になる。&lt;/p&gt;

&lt;p&gt;コントローラアドバイスクラスには例外ハンドラ以外も書ける。
コントローラアドバイスクラスが適用されるのはデフォルトでは全てのコントローラクラスだが、&lt;code&gt;@ControllerAdvice&lt;/code&gt;の値により適用範囲を絞ることもできる。
詳しくは&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/ControllerAdvice.html&#34;&gt;Javadoc&lt;/a&gt;参照。&lt;/p&gt;

&lt;p&gt;Goslingsではコントローラアドバイスクラスは作らなかった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今日はここまで。
&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/17/goslings-development-memo4-spring-boot-logging/&#34;&gt;次回&lt;/a&gt;もまたSpring Bootで、ロギングについて。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goslings開発メモ - その2: Spring Boot続編 (DI)</title>
          <link>https://www.kaitoy.xyz/2017/01/10/goslings-development-memo2-spring-boot-di/</link>
          <pubDate>Tue, 10 Jan 2017 00:21:27 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/01/10/goslings-development-memo2-spring-boot-di/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/&#34;&gt;Goslings開発メモ - その1: Spring Boot編&lt;/a&gt;」の続き。&lt;/p&gt;

&lt;p&gt;Spring Boot続編で、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E4%BE%9D%E5%AD%98%E6%80%A7%E3%81%AE%E6%B3%A8%E5%85%A5&#34;&gt;DI&lt;/a&gt;について。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;diとは&#34;&gt;DIとは&lt;/h1&gt;

&lt;p&gt;DIはDependency Injectionの略。依存性注入と訳される。&lt;/p&gt;

&lt;p&gt;これは、Javaの文脈で具体的目に言うと、あるクラスが依存する具象クラスのインスタンス化と取得をフレームワークに任せることで、具象クラス間の直接的な依存を排除し、よってコンポーネント間を疎結合にする手法。
これにより、アプリの拡張性を高めたり、テストがしやすくなったりする。(&lt;a href=&#34;http://qiita.com/mizunowanko/items/53eed059fc044c5aa5dc&#34;&gt;参考記事&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://projects.spring.io/spring-framework/&#34;&gt;Spring Framework&lt;/a&gt;はもともとこのDI機能を提供するフレームワーク(i.e. DIコンテナ)として普及した。&lt;/p&gt;

&lt;h1 id=&#34;goslingsでdi&#34;&gt;GoslingsでDI&lt;/h1&gt;

&lt;p&gt;Goslingsサーバの内部機能はざっくり、クライアントからのREST API呼び出しを処理するユーザインタフェース層と、Gitリポジトリにアクセスするデータベース層に分かれる。&lt;/p&gt;

&lt;p&gt;Gitリポジトリにアクセスする部分は今回は&lt;a href=&#34;https://eclipse.org/jgit/&#34;&gt;JGit&lt;/a&gt;で実装するが、将来的に別のライブラリで実装しなおす可能性が微レ存なのと、Goslingsの開発自体がWebアプリ開発の練習でもあるので、ちゃんとしたアーキテクチャでと思い、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Data_Access_Object&#34;&gt;DAO&lt;/a&gt;パターンを使ってやった。&lt;/p&gt;

&lt;p&gt;つまり例えば、GitのコミットオブジェクトはJGitのAPIでは&lt;a href=&#34;http://download.eclipse.org/jgit/site/3.7.1.201504261725-r/apidocs/org/eclipse/jgit/revwalk/RevCommit.html&#34;&gt;&lt;code&gt;RevCommitクラス&lt;/code&gt;&lt;/a&gt;で表されるが、ユーザインタフェース層からはリソースクラスである&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/resource/Commit.java&#34;&gt;Commitクラス&lt;/a&gt;(&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/#5-%E3%83%AA%E3%82%BD%E3%83%BC%E3%82%B9%E3%82%AF%E3%83%A9%E3%82%B9%E4%BD%9C%E6%88%90&#34;&gt;前回&lt;/a&gt;参照)を扱う以下の様なDAOインターフェースを呼ぶようにし、JGit依存の実装とは切り離す。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public interface ObjectDao {

  public Commit[] getCommits(String token) throws DaoException;

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(ObjectDao.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/dao/ObjectDao.java&#34;&gt;これ&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ObjectDao&lt;/code&gt;を実装する&lt;code&gt;ObjectDaoImpl&lt;/code&gt;クラスでは、以下の様にJGitを使ってごりごりと実装を書く。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public final class ObjectDaoImpl implements ObjectDao {

  // フィールド定義は省略

  @Override
  public Commit[] getCommits(String token) {
    try {
      return StreamSupport.stream(resolver.getGit(token).log().all().call().spliterator(), false)
               .map(this::convertToCommit)
               .toArray(Commit[]::new);
    } catch (NoHeadException e) {
      // エラー処理
    }
  }

  private Commit convertToCommit(RevCommit commit) {
    // RevCommitをCommitに変換する処理
  }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ユーザインターフェース層は&lt;code&gt;RestApiV1Controller&lt;/code&gt;クラス(&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/#6-%E3%82%B3%E3%83%B3%E3%83%88%E3%83%AD%E3%83%BC%E3%83%A9-rest-api%E3%82%B3%E3%83%B3%E3%83%88%E3%83%AD%E3%83%BC%E3%83%A9-%E4%BD%9C%E6%88%90&#34;&gt;前回&lt;/a&gt;参照)の&lt;code&gt;getCommits&lt;/code&gt;メソッドで、以下の様にObjectDaoを使いたい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public final class RestApiV1Controller {

  private ObjectDao objectDao;

  @RequestMapping(path=&amp;quot;{token}/objects/commits&amp;quot;)
  public Commit[] getCommits(@PathVariable String token) {
    return objectDao.getCommits(token);
  }

  // 以下他のメソッド

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ここで問題になるのが、&lt;code&gt;RestApiV1Controller&lt;/code&gt;の&lt;code&gt;objectDao&lt;/code&gt;フィールドへのインスタンスの代入だが、&lt;code&gt;RestApiV1Controller&lt;/code&gt;内(e.g. &lt;code&gt;RestApiV1Controller&lt;/code&gt;のコンストラクタ)で&lt;code&gt;ObjectDaoImpl&lt;/code&gt;をインスタンス化して代入するのでは、&lt;code&gt;ObjectDaoImpl&lt;/code&gt;というデータベース層の具象クラスへの直接的な依存(i.e. &lt;code&gt;import ObjectDaoImpl&lt;/code&gt;)が発生してしまってまずい。
ユーザインターフェース層とデータベース層が密に結合してしまう。&lt;/p&gt;

&lt;p&gt;ここがDIの使いどころだ。
&lt;code&gt;RestApiV1Controller&lt;/code&gt;への&lt;code&gt;ObjectDaoImpl&lt;/code&gt;インスタンスの注入をフレームワークに任せればいい。&lt;/p&gt;

&lt;h1 id=&#34;spring-bootでのdi&#34;&gt;Spring BootでのDI&lt;/h1&gt;

&lt;p&gt;Spring Bootアプリでは&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/spring-framework-reference/html/beans.html&#34;&gt;Spring FrameworkのDI機能&lt;/a&gt;を何でも使えるが、普通、もっとも簡単な方法である&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/context/annotation/ComponentScan.html&#34;&gt;&lt;code&gt;@ComponentScan&lt;/code&gt;&lt;/a&gt;と&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/spring-framework-reference/html/beans.html#beans-autowired-annotation&#34;&gt;&lt;code&gt;@Autowired&lt;/code&gt;&lt;/a&gt;を使う方法を採る。&lt;/p&gt;

&lt;p&gt;まずは&lt;code&gt;@ComponentScan&lt;/code&gt;だが、これは、&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/#7-%E3%83%A1%E3%82%A4%E3%83%B3%E3%82%AF%E3%83%A9%E3%82%B9%E4%BD%9C%E6%88%90&#34;&gt;前回&lt;/a&gt;書いたように既に使っていて、プロジェクト内の全てのSpring Beanが検索されDIコンテナに登録されるようになっている。
なので、注入したい&lt;code&gt;ObjectDaoImpl&lt;/code&gt;がSpring Beanと判定されるようにすればよい。&lt;/p&gt;

&lt;p&gt;そのためには、&lt;code&gt;ObjectDaoImpl&lt;/code&gt;に以下のアノテーションのいずれかを付ける必要がある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Service.html&#34;&gt;&lt;code&gt;@Service&lt;/code&gt;&lt;/a&gt;: 業務手続を表すAPIを提供する(しばしば状態を持たない)コンポーネント。またはそれっぽいもの。MVCアーキテクチャのM(モデル)や、3層アーキテクチャのビジネスロジック層のコンポーネント。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Repository.html&#34;&gt;&lt;code&gt;@Repository&lt;/code&gt;&lt;/a&gt;: データの保持、取得、検索といった振る舞いを持つ、オブジェクトコレクションを表すコンポーネント。またはそれっぽいもの。MVCアーキテクチャのM(モデル)の内、特にデータベースを扱うコンポーネントや、3層アーキテクチャのデータベース層のコンポーネント。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Controller.html&#34;&gt;&lt;code&gt;@Controller&lt;/code&gt;&lt;/a&gt;: MVCアーキテクチャのC(コントローラ)のコンポーネント。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Component.html&#34;&gt;&lt;code&gt;@Component&lt;/code&gt;&lt;/a&gt;: 一般的なコンポーネント。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(&lt;a href=&#34;http://qiita.com/KevinFQ/items/abc7369cb07eb4b9ae29&#34;&gt;参考記事&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ObjectDaoImpl&lt;/code&gt;はDAOコンポーネントで、これはもちろん&lt;code&gt;@Repository&lt;/code&gt;にあたるのでこれを付ける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Repository
public final class ObjectDaoImpl implements ObjectDao {
  // 省略
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで&lt;code&gt;ObjectDaoImpl&lt;/code&gt;がSpring Beanとして登録されるので、あとは&lt;code&gt;RestApiV1Controller&lt;/code&gt;に&lt;code&gt;@Autowired&lt;/code&gt;で注入してやればいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public final class RestApiV1Controller {

  @Autowired
  private ObjectDao objectDao;

  // 以下省略。

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;@Autowired&lt;/code&gt;を付けたことにより、&lt;code&gt;RestApiV1Controller&lt;/code&gt;のインスタンス化直後に、&lt;code&gt;objectDao&lt;/code&gt;フィールドに適切なSpring Beanが注入されるようになった。&lt;/p&gt;

&lt;p&gt;注入されるSpring Beanはフィールドの型から判断される。
&lt;code&gt;objectDao&lt;/code&gt;フィールドの型は&lt;code&gt;ObjectDao&lt;/code&gt;で、この実装はプロジェクト内に&lt;code&gt;ObjectDaoImpl&lt;/code&gt;しかないので、狙い通り&lt;code&gt;ObjectDaoImpl&lt;/code&gt;が注入される。
今はこれでもいいが、将来&lt;code&gt;ObjectDao&lt;/code&gt;の実装が増えた場合、どの実装を注入すべきかSpring Frameworkには分からなくなるので、今のうちに&lt;a href=&#34;http://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/beans/factory/annotation/Qualifier.html&#34;&gt;&lt;code&gt;@Qualifier&lt;/code&gt;&lt;/a&gt;を使って明示しておくことにする。(&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/spring-framework-reference/html/beans.html#beans-autowired-annotation-qualifiers&#34;&gt;参考&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;まずSpring Beanの方に&lt;code&gt;jgit&lt;/code&gt;という値を持つ&lt;code&gt;@Qualifier&lt;/code&gt;をつける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Repository
@Qualifier(&amp;quot;jgit&amp;quot;)
public final class ObjectDaoImpl implements ObjectDao {
  // 省略
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(ObjectDaoImpl.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/dao/jgit/ObjectDaoImpl.java&#34;&gt;これ&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Spring Beanを使う側にも同じ&lt;code&gt;@Qualifier&lt;/code&gt;をつける。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public final class RestApiV1Controller {

  @Autowired
  @Qualifier(&amp;quot;jgit&amp;quot;)
  private ObjectDao objectDao;

  // 以下省略。

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(RestApiV1Controller.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/controller/RestApiV1Controller.java&#34;&gt;こちら&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで&lt;code&gt;RestApiV1Controller&lt;/code&gt;の&lt;code&gt;objectDao&lt;/code&gt;フィールドにどの&lt;code&gt;ObjectDao&lt;/code&gt;実装が注入されるかがより明確になった。
将来&lt;code&gt;ObjectDao&lt;/code&gt;の別の実装を作るときには、その実装クラスには別の値の&lt;code&gt;@Qualifier&lt;/code&gt;を付けてやれば、&lt;code&gt;RestApiV1Controller&lt;/code&gt;の方の&lt;code&gt;@Qualifier&lt;/code&gt;の値によって注入する実装を切り替えられる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今日はここまで。
&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/13/goslings-development-memo3-spring-boot-exception/&#34;&gt;次回&lt;/a&gt;もまたSpring Bootで、例外処理について。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goslings開発メモ - その1: Spring Boot編</title>
          <link>https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/</link>
          <pubDate>Tue, 03 Jan 2017 23:36:01 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/01/03/goslings-development-memo1-spring-boot/</guid>
          <description>

&lt;p&gt;「&lt;a href=&#34;https://www.kaitoy.xyz/2016/12/11/goslings-development-memo0-intro-design/&#34;&gt;Goslings開発メモ - その0: 紹介と概要と設計編&lt;/a&gt;」の続き。&lt;/p&gt;

&lt;p&gt;Spring Boot編。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;spring-bootとは&#34;&gt;Spring Bootとは&lt;/h1&gt;

&lt;p&gt;Spring Bootは&lt;a href=&#34;http://projects.spring.io/spring-framework/&#34;&gt;Spring Framework&lt;/a&gt;というJavaのWebアプリケーションフレームワークを簡単に利用するためのツールやライブラリ群。&lt;/p&gt;

&lt;p&gt;これを使うと、Webアプリケーションコンテナ(e.g. &lt;a href=&#34;http://tomcat.apache.org/&#34;&gt;Tomcat&lt;/a&gt;)なしで起動できるSpringアプリケーションを、自動コード生成も設定ファイル作成もせずに作ることができる。
必要な設定は自動で構成され、設定のカスタマイズもアノテーションでできる。&lt;/p&gt;

&lt;p&gt;GAになったのが&lt;a href=&#34;https://www.infoq.com/news/2014/04/spring-boot-goes-ga&#34;&gt;2014年4月&lt;/a&gt;なのでかなり新しいものだが、JavaのWebアプリケーションを作るためのものとしては今世界的に最も流行っているもの。&lt;/p&gt;

&lt;p&gt;私が昔とあるWebアプリを作った時は&lt;a href=&#34;http://projects.spring.io/spring-roo/&#34;&gt;Spring Roo&lt;/a&gt;という&lt;a href=&#34;https://ja.wikipedia.org/wiki/RAD_(%E8%A8%88%E7%AE%97%E6%A9%9F%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%E7%92%B0%E5%A2%83&#34;&gt;RADツール&lt;/a&gt;が熱かったが、これはコード自動生成をして開発を助けてくれるもので、なんだか結局あまり流行らなかったようだ。&lt;/p&gt;

&lt;p&gt;Goslingsには最新バージョンの1.4.3.RELEASEを使った。&lt;/p&gt;

&lt;h1 id=&#34;spring-bootことはじめ&#34;&gt;Spring Bootことはじめ&lt;/h1&gt;

&lt;p&gt;包括的網羅的なドキュメントは「&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/htmlsingle/&#34;&gt;Spring Boot Reference Guide&lt;/a&gt;」だが、今回あまり深く学ぶ時間が取れなかったのでこれはちら見した程度。
それよりも、ユースケースごとのチュートリアルが60個以上も載っている「&lt;a href=&#34;https://spring.io/guides/&#34;&gt;Getting Started Guides&lt;/a&gt;」を参考にした。&lt;/p&gt;

&lt;p&gt;Goslingsサーバは基本REST APIサーバなので、上記チュートリアルの内「&lt;a href=&#34;https://spring.io/guides/gs/rest-service/&#34;&gt;Building a RESTful Web Service&lt;/a&gt;」を見ながら以下を実施した。&lt;/p&gt;

&lt;h4 id=&#34;1-プロジェクト作成&#34;&gt;1. プロジェクト作成&lt;/h4&gt;

&lt;p&gt;チュートリアルにはGradleプロジェクトのディレクトリ構成を手動で作るところから書いてあるけど、そこは&lt;a href=&#34;http://qiita.com/grachro/items/d1ebad3857a794895426&#34;&gt;IDEなどで楽できる&lt;/a&gt;。
私はEclipseを使っていて、いつのまにかGradleプラグインである&lt;a href=&#34;https://projects.eclipse.org/projects/tools.buildship&#34;&gt;Eclipse Buildship: Eclipse Plug-ins for Gradle&lt;/a&gt;と&lt;a href=&#34;https://marketplace.eclipse.org/content/gradle-ide-pack&#34;&gt;Gradle IDE Pack&lt;/a&gt;がインストールされていたので、これらを使った。&lt;/p&gt;

&lt;p&gt;どちらのプラグインでもプロジェクトは作成できるが、&lt;a href=&#34;http://qiita.com/grachro/items/16bba860f9d9fe5ee4c5&#34;&gt;Qiitaのこの記事&lt;/a&gt;にあるとおり、Gradle IDE Pack(に含まれる&lt;a href=&#34;https://github.com/spring-projects/eclipse-integration-gradle/&#34;&gt;Gradle (STS) Integration for Eclipse by Pivotal&lt;/a&gt;)で作った場合、Gradle Wrapperが生成されないなどの問題があるので、Buildshipの方で作成。
ただ、Gradle IDE Packの方がパッケージ・エクスプローラでの見え方がちょっとよかったので、こちらでプロジェクトをインポートしなおした。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-development-memo1-spring-boot/gradle_import.png&#34; alt=&#34;gradle_import.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;(上がBuildshipのやつで、下がGradle IDE Packのやつ)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;出来たプロジェクトは以下の感じ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-development-memo1-spring-boot/project_structure.png&#34; alt=&#34;project_structure.png&#34; /&gt;
&lt;/p&gt;

&lt;h4 id=&#34;2-spring-boot-gradle-plugin適用&#34;&gt;2. Spring Boot Gradle plugin適用&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/build-tool-plugins-gradle-plugin.html&#34;&gt;Spring Boot Gradle plugin&lt;/a&gt;というものがあって、これをプロジェクトに適用すると以下の恩恵を受けられる。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;依存ライブラリ管理機能&lt;/p&gt;

&lt;p&gt;Spring関係のライブラリについて適切なバージョンを設定してくれるので、Gradleビルド設定(i.e. &lt;code&gt;build.gradle&lt;/code&gt;)の&lt;code&gt;dependencies&lt;/code&gt;に自分でバージョンを書かなくていい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;実行可能jar(war)のパッケージング機能&lt;/p&gt;

&lt;p&gt;ビルドされたjar(やwar)を、単独で実行可能になるようにマニフェストやライブラリを詰めて再パッケージングする&lt;code&gt;bootRepackage&lt;/code&gt;というGradleタスクが追加される。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プロジェクトから直接アプリを起動する機能&lt;/p&gt;

&lt;p&gt;jarなどのアーティファクトをビルドせずに、プロジェクトから直接アプリを起動できる&lt;code&gt;bootRun&lt;/code&gt;というGradleタスクが追加される。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;build.gradle&lt;/code&gt;に以下の様に書くとSpring Boot Gradle pluginを適用できる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Gradle 2.1より古いバージョン&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;buildscript {
  repositories {
    mavenCentral()
  }
  dependencies {
    classpath(&#39;org.springframework.boot:spring-boot-gradle-plugin:1.4.3.RELEASE&#39;)
  }
}


apply plugin: &#39;org.springframework.boot&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(&lt;code&gt;apply plugin: &#39;org.springframework.boot&#39;&lt;/code&gt;の部分は、Spring Boot Gradle plugin 1.4.1.RELEASE以前は&lt;code&gt;apply plugin: &#39;spring-boot&#39;&lt;/code&gt;だった。)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Gradle 2.1以降&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;plugins {
  id &#39;org.springframework.boot&#39; version &#39;1.4.3.RELEASE&#39;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;3-依存ライブラリ追加&#34;&gt;3. 依存ライブラリ追加&lt;/h4&gt;

&lt;p&gt;Spring Bootは依存ライブラリの管理も簡易化してくれる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;spring-boot-starter-&lt;/code&gt;で始まる&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/htmlsingle/#using-boot-starter&#34;&gt;スターター&lt;/a&gt;と呼ばれるライブラリがいくつか提供されていて、作りたいアプリの種類や機能に応じたものをプロジェクトの依存ライブラリとして追加すると、推移的に諸々の必要なライブラリが追加されるようになっている。
例えば、&lt;a href=&#34;http://www.thymeleaf.org/&#34;&gt;Thymeleaf&lt;/a&gt;をテンプレートエンジンに使ったWebアプリを作るなら&lt;code&gt;spring-boot-starter-thymeleaf&lt;/code&gt;、&lt;a href=&#34;http://projects.spring.io/spring-data-jpa/&#34;&gt;JPA&lt;/a&gt; (&lt;a href=&#34;http://hibernate.org/orm/&#34;&gt;Hibernate&lt;/a&gt;)でデータベースアクセスしたい場合は&lt;code&gt;spring-boot-starter-data-jpa&lt;/code&gt;を使う。&lt;/p&gt;

&lt;p&gt;Webアプリを作るのに最も一般的なのは&lt;code&gt;spring-boot-starter-web&lt;/code&gt;で、Goslingsにもこれを使った。
これを使うと&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/spring-framework-reference/html/mvc.html&#34;&gt;Spring MVC&lt;/a&gt;でアプリを作ることになる。&lt;/p&gt;

&lt;p&gt;また、&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/htmlsingle/#production-ready&#34;&gt;Spring Boot Actuator&lt;/a&gt;という、アプリをプロダクション環境で運用するための機能を有効にするため、&lt;code&gt;spring-boot-starter-actuator&lt;/code&gt;も使った。
これを有効にすると、Web APIでアプリの状態取得などができるようになる。
例えば、&lt;code&gt;http://&amp;lt;サーバ&amp;gt;/health&lt;/code&gt;にアクセスするとアプリの基本的なヘルス情報がJSONで取得できる。&lt;/p&gt;

&lt;p&gt;これら二つのスターターを追加するには、&lt;code&gt;build.gradle&lt;/code&gt;の&lt;code&gt;dependencies&lt;/code&gt;に以下の様に書くだけでいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;dependencies {
  compile &#39;org.springframework.boot:spring-boot-starter-web&#39;
  compile &#39;org.springframework.boot:spring-boot-starter-actuator&#39;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;前節に書いた通り、Spring Boot Gradle pluginのおかげでバージョンの指定は不要。&lt;/p&gt;

&lt;h4 id=&#34;4-ディベロッパツール追加&#34;&gt;4. ディベロッパツール追加&lt;/h4&gt;

&lt;p&gt;Spring Bootの&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/using-boot-devtools.html&#34;&gt;ディベロッパツール&lt;/a&gt;を利用すると、以下の恩恵を受けられる。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;キャッシュの無効化&lt;/p&gt;

&lt;p&gt;Spring Bootがサポートしているライブラリ(e.g. Thymeleafといったテンプレートエンジン)にはキャッシュ機能を持つものがある。
こうした機能はプロダクション環境では性能改善に有効だが、開発時にはじゃまになる。
ディベロッパツールを使うとデフォルトで様々なキャッシュを無効にしてくれる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;自動再起動&lt;/p&gt;

&lt;p&gt;クラスパスに含まれるファイルに変更があるとアプリが自動で再起動される。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ライブリロード&lt;/p&gt;

&lt;p&gt;ブラウザのアドオンを&lt;a href=&#34;http://livereload.com/extensions/&#34;&gt;インストール&lt;/a&gt;すると、アプリに変更があったらブラウザが自動でリロードしてくれるようになる。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ディベロッパツールを追加するには、&lt;code&gt;build.gradle&lt;/code&gt;の&lt;code&gt;dependencies&lt;/code&gt;に以下の様に書くだけでいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;dependencies {
  compile &#39;org.springframework.boot:spring-boot-devtools&#39;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ディベロッパツールは、アプリがプロダクション環境で起動されたと判定すると自動で無効になるので、アーティファクトに含まれても問題ない。
&lt;code&gt;java -jar&lt;/code&gt;で起動されるか、または通常のものではないクラスローダが起動に使われると、プロダクション環境だと判定される。
&lt;code&gt;build.gradle&lt;/code&gt;に以下の様に書けば、アーティファクトに含まれないようにもできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;bootRepackage {
  excludeDevtools = true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ディベロッパツールへの推移的依存を避けるための&lt;a href=&#34;https://github.com/spring-projects/gradle-plugins/tree/master/propdeps-plugin&#34;&gt;propdeps-plugin&lt;/a&gt;というプラグインもあるが、Goslingsは他のアプリが依存するようなものではないので使わなかった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;自動再起動については、Eclipseの自動ビルドはデフォルトで&lt;code&gt;goslings/bin&lt;/code&gt;にクラスファイルを吐くので、ビルドパスの構成で「デフォルト出力フォルダー」を&lt;code&gt;goslings/build/classes/main&lt;/code&gt;に変えないと動かなかった。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ここまででベースとなる&lt;code&gt;build.gradle&lt;/code&gt;ができて、以下の様になった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;buildscript {
  repositories {
    mavenCentral()
  }
  dependencies {
    classpath &amp;quot;org.springframework.boot:spring-boot-gradle-plugin:${springBootVer}&amp;quot;
  }
}

repositories {
  mavenCentral()
}

apply plugin: &#39;java&#39;
apply plugin: &#39;org.springframework.boot&#39;

archivesBaseName = &#39;goslings&#39;
version = &#39;0.0.1&#39;

[compileJava, compileTestJava]*.options*.encoding = &#39;UTF-8&#39;
sourceCompatibility = 1.8
targetCompatibility = 1.8

bootRepackage {
  excludeDevtools = true
}

dependencies {
  compile &#39;org.springframework.boot:spring-boot-starter-web&#39;
  compile &#39;org.springframework.boot:spring-boot-starter-actuator&#39;
  compile &#39;org.springframework.boot:spring-boot-devtools&#39;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;5-リソースクラス作成&#34;&gt;5. リソースクラス作成&lt;/h3&gt;

&lt;p&gt;ここからやっとコーディング。
まずはREST APIで取得するリソースを表現するクラスを作る。&lt;/p&gt;

&lt;p&gt;Goslingsの場合、Gitリポジトリのオブジェクトやリファレンスなどがリソースになる。
例えばコミットオブジェクトを表すクラスは以下の様に書いた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public final class Commit {

  private final String id;
  private final String[] parentIds;
  private final String treeId;

  // 以下、全フィールドをセットするコンストラクタとgetters。

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(Commit.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/resource/Commit.java&#34;&gt;これ&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;POJOとして書けばいいので、&lt;a href=&#34;https://projectlombok.org/&#34;&gt;Lombok&lt;/a&gt;の&lt;code&gt;@Data&lt;/code&gt;か&lt;code&gt;@Value&lt;/code&gt;を使うと楽だろうが、Goslingsには使わなかった。&lt;/p&gt;

&lt;h4 id=&#34;6-コントローラ-rest-apiコントローラ-作成&#34;&gt;6. コントローラ(REST APIコントローラ)作成&lt;/h4&gt;

&lt;p&gt;クライアントからのHTTPリクエストを処理するクラスはコントローラクラスと呼ばれる。
クライアントからのREST API呼び出しもHTTPリクエストなのでコントローラクラスで処理する。&lt;/p&gt;

&lt;p&gt;REST API呼び出しを処理するコントローラクラスは、&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/RestController.html&#34;&gt;&lt;code&gt;@RestController&lt;/code&gt;&lt;/a&gt;を付けて宣言して、&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/RequestMapping.html&#34;&gt;&lt;code&gt;@RequestMapping&lt;/code&gt;&lt;/a&gt;を付けたメソッド(リクエストハンドラ)にURL毎の処理を書いてやればいい。&lt;/p&gt;

&lt;p&gt;以下の様な感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@RestController
@RequestMapping(
  path=&amp;quot;/v1&amp;quot;,
  method=RequestMethod.GET
)
public final class RestApiV1Controller {

  // この辺でフィールド定義など

  @RequestMapping(path=&amp;quot;{token}/objects/commits&amp;quot;)
  public Commit[] getCommits(@PathVariable String token) {
    return objectDao.getCommits(token);
  }

  // 以下他のメソッド

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(RestApiV1Controller.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/controller/RestApiV1Controller.java&#34;&gt;こちら&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;上のコードでは、&lt;code&gt;http://&amp;lt;Goslingsサーバ&amp;gt;/v1/&amp;lt;トークン&amp;gt;/objects/commits&lt;/code&gt;というURLを&lt;code&gt;getCommits&lt;/code&gt;メソッドで処理するようにしている。
このAPIを呼び出すと、前節で作った&lt;code&gt;Commit&lt;/code&gt;クラスのインスタンスの配列がJSON形式で返ってくる。
(getCommitsの実装については次回書く。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;@RestController&lt;/code&gt;を付けると以下の二つのアノテーションを付けたのと同じことになる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Controller.html&#34;&gt;&lt;code&gt;@Controller&lt;/code&gt;&lt;/a&gt;: 一般的なコントローラクラスに付けるアノテーション。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/ResponseBody.html&#34;&gt;&lt;code&gt;@ResponseBody&lt;/code&gt;&lt;/a&gt;: メソッドの戻り値をHTTPレスポンスボディにバインドすることを指示する。これを付けると、戻り値は&lt;a href=&#34;http://wiki.fasterxml.com/JacksonHome&#34;&gt;Jackson JSON&lt;/a&gt;でJSONに変換されてクライアントに返される。これを付けないと、戻り値はスタティックリソースへのパスなどとして扱われ、View(e.g. Thymeleaf)が処理した結果がクライアントに返される。(&lt;a href=&#34;http://qiita.com/tag1216/items/3680b92cf96eb5a170f0&#34;&gt;参考記事&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;見ての通り、URLのパス中の値は&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/PathVariable.html&#34;&gt;&lt;code&gt;@PathVariable&lt;/code&gt;&lt;/a&gt;を使って取得できる。&lt;/p&gt;

&lt;p&gt;ここには書いてないけど、URLクエリパラメータは&lt;a href=&#34;https://docs.spring.io/spring/docs/4.3.4.RELEASE/javadoc-api/org/springframework/web/bind/annotation/RequestParam.html&#34;&gt;&lt;code&gt;@RequestParam&lt;/code&gt;&lt;/a&gt;を使って取得できるし、&lt;a href=&#34;http://mergedoc.osdn.jp/tomcat-servletapi-5-ja/javax/servlet/http/HttpServletRequest.html&#34;&gt;&lt;code&gt;HttpServletRequest&lt;/code&gt;&lt;/a&gt;もメソッドの引数として宣言しておけばSpringが渡してくれる。&lt;/p&gt;

&lt;h4 id=&#34;7-メインクラス作成&#34;&gt;7. メインクラス作成&lt;/h4&gt;

&lt;p&gt;最後に、アプリを起動するメインクラスを作る。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/api/org/springframework/boot/autoconfigure/SpringBootApplication.html&#34;&gt;&lt;code&gt;@SpringBootApplication&lt;/code&gt;&lt;/a&gt;を付けたクラスに&lt;code&gt;main&lt;/code&gt;メソッドを以下の様に定義すればいいだけ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@SpringBootApplication
public class Application {

  public static void main(String[] args) {
    SpringApplication.run(Application.class, args);
  }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(Application.javaの完全なソースは&lt;a href=&#34;https://github.com/kaitoy/goslings/blob/dba65bf4ca7ad1dd91b927d623b6ea9a39870b62/goslings-server/src/main/java/com/github/kaitoy/goslings/server/Application.java&#34;&gt;こちら&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;@SpringBootApplication&lt;/code&gt;を付けると、以下の三つのアノテーションを付けたのと同じことになる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/context/annotation/Configuration.html&#34;&gt;&lt;code&gt;@Configuration&lt;/code&gt;&lt;/a&gt; (&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/api/org/springframework/boot/SpringBootConfiguration.html&#34;&gt;&lt;code&gt;@SpringBootConfiguration&lt;/code&gt;&lt;/a&gt;): Spring Bean定義を提供するクラスであることを示す。(意味不明。)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/api/org/springframework/boot/autoconfigure/EnableAutoConfiguration.html&#34;&gt;&lt;code&gt;@EnableAutoConfiguration&lt;/code&gt;&lt;/a&gt;: Springの&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/reference/html/using-boot-auto-configuration.html&#34;&gt;自動設定機能&lt;/a&gt;を有効にする。この機能は、ライブラリの依存関係から推定して必要な設定をしてくれるもの。例えば&lt;code&gt;tomcat-embedded.jar&lt;/code&gt;に依存していたら、&lt;a href=&#34;http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/api/org/springframework/boot/context/embedded/tomcat/TomcatEmbeddedServletContainerFactory.html&#34;&gt;&lt;code&gt;TomcatEmbeddedServletContainerFactory&lt;/code&gt;&lt;/a&gt;をセットアップしてくれるなど。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/context/annotation/ComponentScan.html&#34;&gt;&lt;code&gt;@ComponentScan&lt;/code&gt;&lt;/a&gt;: このアノテーションを付けたクラスのパッケージ以下から、&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Component.html&#34;&gt;&lt;code&gt;@Component&lt;/code&gt;&lt;/a&gt;、&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Service.html&#34;&gt;&lt;code&gt;@Service&lt;/code&gt;&lt;/a&gt;、&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Repository.html&#34;&gt;&lt;code&gt;@Repository&lt;/code&gt;&lt;/a&gt;、&lt;a href=&#34;http://docs.spring.io/spring-framework/docs/4.3.4.RELEASE/javadoc-api/org/springframework/stereotype/Controller.html&#34;&gt;&lt;code&gt;@Controller&lt;/code&gt;&lt;/a&gt;(など?)が付いたクラスが検索され、Spring Beanとして登録される。XMLのSpring Bean設定ファイルを書かなくてよい。前節で作ったリソースコントローラがこのアノテーションによって利用できるようになる。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;@SpringBootApplication&lt;/code&gt;、というか&lt;code&gt;@Configuration&lt;/code&gt;をつけたクラスは&lt;code&gt;final&lt;/code&gt;にしてはいけない。
すると実行時にエラーになる。&lt;/p&gt;

&lt;h4 id=&#34;8-ビルド-実行&#34;&gt;8. ビルド、実行&lt;/h4&gt;

&lt;p&gt;以上でとりあえず動くものができた。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;gradlew bootRun&lt;/code&gt;を実行するとディベロッパツール付きでアプリが動くし、&lt;code&gt;gradlew build&lt;/code&gt;を実行すれば&lt;code&gt;build/libs/goslings-0.0.1.jar&lt;/code&gt;というアーティファクトが生成され、&lt;code&gt;java -jar build/libs/goslings-0.0.1.jar&lt;/code&gt;でアプリを起動できる。
(いずれもポートは8080)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今日はここまで。
&lt;a href=&#34;https://www.kaitoy.xyz/2017/01/10/goslings-development-memo2-spring-boot-di/&#34;&gt;次回&lt;/a&gt;はまたSpring Bootで、DIについて。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goslings開発メモ - その0: 紹介と概要と設計編</title>
          <link>https://www.kaitoy.xyz/2016/12/11/goslings-development-memo0-intro-design/</link>
          <pubDate>Sun, 11 Dec 2016 15:26:45 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/12/11/goslings-development-memo0-intro-design/</guid>
          <description>

&lt;p&gt;つい先日&lt;a href=&#34;https://github.com/kaitoy/goslings&#34;&gt;&lt;strong&gt;Goslings&lt;/strong&gt;&lt;/a&gt;というものを作った。
&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;Gitのリポジトリの中身&lt;/a&gt;をビジュアライズするWebアプリケーションだ。
なんとなく見て楽しいという効用がある他は、Gitの勉強にちょっと使えるかもしれないという程度のものだが、もともと&lt;a href=&#34;http://qiita.com/advent-calendar/2016/git&#34;&gt;Git Advent Calendar 2016&lt;/a&gt;のネタを作るために作ろうと思ったものなので、とりあえずはこんなものでいいのだ。
将来気が向いたら、リポジトリの変更をリアルタイムに反映したり、リポジトリの操作もできるように拡張してもいいかもしれないけど、実用性が感じられないので多分やらない。&lt;/p&gt;

&lt;p&gt;因みに、goslingsというのはgeese(雁)の子供を指す、ちょっとマイナーな英語。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-development-memo0-design/geese.JPG&#34; alt=&#34;geese&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Gitオブジェクトを見るアプリだから、GOで始まる名前にしようかと思っていて、そういえば今住んでいるFort Collinsに大量にいるgeeseの子供がgoslingsというし、並んで歩いている姿がちょうどコミットグラフのようだと思い、Goslilngsと名付けた。
単数形だと&lt;a href=&#34;https://en.wikipedia.org/wiki/Ryan_Gosling&#34;&gt;カナダのイケメン俳優&lt;/a&gt;かと思われてしまうので、複数形にした。goslingが一人でいることってないし。&lt;/p&gt;

&lt;p&gt;Goslingsは&lt;a href=&#34;https://projects.spring.io/spring-boot/&#34;&gt;Spring Boot&lt;/a&gt;や&lt;a href=&#34;https://eclipse.org/jgit/&#34;&gt;JGit&lt;/a&gt;などの習作でもある。
学んだことはアプリケーションとしてアウトプットするとよく身に付くものだ。
また文章としてもアウトプットしておくとさらによく身に付き、備忘録にもなるので、Goslingsの開発メモをいくつかのエントリに分けて書いていくことにする。&lt;/p&gt;

&lt;p&gt;まずはSpring Boot編を書こうかと思うが、その前にGoslingsの設計等について書いておく。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;goslingsのアーキテクチャ&#34;&gt;Goslingsのアーキテクチャ&lt;/h1&gt;

&lt;p&gt;GoslingsはWebサーバとして動き、始めにクライアントにHTML文書を返した後は、REST APIサーバとして働く。&lt;/p&gt;

&lt;p&gt;サーバ側はJavaでできていて、Spring BootとJGitを使っている。
JGitを使いたかったのでJavaにしたが、そうでなければ&lt;a href=&#34;https://nodejs.org/ja/&#34;&gt;Node&lt;/a&gt;で書きたかった。&lt;/p&gt;

&lt;p&gt;因みに、今回はコーディングの詳細にあまりこだわらないつもりだったので、&lt;a href=&#34;https://projectlombok.org/&#34;&gt;Lombok&lt;/a&gt;で楽をしようかと思ったけど、うっとうしい&lt;a href=&#34;https://github.com/rzwitserloot/lombok/issues/879&#34;&gt;バグ&lt;/a&gt;を踏み、どうやっても回避できなかったので使うのやめた。
二度と使うまい。&lt;/p&gt;

&lt;p&gt;クライアント側はJavaScript(ES2015 + async/await)の&lt;a href=&#34;https://en.wikipedia.org/wiki/Single-page_application&#34;&gt;SPA&lt;/a&gt;で、禁&lt;a href=&#34;https://jquery.com/&#34;&gt;jQuery&lt;/a&gt;縛り。
&lt;a href=&#34;https://facebook.github.io/react/&#34;&gt;React&lt;/a&gt; + &lt;a href=&#34;https://github.com/reactjs/redux&#34;&gt;Redux&lt;/a&gt;というのをやってみたかったが、なんか大げさだしそこまで時間がとれなそうだったので、フレームワークなしで作った。ので、
「&lt;a href=&#34;http://qiita.com/tatesuke/items/b9548dd484b01b139b74&#34;&gt;You Don&amp;rsquo;t Need jQuery&lt;/a&gt;」とにらめっこしながら書いた。&lt;/p&gt;

&lt;p&gt;Gitのコミットグラフの描画には、&lt;a href=&#34;http://visjs.org/&#34;&gt;vis.js&lt;/a&gt;を使った。
&lt;a href=&#34;http://stackoverflow.com/questions/7034/graph-visualization-library-in-javascript&#34;&gt;Stack Overflowの回答&lt;/a&gt;から雰囲気で選んだけど、やりたかったことが全部できて、見た目もよかったのでよかった。&lt;/p&gt;

&lt;p&gt;サーバは&lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt;で動かすためにステートレスに作ったつもりで、後述の作業ディレクトリをコンテナ間で共有し、サーバの負荷に応じてコンテナを増やしたり減らしたり、簡単にスケールするようになっているはず。&lt;/p&gt;

&lt;h1 id=&#34;goslingsの機能設計&#34;&gt;Goslingsの機能設計&lt;/h1&gt;

&lt;p&gt;Goslingsサーバにブラウザでアクセスすると、まず参照したいGitリポジトリのURIを入力するフォームが表示される。
ここにはローカルにあるリポジトリへのファイルシステム上のパス(e.g. &lt;code&gt;C:\repos\project-hoge\.git&lt;/code&gt;)か、リモートにあるリポジトリのURL(e.g. &lt;code&gt;https://repos.foo.com/project-hoge.git&lt;/code&gt;)を入力できる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-development-memo0-design/goslings-form.png&#34; alt=&#34;goslings-form&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;URIを入力して&lt;code&gt;Browse&lt;/code&gt;ボタンを&lt;a href=&#34;http://qiita.com/yaju/items/0ceb6a0343561b4d208e&#34;&gt;押下する&lt;/a&gt;と、Goslingsの作業ディレクトリ(デフォルトではtmpディレクトリの下の&lt;code&gt;goslings&lt;/code&gt;)に、ローカルリポジトリの場合はそこへのsymlinkを、リモートリポジトリの場合はベアなクローンを作成する。
いずれの場合にも、正規化したURIから生成したUID(SHA-1ハッシュ)をsymlinkファイル名とクローンディレクトリ名に使う。
サーバはリポジトリの準備ができたら、そのUIDをトークン(i.e. リポジトリ引換券)としてクライアントに渡す。
クライアントはそのトークンを使って、リポジトリの情報をサーバに要求する。&lt;/p&gt;

&lt;p&gt;こうすることで、以下の様に後でリポジトリを取り扱いやすくなる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;クライアントやサーバは、可変長の長ったらしい特殊文字の含まれたURIの代わりに、40文字の数字とアルファベットだけで構成されたトークンでリポジトリを特定でき、処理がしやすい。&lt;/li&gt;
&lt;li&gt;後でサーバがリポジトリにアクセスする際、ローカルとリモートを区別する必要がないので、処理がしやすい。&lt;/li&gt;
&lt;li&gt;サーバ内部でリポジトリというエンティティを扱う際、リポジトリに直接触るデータレイヤと、クライアントからのリクエストをさばくインターフェースレイヤとの間で、単なる文字列であるトークンをやりとりすればよく、データレイヤの実装の詳細をインターフェースレイヤに曝さなくてよくなり、レイヤをきれいに分離できる。これはJavaの&lt;a href=&#34;https://docs.oracle.com/javase/tutorial/java/IandI/createinterface.html&#34;&gt;インターフェース&lt;/a&gt;を作ってやってもできるが、インターフェースのAPIを考える手間を考えるとトークンの方が楽。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;クライアントはトークンを受け取ったらコミットグラフビューに遷移する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/goslings-development-memo0-design/graph.png&#34; alt=&#34;graph&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;このビューでの表示は&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;以前Gitリポジトリの中身を解説した記事&lt;/a&gt;に合わせた。&lt;/p&gt;

&lt;p&gt;初期状態ではコミットと参照とタグだけが表示されていて、コミットをダブルクリックするとツリーが表示され、さらにツリーをダブルクリックするとドリルダウンしていける。
ノードをシングルクリックするとそのコンテンツを参照できる。&lt;/p&gt;

&lt;h1 id=&#34;goslingsの使い方&#34;&gt;Goslingsの使い方&lt;/h1&gt;

&lt;p&gt;Spring Bootを使ったおかげで、ビルド成果物は単一のjarで、これを以下の様に実行するだけでサーバが立ち上がる。Webアプリケーションコンテナいらず。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ java -jar goslings-server-0.0.1.jar --server.port=80
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;com.github.kaitoy.goslings.server.reposDir&lt;/code&gt;というシステムプロパティを使って作業ディレクトリのパスを指定できる。&lt;/p&gt;

&lt;p&gt;また、&lt;code&gt;com.github.kaitoy.goslings.server.uriPrefix&lt;/code&gt;というシステムプロパティに値を設定すると、その値で始まるURI以外をフォームで入力するとエラーになるようになる。
リモートリポジトリを何でもかんでもクローンされるとディスク容量がいくらあっても足りないので、URLに制限をかけるために作った設定。
汎用性は考えておらず、複数指定したり正規表現を指定したりといったことはできない。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/r/kaitoy/goslings/&#34;&gt;Dockerコンテナイメージ&lt;/a&gt;もあって、以下のようなコマンドでダウンロードして起動できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker pull kaitoy/goslings
$ docker run -p 80:80 -itd kaitoy/goslings 80 /goslings-repos https://github.com/kaitoy/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;docker run&lt;/code&gt;の後ろの方の&lt;code&gt;80 /goslings-repos https://github.com/kaitoy/&lt;/code&gt;が、それぞれ&lt;code&gt;--server.port&lt;/code&gt;、&lt;code&gt;com.github.kaitoy.goslings.server.reposDir&lt;/code&gt;、&lt;code&gt;com.github.kaitoy.goslings.server.uriPrefix&lt;/code&gt;に渡される。
&lt;code&gt;--server.port&lt;/code&gt;のもの以外は省略してもいい。&lt;/p&gt;

&lt;h1 id=&#34;goslings-as-a-service&#34;&gt;Goslings as a Service&lt;/h1&gt;

&lt;p&gt;Goslings as a Service、略してGaaSを &lt;a href=&#34;http://www.goslings.tk&#34;&gt;http://www.goslings.tk&lt;/a&gt; で公開している。
&lt;code&gt;https://github.com/kaitoy/&lt;/code&gt;で始まるURLしか受け付けないようにしてある。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/&#34;&gt;AWS&lt;/a&gt;の無料枠を活用して&lt;a href=&#34;https://aws.amazon.com/ecs/&#34;&gt;EC2 Container Service (ECS)&lt;/a&gt;でホストしていて、&lt;a href=&#34;http://www.freenom.com/ja/index.html&#34;&gt;Freenom&lt;/a&gt;で無料で取得した&lt;code&gt;goslings.tk&lt;/code&gt;ドメインとこれまた無料のFreenomのネームサーバを利用して上記のアドレスにしている。&lt;/p&gt;

&lt;p&gt;AWSもFreenomも無料なのは12か月だけなので、それが過ぎたらGaaSは終了する予定。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Currently Pcap4J Doesn&#39;t Work on Bash on Windows</title>
          <link>https://www.kaitoy.xyz/2016/11/19/pcap4j-doesnt-work-on-bow-yet/</link>
          <pubDate>Sat, 19 Nov 2016 11:41:07 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/11/19/pcap4j-doesnt-work-on-bow-yet/</guid>
          <description>

&lt;h1 id=&#34;tl-dr&#34;&gt;TL;DR&lt;/h1&gt;

&lt;p&gt;I&amp;rsquo;ve attempted to run &lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;&lt;strong&gt;Pcap4J&lt;/strong&gt;&lt;/a&gt; on &lt;a href=&#34;https://msdn.microsoft.com/en-us/commandline/wsl/about&#34;&gt;&lt;strong&gt;Bash on Windows&lt;/strong&gt;&lt;/a&gt; (BoW) but it didn&amp;rsquo;t work due to lack of support for network staff in BoW.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;what-s-bash-on-windows&#34;&gt;What&amp;rsquo;s Bash on Windows&lt;/h1&gt;

&lt;p&gt;Bash on Windows is a feature released in &lt;a href=&#34;https://blogs.windows.com/windowsexperience/2016/08/02/how-to-get-the-windows-10-anniversary-update/#j0WW1oOyf4smWkeX.97&#34;&gt;Windows 10 Anniversary Update&lt;/a&gt; to add Linux fanctionalities to Windows.&lt;/p&gt;

&lt;p&gt;With this feature, we can run Bash and several Linux commands on Windows.&lt;/p&gt;

&lt;p&gt;It sounds similar to &lt;a href=&#34;https://www.cygwin.com/&#34;&gt;Cygwin&lt;/a&gt; and &lt;a href=&#34;http://www.mingw.org/&#34;&gt;MinGW&lt;/a&gt; but actually different. Linux commands Cygwin and MinGW provides are Windows-native binaries. On the other hand, BoW enables to run Ubuntu instance as a subsystem of Windows and to execute Ubuntu-native binaries on it.&lt;/p&gt;

&lt;p&gt;BoW can be easily installed by only 2 steps as per &lt;a href=&#34;https://msdn.microsoft.com/commandline/wsl/install_guide&#34;&gt;the installation guide&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;try-pcap4j-in-bow&#34;&gt;Try Pcap4J in BoW&lt;/h1&gt;

&lt;p&gt;BoW can be started by &lt;code&gt;bash&lt;/code&gt; command in command prompt.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\kaitoy&amp;gt;bash
kaitoy@DESKTOP-41L0NMU:/mnt/c/Users/kaitoy$ uname -a
Linx DESKTOP-41L0NMU 3.4.0+ #1 PREEMPT Thu Aug 1 17:06:05 CST 2013 x86_64 x86_64 x86_64 GNU/Linux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the bash, I ran the following commands to install Pcap4J dependencies:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt-get update
sudo apt-get install openjdk-7-jdk libpcap-dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then, I executed Pcap4J (org.pcap4j.sample.GetNextPacketEx) and got an error as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ java -cp pcap4j-core-1.6.2.jar:pcap4j-packetfactory-static-1.6.2.jar:pcap4j-sample-1.6.2.jar:jna-4.2.1.jar:slf4j-api-1.7.12.jar:logback-classic-1.0.0.jar:logback-core-1.0.0.jar org.pcap4j.sample.GetNextPacketEx
org.pcap4j.sample.GetNextPacketEx.count: 5
org.pcap4j.sample.GetNextPacketEx.readTimeout: 10
org.pcap4j.sample.GetNextPacketEx.snaplen: 65536


java.io.IOException: Return code: -1, Message: getifaddrs: Invalid argument
        at org.pcap4j.util.NifSelector.selectNetworkInterface(NifSelector.java:40)
        at org.pcap4j.sample.GetNextPacketEx.main(GetNextPacketEx.java:43)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This error seems due to &lt;a href=&#34;https://github.com/Microsoft/BashOnWindows/issues/69&#34;&gt;lack of support&lt;/a&gt; for network staff in BoW.&lt;/p&gt;

&lt;p&gt;BoW is still beta. I will try again after its production release.&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Bash on WindowsでWindows側からUbuntu側のファイルをいじると壊れることがあるので注意</title>
          <link>https://www.kaitoy.xyz/2016/11/19/bow-do-not-change-linux-files-from-windows/</link>
          <pubDate>Sat, 19 Nov 2016 01:05:26 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/11/19/bow-do-not-change-linux-files-from-windows/</guid>
          <description>

&lt;p&gt;Bash on WindowsでWindows側からUbuntu側のファイルをいじると危険という情報を見つけたので、試してみたら確かに困った状態になった話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;bash-on-windowsとは&#34;&gt;Bash on Windowsとは&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://msdn.microsoft.com/en-us/commandline/wsl/about&#34;&gt;Bash on Windows&lt;/a&gt; (aka BoW)は、2016/8/3に公開されたWindows 10 Anniversary Updateで使えるようになった、Windows上でBashが使えるようになる機能。&lt;/p&gt;

&lt;p&gt;POSIX APIのWindows実装を提供する&lt;a href=&#34;https://www.cygwin.com/&#34;&gt;Cygwin&lt;/a&gt;などとは違い、WindowsのサブシステムとしてUbuntuが動き、その上でBashが動き、そこからUbuntu用のバイナリをそのまま利用できるというもの。&lt;/p&gt;

&lt;p&gt;2016/11/17現在でまだベータ版の機能。&lt;/p&gt;

&lt;h1 id=&#34;windows側からubuntu側のファイルをいじると壊れる問題&#34;&gt;Windows側からUbuntu側のファイルをいじると壊れる問題&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://blogs.msdn.microsoft.com/commandline/2016/11/17/do-not-change-linux-files-using-windows-apps-and-tools/&#34;&gt;Microsoftの中の人のブログ&lt;/a&gt;に、BoWがセットアップされた環境で、Windows側からUbuntu側のファイル(i.e. &lt;code&gt;%localappdata%\lxss\&lt;/code&gt;以下のファイル)をいじると壊れるという話があった。
いかにもやってしまいそうな操作で危険だし、実際このブログの人はこれに関する問い合わせに毎日1,2件対応しているそうな。&lt;/p&gt;

&lt;p&gt;原因は上記ブログに詳しいが、簡単に言うと、Windows側のプロセスがUbuntu側のファイルを作ったり編集したりする際、パーミッションなどのメタデータを適切に設定しないため、Ubuntu側でファイルが壊れたと判断されてしまうから。
こうなると、結果としてファイルが消えてしまったり、壊れたデータで上書きされてしまったりするとのこと。&lt;/p&gt;

&lt;p&gt;因みに、Ubuntu側からWindows側のファイルをいじるのは問題ないらしい。&lt;/p&gt;

&lt;h1 id=&#34;再現確認&#34;&gt;再現確認&lt;/h1&gt;

&lt;p&gt;そういえばまだBoWをさわったことがなかったので、セットアップして件の問題を体験してみた。&lt;/p&gt;

&lt;p&gt;環境は、VMware Player 7.1.0で作ったVMに評価版のWindows 10 Enterprise v1607をインストールしたもの。
セットアップは&lt;a href=&#34;https://msdn.microsoft.com/en-us/commandline/wsl/install_guide&#34;&gt;公式の手順&lt;/a&gt;に従うだけ。2ステップだけの簡単な手順。&lt;/p&gt;

&lt;p&gt;セットアップ後、コマンドプロンプトで&lt;code&gt;bash&lt;/code&gt;とうつとBoWが起動する。(初回はインストール処理が走り、十数分待たされる。)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[コマンドプロンプト → Bash]&lt;/strong&gt;
&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/bow.png&#34; alt=&#34;bow.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;再現確認に使うのは&lt;code&gt;hoge&lt;/code&gt;と書いた&lt;code&gt;hoge.txt&lt;/code&gt;。
これをWindows側の&lt;code&gt;C:\Users\kaitoy\Desktop\&lt;/code&gt;とUbuntu側の&lt;code&gt;/home/kaitoy/&lt;/code&gt;に置く。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[コマンドプロンプト]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/hoge_cmd.png&#34; alt=&#34;hoge_cmd.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/hoge_ubuntu.png&#34; alt=&#34;hoge_ubuntu.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Windows側からは、Ubuntuのファイルシステムが&lt;code&gt;%localappdata%\lxss\&lt;/code&gt;にマウントされているように見える。
(&lt;code&gt;lxss&lt;/code&gt;はエクスプローラーのオプションから「保護されたオペレーティングシステムファイルを表示しない（推奨）」のチェックをはずさないと見えない。見えなくてもアドレスバーにパスを入力すればアクセスできるけど。)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/lxss.png&#34; alt=&#34;lxss.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;一方Ubuntu側からは、WindowsのCドライブが&lt;code&gt;/mnt/c&lt;/code&gt;にマウントされているように見える。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/mntc.png&#34; alt=&#34;mntc.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ここで、コマンドプロンプトを開き、&lt;code&gt;%localappdata%\lxss\hoge\kaitoy\&lt;/code&gt;(i.e. Ubuntu側の&lt;code&gt;/home/kaitoy/&lt;/code&gt;)に&lt;code&gt;cd&lt;/code&gt;し、&lt;code&gt;hoge.txt&lt;/code&gt;を&lt;code&gt;echo&lt;/code&gt;で編集してみた。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[コマンドプロンプト]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/mod_from_cmd.png&#34; alt=&#34;mod_from_cmd.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;したらBashから見えなくなった。アクセスしようとすると「Input/output error」というエラーになる。これが件の現象か。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/disappeared.png&#34; alt=&#34;disappeared.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;エクスプローラからは見えていたので、GUIで&lt;code&gt;%localappdata%\lxss\hoge\kaitoy\hoge.txt&lt;/code&gt;を削除したら正常な状態に戻った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;再度同じ&lt;code&gt;hoge.txt&lt;/code&gt;を作り、今度はメモ帳で編集して内容を&lt;code&gt;foo&lt;/code&gt;に変えてみた。
この場合は特に問題なし。なぜだ?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/no_problem.png&#34; alt=&#34;no_problem.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;例のブログをよく読むと、実際に問題になるのはファイルの作成だけのように読める。
編集しているようにみえても、アプリによっては新規ファイルを作って既存のを置き換えていることがあるから、編集もするなと言っている模様。
メモ帳は実際に編集しているから大丈夫だったということか。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;今編集した&lt;code&gt;hoge.txt&lt;/code&gt;を今度はエクスプローラから消してみる。
Ubuntu側からは消えてないように見えるが、アクセスしようとするとないと言われる。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/not_deleted.png&#34; alt=&#34;not_deleted.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;エクスプローラのビューをF5で更新したら、今消したはずの&lt;code&gt;hoge.txt&lt;/code&gt;が復活した。
これをダブルクリックで開こうとしたら「Access is denied.」。
エクスプローラから何度消してもすぐ復活する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/access_denied.png&#34; alt=&#34;access_denied.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Bashで消そうとしても「Permission denied」。詰んだ。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/permission_denied.png&#34; alt=&#34;permission_denied.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ということで、むしろWindows側からUbuntu側のファイルを消すのがもっともやばいと言うことがわかった。
&lt;code&gt;lxrun /uninstall /full&lt;/code&gt;、&lt;code&gt;lxrun /install&lt;/code&gt;でUbuntuイメージをインストールしなおさないと直らない。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;最後に、Ubuntu側(i.e. Bash)からWindows側の&lt;code&gt;C:\Users\kaitoy\Desktop\hoge.txt&lt;/code&gt;をいじってみたが、例のブログに書いてある通りなんの問題もなかった。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Bash]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/bow-do-not-change-linux-files-from-windows/fin.png&#34; alt=&#34;fin.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;件の問題もベータがとれたら直るかもしれないが、&lt;code&gt;%localappdata%\lxss\&lt;/code&gt;は保護された隠しフォルダなのでやはり触らないのが無難か。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>git checkoutを図解する</title>
          <link>https://www.kaitoy.xyz/2016/10/08/git-checkout/</link>
          <pubDate>Sat, 08 Oct 2016 16:39:46 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/10/08/git-checkout/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;この記事&lt;/a&gt;を読んだ、またはGitのオブジェクトモデルを理解していることを前提に、&lt;a href=&#34;https://git-scm.com/&#34;&gt;&lt;strong&gt;Git&lt;/strong&gt;&lt;/a&gt;の &lt;code&gt;git checkout&lt;/code&gt; というコマンドについて説明する。&lt;/p&gt;

&lt;p&gt;このコマンドは普通ブランチを切り替えるものと説明されるが、主たる機能は &lt;strong&gt;オブジェクト格納領域から指定されたファイルを取り出し、ワーキングディレクトリに配置する&lt;/strong&gt; ものである。
つまりこれがGitにおけるチェックアウトで、チェックアウト=ブランチの切り替えではない。&lt;/p&gt;

&lt;p&gt;コマンドに与える引数によっては &lt;code&gt;HEAD&lt;/code&gt; の付け替え、つまりはブランチの切り替えもする、というだけ。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git checkout&lt;/code&gt; の動作を &lt;code&gt;HEAD&lt;/code&gt; の付け替えの有無によって分けて考えると分かりやすく覚えやすいので、以下そのように説明する。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;headを付け替えないgit-checkout&#34;&gt;HEADを付け替えないgit checkout&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;HEAD&lt;/code&gt; を付け替えない &lt;code&gt;git checkout&lt;/code&gt; は、引数にワーキングディレクトリ内の &lt;strong&gt;ファイルまたはディレクトリへのパスを与えた場合&lt;/strong&gt; のもの。
ディレクトリを指定した場合はそれ以下の全ファイルが操作対象となる。
パスは絶対パスかカレントディレクトリからの相対パスで、複数指定できる。&lt;/p&gt;

&lt;p&gt;つまりは以下の様なコマンド形式になる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git checkout &amp;lt;パス(複数可)&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;これを実行すると、指定したファイルについて、&lt;strong&gt;インデックスが指しているブロブ&lt;/strong&gt; をオブジェクト格納領域から取り出し、ワーキングディレクトリのファイルを置き変える。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド6.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths/スライド7.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;上のスライドではインデックスが指しているブロブを取り出したが、任意のブロブを取り出すこともできる。
この場合、以下の様なコマンド形式を使う。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git checkout &amp;lt;コミット&amp;gt; &amp;lt;パス(複数可)&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;このコマンド形式だと、&lt;strong&gt;指定したコミットが指すツリー以下のブロブ&lt;/strong&gt; が取り出される。
&lt;code&gt;&amp;lt;コミット&amp;gt;&lt;/code&gt;の部分には、コミットオブジェクトのSHA1ハッシュ値、参照(i.e. ブランチかタグ)、シンボリック参照(e.g. &lt;code&gt;HEAD&lt;/code&gt;)を指定できる。(実際にはこれらが全てではないが、実用的にはこの3種。)&lt;/p&gt;

&lt;p&gt;この形式だと、ワーキングディレクトリだけでなく、取り出すブロブを指すよう &lt;strong&gt;インデックスも更新される&lt;/strong&gt; ことに注意。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths_commit/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths_commit/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_paths_commit/スライド3.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h1 id=&#34;headを付け替えるgit-checkout&#34;&gt;HEADを付け替えるgit checkout&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;HEAD&lt;/code&gt; を付け替える &lt;code&gt;git checkout&lt;/code&gt; は、引数に &lt;strong&gt;パスを与えない場合&lt;/strong&gt; のもの。
代わりにコミットを与える。&lt;/p&gt;

&lt;p&gt;つまりは以下の様なコマンド形式になる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git checkout &amp;lt;コミット&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;コミット&amp;gt;&lt;/code&gt;の部分には、コミットオブジェクトのSHA1ハッシュ値、参照(i.e. ブランチかタグ)、シンボリック参照(e.g. &lt;code&gt;HEAD&lt;/code&gt;)を指定できる。(実際にはこれらが全てではないが、実用的にはこの3種。)&lt;/p&gt;

&lt;p&gt;これを実行すると、&lt;strong&gt;指定したコミットが指すツリー以下の全てのブロブ&lt;/strong&gt; を指すようインデックスを更新し、それらのブロブをオブジェクト格納領域から取り出してワーキングディレクトリに配置する。&lt;/p&gt;

&lt;p&gt;この上更に&lt;code&gt;HEAD&lt;/code&gt;を付け替えるわけだが、付け替え先は&lt;code&gt;&amp;lt;コミット&amp;gt;&lt;/code&gt;の種類によって以下の三通りある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;コミット&amp;gt;&lt;/code&gt;がブランチ: &lt;code&gt;HEAD&lt;/code&gt;はそのブランチを指すよう更新される。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;コミット&amp;gt;&lt;/code&gt;がSHA1ハッシュ値: &lt;code&gt;HEAD&lt;/code&gt;はコミットを指すよう更新される。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;コミット&amp;gt;&lt;/code&gt;がタグかシンボリック参照: &lt;code&gt;HEAD&lt;/code&gt;はタグかシンボリック参照が指すコミットを指すよう更新される。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド6.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド7.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド8.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-checkout/git_checkout_branch/スライド9.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;上のスライド中のコミットをチェックアウトした例を見ると分かるが、コマンド実行前後でワーキングディレクトリからファイルが削除されることもある。
これは多分、実際にはインデックスの更新処理の前に、&lt;code&gt;HEAD&lt;/code&gt;が指すコミットに含まれるファイルをワーキングディレクトリから削除する処理があるからだと考えられる。&lt;/p&gt;

&lt;p&gt;また、上のスライドには表現していないが、コマンド実行前にワーキングディレクトリやインデックスに未コミットな変更が入っている場合、Gitはそれをコマンド実行後のワーキングディレクトリに適用しようとしてくれる。
これは例えばあるブランチで作った変更を別のブランチにコミットしたいようなときは便利だが、&lt;code&gt;checkout&lt;/code&gt;したコミットに別途変更が入っているとその適用は失敗し、コマンドがエラーになるので、普通はコマンド実行前に&lt;code&gt;git stash&lt;/code&gt;しておくのが無難。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Gitの良さが分からない？ ちょっとそこに座れ</title>
          <link>https://www.kaitoy.xyz/2016/10/06/git-vs-subversion/</link>
          <pubDate>Thu, 06 Oct 2016 00:18:05 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/10/06/git-vs-subversion/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://crapp.hatenablog.com/entry/2016/10/01/111528&#34;&gt;Gitの良さがいまだに分からない&lt;/a&gt;という人がいるようなので、Git派の一人としてSubversion(以下SVN)と比較してのGitの良さ(メリット)について語りたい。
(GitとSVNの違いについては他の人の記事に詳しいのであまり書いていない一方、勢い余ってGitのデメリットも書いた。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;本題に入る前に、冒頭にリンクを貼った記事についてひとつだけつっこんでおく。
つっこみどころは他にも沢山あるけど。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;※話の前提としてgitとSVNを採用している現場に下記のような割と違いがあるとする。&lt;/p&gt;

&lt;p&gt;git
イシューごとにブランチを切り、ローカルでコミットして、リモートブランチにpushして、GitHub・GitLab・Bitbucket経由でマージリクエスト。コードレビューの後にマージ。&lt;/p&gt;

&lt;p&gt;SVN
リモートのtrunkに個々人が直接コミット。コードレビューはあまりない。ブランチを切ることもない。&lt;/p&gt;

&lt;p&gt;このような違いが出る背景には次のものがある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gitを採用する現場は、猫も杓子もgit-flowというプラクティスに従う傾向がある
gitを採用する現場は、コードの品質もある程度管理する傾向がある
SVNは集中型でありブランチ機能などが非常に使いにくい
SVNを採用する現場はコードの品質よりも「リリースに含めるならさっさとコミット」と考える傾向がある
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;p&gt;この前提には無理がある。&lt;/p&gt;

&lt;p&gt;Gitのところに書いてあるのが、Gitというツールの枠を大きくはみだした&lt;a href=&#34;https://gist.github.com/Gab-km/3705015&#34;&gt;GitHub Flow&lt;/a&gt;というブランチ戦略+開発プロセスに当たるものであり、
それでGitを批判するのはお門違いであろうという点については、Gitの流行がGitHubの人気によるところが大きく、GitHubを使えることがGitの大きなメリットであるので、目をつむることにする。(マージリクエストを使う羽目になるデメリットなんて言いがかりでしかないとだけ言っておく。)&lt;/p&gt;

&lt;p&gt;看過できないのは、SVNを使った開発がコードレビューもブランチもないという点。&lt;/p&gt;

&lt;p&gt;どこの世界の話をしているんだろうか。
Gitが世に出る前は世間にコードレビューもブランチもあまりなかったかのような前提だが、もちろんそんなことは全くない。
60万個以上のOSSプロジェクト情報を統括する&lt;a href=&#34;https://ja.wikipedia.org/wiki/Ohloh&#34;&gt;Open HUB&lt;/a&gt;によれば、OSSプロジェクトの&lt;a href=&#34;https://www.openhub.net/repositories/compare&#34;&gt;46%がSVNを使っている&lt;/a&gt;。この中にはGitの誕生以降にSVNを使い始めたプロジェクトも多くある。270000余りのプロジェクトの大部分がブランチすら使っていないとでも?&lt;/p&gt;

&lt;p&gt;GitHub Flowと対比するために無理やりこじつけたんだろうけど、その無理のせいで議論のスタート地点からめちゃくちゃだ。&lt;/p&gt;

&lt;p&gt;まともな開発にはコードレビューもブランチも必要だ。
品質管理もリリース管理もしないなら要らないのかもしれないが、そんないい加減な開発現場を前提にSVNかGitかなんて議論しても意味がない。
高品質なソフトウェアを効率よく開発するために則りたい素晴らしい開発フローがあるとして、そのフローをSVNやGitやその他のツールないしひょっとしたらアナクロな日付フォルダの内どれがもっとも上手く実現してくれるか、というのがあるべき議論だ。
この「素晴らしい開発フロー」には一般的に品質管理と並行開発が含まれていて、それらにはコードレビューとブランチの利用が含まれている。
Git(+GitHub)がこんなにも急速にSVNに取って代わって流行ったのは、分散リポジトリの仕組みとブランチの軽量な実装によって効率的な並行開発が実現でき、またプルリクエストなどの機能によりコードレビューを含む快適なソーシャルコーディングが実現できるからだ。
逆に言えば、Gitが流行ったことが、人々が効率的な並行開発やコードレビューを開発フローに取り入れたかった証拠と言えるかもしれない。&lt;/p&gt;

&lt;h1 id=&#34;gitのメリット&#34;&gt;Gitのメリット&lt;/h1&gt;

&lt;p&gt;前置きが長くなったが、少なくともブランチとコードレビューを活用した高品質で高効率なソフトウェア開発をしたいという前提で、SVNに対するGitのメリットを挙げてみたい。&lt;/p&gt;

&lt;h4 id=&#34;1-リポジトリ構造がシンプル&#34;&gt;1. リポジトリ構造がシンプル&lt;/h4&gt;

&lt;p&gt;Gitリポジトリはすごくシンプルに作られているそうな。
確かに、&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;その構造&lt;/a&gt;を見ると、&lt;code&gt;add&lt;/code&gt;、&lt;code&gt;commit&lt;/code&gt;、&lt;code&gt;log&lt;/code&gt;、&lt;code&gt;reset&lt;/code&gt;くらいは自前ですぐに実装できそうだ。&lt;/p&gt;

&lt;p&gt;このシンプルな構造のおかげで、Gitリポジトリは壊れにくい。ここで壊れにくいとは、リポジトリ内部で不整合が起こりにくいということで、コマンドミスでコミット履歴が一部消えたりとかいうトラブルは壊れるに入らない。&lt;/p&gt;

&lt;p&gt;実のところSVNリポジトリの構造を知らないので経験的なことしか言えないが、SVNリポジトリ(というより作業ディレクトリの管理情報?)はちょくちょく変な状態になり、クリーンアップしたり、酷い時には.svn内のファイルを手動でいじったりしなければならなかった。&lt;/p&gt;

&lt;p&gt;因みに、シンプルというのはリポジトリサイズがすごく小さいということにはならず、同等の履歴を含むGitリポジトリとSVNリポジトリはだいたい同サイズなんだそうな。&lt;/p&gt;

&lt;h4 id=&#34;2-ブランチが軽い&#34;&gt;2. ブランチが軽い&lt;/h4&gt;

&lt;p&gt;Gitのブランチは単一のコミットを指す参照で、リポジトリ内ではSHA-1ハッシュ値が書かれただけのたった一つのファイルに過ぎない。
その為ブランチは一瞬で作成できるし、ディスクも圧迫しないので、じゃんじゃん作ってじゃんじゃん消せる。
さらに、ローカルリポジトリに過去の全ファイルの全バージョンが入っているという分散リポジトリの特長のおかげで、ブランチの切り替えも軽快にできる。
ローカルから必要なファイルを作業ディレクトリに展開するだけなので。&lt;/p&gt;

&lt;p&gt;一方SVNはそもそもブランチをサポートする直接的な機能がないため、ブランチはリビジョンのコピーという形で実装されている。
コピーと言ってもハードリンクみたいなものでディスク上に物理的なコピーが作られるわけではなく、軽量という点ではGitと大差ないが、集中リポジトリなせいでブランチの切り替えには差が出る。
&lt;code&gt;svn switch&lt;/code&gt;にしろ&lt;code&gt;svn checkout&lt;/code&gt;にしろネットワークの向こうのサーバとの通信が必要なので、それなりの時間がかかるし、通信が途切れると切り替えられなくなる。&lt;/p&gt;

&lt;p&gt;冒頭に貼った記事にはGitはブランチを切り替える際に&lt;code&gt;stash&lt;/code&gt;とかしないといけなくて面倒とあったが、そんなのSVNだって同じだし、&lt;code&gt;stash&lt;/code&gt;すればいいだけだし、&lt;code&gt;stash&lt;/code&gt;という機能があるだけSVNよりまし。Gitならコミットはあとから書き変えられるので、&lt;code&gt;stash&lt;/code&gt;の代わりに一時的にコミットしちゃってもいい。&lt;/p&gt;

&lt;p&gt;それも嫌なら&lt;a href=&#34;http://qiita.com/shibukk/items/80430b54ecda7f36ca44&#34;&gt;&lt;code&gt;worktree&lt;/code&gt;&lt;/a&gt;使えばよろしい。&lt;/p&gt;

&lt;h4 id=&#34;3-バージョン間の差分取得が速い&#34;&gt;3. バージョン間の差分取得が速い&lt;/h4&gt;

&lt;p&gt;Gitは全てのファイルについて全てのバージョンのコンテンツをまるまるリポジトリに持っている。
一方SVNのリポジトリにはバージョン間の変更が記録されている。
このため、あるファイルについて任意のバージョン間の差分を取るのに、Gitはシンプルにそれぞれのバージョンのファイルを取り出して比較するだけでよいが、SVNは隣り合ったバージョンでなければバージョン間の変更を足し合わせて差分を計算しなければいけない。&lt;/p&gt;

&lt;p&gt;さらに、Gitは比較するファイルをローカルリポジトリから取り出すだけでよいが、SVNはサーバへのアクセスが必要なので、差分取得はGitの方が大分速い。&lt;/p&gt;

&lt;h4 id=&#34;4-ログ取得が速い&#34;&gt;4. ログ取得が速い&lt;/h4&gt;

&lt;p&gt;Gitのコミットは常にプロジェクトの全ファイルに対するものだ。
これは変更したファイルの一部だけを対象とするコミット操作ができないという意味ではない。
Gitがひとつのコミット操作をコミットオブジェクトと呼ばれる単一のファイルに記録し、そのファイルが常にプロジェクトの全ファイルの特定のバージョンを参照しているという意味だ。(正確に言うとこのファイル自身に全ての参照が記録されているわけではないが。)&lt;/p&gt;

&lt;p&gt;このためGitのコミット履歴は実にシンプルで、ログ一覧を取得するには単にコミットをたどりながらコミットオブジェクトに書かれたログを集めればいい。&lt;/p&gt;

&lt;p&gt;一方SVNはファイル毎にバージョンを管理するので、もう少しややこしい。&lt;/p&gt;

&lt;p&gt;さらに、Gitはコミットオブジェクトをローカルリポジトリから持ってこれるがSVNは(以下略)。&lt;/p&gt;

&lt;h4 id=&#34;5-オフラインでだいたいなんでもできる&#34;&gt;5. オフラインでだいたいなんでもできる&lt;/h4&gt;

&lt;p&gt;と、ここまで書いて、Gitのいいところはオフライン作業が捗るところではないかと思い立った。&lt;/p&gt;

&lt;p&gt;実際Gitは、&lt;code&gt;clone&lt;/code&gt;、&lt;code&gt;fetch&lt;/code&gt;、&lt;code&gt;pull&lt;/code&gt;、&lt;code&gt;push&lt;/code&gt;といったあからさまな操作以外はオフラインでできる。
多くの操作にネットワーク通信コストを払わなくていい上、リモートリポジトリサーバが落ちたりネットワークが落ちたり山に籠ったりしていても作業が続けられる。&lt;/p&gt;

&lt;p&gt;ノマドに最適。&lt;/p&gt;

&lt;p&gt;一方SVNがネットワーク通信なしでできることは、…ベースバージョンとのdiffくらい?&lt;/p&gt;

&lt;h4 id=&#34;6-コミット履歴を汚さずにコードレビューできる&#34;&gt;6. コミット履歴を汚さずにコードレビューできる&lt;/h4&gt;

&lt;p&gt;私の職場はSVNを使っていて、コードを書いたら一旦コミットして、リビジョンを偉い人に通知してレビューしてもらっている。
偉い人は遠い異国にいたりするが、こちらがコミットしてしまえばSVNの機能で変更内容の取得も確認もできるという寸法だ。
リポジトリ外で変更内容をやりとりする方法とは違って、レビュー後のコミットミスや漏れが起こる余地がないのがいいが、レビューで受けた指摘は別のコミットを加えて反映したり、酷い時はリバースコミットで変更を取り消す必要がある。
こういうコミット履歴は大抵単なるノイズで、そうでなくてもリポジトリにある必要はない情報だ。&lt;/p&gt;

&lt;p&gt;一方GitならP2Pで偉い人にコミットを送れるし、レビュー後にコミットの作り直しもできるので、コミット履歴をきれいに保てる。
履歴がきれいだと変更のトレーサビリティが高まる。
変更のトレーサビリティが高いと、保守性が高くなり、低メンテナンスコストで高品質なプロダクトの開発につながる。&lt;/p&gt;

&lt;h4 id=&#34;7-ソーシャルコーディングできる&#34;&gt;7. ソーシャルコーディングできる&lt;/h4&gt;

&lt;p&gt;SaaSなら&lt;a href=&#34;https://github.com/&#34;&gt;GitHub&lt;/a&gt;や&lt;a href=&#34;https://bitbucket.org/product&#34;&gt;Bitbucket&lt;/a&gt;、オンプレミスなら&lt;a href=&#34;https://enterprise.github.com/home&#34;&gt;GitHub Enterprise&lt;/a&gt;や&lt;a href=&#34;https://about.gitlab.com/&#34;&gt;GitLab&lt;/a&gt;を利用して、ソーシャルコーディングを実現できるのはやはりGitの大きな強みだ。&lt;/p&gt;

&lt;p&gt;ソーシャルコーディングはアジャイルの先にあるDevOpsに必須とも言える要素で、今後これを実現できないIT企業やユーザ企業は開発力で他企業に差を付けられ、苦しい競争を強いられるであろう。&lt;/p&gt;

&lt;p&gt;バージョン管理ツール単体だけでなく、その上に乗っかるものまで見た場合、GitはSVNに大きく差を付けている感がある。&lt;/p&gt;

&lt;h1 id=&#34;git対svnの迷信&#34;&gt;Git対SVNの迷信&lt;/h1&gt;

&lt;p&gt;調べているうちに、Git対SVNで広く信じられている迷信があることを知ったので、ついでに書き残しておく。&lt;/p&gt;

&lt;h4 id=&#34;1-svnのマージはクソ&#34;&gt;1. SVNのマージはクソ&lt;/h4&gt;

&lt;p&gt;例えば&lt;a href=&#34;http://catcher-in-the-tech.net/806/&#34;&gt;「SVNからGitに移行して分かった、今すぐSVNを捨てるべき3つの理由」&lt;/a&gt;という記事の3つめの理由にSVNのマージ機能がクソと書いてあるが、これは最近では迷信とされている。&lt;/p&gt;

&lt;p&gt;SVNは確かにかつてブランチとマージに対するサポートが貧弱で、ブランチがどこを起点に作られたか、どのコミットをマージしたかといった情報を記憶しなかったため、ユーザがコマンドに教えてあげたり、コミットログを工夫して記録してやらなければならなかった。
しかし、&lt;a href=&#34;https://subversion.apache.org/docs/release-notes/1.5.html#merge-tracking&#34;&gt;バージョン1.5&lt;/a&gt;からこの状況が改善され始め、&lt;a href=&#34;https://subversion.apache.org/docs/release-notes/1.8.html#auto-reintegrate&#34;&gt;バージョン1.8&lt;/a&gt;で成熟したオートマージ機能により、SVNのマージも十分強力なものになった。&lt;/p&gt;

&lt;p&gt;Gitは&lt;a href=&#34;https://git-scm.com/docs/merge-strategies&#34;&gt;オクトパスマージとかマージ戦略オプションとか&lt;/a&gt;あってさらに強力そうではあるけど、そんな高機能を必要とする場面があまりなさそう。&lt;/p&gt;

&lt;h4 id=&#34;2-svnフォルダが各フォルダにあってうっとうしくてほんとクソ&#34;&gt;2. .svnフォルダが各フォルダにあってうっとうしくてほんとクソ&lt;/h4&gt;

&lt;p&gt;これも今では迷信。&lt;a href=&#34;https://subversion.apache.org/docs/release-notes/1.7.html#wc-ng&#34;&gt;バージョン1.7&lt;/a&gt;から&lt;code&gt;.svn&lt;/code&gt;はルートフォルダだけに作られるようになった。&lt;/p&gt;

&lt;h1 id=&#34;gitのデメリット&#34;&gt;Gitのデメリット&lt;/h1&gt;

&lt;p&gt;GitはSVNより全ての点で優れているというわけでもない。
以下、SVNに対するGitのデメリットを挙げてみたい。&lt;/p&gt;

&lt;h4 id=&#34;1-cloneに時間がかかる&#34;&gt;1. cloneに時間がかかる&lt;/h4&gt;

&lt;p&gt;Gitでの開発は基本的にリポジトリ全体を&lt;code&gt;clone&lt;/code&gt;することから始まる。
上記の「オフラインでだいたいなんでもできる」というのは、最初に全部ローカルに持ってきてしまうことで活きてくる利点だ。&lt;/p&gt;

&lt;p&gt;けどリポジトリが大きいとやっぱり&lt;code&gt;clone&lt;/code&gt;は時間がかかる操作になる。
例えば、&lt;a href=&#34;https://github.com/torvalds/linux&#34;&gt;Linuxカーネル&lt;/a&gt;をGitHubから&lt;code&gt;clone&lt;/code&gt;してみたら 45 分程かかった。
そんなに気軽にできる操作ではない。&lt;/p&gt;

&lt;p&gt;このデメリットに対処する方法は&lt;a href=&#34;http://japan.blogs.atlassian.com/2014/05/handle-big-repositories-git/&#34;&gt;いくつかある&lt;/a&gt;が、それをするとオフライン作業の幅を狭めることになる。&lt;/p&gt;

&lt;p&gt;SVNには&lt;code&gt;clone&lt;/code&gt;の概念がないのでこの悩みはない。&lt;/p&gt;

&lt;h4 id=&#34;2-部分cloneのサポートが貧弱&#34;&gt;2. 部分cloneのサポートが貧弱&lt;/h4&gt;

&lt;p&gt;上でも書いたが、GitはSVNのように履歴をディレクトリやファイル毎に管理しているわけではなく、コミットはプロジェクトの全ファイルを参照(i.e. 依存)しているので、特定のディレクトリ以下だけのcloneといった部分cloneの完全な実装は技術的に困難だ。&lt;/p&gt;

&lt;p&gt;Gitはリリース当初、部分cloneのサポートを全く提供せず、バージョン1.7になってそれっぽい&lt;a href=&#34;http://stackoverflow.com/questions/600079/how-do-i-clone-a-subdirectory-only-of-a-git-repository&#34;&gt;sparse checkout&lt;/a&gt;が実装されたが、あまり使い勝手が良くない。
Gitの開発陣は当初から部分cloneの実装に乗り気ではないし、上記の技術的な壁もあるので、今後この状況が大きく改善されることは恐らくないであろう。&lt;/p&gt;

&lt;p&gt;妥協になるだろうが、ソースをモジュール毎に分割して別々のリポジトリに突っ込み、必要に応じて&lt;code&gt;submodule&lt;/code&gt;か&lt;code&gt;subtree&lt;/code&gt;でつなげるのが実用的な解ではないだろうか。
それにしたって面倒だが。&lt;/p&gt;

&lt;p&gt;SVNではリポジトリの一部を&lt;code&gt;checkout&lt;/code&gt;する操作は第一級市民であり、何の制限もなく快適にできる。
この点においてはSVNパイセンの圧勝だ。&lt;/p&gt;

&lt;h4 id=&#34;3-コマンドが分かり辛い&#34;&gt;3. コマンドが分かり辛い&lt;/h4&gt;

&lt;p&gt;Gitはもともと低レベルなバージョン管理ツールとして開発されたためか、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%AA%E3%83%BC%E3%83%8A%E3%82%B9%E3%83%BB%E3%83%88%E3%83%BC%E3%83%90%E3%83%AB%E3%82%BA&#34;&gt;神&lt;/a&gt;の思考パターンが凡人のそれとはかけ離れているためか、Gitのコマンド体系は分かり辛く使いにくいというのは世界共通の認識のようだ。
このためGitの導入に当たってはどうしても高い学習コストを払わなければいけない。&lt;/p&gt;

&lt;p&gt;これは、分散バージョン管理システムというアーキテクチャが複雑だから、という理由からくるものではない。
同じ分散バージョン管理システムでも、&lt;a href=&#34;https://www.mercurial-scm.org/&#34;&gt;Mercurial&lt;/a&gt;は&lt;a href=&#34;https://blogs.atlassian.com/2012/02/mercurial-vs-git-why-mercurial/&#34;&gt;一貫したきれいな使いやすいコマンド体系をもっている&lt;/a&gt;らしい。&lt;/p&gt;

&lt;p&gt;好みの問題もあるだろうが、この点についてもSVNに分があるというのが一般的な認識だ。&lt;/p&gt;

&lt;p&gt;まあGitのGUIツールも&lt;a href=&#34;https://git-scm.com/docs/git-gui&#34;&gt;バンドルされてるやつ&lt;/a&gt;とか&lt;a href=&#34;https://tortoisegit.org/&#34;&gt;TortoiseGit&lt;/a&gt;とか&lt;a href=&#34;https://ja.atlassian.com/software/sourcetree&#34;&gt;SourceTree&lt;/a&gt;とか&lt;a href=&#34;https://www.gitkraken.com/&#34;&gt;イカ&lt;/a&gt;とか色々あるので、それで大分カバーできるだろうが。&lt;/p&gt;

&lt;h4 id=&#34;4-バイナリファイルの扱いが下手&#34;&gt;4. バイナリファイルの扱いが下手&lt;/h4&gt;

&lt;p&gt;Gitは基本的にテキストファイルを扱うよう作られていて、バイナリファイルの扱いは下手だ。
これはSVNも同じだけど、SVNの方がましらしい。&lt;/p&gt;

&lt;p&gt;例えば、バイナリファイルの同等の履歴を管理するのに、GitはSVNより少しだけ多くリポジトリ容量を食う。&lt;/p&gt;

&lt;p&gt;また、Gitはファイルのコンテンツに注目して管理するツールであるが、バイナリファイルは人間から見ると少しの変更(e.g. 画像の明度の変更)でもコンテンツが大きく変わるため、Gitが変更前のファイルと変更後のファイルを別のファイルとして扱ってしまうことがある。(最近のバージョンでは修正されているかも。)&lt;/p&gt;

&lt;p&gt;SVNはファイルそのものに注目しているので、その内容がどんなに劇的に変わっても見失うことはない。&lt;/p&gt;

&lt;p&gt;Gitでバイナリファイル、特にサイズが大きかったり頻繁に修正されるものを扱う必要があるときは、&lt;a href=&#34;https://git-annex.branchable.com/&#34;&gt;git-annex&lt;/a&gt;や&lt;a href=&#34;https://git-lfs.github.com/&#34;&gt;Git Large File Storage (LFS)&lt;/a&gt;の利用を検討すべし。&lt;/p&gt;

&lt;h4 id=&#34;5-アクセスコントロール機能がない&#34;&gt;5. アクセスコントロール機能がない&lt;/h4&gt;

&lt;p&gt;Git自身にはアクセスコントロール機能が全く実装されていない(多分)。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;clone&lt;/code&gt;するときなんかは、HTTPやSSHやTLSの力を借りてリポジトリ単位でのユーザ認証ができたり、&lt;code&gt;push&lt;/code&gt;するときにはファイルシステムのアクセスコントロールの力を借りて特定のファイルの変更を防いだりはできるが、もっと細かい制御をしたい場合は&lt;a href=&#34;https://github.com/sitaramc/gitolite&#34;&gt;Gitolite&lt;/a&gt;の力を借りる必要がある。&lt;/p&gt;

&lt;p&gt;借りてばっかだ。&lt;/p&gt;

&lt;p&gt;一方SVNは自前で&lt;a href=&#34;http://svnbook.red-bean.com/en/1.8/svn.serverconfig.pathbasedauthz.html&#34;&gt;Path-Based Authorization&lt;/a&gt;という機能を持っていて、ユーザ認証とディレクトリまたはファイル単位での読み書き制限ができる。&lt;/p&gt;

&lt;h4 id=&#34;6-ファイル単位の履歴を保持しない&#34;&gt;6. ファイル単位の履歴を保持しない&lt;/h4&gt;

&lt;p&gt;上にも書いたが、GitはSVNのようにファイル単位でバージョン管理をしているわけではないし、また、ファイルそのものではなくそのコンテンツに注目してバージョン管理する。この特徴のせいで、Gitはたまにファイルの行方を見失うことがある。&lt;/p&gt;

&lt;p&gt;上記バイナリファイルの問題もそうだし、テキストファイルでもリネームとコンテンツ変更を同時にやると&lt;code&gt;git log --follow&lt;/code&gt;で&lt;a href=&#34;https://svnvsgit.com/#losing-history-after-rename-in-Git&#34;&gt;ファイルの履歴が追えなくなる&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;SVNはリネームにちゃんと&lt;code&gt;svn mv&lt;/code&gt;を使っている限りファイルを見失うことはない。&lt;/p&gt;

&lt;p&gt;ただこれは実際、Gitのデメリットと言うよりは、GitとSVNの思想の違いと言った方がいいかもしれない。
&lt;code&gt;git log --follow&lt;/code&gt;は単に&lt;a href=&#34;http://stackoverflow.com/questions/5743739/how-to-really-show-logs-of-renamed-files-with-git&#34;&gt;SVNに慣れ親しんだGit初心者のための機能&lt;/a&gt;で、真のGit使いは特定のファイルの履歴を追うということを必要としない。&lt;/p&gt;

&lt;p&gt;ファイルの履歴を見たい煩悩に駆られたら、心を静め、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%AA%E3%83%BC%E3%83%8A%E3%82%B9%E3%83%BB%E3%83%88%E3%83%BC%E3%83%90%E3%83%AB%E3%82%BA&#34;&gt;神&lt;/a&gt;に祈りを捧げ、Gitのソースコードを写経し、Gitコマンドを108回たたいて悟りを開くべし。&lt;/p&gt;

&lt;h1 id=&#34;まとめ&#34;&gt;まとめ&lt;/h1&gt;

&lt;p&gt;Git派としてGit押しの記事を書こうと思っていたが、意外とデメリットもたくさん見えてきてしまった。
結局、GitとSVNどちらが単純に優れているということはないので、プロジェクトの構成やワークフローなどの要件を鑑みて使い分ければよしということか。&lt;/p&gt;

&lt;h1 id=&#34;参考資料&#34;&gt;参考資料&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873114408/&#34;&gt;蝙蝠本&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://git.wiki.kernel.org/index.php/GitSvnComparsion&#34;&gt;GitSvnComparison&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://svnvsgit.com/&#34;&gt;Subversion vs. Git: Myths and Facts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Pcap4J on Nano Server on Hyper-V Containers on Windows 10 on VMware Playerにトライ</title>
          <link>https://www.kaitoy.xyz/2016/09/15/pcap4j-on-hyper-v-container-on-win10/</link>
          <pubDate>Thu, 15 Sep 2016 13:56:35 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/09/15/pcap4j-on-hyper-v-container-on-win10/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;Pcap4J&lt;/a&gt;が動くHyper-VコンテナをWindows 10上でビルドしようとしたけど3合目あたりで息絶えた話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;hyper-v-containersとは&#34;&gt;Hyper-V Containersとは&lt;/h2&gt;

&lt;p&gt;Hyper-V Containersは、MicrosoftによるWindowsネイティブなコンテナ技術である&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/about/about_overview&#34;&gt;Windows Containers&lt;/a&gt;の一種で、これによるコンテナは、同じくWindows Containersの一種であるWindows Server Containersのものに比べて、より厳密に隔離されている分、起動コストが高い。&lt;/p&gt;

&lt;p&gt;実体は&lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt;そのもので、コンテナイメージは&lt;a href=&#34;https://hub.docker.com/&#34;&gt;Docker Hub&lt;/a&gt;からpullできるし、コンテナの操作や管理はdockerコマンドでやる。(昔はコンテナ操作用PowerShellコマンドレットもあったが、不評だったので廃止したようだ。)
&lt;a href=&#34;https://github.com/docker/docker&#34;&gt;ソース&lt;/a&gt;もLinuxとWindowsで一本化されている。&lt;/p&gt;

&lt;p&gt;Windows 10の&lt;a href=&#34;https://blogs.windows.com/japan/2016/08/03/how-to-get-the-windows-10-anniversary-update/#eFCYhK68sDp1V0F7.97&#34;&gt;Anniversary Update&lt;/a&gt;で正式にリリースされたが、なんだかあまり注目されていない気がする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2016/07/31/docker-for-windows/#docker-for-windows%E3%81%A8%E3%81%AF&#34;&gt;Docker for Windows&lt;/a&gt;とは全く別物なので注意。&lt;/p&gt;

&lt;h2 id=&#34;hyper-v-containersのインストール-on-vmware-player&#34;&gt;Hyper-V Containersのインストール (on VMware Player)&lt;/h2&gt;

&lt;p&gt;自前のPCが5年前に買った&lt;a href=&#34;https://dynabook.com/&#34;&gt;dynabook&lt;/a&gt;でWindows 10をサポートしていないので、VMware PlayerのVM上のWindows 10にHyper-V Containersをインストールしてみる。&lt;/p&gt;

&lt;p&gt;VMは、Windows 7に入れたVMware Workstation 11.1.0 build-2496824に付属の VMware Player 7.1.0 build-2496824で作ったもの。
VMのバージョンは11.0。
2CPUでメモリは2.5GB。
ネットワークインターフェースはNAT。
このVMを、&lt;a href=&#34;https://www.kaitoy.xyz/2016/07/31/docker-for-windows/#vmware-player%E3%81%AEvm%E3%81%A7hyper-v%E3%82%92%E4%BD%BF%E3%81%86%E3%81%9F%E3%82%81%E3%81%AE%E8%A8%AD%E5%AE%9A&#34;&gt;Hyper-Vが使えるように設定しておく&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://ascii.jp/elem/000/001/216/1216220/&#34;&gt;この記事&lt;/a&gt;にしたがい、Windows 10の評価版をダウンロード。
今公開されている評価版はAnniversary Update適用済みのバージョン1607で、Hyper-V Containersをサポートしている。&lt;/p&gt;

&lt;p&gt;これをさっき作ったVMにインストール。&lt;/p&gt;

&lt;p&gt;Windows 10を起動し、以下、&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/quick_start/quick_start_windows_10&#34;&gt;Windows Containers on Windows 10&lt;/a&gt;に従って進める。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;containers機能有効化&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.thewindowsclub.com/how-to-open-an-elevated-powershell-prompt-in-windows-10&#34;&gt;PowerShellプロンプトを管理者権限でひらき&lt;/a&gt;、以下のコマンドで&lt;code&gt;containers&lt;/code&gt;機能を有効化。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;Enable-WindowsOptionalFeature -Online -FeatureName containers -All
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1分程度経つと再起動を促されるので再起動。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Hyper-V機能有効化&lt;/p&gt;

&lt;p&gt;再度PowerShellプロンプトを管理者権限で開いて、以下のコマンドでHyper-Vを有効化。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V -All
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1分程度経つと再起動を促されるので再起動。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;OpLocks無効化&lt;/p&gt;

&lt;p&gt;現在のHyper-Vコンテナは、安定性を上げるためにOpLocksという機能を無効にすべきらしい。
再度PowerShellプロンプトを管理者権限で開いて、以下のコマンドを実行する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;Set-ItemProperty -Path &#39;HKLM:SOFTWARE\Microsoft\Windows NT\CurrentVersion\Virtualization\Containers&#39; -Name VSmbDisableOplocks -Type DWord -Value 1 -Force
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dockerインストール&lt;/p&gt;

&lt;p&gt;同じPowerShellプロンプトで以下のコマンドを実行してDocker(EngineとClient)のアーカイブをダウンロード。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;Invoke-WebRequest &amp;quot;https://master.dockerproject.org/windows/amd64/docker-1.13.0-dev.zip&amp;quot; -OutFile &amp;quot;$env:TEMP\docker-1.13.0-dev.zip&amp;quot; -UseBasicParsing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ダウンロードしたアーカイブを解凍。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;Expand-Archive -Path &amp;quot;$env:TEMP\docker-1.13.0-dev.zip&amp;quot; -DestinationPath $env:ProgramFiles
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここまででDockerが&lt;code&gt;C:\Program Files\docker\&lt;/code&gt;に入るので、このパスを環境変数&lt;code&gt;PATH&lt;/code&gt;に追加。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;PATH&lt;/code&gt;の変更を反映させるために再度PowerShellプロンプトを管理者権限で開いて、以下のコマンドでDockerデーモンをサービスに登録。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;dockerd --register-service
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dockerサービスを起動。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;Start-Service Docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(Dockerサービスは自動起動に設定されているので、OS再起動時は上記&lt;code&gt;Start-Service&lt;/code&gt;は不要。)&lt;/p&gt;

&lt;p&gt;これでDockerが使えるようになった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;docker version
Client:
 Version:      1.13.0-dev
 API version:  1.25
 Go version:   go1.7.1
 Git commit:   130db0a
 Built:        Sat Sep 10 13:25:48 2016
 OS/Arch:      windows/amd64


Server:
 Version:      1.13.0-dev
 API version:  1.25
 Go version:   go1.7.1
 Git commit:   130db0a
 Built:        Sat Sep 10 13:25:48 2016
 OS/Arch:      windows/amd64
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;コンテナイメージダウンロード&lt;/p&gt;

&lt;p&gt;どうもDockerコマンドの実行には管理者権限が必要なようなので、このまま管理者権限のPowerShellプロンプトで続ける。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker pull&lt;/code&gt;でNano Serverのコンテナイメージをダウンロード。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;docker pull microsoft/nanoserver
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;docker images&lt;/code&gt;で確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Windows\system32&amp;gt;docker images
REPOSITORY             TAG                 IMAGE ID            CREATED             SIZE
microsoft/nanoserver   latest              3a703c6e97a2        12 weeks ago        970 MB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;試しにコンテナ起動。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;PS C:\Windows\system32&amp;gt;docker run -it microsoft/nanoserver cmd&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;起動はかなり遅い。1分近くかかった。ともあれちゃんと起動した。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/pcap4j-on-hyper-v-container-on-win10/test_container.png&#34; alt=&#34;test_container.png&#34; /&gt;
&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;pcap4jコンテナのビルド&#34;&gt;Pcap4Jコンテナのビルド&lt;/h2&gt;

&lt;p&gt;Pcap4Jコンテナを、&lt;code&gt;docker build&lt;/code&gt;でビルドしてみる。
Dockerfileはとりあえず&lt;a href=&#34;https://www.kaitoy.xyz/2016/07/11/windows_containers_on_tp5/#pcap4j%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A%E3%82%A4%E3%83%A1%E3%83%BC%E3%82%B8%E3%81%AE%E3%83%93%E3%83%AB%E3%83%89&#34;&gt;以前のもの&lt;/a&gt;をちょっと書き変えただけのものを試す。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-dockerfile&#34;&gt;# escape=`

#
# Dockerfile for Pcap4J on Windows Nano Server
#

FROM microsoft/nanoserver
MAINTAINER Kaito Yamada &amp;lt;kaitoy@pcap4j.org&amp;gt;

# Install Chocolatey.
RUN mkdir C:\pcap4j
WORKDIR C:\\pcap4j
ADD https://chocolatey.org/install.ps1 install.ps1
RUN powershell .\install.ps1

# Install dependencies.
RUN choco install -y nmap jdk7 &amp;amp;&amp;amp; `
    choco install -y maven -version 3.2.5

# Build Pcap4J.
RUN powershell -Command Invoke-WebRequest https://github.com/kaitoy/pcap4j/archive/v1.zip -OutFile pcap4j.zip &amp;amp;&amp;amp; `
    powershell -Command Expand-Archive -Path pcap4j.zip -DestinationPath .
WORKDIR pcap4j-1
RUN powershell -Command &amp;quot;mvn -P distribution-assembly install 2&amp;gt;&amp;amp;1 | Add-Content -Path build.log -PassThru&amp;quot;

# Collect libraries.
RUN mkdir bin &amp;amp;&amp;amp; `
    cd pcap4j-packetfactory-static &amp;amp;&amp;amp; `
    mvn -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeScope=compile dependency:copy-dependencies &amp;amp;&amp;amp; `
    mvn -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeGroupIds=ch.qos.logback dependency:copy-dependencies &amp;amp;&amp;amp; `
    cd ../pcap4j-distribution &amp;amp;&amp;amp; `
    mvn -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeArtifactIds=pcap4j-packetfactory-static,pcap4j-sample dependency:copy-dependencies

# Generate sample script. (C:\pcap4j\pcap4j-1\bin\capture.bat)
RUN echo @echo off &amp;gt; bin\capture.bat &amp;amp;&amp;amp; `
    echo &amp;quot;%JAVA_HOME%\bin\java&amp;quot; -cp C:\pcap4j\pcap4j-1\bin\pcap4j-core.jar;C:\pcap4j\pcap4j-1\bin\pcap4j-packetfactory-static.jar;C:\pcap4j\pcap4j-1\bin\pcap4j-sample.jar;C:\pcap4j\pcap4j-1\bin\jna.jar;C:\pcap4j\pcap4j-1\bin\slf4j-api.jar;C:\pcap4j\pcap4j-1\bin\logback-classic.jar;C:\pcap4j\pcap4j-1\bin\logback-core.jar org.pcap4j.sample.GetNextPacketEx &amp;gt;&amp;gt; bin\capture.bat
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#/escape&#34;&gt;escapeディレクティブ&lt;/a&gt;が使えるようになっていたので使うようにしている。
(というか以前Windows Server 2016 TP5で試した時はescapeディレクティブをDockerfileの先頭に書かなかったのがだめだったってだけかもしれない。)
&lt;code&gt;WORKDIR&lt;/code&gt;のパスの区切りにはescapeディレクティブは利かない変な仕様。&lt;/p&gt;

&lt;h4 id=&#34;nano-serverでsystem-net-webclient使えない問題&#34;&gt;Nano ServerでSystem.Net.WebClient使えない問題&lt;/h4&gt;

&lt;p&gt;このDockerfileでビルドしたら、&lt;a href=&#34;https://chocolatey.org/&#34;&gt;Chocolatey&lt;/a&gt;のダウンロード・インストールスクリプトを実行する&lt;code&gt;RUN powershell .\install.ps1&lt;/code&gt;のステップで&lt;code&gt;System.Net.WebClient&lt;/code&gt;が見つからないというエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;new-object : Cannot find type [System.Net.WebClient]: verify that the assembly
containing this type is loaded.
At C:\pcap4j\install.ps1:84 char:17
+   $downloader = new-object System.Net.WebClient
+                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : InvalidType: (:) [New-Object], PSArgumentExcepti
   on
    + FullyQualifiedErrorId : TypeNotFound,Microsoft.PowerShell.Commands.NewOb
   jectCommand
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nano Serverに入っているPowerShellは&lt;a href=&#34;https://technet.microsoft.com/en-us/windows-server-docs/compute/nano-server/powershell-on-nano-server&#34;&gt;Core Editionなる機能限定版&lt;/a&gt;で、System.Net.WebClientだけでなく、&lt;a href=&#34;http://serverfault.com/questions/788949/download-a-file-with-powershell-on-nano-server&#34;&gt;WebアクセスのためのAPIがいろいろ欠けているもよう&lt;/a&gt;。&lt;/p&gt;

&lt;h4 id=&#34;hyper-v-containersでserver-core使えない問題&#34;&gt;Hyper-V ContainersでServer Core使えない問題&lt;/h4&gt;

&lt;p&gt;Nano Serverめんどくさそうなので、Server Coreをpullする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Windows\system32&amp;gt;docker pull microsoft/windowsservercore
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dockerfileの&lt;code&gt;FROM&lt;/code&gt;を&lt;code&gt;microsoft/windowsservercore&lt;/code&gt;に書き変えてビルドしたら、最初の&lt;code&gt;RUN&lt;/code&gt;で以下のエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;container 4bc8d8d38993426fa7a3c76e4aabbe6a229cbd025754723ff396aec04ffbfa1d encountered an error during Start failed in Win32: The operating system of the container does not match the operating system of the host. (0xc0370101)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;調べたら、Hyper-V Containersはまだ&lt;a href=&#34;https://social.msdn.microsoft.com/Forums/en-US/9eea93ac-18de-4953-bc7c-efd76a155526/are-microsoftwindowsservercore-containers-working-on-windows-10?forum=windowscontainers&#34;&gt;Nano Serverしかサポートしていない&lt;/a&gt;ようだ。&lt;/p&gt;

&lt;h4 id=&#34;unzip難しい問題&#34;&gt;unzip難しい問題&lt;/h4&gt;

&lt;p&gt;Chocolateyのダウンロード・インストールスクリプトを実行するのはあきらめて、&lt;a href=&#34;https://chocolatey.org/install#download-powershell-method&#34;&gt;アーカイブを自分でダウンロードする方法&lt;/a&gt;を試す。&lt;/p&gt;

&lt;p&gt;これは&lt;code&gt;https://chocolatey.org/api/v2/package/chocolatey/&lt;/code&gt;というWeb APIをたたいてアーカイブをダウンロードする方法だけど、このURLを&lt;code&gt;ADD&lt;/code&gt;に渡してもうまくいかなかったので、このWeb APIが最終的に呼ぶ&lt;code&gt;https://packages.chocolatey.org/chocolatey.0.10.0.nupkg&lt;/code&gt;を&lt;code&gt;ADD&lt;/code&gt;するようにした。
これでダウンロードできる&lt;code&gt;chocolatey.0.10.0.nupkg&lt;/code&gt;はzipファイルで、unzipするとインストールスクリプトが出てくる。&lt;/p&gt;

&lt;p&gt;しかしこのunzipが曲者で、&lt;a href=&#34;https://www.kaitoy.xyz/2016/09/12/unzip-on-nanoserver/&#34;&gt;妙に苦労した話&lt;/a&gt;を最近書いた。&lt;/p&gt;

&lt;p&gt;で、苦労して取り出したインストールスクリプトを実行したら、エラーがわんさと出ただけだった。
そんなこったろうと思ってはいたが。&lt;/p&gt;

&lt;p&gt;どうせChocolateyをインストールできても、パッケージのインストールスクリプトがまた動かないんだろうから、もうChocolateyはあきらめる。&lt;/p&gt;

&lt;h4 id=&#34;wow64サポートしてない問題&#34;&gt;WoW64サポートしてない問題&lt;/h4&gt;

&lt;p&gt;Chocolateyを使わないようにDockerfileの前半を以下の様に書き変えた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-dockerfile&#34;&gt;(snip)

FROM michaeltlombardi/nanoserveropenjdk
MAINTAINER Kaito Yamada &amp;lt;kaitoy@pcap4j.org&amp;gt;

RUN mkdir C:\pcap4j
WORKDIR C:\\pcap4j

# Install Maven
ADD http://archive.apache.org/dist/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.zip maven.zip
RUN jar xf maven.zip
RUN powershell -command $env:path += &#39;;C:\pcap4j\apache-maven-3.3.9\bin&#39;; setx PATH $env:path /M

# Install Npcap
ADD https://github.com/nmap/npcap/releases/download/v0.08-r7/npcap-0.08-r7.exe npcap.exe
RUN npcap.exe /S

# Build Pcap4J.

(snip)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(因みにこの時点で、&lt;code&gt;PATH&lt;/code&gt;を設定するのに&lt;code&gt;GetEnvironmentVariable&lt;/code&gt;と&lt;code&gt;SetEnvironmentVariable&lt;/code&gt;がうまく使えない問題を乗り越えている。&lt;code&gt;Cannot find an overload for &amp;quot;GetEnvironmentVariable&amp;quot; and the argument count: &amp;quot;2&amp;quot;.&lt;/code&gt;というエラーが出て、PowerShell Desktop Editionのものと仕様がちょっと違うようだったので、&lt;code&gt;GetEnvironmentVariable&lt;/code&gt;も&lt;code&gt;SetEnvironmentVariable&lt;/code&gt;も使わないようにした。)&lt;/p&gt;

&lt;p&gt;このDockerfileでビルドしたら、&lt;code&gt;RUN npcap.exe /S&lt;/code&gt;で以下のエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;The subsystem needed to support the image type is not present.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このsubsystemというのはどうも&lt;a href=&#34;https://ja.wikipedia.org/wiki/WOW64&#34;&gt;WoW64&lt;/a&gt;を指しているようで、&lt;a href=&#34;https://blogs.technet.microsoft.com/windowsserver/2016/02/10/exploring-nano-server-for-windows-server-2016/&#34;&gt;Nano ServerがWoW64をサポートしていない&lt;/a&gt;のにnpcap.exeが32bitバイナリであることが問題のようであった。&lt;/p&gt;

&lt;p&gt;ついでに&lt;a href=&#34;https://ja.wikipedia.org/wiki/Microsoft_Windows_Installer&#34;&gt;MSI&lt;/a&gt;もサポートされていないことがわかった。大丈夫かこれ。&lt;/p&gt;

&lt;h4 id=&#34;nano-serverパッケージプロバイダバグってる問題&#34;&gt;Nano Serverパッケージプロバイダバグってる問題&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://technet.microsoft.com/en-us/windows-server-docs/compute/nano-server/getting-started-with-nano-server#a-namebkmkonlineainstalling-roles-and-features-online&#34;&gt;Nano Serverにもロールや機能の追加ができる&lt;/a&gt;らしいので、ひょっとしてこれで何か改善できないかと思って試した。&lt;/p&gt;

&lt;p&gt;Nano Serverへのロール・機能の追加は、Windowsのパッケージマネジメントシステムである&lt;a href=&#34;https://github.com/OneGet/oneget&#34;&gt;PackageManagement (a.k.a. OneGet)&lt;/a&gt;を使ってやる。PowerShellで&lt;code&gt;Install-PackageProvider NanoServerPackage&lt;/code&gt;と&lt;code&gt;Import-PackageProvider NanoServerPackage&lt;/code&gt;を実行するとNano Serverのパッケージプロバイダが使えるようになり、&lt;code&gt;Find-NanoServerPackage&lt;/code&gt;で利用できるパッケージの一覧が見れる。&lt;/p&gt;

&lt;p&gt;はずなんだけど、&lt;code&gt;Find-NanoServerPackage&lt;/code&gt;でエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;C:\pcap4j&amp;gt;powershell -command Find-NanoServerPackage
DownloadFile : Save-HTTPItem: Bits Transfer failed. Job State:  ExitCode = 255
At C:\Program Files\WindowsPowerShell\Modules\NanoServerPackage\0.1.1.0\NanoServerPackage.psm1:1294 char:9
+         DownloadFile -downloadURL $fullUrl `
+         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : InvalidOperation: (https://nanoser...ServerIndex.txt:String) [DownloadFile], RuntimeException
    + FullyQualifiedErrorId : FailedToDownload,DownloadFile

Get-Content : Cannot find drive. A drive with the name &#39;CleanUp&#39; does not exist.
At C:\Program Files\WindowsPowerShell\Modules\NanoServerPackage\0.1.1.0\NanoServerPackage.psm1:674 char:26
+     $searchFileContent = Get-Content $searchFile
+                          ~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : ObjectNotFound: (CleanUp:String) [Get-Content], DriveNotFoundException
    + FullyQualifiedErrorId : DriveNotFound,Microsoft.PowerShell.Commands.GetContentCommand

Get-Content : Cannot find path
&#39;C:\Users\ContainerAdministrator\AppData\Local\NanoServerPackageProvider\searchNanoPackageIndex.txt&#39; because it does not exist.
At C:\Program Files\WindowsPowerShell\Modules\NanoServerPackage\0.1.1.0\NanoServerPackage.psm1:674 char:26
+     $searchFileContent = Get-Content $searchFile
+                          ~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : ObjectNotFound: (C:\Users\Contai...ackageIndex.txt:String) [Get-Content], ItemNotFoundException
    + FullyQualifiedErrorId : PathNotFound,Microsoft.PowerShell.Commands.GetContentCommand
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/OneGet/NanoServerPackage/issues/4&#34;&gt;NanoServerPackageのIssues&lt;/a&gt;にこのエラーが登録されていた。1か月放置されてる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;パトラッシュ、僕はもう疲れたよ。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Hyper-Vコンテナ(Nano Server)でunzipしたいならjarを使え</title>
          <link>https://www.kaitoy.xyz/2016/09/12/unzip-on-nanoserver/</link>
          <pubDate>Mon, 12 Sep 2016 16:46:54 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/09/12/unzip-on-nanoserver/</guid>
          <description>

&lt;p&gt;Nano Serverでunzipしたかっただけだったのに、妙に苦労した話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;nano-serverとは&#34;&gt;Nano Serverとは&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://technet.microsoft.com/en-us/windows-server-docs/compute/nano-server/getting-started-with-nano-server&#34;&gt;Nano Server&lt;/a&gt;は、Windows Server 2016で追加されるWindows Serverの新たなインストール形式で、&lt;a href=&#34;https://en.wikipedia.org/wiki/Server_Core&#34;&gt;Server Core&lt;/a&gt;よりさらに機能を絞り、リモートで管理するクラウドホストやWebサーバ向けにに特化したもの。&lt;/p&gt;

&lt;p&gt;Server Coreが数GBくらいなのに対し、Nano Serverは数百MBととても軽量で、それゆえ起動が速くセキュア。&lt;/p&gt;

&lt;h2 id=&#34;unzipとは&#34;&gt;unzipとは&lt;/h2&gt;

&lt;p&gt;unzipとは、&lt;a href=&#34;https://ja.wikipedia.org/wiki/ZIP_(%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%83%95%E3%82%A9%E3%83%BC%E3%83%9E%E3%83%83%E3%83%88&#34;&gt;zip&lt;/a&gt;ファイルを解凍する、ただそれだけのこと。&lt;/p&gt;

&lt;p&gt;ただそれだけのことで、基本的な機能だと思うのだが、Windowsはこれを&lt;a href=&#34;https://technet.microsoft.com/en-us/library/dn841359.aspx&#34;&gt;コマンドラインで実行する方法&lt;/a&gt;をつい最近まで正式に提供していなかった。&lt;/p&gt;

&lt;h2 id=&#34;nano-serverでunzip&#34;&gt;Nano Serverでunzip&lt;/h2&gt;

&lt;p&gt;Windows 10の&lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#windows-containers%E3%81%A8%E3%81%AF&#34;&gt;Hyper-V Containers&lt;/a&gt;の上で&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;Pcap4J&lt;/a&gt;のビルドとテストをするDockerイメージをビルドしたくて、そのための依存ライブラリなどをインストールする処理をDockerfileに書いていて、&lt;code&gt;ADD&lt;/code&gt;でzipをダウンロードしたところまではいいんだけど、このzipどうやって解凍してやろうかとなった。
(Dockerホストに置いたものをコンテナに&lt;code&gt;ADD&lt;/code&gt;するのはなんか格好悪いから無しで。Dockerfile裸一貫で実現したい。)&lt;/p&gt;

&lt;p&gt;Windows 10のHyper-V Containersは、&lt;a href=&#34;https://social.msdn.microsoft.com/Forums/en-US/9eea93ac-18de-4953-bc7c-efd76a155526/are-microsoftwindowsservercore-containers-working-on-windows-10?forum=windowscontainers&#34;&gt;現時点でNano Serverしかサポートしていない&lt;/a&gt;のが厳しい点。Server Coreだったら楽だったのに。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以下、いろいろ試したことを書く。&lt;/p&gt;

&lt;h4 id=&#34;正攻法-expand-archive&#34;&gt;正攻法: Expand-Archive&lt;/h4&gt;

&lt;p&gt;PowerShellの v5 で実装されたExpand-Archiveというコマンドレットでzipを解凍できる。
Nano ServerのPowerShellのバージョンを確認したら 5.1 だったのでこれでいけるかと思った。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\&amp;gt;powershell -command &amp;quot;$PSVersionTable.PSVersion&amp;quot;

Major  Minor  Build  Revision
-----  -----  -----  --------
5      1      14284  1000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;したらこのエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Add-Type : Cannot find path &#39;C:\System.IO.Compression.FileSystem.dll&#39; because it does not exist.
At
C:\windows\system32\windowspowershell\v1.0\Modules\Microsoft.PowerShell.Archive\Microsoft.PowerShell.Archive.psm1:914
char:5
+     Add-Type -AssemblyName System.IO.Compression.FileSystem
+     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : ObjectNotFound: (C:\System.IO.Compression.FileSystem.dll:String) [Add-Type], ItemNotFoun
   dException
    + FullyQualifiedErrorId : PathNotFound,Microsoft.PowerShell.Commands.AddTypeCommand
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;どうもPowerShellの 5.1 以降には、.NET FrameworkベースのDesktop Editionと、そこから機能を絞った.NET CoreベースのCore Editionがあり、&lt;a href=&#34;https://technet.microsoft.com/en-us/windows-server-docs/compute/nano-server/powershell-on-nano-server&#34;&gt;Nano ServerのはCore Editionなんだそうな&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;Expand-ArchiveはSystem.IO.Compression.FileSystem.dllの中のZipFileクラスに依存しているんだけど、.NET CoreにはSystem.IO.Compression.FileSystem.dllが含まれていないっぽい。&lt;/p&gt;

&lt;h4 id=&#34;shellオブジェクトのcopyhere&#34;&gt;ShellオブジェクトのCopyHere&lt;/h4&gt;

&lt;p&gt;PowerShellでのunzip方法を調べたらStack Overflowに&lt;a href=&#34;http://stackoverflow.com/questions/27768303/how-to-unzip-a-file-in-powershell&#34;&gt;いくつか載っていた&lt;/a&gt;。
Expand-Archiveと、System.IO.Compression.ZipFileを直接使う方法と、Shellオブジェクト(COMオブジェクト)のCopyHereメソッドを使う方法。&lt;/p&gt;

&lt;p&gt;最初の2つはCore Editionでは使えないことが分かっているので、3つめにトライ。
こんなの↓&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;$shell = New-Object -ComObject shell.application
$zip = $shell.NameSpace(&amp;quot;C:\a.zip&amp;quot;)
MkDir(&amp;quot;C:\a&amp;quot;)
foreach ($item in $zip.items()) {
  $shell.Namespace(&amp;quot;C:\a&amp;quot;).CopyHere($item)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;調べたらこの方法は&lt;a href=&#34;https://support.microsoft.com/ja-jp/kb/2679832&#34;&gt;Microsoftから非推奨にされている&lt;/a&gt;ことが分かったんだけど、一応やってみる。&lt;/p&gt;

&lt;p&gt;したら以下のエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;new-object : Retrieving the COM class factory for component with CLSID {00000000-0000-0000-0000-000000000000} failed
due to the following error: 80040154 Class not registered (Exception from HRESULT: 0x80040154 (REGDB_E_CLASSNOTREG)).
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この方法で利用しようとしているのは&lt;a href=&#34;https://en.wikipedia.org/wiki/Windows_shell&#34;&gt;Windows shell&lt;/a&gt;、つまり&lt;a href=&#34;https://ja.wikipedia.org/wiki/Windows_Explorer&#34;&gt;Windows Explorer&lt;/a&gt;の機能らしく、そうであればまあGUIがないNano Serverで動かないのも当然か。&lt;/p&gt;

&lt;h4 id=&#34;サードパーティツールに頼る&#34;&gt;サードパーティツールに頼る&lt;/h4&gt;

&lt;p&gt;Stack Overflowの&lt;a href=&#34;http://stackoverflow.com/questions/1021557/how-to-unzip-a-file-using-the-command-line&#34;&gt;別の質問&lt;/a&gt;にサードパーティツールに頼る方法がいくつか紹介されていた。&lt;/p&gt;

&lt;p&gt;ここで挙げられていたもののうち、&lt;a href=&#34;http://www.7-zip.org/download.html&#34;&gt;7-Zip&lt;/a&gt;、&lt;a href=&#34;http://www.freebyte.com/fbzip/&#34;&gt;Freebyte Zip&lt;/a&gt;、&lt;a href=&#34;http://infozip.sourceforge.net/&#34;&gt;Info-ZIP&lt;/a&gt;は、配布形式がダメ。&lt;/p&gt;

&lt;p&gt;7-Zipのインストーラをコンテナで実行してみたら、「The subsystem needed to support the image type is not present.」というエラー。7-Zipにはzipで配布されているものもあるんだけど、皮肉としか思えない。&lt;/p&gt;

&lt;p&gt;Freebyte ZipやInfo-ZIPの自己解凍ファイルもコンテナ内では動いてくれない。&lt;/p&gt;

&lt;p&gt;一方、&lt;a href=&#34;http://membrane.com/synapse/library/pkunzip.html&#34;&gt;pkunzip&lt;/a&gt;はコマンドが裸で配布されているので行けるかと思ったが、実行したら「The system cannot execute the specified program.」なるエラー。
よく見たらこれ16bitアプリケーション。Nano Serverは32bitアプリすら実行できないというのに。&lt;/p&gt;

&lt;h4 id=&#34;jarに託された最後の希望&#34;&gt;jarに託された最後の希望&lt;/h4&gt;

&lt;p&gt;上に貼ったStack Overflowの質問には&lt;a href=&#34;https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jar.html&#34;&gt;jarコマンド&lt;/a&gt;を使う方法も挙げられていたが、JDKなんてどうせインストールできないとあきらめていた。&lt;/p&gt;

&lt;p&gt;が、ふと思い立って&lt;a href=&#34;https://hub.docker.com/&#34;&gt;Docker Hub&lt;/a&gt;を検索してみたら、&lt;a href=&#34;https://hub.docker.com/r/michaeltlombardi/nanoserveropenjdk/&#34;&gt;OpenJDK入りのNano Server&lt;/a&gt;をアップしてくれている人がいた。&lt;/p&gt;

&lt;p&gt;pullしてrunしてみたら確かにJDKがインストールされていた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\&amp;gt;java -version
openjdk version &amp;quot;1.8.0_102-1-ojdkbuild&amp;quot;
OpenJDK Runtime Environment (build 1.8.0_102-1-ojdkbuild-b14)
OpenJDK 64-Bit Server VM (build 25.102-b14, mixed mode)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、無事&lt;code&gt;&amp;quot;C:\Program Files\Java\bin\jar.exe&amp;quot; xf hoge.zip&lt;/code&gt;のようにしてunzipできた。&lt;/p&gt;

&lt;p&gt;ここまで1日かかった。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>オープンソースプロジェクトのすゝめ</title>
          <link>https://www.kaitoy.xyz/2016/08/21/an-encouragement-of-open-sourcing/</link>
          <pubDate>Sun, 21 Aug 2016 20:54:12 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/08/21/an-encouragement-of-open-sourcing/</guid>
          <description>

&lt;p&gt;&lt;strong&gt;&lt;em&gt;人は生まれながらにして貴賤の別なく、ただオープンソースプロジェクトを勤めて物事をよく知る者が貴人となるなり。&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;昔、偉い人がそんな感じのことを言っていたような。&lt;/p&gt;

&lt;p&gt;私がGitHubで開発しているライブラリ、&lt;strong&gt;&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;Pcap4J&lt;/a&gt;&lt;/strong&gt; のスターの数がつい先日 &lt;strong&gt;200&lt;/strong&gt; に達したのを記念して、これまでどんな活動をしてきたか、この活動によって何を得たかなどについて書きたい。&lt;/p&gt;

&lt;p&gt;願わくは、この記事に触発されてオープンソースプロジェクトを始める人のあらんことを。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;pcap4jとは&#34;&gt;Pcap4Jとは？&lt;/h2&gt;

&lt;p&gt;Pcap4Jは、パケットキャプチャとパケット解析をするJavaのライブラリ。
ニッチ。&lt;/p&gt;

&lt;p&gt;ただ最近になってビッグデータ解析技術が発達し、大量のパケットをリアルタイムで解析してシステムや運用にフィードバックするというのが現実的になってきたので、パケットキャプチャへの注目が高まってきている雰囲気がある。
こういう分野ではJavaがまだかなり人気なのもあってワンチャンある。&lt;/p&gt;

&lt;p&gt;パケットキャプチャの部分は &lt;strong&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/Pcap&#34;&gt;pcap&lt;/a&gt;&lt;/strong&gt; のラッパ。
パケット解析の部分は割とプラガブルで、外からプロトコル追加などのカスタマイズができるはできるんだけど、作りのせいなのかJavaなせいなのか解析器を書くのが結構つらい。&lt;/p&gt;

&lt;p&gt;競合は &lt;strong&gt;&lt;a href=&#34;http://jpcap.sourceforge.net/&#34;&gt;jpcap&lt;/a&gt;&lt;/strong&gt; や &lt;strong&gt;&lt;a href=&#34;http://jnetpcap.com/&#34;&gt;jNetPcap&lt;/a&gt;&lt;/strong&gt; など。
Google.comで&lt;code&gt;java packet capture&lt;/code&gt;と検索するとだいたいjpcap、Pcap4J、jNetPcapの順で表示される。&lt;/p&gt;

&lt;p&gt;打倒jpcap。&lt;/p&gt;

&lt;h2 id=&#34;数字で見るpcap4jプロジェクト&#34;&gt;数字で見るPcap4Jプロジェクト&lt;/h2&gt;

&lt;p&gt;Pcap4Jリポジトリの一番古いコミットは &lt;strong&gt;2011/12/18&lt;/strong&gt;。
東日本大震災後の節電施策として実施された休日シフト中にコーディングしていた覚えがあるので、多分2011年夏くらいから開発していたんだけど、とりあえずこの最古のコミットをプロジェクトの開始とすると、スターが200になった &lt;strong&gt;2016/8/11&lt;/strong&gt; まで &lt;strong&gt;1698日&lt;/strong&gt; かかったことになる。
約 &lt;strong&gt;0.118個/日&lt;/strong&gt;。遅い…&lt;/p&gt;

&lt;p&gt;コミット数は &lt;strong&gt;559個&lt;/strong&gt;。ほとんどが自前のコミット。
プロジェクト成長過程の動画を &lt;strong&gt;&lt;a href=&#34;http://gource.io/&#34;&gt;Gource&lt;/a&gt;&lt;/strong&gt; というツールで生成してみたが、一人でかけずりまわっているのがよく分かる。&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;embed video-player&#34; style=&#34;text-align: center&#34;&gt;
  &lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;320&#34; height=&#34;193&#34; src=&#34;https://www.youtube.com/embed/VFjNOTGbBhA&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;コミット頻度は約 &lt;strong&gt;0.33個/日&lt;/strong&gt; で、だいたい3日に1コミット。
思っていたより多いけど、胸張れるほどの頻度ではない。&lt;/p&gt;

&lt;p&gt;リリースは &lt;strong&gt;17個&lt;/strong&gt; で、約 &lt;strong&gt;0.30個/月&lt;/strong&gt;。少ない…&lt;/p&gt;

&lt;p&gt;Issuesが &lt;strong&gt;52個&lt;/strong&gt;、プルリクエストが &lt;strong&gt;16個&lt;/strong&gt;。
自分ではIssuesもプルリクエストもあまり作らないので、ほとんどが他人からのもの。
ちゃんとチケット駆動にしてトレーサビリティを確保しておくべきだったと後悔している。
けど面倒だし今更なので今後も適当にコミットしちゃう。&lt;/p&gt;

&lt;p&gt;あとはWatchが &lt;strong&gt;28人&lt;/strong&gt;、Forkが &lt;strong&gt;66個&lt;/strong&gt;、コントリビュータが &lt;strong&gt;7人&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&#34;スター200ってどうなの&#34;&gt;スター200ってどうなの?&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/jquery/jquery&#34;&gt;jQuery&lt;/a&gt;や&lt;a href=&#34;https://facebook.github.io/react/&#34;&gt;React&lt;/a&gt;なんてスター40000超えてるし、Javaなら&lt;a href=&#34;http://projects.spring.io/spring-framework/&#34;&gt;Spring Framework&lt;/a&gt;も10000に達しようとしている。200なんて全然大したことなくない?
と言う声が聞こえるようだが、そんな知らない人を探すのが難しいようなプロジェクトと比べてはいけない。&lt;/p&gt;

&lt;p&gt;スター200以上のプロジェクトは割合でみるととても少ない。&lt;/p&gt;

&lt;p&gt;現在GitHubがホストしてる全プロジェクトは &lt;strong&gt;14,308,407&lt;/strong&gt; 個。
Javaプロジェクトはその内二番目に大きい割合を占めていて &lt;strong&gt;1,501,840&lt;/strong&gt; 個 (約 &lt;strong&gt;10.5%&lt;/strong&gt; )。&lt;/p&gt;

&lt;div style=&#34;max-width: 600px; margin: 0 auto; text-align: center;&#34;&gt;
&lt;caption&gt;&lt;b&gt;GitHubのプロジェクト数 (言語別降順)&lt;/b&gt;&lt;/caption&gt;
&lt;canvas id=&#34;an-encouragement-of-open-sourcing-chart-1&#34;&gt;&lt;/canvas&gt;
(凡例をクリックして除外。グラフにホバーして値表示。)
&lt;/div&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;スター200以上のプロジェクトは &lt;strong&gt;37,031&lt;/strong&gt; 個で、全プロジェクト中、上位約 &lt;strong&gt;0.26%&lt;/strong&gt; に当たる。&lt;/p&gt;

&lt;p&gt;スター200以上のJavaプロジェクトは &lt;strong&gt;3,922&lt;/strong&gt; 個で、全Javaプロジェクト中、上位約 &lt;strong&gt;0.26%&lt;/strong&gt; に当たる。&lt;/p&gt;

&lt;div style=&#34;max-width: 600px; margin: 0 auto; text-align: center;&#34;&gt;
&lt;caption&gt;&lt;b&gt;GitHubのプロジェクト数 (スター数別降順)&lt;/b&gt;&lt;/caption&gt;
&lt;canvas id=&#34;an-encouragement-of-open-sourcing-chart-2&#34;&gt;&lt;/canvas&gt;
(凡例をクリックして除外。グラフにホバーして値表示。)
&lt;/div&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;div style=&#34;max-width: 600px; margin: 0 auto; text-align: center;&#34;&gt;
&lt;caption&gt;&lt;b&gt;GitHubのJavaプロジェクト数 (スター数別降順)&lt;/b&gt;&lt;/caption&gt;
&lt;canvas id=&#34;an-encouragement-of-open-sourcing-chart-3&#34;&gt;&lt;/canvas&gt;
(凡例をクリックして除外。グラフにホバーして値表示。)
&lt;/div&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;無名の個人にとっては、スター200、というかとりあえず100くらいは手ごろで手ごたえのある目標だ。&lt;/p&gt;

&lt;h2 id=&#34;オープンソースプロジェクトの育て方&#34;&gt;オープンソースプロジェクトの育て方&lt;/h2&gt;

&lt;p&gt;GitHubのスターの数というのはそのプロジェクトを気に入ってくれた人の数である。
この数はそのプロジェクトの成果物を実際に使ってくれている人や組織の数、つまり普及率と正の相関があるはずだ。
成果物の普及率はプロジェクトの成長度のひとつの指標であり、スターの増加を見るのはわが子のようなプロジェクトの成長を見るようでとても楽しい。&lt;/p&gt;

&lt;p&gt;ここでは、私がPcap4Jプロジェクトを育てるためにやったことと、やってないけどやるべきだと思っていることなどについて書く。
Pcap4Jはライブラリなので、アプリとかよりもライブラリよりの話が多めかも。&lt;/p&gt;

&lt;h4 id=&#34;未解決の問題を探す&#34;&gt;未解決の問題を探す&lt;/h4&gt;

&lt;p&gt;Pcap4Jプロジェクトを始める前は、競合を調べ、それらとの差別化を考えた。
他のプロジェクトが既に解決している問題を同じように解決したのでは魅力が出ない。
機能なり、性能なり、ユーザビリティなり、デザインなり、サポートプラットフォームなり、何かしらの点で競合より優れていたり、競合にないものを持っていることが重要。
そうでなければ作っていても面白くないし、モチベーションも続かない。&lt;/p&gt;

&lt;p&gt;まだ解決されていない問題を見つけたり、使っているアプリに不満を感じたら、新しいアプリやライブラリやプラグインを自分で作るチャンスととらえるべし。&lt;/p&gt;

&lt;h4 id=&#34;apiを練る&#34;&gt;APIを練る&lt;/h4&gt;

&lt;p&gt;Pcap4Jの開発を始めて、一番頭を使ったのがAPI設計。
分かりやすく、汎用的で、シンプルで、つまり使いやすいAPIを実装すべきことは言うまでもない。
APIがころころ変わるのはユーザにとても嫌がられるので、長い目で見ても問題なさそうな、拡張もしやすそうなAPIを設計すべし。
自分でそのライブラリを使ったアプリを作ってみると、ユーザ視点でAPIを評価できるのでよい。&lt;/p&gt;

&lt;p&gt;逆に、内部の設計はAPIに比べたらそんなに重要じゃない。
10年前の技術を使ったイモい実装でもいい。
とりあえずリリースして、&lt;a href=&#34;http://qiita.com/erukiti/items/9cc7850250268582dde7&#34;&gt;技術的負債&lt;/a&gt;として後で済し崩せばよし。&lt;/p&gt;

&lt;h4 id=&#34;githubに上げる&#34;&gt;GitHubに上げる&lt;/h4&gt;

&lt;p&gt;ある程度コードが書けたらどこかに公開するわけだけど、パブリックなリポジトリなら &lt;strong&gt;&lt;a href=&#34;https://github.com/&#34;&gt;GitHub&lt;/a&gt;&lt;/strong&gt; 一択。&lt;/p&gt;

&lt;p&gt;今の時代、猫も杓子も&lt;a href=&#34;https://github.com/google&#34;&gt;Google&lt;/a&gt;も&lt;a href=&#34;https://github.com/Microsoft&#34;&gt;Microsoft&lt;/a&gt;も&lt;a href=&#34;https://github.com/apple&#34;&gt;Apple&lt;/a&gt;も、ソースを公開すると言ったらGitHubだ。
迷うことはない。&lt;/p&gt;

&lt;p&gt;(弊社も最近&lt;a href=&#34;https://github.com/Hitachi&#34;&gt;組織アカウント&lt;/a&gt;を作ったようだ。知らなかった。)&lt;/p&gt;

&lt;h4 id=&#34;ドキュメントを充実させる-英語で&#34;&gt;ドキュメントを充実させる (英語で)&lt;/h4&gt;

&lt;p&gt;Pcap4JのREADME.mdやドキュメントは、大変だったけど最初から英語と日本語で書いた。
英語がメイン。&lt;/p&gt;

&lt;p&gt;英語は世界でもっとも多く使われている言語で、8.5億人が日常的に話す。実用レベルの英語を話せる人はもっと多く、17.5億人。英語を読んで理解できるというレベルならもっといるかもしれない。
一方、日本語を理解できる人は1.5億人もいない。しかもそのほとんどは極東のごく限られた地域に住む保守的な民族だ。
さらに、ソフトウェア技術の中心は英語の国アメリカにある。日本はどちらかといえばソフトウェア後進国と言わざるを得ない。
せっかくオープンソースプロジェクトに挑戦するなら、それが日本に特化したものでなければ、英語で公開してより多くの先進的な人たちに繋がり、使ってもらい、揉まれるのがやりがいがあり楽しい。&lt;/p&gt;

&lt;p&gt;ドキュメントの内容にも割と力をいれた。&lt;/p&gt;

&lt;p&gt;ドキュメントは理想的には、機能やサポートプラットフォームやインストール方法などを説明するドキュメントと、体系的で網羅的なAPIリファレンスに加え、簡易アプリケーションを書くようなチュートリアルやユースケースベースの解説があるといいと思う。&lt;/p&gt;

&lt;p&gt;因みにここでドキュメントと言っているのはユーザ向けのもの。
コントリビュータ等に向けて内部設計書みたいなものを書くと親切かと思うかもしれないが、全く必要ない。
世界的には&lt;a href=&#34;http://simplearchitect.hatenablog.com/entry/2016/06/20/080807&#34;&gt;ウォータフォールはほぼ完全にその役目を終え&lt;/a&gt;、&lt;a href=&#34;http://www.agilemanifesto.org/iso/ja/&#34;&gt;アジャイル&lt;/a&gt;な開発が当たり前になっている。
こうした開発プロセスでは体系立った設計書など書かない。知りたいことがあればソースを見ればよいというスタンス。
設計書が無くても誰も文句を言わないので安心してさぼるべし。&lt;/p&gt;

&lt;p&gt;因みに因みにプラグインの開発者はユーザの括りなので、それ向けのドキュメントはちゃんと書くべし。&lt;/p&gt;

&lt;p&gt;APIリファレンスはJavaならJavadocでもいい。
Pcap4JのJavadocは &lt;strong&gt;&lt;a href=&#34;http://qiita.com/alucky0707/items/72b578fc9f894a4169c2&#34;&gt;javadoc.io&lt;/a&gt;&lt;/strong&gt; で公開している。
このサービス最高に手軽でありがたいので、なくならないようにもっと広まってほしい。&lt;/p&gt;

&lt;h4 id=&#34;メアドを晒す&#34;&gt;メアドを晒す&lt;/h4&gt;

&lt;p&gt;README.mdには開発者へのコンタクトとしてメアドを晒すべし。&lt;/p&gt;

&lt;p&gt;質問やエンハンス依頼などをしたいがGitHub Issuesに登録するのはちょっと気が引ける、というシャイな人は海外にも意外と結構いて、Pcap4Jの場合、Issuesの5,6倍くらいのメールが来る。
また、仕事がからんでいる人はメールでコンタクトしてくる場合が多いようだ。&lt;/p&gt;

&lt;p&gt;こういう人たちの心をがっちり掴むために、メアドを晒し、素早く丁寧に、できればクールにフレンドリーに対応すべし。
アメリカ人なんかは特にこうした対応の質を重視する。
(逆に言えばバグを出してもしっかりサポートすれば万事OKみたいな雰囲気があってしまうんだけど。)&lt;/p&gt;

&lt;h4 id=&#34;パッケージマネジメントシステムを利用する&#34;&gt;パッケージマネジメントシステムを利用する&lt;/h4&gt;

&lt;p&gt;ライブラリの配布は、言語ごとに普及しているパッケージマネジメントシステムに &lt;strong&gt;必ず&lt;/strong&gt; 乗っかるべし。&lt;/p&gt;

&lt;p&gt;使いたいライブラリがオレオレ配布されていたときの絶望感ったらない。
他のライブラリと統一的に扱えないし、バージョンや依存性の解決も手動でやらなければいけない。
そんな絶望を撒き散らす魔女に自分がなってはいけない。&lt;/p&gt;

&lt;p&gt;Javascriptなら &lt;strong&gt;&lt;a href=&#34;https://www.npmjs.com/&#34;&gt;npm&lt;/a&gt;&lt;/strong&gt; や &lt;strong&gt;&lt;a href=&#34;https://bower.io/&#34;&gt;Bower&lt;/a&gt;&lt;/strong&gt;、Rubyなら &lt;strong&gt;&lt;a href=&#34;https://rubygems.org/&#34;&gt;RubyGems&lt;/a&gt;&lt;/strong&gt;、Pythonなら &lt;strong&gt;&lt;a href=&#34;https://pypi.python.org/pypi&#34;&gt;PyPI&lt;/a&gt;&lt;/strong&gt;(?)。&lt;/p&gt;

&lt;p&gt;Pcap4JはJavaなので &lt;strong&gt;&lt;a href=&#34;https://mvnrepository.com/&#34;&gt;Mavenリポジトリ&lt;/a&gt;&lt;/strong&gt;。当初から &lt;strong&gt;&lt;a href=&#34;http://search.maven.org/&#34;&gt;Maven Central Repository&lt;/a&gt;&lt;/strong&gt; に上げているけど、今なら &lt;strong&gt;&lt;a href=&#34;https://bintray.com/bintray/jcenter&#34;&gt;JCenter&lt;/a&gt;&lt;/strong&gt; の方が手軽でよさそう。
(けどjavadoc.io使うならやっぱりMaven Central Repositoryか。)&lt;/p&gt;

&lt;p&gt;敷居が高そうに見えるが、やってみると意外と簡単なので恐れることはない。&lt;/p&gt;

&lt;h4 id=&#34;ロゴを作る&#34;&gt;ロゴを作る&lt;/h4&gt;

&lt;p&gt;ロゴを作るのを勧めたい。&lt;/p&gt;

&lt;p&gt;パワポでシステム構成を説明するダイアグラムを書いているときに、ロゴがないコンポーネントを見つけた時の絶望感ったらない。
ニートなロゴを作って、希望を振りまく魔法少女たろう。&lt;/p&gt;

&lt;p&gt;プロジェクト名を&lt;a href=&#34;http://photoshopvip.net/77655&#34;&gt;おしゃれなフリーフォント&lt;/a&gt;で書いて、ちょっと&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%AB%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&#34;&gt;カーニング&lt;/a&gt;しただけの&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%AD%E3%82%B4%E3%82%BF%E3%82%A4%E3%83%97&#34;&gt;ロゴタイプ&lt;/a&gt;でもいい。
自分で作ったものがださくてかっこ悪いんじゃないかと不安になったら、&lt;a href=&#34;https://runc.io/&#34;&gt;runC&lt;/a&gt;のロゴマークを見ると心が休まるかもしれない。&lt;/p&gt;

&lt;p&gt;&lt;img alt=&#34;runc.png&#34; src=&#34;https://www.kaitoy.xyz/images/runc.png&#34; style=&#34;margin: 0px auto; display: block; width: 50%; min-width: 200px;&#34;&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kaitoy/pcap4j/blob/v1/www/logos.md&#34;&gt;Pcap4Jのロゴ&lt;/a&gt;は、PのついたキャップをJavaカラーでというアイデアをもとに嫁に描いてもらった。端っこがちょっとジャギジャギしてるのと、ファビコンにするとつぶれてしまうところをいつか何とかしたい。&lt;/p&gt;

&lt;p&gt;&lt;img alt=&#34;pcap4jlogo.png&#34; src=&#34;https://www.kaitoy.xyz/images/pcap4jlogo.png&#34; style=&#34;margin: 0px auto; display: block; width: 50%; min-width: 200px;&#34;&gt;&lt;/p&gt;

&lt;h4 id=&#34;ホームページを作る&#34;&gt;ホームページを作る&lt;/h4&gt;

&lt;p&gt;プロジェクトのホームページを作るのはいいアイデアだ。
箔がつくし、少なくとも作っている自分が楽しい。&lt;/p&gt;

&lt;p&gt;GitHubのプロジェクトページをホームページと言ってもいいが、せっかく &lt;strong&gt;&lt;a href=&#34;https://pages.github.com/&#34;&gt;GitHub Pages&lt;/a&gt;&lt;/strong&gt; が使えるのでトライすべし。(2016/12/16 追記: GitHub PagesにJekyll Theme Chooserという機能が追加され、&lt;a href=&#34;http://qiita.com/kaitoy/items/509ccefb1b31d80ba3f1&#34;&gt;非常に簡単にホームページを作れるようにもなった。&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;最近はシングルページのシンプルなホームページが流行りなので、内容は薄くても構わない。
&lt;a href=&#34;http://gulpjs.com/&#34;&gt;Gulpのホームページ&lt;/a&gt;を見て勇気づけられよう。
&lt;a href=&#34;https://webpack.github.io/&#34;&gt;webpack&lt;/a&gt;もなかなかの手抜きだ。&lt;/p&gt;

&lt;p&gt;ドキュメントには載せにくいカジュアルなPR文句とか、簡単な導入方法とかチュートリアルとかをホームページに書くのがいいかもしれない。
あとはロゴを貼ってGitHubへのリンクを張っておけば充分。
もちろん英語で。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.pcap4j.org/&#34;&gt;Pcap4Jのホームページ&lt;/a&gt;は &lt;strong&gt;&lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt;&lt;/strong&gt; を使って十数時間くらいでできた。
慣れている人ならもっと速くできるだろう。
この際ドメインを取ってしまうのもいい。箔のため。
&lt;code&gt;pcap4j.org&lt;/code&gt;は&lt;a href=&#34;https://www.value-domain.com/&#34;&gt;バリュードメイン&lt;/a&gt;で買ったけど、別にどこでもいい。
費用は業者やドメインによって異なるけど、&lt;code&gt;pcap4j.org&lt;/code&gt;の場合は年1598円。リーズナブル。&lt;/p&gt;

&lt;h4 id=&#34;stack-overflowで盛り上げる&#34;&gt;Stack Overflowで盛り上げる&lt;/h4&gt;

&lt;p&gt;プロジェクトの成熟度を &lt;strong&gt;&lt;a href=&#34;http://stackoverflow.com/&#34;&gt;Stack Overflow&lt;/a&gt;&lt;/strong&gt; の関連投稿数で図る人が一定数いる。&lt;/p&gt;

&lt;p&gt;Stack Overflowはプログラミング技術に関する世界で最も人気なフォーラムサイトだ。
Stack Overflowの投稿数が多ければそれだけコアなユーザや情報が多いということだし、困ったときにそこで質問すれば適切な回答が得られる見込みが高いということ。
ユーザコミュニティが育っているとも言え、そのライブラリを採用する根拠の一つになる。&lt;/p&gt;

&lt;p&gt;Stack Overflowに投稿される質問をチェックし、自分のライブラリなりツールで解決できる問題があったら回答してアピールすることで認知度が高まるだろう。
自分のプロジェクトに対する質問があれば、もちろん積極的に回答すべきだ。特に黎明期は。&lt;/p&gt;

&lt;p&gt;私もStack Overflowで一度だけPcap4JのPRをやったが、めんど^h^h^h時間がとれなくて続かなかった。
反応はよかったのでちょっと後悔。
自分のプロジェクトに関する質問をモニタリングする効率的な方法はないものか…&lt;/p&gt;

&lt;h4 id=&#34;コミットをし続ける&#34;&gt;コミットをし続ける&lt;/h4&gt;

&lt;p&gt;コミットはなるべく頻繁に。&lt;/p&gt;

&lt;p&gt;修正量は多くなくてもいいので、間をあけないことが重要。
今もメンテされているか、活発に開発されているかは、そのライブラリを使うかどうかの大きな判断基準の一つだ。&lt;/p&gt;

&lt;p&gt;同様にIssuesやプルリクエストに迅速に対応することも重要で、できたらいいんだけど、ちょっと大変。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://issuestats.com/&#34;&gt;Issue Stats&lt;/a&gt;&lt;/strong&gt; という、Issuesやプルリクエストへの対応速度などを解析してくれるサービスがある。
対応速度に自信があるならここのバッジを貼るのもいいかもしれない。&lt;/p&gt;

&lt;p&gt;&lt;img alt=&#34;stats.png&#34; src=&#34;https://www.kaitoy.xyz/images/an-encouragement-of-open-sourcing/stats.png&#34; style=&#34;margin: 0px auto; display: block; width: 50%; min-width: 200px;&#34;&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Pcap4Jのこの数字は怖くて見れない。&lt;/p&gt;

&lt;h4 id=&#34;継続的インテグレーションを実装する&#34;&gt;継続的インテグレーションを実装する&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E7%B6%99%E7%B6%9A%E7%9A%84%E3%82%A4%E3%83%B3%E3%83%86%E3%82%B0%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3&#34;&gt;継続的インテグレーション(CI)&lt;/a&gt;を実装すると、品質にまじめに取り組んでる風が出て、ライブラリへの信頼が高まる。&lt;/p&gt;

&lt;p&gt;利用するサービスは &lt;strong&gt;&lt;a href=&#34;https://travis-ci.org/&#34;&gt;Travis CI&lt;/a&gt;&lt;/strong&gt; でも &lt;strong&gt;&lt;a href=&#34;https://circleci.com/&#34;&gt;CircleCI&lt;/a&gt;&lt;/strong&gt; でも &lt;strong&gt;&lt;a href=&#34;http://www.appveyor.com/&#34;&gt;Appveyor&lt;/a&gt;&lt;/strong&gt; でも &lt;strong&gt;&lt;a href=&#34;https://codeship.com/&#34;&gt;Codeship&lt;/a&gt;&lt;/strong&gt; でも &lt;strong&gt;&lt;a href=&#34;https://drone.io/&#34;&gt;Drone&lt;/a&gt;&lt;/strong&gt; でもなんでもいい。
どれも無料で利用でき、GitHubと連携してコミットのプッシュでビルド/テストをキックできる。
なんなら&lt;a href=&#34;https://aws.amazon.com/jp/&#34;&gt;AWS&lt;/a&gt;や&lt;a href=&#34;https://cloud.google.com/&#34;&gt;GCP&lt;/a&gt;や&lt;a href=&#34;https://www.heroku.com/&#34;&gt;Heroku&lt;/a&gt;なんかへのデプロイまで自動化して&lt;a href=&#34;https://en.wikipedia.org/wiki/Continuous_delivery&#34;&gt;継続的デリバリ-(CD)&lt;/a&gt;を実現することもできる。&lt;/p&gt;

&lt;p&gt;CIを実装したらREADME.mdにバッジを貼るのを忘れずに。
とてもオフィシャル感が出る。&lt;/p&gt;

&lt;p&gt;&lt;img alt=&#34;badges.png&#34; src=&#34;https://www.kaitoy.xyz/images/an-encouragement-of-open-sourcing/badges.png&#34; style=&#34;margin: 0px auto; display: block; width: 50%; min-width: 200px;&#34;&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Pcap4JはLinux(Ubuntu)でのテストをTravis CIで、WindowsでのテストをAppveyorでやっていて、Travis CIでのテスト中に &lt;strong&gt;&lt;a href=&#34;http://cobertura.github.io/cobertura/&#34;&gt;Cobertura&lt;/a&gt;&lt;/strong&gt; でコードカバレージを測って &lt;strong&gt;&lt;a href=&#34;https://coveralls.io/github/kaitoy/pcap4j&#34;&gt;Coveralls&lt;/a&gt;&lt;/strong&gt; にアップし、Appveyorでのビルド結果をMaven Central Repositoryにアップしている。&lt;/p&gt;

&lt;p&gt;今からJavaのコードカバレージを測るなら、Coberturaよりも活発に開発されている &lt;strong&gt;&lt;a href=&#34;http://www.eclemma.org/jacoco/&#34;&gt;Jacoco&lt;/a&gt;&lt;/strong&gt; を使うべき。
コードカバレージの管理も、Coverallsより &lt;strong&gt;&lt;a href=&#34;https://codecov.io/&#34;&gt;Codecov&lt;/a&gt;&lt;/strong&gt; の方が&lt;a href=&#34;https://www.slant.co/versus/7928/7929/~coveralls_vs_codecov&#34;&gt;多機能でサポートもいい&lt;/a&gt;らしい。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E9%9D%99%E7%9A%84%E3%82%B3%E3%83%BC%E3%83%89%E8%A7%A3%E6%9E%90&#34;&gt;静的コード解析&lt;/a&gt;もCIの一部で、絶対やるべきなんだけど、Pcap4Jではまだやってない。
いつの日か。
Javaだと何を使うといいんだろう。&lt;/p&gt;

&lt;h4 id=&#34;コーディング規約を作る&#34;&gt;コーディング規約を作る&lt;/h4&gt;

&lt;p&gt;Pcap4Jではできてないんだけど、インデントをどんな感じにするのかとか、変数の命名規則だとか、コメントの書き方とか、プロジェクトのコードを書く上での作法を定め、コーディング規約として公開しておくべし。
できればフォーマッタとかLinterとかの実行をビルドプロセスに組み込んで、コーディング規約への準拠を自動化しておくのが理想。
コードの書き様が統一されると、可読性が増し、品質の向上につながる。&lt;/p&gt;

&lt;p&gt;また、プルリクエストの対応を心穏やかに効率よくできるようになるのが大きい。
今までPcap4Jに来たプルリクエストの中で、処理方式や実装方式は置いといて、許容できるコーディングスタイルで書かれていたものは2割もなかった。
周りのコードに合わせたスタイルで書いてくれるなんてことは期待すべきではない。
インデントがスペースかタブかというレベルでさえ合わせてくれない。
修正箇所以外の部分にまで自前のフォーマットを適用してくるやつもいた。&lt;/p&gt;

&lt;p&gt;コーディング規約がないと、こういったプルリクエストに対してコーディングスタイルの説明から始めないといけない。
自動化して手順を公開していれば、事前にやってくれることが期待できるし、やってくれなかったらここ見ろと言うだけでいい。&lt;/p&gt;

&lt;p&gt;もっと言えば、コーディング規約を含んだコントリビューション手順書を作って、どこのブランチにプルリクエストを送るのかとか、テストはどうするとかまで定めて公開しておいたほうがいいかも。
やり過ぎるとプルリクエスト来なくなりそうだけど。&lt;/p&gt;

&lt;h2 id=&#34;オープンソースプロジェクトをやっていてよかったこと&#34;&gt;オープンソースプロジェクトをやっていてよかったこと&lt;/h2&gt;

&lt;p&gt;Pcap4Jを5年近く続けたことで、単純に楽しい以上によかったことがあったのでそれについて書く。&lt;/p&gt;

&lt;h4 id=&#34;グローバルな気分になった&#34;&gt;グローバルな気分になった&lt;/h4&gt;

&lt;p&gt;Pcap4Jにスターを付けてくれた人は5大陸31ヶ国にわたり、世界中に向けて公開されている実感がある。
プログラミングに国境はなく、日本も西洋諸国も同じ天地の間にあって、同じ日輪に照らされ、同じ月を眺め、海をともにし、空気をともにしているんだと、なんとなくグローバルな気分になれた。&lt;/p&gt;

&lt;div style=&#34;text-align: center;&#34;&gt;
&lt;iframe width=&#34;480&#34; height=&#34;440&#34; src=&#34;https://statpedia.com/embed/HJUP7kHq&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;br&gt;
(所在不明者のスターはグリーンランドに置いた。)
&lt;/div&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;少子高齢化で日本のマーケットは縮小していく一方だし、景気回復もまだまだ遠そうだし、グローバルに事業を展開しないとジリ貧だ、というのは10年以上前から言われている。
グローバルにやるっていうのはつまり、日本市場を特別視するんじゃなくて、プロダクトやサービスを世界で最適な市場に投入するってことなんだと思う。
日本市場→世界進出じゃなくて、世界展開→日本向けローカライズという順。
ソフトウェアやWebサービスにとって、ここでの世界とは具体的に言えば英語圏で、もっとはっきり言えばアメリカ。
&lt;a href=&#34;https://ja.wikipedia.org/wiki/PlayStation_4&#34;&gt;PS4&lt;/a&gt;はそういうやりかただったし、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Pokemon_GO&#34;&gt;Pokemon GO&lt;/a&gt;は、…ちょっと違うか。&lt;/p&gt;

&lt;p&gt;かつて日本のSNS市場を開拓し席巻した&lt;a href=&#34;https://ja.wikipedia.org/wiki/Mixi&#34;&gt;Mixi&lt;/a&gt;は、世界のSNS市場で天下を取った&lt;a href=&#34;https://ja.wikipedia.org/wiki/Facebook&#34;&gt;Facebook&lt;/a&gt;よりちょっとだけ早くサービスを開始していた。もしMixiが最初からアメリカ向けに公開されていたらどうなっていただろうと、ちょっと残念に思うときがある。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;と、こんなにもグローバルな気分、オープンソースプロジェクト無しにはなれなかったであろう。&lt;/p&gt;

&lt;p&gt;真面目な話、スペインのスタートアップに誘われたり、アメリカの国立研究所から質問が来たり、ドイツのJDの卒論をサポートしたり、ウクライナの教育機関から謝辞をもらったりと、貴重なエキサイティングな体験ができ、自分の世界が広がったのは確か。&lt;/p&gt;

&lt;h4 id=&#34;いろいろなことに取り組むモチベーションが出た&#34;&gt;いろいろなことに取り組むモチベーションが出た&lt;/h4&gt;

&lt;p&gt;Pcap4Jプロジェクトに絡めて、CIとか、&lt;a href=&#34;https://en.wikipedia.org/wiki/List_of_JVM_languages&#34;&gt;JVM言語&lt;/a&gt;とか、&lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt;とか、いろいろなことに取り組むことができた。&lt;/p&gt;

&lt;p&gt;技術とは、ただむずかしき字を知り、解し難きドキュメントを読み、世上に実のなき文学を言うにあらず。
手を動かし、Hello Worldレベルを超えたところにこそ学びがある。
とはいえ、こうした学びの作業は多くのひとにとって楽しくも大変なことなので、続けるにはちょっと工夫して動機付けしてやるのがいい。&lt;/p&gt;

&lt;p&gt;私も基本的に腰が重いタイプだが、Pcap4Jプロジェクトがいい動機付けになった。
特に、プロジェクトの改善として結果が表れ残るものは、学びのやりがいがあり高いモチベーションを保てた。&lt;/p&gt;

&lt;h4 id=&#34;ユーザから色々教えてもらえた&#34;&gt;ユーザから色々教えてもらえた&lt;/h4&gt;

&lt;p&gt;凡人一人ででなんて大したことは学べない。
Pcap4Jのユーザから、要望や指摘やIssuesやプルリクエストを通して、色々なことを教えてもらった。
見つけにくい環境依存のバグ、プロジェクト構造のアドバイス、知らなかったプロトコル、思いもしなかったPcap4Jのユースケース、それを実現するためのAPI。&lt;/p&gt;

&lt;p&gt;ユーザの声を聴き、フィードバックを取り入れていくことで、ソフトウェアは真に有用なものになる。
ついでに知識も知見も知恵も深まる。
これがOSSの醍醐味であろう。&lt;/p&gt;

&lt;p&gt;理想的には、&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873116303/&#34;&gt;Team Geek&lt;/a&gt;にも書かれている通り、未完成の内からソースを公開し、可能な限り早い段階でユーザのフィードバックを受けるべきだ。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;いつも1人でやっていると、失敗のリスクが高くなる。そして、成長の可能性が低くなる。&lt;/p&gt;

&lt;p&gt;(中略)&lt;/p&gt;

&lt;p&gt;つまり、1人で仕事をするほうがリスクが高いということだ。誰かと一緒に仕事をすると、アイデアを盗まれたりバカにされたりしないかと不安になるかもしれないが、間違ったことをして時間をムダにすることを不安に思うべきだ。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;まあ、無名の個人が未完成のソフトを公開してフィードバックをもらえるかという疑問もあるが。&lt;/p&gt;

&lt;h4 id=&#34;小金を得た&#34;&gt;小金を得た&lt;/h4&gt;

&lt;p&gt;プロジェクトに興味を持ってくれる人が増えれば、中にはお金を払ってくれる人も出てくる。
それは寄付であったり、作業の見返りだったりする。&lt;/p&gt;

&lt;p&gt;私はPcap4J開発を通して、ちょっとした幾許かの小金を多少得ることができた。
普通オープンソースプロジェクトは直接的にお金を稼ぐ目的でやるものではないし、私もただ自分の楽しみのためにやっていただけだが、もらえるならもらえるに越したことはない。
ありがたや。&lt;/p&gt;

&lt;p&gt;これを目当てにすべきではないが、たなぼたな展開もあるよということで。&lt;/p&gt;

&lt;h2 id=&#34;終わりに&#34;&gt;終わりに&lt;/h2&gt;

&lt;p&gt;オープンソースプロジェクトに依っては、前節で書いたような開発者自身が得るもののほかに、その活動の成果を享受し、活用してさらなる価値を生み出す多くの他人がいる(かもしれない)ことも忘れてはいけない。&lt;/p&gt;

&lt;p&gt;およそ何人にてもいささか身に技術あればこれによりて世の益をなさんと欲するは人情の常なり。
ソフトウェア技術の発展にわずかでも貢献ができたかもしれないと思えば、開発の励みになるものだ。&lt;/p&gt;

&lt;p&gt;ひとつのオープンソースプロジェクトを生み出すのは、無限の未来を生み出すこと。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;願わくは、この記事に触発されてオープンソースプロジェクトを始める人のあらんことを。&lt;/p&gt;

&lt;div style=&#34;display: none;&#34;&gt;
アジア:
  日本: 15
  中国: 55
  台湾: 1
  韓国: 4
  シンガポール: 2
  マレーシア: 1
  インド: 1
ヨーロッパ:
  ドイツ: 6
  フランス: 2
  イギリス: 7
  オランダ: 3
  スペイン: 2
  スイス: 2
  ベルギー: 2
  ギリシャ: 1
  ポーランド: 3
  エストニア: 1
  スウェーデン: 2
  ウクライナ: 1
  ハンガリー: 1
  モンテネグロ: 1
北米:
  アメリカ: 25
  カナダ: 2
南米:
  ブラジル: 4
  ウルグアイ: 1
  セントルシア: 1
中東:
  アラブ首長国連邦: 1
アフリカ:
  ナイジェリア: 1
  モロッコ: 1
オセアニア:
  オーストラリア: 2
その他:
  ロシア: 7
不明: 42
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GitHub Pagesの新機能、ソース設定が地味にいい</title>
          <link>https://www.kaitoy.xyz/2016/08/18/simpler-github-pages-publishing/</link>
          <pubDate>Thu, 18 Aug 2016 00:26:06 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/08/18/simpler-github-pages-publishing/</guid>
          <description>

&lt;p&gt;今日、&lt;a href=&#34;https://github.com/blog/2228-simpler-github-pages-publishing&#34;&gt;よりシンプルにGitHub Pagesを使えるようになった&lt;/a&gt;というアナウンスがあり、ソース設定という新機能が追加されていたので、さっそく試してみた話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;github-pagesの新機能-ソース設定&#34;&gt;GitHub Pagesの新機能: ソース設定&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://pages.github.com/&#34;&gt;GitHub Pages&lt;/a&gt;には&lt;a href=&#34;https://help.github.com/articles/user-organization-and-project-pages/&#34;&gt;User Pages、Organization Pages、Project Pages&lt;/a&gt;の三種類があるが、ソース設定が使えるのはProject Pages、つまりGitHubリポジトリごとに使えて&lt;code&gt;username.github.io/projectname&lt;/code&gt;のようなURLのやつだけ。&lt;/p&gt;

&lt;p&gt;今まではProject Pagesで公開するサイトのソースは&lt;code&gt;gh-pages&lt;/code&gt;という名のブランチに置く必要があったが、ソース設定により&lt;code&gt;master&lt;/code&gt;ブランチのルートに置いたり&lt;code&gt;master&lt;/code&gt;ブランチの&lt;code&gt;/docs&lt;/code&gt;フォルダに置いたりもできるようになった。&lt;/p&gt;

&lt;h2 id=&#34;ソース設定の使い道&#34;&gt;ソース設定の使い道&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.pcap4j.org/&#34;&gt;Pcap4Jのホームページ&lt;/a&gt;のソースを&lt;code&gt;master&lt;/code&gt;ブランチの&lt;code&gt;/docs&lt;/code&gt;フォルダに置く設定にしたら捗った。&lt;/p&gt;

&lt;p&gt;Pcap4Jのホームページは&lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt;で作っていて、以前は、Hugoのソースを&lt;a href=&#34;https://github.com/kaitoy/pcap4j-hp&#34;&gt;pcap4j-hpリポジトリのmasterブランチ&lt;/a&gt;に置き、&lt;code&gt;gh-pages&lt;/code&gt;ブランチを作ってそこにHugoのビルド成果物(=ホームページのソース)を入れていた。&lt;/p&gt;

&lt;p&gt;ローカルPCでは、&lt;code&gt;master&lt;/code&gt;をcloneして、そこから&lt;code&gt;git worktree&lt;/code&gt;で&lt;code&gt;gh-pages&lt;/code&gt;を別のフォルダにチェックアウトしておいてあり、Hugoのビルドオプションで&lt;code&gt;gh-pages&lt;/code&gt;のフォルダにビルド成果物を出力するようにしていた。
これだと、ホームページを修正したい場合、まず&lt;code&gt;master&lt;/code&gt;でHugoソースを修正して&lt;code&gt;git add/commit/push&lt;/code&gt;、次いでビルドして&lt;code&gt;gh-pages&lt;/code&gt;フォルダに移動して&lt;code&gt;git add/commit/push&lt;/code&gt;、というように、二度手間で面倒だった。&lt;/p&gt;

&lt;p&gt;Hugoのビルド成果物を&lt;code&gt;master&lt;/code&gt;ブランチの&lt;code&gt;/docs&lt;/code&gt;フォルダに置けるようにできれば、&lt;code&gt;git add/commit/push&lt;/code&gt;はビルド後に&lt;code&gt;master&lt;/code&gt;に対して一回だけやれば済むようになる。&lt;/p&gt;

&lt;h2 id=&#34;gh-pagesからmasterブランチの-docsフォルダへの移行&#34;&gt;gh-pagesからmasterブランチの/docsフォルダへの移行&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://help.github.com/articles/configuring-a-publishing-source-for-github-pages/&#34;&gt;GitHubのヘルプ&lt;/a&gt;を参考にしつつ、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;ローカルPCで、&lt;code&gt;master&lt;/code&gt;の作業ディレクトリのルートに&lt;code&gt;docs&lt;/code&gt;というフォルダを作り、&lt;code&gt;gh-pages&lt;/code&gt;のフォルダの中身を全てそこに移動。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;master&lt;/code&gt;の&lt;code&gt;docs&lt;/code&gt;を&lt;code&gt;git add/commit/push&lt;/code&gt;。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;GitHubのpcap4j-hpリポジトリのページに行き、SettingsタブのGitHub PagesセクションのSourceを&lt;code&gt;gh-pages branch&lt;/code&gt;から&lt;code&gt;master branch /docs folder&lt;/code&gt;に変えてSaveボタンをクリック。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/simpler-github-pages-publishing/gh-pages-to-docs.png&#34; alt=&#34;gh-pages-to-docs.png&#34; title=&#34;gh-pages-to-docs.png&#34; /&gt;
&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;実にこれだけ。
カスタムドメインにしていてもこれだけ。簡単。ダウンタイムもなし。&lt;/p&gt;

&lt;p&gt;あとはローカルPCの&lt;code&gt;gh-pages&lt;/code&gt;の作業ディレクトリを削除したり、&lt;code&gt;gh-pages&lt;/code&gt;ブランチを削除したり。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Docker for Windowsがコレジャナかった</title>
          <link>https://www.kaitoy.xyz/2016/07/31/docker-for-windows/</link>
          <pubDate>Sun, 31 Jul 2016 14:34:16 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/07/31/docker-for-windows/</guid>
          <description>

&lt;p&gt;7/28にDocker for Winodws(とDocker for Mac)の正式版リリースの&lt;a href=&#34;https://blog.docker.com/2016/07/docker-for-mac-and-windows-production-ready/&#34;&gt;アナウンス&lt;/a&gt;があったので試してみたけど、期待していたものと違ったしなんだか上手く動かなかった話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;docker-for-windowsとは&#34;&gt;Docker for Windowsとは&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/docker-for-windows/&#34;&gt;Docker for Windows&lt;/a&gt;は&lt;a href=&#34;https://www.docker.com/products/docker-toolbox&#34;&gt;Docker Toolbox&lt;/a&gt;の後継製品。(多分。)&lt;/p&gt;

&lt;p&gt;Docker ToolboxはWindowsやMacでDockerを使うための製品で、以下のコンポーネントからなる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.docker.com/products/docker-engine&#34;&gt;Docker Engine&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;コンテナランタイム。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/compose/&#34;&gt;Docker Compose&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;複数のコンテナを組み合わせたアプリケーション/サービスの構築/管理ツール。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/machine/&#34;&gt;Docker Machine&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Docker仮想ホストのプロビジョニング/管理ツール。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://kitematic.com/&#34;&gt;Kitematic&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Dockerコンテナを管理するGUIを提供する製品。
Docker Machineと連携してローカルマシンへのDocker仮想ホストのプロビジョニングもしてくれる。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Docker Toolboxを使うと、&lt;a href=&#34;https://ja.wikipedia.org/wiki/VirtualBox&#34;&gt;VirtualBox&lt;/a&gt;のLinux VMをWindows/Mac上にプロビジョニングして、そのVMにDockerをインストールして、Windows/Macから利用できる。&lt;/p&gt;

&lt;p&gt;Docker for Windowsもだいたい同じで、Docker EngineとDocker ComposeとDocker MachineをWinodwsで利用するための製品。
&lt;a href=&#34;http://electron.atom.io/&#34;&gt;Electron&lt;/a&gt;ベースでOracleのVirtualBox依存なKitematicの代わりに、ネイティブなインストーラがWindows内蔵の&lt;a href=&#34;https://ja.wikipedia.org/wiki/Hyper-V&#34;&gt;Hyper-V&lt;/a&gt;を使ってDockerをセットアップしてくれる。
Hyper-Vを使うため、VirtualBoxより速くて高信頼らしい。
KitematicはDocker for Windowsには付属しないが、別途ダウンロードすればコンテナ管理に使える。Docker for WindowsとDocker Toolboxとは共存はできない。&lt;/p&gt;

&lt;p&gt;私は勝手にDocker for Windowsは&lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#windows-containersとは&#34;&gt;Hyper-V Containers&lt;/a&gt;のデスクトップOS版のようなものかと勘違いしていて、Windowsのコンテナが使えるようになったのかと期待したが違った。
Docker for Windowsは単にDocker ToolboxのVirtualBoxがHyper-Vになっただけのもので、結局Linux VMの中でDockerを使うだけのものだということにセットアップ中に気付いた。&lt;/p&gt;

&lt;p&gt;(2017/9/12追記: &lt;a href=&#34;https://blogs.msdn.microsoft.com/webdev/2017/09/07/getting-started-with-windows-containers/&#34;&gt;これ&lt;/a&gt;とか&lt;a href=&#34;https://docs.docker.com/docker-for-windows/install/#about-windows-containers-and-windows-server-2016&#34;&gt;これ&lt;/a&gt;とかを見るに、いまではDocker for Winodwsは、Hyper-V ContainersやWindows Server Containersのフロントエンドでもあるようだ。)&lt;/p&gt;

&lt;p&gt;コレジャナイ感がすごかった。&lt;/p&gt;

&lt;p&gt;ともあれ、やった作業を以下に記す。&lt;/p&gt;

&lt;h2 id=&#34;docker-for-windows-on-vmware-player&#34;&gt;Docker for Windows on VMware Player&lt;/h2&gt;

&lt;p&gt;現時点ではDocker for WindowsはホストとしてWindows 10 x64 Pro/Enterprise/Education (Version 1511 Build 10586 以降)しかサポートしていない。
自前のPCが5年前に買った&lt;a href=&#34;https://dynabook.com/&#34;&gt;dynabook&lt;/a&gt;でWindows 10をサポートしていないので、VMware PlayerのVM上のWindows 10にDocker for Windowsをインストールしてみる。&lt;/p&gt;

&lt;h4 id=&#34;vmware-playerのvmでhyper-vを使うための設定&#34;&gt;VMware PlayerのVMでHyper-Vを使うための設定&lt;/h4&gt;

&lt;p&gt;VMware PlayerのVMでは通常Hyper-Vは使えないので、&lt;a href=&#34;http://social.technet.microsoft.com/wiki/contents/articles/22283.how-to-install-hyper-v-on-vmware-workstation-10.aspx&#34;&gt;How to Install Hyper-V on vmware Workstation 10 ?&lt;/a&gt;を参考にしてVMの設定をいじる。
この記事はVMware Workstationについてのものだが、VMware Playerでも全く同じ方法でいける。&lt;/p&gt;

&lt;p&gt;いじるのは、dynabookのWindows 7に入れたVMware Workstation 11.1.0 build-2496824に付属の
VMware Player 7.1.0 build-2496824で作ったWindows 10 Pro x64 (Version 1511 Build 10586.494)のVM。
VMのバージョンは11.0。2CPUでメモリは2GB。ネットワークインターフェースはNAT。&lt;/p&gt;

&lt;p&gt;このVMの.vmxファイルをテキストエディタで開いて以下を追記。意味は不明。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hypervisor.cpuid.v0 = &amp;quot;FALSE&amp;quot;
mce.enable = &amp;quot;TRUE&amp;quot;
vhu.enable = &amp;quot;TRUE&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次いで、VMware PlayerのGUIからVMのCPU設定を開き、&lt;code&gt;Intel VT-x/EPTまたはAMD-V/RVIを仮想化&lt;/code&gt;と&lt;code&gt;CPUパフォーマンスカウンタを仮想化&lt;/code&gt;にチェックを付ける。意味はなんとなくしかわからない。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/docker-for-windows/vm.jpg&#34; alt=&#34;vm.jpg&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これだけ。&lt;/p&gt;

&lt;p&gt;Hyper-VはDocker for Windowsのインストーラが有効化してくれるのでここでは何もしなくていい。&lt;/p&gt;

&lt;h4 id=&#34;docker-for-windowsインストール&#34;&gt;Docker for Windowsインストール&lt;/h4&gt;

&lt;p&gt;VMを起動して、&lt;a href=&#34;https://docs.docker.com/docker-for-windows/&#34;&gt;Getting Started with Docker for Windows&lt;/a&gt;に従ってDocker for Windowsをインストールする。&lt;/p&gt;

&lt;p&gt;まず、&lt;a href=&#34;https://download.docker.com/win/stable/InstallDocker.msi&#34;&gt;上記サイト内のリンク&lt;/a&gt;からインストーラをダウンロード。stableの方。&lt;/p&gt;

&lt;p&gt;ダウンロードした&lt;code&gt;InstallDocker.msi&lt;/code&gt;をVM上で実行してウィザードに従えばインストール完了。
ウィザードの最後で&lt;code&gt;Launch Docker&lt;/code&gt;にチェックが付いた状態で&lt;code&gt;Finish&lt;/code&gt;するとDockerを起動してくれる。
この起動中にHyper-Vを有効化してくれる。(OS再起動有り。)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/docker-for-windows/hyper-v.jpg&#34; alt=&#34;hyper-v.jpg&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;OS再起動後、「Failed to create Switch &amp;ldquo;DockerNAT&amp;rdquo;: Hyper-V was unable to find a virtual switch with name &amp;ldquo;DockerNAT&amp;rdquo;」というエラー出た。&lt;code&gt;DockerNAT&lt;/code&gt;が見つからない?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/docker-for-windows/error.jpg&#34; alt=&#34;error.jpg&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;code&gt;DockerNAT&lt;/code&gt;はDocker for Windowsがインストール中に作るHyper-Vの仮想スイッチ。&lt;/p&gt;

&lt;p&gt;以前に&lt;code&gt;hosts&lt;/code&gt;に変なエントリを書いてしまっていたのでそれを一応消して、VMware PlayerのVMのアダプタの設定もちょっといじってしまっていたので一応もとにもどして、再度Docker for Windowsをクリーンインストールしたら上記エラーは出なくなった。
なんだったんだろう。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Dockerの起動中に今度はメモリ系のエラー: 「Failed to create VM &amp;ldquo;MobyLinuxVM&amp;rdquo;: Failed to modify device &amp;lsquo;Memory&amp;rsquo;」。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/docker-for-windows/error2.jpg&#34; alt=&#34;error2.jpg&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;code&gt;MobyLinuxVM&lt;/code&gt;はDockerを動かすHyper-V VMの名前。このVMに割り当てるメモリはホストOSのメモリ量から決められるようで、これが少なすぎるとダメな模様。&lt;/p&gt;

&lt;p&gt;VMware PlayerのVMのメモリを2Gから3.3Gに増やしたらこのエラーもなくなったけど、今度はIPアドレスのエラー: 「Failed to start VM &amp;ldquo;MobyLinuxVM&amp;rdquo;: The VM couldn&amp;rsquo;t get an IP address after 60 tries」。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/docker-for-windows/error3.jpg&#34; alt=&#34;error3.jpg&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;フォーラムを見たら
&lt;a href=&#34;https://forums.docker.com/t/vm-mobylinuxvm-the-vm-couldnt-get-an-ip-address-after-60-tries/8505/11&#34;&gt;このエラーが載っていた&lt;/a&gt;。そこには以下の様な解決方法が挙がっていた。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Docker for Windowsをクリーンインストールしなおす。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;vEthernet (DockerNAT)&lt;/code&gt;のアダプタのオプションでIPv6を無効にする。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;タスクトレイの鯨アイコンから開けるDockerのSettingsで&lt;code&gt;Reset to factory defaults...&lt;/code&gt;を実行。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/docker-for-windows/docker_settings.jpg&#34; alt=&#34;docker_settings.jpg&#34; /&gt;
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;どれもだめだった。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;MobyLinuxVM&lt;/code&gt;がちゃんと起動しなくて、Dockerデーモンに接続できない。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Windows\System32&amp;gt;docker version
Client:
 Version:      1.12.0
 API version:  1.24
 Go version:   go1.6.3
 Git commit:   8eab29e
 Built:        Thu Jul 28 21:15:28 2016
 OS/Arch:      windows/amd64
An error occurred trying to connect: Get http://%2F%2F.%2Fpipe%2Fdocker_engine/v1.24/version: open //./pipe/docker_engine: The system cannot find the file specified.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因みにちゃんと起動すると以下の感じになるらしい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;PS C:\Users\samstevens&amp;gt; docker version
Client:
Version:      1.12.0-rc2
API version:  1.24
Go version:   go1.6.2
Git commit:   906eacd
Built:        Fri Jun 17 20:35:33 2016
OS/Arch:      windows/amd64
Experimental: true

Server:
Version:      1.12.0-rc2
API version:  1.24
Go version:   go1.6.2
Git commit:   a7119de
Built:        Fri Jun 17 22:09:20 2016
OS/Arch:      linux/amd64
Experimental: true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;もうあきらめる。
どうせWindowsコンテナが使えないならあまり面白くないし。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Windows Server 2016 TP5でWindows Containersにリトライ</title>
          <link>https://www.kaitoy.xyz/2016/07/11/windows_containers_on_tp5/</link>
          <pubDate>Mon, 11 Jul 2016 00:30:33 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/07/11/windows_containers_on_tp5/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.microsoft.com/ja-jp/evalcenter/evaluate-windows-server-technical-preview&#34;&gt;Windows Server 2016のTechnical Preview 5(TP5)が公開されていた&lt;/a&gt;ので、
&lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/&#34;&gt;TP4でバグに阻まれて挫折した&lt;/a&gt;、Windows Containersで&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;Pcap4J&lt;/a&gt;を使ってパケットキャプチャする試みにリトライした話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;osセットアップ&#34;&gt;OSセットアップ&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#windows-containersセットアップ&#34;&gt;TP4のとき&lt;/a&gt;と同じ環境。&lt;/p&gt;

&lt;p&gt;以降は&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/quick_start/quick_start_windows_server&#34;&gt;Windows Server Containersのクイックスタートガイド&lt;/a&gt;に沿ってセットアップを進める。
&lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#windows-containersセットアップ&#34;&gt;TP4&lt;/a&gt;からは大分変わっていて、単一のPowershellスクリプトを実行する形式から、Powershellのコマンドレットを逐次手動実行する形式になっている。
面倒だけど何やってるかわかりやすくて好き。&lt;/p&gt;

&lt;h2 id=&#34;コンテナ機能のインストール&#34;&gt;コンテナ機能のインストール&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;管理者権限のパワーシェルウィンドウを開く&lt;/p&gt;

&lt;p&gt;コマンドプロンプトから以下のコマンドを実行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;powershell start-process powershell -Verb runas
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;コンテナ機能のインストール&lt;/p&gt;

&lt;p&gt;開いた青いパワーシェルウィンドウで以下のコマンドを実行するとコンテナ機能がインストールされる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Install-WindowsFeature containers
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;数分で終わる。&lt;/p&gt;

&lt;p&gt;インストールされたのはHyper-V ContainersじゃなくてWindows Server Containersの方。
クイックスタートガイドをみると、前者がWindows 10向け、後者がWindows Server向けというように住み分けされているっぽい。TP4では両方ともWindows Serverで使えたんだけど。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;再起動&lt;/p&gt;

&lt;p&gt;変更を有効にするために再起動が必要。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Restart-Computer -Force
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;dockerインストール&#34;&gt;Dockerインストール&lt;/h2&gt;

&lt;p&gt;Dockerは、コンテナイメージの管理やコンテナの起動などもろもろの機能を提供するDockerデーモンと、その機能を利用するためのCLIを提供するDockerクライアントからなる。この節ではそれら両方をインストールする。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Dockerインストールフォルダ作成&lt;/p&gt;

&lt;p&gt;管理者権限のパワーシェルウィンドウを開いて、以下のコマンドでDockerインストールフォルダを作成。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;New-Item -Type Directory -Path &#39;C:\Program Files\docker\&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dockerデーモンインストール&lt;/p&gt;

&lt;p&gt;まずはデーモンの方をインストール。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Invoke-WebRequest https://aka.ms/tp5/b/dockerd -OutFile $env:ProgramFiles\docker\dockerd.exe -UseBasicParsing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;数分。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dockerクライアントインストール&lt;/p&gt;

&lt;p&gt;次にクライアント。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Invoke-WebRequest https://aka.ms/tp5/b/docker -OutFile $env:ProgramFiles\docker\docker.exe -UseBasicParsing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;数十秒。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;パスの設定&lt;/p&gt;

&lt;p&gt;さっき作ったDockerインストールフォルダにパスを通す。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;[Environment]::SetEnvironmentVariable(&amp;quot;Path&amp;quot;, $env:Path + &amp;quot;;C:\Program Files\Docker&amp;quot;, [EnvironmentVariableTarget]::Machine)
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dockerデーモンをサービスに登録&lt;/p&gt;

&lt;p&gt;パスの設定を反映するためにいったんパワーシェルウィンドウとコマンドプロンプトを閉じて、
また管理者権限でパワーシェルウィンドウ開いて、以下のコマンドでDockerデーモンをサービスに登録する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;dockerd --register-service
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dockerデーモン起動&lt;/p&gt;

&lt;p&gt;Dockerデーモンは以下のコマンドで起動できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Start-Service docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;数秒で立ち上がる。
デフォルトではOS再起動時にはDockerデーモンは自動起動しないので、そのつどこのコマンドを実行する必要がある。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これでDockerインストール完了。
この時点ではコンテナイメージは何もない。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\Administrator&amp;gt;docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因みにインストールされたDockerのバージョンは1.12開発版。現時点での最新版だ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\Administrator&amp;gt;docker -v
Docker version 1.12.0-dev, build 8e92415
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;コンテナイメージのインストール&#34;&gt;コンテナイメージのインストール&lt;/h2&gt;

&lt;p&gt;次に、コンテナイメージをインストールする。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;コンテナイメージのパッケージプロバイダをインストール&lt;/p&gt;

&lt;p&gt;いまいち何なのかはよくわからないが、
コンテナイメージのパッケージプロバイダというのをインストールする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Install-PackageProvider ContainerImage -Force
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;数十秒。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Windows Server Coreのイメージをインストール&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Install-ContainerImage -Name WindowsServerCore
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;9GB以上もあるファイルをダウンロードして処理するのでかなり時間がかかる。
50分くらいかかった。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dockerデーモン再起動&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Restart-Service docker
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;無事Windows Server Coreイメージがインストールされた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;PS C:\Users\Administrator&amp;gt; docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
windowsservercore   10.0.14300.1000     5bc36a335344        8 weeks ago         9.354 GB
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;pcap4jコンテナイメージのビルド&#34;&gt;Pcap4Jコンテナイメージのビルド&lt;/h2&gt;

&lt;p&gt;以下を&lt;code&gt;C:\Users\Administrator\Desktop\pcap4j\Dockerfile&lt;/code&gt;に書いて、&lt;code&gt;cd C:\Users\Administrator\Desktop\pcap4j&lt;/code&gt;して、&lt;code&gt;docker build -t pcap4j .&lt;/code&gt;を実行。
(Notepad使ったので、拡張子を表示する設定にして&lt;code&gt;Dockerfile&lt;/code&gt;の&lt;code&gt;.txt&lt;/code&gt;を消さないといけない罠があった。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-dockerfile&#34;&gt;#
# Dockerfile for Pcap4J on Windows
#

FROM windowsservercore:10.0.14300.1000
MAINTAINER Kaito Yamada &amp;lt;kaitoy@pcap4j.org&amp;gt;

# Install Chocolatey.
RUN mkdir C:\pcap4j
WORKDIR c:\\pcap4j
ADD https://chocolatey.org/install.ps1 install.ps1
RUN powershell .\install.ps1

# Install dependencies.
RUN choco install -y nmap jdk7 &amp;amp;&amp;amp; \
    choco install -y maven -version 3.2.5

# Build Pcap4J.
RUN powershell -Command Invoke-WebRequest https://github.com/kaitoy/pcap4j/archive/v1.zip -OutFile pcap4j.zip &amp;amp;&amp;amp; \
    powershell -Command Expand-Archive -Path pcap4j.zip -DestinationPath .
WORKDIR pcap4j-1
RUN powershell -Command &amp;quot;mvn -P distribution-assembly install 2&amp;gt;&amp;amp;1 | Add-Content -Path build.log -PassThru&amp;quot;

# Collect libraries.
RUN mkdir bin &amp;amp;&amp;amp; \
    cd pcap4j-packetfactory-static &amp;amp;&amp;amp; \
    mvn -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeScope=compile dependency:copy-dependencies &amp;amp;&amp;amp; \
    mvn -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeGroupIds=ch.qos.logback dependency:copy-dependencies &amp;amp;&amp;amp; \
    cd ../pcap4j-distribution &amp;amp;&amp;amp; \
    mvn -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeArtifactIds=pcap4j-packetfactory-static,pcap4j-sample dependency:copy-dependencies

# Generate sample script. (C:\pcap4j\pcap4j-1\bin\capture.bat)
RUN echo @echo off &amp;gt; bin\capture.bat &amp;amp;&amp;amp; \
    echo &amp;quot;%JAVA_HOME%\bin\java&amp;quot; -cp C:\pcap4j\pcap4j-1\bin\pcap4j-core.jar;C:\pcap4j\pcap4j-1\bin\pcap4j-packetfactory-static.jar;C:\pcap4j\pcap4j-1\bin\pcap4j-sample.jar;C:\pcap4j\pcap4j-1\bin\jna.jar;C:\pcap4j\pcap4j-1\bin\slf4j-api.jar;C:\pcap4j\pcap4j-1\bin\logback-classic.jar;C:\pcap4j\pcap4j-1\bin\logback-core.jar org.pcap4j.sample.GetNextPacketEx &amp;gt;&amp;gt; bin\capture.bat
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Dockerfileに書いた処理内容は&lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#pcap4j-on-windows-container&#34;&gt;TP4のとき&lt;/a&gt;とだいたい同じ。
以下、Dockerfile書いているときに気付いたこと。&lt;/p&gt;

&lt;h4 id=&#34;tp4からのアップデート&#34;&gt;TP4からのアップデート&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;WORKDIR や ENV や COPY でパスの区切りは \ 一つだと消えちゃうので \ か / を使わないといけない。
&lt;div style=&#34;font-size: 0.5em; text-align: right;&#34;&gt;&lt;cite&gt;引用元: &lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#pcap4j-on-windows-container&#34;&gt;TP4のときのエントリ&lt;/a&gt;&lt;/cite&gt;&lt;/div&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/docker/manage_windows_dockerfile&#34;&gt;このページ&lt;/a&gt;の各コマンドの&lt;strong&gt;Windows Considerations&lt;/strong&gt;に、&lt;code&gt;WORKDIR&lt;/code&gt;のパスの区切りのバックスラッシュはエスケープしないといけないとか、&lt;code&gt;ADD&lt;/code&gt;のパスの区切りはスラッシュじゃないといけないとか書いてある。
TP4のときはなかったような。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;WORKDIR や COPY のコンテナ内のパスに絶対パスを指定したい場合、C:\hoge、C:/hoge、C:\hoge、いずれもダメ。 以下の様なエラーが出る。
&lt;div style=&#34;font-size: 0.5em; text-align: right;&#34;&gt;&lt;cite&gt;引用元: &lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#pcap4j-on-windows-container&#34;&gt;TP4のときのエントリ&lt;/a&gt;&lt;/cite&gt;&lt;/div&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;これは直った。&lt;code&gt;WORKDIR c:\\pcap4j&lt;/code&gt;で行ける。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;install.ps1の中でChocolateyのインストーラをHTTPSで取ってこようとしてエラー
&lt;div style=&#34;font-size: 0.5em; text-align: right;&#34;&gt;&lt;cite&gt;引用元: &lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#pcap4j-on-windows-container&#34;&gt;TP4のときのエントリ&lt;/a&gt;&lt;/cite&gt;&lt;/div&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;普通に&lt;code&gt;choco install&lt;/code&gt;できたので、HTTPSが使えない制限は消えた模様。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;ビルドしてみると、各ステップの実行(多分レイヤの作成)がすごく遅い。
&lt;div style=&#34;font-size: 0.5em; text-align: right;&#34;&gt;&lt;cite&gt;引用元: &lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#pcap4j-on-windows-container&#34;&gt;TP4のときのエントリ&lt;/a&gt;&lt;/cite&gt;&lt;/div&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;各ステップの実行は相変わらず重い。特にファイル変更が多いときはすごく重い。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;コンテナの起動は非常に遅い。30秒以上かかる。
&lt;div style=&#34;font-size: 0.5em; text-align: right;&#34;&gt;&lt;cite&gt;引用元: &lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#windows-server-containers味見&#34;&gt;TP4のときのエントリ&lt;/a&gt;&lt;/cite&gt;&lt;/div&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;コンテナ起動は早くなったけどまだ5秒くらいかかる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;WORKDIR や ENV で環境変数が展開されない。
&lt;div style=&#34;font-size: 0.5em; text-align: right;&#34;&gt;&lt;cite&gt;引用元: &lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#pcap4j-on-windows-container&#34;&gt;TP4のときのエントリ&lt;/a&gt;&lt;/cite&gt;&lt;/div&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;これはまだ直っていない。&lt;code&gt;%tmp%&lt;/code&gt;、&lt;code&gt;%TMP%&lt;/code&gt;、&lt;code&gt;$TMP&lt;/code&gt;、&lt;code&gt;${TMP}&lt;/code&gt;、どれもだめ。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;コンテナ内で C:\ 直下に . で始まる名前のフォルダ作ると次のステップで消えてる。
&lt;div style=&#34;font-size: 0.5em; text-align: right;&#34;&gt;&lt;cite&gt;引用元: &lt;a href=&#34;https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/#pcap4j-on-windows-container&#34;&gt;TP4のときのエントリ&lt;/a&gt;&lt;/cite&gt;&lt;/div&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;これは再現しなかった。以前のも勘違いだったのかもしれない。
なんにせよデフォルトの.m2フォルダのパスが&lt;code&gt;C:\Users\ContainerAdministrator\.m2&lt;/code&gt;になったので気にしなくてよくなった。&lt;/p&gt;

&lt;h4 id=&#34;ビルドエラー-hcsshim-importlayer-failed-in-win32-the-filename-or-extension-is-too-long-0xce&#34;&gt;ビルドエラー: hcsshim::ImportLayer failed in Win32: The filename or extension is too long. (0xce)&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;choco install&lt;/code&gt;の後で以下のエラーが出た。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;re-exec error: exit status 1: output: time=&amp;quot;2016-07-09T19:57:22-07:00&amp;quot; level=error msg=&amp;quot;hcsshim::ImportLayer failed in Win32: The filename or extension is too long. (0xce) layerId=\\\\?\\C:\\ProgramData\\docker\\windowsfilter\\103de6bf1358c506510ad67990f09ec3e2f10f9e866e846df5a88c04f5edf7aa flavour=1 folder=C:\\Windows\\TEMP\\hcs719016711&amp;quot;
hcsshim::ImportLayer failed in Win32: The filename or extension is too long. (0xce) layerId=\\?\C:\ProgramData\docker\windowsfilter\103de6bf1358c506510ad67990f09ec3e2f10f9e866e846df5a88c04f5edf7aa flavour=1 folder=C:\Windows\TEMP\hcs719016711
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;調べたら&lt;a href=&#34;https://github.com/docker/docker/issues/22449&#34;&gt;DockerのGitHub Issues&lt;/a&gt;に登録されていた。
ここのコメントを参考に以下のコマンドでコンテナホストのアップデートをしたら発生しなくなった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Invoke-WebRequest https://aka.ms/tp5/Update-Container-Host -OutFile update-containerhost.ps1
.\update-containerhost.ps1
Restart-Computer -Force
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;git-cloneできない&#34;&gt;git cloneできない&lt;/h4&gt;

&lt;p&gt;Pcap4Jのソースをダウンロードしたかったんだけど、なぜか&lt;code&gt;git clone&lt;/code&gt;がHTTPSでもGITプロトコルでもエラーを返す。
原因を調べるのが面倒で結局zipでダウンロードするようにした。&lt;/p&gt;

&lt;h4 id=&#34;未実装の機能&#34;&gt;未実装の機能&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/&#34;&gt;Dockerfileのリファレンス&lt;/a&gt;に載っていて、Windows向けのサンプルも書いてあるのに、&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#/escape&#34;&gt;escapeディレクティブ&lt;/a&gt;と&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#/shell&#34;&gt;SHELLコマンド&lt;/a&gt;
が使えなかった。&lt;/p&gt;

&lt;h2 id=&#34;コンテナ起動&#34;&gt;コンテナ起動&lt;/h2&gt;

&lt;p&gt;とりあえず上記DockerfileでPcap4Jコンテナイメージのビルドはできた。&lt;/p&gt;

&lt;p&gt;以下のコマンドでそのイメージからコンテナを起動。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\Administrator&amp;gt;docker run -it pcap4j cmd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コンテナ内で&lt;code&gt;ipconfig&lt;/code&gt;すると&lt;code&gt;vEthernet (Temp Nic Name)&lt;/code&gt;という名のネットワークインターフェースがあることがわかる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\pcap4j\pcap4j-1\bin&amp;gt;ipconfig

Windows IP Configuration


Ethernet adapter vEthernet (Temp Nic Name):

   Connection-specific DNS Suffix  . : localdomain
   Link-local IPv6 Address . . . . . : fe80::59cf:1491:6f8e:30c8%18
   IPv4 Address. . . . . . . . . . . : 172.23.71.6
   Subnet Mask . . . . . . . . . . . : 255.240.0.0
   Default Gateway . . . . . . . . . : 172.16.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;けどPcap4Jからは見えなかった。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\pcap4j\pcap4j-1\bin&amp;gt;capture.bat
org.pcap4j.sample.GetNextPacketEx.count: 5
org.pcap4j.sample.GetNextPacketEx.readTimeout: 10
org.pcap4j.sample.GetNextPacketEx.snaplen: 65536


18:49:00.582 [main] INFO  org.pcap4j.core.Pcaps - No NIF was found.
java.io.IOException: No NIF to capture.
        at org.pcap4j.sample.GetNextPacketEx.main(GetNextPacketEx.java:45)java:44)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;コンテナには&lt;code&gt;ContainerAdministrator&lt;/code&gt;というユーザでログインしていて、これの権限が弱いせいなんじゃないかと。
コンテナ内にも&lt;code&gt;Administrator&lt;/code&gt;というユーザがあるようだったので、こっちでコマンド実行するよう奮闘した。&lt;/p&gt;

&lt;h2 id=&#34;コンテナ内でadministratorでコマンド実行したい&#34;&gt;コンテナ内でAdministratorでコマンド実行したい&lt;/h2&gt;

&lt;h4 id=&#34;userコマンド&#34;&gt;USERコマンド&lt;/h4&gt;

&lt;p&gt;Dockerfileのコマンドに&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#/user&#34;&gt;USER&lt;/a&gt;というのがあるので、&lt;code&gt;USER Administrator&lt;/code&gt;をDockerfileの末尾に追加してみたら以下のエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;The daemon on this platform does not support the command &#39;user&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;userオプション&#34;&gt;&amp;ndash;userオプション&lt;/h4&gt;

&lt;p&gt;docker runコマンドに&lt;a href=&#34;https://docs.docker.com/compose/reference/run/&#34;&gt;&amp;ndash;user&lt;/a&gt;というオプションがあるので以下のように試してみたところ、オプションは無視されて&lt;code&gt;ContainerAdministrator&lt;/code&gt;でコンテナに入った。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;docker run -it --user Administrator pcap4j cmd
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;runas&#34;&gt;runas&lt;/h4&gt;

&lt;p&gt;ちょっと発想の転換をして、&lt;code&gt;ContainerAdministrator&lt;/code&gt;でコンテナに入った後sudoみたいなことをすればいいかと思い、&lt;a href=&#34;https://technet.microsoft.com/en-us/library/bb490994.aspx&#34;&gt;runas&lt;/a&gt;コマンドを試したけどだめだった。
よく分からないエラーがでるし、そもそも&lt;code&gt;Administrator&lt;/code&gt;のパスワードがわからない。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\pcap4j\pcap4j-1\bin&amp;gt;runas /user:Administrator cmd
Enter the password for Administrator:
Attempting to start cmd as user &amp;quot;92EC7B3B09B4\Administrator&amp;quot; ...
RUNAS ERROR: Unable to run - cmd
1326: The user name or password is incorrect.
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\pcap4j\pcap4j-1\bin&amp;gt;runas /user:&amp;quot;User Manager\Administrator&amp;quot; capture.bat
Enter the password for User Manager\Administrator:
RUNAS ERROR: Unable to acquire user password
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;enter-pssession&#34;&gt;Enter-PSSession&lt;/h4&gt;

&lt;p&gt;フォーラムに行ったら&lt;a href=&#34;https://social.msdn.microsoft.com/Forums/en-US/0b6bd405-a235-4608-a06b-a09b9ba08b2e/runas-administrator?forum=windowscontainers&#34;&gt;Enter-PSSession&lt;/a&gt;を使う方法が書いてあった。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://technet.microsoft.com/en-us/library/hh849707.aspx&#34;&gt;Enter-PSSession&lt;/a&gt;はリモートシステムに接続するコマンドレットで、&lt;code&gt;-ContainerName&lt;/code&gt;オプションを使えばコンテナにも接続できる。&lt;/p&gt;

&lt;p&gt;試したら、コンテナが見つからないというエラーが出た。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\Administrator&amp;gt;powershell -command Enter-PSSession -ContainerName amazing_archimedes -RunAsAdministrator
Enter-PSSession : The input ContainerName amazing_archimedes does not exist, or the corresponding container is not running.
At line:1 char:1
+ Enter-PSSession -ContainerName amazing_archimedes -RunAsAdministrator
+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : InvalidOperation: (:) [Enter-PSSession], PSInvalidOperationException
    + FullyQualifiedErrorId : CreateRemoteRunspaceForContainerFailed,Microsoft.PowerShell.Commands.EnterPSSessionCommand
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://technet.microsoft.com/en-us/library/hh849719.aspx&#34;&gt;Invoke-Command&lt;/a&gt;もコンテナをターゲットにできるので試してみたけど、同様のエラー。&lt;/p&gt;

&lt;p&gt;どうもパワーシェルで扱うコンテナやコンテナイメージが、dockerコマンドが扱うものとは別になっているせいっぽい。
そんなことがTP4のときに見たドキュメントに書いてあったのを思い出した。(このドキュメントは消えてた。)&lt;/p&gt;

&lt;p&gt;実際、&lt;code&gt;docker ps&lt;/code&gt;では見えているコンテナが、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\Administrator&amp;gt;docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
a711497f29d8        pcap4j              &amp;quot;cmd&amp;quot;               13 minutes ago      Up 12 minutes                           amazing_archimedes
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コマンドレットからだと見えない。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\Administrator&amp;gt;powershell -command Get-Container
WARNING: Based on customer feedback, we are updating the Containers PowerShell module to better align with Docker. As part of that some cmdlet and parameter names may change in future releases. To learn more about these changes as well as to join in the design process or provide usage feedback please refer to http://aka.ms/windowscontainers/powershell
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そうなると、パワーシェルのコマンドレットには&lt;code&gt;docker build&lt;/code&gt;にあたるものがないのでもうどうしようもない。&lt;/p&gt;

&lt;p&gt;そもそも、TP4の頃のコマンドレットは&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/management/docker-powershell&#34;&gt;廃止になって&lt;/a&gt;、&lt;a href=&#34;https://github.com/Microsoft/Docker-PowerShell/&#34;&gt;新しいコマンドレット&lt;/a&gt;を開発中らしい。やはりdockerコマンドとコマンドレットでコンテナの相互運用ができない仕様にユーザから相当つっこみがあったようだ。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Enter-PSSession&lt;/code&gt;や&lt;code&gt;Invoke-Command&lt;/code&gt;の&lt;code&gt;-ContainerName&lt;/code&gt;オプションもその内修正されるであろう。
それまで待つか。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CloudflareでブログをHTTPS化</title>
          <link>https://www.kaitoy.xyz/2016/07/01/https-support-by-cloudflare/</link>
          <pubDate>Fri, 01 Jul 2016 14:17:41 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/07/01/https-support-by-cloudflare/</guid>
          <description>

&lt;p&gt;最近&lt;a href=&#34;https://pages.github.com/&#34;&gt;GitHub Pages&lt;/a&gt;がHTTPSに正式対応したというニュースを見たことをきっかけに、このブログを&lt;a href=&#34;https://www.cloudflare.com/&#34;&gt;Cloudflare&lt;/a&gt;で常時HTTPS化した話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;このブログ&#34;&gt;このブログ&lt;/h2&gt;

&lt;p&gt;このブログは&lt;a href=&#34;https://www.kaitoy.xyz/2015/08/15/github-pages-and-jekyll/&#34;&gt;GitHub Pagesでホストされている&lt;/a&gt;。
GitHub Pages上のWebサイトはデフォルトでは&lt;code&gt;&amp;lt;GitHubユーザ名&amp;gt;.github.io&lt;/code&gt;というドメインで公開されるが、ちょっとかっこつけたかったのでカスタムドメイン(&lt;code&gt;www.kaitoy.xyz&lt;/code&gt;)にした。&lt;/p&gt;

&lt;p&gt;GitHub Pagesは2014年3月から非公式にHTTPSをサポートしていて、2016年6月8日に&lt;a href=&#34;https://github.com/blog/2186-https-for-github-pages&#34;&gt;正式サポートを表明&lt;/a&gt;したが、これは&lt;code&gt;&amp;lt;GitHubユーザ名&amp;gt;.github.io&lt;/code&gt;ドメインだけが対象であり、カスタムドメインはHTTPSサポートされていない。&lt;/p&gt;

&lt;p&gt;(2018/5/3追記: 2018/5/1にGitHub PagesのカスタムドメインのHTTPSサポートが&lt;a href=&#34;https://blog.github.com/2018-05-01-github-pages-custom-domains-https/&#34;&gt;発表された&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;要するにこのブログにはHTTP接続しかできない状態だった。
これをなんとかHTTPSに対応させたかった。&lt;/p&gt;

&lt;h2 id=&#34;なぜhttps&#34;&gt;なぜHTTPS&lt;/h2&gt;

&lt;p&gt;HTTPS化(常時SSL化)が世界的な流行りな雰囲気を感じていたのと、なにより、&lt;a href=&#34;http://googlewebmastercentral-ja.blogspot.com/2015/12/indexing-https-pages-by-default.html&#34;&gt;Googleに優遇してもらえるから&lt;/a&gt;。
Googleの検索結果の2,3ページ目までに出てこないなら、そのサイトはこの世に存在しないのとあまり変わらない。&lt;/p&gt;

&lt;p&gt;昔はHTTPSにするとSSLプロトコルのオーバーヘッドや暗号化/復号化処理によりHTTPに比べて遅くなると言われていたが、最近ではサーバ/クライアントマシンの性能が上がり、このデメリットは気にするほどのものではなくなった。
逆に、常時SSL化すると&lt;a href=&#34;https://ja.wikipedia.org/wiki/SPDY&#34;&gt;SPDY&lt;/a&gt;や&lt;a href=&#34;https://ja.wikipedia.org/wiki/HTTP/2&#34;&gt;HTTP/2&lt;/a&gt;といった高速なプロトコルの恩恵を受けることができるようになり、HTTPより速くなることもあるらしい。&lt;/p&gt;

&lt;h2 id=&#34;カスタムドメインなgithub-pagesサイトをhttps対応する方法&#34;&gt;カスタムドメインなGitHub PagesサイトをHTTPS対応する方法&lt;/h2&gt;

&lt;p&gt;上記の通りこのブログはカスタムドメインでGitHub Pagesのサポートがなく直接にはHTTPS対応できない。
よって間接的に対応することになるので、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%AA%E3%83%90%E3%83%BC%E3%82%B9%E3%83%97%E3%83%AD%E3%82%AD%E3%82%B7&#34;&gt;リバースプロキシ&lt;/a&gt;を使うことになる。
リバースプロキシサーバを自分で運用するのは大変なので、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%B3%E3%83%B3%E3%83%86%E3%83%B3%E3%83%84%E3%83%87%E3%83%AA%E3%83%90%E3%83%AA%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF&#34;&gt;CDN&lt;/a&gt;サービスを利用する。&lt;/p&gt;

&lt;p&gt;CDNサービスでまず思い当たったのはAWSの&lt;a href=&#34;https://aws.amazon.com/jp/cloudfront/&#34;&gt;CloudFront&lt;/a&gt;だけど、なんだか大げさで面倒そう。
あとは&lt;a href=&#34;https://www.cloudflare.com/&#34;&gt;Cloudflare&lt;/a&gt;が有名なので調べたところ、手軽で無料でよさそうだったのでこれにした。&lt;/p&gt;

&lt;p&gt;因みに、ごく最近始まったサービスの&lt;a href=&#34;https://www.kloudsec.com/&#34;&gt;Kloudsec&lt;/a&gt;というのも見つけたけど、まだベータが付いているし、遅いだのそもそもつながらないだの評判が悪かったのでこれは無し。&lt;/p&gt;

&lt;p&gt;Cloudflareを利用すると、もともとだいたいこんな感じ↓だったのが、&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/direct/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/direct/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/direct/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/direct/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/direct/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/direct/スライド6.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/direct/スライド7.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/direct/スライド8.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/direct/スライド9.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;こんな感じ↓になる。多分。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド6.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド7.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド8.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド9.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド10.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/cdn/スライド11.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上のスライド中のリバースプロキシは実際にはいくつもあり、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%A8%E3%83%8B%E3%83%BC%E3%82%AD%E3%83%A3%E3%82%B9%E3%83%88&#34;&gt;エニーキャスト&lt;/a&gt;によってブラウザから一番近いものが使われる。&lt;/p&gt;

&lt;h2 id=&#34;cloudflare事始め&#34;&gt;Cloudflare事始め&lt;/h2&gt;

&lt;p&gt;Cloudflareの始め方は&lt;a href=&#34;http://qiita.com/superbrothers/items/95e5723e9bd320094537&#34;&gt;Qiitaの記事&lt;/a&gt;を参考にした。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Cloudflareのアカウント作成&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cloudflare.com/&#34;&gt;Cloudflareのサイト&lt;/a&gt;に行って&lt;code&gt;Sign up&lt;/code&gt;のリンクからメアドとパスワードを渡してアカウントを作成。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Cloudflareにサイトを登録&lt;/p&gt;

&lt;p&gt;アカウント作成後に開くページに従い、4つのステップをこなすとサービス利用開始できる。&lt;/p&gt;

&lt;p&gt;まずはサイトの登録。
サブドメインを除いた&lt;code&gt;kaitoy.xyz&lt;/code&gt;を入力して&lt;code&gt;Begin Scan&lt;/code&gt;をクリック。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/add_domain.png&#34; alt=&#34;add_domain.png&#34; title=&#34;add_domain.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;何かのスキャンが始まるので1分ほど待つ。何をしているのかはよくわからない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;CloudflareのDNSの設定&lt;/p&gt;

&lt;p&gt;次のステップでCloudflareのDNSにレコードを登録する。
ブラウザからのトラフィックの誘導には&lt;code&gt;A&lt;/code&gt;か&lt;code&gt;AAAA&lt;/code&gt;か&lt;code&gt;CNAME&lt;/code&gt;を登録できる。
トラフィックは&lt;code&gt;kaitoy.github.io&lt;/code&gt;に送りたいけど、IPアドレスは自分でコントロールできないので&lt;code&gt;A&lt;/code&gt;と&lt;code&gt;AAAA&lt;/code&gt;は使えない。
&lt;code&gt;CNAME&lt;/code&gt;を登録した。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/dns.png&#34; alt=&#34;dns.png&#34; title=&#34;dns.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;適当に入力して&lt;code&gt;Add Record&lt;/code&gt;を押すとレコードを登録できるが、&lt;code&gt;Status&lt;/code&gt;のところがデフォルトで&lt;code&gt;DNS only&lt;/code&gt;(灰色のクラウドのアイコン)になっているので、アイコンをクリックして&lt;code&gt;DNS and HTTP proxy (CDN)&lt;/code&gt;(オレンジ色のクラウドのアイコン)にしておく。
こうしないとブラウザからのトラフィックがCloudflareを経由せず、HTTPS化できないはず。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プランの選択&lt;/p&gt;

&lt;p&gt;サービスプランは無料の&lt;code&gt;Free Website&lt;/code&gt;を選択。常時SSL化するだけならこれで十分なはず。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/select_plan.png&#34; alt=&#34;select_plan.png&#34; title=&#34;select_plan.png&#34; /&gt;
&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;レジストラのネームサーバの変更&lt;/p&gt;

&lt;p&gt;最後にレジストラのサイトに行ってネームサーバを変更するように指示される。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/change_your_ns.png&#34; alt=&#34;change_your_ns.png&#34; title=&#34;change_your_ns.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;Cloudflareからは二つのネームサーバが割り当てられたようだ。
指示されたとおりに変更する。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;cloudflareの設定&#34;&gt;Cloudflareの設定&lt;/h2&gt;

&lt;p&gt;サインアップが終わるとCloudflareのダッシュボードが開く。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/dashboard.png&#34; alt=&#34;dashboard.png&#34; title=&#34;dashboard.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ダッシュボードの&lt;code&gt;Overview&lt;/code&gt;の&lt;code&gt;Statusは&lt;/code&gt;最初は&lt;code&gt;Pending&lt;/code&gt;になっていて、これはネームサーバの変更を反映中ということらしかった。
ネームサーバの変更は数時間くらいかかったが、変更中も&lt;code&gt;http://www.kaitoy.xyz/&lt;/code&gt;にはアクセスできた。&lt;/p&gt;

&lt;p&gt;ダッシュボードからやった設定は以下。
これも&lt;a href=&#34;http://qiita.com/superbrothers/items/95e5723e9bd320094537&#34;&gt;Qiitaの記事&lt;/a&gt;を参考にした。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;SSL&lt;/p&gt;

&lt;p&gt;ダッシュボードの&lt;code&gt;Crypto&lt;/code&gt;の&lt;code&gt;SSL&lt;/code&gt;の設定はデフォルトで&lt;code&gt;Full (strict)&lt;/code&gt;になっている。
これはブラウザ-Cloudflare間とCloudflare-GitHub Pages間両方をSSL化する設定。
上で書いたようにGitHub Pagesの方はSSL対応できずこの設定は使えないので、&lt;code&gt;Flexible&lt;/code&gt;に変更。
こちらはブラウザ-Cloudflare間だけをSSL化する。&lt;/p&gt;

&lt;p&gt;この設定変更をして、SSL証明書が発行されるまで数時間待ったら&lt;code&gt;https://www.kaitoy.xyz/&lt;/code&gt;にアクセスできるようになった。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;HSTS&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/HTTP_Strict_Transport_Security&#34;&gt;HSTS&lt;/a&gt;はHTTPでアクセスしてきたブラウザにHTTPSでアクセスするよう指示する仕組み。
これを有効にしてよりセキュアにする。
ダッシュボードの&lt;code&gt;Crypto&lt;/code&gt;の&lt;code&gt;HTTP Strict Transport Security (HSTS)&lt;/code&gt;から以下の様に設定した。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/hsts.png&#34; alt=&#34;hsts.png&#34; title=&#34;hsts.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kaitoy.xyz&lt;/code&gt;だけじゃなくて&lt;code&gt;www.kaitoy.xyz&lt;/code&gt;で有効にするため、&lt;code&gt;Include subdomains&lt;/code&gt;を&lt;code&gt;On&lt;/code&gt;にしておくのが肝要のはず。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;HTTPSへのリダイレクト&lt;/p&gt;

&lt;p&gt;HTTPでのアクセスをHTTPSにリダイレクトする設定を加える。
ダッシュボードの&lt;code&gt;Page Rules&lt;/code&gt;で以下のルールを作った。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/https-support-by-cloudflare/page_rules.png&#34; alt=&#34;page_rules.png&#34; title=&#34;page_rules.png&#34; /&gt;
&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;ブログサイトの修正&#34;&gt;ブログサイトの修正&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;link&lt;/code&gt;タグや&lt;code&gt;script&lt;/code&gt;タグの&lt;code&gt;www.kaitoy.xyz&lt;/code&gt;を指しているURLをHTTPSに修正。
内部リンクも全部HTTPSにした。これで完了。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ソフトウェアプロジェクトの7つの大罪</title>
          <link>https://www.kaitoy.xyz/2016/06/25/seven-deadly-sins-of-a-software-project/</link>
          <pubDate>Sat, 25 Jun 2016 18:00:29 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/06/25/seven-deadly-sins-of-a-software-project/</guid>
          <description>

&lt;p&gt;このエントリでは、Yegor Bugayenkoによる記事、&lt;a href=&#34;http://www.yegor256.com/2015/06/08/deadly-sins-software-project.html&#34;&gt;Seven Deadly Sins of a Software Project&lt;/a&gt;を紹介する。
(Yegorから和訳と転載の許可は得た。)
以下はその全文の和訳だが、意訳超訳が混じっているので、もとのニュアンスを知りたければ元記事を読んでもいいし、読まなくてもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;保守性は近代ソフトウェア開発において&lt;a href=&#34;http://www.yegor256.com/2014/10/26/hacker-vs-programmer-mentality.html&#34;&gt;最も重要な美徳だ&lt;/a&gt;。
&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E4%BF%9D%E5%AE%88%E6%80%A7&#34;&gt;保守性&lt;/a&gt;は基本的に、新規開発者が本格的な修正を始める前に必要な学習時間で測ることができる。
学習時間が長いほど保守性は低い。
必要な学習時間が無限に近いプロジェクトもあるが、これは文字通り保守不能だ。
私はソフトウェアを保守不能にする7つの基本的で致命的な罪があると考えている。
それらについてここに書く。&lt;/p&gt;

&lt;h2 id=&#34;アンチパターン&#34;&gt;アンチパターン&lt;/h2&gt;

&lt;p&gt;&lt;img alt=&#34;ap.gif&#34; src=&#34;https://www.kaitoy.xyz/images/seven-deadly-sins-of-a-software-project/ap.gif&#34; width=&#34;300&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;不幸にも、我々が使っているプログラミング言語は柔軟すぎる。
可能なことが多過ぎ、禁止されていることは少なすぎる。
例えばJavaは、数千のメソッドを持った単一の「クラス」でアプリケーション全体を記述することに何の反抗もしない。
このアプリケーションは技術的にはコンパイルして実行できる。
しかしこれは&lt;a href=&#34;https://maku77.github.io/program/god-class.html&#34;&gt;ゴッドオブジェクト&lt;/a&gt;と呼ばれるよく知られたアンチパターンだ。&lt;/p&gt;

&lt;p&gt;つまり、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%B3%E3%83%81%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3&#34;&gt;アンチパターン&lt;/a&gt;は技術的には設計に取り入れることができるが、一般的には取り入れるべきではないとされている。
言語ごとに多くのアンチパターンがある。
プロダクトに使われているアンチパターンは、生きている有機体の中の腫瘍のようなものだ。
いったん成長し始めると止めるのは非常に難しい。
やがて体全体が死に至る。
やがてソフトウェア全体が保守不能になり、書き直さなければならなくなる。&lt;/p&gt;

&lt;p&gt;ひとたびアンチパターンを使ってしまうと、その量は次第に増え、「腫瘍」は育つばかりだ。&lt;/p&gt;

&lt;p&gt;これは特にオブジェクト指向言語(Java、C++、Ruby、Python)に当てはまる。
これらが手続き型言語(C、Fortran、COBOL)から多くを引き継いでしまっているからだ。
また、OOP開発者が手続き型で命令的な思考をする傾向にあるからだ。残念なことに。&lt;/p&gt;

&lt;p&gt;ところで、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%B3%E3%83%81%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3&#34;&gt;既存の有名なアンチパターン&lt;/a&gt;のほかに、私は以下のものもダメなコーディング法だと考えている。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/07/26/why-null-is-bad/&#34;&gt;NULL参照&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2016/01/03/oop-alternative-to-utility-classes/&#34;&gt;ユーティリティクラス&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.yegor256.com/2014/06/09/objects-should-be-immutable.html&#34;&gt;可変オブジェクト&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/07/22/getters-setters-evil/&#34;&gt;GetterとSetter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/09/13/orm-is-offensive-anti-pattern/&#34;&gt;オブジェクト関係マッピング(ORM)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;シングルトン&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.yegor256.com/2015/03/09/objects-end-with-er.html&#34;&gt;Controllers、Managers、Validators&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.yegor256.com/2015/02/20/utility-classes-vs-functional-programming.html&#34;&gt;Public Static メソッド&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.yegor256.com/2015/04/02/class-casting-is-anti-pattern.html&#34;&gt;キャスト&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;私ができる実践的な提案は、読んで学ぶということだけだ。
&lt;a href=&#34;http://www.yegor256.com/2015/04/22/favorite-software-books.html&#34;&gt;ここ&lt;/a&gt;に挙げた本か私の著書「&lt;a href=&#34;http://www.yegor256.com/elegant-objects.html&#34;&gt;&amp;ldquo;Elegant Objects&lt;/a&gt;」が多分助けになるだろう。
常にソフトウェアの品質を疑い、「動く」ということだけで満足してはいけない。
ちょうど癌のように、診断が早ければ早いほど生き残る可能性が大きい。&lt;/p&gt;

&lt;h2 id=&#34;追跡不能な変更&#34;&gt;追跡不能な変更&lt;/h2&gt;

&lt;p&gt;&lt;img alt=&#34;uc.gif&#34; src=&#34;https://www.kaitoy.xyz/images/seven-deadly-sins-of-a-software-project/uc.gif&#34; width=&#34;300&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;コミット履歴を見るとき、全ての個々の変更に対して、何を、誰が、なぜ変更したのかがわからないといけない。
さらに、これら3つの情報を得るのにかかる時間は秒単位で計測しないといけない。
殆どのプロジェクトがこのようにできていない。
以下に実践的な提案を示す。&lt;/p&gt;

&lt;h4 id=&#34;常にチケットを使う&#34;&gt;常にチケットを使う&lt;/h4&gt;

&lt;p&gt;プロジェクトやチームがどんなに小さくても、例え一人だけでも、修正しようとしている全ての問題に対してチケット(GitHub issues)を作れ。
チケットに問題の簡単な説明とそれに対する考えを記述しろ。
このチケットをその問題に関する全ての情報の一時的なストレージとして使え。
将来、他の誰かがその「不可解なコミット」が何であるかを理解するために参照する可能性のある全ての情報をそこに書け。&lt;/p&gt;

&lt;h4 id=&#34;コミットからチケットを参照する&#34;&gt;コミットからチケットを参照する&lt;/h4&gt;

&lt;p&gt;言うまでもないが、全てのコミットにはメッセージが付いていないといけない。
メッセージのないコミットはまったくひどい悪習だ。議論の余地はない。
しかしメッセージだけでは不十分だ。
全てのメッセージはチケット番号で始まらないといけない。
GitHub(君ももちろん使っていると思うが)は自動でコミットとチケットをリンクし、変更の追跡可能性を高めてくれる。&lt;/p&gt;

&lt;h4 id=&#34;何も消さない&#34;&gt;何も消さない&lt;/h4&gt;

&lt;p&gt;Gitは「強制」push、つまりサーバに既にあるブランチ全体を上書きするpushを許している。
これは開発履歴を破壊する方法の例のひとつだ。
また、GitHubのチケットを「きれい」にするためにコメントを削除するのをよく見るが、これはまったくの間違いだ。
何であれ決して消すな。
履歴がどんなに汚く(または乱雑に)見えても、そのまま残しておくことだ。&lt;/p&gt;

&lt;h2 id=&#34;アドホックリリース&#34;&gt;アドホックリリース&lt;/h2&gt;

&lt;p&gt;&lt;img alt=&#34;ahr.gif&#34; src=&#34;https://www.kaitoy.xyz/images/seven-deadly-sins-of-a-software-project/ahr.gif&#34; width=&#34;300&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;全てのソフトウェアはエンドユーザに届けられる前にパッケージングされなければいけない。
Javaのライブラリであれば&lt;code&gt;.jar&lt;/code&gt;ファイルにパッケージングされリポジトリにリリースされないといけない。
ウェブアプリケーションであればプラットフォームにデプロイされないといけない。
プロダクトの大きさにかかわらず、テスト、パッケージング、デプロイする正規の手順は常にあるべきだ。&lt;/p&gt;

&lt;p&gt;理想的な解決策はこの手順を自動化し、コマンドラインから単一のコマンドで実行できるようにすることだ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ ./release.sh
...
DONE (took 98.7s)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ほとんどのプロジェクトはこれに程遠い。
そのリリースプロセスにはマジックが含まれていて、担当者(DevOpともいう)はあちらこちらのボタンをクリックしないといけない。
どこかにログインして、いくつかの指標をチェックして、など。
このようなアドホックリリース手順は、ソフトウェアエンジニアリング業界全体でいまだに典型的な罪である。&lt;/p&gt;

&lt;p&gt;ここで私ができる実践的なアドバイスはひとつだけだ。自動化しろ。
私は自動化に&lt;a href=&#34;http://www.yegor256.com/2014/09/11/deployment-script-vs-rultor.html&#34;&gt;rultor.com&lt;/a&gt;を使っているが、好きなのを使えばよい。
重要なのは、手順全体が完全自動化されていてコマンドラインから実行できることだ。&lt;/p&gt;

&lt;h2 id=&#34;自発的静的解析&#34;&gt;自発的静的解析&lt;/h2&gt;

&lt;p&gt;&lt;img alt=&#34;vsa.gif&#34; src=&#34;https://www.kaitoy.xyz/images/seven-deadly-sins-of-a-software-project/vsa.gif&#34; width=&#34;300&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E9%9D%99%E7%9A%84%E3%82%B3%E3%83%BC%E3%83%89%E8%A7%A3%E6%9E%90&#34;&gt;静的解析&lt;/a&gt;はコードの見た目を良くしてくれる。
見た目がよくなると、必然的に上手く動くようになる。
しかしこれは、チームの全員が静的解析ツールに指示されたルールに従うことを強制(!)されているときだけ有効だ。
私はこれについて&lt;a href=&#34;http://www.yegor256.com/2014/08/13/strict-code-quality-control.html&#34;&gt;Strict Control of Java Code Quality&lt;/a&gt;に書いた。
私はJavaプロジェクトでは&lt;a href=&#34;http://www.qulice.com/&#34;&gt;qulice.com&lt;/a&gt;を使い、Rubyでは&lt;a href=&#34;https://github.com/bbatsov/rubocop&#34;&gt;rubocop&lt;/a&gt;を使うが、他にも似たようなツールがほとんど全ての言語にある。&lt;/p&gt;

&lt;p&gt;どんなツールを使ってもいいが、強制しなければいけない!
静的解析ツールを使っているほとんどのプロジェクトで、開発者は単に見栄えのいいレポートを生成するだけで、コードの書き方を直そうとはしない。
そのような「自発的な」アプローチはプロジェクトにとって何のメリットもない。そればかりか、品質への錯覚を生む。&lt;/p&gt;

&lt;p&gt;私が言いたいのは、静的解析は開発パイプラインの中の必須ステップでなければいけないということだ。
もし静的解析ルールがひとつでも破られたら、ビルドを成功にしてはいけない。&lt;/p&gt;

&lt;h2 id=&#34;未知のテストカバレージ&#34;&gt;未知のテストカバレージ&lt;/h2&gt;

&lt;p&gt;&lt;img alt=&#34;utc.gif&#34; src=&#34;https://www.kaitoy.xyz/images/seven-deadly-sins-of-a-software-project/utc.gif&#34; width=&#34;300&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;簡単に言うと、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%B3%E3%83%BC%E3%83%89%E7%B6%B2%E7%BE%85%E7%8E%87&#34;&gt;テストカバレージ&lt;/a&gt;はソフトウェアがユニットテストや統合テストでテストされた度合いだ。
カバレージが高いほど、テスト中に実行されたコードの量が多い。
カバレージ高いのは明らかに良いことだ。&lt;/p&gt;

&lt;p&gt;しかし、多くのプロジェクトで開発者は単にカバレージを知らない。
この指標を計測しないのだ。
テストは書いているかもしれないが、それがソフトウェアのどの程度深くまで行き渡っているか、どの部分がテストされていないのか、誰も全く知らない。
このような状態よりは、カバレージが低くても、計測されて皆にレポートされている状態の方がかなり良い。、&lt;/p&gt;

&lt;p&gt;高いカバレージは高い品質を保証するものではない。
これは明らかだ。
しかし、テストカバレージが未知であることは保守性に問題があるという明確な印だ。
プロジェクトに入った新規開発者は、修正がどの程度カバレージに影響を与えるかを確認できなければいけない。
理想的には、テストカバレージは静的解析でチェックされ、事前に決められた閾値(普通80%位)を下回ったらビルドが失敗するようになっているべきだ。&lt;/p&gt;

&lt;h2 id=&#34;ノンストップ開発&#34;&gt;ノンストップ開発&lt;/h2&gt;

&lt;p&gt;&lt;img alt=&#34;nd.gif&#34; src=&#34;https://www.kaitoy.xyz/images/seven-deadly-sins-of-a-software-project/nd.gif&#34; width=&#34;300&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;ここでノンストップが意味するのは、マイルストーンもリリースも無いということだ。
書いているソフトウェアの種類によらず、頻繁に&lt;a href=&#34;http://semver.org/lang/ja/&#34;&gt;バージョニング&lt;/a&gt;とリリースをしないといけない。
明確なリリース履歴が無いプロジェクトは保守不能なガラクタだ。&lt;/p&gt;

&lt;p&gt;これは概ね、保守性とは私が君のコードを読んで君を理解できるかということだからだ。&lt;/p&gt;

&lt;p&gt;私がソースとそのコミットとリリース履歴を見るとき、開発者の意図が何で、プロジェクトが一年前に何をしていて、今どこに向かっているのか、ロードマップは何か、といったことを説明できなければいけない。
こうした情報の全ては、ソースコード中とGit履歴(こちらがより重要)に入っていなければいけない。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://git-scm.com/book/en/v2/Git-Basics-Tagging&#34;&gt;Gitタグ&lt;/a&gt;と&lt;a href=&#34;https://github.com/blog/1547-release-your-software&#34;&gt;GitHubリリース&lt;/a&gt;はそうした情報を残すための強力な道具だ。
これらをめいっぱい使え。
また、それぞれのバージョンのバイナリは直接ダウンロードできるようにしておくことを忘れるな。
プロジェクトが今バージョン3.4を開発していたとしても、即座にバージョン0.1.3をダウンロードしてテストできなければいけない。&lt;/p&gt;

&lt;h2 id=&#34;ドキュメントに載っていないインターフェース&#34;&gt;ドキュメントに載っていないインターフェース&lt;/h2&gt;

&lt;p&gt;&lt;img alt=&#34;ui.gif&#34; src=&#34;https://www.kaitoy.xyz/images/seven-deadly-sins-of-a-software-project/ui.gif&#34; width=&#34;300&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;全てのソフトウェアは、その機能を使うためのインターフェースを持っている。
RubyのGemであれば、エンドユーザが利用できるクラスとメソッドがある。
Webアプリケーションであれば、エンドユーザが参照して操作できるWebページがある。
全てのソフトウェアプロジェクトはインターフェースを持ち、そのインターフェースは入念にドキュメント化されていないといけない。&lt;/p&gt;

&lt;p&gt;これまでに挙げた全ての項目のように、これも保守性に関することだ。
プロジェクトの新規プログラマは、ソフトウェアをインターフェースから学び始める。
そのソフトウェアが何をするものなのかを理解して自分で使ってみる、ということができなければいけない。&lt;/p&gt;

&lt;p&gt;私はここでユーザに対するドキュメンテーションの話をしている。開発者に対するものではない。
一般的に、ソフトウェア内部のドキュメンテーションには反対だ。
私は&lt;a href=&#34;http://agilemanifesto.org/iso/ja/&#34;&gt;アジャイルソフトウェア開発宣言&lt;/a&gt;に完全に同意している。
動くソフトウェアは包括的なドキュメントよりもはるかに重要だ。
しかしそれは、(開発者ではなく)ユーザが読むための「外部」ドキュメントのことを指しているわけではない。&lt;/p&gt;

&lt;p&gt;要は、エンドユーザとソフトウェアとの間の相互作用はドキュメントに明記されていなければいけない。&lt;/p&gt;

&lt;p&gt;ライブラリであれば、エンドユーザはそれを使うソフトウェア開発者だ。
コントリビュータではなく、それを「ブラックボックス」として単に使うだけの開発者だ。&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;embed video-player&#34; style=&#34;text-align: center&#34;&gt;
  &lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;320&#34; height=&#34;193&#34; src=&#34;https://www.youtube.com/embed/ZtWmlKi3ivc&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上がYegorの記事。&lt;/p&gt;

&lt;p&gt;一般的に認知されているベストプラクティスやアジャイル感に沿った、Yegorにしては丸い内容だ。
むしろ、現在は既にアジャイルは完全に浸透して、その次のステップとしてDevOpsをめざす時代になっているので、開発サイドだけに言及したこの内容だと少々保守的で古臭く感じさえする。&lt;/p&gt;

&lt;p&gt;ただ、改めてだけど、「&lt;a href=&#34;http://localhost:1313/2016/06/25/seven-deadly-sins-of-a-software-project/#%E8%BF%BD%E8%B7%A1%E4%B8%8D%E8%83%BD%E3%81%AA%E5%A4%89%E6%9B%B4&#34;&gt;追跡不能な変更&lt;/a&gt;」に書いてあることはいいプラクティスだと思う。
GitHubで開発するときは、全てのコミットがIssuesかPull Requestsに紐付いていて、相互に導出可能であると便利そう。
面倒だからやったことないけど。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;「&lt;a href=&#34;http://localhost:1313/2016/06/25/seven-deadly-sins-of-a-software-project/#%E3%83%89%E3%82%AD%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%88%E3%81%AB%E8%BC%89%E3%81%A3%E3%81%A6%E3%81%84%E3%81%AA%E3%81%84%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%BC%E3%83%95%E3%82%A7%E3%83%BC%E3%82%B9&#34;&gt;ドキュメントに載っていないインターフェース&lt;/a&gt;」に書いてあることはちょっと引っかかる。
アメリカ人ってのは、分厚い細かいドキュメントなんか書いても誰も読まねーよ、ってのが基本のスタンスだと思っていた。
Steve Jobsだったら、ドキュメントが必要なくなるまでUIを洗練させろとか言いそうだ。
もしくはユースケースベースのざっくりとしたマニュアルをメインにしたり。&lt;/p&gt;

&lt;p&gt;全てのインターフェースを入念にドキュメントしろっていうのはなんだかとても日本的だ。
そうしてくれた方が使う方は助かるんだけど、作る側はドキュメントの保守が大変だ。かなり頑張って気を使っても、ドキュメントと実装のずれってのは本当に簡単に頻繁に起こる。特に大きい会社の大きいプロジェクトで、開発チームとは別にマニュアルチームがあるような場合、このずれはほとんど全く避けられない。&lt;/p&gt;

&lt;p&gt;自然言語でのプログラミングへの希望が大昔からあるようだけど、そんなものより、プログラミング言語で書いたものから自然言語のマニュアルを生成してくれるもののほうがよっぽど価値があると思う。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Pcap4J in Kotlin</title>
          <link>https://www.kaitoy.xyz/2016/04/16/pcap4j-in-kotlin/</link>
          <pubDate>Sat, 16 Apr 2016 11:09:53 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/04/16/pcap4j-in-kotlin/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2016/04/10/pcap4j-in-groovy/&#34;&gt;Groovy&lt;/a&gt;に続いて、&lt;a href=&#34;https://kotlinlang.org/&#34;&gt;&lt;strong&gt;Kotlin&lt;/strong&gt;&lt;/a&gt;で&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;&lt;strong&gt;Pcap4J&lt;/strong&gt;&lt;/a&gt;を使ってパケットキャプチャしてみた。&lt;/p&gt;

&lt;p&gt;KotlinからでもPcap4Jちゃんと動くよということを実証するのが主な目的。
また、今後JavaなアプリはKotlinで書こうかと思っているので、その予習も兼ねている。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;kotlinとは&#34;&gt;Kotlinとは&lt;/h2&gt;

&lt;p&gt;KotlinはJVM言語、つまりJavaのバイトコードにコンパイルされてJavaの実行環境で動くプログラミング言語のひとつ。
&lt;a href=&#34;https://www.jetbrains.com/idea/&#34;&gt;IntelliJ IDEA&lt;/a&gt;で有名な&lt;a href=&#34;https://www.jetbrains.com/&#34;&gt;JetBrains社&lt;/a&gt;によって&lt;a href=&#34;https://github.com/JetBrains/kotlin&#34;&gt;OSS&lt;/a&gt;として開発されている。&lt;/p&gt;

&lt;p&gt;2011年に生まれた新しめな言語で、2016/2/17に&lt;a href=&#34;http://blog.jetbrains.com/jp/2016/02/17/578&#34;&gt;v1がリリースされ&lt;/a&gt;、主にAndroidアプリの開発用として注目されている。&lt;/p&gt;

&lt;p&gt;「実用的」であることを売りにしていて、つまり少ない学習コストで導入でき、既存のJavaコードやMavenなどのツールとの相互運用性を持つとされている。
IntelliJ IDEA、&lt;a href=&#34;http://developer.android.com/sdk/index.html&#34;&gt;Android Studio&lt;/a&gt;、&lt;a href=&#34;https://eclipse.org/&#34;&gt;Eclipse&lt;/a&gt;といった主要なIDEのサポートもあり、開発環境は整っている。
v1以降の後方互換性の維持も表明されていて、長期サポートが必要な製品開発にも堪える。&lt;/p&gt;

&lt;p&gt;さらに、厳格な静的型付けやNullable/Non-Null型などにより安全性を確保しつつ、型推論やラムダ式などで生産性を高めている。&lt;/p&gt;

&lt;p&gt;Javaのバイトコードだけでなく、JavaScriptを生成するバックエンドを持っているのも大きな特徴。
ユースケースがよく分からないが。&lt;/p&gt;

&lt;p&gt;GitHubにホストされているKotlinプロジェクトは、2016/4/15現在、全体の &lt;strong&gt;0.1%&lt;/strong&gt; (&lt;sup&gt;3493&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3215549&lt;/sub&gt;) しかない。
v1のリリースは結構注目を集めたので、この割合は今後増えていくと期待される。&lt;/p&gt;

&lt;h2 id=&#34;kotlinのインストール&#34;&gt;Kotlinのインストール&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://kotlinlang.org/docs/tutorials/&#34;&gt;チュートリアル&lt;/a&gt;に従えば、IDEやテキストエディタ+コマンドラインの環境を整えてHello Worldを書いて実行するところまで簡単にできる。
筆者はEclipse(Mars)とコマンドラインの環境をWindows 7上で作った。
Kotlinのバージョンは1.0.1-2。&lt;/p&gt;

&lt;p&gt;コマンドラインについては、&lt;a href=&#34;https://github.com/JetBrains/kotlin/releases/latest&#34;&gt;GitHub Releases&lt;/a&gt;からアーカイブをダウンロードして、適当なところに展開して&lt;code&gt;bin&lt;/code&gt;フォルダにパスを通すだけ。
前提となるJavaについては、環境変数&lt;code&gt;JAVA_HOME&lt;/code&gt;を設定するか、&lt;code&gt;java&lt;/code&gt;コマンドにパスを通せばいい模様。&lt;/p&gt;

&lt;p&gt;因みにKotlinの書き方は、&lt;a href=&#34;https://kotlinlang.org/docs/tutorials/koans.html&#34;&gt;Kotlin Koans&lt;/a&gt;という例題集を&lt;a href=&#34;http://try.kotlinlang.org/koans&#34;&gt;オンラインのIDE&lt;/a&gt;で解きながらを学ぶことができる。&lt;/p&gt;

&lt;h2 id=&#34;パケットキャプチャ-with-pcap4j-in-java&#34;&gt;パケットキャプチャ with Pcap4J in Java&lt;/h2&gt;

&lt;p&gt;Pcap4Jでパケットキャプチャするコードを普通にJavaで書くと以下の様になる。
(&lt;a href=&#34;https://www.kaitoy.xyz/2016/04/10/pcap4j-in-groovy/&#34;&gt;Groovy&lt;/a&gt;の時のと一緒。)&lt;/p&gt;

&lt;p&gt;&lt;script src=&#34;https://gist.github.com/kaitoy/eebcd5bdfab179cab916d3182f3d6d11.js&#34;&gt;&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;これを実行すると、パケットキャプチャするネットワークインターフェースを選択し、5つのパケットをキャプチャしてタイムスタンプと共にコンソールに表示する。&lt;/p&gt;

&lt;h2 id=&#34;パケットキャプチャ-with-pcap4j-in-kotlin&#34;&gt;パケットキャプチャ with Pcap4J in Kotlin&lt;/h2&gt;

&lt;p&gt;上記処理をKotlinで書くと以下の様になる。&lt;/p&gt;

&lt;p&gt;&lt;script src=&#34;https://gist.github.com/kaitoy/074769880c7bf4c0628c1c25a724c1a7.js&#34;&gt;&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;メインクラスはGroovy同様書かなくていいが、&lt;code&gt;main&lt;/code&gt;関数は必要。&lt;/p&gt;

&lt;p&gt;型推論があってとても楽。
ラムダ式、補間文字列(String interpolation)、名前付き引数といったモダンめな機能は普通に使える。
(名前付き引数はJavaで書いたメソッドをKotlinから呼ぶときは使えない。)&lt;/p&gt;

&lt;p&gt;オープンクラスを実現する機能である&lt;a href=&#34;https://kotlinlang.org/docs/reference/extensions.html&#34;&gt;Extensions&lt;/a&gt;を&lt;code&gt;PcapHandle&lt;/code&gt;に使ってみた。
なんだか便利そう。&lt;/p&gt;

&lt;p&gt;Nullable/Non-Null型がすごい。言語仕様で&lt;code&gt;NullPointerException&lt;/code&gt;が発生しないように守ってくれる。
例えば&lt;code&gt;filter&lt;/code&gt;は宣言の時点では初期化文で&lt;code&gt;null&lt;/code&gt;が入る可能性があるので&lt;code&gt;Nullable&lt;/code&gt;な&lt;code&gt;String&lt;/code&gt;という型に推論されるが、&lt;code&gt;filter?.let&lt;/code&gt;というNullチェックをするメソッドに渡したブロック内では自動で&lt;code&gt;Non-Null&lt;/code&gt;な&lt;code&gt;String&lt;/code&gt;にキャストされ、&lt;code&gt;filter.length&lt;/code&gt;を安全に評価できるようになっている。
Nullチェックをしないで&lt;code&gt;filter.length&lt;/code&gt;と書くとコンパイルエラーになる。すごい。&lt;/p&gt;

&lt;p&gt;けどJavaのコードから返ってくるオブジェクトは普通、プラットフォーム型というものになり、このNullセーフな仕組みが働かない。
これに対しては&lt;a href=&#34;https://kotlinlang.org/docs/reference/java-interop.html#nullability-annotations&#34;&gt;Null可能性アノテーション&lt;/a&gt;を使えば幸せになれるらしい。&lt;/p&gt;

&lt;p&gt;さらに、上記コードには表れていないが、キャストも安全になっている模様。(cf. &lt;a href=&#34;http://kotlinlang.org/docs/reference/typecasts.html#smart-casts&#34;&gt;スマートキャスト&lt;/a&gt;、&lt;a href=&#34;http://kotlinlang.org/docs/reference/typecasts.html#safe-nullable-cast-operator&#34;&gt;セーフキャスト&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Kotlinは基本コンパイラ言語なので、上記コードを実行するには以下ようなコマンドで一旦コンパイルする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;kotlinc -cp pcap4j-core.jar Pcap4jLoop.kt -include-runtime -d Pcap4jLoop.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このコマンドだとKotlinのランタイム入りjarファイルができる。
このjarを、Pcap4J 1.6.2、Slf4J 1.7.12、JNA 4.2.1を使って、以下のコマンドで実行できることを確認した。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;java -cp pcap4j-core.jar;pcap4j-packetfactory-static.jar;jna.jar;slf4j-api.jar;Pcap4jLoop.jar Pcap4jLoopKt tcp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このコマンドで指定しているメインクラス&lt;code&gt;Pcap4jLoopKt&lt;/code&gt;は、上記コードでクラスの記述を省いた為にKotlinがソースファイル名(Pcap4jLoop.kt)を基に自動生成したもの。&lt;/p&gt;

&lt;p&gt;コンパイル/実行方法は&lt;a href=&#34;https://kotlinlang.org/docs/tutorials/command-line.html#creating-and-running-a-first-application&#34;&gt;他にもある&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;スクリプトなkotlin&#34;&gt;スクリプトなKotlin&lt;/h2&gt;

&lt;p&gt;Kotlinプログラムはスクリプトとしても書けて、コンパイル無しで実行することができる。
この場合、&lt;code&gt;main&lt;/code&gt;関数は消してその中身をトップレベルに書き、ファイルの拡張子を&lt;code&gt;.kts&lt;/code&gt;にする。&lt;/p&gt;

&lt;p&gt;&lt;script src=&#34;https://gist.github.com/kaitoy/b6ee844ad2353585a30984ef0bedf844.js&#34;&gt;&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;上記スクリプトは以下のコマンドで実行できた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;kotlinc -cp pcap4j-core.jar;jna.jar;pcap4j-packetfactory-static.jar;slf4j-api.jar -script Pcap4jLoop.kts tcp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;EclipseのKotlinプラグインはこのスクリプト形式をまだサポートしていないようで残念。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Pcap4J in Groovy</title>
          <link>https://www.kaitoy.xyz/2016/04/10/pcap4j-in-groovy/</link>
          <pubDate>Sun, 10 Apr 2016 00:05:27 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/04/10/pcap4j-in-groovy/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://www.groovy-lang.org/index.html&#34;&gt;&lt;strong&gt;Groovy&lt;/strong&gt;&lt;/a&gt;で&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;&lt;strong&gt;Pcap4J&lt;/strong&gt;&lt;/a&gt;を使ってパケットキャプチャしてみた。&lt;/p&gt;

&lt;p&gt;GroovyからでもPcap4Jちゃんと動くよということを実証するのが主な目的。
また、さすがにそろそろ&lt;a href=&#34;https://maven.apache.org/&#34;&gt;Maven&lt;/a&gt;を卒業してGradle(下記)使おうと思うので、予習も兼ねている。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;groovyとは&#34;&gt;Groovyとは&lt;/h2&gt;

&lt;p&gt;GroovyはJVM言語、つまりJavaのバイトコードにコンパイルされてJavaの実行環境で動くプログラミング言語のひとつ。
Javaのプログラマにとってとっつきやすい文法を保ちつつ、動的型付けを実現し、また&lt;a href=&#34;https://www.ruby-lang.org/ja/&#34;&gt;Ruby&lt;/a&gt;などのスクリプト言語の記法や機能を取り入れ、生産性を高めている。&lt;/p&gt;

&lt;p&gt;現在は&lt;a href=&#34;http://www.apache.org/&#34;&gt;Apacheソフトウェア財団&lt;/a&gt;によって管理され、&lt;a href=&#34;https://github.com/apache/groovy&#34;&gt;OSS&lt;/a&gt;として開発が進められている。&lt;/p&gt;

&lt;p&gt;Webアプリケーションフレームワークの&lt;a href=&#34;https://grails.org/&#34;&gt;&lt;strong&gt;Grails&lt;/strong&gt;&lt;/a&gt; やビルドツールの&lt;a href=&#34;http://gradle.org/&#34;&gt;&lt;strong&gt;Gradle&lt;/strong&gt;&lt;/a&gt;で採用されている。
Gradleは最近Javaプロジェクトのビルドツールの主流になっていて、Groovyはその定義ファイルを記述する言語として知名度が高いが、Groovyで開発されているプロジェクトとなるとあまり多くないようだ。
GitHubにホストされているGroovyプロジェクトは、2016/4/9現在 &lt;strong&gt;0.8%弱&lt;/strong&gt; (25,087/3,200,229) しかない。&lt;/p&gt;

&lt;p&gt;なぜ人気がないのかはよく分からないが、少なくとも、長くて打ちにくい名前とダサいロゴは不評のようだ。&lt;/p&gt;

&lt;h2 id=&#34;groovyのインストール&#34;&gt;Groovyのインストール&lt;/h2&gt;

&lt;p&gt;Windows 7にGroovy 2.4.6をインストールする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.groovy-lang.org/install.html&#34;&gt;本家サイトの手順&lt;/a&gt;に従い、Binary Releaseのアーカイブをダウンロードして、適当なところに展開して、展開したフォルダのパスを環境変数&lt;code&gt;GROOVY_HOME&lt;/code&gt;にセットし、&lt;code&gt;%GROOVY_HOME%\bin&lt;/code&gt;を&lt;code&gt;PATH&lt;/code&gt;に追加するだけ。&lt;/p&gt;

&lt;p&gt;Java 6以降が前提なので、&lt;code&gt;JAVA_HOME&lt;/code&gt;にJDK 1.7.0_17のパスをセットしておいた。JREでもいいはず。&lt;/p&gt;

&lt;h2 id=&#34;パケットキャプチャ-with-pcap4j-in-java&#34;&gt;パケットキャプチャ with Pcap4J in Java&lt;/h2&gt;

&lt;p&gt;Pcap4Jでパケットキャプチャするコードを普通にJavaで書くと以下の様になる。&lt;/p&gt;

&lt;p&gt;&lt;script src=&#34;https://gist.github.com/kaitoy/eebcd5bdfab179cab916d3182f3d6d11.js&#34;&gt;&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;これを実行すると、パケットキャプチャするネットワークインターフェースを選択し、5つのパケットをキャプチャしてタイムスタンプと共にコンソールに表示する。&lt;/p&gt;

&lt;h2 id=&#34;パケットキャプチャ-with-pcap4j-in-groovy&#34;&gt;パケットキャプチャ with Pcap4J in Groovy&lt;/h2&gt;

&lt;p&gt;上記処理をGroovyで書くと以下の様になる。&lt;/p&gt;

&lt;p&gt;&lt;script src=&#34;https://gist.github.com/kaitoy/c75837d3537303b004506d3e335eac17.js&#34;&gt;&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;メインクラスを書かなくていいところが大きい。
変数の型を書かなくていいのも楽。
ラムダ式でクロージャも作れるし補間文字列(String interpolation)も使える。&lt;/p&gt;

&lt;p&gt;また、ここでは使っていないが、オープンクラスなどのメタプログラミングもサポートされている。&lt;/p&gt;

&lt;p&gt;上記コードは、Pcap4J 1.6.2、Slf4J 1.7.12、JNA 4.2.1を使って、以下のコマンドで実行できることを確認した。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;groovy -cp &amp;quot;pcap4j-core.jar;jna.jar;slf4j-api.jar;pcap4j-packetfactory-static.jar&amp;quot; Pcap4jLoop.groovy tcp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これはスクリプト的な実行方法だが、&lt;code&gt;groovyc&lt;/code&gt;コマンドで事前にコンパイルしてclassファイルを生成し、&lt;code&gt;java&lt;/code&gt;コマンドで実行することもできる。&lt;/p&gt;

&lt;h3 id=&#34;困ったところ&#34;&gt;困ったところ&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;本家サイトのドキュメントが分かり辛い。&lt;/p&gt;

&lt;p&gt;頭から読んでいくと急にディープな部分に引き込まれ、なかなかコードを書き始められなかった。&lt;/p&gt;

&lt;p&gt;最近の言語やフレームワークのサイトはチュートリアルに従って動くコードを見ながら概要から詳細に理解を深められる形になっていることが多いので、仕様の詳細が羅列されている感じのGroovyサイトはなんとも読みにくかった。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;クラスパスの指定が上手くできない。&lt;/p&gt;

&lt;p&gt;groovyコマンドにオプションで複数のクラスパスを指定するのに、普通に&lt;code&gt;-cp pcap4j-core.jar;jna.jar&lt;/code&gt;みたいにしたら最初の&lt;code&gt;pcap4j-core.jar&lt;/code&gt;にしかクラスパスが通らなかった。
区切りを&lt;code&gt;:&lt;/code&gt;にするとどちらにも通らない。&lt;/p&gt;

&lt;p&gt;環境変数&lt;code&gt;CLASSPATH&lt;/code&gt;に&lt;code&gt;pcap4j-core.jar;jna.jar&lt;/code&gt;をセットしておくと&lt;code&gt;-cp&lt;/code&gt;を使わなくても正しく両方に通るし、&lt;code&gt;%userprofile%\.groovy\&lt;/code&gt;にjarを入れておくだけでもいいみたいなんだけど、&lt;code&gt;-cp&lt;/code&gt;が中途半端にしか機能しないのが気持ち悪い。&lt;/p&gt;

&lt;p&gt;のでちょっとソースを見たら、groovyコマンドはバッチで書かれていることに気付いた。
バッチだと、&lt;code&gt;;&lt;/code&gt;で区切られているものは半角スペースで区切られているのと同じで別々の引数になってしまうので、上のような書き方だと&lt;code&gt;jna.jar&lt;/code&gt;は&lt;code&gt;-cp&lt;/code&gt;の値として処理されない。
クラスパス全体をダブルコーテーションで囲って、&lt;code&gt;-cp &amp;quot;pcap4j-core.jar;jna.jar&amp;quot;&lt;/code&gt;みたいにしたらできた。なんか残念な出来。。。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
      
    
      
        <item>
          <title> ズンドコキヨシ with Pcap4J - ZUNDOKOプロトコルを実装してみた</title>
          <link>https://www.kaitoy.xyz/2016/03/19/zundoko-kiyoshi-with-pcap4j/</link>
          <pubDate>Sat, 19 Mar 2016 11:47:03 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/03/19/zundoko-kiyoshi-with-pcap4j/</guid>
          <description>

&lt;p&gt;先週くらいから巷でズンドコズンドコ騒いでいると思ってはいたが、昨日ようやくその元ネタを見た。
以下のツイートだ。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;Javaの講義、試験が「自作関数を作り記述しなさい」って問題だったから&lt;br&gt;「ズン」「ドコ」のいずれかをランダムで出力し続けて「ズン」「ズン」「ズン」「ズン」「ドコ」の配列が出たら「キ・ヨ・シ！」って出力した後終了って関数作ったら満点で単位貰ってた&lt;/p&gt;&amp;mdash; てくも (@kumiromilk) &lt;a href=&#34;https://twitter.com/kumiromilk/status/707437861881180160&#34;&gt;2016年3月9日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;面白い。
巷ではこれを&lt;a href=&#34;http://qiita.com/shunsugai@github/items/971a15461de29563bf90&#34;&gt;いろんな言語で実装したりしているみたい&lt;/a&gt;でさらに面白い。&lt;/p&gt;

&lt;p&gt;私もこのビッグウェーブに乗らないわけにいかないので、専門分野であるネットワーク周りを開拓しようと思い、ZUNDOKOプロトコルというものを考案して実装してみた。書いたソースは&lt;a href=&#34;https://github.com/kaitoy/zundoko-protocol&#34;&gt;GitHub&lt;/a&gt;においた。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;zundokoプロトコル&#34;&gt;ZUNDOKOプロトコル&lt;/h2&gt;

&lt;p&gt;クライアントはサーバに「ズン」か「ドコ」を送る。&lt;/p&gt;

&lt;p&gt;サーバは「ズン」を4回受信した後に「ドコ」を受信するとクライアントに「キ・ヨ・シ！」を返す。&lt;/p&gt;

&lt;p&gt;クライアント/サーバ間でやり取りするメッセージ(Zundokoパケット)のフォーマットは下図。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; 0                            15                              31
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|             zundoko (null-terminated string)                  |
|                                                               |
|                                                               |
|                                                               |
|                                                               |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;要はzundokoフィールドがあるだけ。
このzundokoフィールドは20 byte固定長で、NULL (0x00)で終わるUTF-8の文字列を保持する。&lt;/p&gt;

&lt;p&gt;このメッセージを運ぶ下位レイヤはEthernetで、EtherTypeは0x01FF。&lt;/p&gt;

&lt;p&gt;Ethernetにした理由は実装(下記)が楽だから。
EtherTypeは&lt;a href=&#34;http://www.iana.org/assignments/ieee-802-numbers/ieee-802-numbers.xhtml#ieee-802-numbers-1&#34;&gt;IANA&lt;/a&gt;でExperimentalとされている範囲から適当に選んだ。もちろんIANAに登録などはしていない。&lt;/p&gt;

&lt;p&gt;因みに、Ethernetヘッダを加えた、クライアント/サーバ間でやり取りする完全なパケットは以下の様になる。(プリアンブルとかは除く。)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; 0                            15
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|    Dst Hardware Address       |
+                               +
|                               |
+                               +
|                               |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|    Src Hardware Address       |
+                               +
|                               |
+                               +
|                               |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|    EtherType (0x01FF)         |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|        zundoko                |
| (null-terminated string)      |
|                               |
|                               |
|                               |
|                               |
|                               |
|                               |
|                               |
|                               |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|            padding            |
|                               |
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;実装&#34;&gt;実装&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;Pcap4J&lt;/a&gt;を使ってクライアントとサーバを実装した。
書いたのは以下の3つのクラス。(といくつかのインナークラス。)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kaitoy/zundoko-protocol/tree/master/src/main/java/com/github/kaitoy/zundoko/protocol/ZundokoPacket.java&#34;&gt;com.github.kaitoy.zundoko.protocol.ZundokoPacket&lt;/a&gt;: Pcap4JがZundokoパケットを解析するのに使うクラス&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kaitoy/zundoko-protocol/tree/master/src/main/java/com/github/kaitoy/zundoko/protocol/ZundokoServer.java&#34;&gt;com.github.kaitoy.zundoko.protocol.ZundokoServer&lt;/a&gt;: Zundokoサーバ&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kaitoy/zundoko-protocol/tree/master/src/main/java/com/github/kaitoy/zundoko/protocol/ZundokoClient.java&#34;&gt;com.github.kaitoy.zundoko.protocol.ZundokoClient&lt;/a&gt;: Zundokoクライアント&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;ビルド&#34;&gt;ビルド&lt;/h2&gt;

&lt;p&gt;今だに&lt;a href=&#34;https://maven.apache.org/&#34;&gt;Maven&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;以下を実行するとビルドできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;git clone https://github.com/kaitoy/zundoko-protocol.git
cd zundoko-protocol
mvn install
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;サーバ-クライアントの使い方&#34;&gt;サーバ/クライアントの使い方&lt;/h2&gt;

&lt;p&gt;下位レイヤがEthernetなのでネットワークセグメントを超えたZundokoパケットのやり取りはできない。
よってまずは同一ネットワーク内にサーバマシンとクライアントマシンを用意する。
VMware Playerのホストとゲストで可。&lt;/p&gt;

&lt;p&gt;サーバマシンとクライアントマシンには&lt;a href=&#34;http://www.winpcap.org/&#34;&gt;WinPcap&lt;/a&gt;か&lt;a href=&#34;http://www.tcpdump.org/&#34;&gt;libpcap&lt;/a&gt;をインストールしておく。&lt;/p&gt;

&lt;p&gt;依存ライブラリをダウンロードするため、&lt;code&gt;zundoko-protocol\bin\&lt;/code&gt;に&lt;code&gt;cd&lt;/code&gt;して以下のコマンドを実行する。(要Maven。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;configure.bat
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;サーバを起動するには、&lt;code&gt;zundoko-protocol\bin\&lt;/code&gt;で以下のコマンドを実行する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;run-server.bat
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;起動するとZundokoパケットをやり取りするネットワークインターフェースを聞かれるので、
クライアントとL2レベルでつながっているものを選ぶ。
選んだインターフェースのMacアドレスはクライアントの起動に使うのでメモしておく。&lt;/p&gt;

&lt;p&gt;クライアントを起動するには、&lt;code&gt;zundoko-protocol\bin\&lt;/code&gt;で以下のコマンドを実行する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;run-client.bat &amp;lt;Macアドレス&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;Macアドレス&amp;gt;&lt;/code&gt;にはサーバ起動時にメモしたMacアドレスを入力する。
起動するとZundokoパケットをやり取りするネットワークインターフェースを聞かれるので、
サーバとL2レベルでつながっているものを選ぶ。&lt;/p&gt;

&lt;p&gt;クライアントが起動すると、一秒おきに「ズン」と「ドコ」をランダムに選び、
サーバに送りつつコンソールに表示する。
また、サーバからZundokoパケット受信したらそのzundokoフィールドの値を表示する。&lt;/p&gt;

&lt;h2 id=&#34;実行例&#34;&gt;実行例&lt;/h2&gt;

&lt;p&gt;&lt;div class=&#34;embed video-player&#34; style=&#34;text-align: center&#34;&gt;
  &lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;320&#34; height=&#34;193&#34; src=&#34;https://www.youtube.com/embed/ad3u4Y86e_I&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>継続的インテグレーションは死んだ</title>
          <link>https://www.kaitoy.xyz/2016/02/09/continuous-integration-is-dead/</link>
          <pubDate>Tue, 09 Feb 2016 00:34:41 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/02/09/continuous-integration-is-dead/</guid>
          <description>

&lt;p&gt;このエントリでは、Yegor Bugayenkoによる記事、&lt;a href=&#34;http://www.yegor256.com/2014/10/08/continuous-integration-is-dead.html&#34;&gt;Continuous Integration is Dead&lt;/a&gt;を紹介する。
(Yegorから和訳と転載の許可は得た。)
以下はその全文の和訳だが、意訳超訳が混じっているので、もとのニュアンスを知りたければ元記事を読んでもいいし、読まなくてもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;数日前、「&lt;a href=&#34;http://devops.com/blogs/continuous-integration-doesnt-work/&#34;&gt;なぜ継続的インテグレーションは機能しないのか&lt;/a&gt;」という私の記事が&lt;a href=&#34;http://www.devops.com/&#34;&gt;DevOps.com&lt;/a&gt;に公開された。
それとほぼ同じ日に、Twitterで非常に否定的な批評が送られてきた。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;継続的インテグレーションが機能しないとはどういうことだ。この人気なすばらしいアイデアが。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;その求めてもない質問への返事をここに書く。&lt;/p&gt;

&lt;p&gt;私はこの分野に関して多少の経験があるが、それに基いた論拠は挙げない。
代わりにロジックだけを頼りにする。&lt;/p&gt;

&lt;p&gt;ところで、私には50以上のオープンソースや営利プロジェクトで5年間Apache Continuum、Hudson、CruiseControl、Jenkinsを利用した経験がある。
さらに、数年前&lt;a href=&#34;http://www.fazend.com/&#34;&gt;fazend.com&lt;/a&gt;(2013年に&lt;a href=&#34;http://www.rultor.com/&#34;&gt;rultor.com&lt;/a&gt;に改名)というホスト型継続的インテグレーションサービスを開発した。
現在&lt;a href=&#34;http://www.travis-ci.org/&#34;&gt;Travis&lt;/a&gt;と&lt;a href=&#34;http://www.appveyor.com/&#34;&gt;AppVeyor&lt;/a&gt;のアクティブユーザでもある。&lt;/p&gt;

&lt;h2 id=&#34;継続的インテグレーションはどう機能すべきか&#34;&gt;継続的インテグレーションはどう機能すべきか&lt;/h2&gt;

&lt;p&gt;考え方はシンプルで明確だ。
&lt;code&gt;master&lt;/code&gt;ブランチ(Subversionなら&lt;code&gt;/trunk&lt;/code&gt;)に新しくコミットをする度に、継続的インテグレーションサーバ(またはサービス)はプロダクト全体のビルドを試みる。
「ビルド」というのはコンパイル、ユニットテスト、統合テスト、品質解析&lt;a href=&#34;http://www.yegor256.com/2014/06/21/casperjs-with-maven.html&#34;&gt;など&lt;/a&gt;を意味する。&lt;/p&gt;

&lt;p&gt;その結果は「成功」か「失敗」だ。
もし成功だったら「ビルドがクリーン」であると言う。
もし失敗だったら、「ビルドが壊れている」と言う。
通常、ビルドが壊れるのは、以前通っていたユニットテストを通らなくするような新しいコードをだれかがコミットしたからだ。&lt;/p&gt;

&lt;p&gt;これは問題の技術的な面だ。
この部分はいつも上手くいく。
まあ、依存が直書きされてるとか、ビルド環境が十分分離されていないとか、ビルドの並列性が完全じゃないとか、そういう問題はあるかもしれないが、この記事はそれらについてではない。
アプリケーションが上手く書かれていてユニットテストが安定しているなら、継続的インテグレーションは簡単だ。
技術的には。&lt;/p&gt;

&lt;p&gt;組織的な面を見てみよう。&lt;/p&gt;

&lt;p&gt;継続的インテグレーションというのは、ビルドを実行するサーバだけを指すのではなく、上手く機能すべき管理的/組織的プロセスだ。
プロセスが上手く機能するとは、Jez Humbleが「&lt;a href=&#34;http://www.amazon.com/gp/product/0321601912/ref=as_li_tl?ie=UTF8&amp;amp;camp=1789&amp;amp;creative=390957&amp;amp;creativeASIN=0321601912&amp;amp;linkCode=as2&amp;amp;tag=yegor256com-20&amp;amp;linkId=GKWBKGZUJGJLFMHE&#34;&gt;継続的デリバリー: ビルド、テスト、デプロイの自動化による確実なソフトウェアリリース&lt;/a&gt;」の55ページで言っていることそのものを意味する。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;もしビルドが失敗したら、開発チームは何をやっていたとしてもそれを中断して、そのビルドの問題を速やかに直す。これが重要だ。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;これが上手くいかず、上手くできないことだ。&lt;/p&gt;

&lt;h2 id=&#34;誰がこれを必要としているのか&#34;&gt;誰がこれを必要としているのか&lt;/h2&gt;

&lt;p&gt;既に述べた通り、継続的インテグレーションとは、開発チーム全体を止めて壊れたビルドを修正させることだ。
繰り返すが、ビルドが壊れたら直ちに、それを修正し、ビルドを安定した状態に戻すコミットを入れることに全員が集中すべきだ。&lt;/p&gt;

&lt;p&gt;ここでひとつ疑問が生じる。誰が、活動中のチーム内の誰がこれを必要としているのだろうか?&lt;/p&gt;

&lt;p&gt;一刻も早く新しい機能をリリースしたいプロダクトオーナ?
または、締め切りに責任を持つ&lt;a href=&#34;http://www.yegor256.com/2015/09/22/micromanagement.html&#34;&gt;プロジェクトマネージャ&lt;/a&gt;かもしれない。
もしくは、他の誰かが作りこんだバグをプレッシャーを受けながら修正すること嫌うプログラマかもしれない。&lt;/p&gt;

&lt;p&gt;誰がこの継続的インテグレーションを好み、誰が必要としているのか?&lt;/p&gt;

&lt;p&gt;誰でもない。&lt;/p&gt;

&lt;h2 id=&#34;実際に何が起こるのか&#34;&gt;実際に何が起こるのか&lt;/h2&gt;

&lt;p&gt;教えよう。
私は何度も見たことがある。
シナリオはいつも同じだ。
継続的インテグレーションのビルドステータスは単に無視されるようになる。
ビルドがクリーンか壊れているかにかかわらず。
そして以前のやり方が継続される。&lt;/p&gt;

&lt;p&gt;Jez Humbleが推奨するように開発を止めて問題に対応したりしない。&lt;/p&gt;

&lt;p&gt;代わりに、継続的インテグレーションサーバから来る情報を無視する。&lt;/p&gt;

&lt;p&gt;しばらくして、次の日かもしれないし月曜日かもしれないが、空いた時間を探してビルドの修正に取り組む。
これは単に、ダッシュボードの赤いボタンが嫌で緑に変えたいからだ。&lt;/p&gt;

&lt;h2 id=&#34;規律についてはどうか&#34;&gt;規律についてはどうか&lt;/h2&gt;

&lt;p&gt;そう、これには別の見方もある。
チームに規律を徹底させることもできる。
ビルドは常にクリーンで、壊した人は何らかの&lt;a href=&#34;http://www.yegor256.com/2016/01/05/how-to-punish-employees.html&#34;&gt;罰&lt;/a&gt;を受けるという厳格なルールを設けることができる。&lt;/p&gt;

&lt;p&gt;これを試すとなると、恐怖駆動型開発を実施することになる。
プログラマは、ビルドを失敗させたら少なくとも&lt;a href=&#34;http://programmers.stackexchange.com/questions/79041&#34;&gt;謝罪&lt;/a&gt;しなければならなくなるため、リポジトリへのコミットを恐れるようになる。&lt;/p&gt;

&lt;p&gt;この場合の厳格な規律(私は大好きだが)は、単に状況を悪化させる。
開発プロセス全体が遅くなり、プログラマはビルドを壊さないように自身のコードをできるだけ長い間手元に保持する。
いざコミットするとなった時、変更は巨大になっていて、マージは非常に難しいか、時に不可能になる。&lt;/p&gt;

&lt;p&gt;結果、プログラマが書いた多くのコードがコミットされること無く捨てられる。
あの恐怖因子のせいだ。&lt;/p&gt;

&lt;h2 id=&#34;ok-解決策は&#34;&gt;OK。解決策は?&lt;/h2&gt;

&lt;p&gt;それについては以前書いた。
「&lt;a href=&#34;http://www.yegor256.com/2014/07/21/read-only-master-branch.html&#34;&gt;読み取り専用マスタブランチ&lt;/a&gt;」だ。&lt;/p&gt;

&lt;p&gt;これは単純で、&lt;code&gt;master&lt;/code&gt;へのマージを一切禁止し、誰でも実行できるスクリプトを作る。
このスクリプトがマージ、テスト、コミットを実行する。
このスクリプトには例外が全く無い。
どんなブランチであっても、たった一つのユニットテストに失敗しただけでも、ブランチ全体が却下される。&lt;/p&gt;

&lt;p&gt;言い換えると、&lt;code&gt;master&lt;/code&gt;にそのコードが入る前に赤いフラグを揚げる。&lt;/p&gt;

&lt;p&gt;これで全ての問題が解決する。&lt;/p&gt;

&lt;p&gt;第一に、ビルドは常にクリーンだ。
ビルドをクリーンに保たないコードは誰もコミットできないので、単純に言ってビルドを壊すことはできない。&lt;/p&gt;

&lt;p&gt;第二に、何かを壊すという恐怖が無い。
単に技術的に壊せないのだ。
マージスクリプトから却下されることしかできない。
その場合、エラーを修正してスクリプトに再挑戦を命じる。
誰もこのやりとりを見ていないので、謝罪する必要が無い。
恐怖因子は消えた。&lt;/p&gt;

&lt;p&gt;ところで、君のプロジェクトで&lt;a href=&#34;http://www.rultor.com/&#34;&gt;rultor.com&lt;/a&gt;を利用して、この「&lt;a href=&#34;http://www.yegor256.com/2014/07/21/read-only-master-branch.html&#34;&gt;読み取り専用マスタブランチ&lt;/a&gt;」原則を徹底してみてくれ。&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;embed video-player&#34; style=&#34;text-align: center&#34;&gt;
  &lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;320&#34; height=&#34;193&#34; src=&#34;https://www.youtube.com/embed/3IXk5yEJMIs&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上がYegorの記事。&lt;/p&gt;

&lt;p&gt;CIは死んだというセンセーショナルなタイトルではあるが、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E7%A5%9E%E3%81%AF%E6%AD%BB%E3%82%93%E3%81%A0&#34;&gt;ニーチェ&lt;/a&gt;とは違って神なるCIを否定しているわけではない。
CIって意外と上手くいかないけど、こうすれば改善できるよという主旨の記事だ。&lt;/p&gt;

&lt;p&gt;Yegorが指摘している、ビルドステータスが無視されるようになるという一つ目の問題は、実例を多く見たことがあるわけではないが確かになんだかよく起こりそうな話だ。
そういえば私もPcap4JのTravisでのビルドエラーをもう数か月無視している。
まあこれはTravis側の問題が原因で、回避策を入れるのが気が進まないだけなんだけど。&lt;/p&gt;

&lt;p&gt;Yegorのやり方は、&lt;a href=&#34;https://gist.github.com/juno/3112343&#34;&gt;GitHub Flow&lt;/a&gt;が&lt;code&gt;master&lt;/code&gt;は常にデプロイ可能としているのを、より厳密に守るように仕組化する感じであろうか。&lt;/p&gt;

&lt;p&gt;GitHub Flowを世に広めたScott Chaconによれば、&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;テストされていなかったり、ビルドを破壊するようなコードをmasterにpushした場合には、開発チーム間におけるソーシャルな取り決めを破ることになり、ちょっと気まずい思いをすることになる&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;とのことで、これはまさにYegorが恐怖因子と指摘した二つ目の問題である。
慣れない内のリポジトリへのコミットの緊張感や、CIサーバからエラー通知が来た時の焦燥感は、多くの人のストレスになっているんじゃないだろうか。
&lt;code&gt;master&lt;/code&gt;の更新をスクリプトに任せてしまえば、それでなおビルドが壊れたとしてもスクリプトのせいにできるので気が楽だろう。&lt;/p&gt;

&lt;p&gt;実装が簡単そうなアイデアでもあるので、いつかCIを実装する日まで覚えておきたい。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Pcap4J Meets Windows Containers</title>
          <link>https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/</link>
          <pubDate>Fri, 22 Jan 2016 17:46:43 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/</guid>
          <description>

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/about/about_overview&#34;&gt;Windows Containers&lt;/a&gt;&lt;/strong&gt; で &lt;strong&gt;&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;Pcap4J&lt;/a&gt;&lt;/strong&gt; のコンテナをビルドしてみた話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;windows-containersとは&#34;&gt;Windows Containersとは&lt;/h2&gt;

&lt;p&gt;Windows Containersは、Microsoftが&lt;a href=&#34;https://www.docker.com/company&#34;&gt;Docker, Inc&lt;/a&gt;と提携して開発している&lt;a href=&#34;http://www.sophia-it.com/content/%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A%E6%8A%80%E8%A1%93&#34;&gt;コンテナ技術&lt;/a&gt;で、Windows版&lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt;とも言われる機能。
今年リリースされる &lt;strong&gt;Windows Server 2016&lt;/strong&gt; に実装される予定で、その3つめのテクニカルプレビューである &lt;strong&gt;Windows Server 2016 Technical Preview 3&lt;/strong&gt; (2015/8/19公開)から評価できるようになった。&lt;/p&gt;

&lt;p&gt;Windows Containersには次の二種類がある。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Windows Server Containers&lt;/p&gt;

&lt;p&gt;プロセスと名前空間の分離を実現する機能で、これによるコンテナはカーネルをホストと共有する。
つまり本家Dockerに近い形の機能。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Hyper-V Containers&lt;/p&gt;

&lt;p&gt;それぞれのコンテナを軽量化されたHyper-Vの仮想マシンっぽいものの上で動かす機能。
このコンテナの実行にはHyper-Vが必要。
Windows Server Containersよりコンテナ間の分離性が高く、カーネルの共有もしないが、そもそもそれってコンテナなの?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;どちらも同じようなインターフェースで操作でき、このインターフェースには&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/reference/ps_docker_comparison&#34;&gt;PowershellのコマンドレットとDockerコマンドの二種類がある&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;より詳しくは、&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/about/about_overview&#34;&gt;Microsoftによる解説&lt;/a&gt;や&lt;a href=&#34;http://www.atmarkit.co.jp/ait/articles/1512/11/news022.html&#34;&gt;@ITのこの記事&lt;/a&gt;がわかりやすい。
また、&lt;a href=&#34;http://qiita.com/Arturias/items/3e82de8328067d0e03a3&#34;&gt;Qiitaのこの記事&lt;/a&gt;がDockerとWindows Server Containersのアーキテクチャを詳細に説明していて面白い。&lt;/p&gt;

&lt;h2 id=&#34;windows-containersセットアップ&#34;&gt;Windows Containersセットアップ&lt;/h2&gt;

&lt;p&gt;まず、Windows 7 x64のノートPCにVMware Player 7.1.0を入れてWindows 10 x64用のVM(CPU2つとメモリ2.5GB)を作り、そこに2015/11/19に公開された &lt;strong&gt;Windows Server 2016 Technical Preview 4&lt;/strong&gt; をインストール。
コマンドでいろいろ設定するの慣れていないのでGUI(Desktop Experience)付きで。
(リモートデスクトップ使えばよかったのかもしれないけど。)
ロケールは英語以外は問題が起きそうなので英語で。&lt;/p&gt;

&lt;p&gt;このVMに、&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/quick_start/inplace_setup&#34;&gt;Microsoftのセットアップガイド&lt;/a&gt;と&lt;a href=&#34;http://www.atmarkit.co.jp/ait/articles/1512/14/news006.html&#34;&gt;@ITの記事&lt;/a&gt;を参照しながらWindows Containersをセットアップ。&lt;/p&gt;

&lt;p&gt;後者の記事によると、Hyper-V ContainersをVM上にセットアップするには、&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/hyperv_on_windows/user_guide/nesting&#34;&gt;Nested Virtualization&lt;/a&gt;というHyper-VのVMの上でHyper-Vを動かす機能を有効にしたホスト上のHyper-V VMを使わないといけないようなので、Windows Server Containersの方を試すことに。&lt;/p&gt;

&lt;p&gt;Windows Server Containersをセットアップする手順は以下。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;VM上でコマンドプロンプトを開いて &lt;code&gt;powershell start-process powershell -Verb runas&lt;/code&gt; を実行。&lt;/li&gt;
&lt;li&gt;青いパワーシェルウィンドウが開くのでそこで &lt;code&gt;wget -uri https://aka.ms/tp4/Install-ContainerHost -OutFile C:\Install-ContainerHost.ps1&lt;/code&gt; を実行。&lt;code&gt;Install-ContainerHost.ps1&lt;/code&gt; というスクリプトがダウンロードされる。&lt;/li&gt;
&lt;li&gt;青いパワーシェルウィンドウで &lt;code&gt;C:\Install-ContainerHost.ps1&lt;/code&gt; を実行するとWindows Server Containersのインストールが始まる。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/pcap4j-meets-windows-containers/install.png&#34; alt=&#34;install.png&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;途中再起動が一回あって、ログインしたらインストール処理が再開した。
全部で2時間以上かかった。&lt;/p&gt;

&lt;p&gt;仮想Ethernetスイッチ接続の追加に失敗したというエラーが出たけどなんなんだろう。
&lt;code&gt;ipconfig&lt;/code&gt; の出力によると &lt;code&gt;vEthernet&lt;/code&gt; というDockerの&lt;a href=&#34;https://www.kaitoy.xyz/2015/07/25/how-to-capture-packets-on-a-local-network-with-pcap4j-container/#docker-network&#34;&gt;virtual Ethernet bridge&lt;/a&gt;にあたるものはちゃんと作られているみたいなんだけど。&lt;/p&gt;

&lt;h2 id=&#34;windows-server-containers味見&#34;&gt;Windows Server Containers味見&lt;/h2&gt;

&lt;p&gt;コマンドプロンプトで &lt;code&gt;docker images&lt;/code&gt; を実行すると、既に &lt;code&gt;windowsservercore&lt;/code&gt; というコンテナイメージが入っていることがわかる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\Administrator&amp;gt;docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
windowsservercore   10.0.10586.0        6801d964fda5        11 weeks ago        0 B
windowsservercore   latest              6801d964fda5        11 weeks ago        0 B
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;docker run -it windowsservercore cmd&lt;/code&gt; を実行すると &lt;code&gt;windowsservercore&lt;/code&gt; からコンテナを起動してその上でコマンドプロンプトを起動できる。
コンテナの起動は非常に遅い。30秒以上かかる。これは今の時点での&lt;a href=&#34;https://msdn.microsoft.com/virtualization/windowscontainers/about/work_in_progress#windows-containers-start-slowly&#34;&gt;制限&lt;/a&gt;らしい。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker login --help&lt;/code&gt; するとわかるが、コンテナイメージのリポジトリは &lt;code&gt;https://registry-win-tp3.docker.io/v1/&lt;/code&gt; という仮っぽいサーバにあって、&lt;code&gt;docker search *&lt;/code&gt; を実行するとそこに登録されたイメージのリストが見れる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;C:\Users\Administrator&amp;gt;docker search *
NAME                 DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED
microsoft/aspnet     ASP.NET 5 framework installed in a Windows...   1         [OK]       [OK]
microsoft/django     Django installed in a Windows Server Core ...   1                    [OK]
microsoft/dotnet35   .NET 3.5 Runtime installed in a Windows Se...   1         [OK]       [OK]
microsoft/golang     Go Programming Language installed in a Win...   1                    [OK]
microsoft/httpd      Apache httpd installed in a Windows Server...   1                    [OK]
microsoft/iis        Internet Information Services (IIS) instal...   1         [OK]       [OK]
microsoft/mongodb    MongoDB installed in a Windows Server Core...   1                    [OK]
microsoft/mysql      MySQL installed in a Windows Server Core b...   1                    [OK]
microsoft/nginx      Nginx installed in a Windows Server Core b...   1                    [OK]
microsoft/node       Node installed in a Windows Server Core ba...   1                    [OK]
microsoft/php        PHP running on Internet Information Servic...   1                    [OK]
microsoft/python     Python installed in a Windows Server Core ...   1                    [OK]
microsoft/rails      Ruby on Rails installed in a Windows Serve...   1                    [OK]
microsoft/redis      Redis installed in a Windows Server Core b...   1                    [OK]
microsoft/ruby       Ruby installed in a Windows Server Core ba...   1                    [OK]
microsoft/sqlite     SQLite installed in a Windows Server Core ...   1                    [OK]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これらはちゃんと &lt;code&gt;docker pull&lt;/code&gt; して使える。
けど多分 &lt;code&gt;docker push&lt;/code&gt; はできない。&lt;/p&gt;

&lt;h2 id=&#34;pcap4j-on-windows-container&#34;&gt;Pcap4J on Windows Container&lt;/h2&gt;

&lt;p&gt;結論から言うと、以下の &lt;code&gt;Dockerfile&lt;/code&gt; を書いて &lt;code&gt;docker build&lt;/code&gt; してPcap4Jをコンテナ上でビルドするところまではできたが、それを実行してもNIFが全く検出できず、よってパケットキャプチャも実行できなかった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#
# Dockerfile for Pcap4J on Windows
#

FROM windowsservercore:latest
MAINTAINER Kaito Yamada &amp;lt;kaitoy@pcap4j.org&amp;gt;

# Install Chocolatey.
RUN mkdir C:\pcap4j
WORKDIR /pcap4j
ADD https://chocolatey.org/install.ps1 install.ps1
RUN powershell .\install.ps1

# Install dependencies.
RUN choco install -y nmap maven git jdk7

# Build Pcap4J.
RUN git clone git://github.com/kaitoy/pcap4j.git
WORKDIR pcap4j
RUN powershell -NoProfile -ExecutionPolicy Bypass -Command &amp;quot;mvn &#39;-Dmaven.repo.local=C:\pcap4j\repo&#39; -P distribution-assembly install 2&amp;gt;&amp;amp;1 | add-content -Path build.log -pass

# Collect libraries.
RUN mkdir bin &amp;amp;&amp;amp; \
    cd pcap4j-packetfactory-static &amp;amp;&amp;amp; \
    mvn -Dmaven.repo.local=C:\pcap4j\repo -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeScope=compile dependency:copy-dependencies &amp;amp;&amp;amp; \
    mvn -Dmaven.repo.local=C:\pcap4j\repo -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeGroupIds=ch.qos.logback dependency:copy-dependencies &amp;amp;&amp;amp; \
    cd ../pcap4j-distribution &amp;amp;&amp;amp; \
    mvn -Dmaven.repo.local=C:\pcap4j\repo -DoutputDirectory=..\bin -Dmdep.stripVersion=true -DincludeArtifactIds=pcap4j-packetfactory-static,pcap4j-sample dependency:copy-dependencies

# Generate sample script. (C:\pcap4j\pcap4j\bin\capture.bat)
RUN echo @echo off &amp;gt; bin\capture.bat &amp;amp;&amp;amp; \
    echo &amp;quot;%JAVA_HOME%\bin\java&amp;quot; -cp C:\pcap4j\pcap4j\bin\pcap4j-core.jar;C:\pcap4j\pcap4j\bin\pcap4j-packetfactory-static.jar;C:\pcap4j\pcap4j\bin\pcap4j-sample.jar;C:\pcap4j\pcap4j\bin\jna.jar;C:\pcap4j\pcap4j\bin\slf4j-api.jar;C:\pcap4j\pcap4j\bin\logback-classic.jar;C:\pcap4j\pcap4j\bin\logback-core.jar org.pcap4j.sample.GetNextPacketEx &amp;gt;&amp;gt; bin\capture.bat
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この &lt;code&gt;Dockerfile&lt;/code&gt; でやっていることはだいたい以下。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://chocolatey.org/&#34;&gt;Chocolatey&lt;/a&gt;をインストール。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://nmap.org/&#34;&gt;Nmap&lt;/a&gt;と&lt;a href=&#34;https://maven.apache.org/&#34;&gt;Maven&lt;/a&gt;と&lt;a href=&#34;https://git-scm.com/&#34;&gt;Git&lt;/a&gt;とJDK7をChocolateyでインストール。&lt;/li&gt;
&lt;li&gt;Pcap4Jのソースを &lt;code&gt;git clone&lt;/code&gt; でダウンロード。&lt;/li&gt;
&lt;li&gt;MavenでPcap4Jのビルドを実行。&lt;/li&gt;
&lt;li&gt;Pcap4Jのサンプルクラスを実行するスクリプトを生成。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;2でNmapは&lt;a href=&#34;http://www.winpcap.org/&#34;&gt;WinPcap&lt;/a&gt;の代わりに入れている。
GUI無しの環境でWinPcapをChocolateyで入れようとしても、エラーが発生したりしなかったりして、しかもどちらにせよ正常に入らない。
これはWinPcapのインストーラがサイレントインストールをサポートしていないから。
Nmapはサイレントインストールできて、インストール処理中にWinPcapを入れてくれるのでありがたい。&lt;/p&gt;

&lt;p&gt;ビルドしてみると、各ステップの実行(多分レイヤの作成)がすごく遅い。
&lt;code&gt;RUN choco install -y nmap maven git jdk7&lt;/code&gt; の後、次のコマンド実行まで30分くらい固まった。&lt;/p&gt;

&lt;p&gt;また、&lt;code&gt;Dockerfile&lt;/code&gt; を書いていて以下のバグに悩まされた。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;WORKDIR&lt;/code&gt; や &lt;code&gt;ENV&lt;/code&gt; で環境変数が展開されない。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;  ENV hoge %tmp%
  RUN echo %hoge%
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;とすると &lt;code&gt;%tmp%&lt;/code&gt; と表示される。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;WORKDIR&lt;/code&gt; や &lt;code&gt;ENV&lt;/code&gt; や &lt;code&gt;COPY&lt;/code&gt; でパスの区切りは &lt;code&gt;\&lt;/code&gt; 一つだと消えちゃうので &lt;code&gt;\\&lt;/code&gt; か &lt;code&gt;/&lt;/code&gt; を使わないといけない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;WORKDIR&lt;/code&gt; や &lt;code&gt;COPY&lt;/code&gt; のコンテナ内のパスに絶対パスを指定したい場合、&lt;code&gt;C:\hoge&lt;/code&gt;、&lt;code&gt;C:/hoge&lt;/code&gt;、&lt;code&gt;C:\\hoge&lt;/code&gt;、いずれもダメ。
以下の様なエラーが出る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  GetFileAttributesEx \\?\Volume{67df3c84-a0ef-11e5-9a63-000c2976fbc3}\C:: The filename, directory name, or volume label syntax is incorrect.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;UNIX式に &lt;code&gt;/hoge&lt;/code&gt; とするといける。C以外のドライブを指定したいときはどうするんだろう。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;コンテナ内で &lt;code&gt;C:\&lt;/code&gt; 直下に &lt;code&gt;.&lt;/code&gt; で始まる名前のフォルダ作ると次のステップで消えてる。
&lt;code&gt;.&lt;/code&gt; で始まる名前のファイルは &lt;code&gt;C:\&lt;/code&gt; 直下じゃなくても次のステップで消えてる。
Mavenのリポジトリがデフォルトで &lt;code&gt;C:\.m2\&lt;/code&gt; 以下にできるのではまる。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;これらのバグを乗り越えて頑張って &lt;code&gt;Dockerfile&lt;/code&gt; 書いたのに、NIFの検出すらできなかったという哀しい結果。
&lt;code&gt;pcap_lookupdev&lt;/code&gt; が以下のエラーを吐いて &lt;code&gt;NULL&lt;/code&gt; を返してきてたので、なんとなくコンテナのNIFに長すぎる名前がついていて検出失敗しているんじゃないかと。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PacketGetAdapterNames: The data area passed to a system call is too small. (122)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因みにコンテナ内から見えるNIFは一つで、以下の構成。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Ethernet adapter vEthernet (Virtual Switch-d206475ce13256766b9a16383540a740fe31da8d20499349fe98693393a8490f-0):

   Connection-specific DNS Suffix  . : localdomain
   Link-local IPv6 Address . . . . . : fe80::4086:d11e:5e6:28fe%26
   IPv4 Address. . . . . . . . . . . : 172.16.0.2
   Subnet Mask . . . . . . . . . . . : 255.240.0.0
   Default Gateway . . . . . . . . . : 172.16.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コンテナ内から &lt;code&gt;www.google.com&lt;/code&gt; とかにping届いたので、このNIFはちゃんと働いていはずなんだけどPcap4Jから見えない。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;
&lt;br&gt;&lt;/p&gt;

&lt;p&gt;後日上記 &lt;code&gt;Dockerfile&lt;/code&gt; でビルドしてみたら、&lt;code&gt;RUN powershell .\install.ps1&lt;/code&gt; で以下のエラーが出るようになった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;The request was aborted: Could not create SSL/TLS secure channel.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;install.ps1の中でChocolateyのインストーラをHTTPSで取ってこようとしてエラーになっている模様。
Windows Containersの&lt;a href=&#34;https://msdn.microsoft.com/en-us/virtualization/windowscontainers/about/work_in_progress#https-and-tls-are-not-supported&#34;&gt;ドキュメント&lt;/a&gt;や&lt;a href=&#34;https://social.msdn.microsoft.com/Forums/en-US/c0d93dda-37b7-4a2c-9a78-55e4ba0b88f5/https-support-in-windowsservercore-image?forum=windowscontainers&#34;&gt;フォーラム&lt;/a&gt;にHTTPSが使えないという制限が載っているけどこのせい?
ちょっと前にやったときは同じ &lt;code&gt;Dockerfile&lt;/code&gt; でビルドできたはずなんだけど。&lt;/p&gt;

&lt;p&gt;試しに以下の処理を挟んでChocolateyのインストーラをHTTPで取ってくるようにしたらChocolateyのインストールまではできた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;RUN powershell $(Get-Content install.ps1) -replace \&amp;quot;https\&amp;quot;,\&amp;quot;http\&amp;quot; &amp;gt; install.mod.ps1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;けど &lt;code&gt;choco install&lt;/code&gt; がHTTPS使うので結局駄目だった。&lt;/p&gt;

&lt;p&gt;もう面倒なのでHTTPSの制限がとれるのをまとう。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Pcap4J with Four Native Libraries on Windows 10</title>
          <link>https://www.kaitoy.xyz/2016/01/12/pcap4j-with-four-native-libraries-on-windows10/</link>
          <pubDate>Tue, 12 Jan 2016 08:43:30 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/01/12/pcap4j-with-four-native-libraries-on-windows10/</guid>
          <description>

&lt;p&gt;I did some basic tests for &lt;strong&gt;&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;Pcap4J&lt;/a&gt;&lt;/strong&gt; 1.6.2 on Windows 10 Pro on &lt;a href=&#34;https://www.vmware.com/products/player&#34;&gt;VMware Player&lt;/a&gt; 7.1.0 using the following native packet capture libraries:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;http://www.winpcap.org/&#34;&gt;Official WinPcap&lt;/a&gt;&lt;/strong&gt; 4.1.3&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;http://sourceforge.net/projects/winpcap413-176/&#34;&gt;Unofficial WinPcap based on libpcap 1.7.4&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;http://www.win10pcap.org/&#34;&gt;Win10Pcap&lt;/a&gt;&lt;/strong&gt; 10.2&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/nmap/npcap&#34;&gt;Npcap&lt;/a&gt;&lt;/strong&gt; 0.0.5&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This article explains each of the above libraries and tells the test results.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;official-winpcap&#34;&gt;Official WinPcap&lt;/h2&gt;

&lt;p&gt;WinPcap is the most common native packet capture library developed based on &lt;a href=&#34;http://www.tcpdump.org/&#34;&gt;&lt;strong&gt;libpcap&lt;/strong&gt;&lt;/a&gt;.
(WinPcap 4.1.3 is based on libpcap 1.0.0.)
It&amp;rsquo;s famous as a component of the de facto standard packet capture tool &lt;a href=&#34;https://www.wireshark.org/&#34;&gt;&lt;strong&gt;Wireshark&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;WinPcap consists of &lt;strong&gt;NPF driver&lt;/strong&gt;, &lt;strong&gt;wpcap.dll&lt;/strong&gt;, and &lt;strong&gt;Packet.dll&lt;/strong&gt;.
The structure is described in the &lt;a href=&#34;http://www.winpcap.org/docs/docs_412/html/group__NPF.html&#34;&gt;WinPcap manual&lt;/a&gt; as below:&lt;/p&gt;

&lt;p&gt;&lt;img alt=&#34;NPF&#34; src=&#34;http://www.winpcap.org/docs/docs_412/html/npf-npf.gif&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;wpcap.dll is Windows version of libpcap.so. It uses Packet Driver API implemented in Packet.dll.
Packet.dll talks with the NPF driver.
wpcap.dll and Packet.dll are installed in &lt;code&gt;C:\Windows\System32\&lt;/code&gt; (64 bit binaries) and &lt;code&gt;C:\Windows\SysWOW64\&lt;/code&gt; (32 bit binaries).&lt;/p&gt;

&lt;p&gt;WinPcap worked without any problems in my tests.&lt;/p&gt;

&lt;h2 id=&#34;winpcap-based-on-libpcap-1-7-4&#34;&gt;WinPcap based on libpcap 1.7.4&lt;/h2&gt;

&lt;p&gt;This is an unofficial version of WinPcap which was built on libpcap 1.7.4.
This doesn&amp;rsquo;t include NPF driver and doesn&amp;rsquo;t update Packet.dll.
These two components need to be installed from the official WinPcap 4.1.3.&lt;/p&gt;

&lt;p&gt;This worked well but &lt;a href=&#34;https://github.com/kaitoy/pcap4j/issues/52&#34;&gt;one moderate problem&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;win10pcap&#34;&gt;Win10Pcap&lt;/h2&gt;

&lt;p&gt;Win10Pcap is a WinPcap-based packet capture library developed by &lt;a href=&#34;http://dnobori.cs.tsukuba.ac.jp/en/&#34;&gt;Daiyuu Nobori&lt;/a&gt;.
This includes its own NPF driver and Packet.dll.
The wpcap.dll Win10Pcap installs is exactly the same as one of the official WinPcap 4.1.3.&lt;/p&gt;

&lt;p&gt;The difference between the original WinPcap and Win10Pcap is &lt;a href=&#34;http://www.ndis.com/&#34;&gt;&lt;strong&gt;NDIS&lt;/strong&gt;&lt;/a&gt; (Network Driver Interface Specification) version.
Win10Pcap is based on NDIS 6.x while WinPcap is based on 5.x.&lt;/p&gt;

&lt;p&gt;NDIS version history is as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;NDIS 2.0: MS-DOS, Windows for Workgroups 3.1&lt;/li&gt;
&lt;li&gt;NDIS 3.0: Windows for Workgroups 3.11, NT 3.5&lt;/li&gt;
&lt;li&gt;NDIS 3.1: Windows 95&lt;/li&gt;
&lt;li&gt;NDIS 4.0: Windows 95 OSR2, NT 4.0&lt;/li&gt;
&lt;li&gt;NDIS 4.1: Windows 98, NT 4.0 SP3&lt;/li&gt;
&lt;li&gt;NDIS 5.0: Windows 98 SE, Me, 2000&lt;/li&gt;
&lt;li&gt;NDIS 5.1: Windows XP&lt;/li&gt;
&lt;li&gt;NDIS 5.2: Windows Server 2003&lt;/li&gt;
&lt;li&gt;NDIS 6.0: Windows Vista&lt;/li&gt;
&lt;li&gt;NDIS 6.1: Windows Vista SP1, Server 2008&lt;/li&gt;
&lt;li&gt;NDIS 6.2: Windows 7, Server 2008 R2&lt;/li&gt;
&lt;li&gt;NDIS 6.3: Windows 8, Server 2012&lt;/li&gt;
&lt;li&gt;NDIS 6.4: Windows 8.1, Server 2012 R2&lt;/li&gt;
&lt;li&gt;NDIS 6.5: Windows 10, Server 2016&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Although NDIS 6.x is backward-compatible with 5.x and WinPcap can run on Vista and newer ones, it&amp;rsquo;s expected Win10Pcap is faster than WinPcap because the newer NDIS is more efficient than older versions.&lt;/p&gt;

&lt;p&gt;Win10Pcap worked mostly fine in my tests, but it didn&amp;rsquo;t detect MAC addresses and IPv6 addresses on devices.&lt;/p&gt;

&lt;h2 id=&#34;npcap&#34;&gt;Npcap&lt;/h2&gt;

&lt;p&gt;Npcap is another NDIS 6.x based version of WinPcap developed by &lt;a href=&#34;http://www.veotax.com/&#34;&gt;Yang Luo&lt;/a&gt; for &lt;a href=&#34;https://nmap.org/&#34;&gt;Nmap&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Npcap has a special functionality that allows to capture/send loopback packets.
It creates an adapter &lt;strong&gt;&amp;ldquo;Npcap Loopback Adapter&amp;rdquo;&lt;/strong&gt; for the functionality during its installation.
This adapter can be used in the same way as other normal adapters.&lt;/p&gt;

&lt;p&gt;Npcap provides its own NPF driver and Packet.dll but wpcap.dll is the one pulled from the official WinPcap 4.1.3.&lt;/p&gt;

&lt;p&gt;I installed Npcap with &lt;strong&gt;&amp;ldquo;WinPcap Compatible Mode&amp;rdquo;&lt;/strong&gt; ON for my tests.
It perfectly worked including MAC/IPv6 addresses detection.&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ソフトウェアアーキテクトは何をするのか?</title>
          <link>https://www.kaitoy.xyz/2016/01/11/who-is-software-architect/</link>
          <pubDate>Mon, 11 Jan 2016 14:41:29 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/01/11/who-is-software-architect/</guid>
          <description>

&lt;p&gt;このエントリでは、Yegor Bugayenkoによる記事、&lt;a href=&#34;http://www.yegor256.com/2014/10/12/who-is-software-architect.html&#34;&gt;What Does a Software Architect Do?&lt;/a&gt;を紹介する。
(Yegorから和訳と転載の許可は得た。)
以下はその全文の和訳だが、意訳超訳が混じっているので、もとのニュアンスを知りたければ元記事を読んでもいいし、読まなくてもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;君のプロジェクトにはソフトウェアアーキテクトが居るだろうか?
必要だと思う?&lt;/p&gt;

&lt;p&gt;まあ、ほとんどの&lt;a href=&#34;http://www.yegor256.com/2015/11/21/ringelmann-effect-vs-agile.html&#34;&gt;アジャイルチーム&lt;/a&gt;はそのような役割を明確には定義せず、民主的な感じで働く。
全ての重要な技術的な意思決定はチーム全体で議論され、最多数の投票を得た解決策が採用される。
しばらくして、このようなチームが「ソフトウェアアーキテクト」バッジを誰かのTシャツに付ける事に決めたときは、もっとも評判のいいプログラマがそのバッジを手にする。&lt;/p&gt;

&lt;p&gt;このバッジが彼の責務を変えることはまれだけども。
結局、チームは同じように働き続け、全員を巻き込んだ技術的議論を楽しむ。
つまり、ソフトウェアアーキテクトは責務が明確に定義された役割というよりもステータスになる。
それは最年長で最も権限のある人へのチームメンバからの尊敬の印になる。そうだろ?&lt;/p&gt;

&lt;p&gt;全く間違っている!&lt;/p&gt;

&lt;h2 id=&#34;アーキテクトは品質の責任を負う&#34;&gt;アーキテクトは品質の責任を負う&lt;/h2&gt;

&lt;p&gt;普通はアーキテクトは最も知識、スキル、経験、権限がある人がなるということは明らかだ。
もちろん普通はアーキテクトは他の人よりもものを知っていて、必要に応じて外交的指導的手腕を発揮してその知識を伝達する。
アーキテクトは普通はチームの中で最も賢いやつだ。&lt;/p&gt;

&lt;p&gt;しかしこのことは、彼をアーキテクトたらしめているものではない。&lt;/p&gt;

&lt;p&gt;そして、チームに必要なものでもない。&lt;/p&gt;

&lt;p&gt;私のソフトウェアアーキテクトの定義こうだ。
アーキテクトは品質の責任を負う人だ。&lt;/p&gt;

&lt;p&gt;「責任 (blame)」を職責 (accountability) とか 責務 (responsibility) と言い換えてもいいが、私は「責任 (blame)」という言葉を使うのがいいと思う。
なぜなら、開発中の製品の全ての品質問題がアーキテクトの個人的な失敗であることをより強調するからだ。
もちろん、その責任の対価として、品質がよかった場合には満足した顧客からの称賛は全てアーキテクトのものだ。&lt;/p&gt;

&lt;p&gt;これがチームに必要なものだ。
開発するソフトウェアの品質に対して誰かが個人的に責任を負うのだ。&lt;/p&gt;

&lt;h2 id=&#34;プロジェクトマネージャの仕事は-アーキテクトによる全ての技術的決定に対して誰にも不信を抱かせないようにすること&#34;&gt;プロジェクトマネージャの仕事は、アーキテクトによる全ての技術的決定に対して誰にも不信を抱かせないようにすること&lt;/h2&gt;

&lt;p&gt;アーキテクトが他のメンバにどのように責任を委譲するかはアーキテクト自身の仕事だ。
知識やスキル、&lt;a href=&#34;http://www.yegor256.com/2014/08/13/strict-code-quality-control.html&#34;&gt;品質管理ツール&lt;/a&gt;、ユニットテストフレームワーク、権限、コーチング、&lt;a href=&#34;http://www.yegor256.com/2016/01/05/how-to-punish-employees.html&#34;&gt;体罰&lt;/a&gt;、何を使おうとも、それが彼の仕事だ。
&lt;a href=&#34;http://www.yegor256.com/2015/09/22/micromanagement.html&#34;&gt;プロジェクトマネージャ&lt;/a&gt;は品質管理をソフトウェアアーキテクトに委譲した。
それをさらにどう委譲するかはソフトウェアアーキテクト&lt;a href=&#34;http://www.yegor256.com/2015/02/23/haircut.html&#34;&gt;次第だ&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;ソフトウェアアーキテクトの役割は全てのプロジェクトにおいて重大だ。
たとえたった二人のプログラマが同じデスクで働いている場合でもだ。
二人のうち一人はアーキテクトでなければならない。&lt;/p&gt;

&lt;p&gt;理想的なアーキテクトは上記の長所の全てを持つ。
彼は全員の意見を聞いて考慮に入れる。
彼はよいコーチであり先生だ。忍耐もある。
彼は効果的な伝達者であり交渉人だ。
外交官だ。
技術的な領域のエキスパートだ。&lt;/p&gt;

&lt;p&gt;しかし、たとえこうした長所全てを持たなくても、彼の決定は常に最終決定だ。&lt;/p&gt;

&lt;p&gt;そして、プロジェクトマネージャの仕事は、アーキテクトによる全ての技術的決定に対して誰にも不信を抱かせないようにすることだ。
これが委譲というものだ。
責任には常に権力が伴う。&lt;/p&gt;

&lt;p&gt;プロジェクトマネージャは定期的にアーキテクトの成果を評価すべきだ。
チームで開発中の製品の品質はアーキテクトの個人的な(!)責任だということを思い出してほしい。
どんな問題であっても彼の問題だ。
彼を責めたり罰したりすることを恐れてはいけない。
ただし、罰を有効なものにするためには、アーキテクトの行動に対して全力で応えるべきだということをを忘れてはいけない。
繰り返すが、彼の決定は最終決定だ。&lt;/p&gt;

&lt;p&gt;もしプロジェクトマネージャが製品の品質に満足せず、またアーキテクトがその状況を改善しないなら、アーキテクトを&lt;a href=&#34;http://www.yegor256.com/2015/09/16/how-to-fire-someone-right.html&#34;&gt;交代&lt;/a&gt;させる。
彼をプログラマに降格させ、他のプログラマをアーキテクトに昇格させる。
ただし、チームにアーキテクトは常に一人だけで、彼の決定が最終的なものであることを忘れてはいけない。&lt;/p&gt;

&lt;p&gt;それが完璧な製品を作れる可能性をもつただ一つの方法だ。&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;embed video-player&#34; style=&#34;text-align: center&#34;&gt;
  &lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;320&#34; height=&#34;193&#34; src=&#34;https://www.youtube.com/embed/0fuEgmibJc4&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上がYegorの記事。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/08/11/daily-stand-up-meetings-are-a-good-tool-for-a-bad-manager/&#34;&gt;スタンドアップミーティングに関する記事&lt;/a&gt;でも言っていた責任の委譲がこの記事でも触れられている。
プロジェクトマネージャは技術的な責任を誰かに委譲して、そいつをアーキテクトと呼べということだ。
責任には権限が伴うので、アーキテクトは技術面での最終決定権を持つ。&lt;/p&gt;

&lt;p&gt;それだけ。Yegorの他の記事に比べてシンプルな主張。
もう少し、アーキテクトが品質を確保するために何をすべきかといったことが書いてあると期待してたが。&lt;/p&gt;

&lt;p&gt;責任を委譲してそれに権限が付随するのか、権限を委譲してそれに責任が付随するのか、という細かい疑問はあるが、この記事の主な主張に対しては特に何も言うことがない。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>pcap-ng support in Pcap4J</title>
          <link>https://www.kaitoy.xyz/2016/01/10/pcap-ng-support-in-pcap4j/</link>
          <pubDate>Sun, 10 Jan 2016 09:52:06 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/01/10/pcap-ng-support-in-pcap4j/</guid>
          <description>

&lt;p&gt;Sometimes I receive inquiries about support for &lt;strong&gt;pcap-ng&lt;/strong&gt; files in &lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;&lt;strong&gt;Pcap4J&lt;/strong&gt;&lt;/a&gt;.
I wrote the result of my investigation on it in this article.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;what-s-a-pcap-ng-file&#34;&gt;What&amp;rsquo;s a pcap-ng file&lt;/h2&gt;

&lt;p&gt;A pcap-ng file (i.e. a file with &lt;code&gt;.pcapng&lt;/code&gt; extension ) is a packet dump file in &lt;a href=&#34;https://github.com/pcapng/pcapng&#34;&gt;&lt;strong&gt;The pcap Next Generation Capture File Format&lt;/strong&gt;&lt;/a&gt; (or pcap-ng format for short).
This format was created to overcome the limitations of the traditional &lt;a href=&#34;https://wiki.wireshark.org/Development/LibpcapFileFormat&#34;&gt;&lt;strong&gt;Libpcap File Format&lt;/strong&gt;&lt;/a&gt; (or pcap format for short) which is used in pcap files.&lt;/p&gt;

&lt;p&gt;Although the pcap format has been widely used for a long time, recent &lt;a href=&#34;https://www.wireshark.org/&#34;&gt;&lt;strong&gt;Wireshark&lt;/strong&gt;&lt;/a&gt;, the de facto standard packet capture tool, uses the pcap-ng format by default to save captured packets.
So, it&amp;rsquo;s expected that the pcap-ng format would be more common and pcap format would be a legacy in the future.&lt;/p&gt;

&lt;h2 id=&#34;pcap-ng-support-in-pcap4j&#34;&gt;pcap-ng support in Pcap4J&lt;/h2&gt;

&lt;p&gt;Of course Pcap4J supports traditional pcap format.
But how about the pcap-ng format?&lt;/p&gt;

&lt;p&gt;Whether Pcap4J can handle pcap-ng files is up to its underlying native library.
Remember Pcap4J is a wrapper library for &lt;a href=&#34;http://www.tcpdump.org/&#34;&gt;&lt;strong&gt;libpcap&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&#34;http://www.winpcap.org/&#34;&gt;&lt;strong&gt;WinPcap&lt;/strong&gt;&lt;/a&gt;.
If the libpcap/WinPcap supports the pcap-ng format Pcap4J does, and vice versa.&lt;/p&gt;

&lt;h2 id=&#34;pcap-ng-support-in-libpcap&#34;&gt;pcap-ng support in libpcap&lt;/h2&gt;

&lt;p&gt;The libpcap got limited support for reading pcap-ng files in &lt;a href=&#34;https://github.com/the-tcpdump-group/libpcap/blob/libpcap-1.1/CHANGES&#34;&gt;1.1.0&lt;/a&gt;, and then the following three bugs around the feature were fixed:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;filtering issue (fixed in 1.2.1)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/the-tcpdump-group/libpcap/issues/139&#34;&gt;pcap_datalink() returns wrong value&lt;/a&gt; (fixed in 1.1.2)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/the-tcpdump-group/libpcap/issues/349&#34;&gt;Wrong timestamps on big-endian machines&lt;/a&gt; (fixed in 1.7.2)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;No enhancement for pcap-ng support since 1.1.0 as of now (1.7.5).&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t know what &amp;ldquo;limited&amp;rdquo; means, but anyway it looked like Pcap4J 1.6.2 could read pcap-ng files without any problems as far as I tested it with libpcap 1.7.4.&lt;/p&gt;

&lt;p&gt;As for writing pcap-ng files, the libpcap doesn&amp;rsquo;t provide any support for it yet.&lt;/p&gt;

&lt;h2 id=&#34;pcap-ng-support-in-winpcap&#34;&gt;pcap-ng support in WinPcap&lt;/h2&gt;

&lt;p&gt;WinPcap is the Windows version of libpcap and each version of it is based on a certain version of libpcap.
The newest version of WinPcap, WinPcap 4.1.3, was developed with libpcap 1.0.0.
It means WinPcap doesn&amp;rsquo;t support pcap-ng format yet at all.&lt;/p&gt;

&lt;p&gt;But, there is an &lt;a href=&#34;http://sourceforge.net/projects/winpcap413-176/&#34;&gt;unofficial build of WinPcap based on libpcap 1.7.4&lt;/a&gt;.
As far as I tested this WinPcap through Pcap4J 1.6.2, it worked well on reading pcap-ng files as well as on basic functionalities such as finding network devices and live capture except &lt;a href=&#34;https://github.com/kaitoy/pcap4j/issues/52&#34;&gt;getting capture statistics&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;how-to-read-a-pcap-ng-file&#34;&gt;How to read a pcap-ng file&lt;/h2&gt;

&lt;p&gt;How to read a pcap-ng file is exactly the same as how to read a pcap file.&lt;/p&gt;

&lt;p&gt;Use &lt;a href=&#34;http://kaitoy.github.io/pcap4j/javadoc/latest/en/org/pcap4j/core/Pcaps.html#openOffline%28java.lang.String%29&#34;&gt;&lt;code&gt;Pcaps.openOffline()&lt;/code&gt;&lt;/a&gt; to open a pcap-ng file and call read methods such as &lt;a href=&#34;http://kaitoy.github.io/pcap4j/javadoc/latest/en/org/pcap4j/core/PcapHandle.html#getNextPacketEx%28%29&#34;&gt;&lt;code&gt;getNextPacketEx()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;http://kaitoy.github.io/pcap4j/javadoc/latest/en/org/pcap4j/core/PcapHandle.html#loop%28int,%20org.pcap4j.core.PacketListener%29&#34;&gt;&lt;code&gt;loop()&lt;/code&gt;&lt;/a&gt; on the returned &lt;a href=&#34;http://kaitoy.github.io/pcap4j/javadoc/latest/en/org/pcap4j/core/PcapHandle.html&#34;&gt;&lt;code&gt;PcapHandle&lt;/code&gt;&lt;/a&gt; object to get packets in the file.&lt;/p&gt;

&lt;p&gt;For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void main(String args[]) throws PcapNativeException, NotOpenException {
  PcapHandle ph = Pcaps.openOffline(&amp;quot;/path/to/test.pcapng&amp;quot;);
  ph.setFilter(&amp;quot;tcp&amp;quot;, BpfProgram.BpfCompileMode.OPTIMIZE);
  while (true) {
    try {
      Packet p = ph.getNextPacketEx();
      if (p != null) {
        System.out.println(p);
      }
    } catch (EOFException e) {
      System.out.println(&amp;quot;End of file&amp;quot;);
      break;
    } catch (TimeoutException e) {
      System.out.println(&amp;quot;Timed out&amp;quot;);
      break;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;If you try to read a pcap-ng file using Pcap4J with a native library which doesn&amp;rsquo;t support pcap-ng format, Pcap4J throws &lt;a href=&#34;http://kaitoy.github.io/pcap4j/javadoc/latest/en/org/pcap4j/core/PcapNativeException.html&#34;&gt;&lt;code&gt;PcapNativeException&lt;/code&gt;&lt;/a&gt; as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Exception in thread &amp;quot;main&amp;quot; org.pcap4j.core.PcapNativeException: bad dump file format
        at org.pcap4j.core.Pcaps.openOffline(Pcaps.java:203)
        at Test.main(Test.java:16)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>オブジェクト指向プログラミングにおいてユーティリティクラスに代わるもの</title>
          <link>https://www.kaitoy.xyz/2016/01/03/oop-alternative-to-utility-classes/</link>
          <pubDate>Sun, 03 Jan 2016 23:36:01 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/01/03/oop-alternative-to-utility-classes/</guid>
          <description>

&lt;p&gt;このエントリでは、Yegor Bugayenkoによる記事、&lt;a href=&#34;http://www.yegor256.com/2014/05/05/oop-alternative-to-utility-classes.html&#34;&gt;OOP Alternative to Utility Classes&lt;/a&gt;を紹介する。
(Yegorから和訳と転載の許可は得た。)
以下はその全文の和訳だが、意訳超訳が混じっているので、もとのニュアンスを知りたければ元記事を読んでもいいし、読まなくてもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;ユーティリティクラス(またはヘルパークラス)は、スタティックメソッドだけを持っていて、状態を内包しない「構造体」だ。
&lt;a href=&#34;http://commons.apache.org/&#34;&gt;Apache Commons&lt;/a&gt;の&lt;code&gt;StringUtils&lt;/code&gt;、&lt;code&gt;IOUtils&lt;/code&gt;、&lt;code&gt;FileUtils&lt;/code&gt;や、&lt;a href=&#34;https://code.google.com/p/guava-libraries/&#34;&gt;Guava&lt;/a&gt;の&lt;code&gt;Iterables&lt;/code&gt;、&lt;code&gt;Iterators&lt;/code&gt;、またJDK7の&lt;code&gt;Files&lt;/code&gt;はユーティリティクラスのいい例だ。&lt;/p&gt;

&lt;p&gt;ユーティリティクラスはよく使われる共通機能を提供するので、この設計手法はJava(やC#、Rubyなど)の世界でとても人気だ。&lt;/p&gt;

&lt;p&gt;要するに我々は、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Don&#39;t_repeat_yourself&#34;&gt;DRY原則&lt;/a&gt;に従い、重複を避けたい。
だから、共通コードをユーティリティクラスに入れて必要に応じて再利用する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// これはひどい設計なので再利用しないように。
public class NumberUtils {
  public static int max(int a, int b) {
    return a &amp;gt; b ? a : b;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実際、これはとても便利なテクニックだ!?&lt;/p&gt;

&lt;h2 id=&#34;ユーティリティクラスは悪だ&#34;&gt;ユーティリティクラスは悪だ&lt;/h2&gt;

&lt;p&gt;しかし、オブジェクト指向の世界では、ユーティリティクラスはかなり悪い(酷いという人さえいるかもしれない)手法だ。&lt;/p&gt;

&lt;p&gt;これについては多くの議論がある。
いくつか挙げると、Nick Malikの「&lt;a href=&#34;http://blogs.msdn.com/b/nickmalik/archive/2005/09/06/461404.aspx&#34;&gt;ヘルパークラスは悪か?&lt;/a&gt;」、Simon Hartの「&lt;a href=&#34;http://smart421.wordpress.com/2011/08/31/why-helper-singletons-and-utility-classes-are-mostly-bad-2/&#34;&gt;なぜヘルパー、シングルトン、ユーティリティクラスはだいたい間違っているのか&lt;/a&gt;」、Marshal Wardの「&lt;a href=&#34;http://www.marshallward.org/avoiding-utility-classes.html&#34;&gt;ユーティリティクラスを避ける&lt;/a&gt;」、Dhaval Dalalの「&lt;a href=&#34;http://www.jroller.com/DhavalDalal/entry/kill_that_util_class&#34;&gt;ユーティルクラスを殺せ!&lt;/a&gt;」、Rob Bagbyの「&lt;a href=&#34;http://www.robbagby.com/posts/helper-classes-are-a-code-smell/&#34;&gt;ヘルパークラスは問題の兆候&lt;/a&gt;」。&lt;/p&gt;

&lt;p&gt;また、StackExchangeにはユーティリティクラスについての質問がいくつかある。
例えば、「&lt;a href=&#34;http://stackoverflow.com/questions/3339929/if-a-utilities-class-is-evil-where-do-i-put-my-generic-code&#34;&gt;ユーティリティクラスが悪なら、どこに共通コードを書けばいい?&lt;/a&gt;」とか、「&lt;a href=&#34;http://stackoverflow.com/questions/3340032/utility-classes-are-evil&#34;&gt;ユーティリティクラスは悪&lt;/a&gt;」とか。&lt;/p&gt;

&lt;p&gt;これらの主張は要するに、ユーティリティクラスは適切なオブジェクトではないということだ。
だから、オブジェクト指向の世界に適合しない。
ユーティリティクラスは、当時の人々が機能分割パラダイムに慣れていたために、手続き型言語から受け継がれた。&lt;/p&gt;

&lt;p&gt;君がこの主張に同意し、ユーティリティクラスを使うのをやめたがっていると想定し、そいつをどのように適切なオブジェクトに置き換えるかを例を挙げながら教えよう。&lt;/p&gt;

&lt;h2 id=&#34;手続き型の例&#34;&gt;手続き型の例&lt;/h2&gt;

&lt;p&gt;例えば、テキストファイルを読んで、行で分割し、各行をトリムして、その結果を別のファイルに保存したいとする。
これはApache Commonsの&lt;code&gt;FileUtils&lt;/code&gt;を使えばできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;void transform(File in, File out) {
  Collection&amp;lt;String&amp;gt; src = FileUtils.readLines(in, &amp;quot;UTF-8&amp;quot;);
  Collection&amp;lt;String&amp;gt; dest = new ArrayList&amp;lt;&amp;gt;(src.size());
  for (String line : src) {
    dest.add(line.trim());
  }
  FileUtils.writeLines(out, dest, &amp;quot;UTF-8&amp;quot;);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上のコードはきれいに見える。
しかし、これは手続き型プログラミングであって、オブジェクト指向じゃない。
コードの各行で、データ(byteとbit)を操作し、コンピューターにどこからデータを取ってどこに書き込むかを明示的に指示している。
処理の手順を定義している。&lt;/p&gt;

&lt;h2 id=&#34;オブジェクト指向な方法&#34;&gt;オブジェクト指向な方法&lt;/h2&gt;

&lt;p&gt;オブジェクト指向パラダイムでは、オブジェクトをインスタンス化して合成すべきだ。
これはオブジェクトにオブジェクト自身のやり方でデータを管理させるためだ。
補足的なスタティックメソッドを呼ぶ代わりに、求めている挙動を提供できるオブジェクトを生成するべきだ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class Max implements Number {
  private final int a;
  private final int b;
  public Max(int x, int y) {
    this.a = x;
    this.b = y;
  }
  @Override
  public int intValue() {
    return this.a &amp;gt; this.b ? this.a : this.b;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下の手続き型のメソッド呼び出しは、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;int max = NumberUtils.max(10, 5);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下の様にオブジェクト指向的になる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;int max = new Max(10, 5).intValue();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;どっちでも同じ?
いや、そうでもない。
もう少し読み進めて欲しい。&lt;/p&gt;

&lt;h2 id=&#34;データ構造ではなくオブジェクト&#34;&gt;データ構造ではなくオブジェクト&lt;/h2&gt;

&lt;p&gt;私なら、上と同じファイル編集機能をオブジェクト指向なやり方で以下の様に設計する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;void transform(File in, File out) {
  Collection&amp;lt;String&amp;gt; src = new Trimmed(
    new FileLines(new UnicodeFile(in))
  );
  Collection&amp;lt;String&amp;gt; dest = new FileLines(
    new UnicodeFile(out)
  );
  dest.addAll(src);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(訳注: 上のコードは以下のコードの誤記だと思われる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;void transform(File in, File out) {
  Trimmed src = new Trimmed(
    new FileLines(new UnicodeFile(in))
  );
  FileLines dest = new FileLines(
    new UnicodeFile(out)
  );
  dest.addAll(src);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;FileLines&lt;/code&gt;は&lt;code&gt;Collection&amp;lt;String&amp;gt;&lt;/code&gt;を実装していて、ファイルの読み込みと書き込みの処理を内包している。
&lt;code&gt;FileLines&lt;/code&gt;のインスタンスは文字列のコレクションと全く同じ挙動をし、全てのI/O処理を隠蔽している。
このインスタンスを繰り返し処理するとファイルが読み込まれる。
このインスタンスに&lt;code&gt;addAll()&lt;/code&gt;するとファイルに書き込まれる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Trimmed&lt;/code&gt;も&lt;code&gt;Collection&amp;lt;String&amp;gt;&lt;/code&gt;を実装していて、文字列のコレクションを内包している(&lt;a href=&#34;https://ja.wikipedia.org/wiki/Decorator_%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3&#34;&gt;Decoratorパターン&lt;/a&gt;)。
一行が取得されるたびにトリムされる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Trimmed&lt;/code&gt;も&lt;code&gt;FileLines&lt;/code&gt;も&lt;code&gt;UnicodeFile&lt;/code&gt;も、上記スニペットに出てくる全てのクラスは小さめだ。
それぞれが自身の単一の機能に責任を持ち、つまり&lt;a href=&#34;http://d.hatena.ne.jp/asakichy/20110808/1312754662&#34;&gt;単一責任原則&lt;/a&gt;に完璧に従っている。&lt;/p&gt;

&lt;p&gt;我々側、つまりライブラリのユーザから見るとこれはそれほど重要ではないかもしれないが、ライブラリの開発者から見ると肝要だ。
80以上のメソッドを持つ3000行のユーティリティクラスである&lt;code&gt;FileUtils&lt;/code&gt;の&lt;code&gt;readLines()&lt;/code&gt;よりも、&lt;code&gt;FileLines&lt;/code&gt;の方が開発やメンテナンスやユニットテストがしやすい。
真面目な話、&lt;a href=&#34;http://svn.apache.org/viewvc/commons/proper/io/trunk/src/main/java/org/apache/commons/io/FileUtils.java?view=co&#34;&gt;そのソース&lt;/a&gt;を読んでみて欲しい。&lt;/p&gt;

&lt;p&gt;オブジェクト指向のアプローチは遅延実行を可能にする。
&lt;code&gt;in&lt;/code&gt;ファイルはそのデータが必要になるまで読まれない。
I/Oエラーで開けなかったら触られすらしない。
全ては&lt;code&gt;addAll()&lt;/code&gt;を呼んだ後に始まる。&lt;/p&gt;

&lt;p&gt;二つ目のスニペットの最終行を除く全行は、小さいオブジェクトをインスタンス化して大きいオブジェクトを合成している。
このオブジェクト合成は、データ変換を起こさないのでCPUコストはむしろ低い。&lt;/p&gt;

&lt;p&gt;さらに、二つ目のスクリプトがO(1)の空間計算量で動くのに対し、一つ目のスクリプトはO(n)で動くのは明らかだ。
これが一つ目のスクリプトでデータに対して手続き型アプローチをした結果だ。&lt;/p&gt;

&lt;p&gt;オブジェクト指向の世界では、データというものはない。オブジェクトとその挙動しかないのだ！&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;embed video-player&#34; style=&#34;text-align: center&#34;&gt;
  &lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;320&#34; height=&#34;193&#34; src=&#34;https://www.youtube.com/embed/psrp3TtaYYI&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上がYegorの記事。&lt;/p&gt;

&lt;p&gt;私はユーティリティクラスは結構好きで、以下の点で有用だと思う。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ライブラリ開発者視点:

&lt;ul&gt;
&lt;li&gt;少数のクラスで多くの共通処理を実装できる。&lt;/li&gt;
&lt;li&gt;ユーティリティクラスは(普通)状態を持たないので、マルチスレッドなどを意識せずに簡単に書ける。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ライブラリ利用者視点:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;オブジェクトを作らなくても使えるので、オーバーヘッドが少なくコードを書くのも楽。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ユーティリティクラスのメソッド呼び出しは大抵、「&amp;lt;問題領域&amp;gt;.&amp;lt;動詞&amp;gt;&amp;lt;目的語&amp;gt;()」という形になっていて、何をやっているのかわかりやすい。&lt;/p&gt;

&lt;p&gt;上で出てきた&lt;code&gt;FileUtils.readLines()&lt;/code&gt;も、ファイルを対象に(問題領域)、行を(目的語)読みこむ(動詞)メソッドであることが一目瞭然。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ユーティリティクラス反対派の主張が、それがオブジェクト真理教の教義に照らして適切なオブジェクトではなく、オブジェクト指向の世界に適合しないという哲学的なものである時点で、ユーティリティクラスをやめる動機に全くつながらない。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;transform()&lt;/code&gt;の実装は、Apache Commonsを使ったやつの方が自分でクラスを作らなくて済み、開発量が少なくてよい、というのが普通の感覚ではないだろうか。&lt;/p&gt;

&lt;p&gt;さらに、Yegorの&lt;code&gt;transform()&lt;/code&gt;の実装だと、I/O処理を隠蔽しすぎて何をやっているのかコードからさっぱりわからない。
&lt;code&gt;addAll()&lt;/code&gt;するとファイルへの書き込みが発生するなんて誰も想像だにしまい。
オブジェクト真理教の神のみぞ知るといった感じの挙動だ。
こんなコードで可読性、つまり保守性が「手続き型の例」のやつより高くなるとは到底思えない。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>git resetとrevertを図解する</title>
          <link>https://www.kaitoy.xyz/2016/01/01/git-revert-reset/</link>
          <pubDate>Fri, 01 Jan 2016 18:38:02 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2016/01/01/git-revert-reset/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;この記事&lt;/a&gt;を読んだ、またはGitのオブジェクトモデルを理解していることを前提に、&lt;a href=&#34;https://git-scm.com/&#34;&gt;&lt;strong&gt;Git&lt;/strong&gt;&lt;/a&gt;の &lt;code&gt;git revert&lt;/code&gt; と &lt;code&gt;git reset&lt;/code&gt;というコマンドについて説明する。
この二つはしばしばコミットを取り消すコマンドとして同じ文脈で説明されることが多いのでこのエントリでも一緒に説明するが、実際は全く異なるコマンドだし、そもそもどちらもコミットを取り消すコマンドではない。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;git-revert&#34;&gt;git revert&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;git revert&lt;/code&gt;は、指定したコミットが持ち込んだ変更を打ち消すコミットを追加する。
リバースパッチを適用すると言ってもよい。
コミットを追加しかしないので、このコマンドによって既存のコミットが消えたり変わったりすることはない。&lt;/p&gt;

&lt;p&gt;図にすると以下の感じ。単純。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-revert-reset/git_revert/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-revert-reset/git_revert/スライド2.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;git-reset&#34;&gt;git reset&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;git reset&lt;/code&gt;には二つの機能がある。
インデックスを再設定する(i.e. resetする)機能と、&lt;code&gt;HEAD&lt;/code&gt;を付け替える(i.e. resetする)機能だ。&lt;/p&gt;

&lt;h4 id=&#34;インデックスの再設定&#34;&gt;インデックスの再設定&lt;/h4&gt;

&lt;p&gt;インデックスの再設定をするコマンドは&lt;code&gt;git reset &amp;lt;ワーキングディレクトリ内のファイルのパス(複数可)&amp;gt;&lt;/code&gt;。
これを実行すると、指定したファイルについて、&lt;code&gt;HEAD&lt;/code&gt;が指すコミットが指すツリー内のブロブを指すようインデックスを更新する。&lt;/p&gt;

&lt;p&gt;何を言っているのかわからないので図にする。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-revert-reset/git_reset_path/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-revert-reset/git_reset_path/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-revert-reset/git_reset_path/スライド3.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(この図では便宜的に&lt;code&gt;HEAD&lt;/code&gt;、つまり参照をオブジェクト格納領域内に書いているが、実際には別の場所にあることに注意。)&lt;/p&gt;

&lt;p&gt;図を見ると、&lt;code&gt;git add Readme.md&lt;/code&gt;と&lt;code&gt;git reset Readme.md&lt;/code&gt;がだいたい逆のことをしていることがわかる。
要するに、&lt;code&gt;git add &amp;lt;パス&amp;gt;&lt;/code&gt;は指定したファイルをステージし、&lt;code&gt;git reset &amp;lt;パス&amp;gt;&lt;/code&gt;は指定したファイルをアンステージする。&lt;/p&gt;

&lt;h4 id=&#34;headの付け替え&#34;&gt;HEADの付け替え&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;HEAD&lt;/code&gt;の付け替えをするコマンドは&lt;code&gt;git reset &amp;lt;コミット&amp;gt;&lt;/code&gt;。
これを実行すると、&lt;code&gt;HEAD&lt;/code&gt;が指しているコミットを指すよう&lt;code&gt;ORIG_HEAD&lt;/code&gt;を作成または更新し、指定したコミットを指すよう&lt;code&gt;HEAD&lt;/code&gt;を更新する。
オプションによってはさらにインデックスやワーキングディレクトリを指定したコミットが指すツリーと同期するよう更新する。&lt;/p&gt;

&lt;p&gt;このオプションには&lt;code&gt;--soft&lt;/code&gt;、&lt;code&gt;--mixed&lt;/code&gt; (デフォルト)、&lt;code&gt;--hard&lt;/code&gt;の三種類があり、それぞれのオプションを付けた時の更新対象を次の表に示す。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;オプション&lt;/th&gt;
&lt;th&gt;HEAD&lt;/th&gt;
&lt;th&gt;インデックス&lt;/th&gt;
&lt;th&gt;ワーキングディレクトリ&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;--soft&lt;/td&gt;
&lt;td&gt;○&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;--mixed&lt;/td&gt;
&lt;td&gt;○&lt;/td&gt;
&lt;td&gt;○&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;--hard&lt;/td&gt;
&lt;td&gt;○&lt;/td&gt;
&lt;td&gt;○&lt;/td&gt;
&lt;td&gt;○&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;この三者の違いについては面倒だしだいたい分かるはずなので図にしないが、&lt;code&gt;git reset &amp;lt;コミット&amp;gt;&lt;/code&gt;したときの&lt;code&gt;HEAD&lt;/code&gt;動きについて次に図示する。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-revert-reset/git_reset_commit/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-revert-reset/git_reset_commit/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-revert-reset/git_reset_commit/スライド3.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;スライド中で&lt;code&gt;git reset HEAD^&lt;/code&gt;した時点で、コミットDは実質的に削除されたに近い状態になる。
&lt;code&gt;ORIG_HEAD&lt;/code&gt;という一時的なシンボリック参照で指されているだけで、どの参照からもたどり着けなくなるからだ。
コミットDはいずれ&lt;code&gt;git gc&lt;/code&gt;によって実際に削除されるはずだし、&lt;code&gt;git push&lt;/code&gt;してもコミットD、それが指すツリー、そのツリーの下にしかないブロブはリモートリポジトリに送られない。&lt;/p&gt;

&lt;p&gt;よって、&lt;code&gt;git reset &amp;lt;コミット&amp;gt;&lt;/code&gt;は普通コミットを削除したいときに使われる。
使われはするが、このコマンド自体がコミットを削除するわけではなくて、あくまで&lt;code&gt;HEAD&lt;/code&gt;を付け替えるコマンドであることを覚えていた方がいざというときに助かる。&lt;/p&gt;

&lt;p&gt;因みに上のスライドでやった操作は、&lt;code&gt;git commit --amend&lt;/code&gt;がやることとほぼ同じ。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Gitの分散バージョン管理の仕組み</title>
          <link>https://www.kaitoy.xyz/2015/12/31/git-dvc/</link>
          <pubDate>Thu, 31 Dec 2015 01:02:59 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/12/31/git-dvc/</guid>
          <description>

&lt;p&gt;このエントリでは、&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;この記事&lt;/a&gt;を読んだ、またはGitのオブジェクトモデルを理解していることを前提に、&lt;a href=&#34;https://git-scm.com/&#34;&gt;&lt;strong&gt;Git&lt;/strong&gt;&lt;/a&gt;の分散バージョン管理の仕組みについて説明する。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;gitの分散バージョン管理&#34;&gt;Gitの分散バージョン管理&lt;/h2&gt;

&lt;p&gt;分散バージョン管理とは、分散したリポジトリでのバージョン管理ということ。
ここでリポジトリが分散しているとは、同じプロジェクトの履歴を管理する完全で独立したリポジトリが複数あるということ。
これにより一つのプロジェクトの開発を地理的に分散して並行して進めることができる。&lt;/p&gt;

&lt;p&gt;Gitは分散バージョン管理のために、リポジトリのクローン(≒コピー)を作る機能と、リポジトリ間でコミットグラフを同期する機能を提供している。&lt;/p&gt;

&lt;p&gt;リポジトリのクローンを作ると言うと、オリジナルとクローンの間に格差があるような気がするが、
実際にはGitは全てのリポジトリが対等であるという思想のもとで実装されている。
このため、リポジトリをクローンする時には(デフォルトで)クローン元の完全なコミットグラフがクローンにコピーされるし、任意のリポジトリ間のデータのやり取りをpeer-to-peerでできる。
クローンからクローンを作ることももちろん可能。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git push&lt;/code&gt;でデータを送る先をアップストリームと呼ぶことはあるし、次節でローカルリポジトリとリモートリポジトリという関係が出てくるが、これはあくまでその時点でそういう設定になっているというだけ。
アップストリームはいつでもいくつでも&lt;code&gt;git remote&lt;/code&gt;コマンドで追加したり削除したりできる。&lt;/p&gt;

&lt;p&gt;このような実装により、Gitの分散バージョン管理ではリポジトリ間で柔軟なデータのやり取りができる。
例えば以下の様な複雑なリポジトリネットワークを組むこともできる。&lt;/p&gt;

&lt;p&gt;&lt;img alt=&#34;good-object-2.png&#34; src=&#34;https://www.kaitoy.xyz/images/git-dvc/repo_net.png&#34; style=&#34;width: 100%; max-width: 400px; margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;h2 id=&#34;ローカルリポジトリとリモートリポジトリ&#34;&gt;ローカルリポジトリとリモートリポジトリ&lt;/h2&gt;

&lt;p&gt;一人の開発者から見て、手元にあるリポジトリを &lt;strong&gt;ローカルリポジトリ&lt;/strong&gt; と呼ぶのに対して、&lt;code&gt;git push&lt;/code&gt;や&lt;code&gt;git pull&lt;/code&gt;や&lt;code&gt;git fetch&lt;/code&gt;でデータをやり取りする相手のリポジトリを &lt;strong&gt;リモートリポジトリ&lt;/strong&gt; と呼ぶ。
リモートリポジトリとのやり取りは、&lt;strong&gt;リモート追跡ブランチ&lt;/strong&gt; と &lt;strong&gt;リモート&lt;/strong&gt; というものを使って実装されている。&lt;/p&gt;

&lt;h4 id=&#34;リモート追跡ブランチ&#34;&gt;リモート追跡ブランチ&lt;/h4&gt;

&lt;p&gt;リモート追跡ブランチは、ローカルリポジトリの&lt;code&gt;.git/refs/remotes/&lt;/code&gt;に格納される参照で、リモートリポジトリ内のローカルブランチのコミットグラフを取得してローカルリポジトリ内に保持するために使われる。
&lt;code&gt;git branch -r&lt;/code&gt;でその一覧が見れる。&lt;/p&gt;

&lt;p&gt;「追跡」ブランチというだけあって、リモートリポジトリ内でコミットグラフが成長した場合、この変更に追随することができる。
このためのコマンドが&lt;code&gt;git fetch&lt;/code&gt;。
因みに&lt;code&gt;git pull&lt;/code&gt;は、&lt;code&gt;git fetch&lt;/code&gt;でリモート追跡ブランチを更新した後、&lt;code&gt;git merge&lt;/code&gt;(オプションによっては&lt;code&gt;git rebase&lt;/code&gt;)でそのリモート追跡ブランチをローカルブランチにマージするのと同じ。&lt;/p&gt;

&lt;h4 id=&#34;リモート&#34;&gt;リモート&lt;/h4&gt;

&lt;p&gt;リモートとは、リモートリポジトリのこと、またはリモートリポジトリに接続するための定義のこと。
この定義は、ローカルリポジトリの&lt;code&gt;.git/config&lt;/code&gt;に&lt;code&gt;remote&lt;/code&gt;セクションとして書かれている。
以下がその例。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[remote &amp;quot;origin&amp;quot;]
        fetch = +refs/heads/*:refs/remotes/origin/*
        url = git@github.com:kaitoy/blog.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;セクション名のところに&lt;code&gt;&amp;quot;origin&amp;quot;&lt;/code&gt;とあるがこれは、この定義で接続するリモートリポジトリをGitコマンドなどで&lt;code&gt;origin&lt;/code&gt;と指定できるということ。
ここで定義されているのは&lt;code&gt;url&lt;/code&gt;と&lt;code&gt;fetch&lt;/code&gt;で、それぞれ以下を意味する。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;url&lt;/p&gt;

&lt;p&gt;リモートリポジトリのURL。
つまり、リモートリポジトリがどのサーバのどのディレクトリにあって、それとのデータのやり取りをどのプロトコルでやるかという定義。
このURLには以下の書式が使える。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;ファイルパス&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/path/to/repo.git&lt;/code&gt;とか&lt;code&gt;C:\\Users\\Kaito\\Desktop\\pcap4j&lt;/code&gt;といった、普通のファイルパスの書式。
&lt;a href=&#34;https://ja.wikipedia.org/wiki/Network_File_System&#34;&gt;NFS&lt;/a&gt;などでリモートリポジトリが共有されている場合などに使われる。&lt;/p&gt;

&lt;p&gt;シンボリックリンクがサポートされているOS上では、クローンはリモートリポジトリをハードリンクで参照する。
このシンボリック参照でのファイル共有がトラブルの元なため、この書式は非推奨。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;ファイルURL&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;file:///path/to/repo.git&lt;/code&gt;とか&lt;code&gt;file://C:/Users/Kaito/Desktop/pcap4j&lt;/code&gt;といった、ローカルホスト上のパスを示すファイルURLの書式。
用途はファイルパスと同様だが、ハードリンクを作る代わりにコピーするのでより安全。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;HTTP(S)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;https://github.com/kaitoy/pcap4j.git&lt;/code&gt;といったHTTPSやHTTPのURL。
リポジトリへのアクセス制御にHTTPの認証機能やHTTPSのクライアント証明書などが使えるほか、HTTPSなら通信の暗号化もできる。&lt;/p&gt;

&lt;p&gt;使用するポートがファイアウォールにブロックされていることが少ないのも使いやすい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Gitプロトコル&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git://example.com/path/to/repo.git&lt;/code&gt;といった書式で、&lt;a href=&#34;https://git-scm.com/book/ja/v1/Git-%E3%82%B5%E3%83%BC%E3%83%90%E3%83%BC-Git-%E3%83%87%E3%83%BC%E3%83%A2%E3%83%B3&#34;&gt;Gitデーモン&lt;/a&gt;によるGitネイティブプロトコルを使うURL。
HTTPよりも高速な通信ができるが、認証機能も暗号化機能もない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;SSH + Gitプロトコル&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ssh://git@github.com/kaitoy/pcap4j.git&lt;/code&gt;のような&lt;a href=&#34;https://ja.wikipedia.org/wiki/Secure_Shell&#34;&gt;SSH&lt;/a&gt;のURLで、これを使うとSSHトンネルを通してGitプロトコルで通信できる。
Gitプロトコル単体を使うのに比べ、SSHの認証機能と暗号化機能を利用できるが、やや遅くなるはず。&lt;/p&gt;

&lt;p&gt;このプロトコルには、&lt;code&gt;git@github.com:kaitoy/pcap4j.git&lt;/code&gt;のような&lt;a href=&#34;https://ja.wikipedia.org/wiki/Secure_copy&#34;&gt;SCP&lt;/a&gt;書式も使える。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Git自体はGitデーモンを含めリポジトリへのアクセス制御の機能を一切持たないので、認証などが必要な場合はHTTPなどその機能を持つプロトコルのURLを使う必要がある。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;fetch&lt;/p&gt;

&lt;p&gt;リモートリポジトリ内のローカルブランチとローカルリポジトリ内の追跡ブランチとがどう対応するかを定義する。
この定義は&lt;code&gt;refspec&lt;/code&gt;と呼ばれる。&lt;/p&gt;

&lt;p&gt;上の例の&lt;code&gt;fetch = +refs/heads/*:refs/remotes/origin/*&lt;/code&gt;だと、リモートリポジトリの&lt;code&gt;.git/refs/heads/&lt;/code&gt;にある全てのブランチをそれぞれ、ローカルリポジトリの&lt;code&gt;.git/refs/remotes/origin/&lt;/code&gt;にある同名のブランチで追跡する、という意味。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;クローン時の挙動&#34;&gt;クローン時の挙動&lt;/h2&gt;

&lt;p&gt;クローン時のデフォルトの挙動は以下の様なもの。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;オブジェクト格納領域内のオブジェクトが全てクローンにコピーされる。
(多分。参照からたどれないオブジェクトもコピーされることを確認した。)
つまり、元のリポジトリ(i.e. リモートリポジトリ)と同じコミットグラフ(とタグオブジェクト)がクローンのリポジトリに入る。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;リモートリポジトリ内の全てのローカルブランチに対応する同名のリモート追跡ブランチがクローンのリポジトリ内に作成される。
これに対応するリモートも作成され、これの&lt;code&gt;fetch&lt;/code&gt;に(前節の例と同様に)&lt;code&gt;+refs/heads/*:refs/remotes/origin/*&lt;/code&gt;が設定される。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;リモートリポジトリのカレントブランチがローカルリポジトリにコピーされ、チェックアウトされる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;リモートリポジトリの全てのタグがクローンにコピーされる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ローカルリポジトリで&lt;code&gt;git fetch&lt;/code&gt;が実行され、全てのリモート追跡ブランチが更新される。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;インデックスはリポジトリ毎に固有の一時的なデータなので、クローンにはコピーされない。&lt;/p&gt;

&lt;p&gt;リモート追跡ブランチもクローンにコピーされない。&lt;/p&gt;

&lt;p&gt;シンボリック参照もクローンにコピーされない。
クローンにはカレントブランチを指す&lt;code&gt;HEAD&lt;/code&gt;だけが作成される。&lt;/p&gt;

&lt;h2 id=&#34;リモートリポジトリとのやり取りの図解&#34;&gt;リモートリポジトリとのやり取りの図解&lt;/h2&gt;

&lt;p&gt;リモートリポジトリをクローンして、変更をプルしたりプッシュしたりする様子を以下に図示する。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-dvc/git_dvc_merge/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-dvc/git_dvc_merge/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-dvc/git_dvc_merge/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-dvc/git_dvc_merge/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-dvc/git_dvc_merge/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-dvc/git_dvc_merge/スライド6.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;これはこれで完全に正しい手順だが、最終的にできるコミットグラフが無駄に分岐していて美しくない。
普通は以下の様に、リベースを挟んで一直線の履歴に保つ方が一般にいいと思う。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-dvc/git_dvc_ff/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-dvc/git_dvc_ff/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-dvc/git_dvc_ff/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-dvc/git_dvc_ff/スライド4.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;このフェッチ + リベースを一度にやってくれるのが、&lt;code&gt;git pull --rebase&lt;/code&gt;。&lt;/p&gt;

&lt;h2 id=&#34;gitで分散バージョン管理する際の注意点&#34;&gt;Gitで分散バージョン管理する際の注意点&lt;/h2&gt;

&lt;p&gt;Gitで分散バージョン管理する際の注意点を二つ挙げる。&lt;/p&gt;

&lt;h4 id=&#34;他のリポジトリにもあるコミットを変更してはいけない&#34;&gt;他のリポジトリにもあるコミットを変更してはいけない&lt;/h4&gt;

&lt;p&gt;Gitには、&lt;code&gt;git commit --amend&lt;/code&gt;、&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/28/git-merge/#%E3%83%AA%E3%83%99%E3%83%BC%E3%82%B9&#34;&gt;&lt;code&gt;git rebase&lt;/code&gt;&lt;/a&gt;といったコミットを変更するコマンドや、&lt;a href=&#34;https://www.kaitoy.xyz/2016/01/01/git-revert-reset/#git-reset&#34;&gt;&lt;code&gt;git reset&lt;/code&gt;&lt;/a&gt;というコミットの削除につながるコマンドがある。
こういうコマンドで他のリポジトリにもあるコミットを変更してはいけない。&lt;/p&gt;

&lt;p&gt;他のリポジトリにもあるコミットとは、クローン時にコピーしてきたコミット、プルしたコミット、プッシュしたコミットなどのこと。&lt;/p&gt;

&lt;p&gt;もしやると、プッシュもプルも簡単にはできなくなり非常に面倒なことになる。&lt;/p&gt;

&lt;h4 id=&#34;開発リポジトリには-基本的に-プッシュしてはいけない&#34;&gt;開発リポジトリには(基本的に)プッシュしてはいけない&lt;/h4&gt;

&lt;p&gt;リポジトリには、&lt;strong&gt;ベアリポジトリ&lt;/strong&gt; と、&lt;strong&gt;開発リポジトリ&lt;/strong&gt; がある。
開発リポジトリは普段使っている普通のリポジトリ。
ベアリポジトリは、簡単に言うとワーキングディレクトリやカレントブランチやリモートを持たないリポジトリで、開発リポジトリのリモートリポジトリとして使われ、&lt;code&gt;git init&lt;/code&gt;や&lt;code&gt;git clone&lt;/code&gt;に&lt;code&gt;--bare&lt;/code&gt;オプションを付けて実行すると作れる。&lt;/p&gt;

&lt;p&gt;ベアリポジトリにはプッシュしていい。
むしろプッシュしないベアリポジトリに意味はない。&lt;/p&gt;

&lt;p&gt;一方、開発リポジトリには(基本的に)プッシュしてはいけない。
これは、プッシュがリモートリポジトリのオブジェクトと参照だけ更新してワーキングディレクトリやインデックスは更新せず、開発者がプッシュされたことに気付けないため(※1)。
気付かないまま開発を進めてコミットを作ると、プッシュによって&lt;code&gt;HEAD&lt;/code&gt;が変わっていたりするため、コミットグラフが変な状態になってしまう。&lt;/p&gt;

&lt;p&gt;お互い示し合わせたうえでプッシュをしたりプッシュするブランチを工夫したりすれば問題が起きないようにできるはできる。&lt;/p&gt;

&lt;p&gt;(※1: と&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873114408/&#34;&gt;O&amp;rsquo;Reillyの蝙蝠本&lt;/a&gt;には書いてあったが、これは&lt;a href=&#34;https://github.com/git/git/blob/master/Documentation/RelNotes/1.7.0.txt&#34;&gt;Git 1.6.xまでの話らしい&lt;/a&gt;。
今はチェックアウトされたブランチにはデフォルトでプッシュできないので、この節に書いた問題は基本的に起きない。
2.6.3で試したら以下のエラーになった。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;remote: error: refusing to update checked out branch: refs/heads/master
remote: error: By default, updating the current branch in a non-bare repository
remote: error: is denied, because it will make the index and work tree inconsistent
remote: error: with what you pushed, and will require &#39;git reset --hard&#39; to match
remote: error: the work tree to HEAD.
remote: error:
remote: error: You can set &#39;receive.denyCurrentBranch&#39; configuration variable t
remote: error: &#39;ignore&#39; or &#39;warn&#39; in the remote repository to allow pushing int
remote: error: its current branch; however, this is not recommended unless you
remote: error: arranged to update its work tree to match what you pushed in som
remote: error: other way.
remote: error:
remote: error: To squelch this message and still keep the default behaviour, se
remote: error: &#39;receive.denyCurrentBranch&#39; configuration variable to &#39;refuse&#39;.
To file://C:/Users/Kaito/Desktop/master
 ! [remote rejected] master -&amp;gt; master (branch is currently checked out)
error: failed to push some refs to &#39;file://C:/Users/Kaito/Desktop/master&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;)&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Gitのマージを図解する</title>
          <link>https://www.kaitoy.xyz/2015/12/28/git-merge/</link>
          <pubDate>Mon, 28 Dec 2015 01:05:29 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/12/28/git-merge/</guid>
          <description>

&lt;p&gt;このエントリでは、&lt;a href=&#34;https://git-scm.com/&#34;&gt;&lt;strong&gt;Git&lt;/strong&gt;&lt;/a&gt;が提供するマージのための機能の内、主なもの4つ、&lt;strong&gt;真のマージ&lt;/strong&gt;、&lt;strong&gt;リベース&lt;/strong&gt;、&lt;strong&gt;ファストフォワードマージ&lt;/strong&gt;、&lt;strong&gt;チェリーピック&lt;/strong&gt; について図解する。
ここでマージとは、とあるブランチのコミットが入れた修正を別のブランチに取り込むこととする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/27/git-repository/&#34;&gt;この記事&lt;/a&gt;を事前に読んでGitのオブジェクトモデルを理解しておくと分かりやすいかもしれない。&lt;/p&gt;

&lt;p&gt;ここで説明するマージは全てローカルリポジトリ内のブランチを操作対象とする。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;真のマージ&#34;&gt;真のマージ&lt;/h2&gt;

&lt;p&gt;真のマージは、複数のブランチでそれぞれ開発が進んでいて、つまりそれぞれのコミットグラフが伸びている場合に、それらの修正を統合するときに実行する。
マージするブランチはいくつでも指定できる。&lt;/p&gt;

&lt;p&gt;基本的なコマンドは&lt;code&gt;git merge &amp;lt;ブランチ(複数可)&amp;gt;&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;操作に成功すると、マージ後のプロジェクトの状態を表すコミット(マージコミット)が作られ、カレントブランチの先頭に追加される。
マージコミットは、マージした全てのブランチが指していたコミットを親として持つ。&lt;/p&gt;

&lt;p&gt;このマージはマージコミットを追加するだけであり、既存のコミットを一切変更しないことを認識しておくべし。&lt;/p&gt;

&lt;p&gt;以下、真のマージの実行例を図示する。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-merge/git_merge/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-merge/git_merge/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-merge/git_merge/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-merge/git_merge/スライド4.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;リベース&#34;&gt;リベース&lt;/h2&gt;

&lt;p&gt;リベースは、あるブランチで作った一連のコミットの起点(ベース)を移動したいときに実行する。
この操作は一般的にはマージとは呼ばれないが、冒頭に書いたマージの定義からするとマージと見なせないこともないのでここに挙げる。&lt;/p&gt;

&lt;p&gt;基本的なコマンドは&lt;code&gt;git rebase &amp;lt;ブランチ&amp;gt;&lt;/code&gt;。
このコマンドは、カレントブランチの起点を指定したブランチが指すコミットに移動する。&lt;/p&gt;

&lt;p&gt;この操作に成功すると、カレントブランチで作ったコミットは(実質)消え、それと同等の修正をもたらす別のコミットが移動先のコミットを起点として作成される。(※1)&lt;/p&gt;

&lt;p&gt;リベースは既存のコミットを消し、コミットグラフを変更してしまうということを認識しておくべし。&lt;/p&gt;

&lt;p&gt;以下、リベースの簡単な実行例を図示する。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-merge/git_rebase/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-merge/git_rebase/スライド2.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;上のスライドのように単純なコミットグラフならいいが、リベースするブランチが分岐していたりするとややこしいことが起き得る。
そういうケースには&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873114408/&#34;&gt;O&amp;rsquo;Reillyの蝙蝠本&lt;/a&gt;などでよく勉強してから臨むべし。&lt;/p&gt;

&lt;p&gt;(※1: より正確には&lt;code&gt;git rebase &amp;lt;ブランチ&amp;gt;&lt;/code&gt;は、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;カレントブランチで作った各コミットが入れた変更をパッチにして、&lt;/li&gt;
&lt;li&gt;それを古い順に一つずつ、指定したブランチが指すコミットに適用しながら新しいコミットを作り、&lt;/li&gt;
&lt;li&gt;カレントブランチが指しているコミットを&lt;code&gt;ORIG_HEAD&lt;/code&gt;で指し、&lt;/li&gt;
&lt;li&gt;カレントブランチを最新のコミットを指すよう更新する。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;2で、指定したブランチが既にチェリーピック(後述)などでカレントブランチのとあるコミットの変更を取り込んでいた場合、そのコミットのパッチの適用はスキップされ、そのパッチによるコミットも作られない。&lt;/p&gt;

&lt;p&gt;また、上でカレントブランチのコミットは実質消えると書いたが、当面はオブジェクトが本当に消えるわけではないし、&lt;code&gt;ORIG_HEAD&lt;/code&gt;とかが指しているのでもどることもできる。)&lt;/p&gt;

&lt;h2 id=&#34;ファストフォワードマージ&#34;&gt;ファストフォワードマージ&lt;/h2&gt;

&lt;p&gt;ファストフォワードマージは、マージ先のコミットが全てマージ元に含まれているときに使えるマージ。
この操作は既存のコミットグラフをいじらないしマージコミットも作らない特殊なマージ。
(実のところマージじゃないと言ってもいい。)
このマージを実行した後は、コミットグラフは一直線になり、ブランチを作らずにコミットを作った場合と同様になる。&lt;/p&gt;

&lt;p&gt;このマージは、&lt;code&gt;git merge &amp;lt;ブランチ&amp;gt;&lt;/code&gt;を実行したときに可能であれば実行される。
(でなければ真のマージが実行される。オプションで選択することもできる。)&lt;/p&gt;

&lt;p&gt;以下にファストフォワードマージの例を図示する。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-merge/git_ff/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-merge/git_ff/スライド2.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ファストフォワードマージはよくリベースとともに実行される。
リベースのスライドの最後のページの図は、ここのスライドの最初のページの図と同じになっている。&lt;/p&gt;

&lt;p&gt;リベース + ファストフォワードは、トピックブランチで入れた修正を、そのブランチを作ったという履歴を残さずに別のブランチに取り入れたいときなどに使う手法。
マージコミットを作る手法よりもコミットグラフをシンプルに保てる。&lt;/p&gt;

&lt;h2 id=&#34;チェリーピック&#34;&gt;チェリーピック&lt;/h2&gt;

&lt;p&gt;チェリーピックは、あるブランチの任意のコミットによる修正を別のブランチに取り込みたいときに実行する。
他の3つのマージに比べて分かりやすい操作であり、また操作対象にするブランチやコミットの自由度が高いので使いやすい。
その反面、コミットログなどに明記しないとどこのコミットをマージしたのかが分からなくなる。&lt;/p&gt;

&lt;p&gt;基本的なコマンドは&lt;code&gt;git cherry-pick &amp;lt;コミット&amp;gt;&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;操作に成功すると、指定したコミットと同等の修正をもたらす新しいコミットが作成され、&lt;code&gt;HEAD&lt;/code&gt;に追加される。&lt;/p&gt;

&lt;p&gt;この操作はコミットを追加するだけであり、既存のコミットは変更しない。&lt;/p&gt;

&lt;p&gt;以下にチェリーピックの例を図示する。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-merge/git_cherry-pick/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-merge/git_cherry-pick/スライド2.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Gitのリポジトリの中身をなるべく正確に理解する</title>
          <link>https://www.kaitoy.xyz/2015/12/27/git-repository/</link>
          <pubDate>Sun, 27 Dec 2015 11:34:18 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/12/27/git-repository/</guid>
          <description>

&lt;p&gt;このエントリでは、&lt;a href=&#34;https://git-scm.com/&#34;&gt;&lt;strong&gt;Git&lt;/strong&gt;&lt;/a&gt;の基本的な使い方は理解している前提で、そのリポジトリの構造をなるべく正確に説明する。
ここに書いてあることは概ね、筆者が&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873114408/&#34;&gt;O&amp;rsquo;Reillyの蝙蝠本&lt;/a&gt;を読んで得た知識に基づく。&lt;/p&gt;

&lt;p&gt;リポジトリの構造というとコアで上級者向けの知識のように聞こえるが、これをまず理解しておくことで強力で複雑なGitの機能を習得するのが非常に楽になる。
具体的には、Gitにおけるブランチの概念などの理解が深まったり、&lt;a href=&#34;https://www.kaitoy.xyz/2016/01/01/git-revert-reset/#git-reset&#34;&gt;&lt;code&gt;git reset&lt;/code&gt;&lt;/a&gt;などのGit特有で分かり辛いコマンドを自信をもって使えるようになったり、なにより、Gitを使う上での最大のハードルである &lt;strong&gt;インデックス&lt;/strong&gt; や &lt;strong&gt;HEAD&lt;/strong&gt; の概念を完璧に理解できるというメリットがある。&lt;/p&gt;

&lt;p&gt;チュートリアルを終えたくらいの初心者にこそ読んでほしいエントリである。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;gitリポジトリの中身&#34;&gt;Gitリポジトリの中身&lt;/h1&gt;

&lt;p&gt;Gitのリポジトリは、プロジェクトをクローンしたときとかにできる&lt;code&gt;.git&lt;/code&gt;ディレクトリ内に詰まっている。
このディレクトリには、&lt;strong&gt;オブジェクト格納領域&lt;/strong&gt; と &lt;strong&gt;インデックス&lt;/strong&gt; というデータ構造が入っている。
また、&lt;strong&gt;参照 (ref)&lt;/strong&gt; や &lt;strong&gt;シンボリック参照 (symref)&lt;/strong&gt; というものも入っている。&lt;/p&gt;

&lt;p&gt;以下、それぞれについて説明する。&lt;/p&gt;

&lt;h3 id=&#34;オブジェクト格納領域&#34;&gt;オブジェクト格納領域&lt;/h3&gt;

&lt;p&gt;オブジェクト格納領域は、ファイルシステム上では&lt;code&gt;.git/objects/&lt;/code&gt;以下にあたる。&lt;/p&gt;

&lt;p&gt;ここには、バージョン管理されているファイルの情報やそのコミット履歴などが保存されていて、具体的には以下の4種類のオブジェクトが置かれている。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;ブロブ&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一つのファイルを表すオブジェクト。
バージョン管理対象のファイルの内容(だけ)を保持する。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;ツリー&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一つのディレクトリを表すオブジェクト。ブロブや別のツリーを指すポインタを持ち、またそれらが表すファイル/ディレクトリの名前や属性を保持する。
つまり、これとブロブを組み合わせると、ファイルシステム上のディレクトリツリーを表すことができる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;コミット&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一つのコミットを表すオブジェクト。コミット日時やログメッセージなどの情報と、一つ前のコミット(親コミット)を指すポインタと、一つのツリーを指すポインタを持つ。
このツリーはプロジェクトのルートディレクトリを表す。
つまり、一つのコミットは、プロジェクトのある時点でのディレクトリツリー全体を表してもいる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;タグ&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一つの注釈付きタグ(&lt;code&gt;git tag -a&lt;/code&gt;で作るタグ)を表すオブジェクト。
タグ名やタグにつけたコメントなどの情報と、一つのオブジェクト(普通はコミット)へのポインタを持つ。
因みに軽量タグ(&lt;code&gt;git tag&lt;/code&gt;で作るタグ)はオブジェクトにならない。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;ファイルシステム上で、一つのオブジェクトは一つのファイルに書き込まれ、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Zlib&#34;&gt;zlib&lt;/a&gt;で圧縮され、&lt;code&gt;.git/objects/&lt;/code&gt;以下に配置される。
そのファイルへのパスには、オブジェクトのコンテンツから計算されたSHA1ハッシュの値(i.e. オブジェクトの名前)が使われる。
例えば&lt;code&gt;.git/objects/16/cacde1ddabe1698b0e41e091e4697313e2b7e5&lt;/code&gt;というファイルがあったら、これは &lt;strong&gt;16cacde1ddabe1698b0e41e091e4697313e2b7e5&lt;/strong&gt; という名のオブジェクトの実体。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git cat-file -p &amp;lt;SHA1ハッシュ&amp;gt;&lt;/code&gt;でオブジェクトのコンテンツを見れるので、いくつか見てみると面白い。
たとえばコミットオブジェクトは以下の様になっている。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ git cat-file -p d444447526f91a97f2edeefc65d4f58e8e006d78
tree 5d43dfbb8dd89018b9a383d6b9f663166e3cf9f9
parent adcf8b197c6c156860dc8aa66ccb9a0c0a3bebb6
author kaitoy &amp;lt;kaitoy@pcap4j.org&amp;gt; 1480004891 -0700
committer kaitoy &amp;lt;kaitoy@pcap4j.org&amp;gt; 1480004891 -0700

[#76] Rmove unneeded makePacketForInvokingPacketField call from IcmpV4InvokingPacketPacket.
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;インデックス&#34;&gt;インデックス&lt;/h3&gt;

&lt;p&gt;インデックスは、&lt;code&gt;git add&lt;/code&gt;の説明とかに出てくる「インデックス」とか「ステージング」とか呼ばれる機能を実現するためのデータ構造で、ファイルシステム上では&lt;code&gt;.git/index&lt;/code&gt;というバイナリファイルにあたる。&lt;/p&gt;

&lt;p&gt;インデックスは、プロジェクトのある時点でのディレクトリツリー全体を表すデータをもつ。
具体的には、プロジェクトの各ファイルについて、対応するブロブへのポインタと、プロジェクトルートディレクトリからの相対パスが記録されている。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git ls-files --stage&lt;/code&gt;で&lt;code&gt;.git/index&lt;/code&gt;の内容を見れる。&lt;/p&gt;

&lt;p&gt;例として、&lt;code&gt;https://github.com/kaitoy/japanese-word-selection&lt;/code&gt;をクローンして上記コマンドを実行すると以下の様に表示される。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ git ls-files --stage
100644 ade14b9196fcad03cd0177c25ec1c31000ecf86a 0       .gitignore
100644 bbbbcd3415597bac39b0314f5c708d90684161fc 0       CHANGES.md
100644 f6b0b485fec1ee0bc53a452bc82cb6b7de2a1d91 0       LICENSE
100644 10e50f7b628d83f1b66f34f2d9d34029e7fc8670 0       README.md
100644 4dc8027d17765180fac5c3292a0195bb09b10ceb 0       assets/japanese-word-selection.gif
100644 dd92c48bae50307b55fb623c1b2beccab963096e 0       lib/japanese-word-selection.coffee
100644 8152af5ad39515fcd5021e3c8afee32910c0cf79 0       package.json
100644 9c0d180898d841bb319f51f1b1c7e07320426eeb 0       spec/japanese-word-selection-spec.coffee
100644 3d32fc0f42cc9babccd5525165e8227dce00a206 0       spec/japanese-word-selection-whitespace-spec.coffee
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一行がひとつのファイルの情報で、左からファイルモード(パーミッション)、ブロブのSHA1ハッシュ、ステージ、ファイルパスが表示されている。
ステージは0～3の値になり得る。&lt;/p&gt;

&lt;p&gt;ステージは普段は0だけだけど、マージコンフリクトが起きた場合は、ベースバージョン、一方のブランチのバージョン、他方のブランチのバージョンの3つをそれぞれステージ1、2、3としてインデックスに保持する。
これは、マージコンフリクトの解消(i.e. 3-wayマージ)を&lt;a href=&#34;https://git-scm.com/docs/git-merge#_how_to_resolve_conflicts&#34;&gt;サポートする機能&lt;/a&gt;のためだ。&lt;/p&gt;

&lt;h3 id=&#34;オブジェクト格納領域とインデックスの図解&#34;&gt;オブジェクト格納領域とインデックスの図解&lt;/h3&gt;

&lt;p&gt;ワーキングディレクトリに変更を入れ、&lt;code&gt;git add&lt;/code&gt;、&lt;code&gt;git commit&lt;/code&gt;をする中で、オブジェクト格納領域とインデックスがどう変化するかを図にした。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_repo/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_repo/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_repo/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_repo/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_repo/スライド5.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_repo/スライド6.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_repo/スライド7.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(タグオブジェクトについては次の節で。)&lt;/p&gt;

&lt;p&gt;スライドの1ページ目や最後のページのようにワーキングディレクトリとインデックスとオブジェクト格納領域が同期していて、&lt;code&gt;git status&lt;/code&gt;を実行すると&lt;code&gt;nothing to commit, working directory clean&lt;/code&gt;と表示される状態をワーキングディレクトリがクリーンであると言い、そうでない状態をワーキングディレクトリがダーティであると言う。&lt;/p&gt;

&lt;p&gt;このスライドにより、Gitがファイルの履歴をどう記録しているかがよく分かるはず。
特に、ブロブが常にファイルのある時点の内容全体を保持していて、Gitが(&lt;a href=&#34;https://subversion.apache.org/&#34;&gt;Subversion&lt;/a&gt;のように)差分を保存しているわけではないことは覚えておくべし。&lt;/p&gt;

&lt;p&gt;スライドの最後のページのオブジェクト格納領域の図で、ツリーとブロブとそれらを指す矢印を省略すると、Gitのブランチ等の説明でよく見かける丸が矢印で連なった図(コミットグラフ)になる。以降の説明でそのような図を使うが、丸がコミットを意味していて、各コミットがルートツリーを指していることはよく認識しておくべし。&lt;/p&gt;

&lt;h3 id=&#34;参照-ref&#34;&gt;参照 (ref)&lt;/h3&gt;

&lt;p&gt;参照は、一つのオブジェクトを指し示すポインタのようなもので、普通はコミットオブジェクトを指す。
参照には、&lt;strong&gt;ローカルブランチ&lt;/strong&gt;、&lt;strong&gt;リモート追跡ブランチ&lt;/strong&gt;、&lt;strong&gt;タグ&lt;/strong&gt; の三種類がある。&lt;/p&gt;

&lt;p&gt;ファイルシステム上では&lt;code&gt;.git/refs/&lt;/code&gt;以下にある、指し示すオブジェクトのSHA1ハッシュ値が書かれただけのテキストファイルにあたる。
&lt;code&gt;.git/refs/heads/&lt;/code&gt;以下にローカルブランチ、&lt;code&gt;.git/refs/remotes/&lt;/code&gt;以下にリモート追跡ブランチ、&lt;code&gt;.git/refs/tags/&lt;/code&gt;以下にタグが置かれる。&lt;/p&gt;

&lt;p&gt;参照は、Gitコマンドなどにおいてコミットを指定する方法としてSHA1ハッシュ値の代わりに使える。
この時、参照の名前は上記ファイルシステム上のパスから&lt;code&gt;.git/&lt;/code&gt;を省いたものになる。
例えば&lt;code&gt;refs/heads/master&lt;/code&gt;。さらに、ディレクトリは省略できるので、同じ参照は&lt;code&gt;heads/master&lt;/code&gt;や単に&lt;code&gt;master&lt;/code&gt;とも書ける。&lt;/p&gt;

&lt;p&gt;ここで、ブランチやタグが単なる参照であるところに注目。
Subversionのようにリポジトリのコピーを作るのとはかなり異なる。
Gitのブランチを作るというのは単に参照を追加するだけだし、ブランチをチェックアウトするというのはブランチが指すコミットが指すツリーが表すディレクトリツリーをファイルシステムに展開するということ。
この実装によってGitのブランチが軽量で速いものになっている。&lt;/p&gt;

&lt;p&gt;ローカルブランチの挙動を以下に図示する。図中で、各コミットには便宜上ラベルとしてアルファベットを付けている。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_branch/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_branch/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_branch/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_branch/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_branch/スライド5.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;このスライドの最後のページでmasterブランチが本流でbugfixブランチが支流かのように書いているが、実際は実装上それらに差はなく全く対等である。&lt;/p&gt;

&lt;p&gt;また、ブランチは単なる一方的な参照であり、コミットオブジェクトからはそれに全く関与しないことに注意。
ブランチを削除してもそれによってコミットが消えることはない(※1)し、また例えば、スライドの最後のページでbugfixブランチを削除したらXがどのブランチで作られたコミットなのかを知るすべはなくなる。&lt;/p&gt;

&lt;p&gt;(※1: ブランチを削除することにより到達不能になるコミットは、結果的に&lt;a href=&#34;https://git-scm.com/book/ja/v2/Git%E3%81%AE%E5%86%85%E5%81%B4-%E3%83%A1%E3%82%A4%E3%83%B3%E3%83%86%E3%83%8A%E3%83%B3%E3%82%B9%E3%81%A8%E3%83%87%E3%83%BC%E3%82%BF%E3%83%AA%E3%82%AB%E3%83%90%E3%83%AA&#34;&gt;&lt;code&gt;git gc&lt;/code&gt;&lt;/a&gt;により削除されはする。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次に、タグの挙動を以下に図示する。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_tag/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_tag/スライド2.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_tag/スライド3.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_tag/スライド4.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_tag/スライド5.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;図中で、タグオブジェクトはオブジェクトなのでオブジェクト格納領域に入り、それを指す参照のタグは&lt;code&gt;.git/refs/&lt;/code&gt;に入る。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;リモート追跡ブランチについては&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/31/git-dvc/&#34;&gt;別のエントリ&lt;/a&gt;で書く。&lt;/p&gt;

&lt;h3 id=&#34;シンボリック参照-symref&#34;&gt;シンボリック参照 (symref)&lt;/h3&gt;

&lt;p&gt;シンボリック参照は参照やオブジェクトを指し示すポインタのようなもので、以下の四つがある。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;HEAD&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;カレントブランチ、つまりチェックアウトしているブランチ(i.e. 参照)を指す。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;ORIG_HEAD&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git merge&lt;/code&gt;や&lt;a href=&#34;https://www.kaitoy.xyz/2016/01/01/git-revert-reset/#git-reset&#34;&gt;&lt;code&gt;git reset&lt;/code&gt;&lt;/a&gt;でHEADが更新されたとき、更新前のHEADが指していたブランチが指していたコミットを指す。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;FETCH_HEAD&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;最後にフェッチされたブランチの最新コミットを指す。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;MERGE_HEAD&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;マージ操作中に作られ、HEADにマージされようとしているコミットを指す。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;それぞれが、Gitコマンドなどにおいてコミットを指定する方法としてSHA1ハッシュ値の代わりに使える。&lt;/p&gt;

&lt;p&gt;ファイルシステム上では&lt;code&gt;.git/{HEAD,ORIG_HEAD,FETCH_HEAD,MERGE_HEAD}&lt;/code&gt;にあたり、全て単純なテキストファイルである。&lt;/p&gt;

&lt;p&gt;特によく使う&lt;code&gt;HEAD&lt;/code&gt;を図示すると以下のようになる。&lt;/p&gt;

&lt;ul class=&#34;bxslider&#34;&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_head/スライド1.PNG&#34; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/git-repository/git_head/スライド2.PNG&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上図に見られるように、&lt;code&gt;HEAD&lt;/code&gt;は通常ブランチを指す。
実際に&lt;code&gt;.git/HEAD&lt;/code&gt;ファイルの中身を見ると以下の様になっていて、確かにブランチを指していることが見て取れる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ref: refs/heads/master
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;gitコマンドの実行内容によっては&lt;code&gt;HEAD&lt;/code&gt;が直接コミットを指すようになることもあり、この場合は特に「detached HEAD」、つまり(ブランチから)切り離されたHEADと呼ばれる。&lt;/p&gt;

&lt;p&gt;スライドの1ページ目の状態では、だいたいのgitコマンドから見てコミットEと&lt;code&gt;master&lt;/code&gt;と&lt;code&gt;HEAD&lt;/code&gt;は等価であると考えていい。
つまり例えば、&lt;code&gt;git reset &amp;lt;コミットEのSHA1ハッシュ値&amp;gt;&lt;/code&gt;、&lt;code&gt;git reset master&lt;/code&gt;、&lt;code&gt;git reset HEAD&lt;/code&gt;は同じ結果になる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上がGitリポジトリの中身のほぼ全容。あとは設定ファイルとかフックスクリプトとかがあるだけ。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;実際のGitリポジトリのオブジェクト、参照、シンボリック参照を、この記事のスライドと同じ見た目でビジュアライズするツール、&lt;a href=&#34;https://www.kaitoy.xyz/tags/goslings/&#34;&gt;&lt;strong&gt;Goslings&lt;/strong&gt;&lt;/a&gt;を作った。
このツールを使って実際のリポジトリの中身を見ながらこの記事を内容を確認すると、より理解が深まるかもしれない。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ReactをAtomパッケージ開発に使ってみた</title>
          <link>https://www.kaitoy.xyz/2015/12/21/hello-react/</link>
          <pubDate>Mon, 21 Dec 2015 00:07:28 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/12/21/hello-react/</guid>
          <description>

&lt;p&gt;私は今&lt;a href=&#34;https://www.hpe.com/us/en/home.html&#34;&gt;HPE&lt;/a&gt;の&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%95%E3%82%A9%E3%83%BC%E3%83%88%E3%83%BB%E3%82%B3%E3%83%AA%E3%83%B3%E3%82%BA_%28%E3%82%B3%E3%83%AD%E3%83%A9%E3%83%89%E5%B7%9E%29&#34;&gt;Fort Collins&lt;/a&gt;オフィスに居候している。
HPEは最近、&lt;a href=&#34;https://facebook.github.io/react/&#34;&gt;React&lt;/a&gt;を使ったUXフレームワークである&lt;a href=&#34;http://www.grommet.io/docs/&#34;&gt;Grommet&lt;/a&gt;を開発していて、私が扱っている製品もそれを使う兆しが見えてきた。
Grommetはいずれ仕事で触ることになりそうなので、まずはReactの勉強をと思い、&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/19/atom-impress/&#34;&gt;とあるAtomパッケージ&lt;/a&gt;の開発に敢えて使ってみた。&lt;/p&gt;

&lt;p&gt;このエントリには、その作業の中で得た知識などについて書いた。
ただし、Reactを使った開発のノウハウみたいなものまでは得ていないので書いていない。&lt;/p&gt;

&lt;p&gt;(因みにGrommetは&lt;a href=&#34;https://github.com/grommet/grommet&#34;&gt;GitHub&lt;/a&gt;で公開されているが、ほとんど話題になっておらずスターも現時点で245しかついていない。。。)&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;reactとは&#34;&gt;Reactとは&lt;/h2&gt;

&lt;p&gt;ReactはFacebookが開発しているWeb UIのフレームワークで、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Model_View_Controller&#34;&gt;MVC&lt;/a&gt;のVだけを実装したもの。
2013年に最初のバージョンが公開され、世界中で流行ってきているらしい。&lt;/p&gt;

&lt;p&gt;その特徴(というかほぼ全容)は仮想DOM(&lt;a href=&#34;https://facebook.github.io/react/docs/glossary.html&#34;&gt;Virtual DOM&lt;/a&gt;)。
ReactのAPIを使うと、リアルDOMと一対一で対応する仮想DOMのツリーを作ることができ、UIを組み立てられる。
リアルDOMの構築や更新はReactが最適化された方法でやってくれるので、性能がいいUIができるらしい。
因みに、仮想DOM自体はReact特有の技術ではなく、別の実装もある。&lt;/p&gt;

&lt;p&gt;もう一つの特徴は&lt;a href=&#34;https://facebook.github.io/jsx/&#34;&gt;JSX&lt;/a&gt;。
これは、JavaScriptのコードの中で、XMLみたいな構文で仮想DOMを記述するための拡張構文。
これを使うとReactコードが見やすく簡単に書けるけど、当然普通のJavaScript実行環境では動かないので、プリコンパイルなどが必要になる。&lt;/p&gt;

&lt;p&gt;FacebookはReactを使った開発に&lt;a href=&#34;http://facebook.github.io/flux/docs/overview.html#content&#34;&gt;Flux&lt;/a&gt;というアーキテクチャの採用を推奨している。
FluxはMVCアーキテクチャに置き換わるもので、従来の複雑なデータフローに反発し、一方向のシンプルなデータフローを提供する。
Fluxは単なるアーキテクチャで、その全体の実装を支援するフレームワークは現時点では無い。
(多分。&lt;a href=&#34;https://facebook.github.io/relay/&#34;&gt;Relay&lt;/a&gt;が一部支援してくれるっぽい。)&lt;/p&gt;

&lt;h2 id=&#34;reactを触った感想&#34;&gt;Reactを触った感想&lt;/h2&gt;

&lt;p&gt;Reactは本当にちょっとしか触っていないので、あまりよく分かっていないんだろうけど、なんだか使いにくかった。&lt;/p&gt;

&lt;p&gt;Reactは仮想DOMを作るところしか助けてくれないので、他のことは全部自分でやらないといけない。
FacebookはReact用のウィジェットすら提供していない。
昔仕事で全部入りの&lt;a href=&#34;https://ja.wikipedia.org/wiki/Dojo_Toolkit&#34;&gt;Dojo&lt;/a&gt;を使っていたので、それとのギャップをすごい感じた。&lt;/p&gt;

&lt;p&gt;そのうえ、他のフレームワークやライブラリと組み合わせて使おうとすると仮想DOMが壁になってくる。普通のフレームワークはリアルDOMを扱うからだ。
例えば、JavaScriptを書いているとすぐ&lt;a href=&#34;https://jquery.com/&#34;&gt;jQuery&lt;/a&gt;を使いたくなるが、これでリアルDOMを直接いじってしまってはReactを使う意味がない気がする。&lt;/p&gt;

&lt;h2 id=&#34;atomパッケージでreactを使う&#34;&gt;AtomパッケージでReactを使う&lt;/h2&gt;

&lt;p&gt;Reactは&lt;a href=&#34;https://www.npmjs.com/&#34;&gt;npm&lt;/a&gt;でも提供されていて、Atomパッケージの開発に簡単に使える。
パッケージの&lt;code&gt;package.json&lt;/code&gt;の&lt;code&gt;dependencies&lt;/code&gt;に&lt;a href=&#34;https://www.npmjs.com/package/react&#34;&gt;react&lt;/a&gt;と&lt;a href=&#34;https://www.npmjs.com/package/react-dom&#34;&gt;react-dom&lt;/a&gt;を入れておけば、パッケージコード中で以下の様に仮想DOMを作れるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var React = require(&#39;react&#39;);
var ReactDOM = require(&#39;react-dom&#39;);

class MyComponent extends React.Component {
  render() {
    return &amp;lt;div&amp;gt;Hello World&amp;lt;/div&amp;gt;;
  }
}

ReactDOM.render(&amp;lt;MyComponent /&amp;gt;, node);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;babelによるjsxの手動コンパイル&#34;&gt;BabelによるJSXの手動コンパイル&lt;/h2&gt;

&lt;p&gt;JSXのコンパイルには&lt;a href=&#34;https://babeljs.io/&#34;&gt;Babel&lt;/a&gt;を使うのがいい。
手動コンパイルにはBabelのコマンドラインツールが必要で、これはnpmで提供されている。
npmコマンドはAtomに同梱されているので別途インストールは不要。&lt;/p&gt;

&lt;p&gt;以下が手順の詳細。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Babelのコマンドラインツールのインストール&lt;/p&gt;

&lt;p&gt;任意の場所で、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm install -g babel-cli
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;を実行すると、Babelのコマンドラインツールがグローバルにインストールされ、任意の場所で&lt;code&gt;babel&lt;/code&gt;コマンドが使えるようになる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Babelの定義ファイル作成&lt;/p&gt;

&lt;p&gt;適当なフォルダ(プロジェクトのルートなど)に&lt;code&gt;.babelrc&lt;/code&gt;というBabelの定義ファイルを作り、以下を書いておく。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;presets&amp;quot;: [&amp;quot;react&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Reactプラグインのインストール&lt;/p&gt;

&lt;p&gt;&lt;code&gt;.babelrc&lt;/code&gt;に書いた&lt;code&gt;presets&lt;/code&gt;の値は、コンパイルにReactプラグインを使うという意味。
なので、以下のコマンドでReactプラグインを(ローカルに)インストールする必要がある。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd &amp;lt;.babelrcを置いたフォルダ&amp;gt;
npm install babel-preset-react
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;コンパイル&lt;/p&gt;

&lt;p&gt;&lt;code&gt;babel&lt;/code&gt;コマンドでコンパイルを実行する。例えば以下を実行すると、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd &amp;lt;.babelrcを置いたフォルダ&amp;gt;
babel src -d lib
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;src/*.jsx&lt;/code&gt;がコンパイルされて、&lt;code&gt;lib/*.js&lt;/code&gt;に出力される。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;language-babelパッケージによるjsxの自動コンパイル&#34;&gt;language-babelパッケージによるJSXの自動コンパイル&lt;/h2&gt;

&lt;p&gt;上記Babelによるコンパイルは、Atomなら&lt;a href=&#34;https://atom.io/packages/language-babel&#34;&gt;language-babelパッケージ&lt;/a&gt;で自動化できる。&lt;/p&gt;

&lt;p&gt;以下、Atomパッケージの開発でlanguage-babelを利用する手順を書く。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;language-babelのインストール&lt;/p&gt;

&lt;p&gt;language-babelをAtomのSettingsなどからインストールして、language-babelのSettingsで、&lt;code&gt;Allow Local Override&lt;/code&gt;にチェックを付ける。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Babelの定義ファイル作成&lt;/p&gt;

&lt;p&gt;手動のと同じ内容の&lt;code&gt;.babelrc&lt;/code&gt;をパッケージプロジェクトのルートに置く。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;package.json編集&lt;/p&gt;

&lt;p&gt;パッケージプロジェクトの&lt;code&gt;package.json&lt;/code&gt;の&lt;code&gt;dependencies&lt;/code&gt;の下あたりに以下の定義を追加して、BabelとReactプラグインへの依存を張る。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;  &amp;quot;devDependencies&amp;quot;: {
    &amp;quot;babel-core&amp;quot;: &amp;quot;^6.1.2&amp;quot;,
    &amp;quot;babel-preset-react&amp;quot;: &amp;quot;^6.1.2&amp;quot;
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上記定義を追加したら、&lt;code&gt;apm install&lt;/code&gt;を実行して追加した依存をダウンロードする。&lt;/p&gt;

&lt;p&gt;因みに、&lt;code&gt;devDependencies&lt;/code&gt;は&lt;code&gt;dependencies&lt;/code&gt;と似てるけど、開発時だけに必要なモジュールを定義するプロパティ。
&lt;code&gt;devDependencies&lt;/code&gt;に書いたものは&lt;code&gt;apm install&lt;/code&gt;したときはダウンロードされるけど、パブリッシュされたものをインストールするときにはダウンロードされない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;language-babelの設定ファイル作成&lt;/p&gt;

&lt;p&gt;language-babelの設定は&lt;code&gt;.languagebabel&lt;/code&gt;というファイルにかく。
これに以下の様な内容を書いてパッケージプロジェクトのルートに置く。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;babelMapsPath&amp;quot;:                   &amp;quot;lib&amp;quot;,
  &amp;quot;babelMapsAddUrl&amp;quot;:                 false,
  &amp;quot;babelSourcePath&amp;quot;:                 &amp;quot;src&amp;quot;,
  &amp;quot;babelTranspilePath&amp;quot;:              &amp;quot;lib&amp;quot;,
  &amp;quot;createMap&amp;quot;:                       false,
  &amp;quot;createTargetDirectories&amp;quot;:         true,
  &amp;quot;createTranspiledCode&amp;quot;:            true,
  &amp;quot;disableWhenNoBabelrcFileInPath&amp;quot;:  false,
  &amp;quot;suppressSourcePathMessages&amp;quot;:      true,
  &amp;quot;suppressTranspileOnSaveMessages&amp;quot;: false,
  &amp;quot;transpileOnSave&amp;quot;:                 true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで、&lt;code&gt;&amp;lt;パッケージプロジェクトのルート&amp;gt;/src/*.jsx&lt;/code&gt;が、Atomで編集して保存したときにコンパイルされ、&lt;code&gt;&amp;lt;パッケージプロジェクトのルート&amp;gt;/lib/*.js&lt;/code&gt;に出力されるようになった。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;babelでjsxをコンパイルする場合の制限&#34;&gt;BabelでJSXをコンパイルする場合の制限&lt;/h2&gt;

&lt;p&gt;手動にしろ自動にしろ、JSXのコンパイルにBabelを使う場合、BabelがCoffeeScriptに対応していないので、CoffeeScript + JSXでは書けない。
JavaScript + JSXで書かないといけない。&lt;/p&gt;

&lt;h2 id=&#34;minified-exception&#34;&gt;Minified exception&lt;/h2&gt;

&lt;p&gt;React周りでバグを作りこんでエラーが発生した場合、コンソールに以下のようなエラーメッセージが出ることがある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Uncaught Error: Minified exception occured; use the non-minified dev environment for the full error message and additional helpful warnings.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これではエラーの詳細はわからない。詳細を見たい場合は、AtomをDev Modeで開いておく必要がある。
(e.g. Atomのメニューバーの[View]&amp;gt;[Developer]&amp;gt;[Open In Dev Mode]から開く。)&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>impress.jsでのプレゼン資料作成をサポートするAtomパッケージ - impress</title>
          <link>https://www.kaitoy.xyz/2015/12/19/atom-impress/</link>
          <pubDate>Sat, 19 Dec 2015 23:37:08 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/12/19/atom-impress/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://atom.io/&#34;&gt;&lt;strong&gt;Atom&lt;/strong&gt;&lt;/a&gt;のパッケージを作った話。&lt;/p&gt;

&lt;p&gt;ついでに、パッケージプロジェクト内で別のプロジェクトを取り込んで使いたい場合に、&lt;a href=&#34;https://git-scm.com/book/ja/v2/Git-%E3%81%AE%E3%81%95%E3%81%BE%E3%81%96%E3%81%BE%E3%81%AA%E3%83%84%E3%83%BC%E3%83%AB-%E3%82%B5%E3%83%96%E3%83%A2%E3%82%B8%E3%83%A5%E3%83%BC%E3%83%AB&#34;&gt;Gitのサブモジュール&lt;/a&gt;を使ってはダメという話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;impress-js&#34;&gt;impress.js&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/impress/impress.js&#34;&gt;&lt;strong&gt;impress.js&lt;/strong&gt;&lt;/a&gt;というJavaScriptライブラリがある。
HTML5とCSS3とJavaScriptでプレゼン資料を作るためのライブラリで、これを使うと、&lt;a href=&#34;https://products.office.com/ja-jp/powerpoint&#34;&gt;PowerPoint&lt;/a&gt;や&lt;a href=&#34;http://www.apple.com/jp/mac/keynote/&#34;&gt;Keynote&lt;/a&gt;といった従来のツールによるものからは一線を画す斬新な資料を作ることができる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://impress.github.io/impress.js/#/bored&#34;&gt;公式のデモ&lt;/a&gt;を見ればその魅力を堪能できる。&lt;/p&gt;

&lt;p&gt;デモを見ると分かるが、&lt;a href=&#34;https://prezi.com/&#34;&gt;&lt;strong&gt;Prezi&lt;/strong&gt;&lt;/a&gt;に触発されたライブラリだ。
Preziでも非常に新鮮な資料を作れるが、ほぼ有料で、また作成した資料をPreziのサーバに置かなければいけないので、仕事で使う資料作りには使いにくい。
その点impress.jsは、&lt;a href=&#34;https://ja.wikipedia.org/wiki/MIT_License&#34;&gt;MIT&lt;/a&gt;(と&lt;a href=&#34;https://ja.wikipedia.org/wiki/GNU_General_Public_License&#34;&gt;GPLv2&lt;/a&gt;)で公開されていて自由に無料で使えるのがよい。&lt;/p&gt;

&lt;p&gt;ただし、Preziがスライドという概念から大きく脱却しているのに対して、実のところimpress.jsで作れる資料はあくまでスライドベースだ。
従来のものに比べてスライドの並びに制約がなく、スライド間の遷移がダイナミックというだけだ。
impress.jsでもまあ工夫すればPreziのような資料は作れるが。
独自のオーサリングツール/ビューワに依存するPreziに対し、impress.jsは標準的なHTML/CSS/JavaScriptにだけ依存しているので、&lt;a href=&#34;https://jquery.com/&#34;&gt;jQuery&lt;/a&gt;などのWeb技術を活用してスライドを作れるという副次的なメリットはある。&lt;/p&gt;

&lt;p&gt;impress.jsは、2012年に最初のバージョンが公開されてからもう4年近く経つが、未だにそれほど広く使われている様子はない。
PowerPointが幅を利かせているせいもあるだろうが、その使い辛さから利用をためらう人が多いのではないだろうか。
impress.jsはあまりドキュメントが充実しているとは言えない。
&lt;a href=&#34;https://github.com/impress/impress.js#how-to-use-it&#34;&gt;GitHubに公開されているREADME&lt;/a&gt;には、使い方はソースを見よ、それで分からないなら使うなとある。
さらにソース中には、impress.jsを使うには、HTMLとCSSのスキルに加えてデザイナーのセンスも必要とある。
かなりハードルを上げている。&lt;/p&gt;

&lt;p&gt;このハードルをクリアしていたとしても、実際、impress.jsで資料を作るのはPowerPointに比べて10倍は大変だ。
impress.jsはスライド(impress.js用語ではステップ)間の遷移を制御してくれるだけで、各スライドのコンテンツを作るという部分に関してはなんのサポートも提供しない。
テンプレートもなければ、表やグラフを書く機能もなく、アニメーションも作れない。
そういうことをしたければ、自分で別途ライブラリを探して使うなりしないといけない。&lt;/p&gt;

&lt;p&gt;ちょっとした図を書くにも、テキストエディタでちまちまHTMLとCSSを書いて、ブラウザで表示して確認して、思った通りになっていなければディベロッパツールでデバッグして、Web UIでも書いていたんだっけという気になってくる。&lt;/p&gt;

&lt;h2 id=&#34;impressパッケージ&#34;&gt;impressパッケージ&lt;/h2&gt;

&lt;p&gt;そんな負担を少しでも軽くしたいと思って作ったのが&lt;a href=&#34;https://atom.io/packages/impress&#34;&gt;impressパッケージ&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;同じ目的のツール(i.e. オーサリングツール)は実は既に&lt;a href=&#34;https://github.com/impress/impress.js/wiki/Examples-and-demos#authoring-tools&#34;&gt;いくつかあった&lt;/a&gt;。
なかでも、&lt;a href=&#34;https://github.com/regebro/hovercraft&#34;&gt;Hovercraft!&lt;/a&gt;というのが高機能で便利そう。
ただ、これらはPowerPointほど自在にスライドを作れるまでには至っておらず、結局は仕上げにHTML/CSSを手でいじる作業が必要になる。(と思う。)
また、jQueryのプラグイン使ってかっこいいことしたいとか言う場合にも、手でコードを書かなければいけない。&lt;/p&gt;

&lt;p&gt;つまりテキストエディタを開かなければいけない。よってAtomを起動することになる。(私は。)&lt;/p&gt;

&lt;p&gt;であれば、オーサリングツールもAtomに統合されていた方が便利なんじゃないの?
というのがimpressパッケージを作った動機。&lt;/p&gt;

&lt;p&gt;まだ機能は少なくて、新規資料プロジェクトの雛形生成、&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/atom-impress/new_project.gif&#34; alt=&#34;new_project&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;ステップをリスト表示するビュー表示、&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/atom-impress/step_list_view.gif&#34; alt=&#34;step_list_view&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;プレビューができるだけ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/atom-impress/preview.gif&#34; alt=&#34;preview&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ゆくゆくは、GUIでステップの配置や角度を編集する機能、GUIでステップ内の図を作成する機能を作りたい。
あとできればアニメーションを付ける機能とかも。
Hovercraft!みたいにHTML書かなくてもいいよ、というのを目指すつもりはなくて、あくまでもコーダーのための、コーディングを補助するツールを目指す。&lt;/p&gt;

&lt;h2 id=&#34;パッケージのサブモジュール&#34;&gt;パッケージのサブモジュール&lt;/h2&gt;

&lt;p&gt;impressパッケージは、新規資料プロジェクトの雛形生成機能などのため、impress.jsプロジェクト(の&lt;a href=&#34;https://github.com/kaitoy/impress.js&#34;&gt;フォーク&lt;/a&gt;)をサブモジュールとしてとりこんでいる。&lt;/p&gt;

&lt;p&gt;最初はGitのサブモジュールコマンド(&lt;code&gt;git submodule&lt;/code&gt;)を使って取り込んでいて、上手くいっているように見えたが、パブリッシュ後に次のような問題が発生した。
即ち、試しにimpressパッケージをインストールしてみたら、サブモジュールのフォルダの中身がからっぽだった。&lt;/p&gt;

&lt;p&gt;これは、Atomのパッケージマネージャがパッケージを&lt;a href=&#34;https://help.github.com/articles/about-releases/&#34;&gt;GitHub Releases&lt;/a&gt;から&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/02/unpublish-atom-package/#%E6%B3%A8%E6%84%8F%E3%81%99%E3%81%B9%E3%81%8D%E7%82%B9-3-%E3%83%91%E3%83%83%E3%82%B1%E3%83%BC%E3%82%B8%E3%81%AE%E3%82%AD%E3%83%A3%E3%83%83%E3%82%B7%E3%83%A5&#34;&gt;ダウンロードしてインストールする&lt;/a&gt;からだ。サブモジュールの中身はGitHub Releasesに登録されるアーカイブに含まれない。このGitHub Releasesの挙動は、サブモジュールを含むGitプロジェクトをクローンした場合、&lt;a href=&#34;https://git-scm.com/book/ja/v2/Git-%E3%81%AE%E3%81%95%E3%81%BE%E3%81%96%E3%81%BE%E3%81%AA%E3%83%84%E3%83%BC%E3%83%AB-%E3%82%B5%E3%83%96%E3%83%A2%E3%82%B8%E3%83%A5%E3%83%BC%E3%83%AB#%E3%82%B5%E3%83%96%E3%83%A2%E3%82%B8%E3%83%A5%E3%83%BC%E3%83%AB%E3%82%92%E5%90%AB%E3%82%80%E3%83%97%E3%83%AD%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E3%81%AE%E3%82%AF%E3%83%AD%E3%83%BC%E3%83%B3&#34;&gt;デフォルトではサブモジュールはクローンされない&lt;/a&gt;というGitサブモジュールの仕様に関係しているのかもしれない。&lt;/p&gt;

&lt;p&gt;この問題をきっかけにGitサブモジュールについてちょっと調べてみた。
&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873114408/&#34;&gt;蝙蝠本&lt;/a&gt;によると、Git開発チームはあまりサブモジュールコマンドの開発に熱心ではなく真面目に作らなかったらしい。
また、&lt;a href=&#34;http://japan.blogs.atlassian.com/2014/03/alternatives-to-git-submodule-git-subtree/&#34;&gt;あるブログ&lt;/a&gt;によればサブモジュールコマンドは大分まえからオワコンらしい。このブログによれば、今は多くの場合&lt;code&gt;git subtree&lt;/code&gt;を使うのがいいとのこと。&lt;code&gt;git subtree&lt;/code&gt;は蝙蝠本にも&lt;a href=&#34;https://git-scm.com/book/en/v2&#34;&gt;Pro Git&lt;/a&gt;にも載ってないのだが。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git subtree&lt;/code&gt;でプロジェクトを取り込んだ場合、親プロジェクトのクローン時にサブプロジェクトもデフォルトでクローンされる仕様だ。
(というか正しくは、サブモジュールと違って、子プロジェクトが親プロジェクトにマージされているから、一緒にクローンされるというだけ。)
これを使ってimpressパッケージを構成しなおしてみたら件の問題が解決した。
因みにやりかたは、impressパッケージプロジェクトのルートに&lt;code&gt;impress.js&lt;/code&gt;というフォルダを作った後、以下のコマンドを実行しただけ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git subtree add --prefix impress.js git@github.com:kaitoy/impress.js.git master --squash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ということで、Atomのパッケージに別のプロジェクトを取り込んで使いたい場合は、&lt;code&gt;git submodule&lt;/code&gt;ではなく、&lt;code&gt;git subtree&lt;/code&gt;を使わないといけないという教訓を得た。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Pcap4JがSoftware Quality Award 2015で入賞</title>
          <link>https://www.kaitoy.xyz/2015/12/03/software-quality-award-2015/</link>
          <pubDate>Thu, 03 Dec 2015 12:28:24 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/12/03/software-quality-award-2015/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;http://www.teamed.io/&#34;&gt;Teamed.io&lt;/a&gt;が主催の、ソフトウェアの品質とその開発プロジェクトの品質への取り組みを競うコンテスト、&lt;a href=&#34;http://www.yegor256.com/2015/04/16/award.html&#34;&gt;Software Quality Award&lt;/a&gt;の第一回が2015年4月～11月にかけて開催された。
Teamed.ioのCTOであるYegorとは、彼のブログを和訳してここに載せている関係でたまにメールしているが、そのやりとりの中で誘われたので私も&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;Pcap4J&lt;/a&gt;をひっさげてそれに参加した。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;優勝すると$4,096もらえるということではあったが、150以上のプロジェクトがエントリーしていて、&lt;a href=&#34;http://gulpjs.com/&#34;&gt;Gulp&lt;/a&gt;とか有名なものも入っていたので、どうせ全然ダメだろと思ってエントリー以来なにも対策しなかったが、なんと &lt;strong&gt;8位&lt;/strong&gt; 入賞を果たしてしまった。
まあ講評をみるとずいぶんこき下ろされてはいるが…&lt;/p&gt;

&lt;p&gt;因みに講評は以下の感じ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;utilパッケージがあってそこにユーティリティクラスがある。クソだ。&lt;/li&gt;
&lt;li&gt;NULLが可変オブジェクトで使われている。例えば&lt;a href=&#34;https://github.com/kaitoy/pcap4j/blob/master/pcap4j-core/src/main/java/org/pcap4j/core/AbstractPcapAddress.java&#34;&gt;AbstractPcapAddress&lt;/a&gt;。クソだ。&lt;/li&gt;
&lt;li&gt;スタティックメソッドとスタティック変数が多すぎる。文字通りどこにでもある。pcap4j-packetfactory-staticという名のスタティックメソッドだらけのモジュールまである。&lt;/li&gt;
&lt;li&gt;JavaDocに一貫性がなく、未完なものもある。&lt;a href=&#34;https://github.com/kaitoy/pcap4j/blob/master/pcap4j-core/src/main/java/org/pcap4j/core/NotOpenException.java#L21-L23&#34;&gt;これ&lt;/a&gt;とか。&lt;/li&gt;
&lt;li&gt;ほんのちょっとのissuesとたった6つのプルリクエストしかない。コミットがissuesにリンクされてない。変更のトレーサビリティはほとんどゼロだ。&lt;/li&gt;
&lt;li&gt;リリース手順が自動化されていない。&lt;a href=&#34;https://github.com/kaitoy/pcap4j/releases&#34;&gt;リリース&lt;/a&gt;がドキュメントに書かれていない。&lt;/li&gt;
&lt;li&gt;静的解析してなくて、そのせいか乱雑なコードがたまにある。&lt;/li&gt;
&lt;li&gt;スコア: 3&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;静的解析くらいは導入しようかな…&lt;/p&gt;

&lt;p&gt;ユーティリティクラスとかNULLとかスタティックメソッドは使うのやめるつもりはないけど。&lt;/p&gt;

&lt;p&gt;そういえば、入賞者にはスポンサーである&lt;a href=&#34;https://www.jetbrains.com/products.html&#34;&gt;JetBrainsの製品&lt;/a&gt;の一年ライセンスがもらえることになっていたはずだが特に連絡がないな。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Atomパッケージをアンパブリッシュする</title>
          <link>https://www.kaitoy.xyz/2015/12/02/unpublish-atom-package/</link>
          <pubDate>Wed, 02 Dec 2015 11:23:02 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/12/02/unpublish-atom-package/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://atom.io/&#34;&gt;&lt;strong&gt;Atom&lt;/strong&gt;&lt;/a&gt;のパッケージをリリースすることをパブシッシュというが、リリースを取り消すことをアンパブリッシュという。
この記事はそのアンパブリッシュのやり方などについて。&lt;/p&gt;

&lt;p&gt;筆者の環境は以下。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Windows 7 x64&lt;/li&gt;
&lt;li&gt;Atom 1.2.4&lt;/li&gt;
&lt;li&gt;Git for Windows 2.6.3&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;アンパブリッシュのやり方&#34;&gt;アンパブリッシュのやり方&lt;/h2&gt;

&lt;p&gt;リリースしたパッケージのプロジェクトのルートフォルダ(package.jsonがあるところ)に&lt;code&gt;cd&lt;/code&gt;して、&lt;code&gt;apm unpublish&lt;/code&gt;を実行するだけ。&lt;/p&gt;

&lt;p&gt;または、任意のフォルダで&lt;code&gt;apm unpublish &amp;lt;パッケージ名&amp;gt;&lt;/code&gt;を実行する。&lt;/p&gt;

&lt;p&gt;特定のバージョンだけアンパブリッシュしたい場合は、&lt;code&gt;apm unpublish &amp;lt;パッケージ名&amp;gt;@&amp;lt;バージョン&amp;gt;&lt;/code&gt;。例えば&lt;code&gt;apm unpublish disturb-me@0.1.0&lt;/code&gt;。&lt;/p&gt;

&lt;h2 id=&#34;注意すべき点-1-git-bashでアンパブリッシュするとエラー&#34;&gt;注意すべき点 1: Git Bashでアンパブリッシュするとエラー&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://git-for-windows.github.io/&#34;&gt;Git for Windows&lt;/a&gt;のGit Bash上で、Windows版Atomに付属するapmで&lt;code&gt;apm unpublish&lt;/code&gt;を実行すると以下のエラーが出る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error: EINVAL, invalid argument
    at new Socket (net.js:157:18)
    at process.stdin (node.js:693:19)
    at Unpublish.module.exports.Unpublish.promptForConfirmation (C:\Users\Kaito\AppData\Local\atom\app-1.2.4\resources\app\apm\lib

\unpublish.js:87:48)
    at Unpublish.module.exports.Unpublish.run (C:\Users\Kaito\AppData\Local\atom\app-1.2.4\resources\app\apm\lib\unpublish.js:126:21)
    at Object.module.exports.run (C:\Users\Kaito\AppData\Local\atom\app-1.2.4\resources\app\apm\lib\apm-cli.js:226:32)
    at Object.&amp;lt;anonymous&amp;gt; (C:\Users\Kaito\AppData\Local\atom\app-1.2.4\resources\app\apm\lib\cli.js:6:7)
    at Object.&amp;lt;anonymous&amp;gt; (C:\Users\Kaito\AppData\Local\atom\app-1.2.4\resources\app\apm\lib\cli.js:17:4)
    at Module._compile (module.js:456:26)
    at Object.Module._extensions..js (module.js:474:10)
    at Module.load (module.js:356:32)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;コマンドプロンプトでやるべし。&lt;/p&gt;

&lt;h2 id=&#34;注意すべき点-2-アンパブリッシュはパブリッシュの真逆じゃない&#34;&gt;注意すべき点 2: アンパブリッシュはパブリッシュの真逆じゃない&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/08/21/japanese-word-selection/#10-%E3%83%91%E3%83%96%E3%83%AA%E3%83%83%E3%82%B7%E3%83%A5&#34;&gt;以前の記事&lt;/a&gt;で
&lt;code&gt;apm publish&lt;/code&gt;は以下の処理をすると書いた。&lt;/p&gt;

&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;(初回のみ)パッケージ名をatom.ioに登録する。&lt;/li&gt;
&lt;li&gt;package.jsonのversionをインクリメントしてコミットする。&lt;code&gt;apm publish&lt;/code&gt;にminorを指定するので、0.1.0になる。代わりにmajorかpatchを指定すると、1.0.0か0.0.1になる。&lt;/li&gt;
&lt;li&gt;Gitのタグを作る。&lt;/li&gt;
&lt;li&gt;GitHubに変更とタグをpushする。&lt;/li&gt;
&lt;li&gt;atom.ioにパッケージを登録する。&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;この内、&lt;code&gt;apm unpublish&lt;/code&gt;が取り消してくれるのは 5 だけ。&lt;/p&gt;

&lt;p&gt;3, 4 のタグ作成も取り消したいのであれば、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git tag -d v0.1.0
git push origin :v0.1.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;のようにして、ローカルリポジトリとリモートリポジトリ両方のタグを削除する。&lt;/p&gt;

&lt;p&gt;また、2 のpackage.jsonのversion変更を取り消したいのであれば、&lt;code&gt;git log&lt;/code&gt;で&lt;code&gt;Prepare 0.1.0 release&lt;/code&gt;みたいなログのコミットをさがしてそのハッシュをメモり、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git revert &amp;lt;ハッシュ&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;を実行して&lt;code&gt;git push&lt;/code&gt;。(上記&amp;lt;ハッシュ&amp;gt;の部分は、&lt;code&gt;apm publish&lt;/code&gt;後何もcommitしてないなら&lt;code&gt;HEAD&lt;/code&gt;でもよし。)&lt;/p&gt;

&lt;h2 id=&#34;注意すべき点-3-パッケージのキャッシュ&#34;&gt;注意すべき点 3: パッケージのキャッシュ&lt;/h2&gt;

&lt;p&gt;とあるパッケージ、仮に&lt;code&gt;hoge&lt;/code&gt;を開発していたとき、以下のような操作をした後に変な現象が起こった。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;バージョン&lt;code&gt;0.1.0&lt;/code&gt;をパブリッシュ。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hoge&lt;/code&gt;をちゃんとインストールできるかを確認するために、

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;apm unlink hoge&lt;/code&gt;で&lt;code&gt;.atom\packages&lt;/code&gt;からリンクを削除。(&lt;a href=&#34;https://www.kaitoy.xyz/2015/08/21/japanese-word-selection/#11-%E3%83%91%E3%83%83%E3%82%B1%E3%83%BC%E3%82%B8%E3%81%AE%E3%82%A2%E3%83%83%E3%83%97%E3%83%87%E3%83%BC%E3%83%88%E3%81%AE%E9%96%8B%E7%99%BA&#34;&gt;以前&lt;/a&gt;、パブリッシュすると&lt;code&gt;.atom\packages&lt;/code&gt;にはパッケージの実ファイルが入ると書いたが、リンクのままだった。勘違い?)&lt;/li&gt;
&lt;li&gt;AtomのSettingsから&lt;code&gt;hoge&lt;/code&gt;をインストール。&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;ちゃんとインストールできなかったので&lt;code&gt;apm unpublish hoge&lt;/code&gt;して、バージョンも戻す。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hoge&lt;/code&gt;を修正して、再度&lt;code&gt;0.1.0&lt;/code&gt;としてパブリッシュ。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hoge&lt;/code&gt;をちゃんとインストールできるかを再度確認するために、

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;apm unlink hoge&lt;/code&gt;して、&lt;/li&gt;
&lt;li&gt;AtomのSettingsから&lt;code&gt;hoge&lt;/code&gt;をインストール。&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;これをしたら最終的になぜか修正前の&lt;code&gt;hoge&lt;/code&gt;がインストールされた。
どうやらキャッシュがある模様ということで、&lt;a href=&#34;https://github.com/atom/apm/blob/master/src/install.coffee&#34;&gt;apmのソース&lt;/a&gt;をみたら、パッケージのインストール中に以下のようなことをしていることがわかった。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;AtomのサイトのREST API (&lt;a href=&#34;https://www.atom.io/api/packages/hoge/&#34;&gt;https://www.atom.io/api/packages/hoge/&lt;/a&gt;) からパッケージ情報を取得。&lt;/li&gt;
&lt;li&gt;また別のREST API (&lt;a href=&#34;https://www.atom.io/api/packages/hoge/versions/0.1.0/tarball&#34;&gt;https://www.atom.io/api/packages/hoge/versions/0.1.0/tarball&lt;/a&gt;) を実行して、パッケージのアーカイブ(tar.gz)をテンポラリフォルダにダウンロード。
どうもこれは実際にはGitHubの&lt;a href=&#34;https://help.github.com/articles/about-releases/&#34;&gt;Releases&lt;/a&gt;からダウンロードしている模様。
因みにGitHub Releasesのアーカイブは、リポジトリにタグが追加されると自動で作られる。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;npm install&lt;/code&gt;でそのアーカイブを指定してインストール。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;この手順の 2 をやる前に、&lt;code&gt;.atom\.apm\hoge\0.1.0\package.tgz&lt;/code&gt;を探して、見つかるとダウンロードせずにこっちをインストールする。
ソースの雰囲気から、&lt;code&gt;.atom\.apm\&lt;/code&gt;に入っているのはキャッシュのようで、いつ作られるかはよくわからないが、これが上記変な現象の原因ぽい。&lt;/p&gt;

&lt;p&gt;ということで、&lt;code&gt;.atom\.apm\hoge\0.1.0\package.tgz&lt;/code&gt;を消して再度インストールしたら無事修正後の&lt;code&gt;hoge&lt;/code&gt;が入った。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;このキャッシュの件や、&lt;code&gt;apm unpublish&lt;/code&gt;がパッケージのバージョンを戻さないところをみると、同じバージョンを再度パブリッシュするのはダメな操作なのかもしれない。
修正したかったらバージョンを上げろということなのかも。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ありがとうさようならjapanese-wrap</title>
          <link>https://www.kaitoy.xyz/2015/11/16/thanks-bye-bye-japanese-wrap/</link>
          <pubDate>Mon, 16 Nov 2015 22:38:11 -0700</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/11/16/thanks-bye-bye-japanese-wrap/</guid>
          <description>&lt;p&gt;テキストエディタ&lt;a href=&#34;https://atom.io/&#34;&gt;Atom&lt;/a&gt;のとある有名なパッケージの話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/08/21/japanese-word-selection/&#34;&gt;以前の記事&lt;/a&gt;でも触れた&lt;a href=&#34;https://github.com/raccy/japanese-wrap&#34;&gt;japanese-wrap&lt;/a&gt;。
日本語が画面の端でうまく改行(softwrap)してくれない問題を解決してくれるパッケージ。
Atomで日本語を書く殆どの人がインストールしているであろうパッケージだが、先日11/12にリリースされた&lt;a href=&#34;http://blog.atom.io/2015/11/12/atom-1-2.html&#34;&gt;Atom 1.2&lt;/a&gt;で&lt;a href=&#34;https://ja.wikipedia.org/wiki/CJK%E7%B5%B1%E5%90%88%E6%BC%A2%E5%AD%97&#34;&gt;CJK文字&lt;/a&gt; (中国語・日本語・朝鮮語・ベトナム語の文字)のsoftwrapへの対応が実装されたので、もはや不要になった。&lt;/p&gt;

&lt;p&gt;むしろ、Atom 1.2でjapanese-wrapを有効にすると、以下のように残念なことになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/thanks-bye-bye-japanese-wrap/w-japanese-wrap.jpg&#34; alt=&#34;project tree&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;japanese-wrapにはずっとお世話になってきたので申し訳なく名残惜しくもあるが、AtomのSettingsからDisableまたはUninstallさせてもらうしかあるまい。すると以下の様に直る。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/thanks-bye-bye-japanese-wrap/wo-japanese-wrap.jpg&#34; alt=&#34;project tree&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ありがとうさようならjapanese-wrap。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>よいオブジェクトの七つの美徳</title>
          <link>https://www.kaitoy.xyz/2015/10/28/seven-virtues-of-good-object/</link>
          <pubDate>Wed, 28 Oct 2015 13:38:47 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/10/28/seven-virtues-of-good-object/</guid>
          <description>

&lt;p&gt;このエントリでは、Yegor Bugayenkoによる記事、&lt;a href=&#34;http://www.yegor256.com/2014/11/20/seven-virtues-of-good-object.html&#34;&gt;Seven Virtues of a Good Object&lt;/a&gt;を紹介する。
(Yegorから和訳と転載の許可は得た。)
以下はその全文の和訳だが、意訳超訳が混じっているので、もとのニュアンスを知りたければ元記事を読んでもいいし、読まなくてもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Martin Fowler&lt;a href=&#34;http://martinfowler.com/bliki/InversionOfControl.html&#34;&gt;曰く&lt;/a&gt;、&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;ライブラリは本質的には呼び出し可能な関数の集合で、最近は普通クラス内にまとめられる。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;クラス内にまとめられた関数?
失礼を承知で言わせてもらうが、これは間違っている。
そして、これはオブジェクト指向プログラミングにおいて、クラスに対する非常に一般的な誤解だ。
クラスは関数をまとめるものではないし、オブジェクトはデータ構造体ではない。&lt;/p&gt;

&lt;p&gt;では、なにが適切なオブジェクトなのか?
どれが不適切なオブジェクトなのか?
その違いは何か?
これは論争を呼ぶ主題ではあるが、とても重要だ。
オブジェクトが何かを理解しなければ、オブジェクト指向ソフトウェアをどうやって書くんだ?
まあ、JavaやRubyなどのおかげで、書けることは書ける。
しかし、はたして良いものができるだろうか?
不幸にも、これは厳密な科学ではなく、様々な意見がある。
ここに、良いオブジェクトの特性を私なりにリストアップする。&lt;/p&gt;

&lt;h1 id=&#34;クラス-vs-オブジェクト&#34;&gt;クラス vs オブジェクト&lt;/h1&gt;

&lt;p&gt;&lt;img alt=&#34;good-object-1.png&#34; src=&#34;https://www.kaitoy.xyz/images/seven-virtues-of-good-object/good-object-1.png&#34; width=&#34;300&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;オブジェクトについて議論を始める前に、クラスとは何かを定義しよう。
それはオブジェクトが生まれる(インスタント化される)場所だ。
クラスの主な責任は、要求に応じて新しいオブジェクトを構築し、使われなくなったオブジェクトを破壊することだ。
クラスはその子供たちがどのように見えどのように振る舞うべきかを知っている。
言い換えれば、子供たちが従うべき契約を知っている。&lt;/p&gt;

&lt;p&gt;クラスが「オブジェクトのテンプレート」であると言われることもある。(例えば&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%AF%E3%83%A9%E3%82%B9_%28%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF%29&#34;&gt;Wikipediaにはそう書いてある&lt;/a&gt;。)
この定義はクラスを受動的なポジションに置いているので正しくない。
この定義は、だれかがテンプレートを取得してそこからオブジェクトを構築するということを想定している。
これは、技術的には正しいかもしれないが、概念的には間違っている。
クラスとその子供たちだけが居るのであって、他の誰も関係すべきではない。
あるオブジェクトがクラスに他のオブジェクトを作るように頼み、そのクラスがオブジェクトを構築する。それだけだ。
RubyはJavaやC++に比べてこの概念をかなりうまく表現している。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;photo = File.new(&#39;/tmp/photo.png&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;photo&lt;/code&gt;オブジェクトは&lt;code&gt;File&lt;/code&gt;クラスによって構築される。(&lt;code&gt;new&lt;/code&gt;はそのクラスへのエントリポイント。)
オブジェクトは、いったん構築されると、自身に基づいて行動する。
オブジェクトは、自身を誰が構築したかとか、何人兄弟姉妹がいるかとかを知っているべきではない。
そう、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%AA%E3%83%95%E3%83%AC%E3%82%AF%E3%82%B7%E3%83%A7%E3%83%B3_%28%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6%29&#34;&gt;リフレクション&lt;/a&gt;は酷いアイデアだと言っている。
それについては他の記事で詳しく書くとして、ここでは、オブジェクトについてと、その最高と最悪の両面について話そう。&lt;/p&gt;

&lt;h1 id=&#34;1-彼は実世界に存在している&#34;&gt;1. 彼は実世界に存在している&lt;/h1&gt;

&lt;p&gt;&lt;img alt=&#34;good-object-2.png&#34; src=&#34;https://www.kaitoy.xyz/images/seven-virtues-of-good-object/good-object-2.png&#34; width=&#34;300&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;まず第一に、オブジェクトは生きた有機体だ。
もっと言えば、オブジェクトは&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E6%93%AC%E4%BA%BA%E5%8C%96&#34;&gt;擬人化&lt;/a&gt;されるべきだ。
つまり、人間(もしくは、君がより好むならペット)のように扱われるべきだ。
基本的にこれは、オブジェクトはデータ構造体や関数の集合ではないということを意味している。
代わりに、オブジェクトは独立したエンティティで、それ自身のライフサイクル、振る舞い、性質を持つ。&lt;/p&gt;

&lt;p&gt;従業員、部署、HTTPリクエスト、MySQLのテーブル、ファイルの行、ファイルそのもの、これらは適切なオブジェクトだ。
なぜならこれらは、ソフトウェアを停止した時でも実世界に存在しているから。
より正確には、オブジェクトは実世界のモノの表現のひとつだ。
オブジェクトは実世界のモノと他のオブジェクトとの間のプロキシだ。
そのようなモノが存在しなければ、明らかにオブジェクトは存在しない。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;photo = File.new(&#39;/tmp/photo.png&#39;)
puts photo.width()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この例では、&lt;code&gt;File&lt;/code&gt;に新しいオブジェクト&lt;code&gt;photo&lt;/code&gt;を構築するよう頼んでいる。
&lt;code&gt;photo&lt;/code&gt;はディスク上の実際のファイルの表現となる。
ファイルもまた仮想のもので、コンピュータが起動している間だけ存在すると言う人がいるかもしれない。
それには私も同意し、「実世界」の定義を次のように改善しよう。
オブジェクトが住むプログラムの範囲外に存在する全てのもの。
ディスク上のファイルはプログラムの範囲外にあり、その表現をプログラム内に作成することは完全に正しいことと言える。&lt;/p&gt;

&lt;p&gt;コントローラ、パーサ、フィルタ、バリデータ、サービスロケータ、シングルトン、ファクトリー、これれは良いオブジェクトではない。(そう、ほとんどのGoFパターンはアンチパターンだ!)
これらはソフトウェアの外側、実世界に存在していない。
他のオブジェクト同士を結びつけるためだけに考案されたものだ。
人工的で偽のモノだ。何も表現していない。
真面目な話、XMLパーサ、これが表現するものはなんだ?
何もない。&lt;/p&gt;

&lt;p&gt;上記オブジェクトのいくつかは名前を変えれば良いオブジェクトになる。他のものは決して存在を許されない。
例えば、XMLパーサは「パース可能なXML」と改名でき、プログラム外に存在するXMLドキュメントを表現するようになる。&lt;/p&gt;

&lt;p&gt;常に、「このオブジェクトの背後にある実世界のエンティティは何か?」を自問しよう。
もし回答が見つからなければ、リファクタリングを考えるときだ。&lt;/p&gt;

&lt;h1 id=&#34;2-彼は契約によって働く&#34;&gt;2. 彼は契約によって働く&lt;/h1&gt;

&lt;p&gt;&lt;img alt=&#34;good-object-3.png&#34; src=&#34;https://www.kaitoy.xyz/images/seven-virtues-of-good-object/good-object-3.png&#34; width=&#34;300&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;良いオブジェクトは常に契約によって働く。
彼は、個人的な実力ではなく、契約に従うということを理由に雇われることを期待している。
一方、我々がオブジェクトを雇うとき、差別待遇をして、特定のクラスの特定のオブジェクトが我々のために働いてくれると期待してはいけない。
どんなオブジェクトも契約通りのことをすると考えるべきだ。
オブジェクトが期待通りの働きをしている限りは、彼の出生や性別や信仰に興味を持つべきではない。&lt;/p&gt;

&lt;p&gt;例えば、ある写真をスクリーンに表示したいとする。その写真はPNGフォーマットのファイルから読みこまれる。
私は&lt;code&gt;DataFile&lt;/code&gt;クラスのオブジェクトと契約を結び、その画像のバイナリコンテンツをくれるよう頼む。&lt;/p&gt;

&lt;p&gt;しかし待ってほしい。私はそのデータが厳密にどこから来るかを気にするだろうか?
ディスク上のファイル、HTTPリクエスト、Dropbox上のドキュメントかもしれないが、実際私は気にしない。
私が気にするのは、オブジェクトがPNGデータが入ったバイト配列をくれるということだけだ。
つまり、私が結ぶ契約は以下のようなものだ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;interface Binary {
  byte[] read();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この場合、(DataFileクラスだけでなく)どんなクラスのどんなオブジェクトでも私のもとで働くことができる。
オブジェクトが働く資格を得るためにすべきは、&lt;code&gt;Binary&lt;/code&gt;インターフェースを実装することにより、契約に従うということだけだ。&lt;/p&gt;

&lt;p&gt;この際のルールは単純で、良いオブジェクトの全てのpublicメソッドは、インターフェースのものを実装すべきだということだ。
もしオブジェクトがインターフェースから継承していないpublicメソッドを持っていたら、それはダメな設計だ。&lt;/p&gt;

&lt;p&gt;これには実用的な理由が二つある。
第一に、無契約で働いているオブジェクトは、ユニットテストで使うモックが作れない。
第二に、無契約なオブジェクトは&lt;a href=&#34;https://ja.wikipedia.org/wiki/Decorator_%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3&#34;&gt;デコレータ&lt;/a&gt;で拡張できない。&lt;/p&gt;

&lt;h1 id=&#34;3-彼はユニーク&#34;&gt;3. 彼はユニーク&lt;/h1&gt;

&lt;p&gt;良いオブジェクトは常に、ユニークであるために何かを内包しているべきだ。
何も内包していないと、そのオブジェクトとまったく同じクローンが存在し得ることになる。私はこれはダメなことだと考えている。
以下がクローンが存在し得る悪いオブジェクトの例。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class HTTPStatus implements Status {
  private URL page = new URL(&amp;quot;http://www.google.com&amp;quot;);
  @Override
  public int read() throws IOException {
    return HttpURLConnection.class.cast(
      this.page.openConnection()
    ).getResponseCode();
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;HTTPStatus&lt;/code&gt;クラスのインスタンスは複数作れ、それら全ては互いに等しい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;first = new HTTPStatus();
second = new HTTPStatus();
assert first.equals(second);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;明らかにユーティリティクラスは、スタティックメソッドだけを持つので、よいオブジェクトにインスタンス化できない。
より一般的には、ユーティリティクラスはこの記事で述べられているどのメリットも持たず、「クラス」と呼ぶことさえできない。
ユーティリティクラスは単純にオブジェクトパラダイムの酷い乱用で、モダンなオブジェクト指向言語の作者がスタティックメソッドを有効にしたせいで存在している。&lt;/p&gt;

&lt;h1 id=&#34;4-彼は不変-immutable&#34;&gt;4. 彼は不変(Immutable)&lt;/h1&gt;

&lt;p&gt;良いオブジェクトは内包する状態を決して変えるべきではない。
オブジェクトは実世界のエンティティの表現であることを思い出してほしい。このエンティティは、オブジェクトが存続する間は変化しないはずだ。
言い換えれば、オブジェクトはそれが表すエンティティに決して背いてはいけない。
オブジェクトがその所有者を変化させることはないよね。&lt;/p&gt;

&lt;p&gt;不変であることが、全てのメソッドが常に同じ値を返すことを意味するわけではないことに注意してほしい。
むしろ、良い不変オブジェクトはとても動的だ。
しかし、それは内部状態を変えることはない。例えば、&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Immutable
final class HTTPStatus implements Status {
  private URL page;
  public HTTPStatus(URL url) {
    this.page = url;
  }
  @Override
  public int read() throws IOException {
    return HttpURLConnection.class.cast(
      this.page.openConnection()
    ).getResponseCode();
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;read()&lt;/code&gt;メソッドは異なる値を返す可能性があるが、このオブジェクトは不変だ。
ある一つのウェブページを指し、他のどこを指すこともない。
内包する状態を決して変えないし、表現しているURLに背くこともない。&lt;/p&gt;

&lt;p&gt;なぜこの不変性が美徳なのか?
次の記事で詳細を説明している: &lt;a href=&#34;http://www.yegor256.com/2014/06/09/objects-should-be-immutable.html&#34;&gt;オブジェクトは不変であるべきだ&lt;/a&gt;。
要するに、不変オブジェクトが優れている理由は、&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;不変オブジェクトは簡単に構築、テスト、使用できる。&lt;/li&gt;
&lt;li&gt;真の不変オブジェクトは常にスレッドセーフ。&lt;/li&gt;
&lt;li&gt;時間的結合(訳注: コードの実行順の暗黙的な制約)を回避するのに役立つ。&lt;/li&gt;
&lt;li&gt;不変オブジェクトを使っても副作用がおきない。(防御的コピー無)&lt;/li&gt;
&lt;li&gt;エラー発生時の原子性が保証されている。&lt;/li&gt;
&lt;li&gt;キャッシュしやすい。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/07/26/why-null-is-bad/&#34;&gt;NULL参照&lt;/a&gt;を防ぐ。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;もちろん、良いオブジェクトは&lt;a href=&#34;https://www.kaitoy.xyz/2015/07/22/getters-setters-evil/&#34;&gt;setter&lt;/a&gt;をもたない。セッターはオブジェクトの状態を変え得るし、URLに背くことを強要する。
言い換えると、&lt;code&gt;HTTPStatus&lt;/code&gt;で&lt;code&gt;setURL()&lt;/code&gt;メソッドを実装することは酷い間違いとなる。&lt;/p&gt;

&lt;p&gt;その他にも、不変オブジェクトを使うことで、設計は必然的に凝集度の高いものになり、また密で理解しやすいものになる。
これについては&lt;a href=&#34;http://www.yegor256.com/2014/11/07/how-immutability-helps.html&#34;&gt;不変性がどう役に立つか&lt;/a&gt;という記事で説明している。&lt;/p&gt;

&lt;h1 id=&#34;5-彼のクラスはスタティックなものをいっさいもたない&#34;&gt;5. 彼のクラスはスタティックなものをいっさいもたない&lt;/h1&gt;

&lt;p&gt;スタティックメソッドは、オブジェクトではなくクラスの挙動を実装する。
&lt;code&gt;File&lt;/code&gt;クラスがあり、その子供が&lt;code&gt;size()&lt;/code&gt;メソッドを持つとする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;final class File implements Measurable {
  @Override
  public int size() {
    // calculate the size of the file and return
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここまではよい。&lt;code&gt;size()&lt;/code&gt;メソッドは&lt;code&gt;Measurable&lt;/code&gt;契約によって存在し、&lt;code&gt;File&lt;/code&gt;クラスの全てのオブジェクトはそのサイズを測ることができる。
このクラスを、代わりにスタティックメソッドを持つように実装するのは酷い間違いだ。
(こうした設計は&lt;a href=&#34;http://www.yegor256.com/2014/05/05/oop-alternative-to-utility-classes.html&#34;&gt;ユーティリティクラス&lt;/a&gt;と呼ばれ、JavaやRubyなどのほぼ全てのOOP言語でとても人気だ。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// TERRIBLE DESIGN, DON&#39;T USE!
class File {
  public static int size(String file) {
    // calculate the size of the file and return
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この設計はオブジェクト指向パラダイムの真逆を行く。
なぜかって?
なぜならスタティックメソッドはオブジェクト指向プログラミングを「クラス指向」プログラミングに変えてしまうからだ。
この、&lt;code&gt;size()&lt;/code&gt;メソッドは、オブジェクトではなくクラスの挙動を公開する。
これの何が間違っているかと言われるかもしれない。
なぜオブジェクトとクラス両方をコード中で第一級市民として使えないのか?
なぜ両方ともがメソッドやプロパティを持てないのか?&lt;/p&gt;

&lt;p&gt;この問題は、クラス指向プログラミングでは、分離ができなくなるというものだ。
複雑な問題をブレイクダウンできなくなる。
なぜなら、プログラム全体の中でクラスのインスタンスがたったひとつしか存在しないからだ。
OOPの力は、オブジェクトをスコープを分離するための道具として使えることだ。
あるオブジェクトをメソッド中でインスタンス化したとき、そのオブジェクトは特定のタスク専任となる。
そのオブジェクトは、メソッド周辺の他のオブジェクトから完璧に分離されている。
このオブジェクトはメソッドスコープのローカル変数だ。
スタティックメソッドを持つクラスは、どこで使うにしろ常にグローバル変数だ。
このため、この変数とのやりとりを分離することはできない。&lt;/p&gt;

&lt;p&gt;オブジェクト指向の原理に概念的に反しているということの他にも、パブリックなスタティックメソッドは実用的な欠点も持っている。&lt;/p&gt;

&lt;p&gt;第一に、モックを作れない。
(いや、&lt;a href=&#34;https://code.google.com/p/powermock/&#34;&gt;PowerMock&lt;/a&gt;を使うことはできる。が、これはJavaプロジェクトで取り得る決断の中で最悪なものとなるだろう。。。私はそれを数年前にやってしまった。)&lt;/p&gt;

&lt;p&gt;第二に、定義上スレッドセーフではない。なぜなら、常にスタティック変数とともに動くからで、スタティック変数は全てのスレッドからアクセスできるからだ。
スタティックメソッドをスレッドセーフに作ることもできるが、この場合常に明示的な同期が必要になる。&lt;/p&gt;

&lt;p&gt;パブリックなスタティックメソッドを見つけたら常に、即座に書き直すべきだ。
スタティック(グローバル)変数がどれだけ酷いかについては説明したくもない。それは明らかだ。&lt;/p&gt;

&lt;h1 id=&#34;6-彼の名前は職名ではない&#34;&gt;6. 彼の名前は職名ではない&lt;/h1&gt;

&lt;p&gt;&lt;img alt=&#34;good-object-4.png&#34; src=&#34;https://www.kaitoy.xyz/images/seven-virtues-of-good-object/good-object-4.png&#34; width=&#34;300&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;オブジェクト名はそのオブジェクトが何であるかを示すべきで、何をするかを示すべきではない。
実世界の物に名付けるのと同様に。
ページ集めではなく本、水入れではなくカップ、体飾りではなくTシャツ。
もちろん、プリンタやコンピュータのような例外はあるが、これらはこの記事を読まなかった人々によってごく最近発明されたものだ。&lt;/p&gt;

&lt;p&gt;例えば、次のような名前はその持ち主が何であるかを示す。
りんご、ファイル、HTTPリクエスト群、ソケット、XMLドキュメント、ユーザリスト、正規表現、整数、PostgreSQLテーブル、Jeffrey Lebowski。
適切な名前はいつも小さい絵として描ける。正規表現でさえ描ける。&lt;/p&gt;

&lt;p&gt;逆に、次に挙げる名前の例は持ち主が何をするかを示す。
ファイルリーダ、テキストパーサ、URLバリデータ、XMLプリンタ、サービスロケータ、シングルトン、スクリプトランナ、Javaプログラマ。
これらの絵を描けるか?
描けない。
こういう名前は良いオブジェクトには適さない。
これらは酷い設計につながる酷い名前だ。&lt;/p&gt;

&lt;p&gt;一般的に、「-er」で終わる名前を避けるべきだ。そのほとんどはダメなものだ。&lt;/p&gt;

&lt;p&gt;「&lt;code&gt;FileReader&lt;/code&gt;の代わりは何」と疑問に思うだろう。
よりよい名前は何?&lt;/p&gt;

&lt;p&gt;ええと、我々は既に&lt;code&gt;File&lt;/code&gt;を持っていて、それは実世界のディスク上のファイルの表現だ。
この表現は十分に強力ではない。なぜなら、それはファイルの内容を読む方法を知らないからだ。
その能力を持ったより強力なものを作りたい。
何という名前にする?
名前は、その持ち主が何をするかではなく、何であるかを示すべきであるということを思い出してほしい。
持ち主は何か?
データを持ったファイルだ。ただのファイルではなく。
&lt;code&gt;File&lt;/code&gt;っぽいけど、もっと洗練されたものだ。データを持った。
なので、&lt;code&gt;FileWithData&lt;/code&gt;、もしくは単に&lt;code&gt;DataFile&lt;/code&gt;というのはどうだろう?&lt;/p&gt;

&lt;p&gt;同様のロジックを他の全ての名前にも適用すべきだ。
常に何をするかよりも何であるかを考えよう。
オブジェクトに職名ではなく、リアルで、意味のある名前を付けよう。&lt;/p&gt;

&lt;p&gt;より詳しくは「&lt;a href=&#34;http://www.yegor256.com/2015/03/09/objects-end-with-er.html&#34;&gt;-ERで終わるオブジェクトを作るな&lt;/a&gt;」を参照。&lt;/p&gt;

&lt;h1 id=&#34;7-彼のクラスはfinalかabstractのどちらか&#34;&gt;7. 彼のクラスはFinalかAbstractのどちらか&lt;/h1&gt;

&lt;p&gt;&lt;img alt=&#34;good-object-5.png&#34; src=&#34;https://www.kaitoy.xyz/images/seven-virtues-of-good-object/good-object-5.png&#34; width=&#34;300&#34; style=&#34;margin: 0px auto; display: block;&#34;&gt;&lt;/p&gt;

&lt;p&gt;良いオブジェクトはfinalまたはabstractなクラスから生成される。
&lt;code&gt;final&lt;/code&gt;クラスは継承によって拡張できないクラスだ。
&lt;code&gt;abstract&lt;/code&gt;クラスは子供を持てないクラスだ。
簡単に言うと、クラスは、「君は僕を決して壊せない。僕はブラックボックスだ。」か、または「僕は壊れている。直してから使ってくれ。」のどちらかを言う。&lt;/p&gt;

&lt;p&gt;その間には何もない。finalクラスはブラックボックスで、あらゆる意味で変更できない。
オブジェクトは現状のままで働き、君はそれを使うか捨てるかしかしない。
そのプロパティを継承する別のクラスを作ることはできない。
これは&lt;code&gt;final&lt;/code&gt;修飾子によって禁止されている。
そのようなfinalクラスを拡張する唯一の手段は、その子供をデコレートすることだ。
例えば、(上記)&lt;code&gt;HTTPStatus&lt;/code&gt;クラスがあり、それを気に入らなかったとする。
いやまあ好きではあるけど、私にとっては十分強力ではないんだ。
HTTPステータスが400より大きい場合に例外を投げて欲しい。
&lt;code&gt;read()&lt;/code&gt;メソッドにもう少し処理をしてもらいたい。
古風なやり方は、そのクラスを拡張してメソッドを上書きすることだ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class OnlyValidStatus extends HTTPStatus {
  public OnlyValidStatus(URL url) {
    super(url);
  }
  @Override
  public int read() throws IOException {
    int code = super.read();
    if (code &amp;gt; 400) {
      throw new RuntimException(&amp;quot;unsuccessful HTTP code&amp;quot;);
    }
    return code;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なぜこれではダメなのか?
メソッドのひとつをオーバーライドすることで親クラス全体のロジックを壊す危険があるので全然ダメだ。
&lt;code&gt;read()&lt;/code&gt;を子クラスでオーバーライドしたら、親クラスから来る全てのメソッドがその新しいやつを使うことになる、ということを忘れないで欲しい。
これは、文字通り新しい「実装のかけら」をクラスの内部に挿入するということだ。
哲学的に言って、これは反則だ。&lt;/p&gt;

&lt;p&gt;一方、finalクラスを拡張するためには、それをブラックボックスのように扱い、他の実装でデコレートする必要がある。(&lt;a href=&#34;https://ja.wikipedia.org/wiki/Decorator_%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3&#34;&gt;デコレータパターン&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;final class OnlyValidStatus implements Status {
  private final Status origin;
  public OnlyValidStatus(Status status) {
    this.origin = status;
  }
  @Override
  public int read() throws IOException {
    int code = this.origin.read();
    if (code &amp;gt; 400) {
      throw new RuntimException(&amp;quot;unsuccessful HTTP code&amp;quot;);
    }
    return code;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このクラスがもともとと同じインターフェース、&lt;code&gt;Status&lt;/code&gt;を実装していることに注目して欲しい。
&lt;code&gt;HTTPStatus&lt;/code&gt;のインスタンスはコンストラクタを通して渡され、内包される。
そして、全てのメソッド呼び出しは割り込まれ、必要に応じて独自に実装される。
この設計だと、もとのオブジェクトをブラックボックスとして扱い、その内部のロジックには決して触らない。&lt;/p&gt;

&lt;p&gt;もし&lt;code&gt;final&lt;/code&gt;というキーワードを使わなかったら、だれでも(君自身でも)そのクラスを拡張し、損なうことができる。(よって&lt;code&gt;final&lt;/code&gt;でないクラスは悪い設計だ。)&lt;/p&gt;

&lt;p&gt;abstractクラスは真反対なケースだ。それは不完全で、そのままでは使えないことを示している。
独自の実装ロジックを挿入する必要があるが、それは許可された部分だけに限られる。
この部分は&lt;code&gt;abstract&lt;/code&gt;メソッドとして明示的に示されている。
例えば、&lt;code&gt;HTTPStatus&lt;/code&gt;は以下のようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;abstract class ValidatedHTTPStatus implements Status {
  @Override
  public final int read() throws IOException {
    int code = this.origin.read();
    if (!this.isValid()) {
      throw new RuntimException(&amp;quot;unsuccessful HTTP code&amp;quot;);
    }
    return code;
  }
  protected abstract boolean isValid();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;見て分かるとおり、このクラスはHTTPコードを検証する方法を知らないので、継承して&lt;code&gt;isValid()&lt;/code&gt;をオーバーライドすることによってそのロジックを挿入することを期待している。
この継承は親クラスを損なわない。他の全メソッドが&lt;code&gt;final&lt;/code&gt;によって守られているからだ。(メソッドの修飾子に注目してくれ。)
つまり、このクラスは攻撃への備えがしてあって、完全に防御している。&lt;/p&gt;

&lt;p&gt;まとめると、クラスは&lt;code&gt;final&lt;/code&gt;か&lt;code&gt;abstract&lt;/code&gt;のどちらかであるべきで、その中間はない。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上がYegorの記事。&lt;/p&gt;

&lt;p&gt;この記事は、オブジェクト指向原理主義者であるYegorが彼のオブジェクト観の概論を書いたものだ。
彼のオブジェクトに対するとんがった信念が読み取れる。&lt;/p&gt;

&lt;p&gt;記事の内容をまとめると、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;オブジェクトは何か実体と対応していないといけない。&lt;/li&gt;
&lt;li&gt;クラスはインターフェースを実装していないといけない。&lt;/li&gt;
&lt;li&gt;オブジェクトはユニーク性を保証するフィールドを持っていないといけない。&lt;/li&gt;
&lt;li&gt;オブジェクトは不変でないといけない&lt;/li&gt;
&lt;li&gt;クラスはスタティックメソッド/フィールドを持っていてはいけない。&lt;/li&gt;
&lt;li&gt;erで終わるクラス名を使ってはいけない。&lt;/li&gt;
&lt;li&gt;クラスにはfinalかabstractが付いていないといけない。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;#1と#6はだいたい同じことを主張していて、その内容は実用的というよりかは哲学的だ。
敢えて実用面について言えば、同じ哲学を共有しているチームがこの主張に従えば、そのチーム内でコードの可読性や保守性が上がるというメリットがあると考えられる。
が、オブジェクト指向原理主義よりもGoFのデザインパターンの方がはるかに広く深く浸透しているので、このメリットはあまりありがたみが無い。
私はオブジェクト真理教に入信したわけではないので、これからもControllerとかFactoryとかServiceとかいうクラスを書くだろう。&lt;/p&gt;

&lt;p&gt;#2については、言っていることは分かるしインターフェースのメリットもよく理解しているつもりだが、わんさとクラスを書かないといけないのに逐一インターフェースまで書いてられるかというのが本音だ。
実際には、モックを書いたり多態したいとき、または将来そうなると天啓があったとき、つまりは必要に応じてインターフェースを書くのであって、なんでもかんでも書いていたら書くのも読むのもいたずらに大変になってしまう。(そういう方針をとって開発者から不満が噴出したプロジェクトが身近にあったと聞いた。)
Yegorのプロジェクトでは全てのクラスがインターフェースを実装しているんだろうか。信じ難い。&lt;/p&gt;

&lt;p&gt;#3も、ちょっと実用的な雰囲気の主張だが、よくみるとこれに従うことでどんなメリットがあるかとか、従わないことでどんな問題が発生するかとかが書いてない。
哲学的な主張か。
私が開発している&lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;Pcap4J&lt;/a&gt;には、ネットワークパケットを表すクラスが多数あるが、それらからインスタンス化されるオブジェクトは必ずしもユニークではない。
例えば、Ethernetヘッダを表すクラスである&lt;a href=&#34;https://github.com/kaitoy/pcap4j/blob/master/pcap4j-core/src/main/java/org/pcap4j/packet/EthernetPacket.java&#34;&gt;EthernetHeader&lt;/a&gt;は、Ethernetパケットの送り元と送り先が同じで、且つレイヤ3のプロトコルが同じなら&lt;code&gt;equals()&lt;/code&gt;が&lt;code&gt;true&lt;/code&gt;を返す。
つまり、実世界で異なるパケットのヘッダでも、Java世界では同一とみなされることがよくある。
この実装で実用上困ることは無い気がするけど、オブジェクト指向原理主義に照らすとダメってことか?
&lt;code&gt;UUID&lt;/code&gt;みたいなフィールドでも加えればいいのか?
そんなフィールドはEthernetヘッダにはないのに?&lt;/p&gt;

&lt;p&gt;#4は好き。ただ全てに適用できるかというと疑問。不変オブジェクトで、例えば&lt;a href=&#34;http://qiita.com/disc99/items/840cf9936687f97a482b#effective-java-builder&#34;&gt;Builderパターン(GoFじゃなくてEffective Javaの方)&lt;/a&gt;が対応している問題をどう解決するんだろう?
すごく頑張ってYegorの言いつけを守りながら、Builderパターンっぽくインスタンス化できるEthernetHeader(という名のEthernetヘッダフィールドの値を保持するクラス)を書いてみたら以下のようになった。&lt;/p&gt;

&lt;p&gt;まず、一般的なヘッダを表す&lt;code&gt;Header&lt;/code&gt;クラスを作る。不変で、&lt;code&gt;id&lt;/code&gt;という適当なフィールドを持つ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package test;
import org.pcap4j.util.MacAddress;

public final class Header {
  private final int id;

  public Header(int id) {
    this.id = id;
  }

  public int getId() { return id; }

  public DstAddrSetEthernetHeader dstAddr(MacAddress dstAddr) {
    return new DstAddrSetEthernetHeader(this, dstAddr);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次に、&lt;code&gt;Header&lt;/code&gt;をデコレートして拡張し、&lt;code&gt;dstAddr&lt;/code&gt;というフィールドを追加したもちろん不変なクラス&lt;code&gt;DstAddrSetEthernetHeader&lt;/code&gt;(dstAddrだけがセットされたEthernetヘッダ)を作る。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package test;
import org.pcap4j.util.MacAddress;

public final class DstAddrSetEthernetHeader {
  private final Header header;
  private final MacAddress dstAddr;

  DstAddrSetEthernetHeader(Header header, MacAddress dstAddr) {
    this.header = header;
    this.dstAddr = dstAddr;
  }

  public MacAddress getDstAddr() { return dstAddr; }

  public int getId() { return header.getId(); }

  public DstAddrAndSrcAddrSetEthernetHeader srcAddr(MacAddress srcAddr) {
    return new DstAddrAndSrcAddrSetEthernetHeader(this, srcAddr);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;さらに&lt;code&gt;DstAddrSetEthernetHeader&lt;/code&gt;をデコレートして拡張し、&lt;code&gt;srcAddr&lt;/code&gt;というフィールドを追加したもちろん不変なクラス&lt;code&gt;DstAddrAndSrcAddrSetEthernetHeader&lt;/code&gt;(dstAddrとsrcAddrがセットされたEthernetヘッダ)を作る。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package test;
import org.pcap4j.packet.namednumber.EtherType;
import org.pcap4j.util.MacAddress;

public final class DstAddrAndSrcAddrSetEthernetHeader {
  private final DstAddrSetEthernetHeader header;
  private final MacAddress srcAddr;

  DstAddrAndSrcAddrSetEthernetHeader(DstAddrSetEthernetHeader header, MacAddress srcAddr) {
    this.header = header;
    this.srcAddr = srcAddr;
  }

  public MacAddress getSrcAddr() { return srcAddr; }

  public int getId() { return header.getId(); }

  public MacAddress getDstAddr() { return header.getDstAddr(); }

  public EthernetHeader type(EtherType type) {
    return new EthernetHeader(this, type);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;やっとビルド対象である&lt;code&gt;EthernetHeader&lt;/code&gt;を書く。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package test;
import org.pcap4j.packet.namednumber.EtherType;
import org.pcap4j.util.MacAddress;

public final class EthernetHeader {
  private final int id;
  private final MacAddress dstAddr;
  private final MacAddress srcAddr;
  private final EtherType type;

  public EthernetHeader(DstAddrAndSrcAddrSetEthernetHeader header, EtherType type) {
    this.id = header.getId();
    this.dstAddr = header.getDstAddr();
    this.srcAddr = header.getSrcAddr();
    this.type = type;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上記4つのクラスを使って、次のようにBuilderパターンっぽいことができる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package test;
import org.pcap4j.packet.namednumber.EtherType;
import org.pcap4j.util.MacAddress;

public class ImmutableBuilderSample {
  public static void main(String[] args) {
    EthernetHeader header
      = new Header(1)
          .dstAddr(MacAddress.getByName(&amp;quot;aa:bb:cc:dd:ee:ff&amp;quot;))
          .srcAddr(MacAddress.getByName(&amp;quot;11:22:33:44:55:66&amp;quot;))
          .type(EtherType.IPV4);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;パラメータの設定順を自由にしたければ、さらに&lt;code&gt;SrcAddrSetEthernetHeader&lt;/code&gt;とか&lt;code&gt;TypeSetEthernetHeader&lt;/code&gt;とか&lt;code&gt;DstAddrAndTypeSetEthernetHeader&lt;/code&gt;とか作らないといけない。これは疲れる。
沢山オブジェクトを作るのに、最後の&lt;code&gt;EthernetHeader&lt;/code&gt;以外のが使い捨てというのも辛い。
&lt;code&gt;EthernetHeader&lt;/code&gt;は3つしかフィールドがないからまだましな方なんだが。&lt;/p&gt;

&lt;p&gt;私は、不変クラスはスレッドセーフにすることを主目的として作る。
普通アプリケーションはマルチスレッドになるんだから、基本的にクラスは不変を目指して作り、どうしても可変にしたくなったときは内部で同期してスレッドセーフに保つか、外で同期してもらうか、またはシングルスレッドで使ってもらうかを考える。
上記のBuilderなんかは可変フィールドを使わないとまともに作れないし、その性質上マルチスレッドで使うことは普通ないし、無理に不変にする必要はなかろう。&lt;/p&gt;

&lt;p&gt;#5については、Yegorが問題視していることにはだいたい納得できる。(哲学的な部分以外は。。。)
しかし、Yegorが、スタティックメソッドが可変フィールドを参照することを前提に話しているところにひっかかる。
私はpublic staticなフィールドをfinal無しで書くことはないし、スタティックメソッドは殆どの場合引数だけを使うように書き、たまにfinalなフィールドを参照させるくらいだ。(ちょっとあやしいけど多分。)
世のユーティリティクラスもだいたいそんな感じで書かれているんじゃなかろうか。
この場合、スレッドセーフじゃないという問題点は出ないし、問題の分離も、スタティックフィールドでデータを共有するわけではないのでちゃんとできる。
モックはできないけど、ユーティリティクラスのモックを書きたいことなんてあるだろうか?&lt;/p&gt;

&lt;p&gt;#7は同意。abstractじゃないメソッドをオーバーライドするのって気持ち悪いし。
ところでデコレータパターンってすごい便利で汎用性高いと思うんだけど、いざというときに思いつかないようで、あんまり使ったことないな。&lt;/p&gt;

&lt;p&gt;以上ひとつひとつの主張について考えてみたけど、反感が多いな。
これはオブジェクト真理教に入信するメリットが見えてこないからだろう。
もともとOOPっていうのは、手続き型言語が隆盛な時代の関数を使った処理の分離という考え方を押し進め、処理と処理対象データを一緒にして分離するという実用的で技術的な目的のもとに生まれたもので、オブジェクトは実世界のモノを表現しなきゃいけないってのは後付けの哲学だ。
OOPはそれを共通認識として発展したわけではないので、極端な哲学に縛られていると長い歴史に揉まれた強力なノウハウの多くが使えなくなってしまう。
GoFのデザインパターンを否定するなら、GoFが解決した問題への別解を提示してくれないとなかなか受け入れがたい。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Step by Step to Add a Protocol Support to Pcap4J (Part 2)</title>
          <link>https://www.kaitoy.xyz/2015/10/12/step-by-step-to-add-a-protocol-support-to-pcap4j-2/</link>
          <pubDate>Mon, 12 Oct 2015 01:00:13 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/10/12/step-by-step-to-add-a-protocol-support-to-pcap4j-2/</guid>
          <description>

&lt;p&gt;This is continued from &lt;a href=&#34;https://www.kaitoy.xyz/2015/08/09/step-by-step-to-add-a-protocol-support-to-pcap4j-1/&#34;&gt;the part 1&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We are adding DHCP support to &lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;Pcap4J&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h3 id=&#34;packet-piece-class&#34;&gt;Packet Piece Class&lt;/h3&gt;

&lt;p&gt;A packet piece class is a Java class which represents a field of a packet.
We should create such classes instead of using a primitive types in some cases.&lt;/p&gt;

&lt;p&gt;In the case of DHCP, its &lt;strong&gt;flags&lt;/strong&gt; field includes two fields in itself as like below:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;                    1 1 1 1 1 1
0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|B|             MBZ             |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

B:  BROADCAST flag
MBZ:  MUST BE ZERO (reserved for future use)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Although this flags field is 2 bytes long and can be held by a primitive short variable, it&amp;rsquo;s better to create a packet piece class to hold it for better usability.&lt;/p&gt;

&lt;p&gt;I mean,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;boolean broadcast = DhcpV4Packet.getHeader().getFlags().isBroadcast();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;is better than&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;boolean broadcast = (0x8000 &amp;amp; DhcpV4Packet.getHeader().getFlags()) != 0;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;dhcpv4flags-class&#34;&gt;DhcpV4Flags class&lt;/h3&gt;

&lt;p&gt;Now, let&amp;rsquo;s write a packet piece class &lt;strong&gt;DhcpV4Flags&lt;/strong&gt; for the flags field.
For writing packet piece classes, there is no rule except that they must implement &lt;a href=&#34;http://docs.oracle.com/javase/7/docs/api/java/io/Serializable.html&#34;&gt;Serializable interface&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package org.pcap4j.packet;

import java.io.Serializable;

public final class DhcpV4Flags implements Serializable {

  private static final long serialVersionUID = -7144264525666462708L;

  private final short value;

  public static DhcpV4Flags newInstance(short value) {
    return new DhcpV4Flags(value);
  }

  private DhcpV4Flags(short value) {
    this.value = value;
  }

  public short value() {
    return value;
  }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What we should do to implement Serializable is only adding a field &lt;code&gt;private static final long serialVersionUID&lt;/code&gt; in this case because DhcpV4Flags has only one primitive short field.&lt;/p&gt;

&lt;p&gt;The short field holds entire value of the flags field.
The constructor receives a short value and simply stores it in the short field.
I made the constructor private and wrote a static factory method &lt;code&gt;newInstance&lt;/code&gt;, which is just my taste and not necessary.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Here, let&amp;rsquo;s remember that the flags field has two fields in itself, which are B (BROADCAST) and MBZ (MUST BE ZERO), and add two methods to get them.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;  public boolean isBroadcast() { return (value &amp;amp; 0x8000) != 0; }

  public short getMbz() { return (short)(value &amp;amp; 0x7FFF); }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;And, generally speaking, we should always override &lt;code&gt;toString&lt;/code&gt;, &lt;code&gt;equals&lt;/code&gt;, and &lt;code&gt;hashCode&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append(&amp;quot;[BROADCAST: &amp;quot;)
      .append(isBroadcast())
      .append(&amp;quot;] [value: 0x&amp;quot;)
      .append(ByteArrays.toHexString(value, &amp;quot;&amp;quot;))
      .append(&amp;quot;]&amp;quot;);

    return sb.toString();
  }

  @Override
  public boolean equals(Object obj) {
    if (obj == this) { return true; }
    if (!this.getClass().isInstance(obj)) { return false; }

    DhcpV4Flags other = (DhcpV4Flags)obj;
    return this.value == other.value;
  }

  @Override
  public int hashCode() { return value; }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;The last thing to write is &lt;strong&gt;Builder class&lt;/strong&gt;, which is another way to instantiate DhcpV4Flags objects.
The static factory method I wrote above is used when dissecting a real DHCP packet (i.e. a byte array), while the Builder is used when crafting a DHCP packet object.&lt;/p&gt;

&lt;p&gt;A Builder class is usually written as an inner class.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public final class DhcpV4Flags implements Serializable {

  (snip)

  public Builder getBuilder() {
    return new Builder(this);
  }

  public static final class Builder {

    private boolean broadcast = false;
    private short mbz = 0;

    public Builder() {}

    private Builder(DhcpV4Flags flags) {
      this.broadcast = flags.isBroadcast();
      this.mbz = flags.getMbz();
    }

    public Builder broadcast(boolean broadcast) {
      this.broadcast = broadcast;
      return this;
    }

    public Builder mbz(short mbz) {
      this.mbz = mbz;
      return this;
    }

    public DhcpV4Flags build() {
      return new DhcpV4Flags(this);
    }

  }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And, DhcpV4Flags needs a constructor which uses the Builder.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;  private DhcpV4Flags(Builder builder) {
    if (builder == null) {
      throw new NullPointerException(&amp;quot;builder is null.&amp;quot;);
    }
    if (builder.mbz &amp;lt; 0) {
      throw new IllegalArgumentException(
              &amp;quot;mbz must be equal or greater than zero but it is: &amp;quot; + builder.mbz
            );
    }

    this.value = builder.broadcast ? (short)(builder.mbz | 0x8000) : builder.mbz;
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s all. The entire code is as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package org.pcap4j.packet;

import java.io.Serializable;
import org.pcap4j.util.ByteArrays;

public final class DhcpV4Flags implements Serializable {

  private static final long serialVersionUID = -7144264525666462708L;

  private final short value;

  public static DhcpV4Flags newInstance(short value) {
    return new DhcpV4Flags(value);
  }

  private DhcpV4Flags(short value) {
    this.value = value;
  }

  private DhcpV4Flags(Builder builder) {
    if (builder == null) {
      throw new NullPointerException(&amp;quot;builder is null.&amp;quot;);
    }
    if (builder.mbz &amp;lt; 0) {
      throw new IllegalArgumentException(
              &amp;quot;mbz must be equal or greater than zero but it is: &amp;quot; + builder.mbz
            );
    }

    this.value = builder.broadcast ? (short)(builder.mbz | 0x8000) : builder.mbz;
  }

  public short value() {
    return value;
  }

  public boolean isBroadcast() { return (value &amp;amp; 0x8000) != 0; }

  public short getMbz() { return (short)(value &amp;amp; 0x7FFF); }

  public Builder getBuilder() {
    return new Builder(this);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append(&amp;quot;[BROADCAST: &amp;quot;)
      .append(isBroadcast())
      .append(&amp;quot;] [value: 0x&amp;quot;)
      .append(ByteArrays.toHexString(value, &amp;quot;&amp;quot;))
      .append(&amp;quot;]&amp;quot;);

    return sb.toString();
  }

  @Override
  public boolean equals(Object obj) {
    if (obj == this) { return true; }
    if (!this.getClass().isInstance(obj)) { return false; }

    DhcpV4Flags other = (DhcpV4Flags)obj;
    return this.value == other.value;
  }

  @Override
  public int hashCode() { return value; }

  public static final class Builder {

    private boolean broadcast = false;
    private short mbz = 0;

    public Builder() {}

    private Builder(DhcpV4Flags flags) {
      this.broadcast = flags.isBroadcast();
      this.mbz = flags.getMbz();
    }

    public Builder broadcast(boolean broadcast) {
      this.broadcast = broadcast;
      return this;
    }

    public Builder mbz(short mbz) {
      this.mbz = mbz;
      return this;
    }

    public DhcpV4Flags build() {
      return new DhcpV4Flags(this);
    }

  }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;In the next part, we&amp;rsquo;ll write the DHCP packet class.&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>ORMは不快なアンチパターン</title>
          <link>https://www.kaitoy.xyz/2015/09/13/orm-is-offensive-anti-pattern/</link>
          <pubDate>Sun, 13 Sep 2015 13:52:30 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/09/13/orm-is-offensive-anti-pattern/</guid>
          <description>

&lt;p&gt;このエントリでは、Yegor Bugayenkoによる記事、&lt;a href=&#34;http://www.yegor256.com/2014/12/01/orm-offensive-anti-pattern.html&#34;&gt;ORM Is an Offensive Anti-Pattern&lt;/a&gt;を紹介する。
(Yegorから和訳と転載の許可は得た。)
以下はその全文の和訳だが、意訳超訳が混じっているので、もとのニュアンスを知りたければ元記事を読んでもいいし、読まなくてもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;結論から言えば、ORMはオブジェクト指向プログラミングの原則の全てに違反するひどいアンチパターンだ。オブジェクトをバラバラに引き裂き、もの言わぬ受身なデータ入れに変えてしまう。
小さいWebアプリケーションから、数千のテーブルをCRUD操作するエンタープライズシステムまで、どんなアプリケーションにもORMが存在することはゆるせない。
代わりになるものは?
SQLを話すオブジェクトだ。&lt;/p&gt;

&lt;h1 id=&#34;ormの仕組み&#34;&gt;ORMの仕組み&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E9%96%A2%E4%BF%82%E3%83%9E%E3%83%83%E3%83%94%E3%83%B3%E3%82%B0&#34;&gt;オブジェクト関係マッピング&lt;/a&gt; (Object-relatinal mapping、ORM)は、オブジェクト指向言語(例えばJava)からリレーショナルデータベースにアクセスする技術(またはデザインパターン)だ。
ほとんどの言語で複数のORM実装がある。
例えば、Javaの&lt;a href=&#34;http://hibernate.org/orm/&#34;&gt;Hibernate&lt;/a&gt;、Ruby on Ralsの&lt;a href=&#34;http://guides.rubyonrails.org/active_record_basics.html&#34;&gt;ActiveRecord&lt;/a&gt;、PHPの&lt;a href=&#34;http://www.doctrine-project.org/&#34;&gt;Doctrine&lt;/a&gt;、Pythonの&lt;a href=&#34;http://www.sqlalchemy.org/&#34;&gt;SQLAlchemy&lt;/a&gt;。
Javaでは、ORMデザインは&lt;a href=&#34;https://ja.wikipedia.org/wiki/Java_Persistence_API&#34;&gt;JPA&lt;/a&gt;として標準化されてさえいる。&lt;/p&gt;

&lt;p&gt;最初に、ORMがどう動くかを見てみよう。JavaとPostgreSQLとHibernateを使い、データベースに&lt;code&gt;post&lt;/code&gt; (訳注: ブログポスト、ブログの記事)という単一のテーブルがあるとする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+-----+------------+--------------------------+
| id  | date       | title                    |
+-----+------------+--------------------------+
|   9 | 10/24/2014 | How to cook a sandwich   |
|  13 | 11/03/2014 | My favorite movies       |
|  27 | 11/17/2014 | How much I love my job   |
+-----+------------+--------------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で、このテーブルをJavaアプリケーションからCRUD操作したい。(CRUDはcreate、read、update、deleteの略。)
まず、&lt;code&gt;Post&lt;/code&gt;クラスを書く。(長くてごめん。けどなるべく短くしたんだ。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Entity
@Table(name = &amp;quot;post&amp;quot;)
public class Post {
  private int id;
  private Date date;
  private String title;

  @Id
  @GeneratedValue
  public int getId() {
    return this.id;
  }

  @Temporal(TemporalType.TIMESTAMP)
  public Date getDate() {
    return this.date;
  }

  public Title getTitle() {
    return this.title;
  }

  public void setDate(Date when) {
    this.date = when;
  }

  public void setTitle(String txt) {
    this.title = txt;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hibernateでの処理をする前に、セッションファクトリを作らないといけない。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SessionFactory factory = new AnnotationConfiguration()
  .configure()
  .addAnnotatedClass(Post.class)
  .buildSessionFactory();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このファクトリは&lt;code&gt;Post&lt;/code&gt;オブジェクトを操作したいときに「セッション」を作ってくれる。
セッションを使う全ての操作は以下のようなコードブロックで囲わないといけない。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Session session = factory.openSession(); try {
  Transaction txn = session.beginTransaction();
  // your manipulations with the ORM, see below
  txn.commit();
} catch (HibernateException ex) {
  txn.rollback();
} finally {
  session.close();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;セッションが準備できたら、以下のようにしてデータベーステーブルから全てのpostのリストを取得する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;List posts = session.createQuery(&amp;quot;FROM Post&amp;quot;).list();
for (Post post : (List&amp;lt;Post&amp;gt;) posts){
  System.out.println(&amp;quot;Title: &amp;quot; + post.getTitle());
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここで何が起こっているかは明確だと思う。
Hibernateという巨大で強力なエンジンが、データベースへの接続、SQLの&lt;code&gt;SELECT&lt;/code&gt;リクエスト発行、及びデータの取得をする。
そして、&lt;code&gt;Post&lt;/code&gt;クラスのインスタンスを作り、データをつめる。
そのオブジェクトが我々に渡されるとき、それにはデータが詰まっていて、getterでデータを取り出すことができる。上記&lt;code&gt;getTitle()&lt;/code&gt;でやっているように。&lt;/p&gt;

&lt;p&gt;逆の処理をしてオブジェクトをデータベースに送りたい場合は、同じことを逆の手順でやればいい。
&lt;code&gt;Post&lt;/code&gt;のインスタンスを作り、データを入れ、Hibernateに保存するよう頼む。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Post post = new Post();
post.setDate(new Date());
post.setTitle(&amp;quot;How to cook an omelette&amp;quot;); session.save(post);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これがほぼ全てのORMの仕組みだ。
基本的な原則はいつも同じで、ORMオブジェクトは無気力なデータの包みだ。
我々はORMフレームワークと話して、ORMフレームワークはデータベースと話す。
オブジェクトは我々のリクエストをORMフレームワークに送り、そのレスポンスを読むのを助けてくれるだけだ。
こうしたオブジェクトは、getterやsetterのほかに何のメソッドも持たない。どのデータベースから来たのかすら知らない。&lt;/p&gt;

&lt;p&gt;これがオブジェクト関係マッピングの仕組みだ。&lt;/p&gt;

&lt;p&gt;これの何が間違ってるかって? 全てだ!&lt;/p&gt;

&lt;h1 id=&#34;ormの何が悪いのか&#34;&gt;ORMの何が悪いのか&lt;/h1&gt;

&lt;p&gt;真面目な話、何が悪い?
Hibernateは既に10年以上にわたって最も人気のあるJavaライブラリの一つだ。
この世のほぼ全てのSQL集約的なアプリケーションが使っている。
Javaのチュートリアルは、データベースに接続するアプリケーションのためのものとしてHibernate(またはTopLinkやOpenJPAのような&lt;a href=&#34;https://en.wikipedia.org/wiki/List_of_object-relational_mapping_software&#34;&gt;ほかのORM&lt;/a&gt;)を挙げる。
それはデファクトスタンダードであって、なお間違っていると言っているのか?
そうだ。&lt;/p&gt;

&lt;p&gt;私はORMの根底にあるアイデア全体が間違っていると訴えている。
この発明は多分、OOPにおいて最大の失敗である&lt;a href=&#34;https://www.kaitoy.xyz/2015/07/26/why-null-is-bad/&#34;&gt;NULL&lt;/a&gt;に次ぐ失敗だ。&lt;/p&gt;

&lt;p&gt;実際、私だけがこんなことを言っているわけではないし、最初に言ったわけでもないことは明白だ。
この問題に関しては、既に多くの記述が尊敬すべき著者によって公開されている。例えば、Martin Fowlerによる&lt;a href=&#34;http://martinfowler.com/bliki/OrmHate.html&#34;&gt;OrmHate&lt;/a&gt;、Jeff Atwoodによる&lt;a href=&#34;http://blog.codinghorror.com/object-relational-mapping-is-the-vietnam-of-computer-science/&#34;&gt;Object-Relational Mapping Is the Vietnam of Computer Science&lt;/a&gt;、Ted Newardによる&lt;a href=&#34;http://blogs.tedneward.com/2006/06/26/The+Vietnam+Of+Computer+Science.aspx&#34;&gt;The Vietnam of Computer Science&lt;/a&gt;、Laurie Vossによる&lt;a href=&#34;http://seldo.com/weblog/2011/08/11/orm_is_an_antipattern&#34;&gt;ORM Is an Anti-Pattern&lt;/a&gt;などで、他にも沢山ある。&lt;/p&gt;

&lt;p&gt;しかし、私の論点はこれらの著者とは違っている。
彼らが挙げている、「ORMは遅い」とか「データベースアップグレードが難しい」といった理由は実用的で有効ではあるが、重要なポイントが欠けている。
こういう実用的な論点に対しては、Bozhidar Bozhanovが彼のブログポストの&lt;a href=&#34;http://techblog.bozho.net/orm-haters-dont-get-it/&#34;&gt;ORM Haters Don’t Get It&lt;/a&gt;の中でとてもよい実用的な回答を示している。&lt;/p&gt;

&lt;p&gt;重要なポイントとは、ORMが、データベースとのやり取りをオブジェクト内にカプセル化するのではなく、それを抜き取り、密で堅い&lt;a href=&#34;https://www.kaitoy.xyz/2015/10/28/seven-virtues-of-good-object/&#34;&gt;生ける有機体&lt;/a&gt;を文字通りばらばらに引き裂く、ということだ。
引き裂かれたオブジェクトの欠片はデータを保持し、ほかの欠片(ORMのエンジンであるセッションファクトリ内に実装されているもの)はそのデータの扱い方を知っていて、それをリレーショナルデータベースへ転送する。
下の絵を見てくれ。これはORMがやっていることを図示している。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/orm-is-offensive-anti-pattern/orm-anti-pattern.svg&#34; alt=&#34;orm-anti-pattern.svg&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;ブログポストの記事を読むとき、二つのコンポーネントを扱わないといけない。一つはORMで、もう一つは手足を奪われたオブジェクト。
OOPにおいては、扱うふるまいは単一のエントリーポイント、つまり一つのオブジェクトから提供されることになっている。
しかしORMの場合、ふるまいは二つのエントリーポイント、つまりORMと「もの」から提供される。
これはもはやオブジェクトとは呼べない。&lt;/p&gt;

&lt;p&gt;この不快でひどいオブジェクト指向パラダイム違反のせいで、上記記事で述べられているような多くの実用的な問題を抱える。
私はこれにもう少しだけ付け加える。&lt;/p&gt;

&lt;h2 id=&#34;sqlが隠蔽されない&#34;&gt;SQLが隠蔽されない&lt;/h2&gt;

&lt;p&gt;ORMユーザはSQL(もしくは&lt;a href=&#34;https://docs.jboss.org/hibernate/orm/3.3/reference/en/html/queryhql.html&#34;&gt;HQL&lt;/a&gt;のような方言)を書くはずだ。
前記の例を見てほしい。全てのブログポストを取得するために&lt;code&gt;session.createQuery(&amp;quot;FROM Post&amp;quot;)&lt;/code&gt;を実行している。
これはSQLではないけど、よく似たものだ。
つまり、リレーショナルモデルはオブジェクト内にカプセル化されていない。
代わりに、それはアプリケーション全体に公開されている。
オブジェクトに触る誰しもが、何かを取得したり保存したりするためにリレーショナルモデルを扱わないといけない。
つまり、ORMはSQLを隠蔽したりラップしたりしておらず、アプリケーション全体に撒き散らしている。&lt;/p&gt;

&lt;h2 id=&#34;テストが困難&#34;&gt;テストが困難&lt;/h2&gt;

&lt;p&gt;ブログポストのリストを操作するオブジェクトがある場合、それは&lt;code&gt;SessionFactory&lt;/code&gt;のインスタンスを扱わないといけない。
この依存をどうする?
モックを作らないといけない?
これはどのくらい複雑な作業だろうか?
上記コードを見てほしい。ユニットテストがどれだけ冗長でやっかいなものになるかわかるはずだ。
代わりに、統合テストを書いてアプリケーション全体をテスト用PostgreSQLに接続することもできる。
この場合、&lt;code&gt;SessionFactory&lt;/code&gt;のモックは不要だ。
しかしこういうテストは遅く、さらに注目すべきことには、データベースに対して何もしないオブジェクトがデータベースインスタンスに対してテストされることになる。最悪な設計だ。&lt;/p&gt;

&lt;p&gt;もう一度繰り返すが、ORMの実用的な問題は結果に過ぎない。
根本的な欠陥は、ORMがオブジェクトをバラバラにし、&lt;a href=&#34;https://www.kaitoy.xyz/2015/10/28/seven-virtues-of-good-object/&#34;&gt;オブジェクト&lt;/a&gt;の真の概念にひどく違反していることだ。&lt;/p&gt;

&lt;h1 id=&#34;sqlを話すオブジェクト&#34;&gt;SQLを話すオブジェクト&lt;/h1&gt;

&lt;p&gt;他の選択肢は?
例を挙げて教えよう。
あの、&lt;code&gt;Post&lt;/code&gt;クラスを私のやり方で設計してみよう。
これは二つのクラスに分ける必要がある。&lt;code&gt;Post&lt;/code&gt;と&lt;code&gt;Posts&lt;/code&gt;だ。
単数形と複数形。
私の&lt;a href=&#34;https://www.kaitoy.xyz/2015/10/28/seven-virtues-of-good-object/&#34;&gt;以前の記事&lt;/a&gt;ですでに述べたように、よいオブジェクトは常に現実世界のエンティティの抽象だ。
この原則が実際にどう働くかをここに示す。
我々は二つのエンティティを扱う。データベーステーブルとテーブルの行だ。
これが二つのクラスを作る理由だ。&lt;code&gt;Posts&lt;/code&gt;がテーブルを表し、&lt;code&gt;Post&lt;/code&gt;が行を表す。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/orm-is-offensive-anti-pattern/sql-speaking-object.svg&#34; alt=&#34;sql-speaking-object.svg&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;例の&lt;a href=&#34;https://www.kaitoy.xyz/2015/10/28/seven-virtues-of-good-object/&#34;&gt;記事&lt;/a&gt;で既に述べたように、全てのオブジェクトは契約によって働き、インターフェースを実装すべきだ。
我々の設計も二つのインターフェースから始めよう。
もちろん、オブジェクトは不変だ。&lt;code&gt;Posts&lt;/code&gt;は以下のようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Immutable
interface Posts {
  Iterable&amp;lt;Post&amp;gt; iterate();
  Post add(Date date, String title);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;Post&lt;/code&gt;は以下だ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Immutable
interface Post {
  int id();
  Date date();
  String title();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;データベーステーブル内の全てのpostを表示するには以下のようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Posts posts = // we&#39;ll discuss this right now
for (Post post : posts.iterate()){
  System.out.println(&amp;quot;Title: &amp;quot; + post.title());
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;新しいpostを作る場合は以下のようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Posts posts = // we&#39;ll discuss this right now
posts.add(new Date(), &amp;quot;How to cook an omelette&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このようにすると真のオブジェクトになる。
これらのオブジェクトは全ての処理を受け持ち、実装の詳細を完璧に隠蔽する。
トランザクションもセッションもファクトリもない。
これらのオブジェクトが実際にPostgreSQLと話しているのかテキストファイルからデータを持ってきているのかすらわからない。
&lt;code&gt;Posts&lt;/code&gt;に求められるのは、全てのブログポストを取得する機能と新しいブログポストを作る機能だけだ。
実装の詳細は完璧に内部に隠蔽されている。
これから、どのようにこれら二つのクラスを実装できるかを見ていきたい。&lt;/p&gt;

&lt;p&gt;ここではJDBCラッパに&lt;a href=&#34;http://jdbc.jcabi.com/&#34;&gt;jcabi-jdbc&lt;/a&gt;を使うが、好みに応じてほかのものやJDBCを直接使ってもよい。
それは全く重要ではない。重要なのは、データベースとのやり取りをオブジェクト内に隠蔽することだ。
&lt;code&gt;Posts&lt;/code&gt;から始めよう。&lt;code&gt;PgPosts&lt;/code&gt;クラス(「pg」はPostgreSQLのこと)に実装する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Immutable
final class PgPosts implements Posts {
  private final Source dbase;
  public PgPosts(DataSource data) {
    this.dbase = data;
  }
  public Iterable&amp;lt;Post&amp;gt; iterate() {
    return new JdbcSession(this.dbase)
      .sql(&amp;quot;SELECT id FROM post&amp;quot;)
      .select(
        new ListOutcome&amp;lt;Post&amp;gt;(
          new ListOutcome.Mapping&amp;lt;Post&amp;gt;() {
            @Override
            public Post map(final ResultSet rset) {
              return new PgPost(rset.getInteger(1));
            }
          }
        )
      );
  }
  public Post add(Date date, String title) {
    return new PgPost(
      this.dbase,
      new JdbcSession(this.dbase)
        .sql(&amp;quot;INSERT INTO post (date, title) VALUES (?, ?)&amp;quot;)
        .set(new Utc(date))
        .set(title)
        .insert(new SingleOutcome&amp;lt;Integer&amp;gt;(Integer.class))
    );
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次に&lt;code&gt;Post&lt;/code&gt;を&lt;code&gt;PgPost&lt;/code&gt;クラスに実装する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Immutable
final class PgPost implements Post {
  private final Source dbase;
  private final int number;
  public PgPost(DataSource data, int id) {
    this.dbase = data;
    this.number = id;
  }
  public int id() {
    return this.number;
  }
  public Date date() {
    return new JdbcSession(this.dbase)
      .sql(&amp;quot;SELECT date FROM post WHERE id = ?&amp;quot;)
      .set(this.number)
      .select(new SingleOutcome&amp;lt;Utc&amp;gt;(Utc.class));
  }
  public String title() {
    return new JdbcSession(this.dbase)
      .sql(&amp;quot;SELECT title FROM post WHERE id = ?&amp;quot;)
      .set(this.number)
      .select(new SingleOutcome&amp;lt;String&amp;gt;(String.class));
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今作ったクラスを使ってデータベースとやり取りする完全なシナリオは以下のようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Posts posts = new PgPosts(dbase);
for (Post post : posts.iterate()){
  System.out.println(&amp;quot;Title: &amp;quot; + post.title());
}
Post post = posts.add(new Date(), &amp;quot;How to cook an omelette&amp;quot;);
System.out.println(&amp;quot;Just added post #&amp;quot; + post.id());
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/aintshy/hub/tree/0.7.2/src/main/java/com/aintshy/pgsql&#34;&gt;ここ&lt;/a&gt;で完全な実用的な例を見られる。
これはオープンソースのWebアプリで、上で説明したのと全く同じアプローチ、つまりSQLを話すオブジェクトを使ってPostgreSQLにアクセスする。&lt;/p&gt;

&lt;h1 id=&#34;性能は&#34;&gt;性能は?&lt;/h1&gt;

&lt;p&gt;「性能は?」と君が叫んでいるのが聞こえる。
数行上のスクリプトにはデータベースとの冗長なやりとりを書いた。
まず、&lt;code&gt;SELECT id&lt;/code&gt;でブログポストのIDを取得し、さらに、タイトルを取得するために&lt;code&gt;SELECT title&lt;/code&gt;をそれぞれのブログポストに対して実行する。
これは非効率だ。単に遅すぎると言ってもいい。&lt;/p&gt;

&lt;p&gt;心配はいらない。これはオブジェクト指向プログラミングであり、柔軟なんだ!
&lt;code&gt;PgPost&lt;/code&gt;のデコレータを作り、全てのデータをそのコンストラクタで受け取って内部で永遠にキャッシュしよう。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Immutable
final class ConstPost implements Post {
  private final Post origin;
  private final Date dte;
  private final String ttl;
  public ConstPost(Post post, Date date, String title) {
    this.origin = post;
    this.dte = date;
    this.ttl = title;
  }
  public int id() {
    return this.origin.id();
  }
  public Date date() {
    return this.dte;
  }
  public String title() {
    return this.ttl;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このデコレータはPostgreSQLやJDBCについて何も関与しないことに注目してほしい。
単に&lt;code&gt;Post&lt;/code&gt;オブジェクトをデコレートして日付(date)とタイトル(title)をキャッシュするだけだ。
例によってこのデコレータは不変だ。&lt;/p&gt;

&lt;p&gt;さて、&lt;code&gt;Posts&lt;/code&gt;の別の実装を作って、「定数」オブジェクトを返すようにしてみよう。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Immutable
final class ConstPgPosts implements Posts {
  // ...
  public Iterable&amp;lt;Post&amp;gt; iterate() {
    return new JdbcSession(this.dbase)
      .sql(&amp;quot;SELECT * FROM post&amp;quot;)
      .select(
        new ListOutcome&amp;lt;Post&amp;gt;(
          new ListOutcome.Mapping&amp;lt;Post&amp;gt;() {
            @Override
            public Post map(final ResultSet rset) {
              return new ConstPost(
                new PgPost(rset.getInteger(1)),
                Utc.getTimestamp(rset, 2),
                rset.getString(3)
              );
            }
          }
        )
      );
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今、この新しいクラスの&lt;code&gt;iterate()&lt;/code&gt;が返す全てのブログポストには、データベースとの一往復で取得された日付とタイトルが入っている。
デコレータやインターフェースの複数の実装を使うことで、どんな機能も望みどおりに構成することができる。
最も重要なことは、機能は拡張されたが設計は複雑になっていないことだ。クラスのサイズが大きくなっていないからね。
代わりに、小さく、それ故強度と凝集度が高い新しいクラスを導入した。&lt;/p&gt;

&lt;h1 id=&#34;トランザクションは&#34;&gt;トランザクションは?&lt;/h1&gt;

&lt;p&gt;全てのオブジェクトはそれ自身のトランザクションを扱い、それを&lt;code&gt;SELECT&lt;/code&gt;や&lt;code&gt;INSERT&lt;/code&gt;と同様にカプセル化すべきだ。
これはトランザクションのネストにつながる。
トランザクションのネストは、データベースサーバがサポートしていれば全く素晴らしいものだ。
サポートされていなければ、セッション全体に渡るトランザクションを表すオブジェクトを作り、「callable」クラスを受け取ればいい。
以下がその例。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;final class Txn {
  private final DataSource dbase;
  public &amp;lt;T&amp;gt; T call(Callable&amp;lt;T&amp;gt; callable) {
    JdbcSession session = new JdbcSession(this.dbase);
    try {
      session.sql(&amp;quot;START TRANSACTION&amp;quot;).exec();
      T result = callable.call();
      session.sql(&amp;quot;COMMIT&amp;quot;).exec();
      return result;
    } catch (Exception ex) {
      session.sql(&amp;quot;ROLLBACK&amp;quot;).exec();
      throw ex;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そして、ひとつのトランザクションに複数のオブジェクト操作をラップしたい場合はこのようにする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;new Txn(dbase).call(
  new Callable&amp;lt;Integer&amp;gt;() {
    @Override
    public Integer call() {
      Posts posts = new PgPosts(dbase);
      Post post = posts.add(new Date(), &amp;quot;How to cook an omelette&amp;quot;);
      posts.comments().post(&amp;quot;This is my first comment!&amp;quot;);
      return post.id();
    }
  }
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このコードは新しいブログポストを作ってコメントを加える。
もし処理に失敗したら、トランザクション全体がロールバックされる。&lt;/p&gt;

&lt;p&gt;私にはこのアプローチがオブジェクト指向に見える。
私はこれを「SQLを話すオブジェクト」と呼んでいる。
なぜなら、このオブジェクトはデータベースサーバとSQLを話す方法を知っているからだ。
それはオブジェクトのスキルで、完璧に内部にカプセル化されている。&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;embed video-player&#34; style=&#34;text-align: center&#34;&gt;
  &lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;320&#34; height=&#34;193&#34; src=&#34;https://www.youtube.com/embed/DEqcn4-freM&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上がYegorの記事。&lt;/p&gt;

&lt;p&gt;ORMはHibernateをちょっと使ったことがあるくらい。
IPAのデータベーススペシャリストの試験を申し込んだものの参考書が理解できなくてあきらめた過去もあり、この分野には苦手意識があって、あまり大きい声は出せない。&lt;/p&gt;

&lt;p&gt;Hibernateについてちょっと言えば、使い始めはすばらしいものに見えて興奮するが、だんだんとその融通の利かなさにうんざりしてきて、結局DAOとかにSQLを書きまくったり、自分でデータをキャッシュする仕組みを書いたりする羽目になる、というイメージ。
Hibernateを初歩的に使うと一行もSQL(やHQL)を書かずにRDBを使うアプリケーションを書けるので、ORMはSQLを学ぶコストをカットするためのツールであると勘違いしてしまうが、実際にはインピーダンスミスマッチの解決が主目的であって、実用に際してはRDBとSQLへの深い知識が必要になる。&lt;/p&gt;

&lt;p&gt;もちろんこれはORMの「実用的な問題」であって、Yegorが書いていることとは違う。&lt;/p&gt;

&lt;p&gt;日本では、Yegorも挙げているLaurie Vossの&lt;a href=&#34;http://seldo.com/weblog/2011/08/11/orm_is_an_antipattern&#34;&gt;2011年半ばのブログポスト&lt;/a&gt;がきっかけでORMの問題が話題になったようだ。
これは&lt;a href=&#34;https://ja.wikipedia.org/wiki/NoSQL&#34;&gt;NoSQL&lt;/a&gt;が日本で大きく取り上げられ始めた時期ともかぶっている気がする。
もっと前から本当に性能にシビアなWebサービス界ではNoSQLを使うのが主流になっていたみたいだけど。
これはGoogle、Amazon、FacebookといったWebサービス企業のカリスマがNoSQLを押したのもあるか。
ホリエモンもエンジニアだったころ自社のサービスを作った時に使ったとか。これは15年以上前の話だから、かなり先見性があったんだな。&lt;/p&gt;

&lt;p&gt;今RDBをもっとも使っている分野であろうエンタープライズ向けのシステムやパッケージソフトも、サービス化が大きなトレンドであり、それに加えてマルチテナント化が進めば扱うデータ量が増え、性能に対してどんどんシビアになり、NoSQLを取り入れる動きが増えるんだろう。
&lt;a href=&#34;http://japan.zdnet.com/article/35061140/&#34;&gt;2015年はNoSQL元年&lt;/a&gt;なんて記事もある。この記事によれば、NoSQLは大量の非構造化データを扱うIoTやM2Mの分野に有効だそうな。&lt;/p&gt;

&lt;p&gt;まあこれもYegorが書いていることとは関係ないけど。&lt;/p&gt;

&lt;p&gt;Yegorが言っていること、ORMは本来オブジェクトの仕事であるものを取り上げてしまうのでだめだという理屈は、オブジェクト原理主義者から見ればそうなのかもしれないが、一般の開発者から見ればそれがいいんじゃないかという話になって、議論はかみ合わない。
Yegor自身が前半で書いているORMを使ったコードより、後半のOOP原理的コードの方がかなり長い。
それってORMを使った方がやっぱりいいんじゃないのという感想を持つ人が多いのでは。(少なくとも「実用的な問題」を抜きにすれば。)&lt;/p&gt;

&lt;p&gt;オブジェクト原理主義をしっかり理解し、そのメリットを知らなければYegorの説教も馬の耳にだ。というわけで、次は&lt;a href=&#34;http://www.yegor256.com/2014/11/20/seven-virtues-of-good-object.html&#34;&gt;Seven Virtues of a Good Object&lt;/a&gt;を読むか。(&lt;a href=&#34;https://www.kaitoy.xyz/2015/10/28/seven-virtues-of-good-object/&#34;&gt;訳した。&lt;/a&gt;)&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>AtomにおけるGIF画像のキャッシュ</title>
          <link>https://www.kaitoy.xyz/2015/09/07/caching-gifs-on-atom/</link>
          <pubDate>Mon, 07 Sep 2015 20:10:31 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/09/07/caching-gifs-on-atom/</guid>
          <description>

&lt;p&gt;以前、&lt;a href=&#34;https://atom.io/packages/disturb-me&#34;&gt;&lt;strong&gt;disturb-me&lt;/strong&gt;&lt;/a&gt;という&lt;a href=&#34;https://atom.io/&#34;&gt;&lt;strong&gt;Atom&lt;/strong&gt;&lt;/a&gt;パッケージを作ったという&lt;a href=&#34;https://www.kaitoy.xyz/2015/09/06/disturb-me/&#34;&gt;エントリ&lt;/a&gt;を書いた。
このエントリでは、disturb-meに見つけたバグの修正のなかで、AtomがGIF画像をキャッシュする問題に対応したという話を書く。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;disturb-meのバグ&#34;&gt;disturb-meのバグ&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/09/06/disturb-me/#6-%E3%83%AA%E3%83%AA%E3%83%BC%E3%82%B9%E3%81%AA%E3%81%A9&#34;&gt;以前のエントリの最後&lt;/a&gt;にも書いた通り、disturb-me 1.0.0には、ループしないGIFアニメーション画像を設定で指定した場合、そのアニメーションが画像の初回表示時にしか再生されないというバグがある。&lt;/p&gt;

&lt;p&gt;disturb-meは、&lt;code&gt;Ctrl+Alt+d Ctrl+Alt+m&lt;/code&gt;と入力すると画像を表示し、もう一度それを入力すると画像を消す。
デフォルトで表示する画像はAtomのロゴで、表示を始める時と消す時にGIF画像でループしないアニメーションを再生する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/kaitoy/disturb-me/raw/master/assets/disturb-me-demo.gif&#34; alt=&#34;screenshot&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;このデフォルトの状態で、一度Atomロゴを表示して消して、再度表示して消すと、消すときのアニメーションが再生されない。(表示を始める時のアニメーションはなぜか再生される。)&lt;/p&gt;

&lt;h2 id=&#34;バグの原因&#34;&gt;バグの原因&lt;/h2&gt;

&lt;p&gt;disturb-meは、&lt;code&gt;img&lt;/code&gt;タグをAtomウィンドウ内に追加した後、その&lt;code&gt;src&lt;/code&gt;属性に画像へのパスをセットして画像を表示させるが、どうもAtom(のChromium)が画像をキャッシュしてくれるせいで、一度表示し終わったGIFアニメーションは二度と再生されない模様。
なぜ表示開始時のアニメーションが再生されるかは不明。&lt;/p&gt;

&lt;h2 id=&#34;バグ修正&#34;&gt;バグ修正&lt;/h2&gt;

&lt;p&gt;外部リソースをロードするときにブラウザによるキャッシュを回避するには、URLにランダムな値をもつクエリストリングを付けるのが常套手段。&lt;/p&gt;

&lt;p&gt;今回のバグも、&lt;code&gt;src&lt;/code&gt;にセットするGIF画像のパス(URL)にそのようなクエリストリングをつければよい。
例えば、&lt;strong&gt;C:\images\hoge.gif&lt;/strong&gt;を表示したいなら、&lt;code&gt;&amp;lt;img src=&amp;quot;C:\images\hoge.gif?time=1441559906660&amp;quot;&amp;gt;&amp;lt;img&amp;gt;&lt;/code&gt;という風にする。
ここでtimeの値には&lt;code&gt;Date.now()&lt;/code&gt;とかで毎回違う値を生成して使う。&lt;/p&gt;

&lt;h2 id=&#34;atomプロトコルの問題&#34;&gt;Atomプロトコルの問題&lt;/h2&gt;

&lt;p&gt;ここで一つ問題が。disturb-meがデフォルトで使うAtomロゴの画像はパッケージに含まれていて、そういうリソースのURLには&lt;a href=&#34;https://atom.io/docs/latest/creating-a-package#bundle-external-resources&#34;&gt;&lt;strong&gt;Atomプロトコル&lt;/strong&gt;&lt;/a&gt;を使うのが普通。
Atomプロトコルを使うと、&lt;code&gt;atom://disturb-me/assets/atom/white/atom_born.gif&lt;/code&gt;みたいに書いて、パッケージ内の相対パスでリソースを指定できる。&lt;/p&gt;

&lt;p&gt;このAtomプロトコルが、今の時点(Atom v1.0.11)でクエリストリングに対応していない。困った。&lt;/p&gt;

&lt;h2 id=&#34;atomプロトコルの問題への対応&#34;&gt;Atomプロトコルの問題への対応&lt;/h2&gt;

&lt;p&gt;いい機会なので、Atomのソースをfork、cloneして、Atomプロトコルを(簡易的に)クエリストリングに対応させ、ビルドして確認し、プルリクエストを送ってみた。これについてはまた別のエントリで書くかもしれない。&lt;/p&gt;

&lt;p&gt;このプルリクエストが取り込まれるまでの暫定対策として、&lt;a href=&#34;https://github.com/atom/atom/blob/master/src/browser/atom-protocol-handler.coffee&#34;&gt;Atomプロトコルハンドラのソース&lt;/a&gt;を見て、AtomプロトコルのURLからリソースのファイルシステム上での絶対パスを導いている部分をdisturb-me内にパクって、&lt;code&gt;src&lt;/code&gt;にセットする値として&lt;code&gt;atom://&lt;/code&gt;を使わないようにした。&lt;/p&gt;

&lt;p&gt;これでちゃんと動いた。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Atomウィンドウ内で画像を動かすパッケージ - disturb-me</title>
          <link>https://www.kaitoy.xyz/2015/09/06/disturb-me/</link>
          <pubDate>Sun, 06 Sep 2015 20:18:14 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/09/06/disturb-me/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://atom.io/&#34;&gt;&lt;strong&gt;Atom&lt;/strong&gt;&lt;/a&gt;のパッケージを見ていて、便利なパッケージが沢山あるなぁと思いつつ、真面目なパッケージばかりでもつまらないので、たまには不真面目で役に立たないパッケージがあってもいいかと思って作ったパッケージの話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;disturb-me&#34;&gt;disturb-me&lt;/h2&gt;

&lt;p&gt;作ったのは&lt;a href=&#34;https://atom.io/packages/disturb-me&#34;&gt;&lt;strong&gt;disturb-me&lt;/strong&gt;&lt;/a&gt;というパッケージ。
&lt;code&gt;Ctrl+Alt&lt;/code&gt;を押しながら&lt;code&gt;d&lt;/code&gt;と&lt;code&gt;m&lt;/code&gt;を押すとAtomウィンドウ内に画像が表示され、その画像がランダムに動き回り作業の邪魔をするというもの。&lt;/p&gt;

&lt;p&gt;画像はパッケージの設定から指定できる。デフォルトではAtomのロゴ。&lt;/p&gt;

&lt;p&gt;最初は&lt;strong&gt;pac-m●n&lt;/strong&gt;というパッケージ名にして、ゲーム界のミッキーことパ●クマンが動き回るパッケージにしようと思ってたけど、バンダイナムコからダメだと言われてしまった。
この構想はいつか&lt;a href=&#34;https://open.channel.or.jp/user.php&#34;&gt;カタログIPオープン化プロジェクト&lt;/a&gt;を利用して実現しようと思う。&lt;/p&gt;

&lt;h2 id=&#34;disturb-meの作り方&#34;&gt;disturb-meの作り方&lt;/h2&gt;

&lt;p&gt;以前&lt;a href=&#34;https://www.kaitoy.xyz/2015/08/21/japanese-word-selection/&#34;&gt;別のエントリ&lt;/a&gt;でAtomパッケージの作り方の基本について書いたので、ここではそこで書かなかったことを書く。&lt;/p&gt;

&lt;h4 id=&#34;1-メインスクリプト-コマンド&#34;&gt;1. メインスクリプト - コマンド&lt;/h4&gt;

&lt;p&gt;今回はコマンドを追加するので&lt;a href=&#34;https://atom.io/docs/api/latest/CommandRegistry&#34;&gt;&lt;strong&gt;CommandRegistry&lt;/strong&gt;&lt;/a&gt;を使う。
CommandRegistryのインスタンスには&lt;strong&gt;atom.commands&lt;/strong&gt;でアクセスでき、その&lt;strong&gt;add&lt;/strong&gt;メソッドでコマンドを追加できる。&lt;/p&gt;

&lt;p&gt;addメソッドの引数は、第一引数から順に、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;target: コマンドを有効にするDOM要素か、それを示すCSSセレクタ。&lt;/li&gt;
&lt;li&gt;commandName: コマンドパレットに表示するコマンド名。全部小文字で、単語をハイフンでつないで、パッケージ名を先頭につけるのがルール。&lt;/li&gt;
&lt;li&gt;callback(event): コマンドを実行したときに呼ばれるメソッド。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;disturb-meのコマンドはAtomウィンドウ内のどこでも有効にしたいので、第一引数にはAtomウィンドウを表すカスタムタグである&lt;strong&gt;atom-workspace&lt;/strong&gt;を指定する。
コードは以下の感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-coffeescript&#34;&gt;  activate: (state) -&amp;gt;
    @subscriptions = new CompositeDisposable
    @subscriptions.add atom.commands.add &#39;atom-workspace&#39;, &#39;disturb-me:toggle&#39;: =&amp;gt; @toggle()

  toggle: -&amp;gt;
    # 画像を挿入したり削除したりするコード。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;toggle&lt;/strong&gt;の中では画像を挿入したり削除したりするわけだけど、この処理は、その画像を表す別のクラスにまかせることにする。
のでtoggleは以下のように書く。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-coffeescript&#34;&gt;  @disturber: null

  toggle: -&amp;gt;
    if @disturber?
      @disturber.stop()
      @disturber = null
    else
      @disturber = new Disturber()
      document.body.appendChild(@disturber.getElement())
      @disturber.start()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Disturber&lt;/strong&gt;が画像を表すクラス。別のファイル(&lt;strong&gt;lib/disturber.coffee&lt;/strong&gt;)の中で定義して、スクリプトの先頭辺りで&lt;code&gt;Disturber = require &#39;./disturber&#39;&lt;/code&gt;のようにインポートする。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;document.body.appendChild&lt;/strong&gt;しているところは、何かAtomのAPI(&lt;a href=&#34;https://atom.io/docs/api/latest/ViewRegistry&#34;&gt;&lt;strong&gt;ViewRegistry&lt;/strong&gt;&lt;/a&gt;とか)を使うべきなのかも。&lt;/p&gt;

&lt;h4 id=&#34;2-disturber&#34;&gt;2. Disturber&lt;/h4&gt;

&lt;p&gt;Disturberは以下のように書く。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-coffeescript&#34;&gt;module.exports =
class Disturber

  element: null

  constructor: -&amp;gt;
    # &amp;lt;img&amp;gt;を作って@elementに入れる。

  destroy: -&amp;gt;
    # @elementをDOMツリーから削除する。

  getElement: -&amp;gt;
    # @element返す。

  start: -&amp;gt;
    # @elementのsrcを設定して、ランダムに動かし始める。

  stop: -&amp;gt;
    # @elementを止める。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;あまり取り立てて書くことないな…。&lt;/p&gt;

&lt;p&gt;因みに画像を動かすのには&lt;a href=&#34;https://www.npmjs.com/package/velocity-animate&#34;&gt;&lt;strong&gt;Velocity&lt;/strong&gt;&lt;/a&gt;を使い、DOMの操作とかにちょっと&lt;a href=&#34;https://www.npmjs.com/package/jquery&#34;&gt;&lt;strong&gt;jQuery&lt;/strong&gt;&lt;/a&gt;を使う。&lt;/p&gt;

&lt;h4 id=&#34;3-パッケージ設定&#34;&gt;3. パッケージ設定&lt;/h4&gt;

&lt;p&gt;動かす画像や動かす速度はユーザが設定できるようにする。
設定はメインスクリプトで定義でき、その値には&lt;a href=&#34;https://atom.io/docs/api/latest/Config&#34;&gt;&lt;strong&gt;Config&lt;/strong&gt;&lt;/a&gt;クラスでアクセスできる。&lt;/p&gt;

&lt;p&gt;メインスクリプトでの定義は以下のように書く。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-coffeescript&#34;&gt;module.exports = DisturbMe =
  disturber: null
  subscriptions: null

  config:
    bornImage:
      title: &#39;Born-Image&#39;
      type: &#39;string&#39;
      default: &#39;atom://disturb-me/assets/atom/white/atom_born.gif&#39;
    bornDuration:
      title: &#39;Born-Duration&#39;
      type: &#39;integer&#39;
      default: 2000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;するとパッケージ設定画面が以下のようになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/disturb-me/settings.jpg&#34; alt=&#34;settings&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;各設定の定義に最低限必要な属性は&lt;strong&gt;type&lt;/strong&gt;と&lt;strong&gt;default&lt;/strong&gt;。オプショナルなものに&lt;strong&gt;title&lt;/strong&gt;、&lt;strong&gt;description&lt;/strong&gt;などがある。
typeには、&lt;strong&gt;string&lt;/strong&gt;、&lt;strong&gt;integer&lt;/strong&gt;、&lt;strong&gt;number&lt;/strong&gt;、&lt;strong&gt;boolean&lt;/strong&gt;、&lt;strong&gt;array&lt;/strong&gt;、&lt;strong&gt;object&lt;/strong&gt;、&lt;strong&gt;color&lt;/strong&gt;を指定できる。
詳しくは&lt;a href=&#34;https://atom.io/docs/api/latest/Config&#34;&gt;&lt;strong&gt;Config&lt;/strong&gt;&lt;/a&gt;クラスの説明に載ってる。&lt;/p&gt;

&lt;p&gt;Configクラスのインスタンスには&lt;strong&gt;atom.config&lt;/strong&gt;でアクセスでき、上で定義した設定を以下のように操作できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-coffeescript&#34;&gt;imagePath = atom.config.get(&#39;disturb-me.bornImage&#39;)
atom.config.set(&#39;disturb-me.bornDuration&#39;, &#39;1000&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;4-キーバインディング&#34;&gt;4. キーバインディング&lt;/h4&gt;

&lt;p&gt;メインスクリプト内でコマンドパレットに表示するコマンドを定義したが、これにキーボードショートカット(キーバインディング)を設定する。&lt;/p&gt;

&lt;p&gt;キーバインディングは&lt;strong&gt;keymaps&lt;/strong&gt;フォルダの中の&lt;strong&gt;cson&lt;/strong&gt;ファイルで以下のように定義する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cson&#34;&gt;&#39;atom-workspace&#39;:
  &#39;ctrl-alt-d ctrl-alt-m&#39;: &#39;disturb-me:toggle&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これ見ればだいたい書き方はわかるはず。(詳細は&lt;a href=&#34;https://atom.io/docs/latest/behind-atom-keymaps-in-depth&#34;&gt;Atom Flight Manual&lt;/a&gt;に。)&lt;/p&gt;

&lt;p&gt;特殊キーは&lt;strong&gt;cmd&lt;/strong&gt;、&lt;strong&gt;ctrl&lt;/strong&gt;、&lt;strong&gt;alt&lt;/strong&gt;、&lt;strong&gt;shift&lt;/strong&gt;、&lt;strong&gt;enter&lt;/strong&gt;、&lt;strong&gt;escape&lt;/strong&gt;、&lt;strong&gt;backspace&lt;/strong&gt;、&lt;strong&gt;delete&lt;/strong&gt;、&lt;strong&gt;tab&lt;/strong&gt;、&lt;strong&gt;home&lt;/strong&gt;、&lt;strong&gt;end&lt;/strong&gt;、&lt;strong&gt;pageup&lt;/strong&gt;、&lt;strong&gt;pagedown&lt;/strong&gt;、&lt;strong&gt;left&lt;/strong&gt;、&lt;strong&gt;right&lt;/strong&gt;、&lt;strong&gt;up&lt;/strong&gt;、&lt;strong&gt;down&lt;/strong&gt;が使える。&lt;/p&gt;

&lt;p&gt;同時に押すキーはハイフンでつなぎ、連続して押すキーはスペースで区切るので、上記&lt;code&gt;ctrl-alt-d ctrl-alt-m&lt;/code&gt;は、&lt;code&gt;Ctrl+Alt&lt;/code&gt;を押しながら&lt;code&gt;d&lt;/code&gt;と&lt;code&gt;m&lt;/code&gt;を連続して押す、という意味。&lt;/p&gt;

&lt;h4 id=&#34;5-package-json&#34;&gt;5. package.json&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/08/21/japanese-word-selection/#5-package-json%E7%B7%A8%E9%9B%86&#34;&gt;前回&lt;/a&gt;と同様の編集に加えて、今回は二つのnpmパッケージに依存するので、&lt;strong&gt;dependencies&lt;/strong&gt;を以下のように書く。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;  &amp;quot;dependencies&amp;quot;: {
    &amp;quot;velocity-animate&amp;quot;: &amp;quot;&amp;gt;=1.2.0&amp;quot;,
    &amp;quot;jquery&amp;quot;: &amp;quot;&amp;gt;=2.0.0&amp;quot;
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これを書いて、プロジェクトルートフォルダで&lt;code&gt;apm install&lt;/code&gt;すると、ルート直下の&lt;strong&gt;node_modules&lt;/strong&gt;フォルダに依存モジュールがインストールされる。&lt;/p&gt;

&lt;p&gt;node_modulesは&lt;strong&gt;Package Generator&lt;/strong&gt;が生成する&lt;strong&gt;.gitignore&lt;/strong&gt;に入っているので、リポジトリには入らない。&lt;/p&gt;

&lt;h4 id=&#34;6-リリースなど&#34;&gt;6. リリースなど&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/08/21/japanese-word-selection/&#34;&gt;前回&lt;/a&gt;と同様にリリースする。
めんどいのでテストは書かない。&lt;/p&gt;

&lt;p&gt;リリース後、ループしないgifアニメーション画像をdisturb-meに使った場合、そのアニメーションが再生されない場合があるバグに気付いた。
これについては&lt;a href=&#34;https://www.kaitoy.xyz/2015/09/07/caching-gifs-on-atom/&#34;&gt;別のエントリ&lt;/a&gt;で書いた。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GitHub Pagesでブログ立ち上げ - Hugoを使う</title>
          <link>https://www.kaitoy.xyz/2015/08/28/using-hugo/</link>
          <pubDate>Fri, 28 Aug 2015 23:36:21 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/08/28/using-hugo/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/08/25/tools-for-jekyll/&#34;&gt;&lt;strong&gt;GitHub Pagesでブログ立ち上げ - Jekyllのためのツール&lt;/strong&gt;&lt;/a&gt;の続き。
前回は、&lt;a href=&#34;https://pages.github.com/&#34;&gt;&lt;strong&gt;GitHub Pages&lt;/strong&gt;&lt;/a&gt;で公開するブログサイトを構築するのに、&lt;a href=&#34;http://jekyllrb.com/docs/home/&#34;&gt;&lt;strong&gt;Jekyll&lt;/strong&gt;&lt;/a&gt;とJekyll関連ツールを使おうと四苦八苦したが、結局Jekyllに見切りをつけ、&lt;a href=&#34;https://gohugo.io/&#34;&gt;&lt;strong&gt;Hugo&lt;/strong&gt;&lt;/a&gt;を使うことに決めた。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;hugoとは&#34;&gt;Hugoとは&lt;/h2&gt;

&lt;p&gt;Hugoは、国内では2014年末くらいから盛り上がってきているブログサイト構築ツール。
そのホームページによると、ウェブサイトフレームワークで、静的サイトジェネレータとのこと。&lt;/p&gt;

&lt;p&gt;フレームワークと名乗ってはいるが、その正体は、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Markdown&#34;&gt;&lt;strong&gt;Markdown&lt;/strong&gt;&lt;/a&gt;で書かれた記事を元にブログサイトのソースを生成するコンテントビルド機能と、記事作成(など)を支援するユーティリティ機能を持ったコマンドラインツール。&lt;/p&gt;

&lt;p&gt;また、静的サイトジェネレータというのは、静的なサイトを生成するという意味ではなく、静的にサイトを生成するという意味。もっと言えば、WordPressとかがアクセス時にビルドが走るのに対し、Hugoを使った場合は事前にビルド済みのものをサーバにアップロードすることになる、ということ。らしい。WordPressは使ったことがないのでよく知らないが、Hugoのホームページにそう書いてある。
つまり、Hugoは静的なサイトだけを扱うツールってわけではないので、JavaScriptとかを駆使して動的でインタラクティブなページを作ってもいいはず。&lt;/p&gt;

&lt;h2 id=&#34;hugoのインストール&#34;&gt;Hugoのインストール&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://gohugo.io/overview/installing/&#34;&gt;インストールガイド&lt;/a&gt;に従ってHugoをインストールする。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/spf13/hugo/releases&#34;&gt;HugoのGitHub Releases&lt;/a&gt;からWindows用バイナリをダウンロード。このときはバージョン0.14が最新だったので、&lt;strong&gt;hugo_0.14_windows_amd64.zip&lt;/strong&gt;をダウンロードした。&lt;/p&gt;

&lt;p&gt;このzipの中身は&lt;strong&gt;hugo_0.14_windows_amd64.exe&lt;/strong&gt;というバイナリ一つとLICENSE.mdとREADME.mdだけ。
このhugo_0.14_windows_amd64.exeがHugoのすべてなので、これを適当な場所において実行できるようにしとけばよい。
今回は、&lt;strong&gt;hugo.bat&lt;/strong&gt;というファイルに以下の内容を書き、PATHの通ったフォルダにいれた。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bat&#34;&gt;@echo off
C:\Users\Kaito\Desktop\tool\hugo_0.14_windows_amd64\hugo_0.14_windows_amd64.exe %*
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで、どこからでも&lt;code&gt;hugo [arguments]&lt;/code&gt;と打てばHugoコマンドが実行できる。&lt;/p&gt;

&lt;h2 id=&#34;hugoのシンタックスハイライト&#34;&gt;Hugoのシンタックスハイライト&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://gohugo.io/extras/highlighting/&#34;&gt;ドキュメント&lt;/a&gt;によると、Hugoでは&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%B7%E3%83%B3%E3%82%BF%E3%83%83%E3%82%AF%E3%82%B9%E3%83%8F%E3%82%A4%E3%83%A9%E3%82%A4%E3%83%88&#34;&gt;シンタックスハイライト&lt;/a&gt;を実現する方法を以下の2つから選べる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;サーバサイド: Hugoでのブログサイト生成時にハイライトしておく方法。&lt;/li&gt;
&lt;li&gt;クライアントサイド: クライアントがブログを読み込んだ時にJavaScriptでハイライトする方法。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;前者の方が当然クライアントの負荷が軽くなるが、&lt;a href=&#34;http://pygments.org/&#34;&gt;&lt;strong&gt;Pygments&lt;/strong&gt;&lt;/a&gt;のインストールが必要だったりめんどくさそうなので後者にする。(Pygmentsは&lt;a href=&#34;https://www.kaitoy.xyz/2015/08/15/github-pages-and-jekyll/&#34;&gt;Jekyllのとき&lt;/a&gt;にすでに入れたけど…)&lt;/p&gt;

&lt;p&gt;クライアントサイドでやるのもいくつかやり方があるが、例えば&lt;a href=&#34;https://highlightjs.org/&#34;&gt;Highlight.js&lt;/a&gt;を使うなら以下をHTMLヘッダに加えるだけでいい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;link rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;https://yandex.st/highlightjs/8.0/styles/default.min.css&amp;quot;&amp;gt;
&amp;lt;script src=&amp;quot;https://yandex.st/highlightjs/8.0/highlight.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script&amp;gt;hljs.initHighlightingOnLoad();&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この&lt;code&gt;default.min.css&lt;/code&gt;の部分を変えると&lt;a href=&#34;https://highlightjs.org/static/demo/&#34;&gt;色々なスタイル&lt;/a&gt;が選べる。
このブログでは&lt;code&gt;Zenburn&lt;/code&gt;を使うことにした。&lt;/p&gt;

&lt;h2 id=&#34;hugo味見&#34;&gt;Hugo味見&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gohugo.io/commands/&#34;&gt;Hugoコマンドリファレンス&lt;/a&gt;を見つつ、Hugoの味見をする。&lt;/p&gt;

&lt;p&gt;サイトのひな形を作るコマンドは&lt;code&gt;hugo new site [path]&lt;/code&gt;。&lt;code&gt;hugo new site blog&lt;/code&gt;を実行して、&lt;strong&gt;blog&lt;/strong&gt;という名のフォルダにサイトの初期ソースを生成。blogの部分はファイルもフォルダも存在しないパスを指定する。&lt;/p&gt;

&lt;p&gt;この時点で、blogフォルダ内には以下のものが入っている。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gohugo.io/content/archetypes/&#34;&gt;&lt;strong&gt;archetypes&lt;/strong&gt;&lt;/a&gt;: 新規記事作成時に自動で挿入される&lt;a href=&#34;https://gohugo.io/content/front-matter/&#34;&gt;&lt;strong&gt;Front Matter&lt;/strong&gt;&lt;/a&gt; (後述)のカスタマイズをするためのファイルを置くフォルダ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gohugo.io/content/organization/&#34;&gt;&lt;strong&gt;content&lt;/strong&gt;&lt;/a&gt;: ブログのコンテンツ(記事など)を置くフォルダ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gohugo.io/extras/datafiles/&#34;&gt;&lt;strong&gt;data&lt;/strong&gt;&lt;/a&gt;: サイト生成時に使うデータを置くフォルダ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://gohugo.io/templates/overview/&#34;&gt;&lt;strong&gt;layouts&lt;/strong&gt;&lt;/a&gt;: サイトのレイアウトを定義するファイルを置くフォルダ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gohugo.io/themes/creation&#34;&gt;&lt;strong&gt;static&lt;/strong&gt;&lt;/a&gt;: CSSとかJavaScriptとか画像とかのファイルを置くフォルダ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gohugo.io/overview/configuration/&#34;&gt;&lt;strong&gt;config.toml&lt;/strong&gt;&lt;/a&gt;: 設定ファイル。これは&lt;a href=&#34;https://github.com/toml-lang/toml&#34;&gt;&lt;strong&gt;TOML&lt;/strong&gt;&lt;/a&gt;だが、&lt;a href=&#34;https://ja.wikipedia.org/wiki/YAML&#34;&gt;&lt;strong&gt;YAML&lt;/strong&gt;&lt;/a&gt;か&lt;a href=&#34;https://ja.wikipedia.org/wiki/JavaScript_Object_Notation&#34;&gt;&lt;strong&gt;JSON&lt;/strong&gt;&lt;/a&gt;でもいい。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;記事を作るコマンドは&lt;code&gt;hugo new  [path]&lt;/code&gt;。blogフォルダに&lt;code&gt;cd&lt;/code&gt;して、二つ記事を作ってみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;hugo new about.md
hugo new post/first_post.md
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;blog\content\about.md&lt;/strong&gt;と&lt;strong&gt;blog\content\post\first_post.md&lt;/strong&gt;が生成された。
これらには、Front Matterという、記事のメタ情報が自動で書き込まれる。
デフォルトで書き込まれるのは、日付 (&lt;strong&gt;date&lt;/strong&gt;)、ドラフトフラグ (&lt;strong&gt;draft&lt;/strong&gt;)、タイトル (&lt;strong&gt;title&lt;/strong&gt;)だけだが、
&lt;a href=&#34;https://gohugo.io/content/archetypes/&#34;&gt;&lt;strong&gt;Archetypes&lt;/strong&gt;&lt;/a&gt;という機能でカスタマイズできる。
が、今はやらない。&lt;/p&gt;

&lt;p&gt;about.mdとfirst_post.mdには適当に記事の内容を書いておく。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次に&lt;a href=&#34;https://gohugo.io/themes/overview/&#34;&gt;テーマ&lt;/a&gt;を設定する。テーマを使えば、自分でレイアウトを書く必要がない。&lt;/p&gt;

&lt;p&gt;テーマは&lt;a href=&#34;https://github.com/spf13/hugoThemes&#34;&gt;&lt;strong&gt;Hugo Themes&lt;/strong&gt;&lt;/a&gt;にリストされていて、ひとつひとつ選んでインストールもできるけど、今回は全部いっぺんにインストールして色々見てみる。blogフォルダ内で以下を実行すると、&lt;strong&gt;blog\themes&lt;/strong&gt;に全テーマがインストールされる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;git clone --recursive https://github.com/spf13/hugoThemes.git themes
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これで、以下のコマンドを実行すると、サイトがビルドされ、サーバが起動し、ブラウザで確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;hugo server -t angels-ladder -D -w
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;-t&lt;/code&gt;でテーマを指定している。指定するのは&lt;strong&gt;blog\themes&lt;/strong&gt;内のフォルダ名。&lt;code&gt;-D&lt;/code&gt;はドラフト記事をビルドしたいときにつけるオプション。さっき作ったabout.mdとfirst_post.mdは、そのFront Matterのdraftがtrueになっていて、つまりドラフトなので、&lt;code&gt;-D&lt;/code&gt;を付けないとビルドされない。&lt;code&gt;-w&lt;/code&gt;は&lt;a href=&#34;https://gohugo.io/extras/livereload/&#34;&gt;&lt;strong&gt;LiveReload&lt;/strong&gt;&lt;/a&gt;を有効にするフラグで、付けておくとソースを修正したら自動でリビルドとブラウザのリロードが実行される。(変更を監視されるのはサブフォルダ内だけ。config.tomlの変更は無視される。)&lt;/p&gt;

&lt;p&gt;サーバには&lt;strong&gt;&lt;a href=&#34;http://localhost:1313/&#34;&gt;http://localhost:1313/&lt;/a&gt;&lt;/strong&gt;でアクセスできる。今回指定したテーマangels-ladderだと、トップページにfirst_post.mdの記事へのリンクがあり、その内容を確認できる。about.mdの方はリンクはなく、直接&lt;strong&gt;&lt;a href=&#34;http://localhost:1313/about/&#34;&gt;http://localhost:1313/about/&lt;/a&gt;&lt;/strong&gt;アクセスしないと見れない。この辺りはテーマ(と設定?)によって異なるのかな。
まあabout.mdは試しに作ってみただけなので消しておく。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;hugo server&lt;/code&gt;の&lt;code&gt;-t&lt;/code&gt;に与える値を変えれば簡単にテーマを切り替えられるので、いろいろ見てみる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以上で味見終わり。&lt;/p&gt;

&lt;h2 id=&#34;テーマの選定-robust&#34;&gt;テーマの選定 - Robust&lt;/h2&gt;

&lt;p&gt;Hugo Themesにあるテーマはどれもあまりしっくりこなかった。
もう自分で作ろうかと思っていたところ、&lt;a href=&#34;https://github.com/dim0627/hugo_theme_robust&#34;&gt;&lt;strong&gt;Robust&lt;/strong&gt;&lt;/a&gt;というテーマを見つけた。
&lt;a href=&#34;http://yet.unresolved.xyz/&#34;&gt;こんな感じ&lt;/a&gt;のページができる。いい。これを使うことにする。&lt;/p&gt;

&lt;p&gt;blogフォルダ内で、いったんthemesを消してから以下を実行してRobustをインストール。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bat&#34;&gt;&amp;gt; git init .
&amp;gt; git submodule add https://github.com/dim0627/hugo_theme_robust.git themes/hugo_theme_robust
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここでは、&lt;code&gt;git init&lt;/code&gt;でblogフォルダをGitリポジトリにして、&lt;code&gt;git submodule add&lt;/code&gt;で&lt;strong&gt;hugo_theme_robust&lt;/strong&gt; (RobustのGitHubプロジェクト)を&lt;a href=&#34;https://git-scm.com/book/ja/v1/Git-%E3%81%AE%E3%81%95%E3%81%BE%E3%81%96%E3%81%BE%E3%81%AA%E3%83%84%E3%83%BC%E3%83%AB-%E3%82%B5%E3%83%96%E3%83%A2%E3%82%B8%E3%83%A5%E3%83%BC%E3%83%AB&#34;&gt;サブモジュール&lt;/a&gt;として追加している。
こうすることで、blogとhugo_theme_robustを別々のリポジトリとして管理しつつ、hugo_theme_robustをblogの一部として使うことができる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;hugo server&lt;/code&gt;するときやビルド時に毎回テーマを指定しなくてもいいように、
config.tomlに&lt;code&gt;theme = &amp;quot;hugo_theme_robust&amp;quot;&lt;/code&gt;を追記しておく。&lt;/p&gt;

&lt;h2 id=&#34;テーマのカスタマイズ&#34;&gt;テーマのカスタマイズ&lt;/h2&gt;

&lt;p&gt;テーマフォルダ内の構成はblogフォルダ(プロジェクトルート)内と同じようになっていて、Hugoがサイトをビルドするとき、プロジェクトルート内のフォルダとテーマフォルダ内のフォルダをマージしたものを使ってくれる。この際、プロジェクトルート内のファイルが優先される。&lt;/p&gt;

&lt;p&gt;つまり例えば以下のような構成のプロジェクトがあったとする。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;blog

&lt;ul&gt;
&lt;li&gt;layouts

&lt;ul&gt;
&lt;li&gt;hoge.html&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;themes

&lt;ul&gt;
&lt;li&gt;hugo_theme_robust

&lt;ul&gt;
&lt;li&gt;layouts

&lt;ul&gt;
&lt;li&gt;hoge.html&lt;/li&gt;
&lt;li&gt;foo.html&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Hugoはこれをビルドするとき、layouts内には&lt;strong&gt;blog\layouts\hoge.html&lt;/strong&gt;と&lt;strong&gt;blog\thmes\hugo_theme_robust\layouts\foo.html&lt;/strong&gt;があるものとして処理してくれる。テーマをちょっとカスタマイズしたいときに、テーマのソースをいじらないでいいのが便利。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Robustはとりあえず設定ファイルをカスタマイズすれば使える。設定ファイルは、Robustはconfig.yamlだけど、ルートにconfig.toml置いたらちゃんと上書きできた。&lt;/p&gt;

&lt;h2 id=&#34;記事の仕上げ&#34;&gt;記事の仕上げ&lt;/h2&gt;

&lt;p&gt;first_post.mdの内容を仕上げて、以下のコマンドでdraftフラグをオフにする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bat&#34;&gt;&amp;gt; hugo undraft content\post\first_post.md
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これをやるとdateも更新される。&lt;/p&gt;

&lt;h2 id=&#34;githubへソースを保存&#34;&gt;GitHubへソースを保存&lt;/h2&gt;

&lt;p&gt;blog内の変更をコミットして、GitHubにblogという名のリポジトリを作成して、以下のコマンドでソースをアップロードする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bat&#34;&gt;&amp;gt; git remote add origin git@github.com:kaitoy/blog.git
&amp;gt; git push -u origin master
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;また、ここで、&lt;strong&gt;gh-pages&lt;/strong&gt;というブランチを作り、中身を空にして、masterとは別途チェックアウトしておく。
コマンドは以下。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bat&#34;&gt;&amp;gt; git checkout -b gh-pages
&amp;gt; rm -rf *
&amp;gt; git rm -rf .
&amp;gt; git commit -m &amp;quot;Init GitHub Pages branch.&amp;quot;
&amp;gt; git push origin gh-pages
&amp;gt; git checkout master
&amp;gt; git clone -b gh-pages git@github.com:kaitoy/blog.git pages
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これでgh-pagesブランチが&lt;strong&gt;blog\pages&lt;/strong&gt;フォルダに展開された。&lt;/p&gt;

&lt;p&gt;因みにgh-pagesは、&lt;a href=&#34;https://www.kaitoy.xyz/2015/08/15/github-pages-and-jekyll/#github-pages%E5%91%B3%E8%A6%8B&#34;&gt;以前のエントリ&lt;/a&gt;にも書いたが、GitHub Pagesで公開するサイトを置く特別なブランチ。&lt;/p&gt;

&lt;p&gt;(2016/8/18追記: &lt;a href=&#34;https://www.kaitoy.xyz/2016/08/18/simpler-github-pages-publishing/&#34;&gt;今はgh-pagesブランチは不要。&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;ビルド-デプロイ&#34;&gt;ビルド・デプロイ&lt;/h2&gt;

&lt;p&gt;ビルドコマンドは単に&lt;code&gt;hugo&lt;/code&gt;。ビルド成果物はデフォルトで&lt;strong&gt;public&lt;/strong&gt;というフォルダに入る。
ここでは、pagesフォルダに入るように以下のコマンドでビルドする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bat&#34;&gt;&amp;gt; hugo -d pages
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;ビルド完了したら、pagesフォルダに&lt;code&gt;cd&lt;/code&gt;して、全てのファイルを&lt;code&gt;git add&lt;/code&gt;して、コミットしてプッシュすればデプロイ完了。
&lt;code&gt;https://kaitoy.github.io/blog/&lt;/code&gt;でサイトを確認できる。&lt;/p&gt;

&lt;h2 id=&#34;カスタムドメイン&#34;&gt;カスタムドメイン&lt;/h2&gt;

&lt;p&gt;サイトに&lt;code&gt;http://www.kaitoy.xyz&lt;/code&gt;でアクセスできるようにする。手順は以下。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.value-domain.com/&#34;&gt;&lt;strong&gt;VALUE-DOMAIN&lt;/strong&gt;&lt;/a&gt;でkaitoy.xyzを取得。&lt;/li&gt;
&lt;li&gt;VALUE-DOMAINのDNS設定に&lt;code&gt;cname tbd kaitoy.github.io.&lt;/code&gt;を追加。&lt;/li&gt;
&lt;li&gt;gh-pagesブランチのルートに&lt;strong&gt;CNAME&lt;/strong&gt;というファイルを作り、&lt;strong&gt;www.kaitoy.xyz&lt;/strong&gt;とだけ書いておく。&lt;/li&gt;
&lt;li&gt;config.tomlのbaseurlを&lt;strong&gt;&lt;a href=&#34;http://www.kaitoy.xyz&#34;&gt;http://www.kaitoy.xyz&lt;/a&gt;&lt;/strong&gt;に変更。ビルドしてプッシュ。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;以上でブログサイト立ち上げ完了。あとはテーマをカスタマイズしたり、ひたすらエントリを書く。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GitHub Pagesでブログ立ち上げ - Jekyllのためのツール</title>
          <link>https://www.kaitoy.xyz/2015/08/25/tools-for-jekyll/</link>
          <pubDate>Tue, 25 Aug 2015 22:36:28 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/08/25/tools-for-jekyll/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2015/08/15/github-pages-and-jekyll/&#34;&gt;&lt;strong&gt;GitHub Pagesでブログ立ち上げ - GitHub PagesとJekyll&lt;/strong&gt;&lt;/a&gt;の続き。
前回は、&lt;a href=&#34;https://pages.github.com/&#34;&gt;&lt;strong&gt;GitHub Pages&lt;/strong&gt;&lt;/a&gt;と&lt;a href=&#34;http://jekyllrb.com/docs/home/&#34;&gt;&lt;strong&gt;Jekyll&lt;/strong&gt;&lt;/a&gt;でブログを始めることにして、Jekyllのセットアップに四苦八苦した。&lt;/p&gt;

&lt;p&gt;Jekyllがだいたいセットアップできたところで、どんなサイトデザインにしようか考え始めた。
調べたところ、生のJekyllを使うよりも簡単に見栄えのいいサイトを作れる方法がある模様。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;octopress&#34;&gt;Octopress&lt;/h2&gt;

&lt;p&gt;もっとも有名なのは&lt;a href=&#34;http://octopress.org/&#34;&gt;&lt;strong&gt;Octopress&lt;/strong&gt;&lt;/a&gt;。
ホームページの説明によると、「Octopress is a framework designed for Jekyll, the static blogging engine powering Github Pages」とのこと。
フレームワークと呼ぶのはちょっと大げさな気がする。
まあ見たところ、Jekyllをサイト生成エンジンとした、ブログサイト構築、ブログエントリ作成、ブログサイトデプロイなどを簡易化するツール。&lt;/p&gt;

&lt;p&gt;広く使われていて情報が豊富だし、テーマを選んでエントリの内容を&lt;a href=&#34;https://ja.wikipedia.org/wiki/Markdown&#34;&gt;&lt;strong&gt;Markdown&lt;/strong&gt;&lt;/a&gt;で書くだけでかっこいいサイトが作れる。バージョンは2系が主に使われているやつで、3系がβ状態。&lt;/p&gt;

&lt;p&gt;血迷って3系に手を出してみる。&lt;a href=&#34;https://github.com/octopress/octopress&#34;&gt;GitHubにあるREADME&lt;/a&gt;を見ながらWindows 7上にインストールして、適当なサイトを作ろうとするも&lt;code&gt;jekyll build&lt;/code&gt;でエラー。さすがにWindowsじゃだめかと思い、CentOS 7のVMを立ち上げてそこでやってみるもまた&lt;code&gt;jekyll build&lt;/code&gt;でエラー。&lt;/p&gt;

&lt;p&gt;心折れかけながらドキュメントなど見ていたら、多くのプラグインがまだ開発中で、3系は基本的な機能しか動かなそうなことが発覚。素直に2系にすることに。&lt;/p&gt;

&lt;p&gt;2系は成熟しているし情報が沢山あるので、順調にインストールとテストサイト作成に成功したあたりで、不審な情報を発見した。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://jekyllrb.com/docs/plugins/&#34;&gt;Jekyllのドキュメント&lt;/a&gt;によると、GitHub Pagesではセキュリティ対策のためにJekyll をセーフモードで実行するため、カスタムプラグインが無効になるとのこと。
Octopressが生成したJekyllソースをGitHub Pagesに上げたらビルドして公開してくれると思っていたけど、OctopressはJekyllのプラグイン機能をもりもり利用しているようなので、上手くいかないようだ。&lt;/p&gt;

&lt;p&gt;つまりOctopressをGitHub Pages上のサイトに使うとしたら、結局ビルド成果物をアップしないといけなくなる。JekyllのソースだけをGitHubで管理するように出来たらいいと思っていたが当てが外れた。&lt;/p&gt;

&lt;h2 id=&#34;jekyll-bootstrap&#34;&gt;Jekyll-Bootstrap&lt;/h2&gt;

&lt;p&gt;Octopressを使うモチベーションが下がり、他のを探したところ、&lt;a href=&#34;http://jekyllbootstrap.com/&#34;&gt;&lt;strong&gt;Jekyll-Bootstrap&lt;/strong&gt;&lt;/a&gt;というのを見つけた。&lt;/p&gt;

&lt;p&gt;Jekyll-BootstrapはJekyllのソースそのもので、面倒な部分は既にできてるので、ユーザはテンプレートを使って記事の内容を書くだけでいいよ、というもの。テーマ機能と、記事作成作業を&lt;a href=&#34;http://docs.seattlerb.org/rake/&#34;&gt;&lt;strong&gt;Rake&lt;/strong&gt;&lt;/a&gt;で簡易化するためのRakefile付き。&lt;/p&gt;

&lt;p&gt;すばらしいことに、「JekyllのソースだけをGitHubで管理するように出来たらいい」という需要に応えることを目指して作られていて、Jekyll-Bootstrapをベースに作ったJekyllソースはGitHub Pages上のJekyllでビルド可能。&lt;/p&gt;

&lt;p&gt;まさに求めていたものと心躍った。
が、&lt;a href=&#34;https://github.com/plusjade/jekyll-bootstrap&#34;&gt;プロジェクトページ&lt;/a&gt;を見るにあまり活発に開発が進んでない模様。
廃れ行きそうなツールを使うのもなぁ…&lt;/p&gt;

&lt;h2 id=&#34;結論&#34;&gt;結論&lt;/h2&gt;

&lt;p&gt;Jekyll-Bootstrapを使うのは気が進まない。Octopressを使うとビルド成果物をアップしないといけない。
どうせビルド成果物を上げるのなら、Jekyllにこだわる必要はないか、ということで、去年末くらいから盛り上がってきている&lt;a href=&#34;https://gohugo.io/&#34;&gt;&lt;strong&gt;Hugo&lt;/strong&gt;&lt;/a&gt;にすることに。Hugoについてはまた&lt;a href=&#34;https://www.kaitoy.xyz/2015/08/28/using-hugo/&#34;&gt;別のエントリ&lt;/a&gt;で書く。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Atomパッケージを作る - ワード境界を日本語対応させるパッケージ: japanese-word-selection</title>
          <link>https://www.kaitoy.xyz/2015/08/21/japanese-word-selection/</link>
          <pubDate>Fri, 21 Aug 2015 15:31:41 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/08/21/japanese-word-selection/</guid>
          <description>

&lt;p&gt;このブログは&lt;a href=&#34;https://atom.io/&#34;&gt;&lt;strong&gt;Atom&lt;/strong&gt;&lt;/a&gt;というGitHubが開発したテキストエディタを使って書いている。
このエントリは、そのAtomのパッケージを作ってみたというお話。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;atomとは&#34;&gt;Atomとは&lt;/h2&gt;

&lt;p&gt;Atomは、2015/6/25にバージョン1.0がリリースされたばかりの新しいテキストエディタで、そのせいもあってか日本語サポートはあまり充実していない。
例えば、テキストを画面の端で折り返す「Soft Wrap」という機能はマルチバイト文字に対応しておらず、日本語で横に長い文を書いたりすると画面からはみ出てしまって不便。&lt;/p&gt;

&lt;p&gt;しかしAtomは、パッケージなる、機能を拡張できるプラグインみたいな仕組みを持っていて、例えば上記Soft Wrapの問題は&lt;a href=&#34;https://github.com/raccy/japanese-wrap&#34;&gt;&lt;strong&gt;japanese-wrap&lt;/strong&gt;&lt;/a&gt;というパッケージをインストールすることで解決できる。
パッケージは誰でも作って配布することができる。&lt;/p&gt;

&lt;h2 id=&#34;日本語のワード境界&#34;&gt;日本語のワード境界&lt;/h2&gt;

&lt;p&gt;Atomでブログを書いていて不満を感じたのは、日本語のワード境界をちゃんと判定してくれないところ。&lt;/p&gt;

&lt;p&gt;以前は(今もたまに)&lt;a href=&#34;http://sakura-editor.sourceforge.net/&#34;&gt;&lt;strong&gt;サクラエディタ&lt;/strong&gt;&lt;/a&gt;という和製テキストエディタを使っていて、日本語文の中の一語をダブルクリックで選択するという操作をよくやっていた。
例えば、「Atomのパッケージは便利」という文があったら、「パッケージ」の辺りをダブルクリックすると「パッケージ」という単語を選択できる。&lt;/p&gt;

&lt;p&gt;Atomでも癖でこの操作をすると、妙に広い範囲が選択されてしまう。
上記例だと「Atomのパッケージは便利」全体が選択されてしまう。不便。&lt;/p&gt;

&lt;h2 id=&#34;japanese-word-selection&#34;&gt;japanese-word-selection&lt;/h2&gt;

&lt;p&gt;この問題を解決してくれそうなパッケージを探したけど見つからなかったので、いい機会と思い自分で作ったのが&lt;a href=&#34;https://atom.io/packages/japanese-word-selection&#34;&gt;&lt;strong&gt;japanese-word-selection&lt;/strong&gt;&lt;/a&gt;。ソースは&lt;a href=&#34;https://github.com/kaitoy/japanese-word-selection&#34;&gt;GitHub&lt;/a&gt;に。&lt;/p&gt;

&lt;p&gt;インストールして有効にすると、日本語のワード境界を判定するようになる。実のところ、とりあえずは文字種の境目を見ているだけ。ひらがな、カタカナ、半角カタカナ、漢字に対応。
特殊文字の全角版の処理どうするとか、あまり深く考えて作ってないけど、使ってて変な挙動を見つけたらおいおい直すということで。&lt;/p&gt;

&lt;p&gt;とりあえず、&lt;strong&gt;Edit &amp;gt; Text&lt;/strong&gt; の &lt;strong&gt;Delete to Previous Word Boundary&lt;/strong&gt; と &lt;strong&gt;Delete to Next Word Boundary&lt;/strong&gt; がちゃんと動かないのは見つけた。パッケージで上書きした処理を通っていない気がする。けど、デフォルトでキーバインディングもないし、あまり使われなそうな機能なのでほっておく。&lt;/p&gt;

&lt;h2 id=&#34;atomのパッケージの作り方&#34;&gt;Atomのパッケージの作り方&lt;/h2&gt;

&lt;p&gt;パッケージの作り方は、&lt;a href=&#34;https://atom.io/docs/latest/&#34;&gt;&lt;strong&gt;Atom Flight Manual&lt;/strong&gt;&lt;/a&gt;の&lt;a href=&#34;https://atom.io/docs/latest/hacking-atom-package-word-count&#34;&gt;このあたり&lt;/a&gt;を参考に。
Atom Flight ManualにはAtomの使い方からパッケージの作り方まで体系的に纏められているので一度は通して読みたい。&lt;/p&gt;

&lt;p&gt;パッケージ開発にあたって、前提として知っておくべきは、Atomは&lt;a href=&#34;http://electron.atom.io/&#34;&gt;&lt;strong&gt;Electron&lt;/strong&gt;&lt;/a&gt;という実行環境の上で動いているということ。
(Atomが先で、そこからElectronがスピンオフした。)&lt;/p&gt;

&lt;p&gt;Electronはざっくり&lt;a href=&#34;https://nodejs.org/&#34;&gt;&lt;strong&gt;Node&lt;/strong&gt;&lt;/a&gt;と&lt;a href=&#34;https://www.chromium.org/Home&#34;&gt;&lt;strong&gt;Chromium&lt;/strong&gt;&lt;/a&gt;(Google ChromeのOSS版)でできていて、その上で動くアプリケーションは、HTMLとCSSで書いた画面をChromiumで表示して、それをNodeで動かすJavaScriptで制御する、という形で実装される。AtomはJavaScriptの代わりに、より高級な&lt;a href=&#34;http://coffeescript.org/&#34;&gt;&lt;strong&gt;CoffeeScript&lt;/strong&gt;&lt;/a&gt;を使っているので、パッケージを作る際はCoffeeScriptのコードをがりがり書くことになる。&lt;/p&gt;

&lt;p&gt;パッケージは&lt;a href=&#34;https://www.npmjs.com/&#34;&gt;npm&lt;/a&gt;のパッケージっぽく書く。&lt;/p&gt;

&lt;p&gt;Atomは&lt;a href=&#34;https://ja.wikipedia.org/wiki/Model_View_ViewModel&#34;&gt;MVVM&lt;/a&gt;な感じの設計になっていて、コアのViewModelとかをパッケージからいじることでいろんな機能を実現できる。&lt;/p&gt;

&lt;p&gt;以下、備忘録として、japanese-word-selectionを作った時にやったことを書いておく。Atomのバージョンは1.0.7。&lt;/p&gt;

&lt;h4 id=&#34;1-パッケージテンプレート生成&#34;&gt;1. パッケージテンプレート生成&lt;/h4&gt;

&lt;p&gt;Atomを起動して、&lt;code&gt;Ctrl+Shift+P&lt;/code&gt;でコマンドパレットを開いて、&lt;code&gt;generate package&lt;/code&gt;と入力してEnter。
&lt;strong&gt;Package Generator&lt;/strong&gt;が起動して、作成するパッケージの名前を聞かれるのでjapanese-word-selectionを入力。(因みに、パッケージ名に&lt;strong&gt;atom-&lt;/strong&gt;というプレフィックスを付けているのをたまに見るが、これは推奨されていない。)
するとパッケージのテンプレートが作成され、それを読み込んだAtomウィンドウが開く(下図)。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.kaitoy.xyz/images/japanese-word-selection/project_tree.jpg&#34; alt=&#34;project tree&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;パッケージ構成については概ね以下の感じ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;keymaps: キーバインディングを定義する&lt;a href=&#34;https://github.com/bevry/cson&#34;&gt;cson&lt;/a&gt;ファイルをいれる。&lt;/li&gt;
&lt;li&gt;lib: パッケージの機能を実装するCoffeeスクリプトを入れる。

&lt;ul&gt;
&lt;li&gt;デフォルトで「&lt;strong&gt;パッケージ名.coffee&lt;/strong&gt;」がメインスクリプト。&lt;/li&gt;
&lt;li&gt;Package Generatorが作る「&lt;strong&gt;パッケージ名-view.coffee&lt;/strong&gt;」というスクリプトは、Atomの画面に新たなペインを追加したいときとかに書くコードのサンプル。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;menus: ツールバーとかコンテクストメニューに追加するメニューを定義するcsonファイルを入れる。&lt;/li&gt;
&lt;li&gt;spec: パッケージのテストを入れる。テストは&lt;a href=&#34;http://jasmine.github.io/&#34;&gt;Jasmine&lt;/a&gt;を使って書く。&lt;/li&gt;
&lt;li&gt;styles: パッケージが追加するペインとかに独自のスタイルを指定したいときとかに&lt;a href=&#34;http://less-ja.studiomohawk.com/&#34;&gt;Less&lt;/a&gt;かCSSを入れる。&lt;/li&gt;
&lt;li&gt;package.json: パッケージの名前とか依存関係とかを定義するファイル。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;japanese-word-selectionはメニューもコマンドもペインも追加しないので、keymaps、lib/japanese-word-selection-view.coffee、menus、spec/japanese-word-selection-view-spec.coffee、stylesは消す。&lt;/p&gt;

&lt;p&gt;以下、ここで生成したパッケージフォルダを&lt;strong&gt;&amp;lt;パッケージルート&amp;gt;&lt;/strong&gt;と書く。&lt;/p&gt;

&lt;h4 id=&#34;2-メインスクリプト編集-概要&#34;&gt;2. メインスクリプト編集 - 概要&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;&amp;lt;パッケージルート&amp;gt;/lib/japanese-word-selection.coffee&lt;/strong&gt;を編集して機能を実装する。
Package Generatorがサンプルコードを書いてくれているので、それを書き変えて行けばよい。&lt;/p&gt;

&lt;p&gt;機能は特定のAPIをもったオブジェクトに実装して、それを &lt;strong&gt;module.exports&lt;/strong&gt; に代入する。
今回は &lt;strong&gt;JapaneseWordSelection&lt;/strong&gt; がそのオブジェクト。「特定のAPI」というのは以下のメソッド。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;activate(state): パッケージが有効化されるときに呼ばれる。&lt;/li&gt;
&lt;li&gt;deactivate(): パッケージが無効化されるときに呼ばれる。無くてもいい。&lt;/li&gt;
&lt;li&gt;serialize(): Atomウィンドウを閉じるときに、パッケージの状態を保存したいときに実装するメソッド。無くてもいい。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;JapaneseWordSelectionには、activateとdeactivateを実装して、前者の中でワード境界判定処理をいじり、後者の中で元に戻すようにする。つまり、japanese-word-selection.coffeeはだいたい以下のようなコードになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-coffeescript&#34;&gt;module.exports = JapaneseWordSelection =

  activate: -&amp;gt;
    # ワード境界判定処理を日本語対応させる。

  deactivate: -&amp;gt;
    # ワード境界判定処理を元に戻す。
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;3-メインスクリプト編集-activate&#34;&gt;3. メインスクリプト編集 - activate&lt;/h4&gt;

&lt;p&gt;実際の処理を書く際には、&lt;a href=&#34;https://atom.io/docs/api/latest&#34;&gt;Atom APIのドキュメント&lt;/a&gt;を参照する。また、&lt;a href=&#34;https://github.com/atom/atom&#34;&gt;Atomのソース&lt;/a&gt;を見てAtom APIの実装の詳細を見るべきときもある。&lt;/p&gt;

&lt;p&gt;パッケージのスクリプトからは、Atomクラスのインスタンスである &lt;strong&gt;atom&lt;/strong&gt; というグローバル変数が使えて、これを入り口にAtomウィンドウ内の各要素のViewModelオブジェクトをいじることができる。&lt;/p&gt;

&lt;p&gt;イベントを扱うときには、&lt;a href=&#34;https://atom.io/docs/api/v1.0.7/CompositeDisposable&#34;&gt;CompositeDisposable&lt;/a&gt;が便利。これを使うと、以下のようにして、ViewModelオブジェクトとかに登録したイベントハンドラを後で簡単に削除できる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-coffeescript&#34;&gt;@disposables = new CompositeDisposable
editor = atom.workspace.getActiveTextEditor()
@disposables.add editor.onDidChange -&amp;gt;  # editorにイベントハンドラを登録。
@disposables.add editor.onDidChangePath -&amp;gt;  # editorに別のイベントハンドラを登録。

(snip)

@disposables.dispose()  # 全てのイベントハンドラを削除。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;JapaneseWordSelection#activate()では、&lt;a href=&#34;https://atom.io/docs/api/v1.0.7/Workspace#instance-observeTextEditors&#34;&gt;atom.workspace.observeTextEditors(callback)&lt;/a&gt;というAPIを利用して&lt;a href=&#34;https://atom.io/docs/api/v1.0.7/TextEditor&#34;&gt;TextEditor&lt;/a&gt;オブジェクトを取得して、それが持っている&lt;a href=&#34;https://atom.io/docs/api/v1.0.7/Cursor&#34;&gt;Cursor&lt;/a&gt;オブジェクトの振る舞いを変更する。
この、observeXXXXというAPIは他にもいろいろあって、実行すると既存の全てのXXXXのインスタンスをcallbackに渡してくれて、さらに、それ以降XXXXのインスタンスが作られるたびにcallbackを呼び出すイベントハンドラを登録してくれる。&lt;/p&gt;

&lt;p&gt;このobserveXXXXとかに上記CompositeDisposableが使えて、observeXXXXの場合、その戻り値をCompositeDisposableにaddしておくと、後でCompositeDisposable#dispose()でイベントハンドラを削除できる。&lt;/p&gt;

&lt;p&gt;まとめると、JapaneseWordSelection#activate()は以下のようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-coffeescript&#34;&gt;module.exports = JapaneseWordSelection =

  disposables: null

  activate: -&amp;gt;
    @disposables = new CompositeDisposable
    @disposables.add atom.workspace.observeTextEditors (editor) -&amp;gt;
      JapaneseWordSelection.japanizeWordBoundary(editor, cursor) for cursor in editor.getCursors()

  japanizeWordBoundary: (editor, cursor) -&amp;gt;
    # Cursorオブジェクトの振る舞いを変更する処理
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(今見ると、Cursorの方もobserveした方がいいか。後で直そう。)&lt;/p&gt;

&lt;h4 id=&#34;4-メインスクリプト編集-deactivate&#34;&gt;4. メインスクリプト編集 - deactivate&lt;/h4&gt;

&lt;p&gt;JapaneseWordSelection#deactivate()は、追加したイベントハンドラを削除して、全てのCursorオブジェクトの振る舞いを元に戻すだけ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-coffeescript&#34;&gt;  deactivate: -&amp;gt;
    @disposables.dispose()
    for i, editor of atom.workspace.getTextEditors()
      for j, cursor of editor.getCursors()
        # Cursorオブジェクトの振る舞いを元に戻す処理
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;5-package-json編集&#34;&gt;5. package.json編集&lt;/h4&gt;

&lt;p&gt;package.jsonは、Package Generatorが以下のようなひな形を作ってくれている。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;japanese-word-selection&amp;quot;,
  &amp;quot;main&amp;quot;: &amp;quot;./lib/japanese-word-selection&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.0.0&amp;quot;,
  &amp;quot;description&amp;quot;: &amp;quot;A short description of your package&amp;quot;,
  &amp;quot;keywords&amp;quot;: [
  ],
  &amp;quot;activationCommands&amp;quot;: {
    &amp;quot;atom-workspace&amp;quot;: &amp;quot;japanese-word-selection:toggle&amp;quot;
  },
  &amp;quot;repository&amp;quot;: &amp;quot;https://github.com/atom/japanese-word-selection&amp;quot;,
  &amp;quot;license&amp;quot;: &amp;quot;MIT&amp;quot;,
  &amp;quot;engines&amp;quot;: {
    &amp;quot;atom&amp;quot;: &amp;quot;&amp;gt;=1.0.0 &amp;lt;2.0.0&amp;quot;
  },
  &amp;quot;dependencies&amp;quot;: {
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これに以下の編集を加える。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;description&lt;/strong&gt; にパッケージの説明を書く。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;keywords&lt;/strong&gt; にパッケージリポジトリ内での検索のためのタグを書く。&lt;/li&gt;
&lt;li&gt;japanese-word-selectionはとりあえずコマンドを作らないので、&lt;strong&gt;activationCommands&lt;/strong&gt; は消す。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;repository&lt;/strong&gt; にjapanese-word-selectionのソースを置く(予定の)GitHubリポジトリのアドレスを書く。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;これだけ。以下のようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;japanese-word-selection&amp;quot;,
  &amp;quot;main&amp;quot;: &amp;quot;./lib/japanese-word-selection&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.0.0&amp;quot;,
  &amp;quot;description&amp;quot;: &amp;quot;Japanize word boundary.&amp;quot;,
  &amp;quot;keywords&amp;quot;: [
    &amp;quot;japanese&amp;quot;,
    &amp;quot;selection&amp;quot;,
    &amp;quot;word&amp;quot;
  ],
  &amp;quot;repository&amp;quot;: &amp;quot;https://github.com/kaitoy/japanese-word-selection&amp;quot;,
  &amp;quot;license&amp;quot;: &amp;quot;MIT&amp;quot;,
  &amp;quot;engines&amp;quot;: {
    &amp;quot;atom&amp;quot;: &amp;quot;&amp;gt;=1.0.0 &amp;lt;2.0.0&amp;quot;
  },
  &amp;quot;dependencies&amp;quot;: {
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;version&lt;/strong&gt; はパッケージリリース(パブリッシュ)時に自動でインクリメントされるので、0.0.0のままほっておく。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;dependencies&lt;/strong&gt; には依存するnpmパッケージを定義できるが、japanese-word-selectionは一人で動くので何も書かない。
因みに、dependenciesに何か追加したら、package.jsonがあるフォルダで&lt;code&gt;apm install&lt;/code&gt;というコマンドを実行すると、そのフォルダの下に&lt;strong&gt;node_modules&lt;/strong&gt;というフォルダができて、そこに依存がインストールされる。&lt;/p&gt;

&lt;p&gt;このpackage.jsonは&lt;a href=&#34;https://docs.npmjs.com/files/package.json&#34;&gt;npmのpackage.json&lt;/a&gt;を拡張したもので、npmのpackage.jsonのプロパティは全部使える。&lt;/p&gt;

&lt;h4 id=&#34;6-動作確認&#34;&gt;6. 動作確認&lt;/h4&gt;

&lt;p&gt;作成したパッケージは、Package Generatorに生成された時点でAtomから使えるようになっている。
ソースを変更したら、&lt;code&gt;Ctrl+Shift+F5&lt;/code&gt;(昔は&lt;code&gt;Ctrl+Alt+r&lt;/code&gt;だったような…)でウィンドウをリロードして反映して動作確認できる。&lt;/p&gt;

&lt;p&gt;ログを見たい時など、&lt;code&gt;Ctrl+Shift+i&lt;/code&gt;でディベロッパツールを開いておくと便利。&lt;/p&gt;

&lt;h4 id=&#34;7-テスト&#34;&gt;7. テスト&lt;/h4&gt;

&lt;p&gt;上記の通り、パッケージのテストはJasmineを使って書いて、&lt;strong&gt;&amp;lt;パッケージルート&amp;gt;/spec/&lt;/strong&gt;に入れる。テストファイル名の拡張子を除いた部分は&lt;strong&gt;-spec&lt;/strong&gt;というポストフィックスを付けなければいけない。&lt;/p&gt;

&lt;p&gt;テストの書き方については、&lt;a href=&#34;https://atom.io/docs/latest/hacking-atom-writing-specs&#34;&gt;Atomのマニュアル&lt;/a&gt;とか、&lt;a href=&#34;https://github.com/atom/atom/tree/master/spec&#34;&gt;Atomのテスト&lt;/a&gt;とか、Jasmineのマニュアルとかを参照ということで、ここでは割愛する。テスト書くのは必須ではないし。&lt;/p&gt;

&lt;p&gt;テストは&lt;code&gt;Ctrl+Shift+y&lt;/code&gt;(昔は&lt;code&gt;Ctrl+Alt+p&lt;/code&gt;だったような…)で実行できる。&lt;/p&gt;

&lt;h4 id=&#34;8-その他ファイルの編集&#34;&gt;8. その他ファイルの編集&lt;/h4&gt;

&lt;p&gt;README.md、LICENSE.md、CHANGELOG.mdを修正。詳細は割愛。&lt;/p&gt;

&lt;h4 id=&#34;9-githubへ保存&#34;&gt;9. GitHubへ保存&lt;/h4&gt;

&lt;p&gt;GitHubにjapanese-word-selectionという名のリポジトリを作り、そこにソースを保存。詳細は割愛。
Atomのドキュメントによると、今のところ、GitHubへのソース保存は以下のパブリッシュのために必須な模様。&lt;/p&gt;

&lt;h4 id=&#34;10-パブリッシュ&#34;&gt;10. パブリッシュ&lt;/h4&gt;

&lt;p&gt;作ったパッケージをリリースすることを、パブリッシュという。
手順は&lt;a href=&#34;https://atom.io/docs/latest/hacking-atom-package-word-count#publishing&#34;&gt;Atomのドキュメント&lt;/a&gt;に説明されている。&lt;/p&gt;

&lt;p&gt;パブリッシュするには、&lt;strong&gt;apm&lt;/strong&gt; という、Atomのパッケージを管理するコマンドラインツールが必要。どうもAtom本体と一緒にインストールされるっぽい。&lt;/p&gt;

&lt;p&gt;やることは、&amp;lt;パッケージルート&amp;gt;に&lt;code&gt;cd&lt;/code&gt;して、&lt;code&gt;apm publish minor&lt;/code&gt;を実行するだけ。
このコマンドは以下の処理をする。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;(初回のみ)パッケージ名をatom.ioに登録する。&lt;/li&gt;
&lt;li&gt;package.jsonのversionをインクリメントしてコミットする。&lt;code&gt;apm publish&lt;/code&gt;にminorを指定するので、0.1.0になる。代わりにmajorかpatchを指定すると、1.0.0か0.0.1になる。&lt;/li&gt;
&lt;li&gt;Gitのタグを作る。&lt;/li&gt;
&lt;li&gt;GitHubに変更とタグをpushする。&lt;/li&gt;
&lt;li&gt;atom.ioにパッケージを登録する。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;私の場合、初回だったので、コマンド実行中にatom.ioのアカウントを作ってAPIトークンを取得する手順があった。
以下がコマンドのメッセージ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# cd japanese-word-selection
# apm publish minor
Welcome to Atom!

Before you can publish packages, you&#39;ll need an API token.

Visit your account page on Atom.io https://atom.io/account,
copy the token and paste it below when prompted.

Press [Enter] to open your account page on Atom.io.
Token&amp;gt; hogeeeeeeeeeeeeeeeee
Saving token to Keychain done
Registering japanese-word-selection done
Preparing and tagging a new version done
Pushing v0.1.0 tag done
Publishing japanese-word-selection@v0.1.0 done
Congrats on publishing a new package!
Check it out at https://atom.io/packages/japanese-word-selection
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://atom.io/packages/japanese-word-selection&#34;&gt;https://atom.io/packages/japanese-word-selection&lt;/a&gt; に行ったらちゃんとjapanese-word-selectionのページができていた。
これでパブリッシュまで完了。&lt;/p&gt;

&lt;p&gt;因みに、&lt;code&gt;apm unpublish パッケージ名@バージョン&lt;/code&gt;で&lt;a href=&#34;https://www.kaitoy.xyz/2015/12/02/unpublish-atom-package/&#34;&gt;パブリッシュを取り消す&lt;/a&gt;ことができる。&lt;/p&gt;

&lt;h4 id=&#34;11-パッケージのアップデートの開発&#34;&gt;11. パッケージのアップデートの開発&lt;/h4&gt;

&lt;p&gt;Package Generatorでパッケージを生成すると、そのフォルダへのリンクが&lt;code&gt;%userprofile%\.atom\packages\&lt;/code&gt;に生成される。
このフォルダは&lt;code&gt;apm link&lt;/code&gt;コマンドでリンクを張るフォルダであり、普通にインストールしたパッケージが入る場所だ。
ここに入っているパッケージが、AtomのGUIのInstalled Packagesに表示される。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;apm publish&lt;/code&gt;しても、パブリッシュしたパッケージは&lt;code&gt;%userprofile%\.atom\packages\&lt;/code&gt;にリンクのまま残る。
ので、アップデートバージョンも、初バージョンの開発とまったく同じように開発してパブリッシュできる。&lt;/p&gt;

&lt;p&gt;昔はこの↓ような面倒なことが必要だったはずなんだけど。&lt;/p&gt;

&lt;p&gt;&amp;mdash;&amp;mdash; 以下昔話 &amp;mdash;&amp;mdash;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;apm publish&lt;/code&gt;をすると、パブリッシュしたバージョンがインストールされた状態になる。
具体的には、&lt;code&gt;%userprofile%\.atom\packages\&lt;/code&gt;にそのパッケージが入っている状態になる。&lt;/p&gt;

&lt;p&gt;パッケージのアップデートを開発する際は、修正している版のパッケージ(&amp;lt;パッケージルート&amp;gt;に入っている方)を優先してロードして欲しくなるが、そのためには&lt;code&gt;%userprofile%\.atom\dev\packages\&lt;/code&gt;に修正版(のリンク)をいれて、Atomをdev modeで起動する必要がある。&lt;/p&gt;

&lt;p&gt;この手順は、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&amp;lt;パッケージルート&amp;gt;に&lt;code&gt;cd&lt;/code&gt;して、&lt;code&gt;apm link --dev&lt;/code&gt;を実行する。これでそのフォルダへのリンクが&lt;code&gt;.atom\dev\packages\&lt;/code&gt;に作成される。&lt;/li&gt;
&lt;li&gt;Atomのメニューの &lt;strong&gt;View &amp;gt; Developer &amp;gt; Open In Dev Mode&lt;/strong&gt; からdev modeのAtomウィンドウを開く。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;因みに、Package Generatorは、作成したパッケージフォルダへのリンクを&lt;code&gt;%userprofile%\.atom\packages\&lt;/code&gt;に作成する。リンクの一覧は&lt;code&gt;apm links&lt;/code&gt;で参照でき、&lt;code&gt;apm unlink&lt;/code&gt;で削除できる。&lt;/p&gt;

&lt;p&gt;&amp;mdash;&amp;mdash; 以上昔話 &amp;mdash;&amp;mdash;&lt;/p&gt;

&lt;h2 id=&#34;関連エントリ&#34;&gt;関連エントリ&lt;/h2&gt;

&lt;p&gt;後日もう一つパッケージを作り、&lt;a href=&#34;https://www.kaitoy.xyz/2015/09/06/disturb-me/&#34;&gt;それに関する記事&lt;/a&gt;を書いた。
こちらはjapanese-word-selectionでやらなかったコマンドなどの実装をやっている。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>GitHub Pagesでブログ立ち上げ - GitHub PagesとJekyll</title>
          <link>https://www.kaitoy.xyz/2015/08/15/github-pages-and-jekyll/</link>
          <pubDate>Sat, 15 Aug 2015 10:48:49 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/08/15/github-pages-and-jekyll/</guid>
          <description>

&lt;p&gt;このブログを立ち上げたときの作業を、主に備忘録としていくつかのエントリに分けて書く。
このエントリでは主に&lt;a href=&#34;https://pages.github.com/&#34;&gt;&lt;strong&gt;GitHub Pages&lt;/strong&gt;&lt;/a&gt;と&lt;a href=&#34;http://jekyllrb.com/docs/home/&#34;&gt;&lt;strong&gt;Jekyll&lt;/strong&gt;&lt;/a&gt;について書く。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;今の構成&#34;&gt;今の構成&lt;/h2&gt;

&lt;p&gt;このブログは、&lt;a href=&#34;https://gohugo.io/&#34;&gt;&lt;strong&gt;Hugo&lt;/strong&gt;&lt;/a&gt;で作って、GitHub Pagesで公開している。&lt;/p&gt;

&lt;p&gt;Hugoについては別のエントリで書くとして、GitHub Pagesは、GitHubが提供しているウェブページのホスティングサービスで、GitHubに特定の名前のリポジトリ、または任意のリポジトリに特定の名前のブランチを作ってウェブサイトのソースを置くと、公開してくれるというサービス。&lt;a href=&#34;https://ja.wikipedia.org/wiki/Platform_as_a_Service&#34;&gt;PaaS&lt;/a&gt;にあたるのかな。
&lt;a href=&#34;https://pages.github.com/&#34;&gt;GitHub Pagesのサイト&lt;/a&gt;に利用方法が載っている。&lt;/p&gt;

&lt;p&gt;以下、このブログ立ち上げに向けてやった作業について書く。&lt;/p&gt;

&lt;h2 id=&#34;github-pages味見&#34;&gt;GitHub Pages味見&lt;/h2&gt;

&lt;p&gt;GitHub Pagesを利用するには、&lt;strong&gt;GitHubユーザ名.github.io&lt;/strong&gt; という名前のリポジトリを作るか、任意のリポジトリに&lt;strong&gt;gh-pages&lt;/strong&gt; という名前のブランチを作って、そこにサイトのソースを置けばいい。そのサイトには、前者の場合は&lt;code&gt;http://GitHubユーザ名.github.io&lt;/code&gt;で、後者の場合は&lt;code&gt;http://GitHubユーザ名.github.io/リポジトリ名&lt;/code&gt;でアクセスできる。
(2016/8/18追記: &lt;a href=&#34;https://www.kaitoy.xyz/2016/08/18/simpler-github-pages-publishing/&#34;&gt;今はgh-pagesブランチは不要。&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;とりあえず前者をやってみる。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;kaitoy.github.io&lt;/strong&gt; という名前の&lt;a href=&#34;https://github.com/kaitoy/kaitoy.github.io&#34;&gt;リポジトリ&lt;/a&gt;を作って、そのルートに「Hello World」とだけ書いた &lt;strong&gt;index.html&lt;/strong&gt; を置く。&lt;/li&gt;
&lt;li&gt;ブラウザで&lt;code&gt;http://kaitoy.github.io&lt;/code&gt;にアクセスすると、「Hello World」と表示された。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;これだけ。&lt;/p&gt;

&lt;h2 id=&#34;github-pagesとjekyll&#34;&gt;GitHub PagesとJekyll&lt;/h2&gt;

&lt;p&gt;GitHub Pagesには、普通にHTML/CSS/Javascriptのソースを置いてもいいけど、Jekyllを利用することもできる。&lt;/p&gt;

&lt;p&gt;Jekyllは、ブログ用の静的サイトジェネレータなるもので、&lt;a href=&#34;https://ja.wikipedia.org/wiki/Markdown&#34;&gt;&lt;strong&gt;Markdown&lt;/strong&gt;&lt;/a&gt;で書いた記事を元にブログサイトのソースを生成するツール。GitHub Pages用のリポジトリにJekyllのソースをアップロードすると、Jekyllでビルドされ、その結果が公開される。&lt;/p&gt;

&lt;p&gt;これはうれしい。  Jekyllのソースとビルド結果を別々に管理しなくてよくて楽だし、公開されるサイトが最新のソースに基づいていることが保証される。&lt;/p&gt;

&lt;p&gt;結論から言うと、以下のような理由で結局Jekyllは使わなかったんだけど、Jekyllとの格闘の記録を残しておく。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Windowsを正式サポートしていない。&lt;/li&gt;
&lt;li&gt;Rubyで書かれてるため、ビルドが遅い。ブログエントリが数百とかになると辛くなってくるらしい。&lt;/li&gt;
&lt;li&gt;Jekyllを使っても、かっこいいサイトを手軽に作ろうと思ったら、結局ビルド成果物もGitHubに上げないといけなくなる。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;jekyllセットアップ&#34;&gt;Jekyllセットアップ&lt;/h2&gt;

&lt;p&gt;GitHub PagesでJekyll使う場合は、GitHub Pagesと同じJekyll環境を手元に作ってプレビューできるようにしておくべきとのこと。なので、&lt;a href=&#34;https://help.github.com/articles/using-jekyll-with-pages/&#34;&gt;これ&lt;/a&gt;に従って自分のPC (Windows 7) にJekyllをセットアップする。&lt;/p&gt;

&lt;h4 id=&#34;１-rubyインストール&#34;&gt;１．Rubyインストール&lt;/h4&gt;

&lt;p&gt;Jekyllは &lt;strong&gt;Ruby&lt;/strong&gt; で書かれてるので、まずはRubyをインストールする。
Windowsなので&lt;a href=&#34;http://rubyinstaller.org/&#34;&gt;&lt;strong&gt;RubyInstaller&lt;/strong&gt;&lt;/a&gt; (ver. 2.2.2)をダウンロードしてインストール。
&lt;a href=&#34;http://bundler.io/&#34;&gt;&lt;strong&gt;Bundler&lt;/strong&gt;&lt;/a&gt; (RubyのパッケージであるGemの依存をアプリケーションごとに管理するツール) もあるといいらしいので、&lt;code&gt;gem install bundler&lt;/code&gt;を実行してインストール。&lt;/p&gt;

&lt;h4 id=&#34;2-jekyllインストール&#34;&gt;2.  Jekyllインストール&lt;/h4&gt;

&lt;p&gt;さっき作ったリポジトリ　&lt;strong&gt;kaitoy.github.io&lt;/strong&gt; (の手元のクローン)のルートに、Bundlerの定義ファイルを &lt;strong&gt;Gemfile&lt;/strong&gt; という名前で作り、以下の内容を書く。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;source &#39;https://rubygems.org&#39;
gem &#39;github-pages&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;依存するGemは &lt;strong&gt;jekyll&lt;/strong&gt; じゃなくて &lt;strong&gt;github-pages&lt;/strong&gt;。これはGitHub Pages環境のJekyllということだろう。&lt;/p&gt;

&lt;p&gt;で、&lt;strong&gt;kaitoy.github.io&lt;/strong&gt; のルートで&lt;code&gt;bundle install&lt;/code&gt;を実行する。ここでエラー発生。
エラーメッセージによると、native gemをビルドするために &lt;strong&gt;DevKit&lt;/strong&gt; なるものが要るとのこと。&lt;/p&gt;

&lt;p&gt;再びRubyInstallerのページに行ってDevKitをダウンロードして、&lt;a href=&#34;http://github.com/oneclick/rubyinstaller/wiki/Development-Kit&#34;&gt;wiki&lt;/a&gt;に従ってインストール。&lt;/p&gt;

&lt;p&gt;再度&lt;code&gt;bundle install&lt;/code&gt;したらJekyllのインストールに成功。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;github-pages: ver. 35&lt;/li&gt;
&lt;li&gt;jekyll: ver. 2.4.0&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;これで、ちょくちょく&lt;code&gt;bundle update&lt;/code&gt;を実行すれば、最新のGitHub Pages環境に追随できる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;bundle exec jekyll serve&lt;/code&gt;すると、カレントディレクトリのJekyllソースがビルドされ、Webサーバが起動し、&lt;code&gt;http://localhost:4000&lt;/code&gt;でそのビルド結果を見れるらしい。&lt;/p&gt;

&lt;h4 id=&#34;3-jekyll味見&#34;&gt;3.  Jekyll味見&lt;/h4&gt;

&lt;p&gt;試しに、適当な場所で&lt;code&gt;jekyll new hoge&lt;/code&gt;を実行し、新規サイトフォルダ &lt;strong&gt;hoge&lt;/strong&gt; を作り、その中で&lt;code&gt;jekyll build&lt;/code&gt;してみる。以下のエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/posix-spawn-0.3.11/lib/posix/spawn.rb:164: warning: cannot close fd before spawn
&#39;which&#39; は、内部コマンドまたは外部コマンド、
操作可能なプログラムまたはバッチ ファイルとして認識されていません。
[31m  Liquid Exception: No such file or directory - python c:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/pygments.rb-0.6.1/lib/pygments/mentos.py in jekyll/_posts/2015-05-29-welcome-to-jekyll.markdown[0m
                    done.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Jekyllのサイトを見直したらWindowsはサポートされていないとのこと。
けど、Windowsにセットアップする方法は検索したらたくさん出てきた。
Jekyllのサイトでも紹介されている&lt;a href=&#34;http://jekyll-windows.juthilo.com/&#34;&gt;&lt;strong&gt;Run Jekyll on Windows&lt;/strong&gt;&lt;/a&gt;というサイトの手順に従うとか、&lt;a href=&#34;https://github.com/madhur/PortableJekyll&#34;&gt;&lt;strong&gt;Portable Jekyll&lt;/strong&gt;&lt;/a&gt;という、WindowsでJekyllを動かすためのツールを集めたものを使うとか。&lt;/p&gt;

&lt;p&gt;後者は、Jekyllのインスタンスを含んでいて、将来にわたるJekyllのアップデートについていってくれるか怪しいので、前者を見てみる。&lt;/p&gt;

&lt;h4 id=&#34;4-run-jekyll-on-windowsを試す&#34;&gt;4. Run Jekyll on Windowsを試す&lt;/h4&gt;

&lt;p&gt;Run Jekyll on Windowsによると、Jekyllはデフォルトでsyntax highlighterの &lt;strong&gt;pygments.rb&lt;/strong&gt; なるものに依存していて、pygments.rbをWindowsで使うには &lt;strong&gt;Python&lt;/strong&gt; とそのモジュールである &lt;strong&gt;Pygments&lt;/strong&gt; などをインストールする必要があるのこと。&lt;/p&gt;

&lt;p&gt;とりあえずPythonを&lt;a href=&#34;https://www.python.org/downloads/windows/&#34;&gt;ここ&lt;/a&gt;からダウンロードしてインストール。バージョンは、3系はPygmentsがサポートしていないようなので2.7.10。
&lt;strong&gt;pip&lt;/strong&gt; なるPythonパッケージ管理ツールが要るとRun Jekyll on Windowsに書いてあるが、2.7.10にはデフォルトで入っていた。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;python -m pip install Pygments&lt;/code&gt;を実行してPygmentsをインストール。これはどうもpygments.rbがラップしているものらしい。&lt;/p&gt;

&lt;p&gt;また、Jekyllにはauto-regenerationなる、ファイル変更を検知して自動ビルドする機能があって、Windowsでこれを使うには &lt;strong&gt;wdm&lt;/strong&gt; というgemが必要らしい。
以下をGemfileに追加して、&lt;code&gt;bundle install&lt;/code&gt;する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gem &#39;wdm&#39;, &#39;~&amp;gt; 0.1.0&#39; if Gem.win_platform?
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;したら以下のエラー。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c:\Ruby22-x64\lib\ruby\gems\2.2.0\gems\wdm-0.1.0\ext\wdm/rb_monitor.c:508: undefined reference to `rb_thread_blocking_region&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;どうも、&lt;a href=&#34;https://github.com/Maher4Ever/wdm/issues/18&#34;&gt;ここ&lt;/a&gt;によると、エラーメッセージにある &lt;strong&gt;rb_thread_blocking_region&lt;/strong&gt; というメソッドは、Ruby 2.0で非推奨になり2.2で消されたものらしい。&lt;/p&gt;

&lt;p&gt;wdmはもう数年更新されておらず、修正の見込みはなさそう。(後日見たら開発再開されてて、この問題も修正されていた。)&lt;/p&gt;

&lt;p&gt;Rubyをダウングレードするの面倒なので、試しにそのまま&lt;code&gt;jekyll serve&lt;/code&gt;したら以下のメッセージが出たけど動いた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  Please add the following to your Gemfile to avoid polling for changes:
    gem &#39;wdm&#39;, &#39;&amp;gt;= 0.1.0&#39; if Gem.win_platform?
 Auto-regeneration: enabled for &#39;c:/Users/Kaito/mirrored_data/pleiades/workspace/kaitoy.github.io/hoge&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;auto-regenerationも動いている模様。実際ソースをいじったら自動で反映された。
よくわからないが、よしとする。&lt;/p&gt;

&lt;p&gt;実は、以下のエラー(上でも出てたやつ)はまだ出ている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/posix-spawn-0.3.11/lib/posix/spawn.rb:164: warning: cannot close fd before spawn
&#39;which&#39; は、内部コマンドまたは外部コマンド、
操作可能なプログラムまたはバッチ ファイルとして認識されていません。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このwarningについてはRun Jekyll on Windowsには載っていないが、pygments.rbを0.5.0にダウングレードすればいいとの情報が&lt;a href=&#34;https://github.com/jekyll/jekyll/issues/2052&#34;&gt;ここ&lt;/a&gt;とかにある。&lt;/p&gt;

&lt;h2 id=&#34;5-jekyllとの決別&#34;&gt;5. Jekyllとの決別&lt;/h2&gt;

&lt;p&gt;この辺りまでJekyllをセットアップした後、JekyllのWindowsとの相性の悪さに嫌気がさしつつ、Jekyllで簡単にかっこいいサイトを作るためのツールなどを調べているうちに、Jekyllを使うのをやめた。それについては&lt;a href=&#34;https://www.kaitoy.xyz/2015/08/25/tools-for-jekyll/&#34;&gt;別のエントリ&lt;/a&gt;で書く。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>スタンドアップミーティングはダメマネージャーが好む手法</title>
          <link>https://www.kaitoy.xyz/2015/08/11/daily-stand-up-meetings-are-a-good-tool-for-a-bad-manager/</link>
          <pubDate>Tue, 11 Aug 2015 22:35:09 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/08/11/daily-stand-up-meetings-are-a-good-tool-for-a-bad-manager/</guid>
          <description>

&lt;p&gt;このエントリでは、Yegor Bugayenkoによる記事、&lt;a href=&#34;http://www.yegor256.com/2015/01/08/morning-standup-meetings.html&#34;&gt;Daily Stand-Up Meetings Are a Good Tool for a Bad Manager&lt;/a&gt;を紹介する。
(Yegorから和訳と転載の許可は得た。)
以下はその全文の和訳だが、意訳超訳が混じっているので、もとのニュアンスを知りたければ元記事を読んでもいいし、読まなくてもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;スタンドアップミーティング (または単純にスタンドアップ)は、「チームマネージャに状況報告をするためのデイリーチームミーティング」であるとWikipediaに書かれている。
こうしたミーティングは、ソフトウェア開発チームの間でとても人気な手法ではあるが、単なる悪であり、よいマネージャは決してやらない。
以下、その理由を説明する。&lt;/p&gt;

&lt;p&gt;私は、スタンドアップのやり方が適切だったり不適切だったりする、と言いたいわけではない。それについて述べた記事は大量にある。
また、スタンドアップを上手く機能するように実施する方法についてアドバイスしようとしているわけでもない。
よいマネージャはデイリースタンドアップを決して実施すべきでないと言っているのだ。
スタンドアップは、単に「機能しない」だけでなく、非常に悪い、時に破壊的なものをマネジメントプロセスにもたらす。それがアジャイルかどうかにかかわらず。
一方、ダメなマネージャは常に、デイリースタンドアップを重要なマネジメント手法として使う。&lt;/p&gt;

&lt;p&gt;私の意図を説明するため、マネジメントをいくつかの異なった視点から見ながら、よいマネージャとダメなマネージャが仕事をどのように進めるかを比べてみよう。&lt;/p&gt;

&lt;h3 id=&#34;情報&#34;&gt;情報&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;ダメなマネージャは進捗を尋ねる。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;オフィスを歩き回り進捗を訪ねて回るのは、ひどいマネージャの崇高な習慣だ。
彼は、プロセスと情報伝達フローを適切に構築できるほど賢明ではなく、チームが何をしているかを知らない。
しかし、彼は進捗を知る必要がある。彼もまた上司からちょくちょく尋ねられるからだ。
必要な情報を収集する唯一の方法は、チームに「今何の作業をしているの?」と尋ねることだ。
朝のスタンドアップは、メンバの作業内容を知らないことに気付かれずに、このうっとうしい質問を正式に尋ねる最高の場だ。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;よいマネージャは必要なときに報告を受ける。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;プロジェクトマネージメントにはコミュニケーション管理が必要だ。
情報伝達フローが適切に構成されていれば、チームメンバはいつどのようにマネージャに報告すればいいかが分かる。
何か問題が起きたとき、そういう状況をどのように報告しなければいけないかを全員が知っている。即時、直接報告するのだ。
作業が完了したとき、必要に応じてプロジェクトマネージャにどのように知らせるかを全員が理解している。
完璧なプロジェクトマネージャは決してチームに質問しない。代わりに、チームが必要なときにマネージャに報告する。
そして、報告を怠るメンバが出たときには、その壊れたコミュニケーションチャネルを修復するのがよいプロジェクトマネージャだ。
ただし、情報収集のためにデイリーミーティングは決して実施しない。&lt;/p&gt;

&lt;p&gt;よいマネージャとして、何がゴールで何がプロジェクトマネージャ(またはスクラムマスタ)として重要かをチームに伝えるべきだ。
チームメンバは、マネージャがチームの進捗、リスク、障害、失敗について知るために何が重要であるかを知っているべきだし、チームメンバがマネージャの期待に沿えなければどんなトラブルに陥るかを理解しているべきだ。
プロジェクトやチームが取り組んでいる最も重要な課題についてをチームに伝えることは、よいマネージャとしてすべき仕事だ。
また、よいチームメンバとしては、重要な情報をつかんだら、すぐにマネージャに知らせることが重要だ。
これが完璧なマネージメントというものだ。&lt;/p&gt;

&lt;p&gt;もしそのようなチームワークを築いたなら、開発者が今日何をしてどんな問題にあったかを、明日の朝まで待ってから尋ねる必要はなくなる。
マネージャはこういった情報をもっと早く、まさに必要なタイミングで知るようになる。
オフィスの外にいるときでさえ、プロジェクトで起こっていることを知ることができるようになる。
実際には、オフィスは全く不要にさえなるが、これはまた別の機会に議論したい。&lt;/p&gt;

&lt;p&gt;デイリースタンドアップはプログラマ間で情報交換する最高の機会で、スクラムマスタに報告してフィードバックを受けるだけの場ではないと言う人がいるかもしれない。
もう一度、同じことを言うが、なぜ、その日の必要になった時点で情報交換をしないのか?
なぜ、10人のメンバを毎朝集めて、その内たった5人だけに関係することを議論する必要がある?
答えよう。ダメなマネージャは、チームメンバ間で情報交換する場を用意する他の方法を知らず、朝のスタンドアップを適切なコミュニケーションモデルの代わりとして使う。
こういったミーティングは、マネージャが熱心に働いていて、大げさな給料を受け取るに値するかのような印象を与える。
対照的に、よいマネージャは定期的な状況報告ミーティングをいっさい実施しない。
なぜなら、効果的なコミュニケーションツールの使い方を知っているからだ。
例えば、問題追跡ツール、メール、コードレビュー、意思決定ミーティング、ペアプログラミングなど。&lt;/p&gt;

&lt;h3 id=&#34;責任&#34;&gt;責任&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;ダメなマネージャはマイクロマネージメントをする。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;ダメなマネージャはプロジェクトマネージメントのことをほとんど知らないので、大きな不安を抱えている。
彼はチームのコントロールを失うことを恐れていて、チームを信頼せず、いつも十分な情報を得ていないと感じ、上司から状況を尋ねられたときに動揺する。
このため、彼はチームメンバを抗うつ薬として使う。チームメンバが彼の言う通りのことをしているとき、彼はより安心と安定を感じる。
デイリースタンドアップミーティングは、彼がメンバに何をしているかを尋ね、代わりに何をすべきかを指示するためのすばらしい機会だ。
このマネージャは、メンバに個人の目標と計画を報告するよう強制し、必要だと感じればそれらを修正する。
次のようなやりとりをを何回聞いたことがある?「私はテストXをやるつもりです。…いや、それは来週だ。今日はYをやってくれ。」
これはマイクロマネージメントだ。デイリースタンドアップはマイクロマネージャのための完璧なツールだ。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;よいマネージャは責任を委譲する。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;理想的なマネージメントには4つのステップが必要だ。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;複雑なタスクを小さいサブタスクに分解する。&lt;/li&gt;
&lt;li&gt;それらを部下に委譲する。&lt;/li&gt;
&lt;li&gt;報酬と、ペナルティと、ルールをはっきりと伝える。&lt;/li&gt;
&lt;li&gt;報酬はちゃんと支払われること、ペナルティは免れられないこと、ルールは厳格に守られることを確実にする。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;完璧なマネージャは日々何をするかをメンバに指示しないし、業務時間の使い方にも口を出さない。
彼は信頼し、コントロールする。
彼は、メンバに作業方法を指示して自尊心を削ぐようなことは決してしない。
すばらしいマネージャは次のようなことを言う。「今日はテストXをやるつもりだって? それは君の判断だ。最大限尊重するよ。ただ、Yが今週中に完了しなければ、君は約束どおりプロジェクトからはずされるということを忘れないでくれ。」
こういうマネージャにデイリースタンドアップが必要だろうか?
チームメンバに何をしているか聞く必要があるだろうか?
彼はメンバの計画によけいな干渉はしない。
代わりに、メンバを信頼し、成果をコントロールするだけだ。&lt;/p&gt;

&lt;p&gt;重ねて言うが、私は責任は委譲されるべきだと強く信じている。この委譲は3つの要素からなる。報酬、ペナルティ、ルールだ。
近代西洋文化の中では、これらを定めるのはむしろ難しいかもしれない。普通は長期の契約と月々の給料がある。
しかし、よいマネージャは方法を模索しないといけない。それぞれのタスクは委譲され、分離されないといけない。
これは、あるタスクに従事しているプログラマは、その成功または失敗に個人的な責任を持たなければいけないということだ。
また、そのタスクの結果が与える影響を知っていなければいけない。&lt;/p&gt;

&lt;p&gt;よいマネージャは、どんなチームメンバでも必ず責任逃れをしようとするということを理解している。
誰もがマネージャの両肩に&lt;a href=&#34;http://hbr.org/1999/11/management-time-whos-got-the-monkey/ar/1&#34;&gt;責任猿&lt;/a&gt;(訳注: 責任のメタファである猿)を返そうとする。
それは自然で不可避なことだ。デイリースタンドアップミーティングはこのたくらみを助長するだけだ。&lt;/p&gt;

&lt;p&gt;朝、君が私に進捗を聞くと、私はいくつか問題があって今週末までにタスクが完了できるか怪しいと言う。
それだけだ。私はもうそのタスクに責任がない。もし間に合わなくても私の失敗ではない。
私は失敗するかもしれないと伝えたよね?
今後、その責任は君がもつんだ。&lt;/p&gt;

&lt;p&gt;よいマネージャはこういう策略について知っていて、それを防ぐために報酬・ペナルティ・ルールを明確に規定する。
もし間に合わないかもしれないと言われたら、報酬を逃しペナルティを受けることを思い出させればいい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- 締め切りに間に合わないかもしれない…
- それは残念だ。君は$200の週末ボーナスを逃すことになる。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;プロジェクトマネージャやスクラムマスタがこんなことを言っているのを見たことがあるかい?
あまりないと思う。そう、よいマネージャは珍獣なんだ。
しかし、よいマネージャだけが報酬・ペナルティ・ルールを明確に厳格に定義する能力を持つ。&lt;/p&gt;

&lt;p&gt;この3点が定義されれば、毎朝状況報告ミーティングをする必要はなくなる。
全てがありのままに明確になる。全員がゴールと目標を把握する。
全員が失敗したときに何が起こるかを知っているし、成功したときに何を得られるかも知っている。
マネージャは毎朝それをメンバに確認する必要はない。マネージャはメンバの進捗を確認する必要もない。
マネージャは既に非常に明確に各メンバの目標を定めている。それについて毎朝話す必要があるだろうか?&lt;/p&gt;

&lt;p&gt;ダメなマネージャは目標を定める能力がないので、毎朝メンバをマイクロマネージメントしようとする。
実際、ダメなマネージャは一日中マイクロマネージメントしている。
明確なゴールやルールがないので、チームが間違ったことをしたり何もできなかったりするのではないかと恐れている。
しょっちゅう状況確認するのはそのせいだ。
実際のところ、彼はチームの首根っこをつかんでいるのだ。&lt;/p&gt;

&lt;h3 id=&#34;モチベーション&#34;&gt;モチベーション&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;ダメなマネージャは皆の前で恥をさらさせてモチベーションを下げさせる。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;ダメなマネージャはチームメンバにやる気を出させる適切な仕組みの作り方を知らないため、恥をさらすことへの生理的な恐怖を利用する。
誰も「忘れました」と皆の前で言いたくないのが当然だ。
デイリースタンドアップミーティングは全員を一列に並べて「昨日何をした?」と尋ねる場だ。
この恐怖の時間はチームにやる気を出させるだろ?
私はそうは思わないが。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;よいマネージャは目標でモチベーションを上げさせる。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;理想的なマネージメントは、目標を定めて、チームメンバがスキル、リソース、知識、情熱を駆使してそれを達成できるようにする。
適切に定められた目標は常に3つの要素からなる。報酬、ペナルティ、ルールだ。
すばらしいマネージャは組織の目標を個人の目標に落とし込む方法を知っている。
「もし今週中にこの機能を納品できたら、会社はさらなる利益を出せる。サリー、君個人としては$500を得る。もし君がしくじったら、君は他の、あまり面白くないプロジェクトに異動することになる。」
これが完璧に定められた目標だ。毎朝、皆の前で、機能の実装を忘れてないかとか、熱心に作業しているかとか、サリーに尋ねる必要があるだろうか?
この尋問は彼女の手助けになるだろうか?
なるはずがない !
彼女は既に何のために作業しているか知っていて、動機付けは十分だ。
彼女が期日に作業を終えたら、ミーティングを開いて、皆の前で$500のチェックをあげよう。
これがよいマネージャによるミーティングの使い方だ。&lt;/p&gt;

&lt;p&gt;他にもある。
皆の前での日々の進捗報告は、チーム内最高のメンバを堕落させ、最悪にしてしまう。
主な理由は、彼らは突出した成果を出すことで他の人の気を損ねたくないからだ。
グループ内で他の皆と同じように振舞おうとするのは、人間の性だ。
皆が「まだ結果は出ていません」と報告しているときに、有能なプログラマが「全てのタスクを終えたので、他の仕事をください」と言うことを期待するのは奇妙だ。
いや、一回くらいはこういうことを言うかもしれないが、しばらくするとこの有能なプログラマは熱心に作業することをやめるか、チームを抜ける。
彼は、彼の成果が際立っていることを知り、それがグループから評価されていないことを知る。マネージャが何を言おうとも。&lt;/p&gt;

&lt;p&gt;よいマネージャは、プログラマそれぞれに固有の作業速度、質、給料があることを理解する。
よいマネージャは、人によって与えるタスクを変え、異なる結果が返ってくることを期待する。
明らかに、朝全員を並ばせて、皆が同じような報告をすることを期待するのは大きな間違いだ。
この間違いは、突出した成果を出して格別な評価と報酬を得たがっている有能なメンバに破壊的な効果をもたらす。&lt;/p&gt;

&lt;p&gt;ダメなマネージャは異なる人々を異なる方法でマネージメントできない。単にやり方を知らないからだ。
そのため、デイリースタンドアップという、全員が同じような、比較しやすい成果を報告する場が必要になる。
また、皆と違った報告をする人を責めたり励ましたりもしやすい。
言い換えると、ダメなマネージャはデイリースタンドアップを平等の手段として使う。この場合の平等は、チーム全体のモチベーションを破滅させるだけだ。&lt;/p&gt;

&lt;p&gt;デイリースタンドアップや、他のあらゆる状況報告ミーティングは、怠惰で愚かなマネージャを隠して守るのにはすばらしい手段だ。
マネージャの無能っぷりをチームメンバから隠すことができる。
適正のなさを隠し、問題や挑戦やリスクへの恐れを隠す。
よいマネージャになりたいなら、デイリースタンドアップで自分自身を困らせないことだ。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上がYegorの記事。&lt;/p&gt;

&lt;p&gt;Yegorは、自身が経営する&lt;a href=&#34;http://www.teamed.io/&#34;&gt;Teamed.io&lt;/a&gt;という会社でのソフトウェア開発プロジェクトを、自身が考案した&lt;a href=&#34;http://www.xdsd.org/&#34;&gt;XDSD&lt;/a&gt;という手法を使ってマネジメントしている。
上の記事は、そのXDSDを念頭に、
巷で流行っている&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%B9%E3%82%AF%E3%83%A9%E3%83%A0_%28%E3%82%BD%E3%83%95%E3%83%88%E3%82%A6%E3%82%A7%E3%82%A2%E9%96%8B%E7%99%BA%29&#34;&gt;スクラム&lt;/a&gt;などで行われるデイリースタンドアップにはっきりと異を唱えるものだ。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.agilemanifesto.org/iso/ja/&#34;&gt;アジャイルソフトウェア開発宣言&lt;/a&gt;が発表されてから14年もたち、私の会社のような古い体質の組織にもアジャイルな手法や理念はさすがに浸透していて、私の周りでもデイリーミーティングをするチームが目立つ。私としては、管理される側にとっても、管理する側にとっても、いい情報交換の場だとは思うが、だらだら長くなりがちで、じわじわ煩わしくなるのが難。&lt;/p&gt;

&lt;p&gt;Yegorは、定例ミーティングなんかやめて、情報交換は必要なときに必要な人どうしでやれよと言っているわけだけど、悪いニュースは隠したくなるし、いいニュースもきっかけがないと報告するのがおっくうになるのは自然の摂理ではないか。
この摂理を乗り越え、適時情報共有するための、「適切な情報伝達フロー」の作り方は、また別の記事に書かれているんだろうか。&lt;/p&gt;

&lt;p&gt;責任の委譲についてのくだりは、以前読んだドラッカーを思い出した。もしドラだけど。
ドラッカーは「権限 (authority) を委譲しろ」と言っていたけど、Yegorは「責任 (responsibility) を委譲すべき」と言っている。
また、ドラッカーは、「権限の委譲を責任の放棄と混同してはいけない。権限を委譲したらむしろマネージャの責任は大きくなる」と言っていた。
つまり、Yegorはここでさらっとドラッカーにも異を唱えていることになる。
権威によるバイアスもあるのかもしれないが、私にはやはりドラッカーの話の方がしっくりくる。責任は猿みたいに身軽に移動できるものとは思えない。
失敗した部下のボーナスを減らして別のプロジェクトに飛ばしたところで、開発の遅れを取り戻せるわけではないし、納品が遅れたら怒られるのは結局上の人たちだ。&lt;/p&gt;

&lt;p&gt;ところで、XDSDもそうっぽいけど、アジャイルな開発手法は基本的に、意欲に満ちた優秀なメンバで構成されたチームを前提に組み立てられたものだ。
私の会社を含む、日本の大企業がやっているような、経験(ほぼ)不問、サークルやバイトでの体験談を聞いて新卒一括人柄採用なんてボランティアみたいな選考方法を刷新しない限り、上手く回るようになることはない。
こんないい加減なやり方で集められた烏合の衆で、何千万も何億も稼ぐソフトウェアを作ろうってんだから、上の人たちはさぞかし大変なんだろう。意欲に欠けた部下の尻を叩くためにデイリースタンドアップをやらざるを得ないマネージャを批判するのは、ちょっと気の毒に思える。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Step by Step to Add a Protocol Support to Pcap4J (Part 1)</title>
          <link>https://www.kaitoy.xyz/2015/08/09/step-by-step-to-add-a-protocol-support-to-pcap4j-1/</link>
          <pubDate>Sun, 09 Aug 2015 21:53:29 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/08/09/step-by-step-to-add-a-protocol-support-to-pcap4j-1/</guid>
          <description>

&lt;p&gt;I will show how to add a protocol support to &lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;Pcap4J&lt;/a&gt; in detail giving the example of DHCP (v4) via some posts.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h3 id=&#34;named-number-class&#34;&gt;Named Number Class&lt;/h3&gt;

&lt;p&gt;First of all, we need to know the packet format. It&amp;rsquo;s explained in &lt;a href=&#34;http://www.ietf.org/rfc/rfc2131.txt&#34;&gt;RFC 2131&lt;/a&gt; as below:&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code&gt;0                   1                   2                   3
0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|     op (1)    |   htype (1)   |   hlen (1)    |   hops (1)    |
+---------------+---------------+---------------+---------------+
|                            xid (4)                            |
+-------------------------------+-------------------------------+
|           secs (2)            |           flags (2)           |
+-------------------------------+-------------------------------+
|                          ciaddr  (4)                          |
+---------------------------------------------------------------+
|                          yiaddr  (4)                          |
+---------------------------------------------------------------+
|                          siaddr  (4)                          |
+---------------------------------------------------------------+
|                          giaddr  (4)                          |
+---------------------------------------------------------------+
|                                                               |
|                          chaddr  (16)                         |
|                                                               |
|                                                               |
+---------------------------------------------------------------+
|                                                               |
|                          sname   (64)                         |
+---------------------------------------------------------------+
|                                                               |
|                          file    (128)                        |
+---------------------------------------------------------------+
|                                                               |
|                          options (variable)                   |
+---------------------------------------------------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;FIELD&lt;/th&gt;
&lt;th&gt;OCTETS&lt;/th&gt;
&lt;th&gt;DESCRIPTION&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;op&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Message op code / message type.&lt;br&gt;1 = BOOTREQUEST, 2 = BOOTREPLY&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;htype&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Hardware address type, see ARP section in &amp;ldquo;Assigned&lt;br&gt;Numbers&amp;rdquo; RFC; e.g., &amp;lsquo;1&amp;rsquo; = 10mb ethernet.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;hlen&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Hardware address length (e.g.  &amp;lsquo;6&amp;rsquo; for 10mb ethernet).&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;hops&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Client sets to zero, optionally used by relay agents when booting via a relay agent.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;xid&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;Transaction ID, a random number chosen by the client, used by the client and server to associate messages and responses between a client and a server.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;secs&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;Filled in by client, seconds elapsed since client began address acquisition or renewal process.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;flags&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;Flags (see figure 2).&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;ciaddr&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;Client IP address; only filled in if client is in BOUND, RENEW or REBINDING state and can respond to ARP requests.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;yiaddr&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&amp;lsquo;your&amp;rsquo; (client) IP address.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;siaddr&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;IP address of next server to use in bootstrap; returned in DHCPOFFER, DHCPACK by server.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;giaddr&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;Relay agent IP address, used in booting via a relay agent.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;chaddr&lt;/td&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;Client hardware address.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;sname&lt;/td&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;td&gt;Optional server host name, null terminated string.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;file&lt;/td&gt;
&lt;td&gt;128&lt;/td&gt;
&lt;td&gt;Boot file name, null terminated string; &amp;ldquo;generic&amp;rdquo; name or null in DHCPDISCOVER, fully qualified directory-path name in DHCPOFFER.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;options&lt;/td&gt;
&lt;td&gt;var&lt;/td&gt;
&lt;td&gt;Optional parameters field.  See the options documents for a list of defined options.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/blockquote&gt;

&lt;p&gt;It looks DHCP has only one packet format, and the packet doesn&amp;rsquo;t have a payload.
So, we will need to write only one packet class, one header class, and one builder class for DHCP. Easy!&lt;/p&gt;

&lt;p&gt;The header class will have java fields which represent the packet fields listed above (e.g. op, htype, etc.).&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start with writing named number classes, which we will use for types of some of the java fields of the header class.
For example, &lt;code&gt;op&lt;/code&gt; field, which holds a message op code, &lt;code&gt;1&lt;/code&gt; or &lt;code&gt;2&lt;/code&gt; in an octet.
Although the value &lt;code&gt;op&lt;/code&gt; field carries can be stored in a primitive &lt;code&gt;byte&lt;/code&gt; field in the header class,
it&amp;rsquo;s recommended to create a named number class to store the value with its name (meaning) for more readability and usability.
&lt;code&gt;new DhcpV4Packet.Builder().operationCode(DhcpV4OperationCode.BOOTREQUEST)&lt;/code&gt; looks better than &lt;code&gt;new DhcpV4Packet.Builder().operationCode((byte)1)&lt;/code&gt;, doesn&amp;rsquo;t it?&lt;/p&gt;

&lt;p&gt;Named number classes are in &lt;a href=&#34;https://github.com/kaitoy/pcap4j/tree/master/pcap4j-core/src/main/java/org/pcap4j/packet/namednumber&#34;&gt;&lt;code&gt;org.pcap4j.packet.namednumber package&lt;/code&gt;&lt;/a&gt; in pcap4j-core project.
To write a named number class easily, extend &lt;a href=&#34;https://github.com/kaitoy/pcap4j/blob/master/pcap4j-core/src/main/java/org/pcap4j/packet/namednumber/NamedNumber.java&#34;&gt;&lt;code&gt;NamedNumber&lt;/code&gt;&lt;/a&gt;.
The minimum implementation of a number class looks like below:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package org.pcap4j.packet.namednumber;

public final class DhcpV4OperationCode extends NamedNumber&amp;lt;Byte, DhcpV4OperationCode&amp;gt; {

  private static final long serialVersionUID = 3155818580398801532L;

  public DhcpV4OperationCode(Byte value, String name) {
    super(value, name);
  }

  @Override
  public int compareTo(DhcpV4OperationCode o) {
    return value().compareTo(o.value());
  }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Only one method we must implement is &lt;code&gt;compareTo&lt;/code&gt;. The code in the method is always the same: &lt;code&gt;return value().compareTo(o.value());&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;And, because &lt;code&gt;NamedNumber&lt;/code&gt; doesn&amp;rsquo;t have the default constructor, we need to write a constructor with 2 arguments, &lt;code&gt;Byte value&lt;/code&gt; and &lt;code&gt;String name&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Sometimes we may want to override &lt;code&gt;public String valueAsString()&lt;/code&gt;. For example, in the case where the String representation of the value should be like &lt;code&gt;0x0a&lt;/code&gt; instead of &lt;code&gt;10&lt;/code&gt;. &lt;code&gt;DhcpV4OperationCode&lt;/code&gt; isn&amp;rsquo;t the case, though.&lt;/p&gt;

&lt;p&gt;Then, we&amp;rsquo;d better to add pre-defined objects so that:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;we will not need to repeatedly instantiate them for the same value, and&lt;/li&gt;
&lt;li&gt;we will not need to refer to the RFC when you craft DHCP packets.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;  public static final DhcpV4OperationCode BOOTREQUEST
    = new DhcpV4OperationCode((byte)1, &amp;quot;BOOTREQUEST&amp;quot;);

  public static final DhcpV4OperationCode BOOTREPLY
    = new DhcpV4OperationCode((byte)2, &amp;quot;BOOTREPLY&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;From a pre-defined object, we can get its value by &lt;code&gt;DhcpV4OperationCode.BOOTREQUEST.value()&lt;/code&gt;.
But, how do we get a pre-defined object from a value? We need to do it when we parse a real packet (a byte array) captured and build a DHCP packet object.&lt;/p&gt;

&lt;p&gt;So, let&amp;rsquo;s enhance the code as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;  private static final Map&amp;lt;Byte, DhcpV4OperationCode&amp;gt; registry
    = new HashMap&amp;lt;Byte, DhcpV4OperationCode&amp;gt;();

  static {
    registry.put(BOOTREQUEST.value(), BOOTREQUEST);
    registry.put(BOOTREPLY.value(), BOOTREPLY);
  }

  public static DhcpV4OperationCode getInstance(Byte value) {
    if (registry.containsKey(value)) {
      return registry.get(value);
    }
    else {
      return new DhcpV4OperationCode(value, &amp;quot;unknown&amp;quot;);
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The new field &lt;code&gt;registry&lt;/code&gt; holds the mapping between values and pre-defined objects, and the &lt;code&gt;getInstance&lt;/code&gt; method is the API to get a pre-defined objects (or new one if not registered) by a value by searching in the &lt;code&gt;registry&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We may want to add one more API which is to add an object instantiated outside of this class to the &lt;code&gt;registy&lt;/code&gt; like below:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;  public static DhcpV4OperationCode register(DhcpV4OperationCode version) {
    return registry.put(version.value(), version);
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, the entire code looks like below:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package org.pcap4j.packet.namednumber;

import java.util.HashMap;
import java.util.Map;

public final class DhcpV4OperationCode extends NamedNumber&amp;lt;Byte, DhcpV4OperationCode&amp;gt; {

  private static final long serialVersionUID = 3155818580398801532L;

  public static final DhcpV4OperationCode BOOTREQUEST
   = new DhcpV4OperationCode((byte)1, &amp;quot;BOOTREQUEST&amp;quot;);

  public static final DhcpV4OperationCode BOOTREPLY
   = new DhcpV4OperationCode((byte)2, &amp;quot;BOOTREPLY&amp;quot;);

  private static final Map&amp;lt;Byte, DhcpV4OperationCode&amp;gt; registry
    = new HashMap&amp;lt;Byte, DhcpV4OperationCode&amp;gt;();

  static {
    registry.put(BOOTREQUEST.value(), BOOTREQUEST);
    registry.put(BOOTREPLY.value(), BOOTREPLY);
  }

  public static DhcpV4OperationCode getInstance(Byte value) {
    if (registry.containsKey(value)) {
      return registry.get(value);
    }
    else {
      return new DhcpV4OperationCode(value, &amp;quot;unknown&amp;quot;);
    }
  }

  public static DhcpV4OperationCode register(DhcpV4OperationCode version) {
    return registry.put(version.value(), version);
  }

  public DhcpV4OperationCode(Byte value, String name) {
    super(value, name);
  }

  @Override
  public int compareTo(DhcpV4OperationCode o) {
    return value().compareTo(o.value());
  }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Likewise, &lt;code&gt;htype&lt;/code&gt; should be represented by a named number class.
Fortunately, we can use the existing class &lt;a href=&#34;https://github.com/kaitoy/pcap4j/blob/master/pcap4j-core/src/main/java/org/pcap4j/packet/namednumber/ArpHardwareType.java&#34;&gt;ArpHardwareType&lt;/a&gt; for it.&lt;/p&gt;

&lt;p&gt;In the &lt;a href=&#34;https://www.kaitoy.xyz/2015/10/12/step-by-step-to-add-a-protocol-support-to-pcap4j-2/&#34;&gt;next part&lt;/a&gt;, we will write a packet piece class for the &lt;code&gt;flags&lt;/code&gt; field.&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Another way to capture LAN packets with pcap4j container</title>
          <link>https://www.kaitoy.xyz/2015/07/27/another-way-to-capture-lan-packets-with-pcap4j-container/</link>
          <pubDate>Mon, 27 Jul 2015 23:41:49 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/07/27/another-way-to-capture-lan-packets-with-pcap4j-container/</guid>
          <description>

&lt;p&gt;2 days ago, I posted an article &lt;a href=&#34;https://www.kaitoy.xyz/2015/07/25/how-to-capture-packets-on-a-local-network-with-pcap4j-container/&#34;&gt;How to capture packets on a local network with Pcap4J container&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Today, I was reading &lt;a href=&#34;https://docs.docker.com/reference/run/#network-settings&#34;&gt;Docker Docs&lt;/a&gt; and found another way to do it.
I&amp;rsquo;m writing about it here.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h3 id=&#34;net-option-for-docker-run&#34;&gt;&amp;ndash;net option for docker run&lt;/h3&gt;

&lt;p&gt;When we start a docker container we use &lt;code&gt;docker run&lt;/code&gt; command. It accepts some options.
&lt;code&gt;--net&lt;/code&gt; is one of them, which is to set a network mode for a container.
Network modes &lt;code&gt;--net&lt;/code&gt; takes are &lt;code&gt;bridge&lt;/code&gt;, &lt;code&gt;none&lt;/code&gt;, &lt;code&gt;container:&amp;lt;name|id&amp;gt;&lt;/code&gt;, and &lt;code&gt;host&lt;/code&gt;.
The &lt;code&gt;bridge&lt;/code&gt; is the default mode where containers connect to the virtual Ethernet bridge &lt;code&gt;docker0&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;What I use in this article is &lt;code&gt;host&lt;/code&gt; mode. If it&amp;rsquo;s specified containers use the host network stack,
which means Pcap4J on a container with the &lt;code&gt;host&lt;/code&gt; mode can see network interfaces on its host and sniff network traffic via them directly.&lt;/p&gt;

&lt;p&gt;This sounds easy. And more, according to the Docker Docs, the &lt;code&gt;host&lt;/code&gt; mode gives significantly better networking performance than the &lt;code&gt;bridge&lt;/code&gt; mode. But instead, &lt;code&gt;host&lt;/code&gt; is insecure. (See &lt;a href=&#34;https://docs.docker.com/reference/run/#mode-host&#34;&gt;Docker Docs - Mode: host&lt;/a&gt; for the details.)&lt;/p&gt;

&lt;h3 id=&#34;what-i-did&#34;&gt;What I did&lt;/h3&gt;

&lt;p&gt;In the same environment with &lt;a href=&#34;https://www.kaitoy.xyz/2015/07/25/how-to-capture-packets-on-a-local-network-with-pcap4j-container/#what-i-did:a3622224f79a64f15ba6f2b66e1010d9&#34;&gt;2 days ago&lt;/a&gt;, I did the followings:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Start a Pcap4J container with the network mode set to host&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;  [root@localhost ~]# docker run --name pcap4j-hostnet --net=host kaitoy/pcap4j:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;rsquo;s it.&lt;/p&gt;

&lt;p&gt;The above command create a container named &lt;code&gt;pcap4j-hostnet&lt;/code&gt; from the image &lt;code&gt;kaitoy/pcap4j:latest&lt;/code&gt; and execute &lt;code&gt;/bin/sh /usr/local/src/pcap4j/bin/capture.sh eth0 false&lt;/code&gt; in the container.
  The &lt;code&gt;capture.sh&lt;/code&gt; starts packet capturing on &lt;code&gt;eth0&lt;/code&gt; using Pcap4J.
  This &lt;code&gt;eth0&lt;/code&gt; is the interface of the docker host mashine because the network mode is set to &lt;code&gt;host&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;What a easy way.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
      
    
      
        <item>
          <title>なぜNullはダメか</title>
          <link>https://www.kaitoy.xyz/2015/07/26/why-null-is-bad/</link>
          <pubDate>Sun, 26 Jul 2015 19:07:20 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/07/26/why-null-is-bad/</guid>
          <description>

&lt;p&gt;このエントリでは、Yegor Bugayenkoによる記事、&lt;a href=&#34;http://www.yegor256.com/2014/05/13/why-null-is-bad.html&#34;&gt;Why NULL is Bad?&lt;/a&gt;を紹介する。
(Yegorから和訳と転載の許可は得た。)
以下はその全文の和訳だが、意訳超訳が混じっているので、もとのニュアンスを知りたければ元記事を読んでもいいし、読まなくてもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Javaで&lt;code&gt;NULL&lt;/code&gt;を使う単純な例を以下に示す。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public Employee getByName(String name) {
  int id = database.find(name);
  if (id == 0) {
    return null;
  }
  return new Employee(id);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このメソッドの何が間違っているのか? オブジェクトの代わりに&lt;code&gt;NULL&lt;/code&gt;を返す可能性がある、というのが間違っているところだ。
&lt;code&gt;NULL&lt;/code&gt;はオブジェクト指向パラダイムにおけるひどい慣習で、全力で避けるべきものだ。
これについては多くの意見が既に発表されている。
たとえば、Tony Hoareによるプレゼン&lt;a href=&#34;http://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare&#34;&gt;Null References, The Billion Dollar Mistake&lt;/a&gt;や、David Westの著書&lt;a href=&#34;http://www.amazon.com/gp/product/0735619654/ref=as_li_tl?ie=UTF8&amp;amp;camp=1789&amp;amp;creative=9325&amp;amp;creativeASIN=0735619654&amp;amp;linkCode=as2&amp;amp;tag=yegor256com-20&amp;amp;linkId=NQQHJZPHOKM6BTCT&#34;&gt;Object Thinking&lt;/a&gt;の全体に渡って述べられている。&lt;/p&gt;

&lt;p&gt;ここで、その論拠のすべてをまとめ、&lt;code&gt;NULL&lt;/code&gt;の使用を回避して適切なオブジェクト指向構造に置き換える方法の例を紹介したいと思う。&lt;/p&gt;

&lt;p&gt;基本的に、&lt;code&gt;NULL&lt;/code&gt;の代わりになり得るものはふたつある。&lt;/p&gt;

&lt;p&gt;ひとつは&lt;a href=&#34;https://en.wikipedia.org/wiki/Null_Object_pattern&#34;&gt;Nullオブジェクト&lt;/a&gt;デザインパターンだ。(それをひとつの不変オブジェクトにするのが最善。)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public Employee getByName(String name) {
  int id = database.find(name);
  if (id == 0) {
    return Employee.NOBODY;
  }
  return Employee(id);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;もうひとつは、オブジェクトを返せないときに例外を投げて&lt;a href=&#34;http://martinfowler.com/ieeeSoftware/failFast.pdf&#34;&gt;フェイルファスト&lt;/a&gt;することだ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public Employee getByName(String name) {
  int id = database.find(name);
  if (id == 0) {
    throw new EmployeeNotFoundException(name);
  }
  return Employee(id);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;さて、&lt;code&gt;NULL&lt;/code&gt;に反対する論拠を見てみよう。&lt;/p&gt;

&lt;p&gt;因みに、上記Tony HoareのプレゼンやDavid Westの著書に加えて、私はこの記事を書く前に以下の本や記事を読んだ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Robert Martinの&lt;a href=&#34;http://www.amazon.com/dp/0132350882/&#34;&gt;Clean Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Steve McConnellの&lt;a href=&#34;http://www.amazon.com/dp/0735619670/&#34;&gt;Code Complete&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;John Sonmezの&lt;a href=&#34;http://elegantcode.com/2010/05/01/say-no-to-null/&#34;&gt;Say &amp;ldquo;No&amp;rdquo; to &amp;ldquo;Null&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;StackOverflowの&lt;a href=&#34;http://stackoverflow.com/questions/1274792/is-returning-null-bad-design&#34;&gt;Is returning null bad design?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;アドホック-場当たりな-エラー処理&#34;&gt;アドホック(場当たりな)エラー処理&lt;/h3&gt;

&lt;p&gt;インプットとしてオブジェクトを受け取った場合は常に、それが&lt;code&gt;NULL&lt;/code&gt;でないか、また有効なオブジェクト参照かどうかを確認しないといけない。
その確認を忘れると、&lt;code&gt;NullPointerException&lt;/code&gt; (NPE)が実行時に処理を止めてしまう恐れがある。
このため、ロジックが複数の確認処理やif/then/else分岐に汚染されてしまう。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// this is a terrible design, don&#39;t reuse
Employee employee = dept.getByName(&amp;quot;Jeffrey&amp;quot;);
if (employee == null) {
  System.out.println(&amp;quot;can&#39;t find an employee&amp;quot;);
  System.exit(-1);
} else {
  employee.transferTo(dept2);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これは、&lt;a href=&#34;https://ja.wikipedia.org/wiki/C%E8%A8%80%E8%AA%9E&#34;&gt;C&lt;/a&gt;などの命令文を並べる手続き型言語において、例外的な状況に対応する手法だ。
OOPは、主にこういったアドホックエラー処理のブロックを排除する目的で、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E4%BE%8B%E5%A4%96%E5%87%A6%E7%90%86&#34;&gt;例外処理&lt;/a&gt;を導入した。
OOPでは、例外処理をアプリケーションレベルのエラーハンドラにまかせることで、コードをかなりきれいで短いものにできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;dept.getByName(&amp;quot;Jeffrey&amp;quot;).transferTo(dept2);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;NULL&lt;/code&gt;参照は手続き型言語から受け継がれたものだと認識し、Nullオブジェクトか例外を変わりに使うべきだ。&lt;/p&gt;

&lt;h3 id=&#34;あいまいな意図&#34;&gt;あいまいな意図&lt;/h3&gt;

&lt;p&gt;上記メソッドの目的を明確に伝えるためには、&lt;code&gt;getByName()&lt;/code&gt;は&lt;code&gt;getByNameOrNullIfNotFound()&lt;/code&gt;という名前でなければいけない。
これと同様の名前を、オブジェクトか&lt;code&gt;NULL&lt;/code&gt;を返す全ての関数が持たなければいけない。
さもなくば、だれかがあいまいなコードを読むはめになる。だから、コードの意図を明確にするために、関数に長い名前をつけるべきだ。&lt;/p&gt;

&lt;p&gt;このあいまいさを排除するために、関数は、実オブジェクトを返すか、Nullオブジェクトを返すか、例外を投げる、しかしてはいけない。&lt;/p&gt;

&lt;p&gt;性能を考慮すると&lt;code&gt;NULL&lt;/code&gt;を返さざるを得ない場合もあるだろうと主張する人がいるかもしれない。
たとえば、Javaの&lt;code&gt;&lt;a href=&#34;http://docs.oracle.com/javase/jp/7/api/java/util/Map.html&#34;&gt;Map&lt;/a&gt;&lt;/code&gt;インターフェースの&lt;code&gt;get()&lt;/code&gt;メソッドは、指定された要素がないときに&lt;code&gt;NULL&lt;/code&gt;を返す。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Employee employee = employees.get(&amp;quot;Jeffrey&amp;quot;);
if (employee == null) {
  throw new EmployeeNotFoundException();
}
return employee;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このコードでは、&lt;code&gt;Map&lt;/code&gt;が&lt;code&gt;NULL&lt;/code&gt;を使っているおかげで、mapを一回しか検索しない。
もし、&lt;code&gt;Map&lt;/code&gt;の&lt;code&gt;get()&lt;/code&gt;を、要素が見つからないときに例外を投げるように修正したら、以下のようなコードになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;if (!employees.containsKey(&amp;quot;Jeffrey&amp;quot;)) { // first search
  throw new EmployeeNotFoundException();
}
return employees.get(&amp;quot;Jeffrey&amp;quot;); // second search
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;明らかに、この方法は最初のものより2倍遅い。さて、どうする?&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Map&lt;/code&gt;インターフェースは、(作者を攻めるわけではないが、)設計に問題がある。
その&lt;code&gt;get()&lt;/code&gt;メソッドは&lt;code&gt;Iterator&lt;/code&gt;を返すべきで、その場合以下のようなコードになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Iterator found = Map.search(&amp;quot;Jeffrey&amp;quot;);
if (!found.hasNext()) {
  throw new EmployeeNotFoundException();
}
return found.next();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因みに、C++の標準ライブラリの&lt;a href=&#34;http://www.cppll.jp/cppreference/cppmap_details.html&#34;&gt;map::find()&lt;/a&gt;はまさにこのように設計されている。&lt;/p&gt;

&lt;h3 id=&#34;コンピュータ思考-vs-オブジェクト思考&#34;&gt;コンピュータ思考 vs. オブジェクト思考&lt;/h3&gt;

&lt;p&gt;Javaのオブジェクトはデータ構造を指すポインタで、&lt;code&gt;NULL&lt;/code&gt;は何も指さないポインタ(Intel x86プロセッサでは0x00000000)であることを知っている人にとっては、&lt;code&gt;if (employee == null)&lt;/code&gt;という文は理解できる。&lt;/p&gt;

&lt;p&gt;しかし、もし君がオブジェクトになって考えたとすると、この文はかなり意味のないものになる。オブジェクト視点で上記コードは以下のように見える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- もしもし、ソフトウェア部ですか?
- はい。
- Jeffreyと話したいのですが。
- 少々お待ちください。。。
- もしもし。
- あなたはNULLですか?
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;会話の最後の質問が変だろ?&lt;/p&gt;

&lt;p&gt;代わりに、もしJeffreyへの取り次ぎをお願いした後で電話が切れたら、自分に問題(例外)が発生した、ということにする。
この時点で、もう一度電話してみるか、Jeffreyにつながらないので仕事が進みませんと上司に報告する。&lt;/p&gt;

&lt;p&gt;あるいは、ソフトウェア部の人が、Jeffreyではないがだいたいの質問に答えられる人に取り次いでくれるかもしれないし、
Jeffreyにしかわからない用事だから無理、と拒否してくるかもしれない(Nullオブジェクト)。&lt;/p&gt;

&lt;h3 id=&#34;遅いエラー&#34;&gt;遅いエラー&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://martinfowler.com/ieeeSoftware/failFast.pdf&#34;&gt;フェイルファスト&lt;/a&gt;な&lt;code&gt;getByName()&lt;/code&gt;に対して、Nullオブジェクトを使った方はゆっくり死のうとしている。途中で他のものを殺しながら。
問題が発生したので例外処理をすぐに始めるべきだと周りに知らせる代わりに、クライアントからエラーを隠している。&lt;/p&gt;

&lt;p&gt;この議論は、前述した「アドホックエラー処理」に近い。&lt;/p&gt;

&lt;p&gt;コードはできるだけもろい方がいい。必要なときに壊れるように。&lt;/p&gt;

&lt;p&gt;メソッドを、それが扱うデータに対してできるだけ厳しくさせ、与えられたデータに不備があったりメソッドの使用方法に反していたら、例外を投げるようにすべきだ。&lt;/p&gt;

&lt;p&gt;もしくは、共通的な挙動をする他は常に例外を投げるNullオブジェクトを返すべきだ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public Employee getByName(String name) {
  int id = database.find(name);
  Employee employee;
  if (id == 0) {
    employee = new Employee() {
      @Override
      public String name() {
        return &amp;quot;anonymous&amp;quot;;
      }
      @Override
      public void transferTo(Department dept) {
        throw new AnonymousEmployeeException(
          &amp;quot;I can&#39;t be transferred, I&#39;m anonymous&amp;quot;
        );
      }
    };
  } else {
    employee = Employee(id);
  }
  return employee;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;可変で不完全なオブジェクト&#34;&gt;可変で不完全なオブジェクト&lt;/h3&gt;

&lt;p&gt;一般的に、オブジェクトは&lt;a href=&#34;http://www.yegor256.com/2014/06/09/objects-should-be-immutable.html&#34;&gt;不変的&lt;/a&gt;に設計することが望ましい。
これはつまり、オブジェクトはインスタンス化の際に必要な情報を全て受け取り、その後そのライフサイクル全体に渡ってその状態を変えないということだ。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;NULL&lt;/code&gt;は、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E9%81%85%E5%BB%B6%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%81%BF&#34;&gt;遅延読み込み&lt;/a&gt;をする際によく使われ、オブジェクトを不完全で可変にしてしまう。以下が例だ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class Department {
  private Employee found = null;
  public synchronized Employee manager() {
    if (this.found == null) {
      this.found = new Employee(&amp;quot;Jeffrey&amp;quot;);
    }
    return this.found;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この手法は、広く使われてはいるが、OOPにおけるアンチパターンだ。
主な理由は、実行環境の性能問題の責任をオブジェクトに負わせているからだ。本来それは&lt;code&gt;Employee&lt;/code&gt;オブジェクトが気にすべきことではない。&lt;/p&gt;

&lt;p&gt;オブジェクトが、自身の状態を管理して、自身の役割に関するふるまいを公開する代わりに、戻り値のキャッシュの面倒を見なければいけない。これが遅延読み込みというものだ。&lt;/p&gt;

&lt;p&gt;キャッシュはemployee(従業員)がオフィスでするようなことじゃないだろ?&lt;/p&gt;

&lt;p&gt;解決策?
遅延読み込みを上記の例みたいな原始的な方法でやらないことだ。代わりに、キャッシュ処理をアプリケーションの他のレイヤに移せばいい。&lt;/p&gt;

&lt;p&gt;たとえば、Javaなら、アスペクト指向プログラミングのアスペクトが使える。
たとえば、&lt;a href=&#34;http://aspects.jcabi.com/&#34;&gt;jcabi-aspects&lt;/a&gt;には&lt;code&gt;&lt;a href=&#34;http://aspects.jcabi.com/annotation-cacheable.html&#34;&gt;@Cacheable&lt;/a&gt;&lt;/code&gt;というアノテーションがあり、メソッドの戻り値をキャッシュできる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import com.jcabi.aspects.Cacheable;
public class Department {
  @Cacheable(forever = true)
  public Employee manager() {
    return new Employee(&amp;quot;Jacky Brown&amp;quot;);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;君がこの分析に納得して&lt;code&gt;NULL&lt;/code&gt;を使うのをやめることを願う。&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;embed video-player&#34; style=&#34;text-align: center&#34;&gt;
  &lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;320&#34; height=&#34;193&#34; src=&#34;https://www.youtube.com/embed/o3aNJX7AP3M&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上がYegorの記事。&lt;/p&gt;

&lt;p&gt;Nullを使っちゃだめという意見はめずらしくないが、その根拠をコードの信頼性、可読性といった技術的な側面からだけでなく、
オブジェクト界に降り立って見たときに感じる違和感というオブジェクト哲学的な側面からも説明する辺りが面白い。&lt;/p&gt;

&lt;p&gt;まあNullを完全に使わないという境地には、少なくともJavaのコードでは一生たどり着ける気がしないが。
メソッドの先頭で引数のNullチェックをするとかもダメなんだろうか。それがダメだとフェイルファストができなかったり、メッセージのないNullPointerExceptionが発生したりして微妙。
あ、フルスクラッチで完全に自己完結したアプリケーションを作る場合の話か。それならそもそもNullを渡すなという話にしかならないか。&lt;/p&gt;

&lt;p&gt;自分で書くクラスやライブラリについて、Nullは内部的には使うけど、APIには一切Nullを返させない、くらいなら実現するのは難しくなさそうだし、やったほうがいい気もする。(この場合遅延読み込みで一時的にNullをセットしておくのはあり。)
ただ、性能を考えた場合は、例えばエラー処理はアドホックが一番軽くて、次にNullオブジェクトパターンで、例外はちょっと重めという風になるだろうから、Nullを返したくなることもありそう。&lt;/p&gt;

&lt;p&gt;ことあるごとに例外を投げてくるAPIは使う側にとってはうっとうしいしなぁ。
多彩な例外を投げ分けるJavaのリフレクションみたいなのは、使うとコードが散らかってかなわん。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>How to capture packets on a local network with Pcap4J container</title>
          <link>https://www.kaitoy.xyz/2015/07/25/how-to-capture-packets-on-a-local-network-with-pcap4j-container/</link>
          <pubDate>Sat, 25 Jul 2015 19:05:06 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/07/25/how-to-capture-packets-on-a-local-network-with-pcap4j-container/</guid>
          <description>

&lt;p&gt;I&amp;rsquo;ll show how to capture packets on a local network with Pcap4J container.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h3 id=&#34;docker-network&#34;&gt;Docker network&lt;/h3&gt;

&lt;p&gt;By default, Docker containers are not connected to a local network.
They are connected only to a virtual network Docker creates as like below:&lt;/p&gt;

&lt;p&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;https://www.kaitoy.xyz/images/docker_network.jpg&#34; alt=&#34;Docker network&#34; width=&#34;500&#34; /&gt;
    
    
&lt;/figure&gt;
&lt;/p&gt;

&lt;p&gt;Refer to &lt;a href=&#34;https://docs.docker.com/articles/networking/&#34;&gt;the Docker doc&lt;/a&gt; for more details.&lt;/p&gt;

&lt;h3 id=&#34;what-s-a-challenge&#34;&gt;What&amp;rsquo;s a challenge&lt;/h3&gt;

&lt;p&gt;In order to let a Pcap4J container capture packets in a local (real) network,
we need to directly connect the container to the local network,
because docker0 forwards only packets the destinations of which are in the virtual network.&lt;/p&gt;

&lt;p&gt;How to do it is explained in some articles.
I referred to one of them, &lt;a href=&#34;http://blog.oddbit.com/2014/08/11/four-ways-to-connect-a-docker/&#34;&gt;Four ways to connect a docker container to a local network in Odd Bits blog&lt;/a&gt;, and succeeded in local network capturing using the 4th way.&lt;/p&gt;

&lt;p&gt;What I actually did is as follows.&lt;/p&gt;

&lt;h3 id=&#34;what-i-did&#34;&gt;What I did&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Environment&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;OS: CentOS 7.0 (on VMware Player 7.1.0 on Windows 7)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@localhost ~]# uname -a
Linux localhost.localdomain 3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;user: root&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Pcap4J version: 1.5.1-SNAPSHOT&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Docker version: 1.6.2&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Network interfaces:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;  [root@localhost ~]# ip addr show
  1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN
      link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
      inet 127.0.0.1/8 scope host lo
         valid_lft forever preferred_lft forever
      inet6 ::1/128 scope host
         valid_lft forever preferred_lft forever
  2: eth0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000
      link/ether 00:0c:29:8e:95:27 brd ff:ff:ff:ff:ff:ff
      inet 192.168.1.123/24 brd 192.168.1.255 scope global dynamic eth0
         valid_lft 85975sec preferred_lft 85975sec
      inet6 2601:282:8102:2623:20c:29ff:fe8e:9527/64 scope global dynamic
         valid_lft 221469sec preferred_lft 221469sec
      inet6 fe80::20c:29ff:fe8e:9527/64 scope link
         valid_lft forever preferred_lft forever
  3: docker0: &amp;lt;NO-CARRIER,BROADCAST,MULTICAST,UP&amp;gt; mtu 1500 qdisc noqueue state DOWN
      link/ether 56:84:7a:fe:97:99 brd ff:ff:ff:ff:ff:ff
      inet 172.17.42.1/16 scope global docker0
         valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Prerequisites:

&lt;ul&gt;
&lt;li&gt;Docker is installed and Docker service is started&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://man7.org/linux/man-pages/man1/nsenter.1.html&#34;&gt;nsenter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Step by step&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Preparing&lt;/p&gt;

&lt;p&gt;Create a utility script &lt;code&gt;docker-pid&lt;/code&gt; with the following content and place it somewhere in the &lt;code&gt;PATH&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;  #!/bin/sh
  exec docker inspect --format &#39;{{ .State.Pid }}&#39; &amp;quot;$@&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This script show the PID of a docker container by name or ID.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Pull the latest Pcap4J image&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@localhost ~]# docker pull kaitoy/pcap4j
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Start a Pcap4J container with wait mode&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@localhost ~]# docker run --name pcap4j-br kaitoy/pcap4j:latest eth1 true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This container (&lt;code&gt;pcap4j-br&lt;/code&gt;) waits for a ping to &lt;code&gt;eth0&lt;/code&gt; on the container before staring capturing packets with &lt;code&gt;eth1&lt;/code&gt; on the container.
After the container starts, you will see messages like below:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;17:49:21.196 [main] INFO  org.pcap4j.core.Pcaps - 3 NIF(s) found.
eth0 (null)
IP address: /172.17.0.3
IP address: /fe80:0:0:0:42:acff:fe11:3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The messages say IP address of &lt;code&gt;eth0&lt;/code&gt; is &lt;code&gt;172.17.0.3&lt;/code&gt;. We will use it later.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Configure a bridge interface&lt;/p&gt;

&lt;p&gt;Open another terminal and do the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@localhost ~]# ip link add eth1 link eth0 type macvlan mode bridge
[root@localhost ~]# ip link set netns $(docker-pid pcap4j-br) eth1
[root@localhost ~]# nsenter -t $(docker-pid pcap4j-br) -n ip link set eth1 up
[root@localhost ~]# nsenter -t $(docker-pid pcap4j-br) -n ip route del default
[root@localhost ~]# nsenter -t $(docker-pid pcap4j-br) -n ip addr add 192.168.1.200/24 dev eth1
[root@localhost ~]# nsenter -t $(docker-pid pcap4j-br) -n ip route add default via 192.168.1.1 dev eth1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The above commands
1) add an interface &lt;code&gt;eth1&lt;/code&gt; bridged to &lt;code&gt;eth0&lt;/code&gt; to the Docker host machine,
2) move the &lt;code&gt;eth1&lt;/code&gt; to the name space of &lt;code&gt;pcap4j-br&lt;/code&gt;,
3) start &lt;code&gt;eth1&lt;/code&gt;,
4) delete the default route in &lt;code&gt;pcap4j-br&lt;/code&gt;,
5) add an IP address &lt;code&gt;192.168.1.200/24&lt;/code&gt; to &lt;code&gt;eth1&lt;/code&gt;,
6) and set the default route in &lt;code&gt;pcap4j-br&lt;/code&gt; to &lt;code&gt;192.168.1.1&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Too much hassle? I agree. Let&amp;rsquo;s use an awesome tool, &lt;a href=&#34;https://github.com/jpetazzo/pipework&#34;&gt;pipework&lt;/a&gt;.
This tool accomplishes the above 6 steps in easier way as shown below:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@localhost ~]# git clone https://github.com/jpetazzo/pipework.git
[root@localhost ~]# cd pipework
[root@localhost pipework]# ./pipework eth0 pcap4j-br 192.168.1.200/24@192.168.1.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pipework uses &lt;code&gt;ip netns exec&lt;/code&gt; command instead of &lt;code&gt;nsenter&lt;/code&gt; to manipulate a container.
Incidentally, &lt;code&gt;docker exec&lt;/code&gt; didn&amp;rsquo;t work for the step 3 due to an error &amp;ldquo;&lt;code&gt;RTNETLINK answers: Operation not permitted&lt;/code&gt;&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;In addition, in my case, because I was doing it on a VMware VM, I needed to enable the promiscuous mode of &lt;code&gt;eth0&lt;/code&gt; (on the docker host machine) as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@localhost ~]# ip link set dev eth0 promisc on
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Try to poke the container&lt;/p&gt;

&lt;p&gt;You can now communicate with &lt;code&gt;pcap4j-br&lt;/code&gt; using &lt;code&gt;eth1&lt;/code&gt; &lt;strong&gt;from another host&lt;/strong&gt;.
I tried some pings from the VM&amp;rsquo;s host to &lt;code&gt;pcap4j-br&lt;/code&gt; and saw replies.&lt;/p&gt;

&lt;p&gt;Note that you can &lt;strong&gt;NOT&lt;/strong&gt; communicate with &lt;code&gt;pcap4j-br&lt;/code&gt; via &lt;code&gt;eth1&lt;/code&gt; from the docker host.
See the &lt;a href=&#34;http://blog.oddbit.com/2014/08/11/four-ways-to-connect-a-docker/&#34;&gt;Odd Bits blog&lt;/a&gt; for the details.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Start packet capturing&lt;/p&gt;

&lt;p&gt;Ping to &lt;code&gt;eth0&lt;/code&gt; of &lt;code&gt;pcap4j-br&lt;/code&gt; form the docker host to start packet capturing.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@localhost ~]# ping -c 1 172.17.0.3
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Getter/Setterは悪だ。以上。</title>
          <link>https://www.kaitoy.xyz/2015/07/22/getters-setters-evil/</link>
          <pubDate>Wed, 22 Jul 2015 00:21:15 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/07/22/getters-setters-evil/</guid>
          <description>

&lt;p&gt;このエントリでは、Yegor Bugayenkoによる記事、&lt;a href=&#34;http://www.yegor256.com/2014/09/16/getters-and-setters-are-evil.html&#34;&gt;Getters/Setters. Evil. Period.&lt;/a&gt;を紹介する。
(Yegorから和訳と転載の許可は得た。)
以下はその全文の和訳だが、意訳超訳が混じっているので、もとのニュアンスを知りたければ元記事を読んでもいいし、読まなくてもいい。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;2003年にAllen Holubが書いた&lt;a href=&#34;http://www.javaworld.com/article/2073723/core-java/why-getter-and-setter-methods-are-evil.html&#34;&gt;Why getter and setter methods are evil&lt;/a&gt;という有名な記事に端を発する古い議論がある。それは、getter/setterはアンチパターンで避けるべきものなのか、
もしくはオブジェクト指向プログラミングに必須なものなのかというもの。
この議論に少しだけ私の意見を加えたいと思う。&lt;/p&gt;

&lt;p&gt;上記記事の要旨はこうだ。
getterやsetterはひどい慣習で、これらを使うやつらはゆるせん。誤解の無いようもう一度言うが、
私はget/setを可能な限り避けるべきだと言っているのではない。それらは君のコードに決して現れてはいけないのだ。&lt;/p&gt;

&lt;p&gt;横柄で目につく物言いだろう?
君は15年来get/setパターンを使い続けている尊敬を集めるJavaアーキテクトなんだろう?
どこぞの馬の骨にこんなデタラメを言われたくはないだろう?
ああ、その気持ちはわかる。私がDavid Westの&lt;a href=&#34;http://www.amazon.com/gp/product/0735619654/ref=as_li_tl?ie=UTF8&amp;amp;camp=1789&amp;amp;creative=9325&amp;amp;creativeASIN=0735619654&amp;amp;linkCode=as2&amp;amp;tag=yegor256com-20&amp;amp;linkId=NQQHJZPHOKM6BTCT&#34;&gt;Object Thinking&lt;/a&gt;という本に出会ったとき、
私もほとんど同じことを感じた。
Object Thinkingは、私が今まで読んだオブジェクト指向プログラミングについての本の中で最高のものだ。
だからお願いだ。ひとまず落ち着いて。私に説明させてほしい。&lt;/p&gt;

&lt;h3 id=&#34;既存の論拠&#34;&gt;既存の論拠&lt;/h3&gt;

&lt;p&gt;オブジェクト指向の世界で、アクセッサ(getterやsetterの別名)に反対する論拠はいくつかあるが、
私にはそれら全てが十分に有力であるとは思えない。ひとつひとつ簡単に見ていこう。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;頼め、尋ねるな&lt;/p&gt;

&lt;p&gt;Allen Holub曰く、「ある処理をする際、その処理のために君が欲しい情報をオブジェクトに尋ねてはいけない。
その情報を持ったオブジェクトにその処理をするよう頼みなさい。」&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;カプセル化原則違反&lt;/p&gt;

&lt;p&gt;setterを通してどんな新たなデータも入力できるので、
一つのオブジェクトをその他の様々なオブジェクトが様々に扱うことができてしまう。
また、だれでもオブジェクトを変更できるので、
オブジェクトが単純に自身の状態を安全にカプセル化できない。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;実装の詳細の暴露&lt;/p&gt;

&lt;p&gt;あるオブジェクトから他のオブジェクトを取得できる場合、前者のオブジェクトの実装の詳細に過度に依存してしまう。
もし明日その実装、例えば返すオブジェクトの型が変わったら、周辺のコードも書き換えないといけない。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;これらの全ての論拠は正当だが、重要なポイントが抜けている。&lt;/p&gt;

&lt;h3 id=&#34;根本的な誤解&#34;&gt;根本的な誤解&lt;/h3&gt;

&lt;p&gt;ほとんどのプログラマはオブジェクトはメソッドを持ったデータ構造だと考えている。
ここでBozhidar Bozhanovによる記事、&lt;a href=&#34;https://dzone.com/articles/getters-and-setters-are-not&#34;&gt;Getters and Setters Are Not Evil&lt;/a&gt;から引用する。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;しかし、人々がgetterやsetterをつけるオブジェクトのほとんどが、単純なデータホルダだ。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;この思い違いが巨大な誤解の結果だ!
オブジェクトは単純なデータホルダではない。オブジェクトはメソッド付きのデータ構造ではない。
このデータホルダというコンセプトは、CやCOBOLといった手続き型言語からオブジェクト指向プログラミングに持ち込まれたものだ。
もう一度言う。オブジェクトはデータとそれを操作する関数をセットにしたものではない。
オブジェクトはデータエンティティではない。では何か?&lt;/p&gt;

&lt;h3 id=&#34;ボールと犬&#34;&gt;ボールと犬&lt;/h3&gt;

&lt;p&gt;真のオブジェクト指向プログラミングでは、
オブジェクトは&lt;a href=&#34;https://www.kaitoy.xyz/2015/10/28/seven-virtues-of-good-object/&#34;&gt;生きている生物&lt;/a&gt;だ。私や君と同じように。
オブジェクトは生きている有機体で、それ自身の挙動や、特性や、ライフサイクルを持っている。&lt;/p&gt;

&lt;p&gt;生きている有機体はsetterを持てるだろうか? 犬にボールを&amp;rdquo;set&amp;rdquo;できるだろうか? 無理だろう。
だが、以下のコードはまさにそれをしている。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Dog dog = new Dog();
dog.setBall(new Ball());
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これをどう感じる?&lt;/p&gt;

&lt;p&gt;また、ボールを犬から取得できるだろうか?
まあ、できるかもしれない、もしその犬がボールを食べて、君が手術をするのであれば。
この場合、確かに、犬からボールを&amp;rdquo;get&amp;rdquo;できる。以下のコードが今話したようなことをやっている。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Dog dog = new Dog();
Ball ball = dog.getBall();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;またさらにばかげた例がこれだ。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Dog dog = new Dog();
dog.setWeight(&amp;quot;23kg&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;現実世界でこの処理がどんなか想像できるかな?&lt;/p&gt;

&lt;p&gt;君が毎日書いているコードはこれに似ているかい?
もしそうなら、君は手続き型プログラマだ。認めなさい。
David Westが彼の本の30ページでそれについて以下のように言っている。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;成功した手続き型開発者が成功するオブジェクト開発者に移行するための最初のステップは、ロボトミーだ。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;君はロボトミーが必要か？
因みに、WestのObject Thinkingを読んでいた時、私には明らかに必要だったので受けた。&lt;/p&gt;

&lt;h3 id=&#34;オブジェクト思考&#34;&gt;オブジェクト思考&lt;/h3&gt;

&lt;p&gt;オブジェクト思考を開始すると、君は即座にメソッド名を変更し、多分以下のコードに辿り着く。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Dog dog = new Dog();
dog.take(new Ball());
Ball ball = dog.give();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今、私たちは犬を実際の動物として扱っている。この犬は、ボールを私たちから受け取り、頼めば返してくれる。
ここで特筆すべきは、この犬は &lt;code&gt;NULL&lt;/code&gt; を返すことはできない。犬は &lt;code&gt;NULL&lt;/code&gt; が何なのかなんて知らないからね。オブジェクト思考は即座に&lt;a href=&#34;http://www.yegor256.com/2014/05/13/why-null-is-bad.html&#34;&gt;NULL参照&lt;/a&gt;をコードから排除する。&lt;/p&gt;

&lt;p&gt;さらに、オブジェクト思考はオブジェクト不変性につながる。
犬の体重の例を、君は以下のように書き換えるだろう。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Dog dog = new Dog(&amp;quot;23kg&amp;quot;);
int weight = dog.weight();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この犬は不変な生きた有機体であり、だれも外からその体重やサイズや名前などを変更することはできない。
この犬は要求に応じて体重や名前を教えてくれる。
オブジェクトの中身を要求するパブリックメソッドには何の問題もないが、
こういったメソッドは&amp;rdquo;getter&amp;rdquo;ではなく、&amp;rdquo;get&amp;rdquo;というプレフィックスは決して付かない。
私たちは犬から何かを取ろうというのではない。犬から名前を取るのではなく、犬に名前を教えてくれるよう頼むのだ。
この違いが分かるかな?&lt;/p&gt;

&lt;p&gt;語義論の話をしているというわけでもない。
手続き型プログラミング思考とオブジェクト指向プログラミング思考とを区別しようというのだ。
手続き型プログラミングでは、私たちはデータを扱い、必要に応じてそれを操作したり取得したりセットしたり消したりする。
私たちはデータの責任者で、そのデータは単なる受動的なコンポーネントだ。
犬は私たちとは何の関係もなく、ただのデータホルダだ。それは生命を持っていない。
私たちはそれから必要なものを何でも自由に取得できるし、どんなデータでもセットすることができる。
これがCやCOBOLやPascalなどの手続き型言語のやりかただ。&lt;/p&gt;

&lt;p&gt;それに対して、真のオブジェクト指向の世界では、オブジェクトを生きた有機体のように扱い、
オブジェクトには生まれた日と死ぬ瞬間がある。また、君が望むなら、アイデンティティや性質を持たせてもいい。
犬にはデータの一部(例えば体重)をくれるよう頼むことができるし、犬はその情報を返してもよい。
ただ、この犬は能動的なコンポーネントであることを忘れてはいけない。
こちらの要求に対し、何をするかは犬が決めるのだ。&lt;/p&gt;

&lt;p&gt;以上が、getやsetで始まるメソッドをオブジェクトに持たせることが概念的に間違っている理由だ。
それは、多くの人々が主張するように、カプセル化を崩すということではない。
それは、君がオブジェクト的な思考をしているか、もしくは今だCOBOLをJavaのシンタックスで書いているかということだ。&lt;/p&gt;

&lt;p&gt;追伸: そうだ、君はこう尋ねるかもしれない。JavaBeans、JPA、JAXBなどのget/set表記に頼るJava APIはどうなんだ?
Rubyに付属するアクセッサ生成を簡易化する機能は?
ああ、それらは全て私たちにとっての不幸だ。
手続き型COBOLの原始的な世界に留まることは、真のオブジェクトからなる美しい世界を正しく理解し感謝するのに比べてはるかに簡単だ。&lt;/p&gt;

&lt;p&gt;追追伸: 言い忘れたが、setterを使った依存性注入もひどいアンチパターンだ。
それについてはいずれ書く。&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;embed video-player&#34; style=&#34;text-align: center&#34;&gt;
  &lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;320&#34; height=&#34;193&#34; src=&#34;https://www.youtube.com/embed/WSgP85kr6eU&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上がYegorの記事。&lt;/p&gt;

&lt;p&gt;Javaを始めた当初から今まで、Getter/Setterは絶対正義だと信じ、クラスを作れば無心でIDEの言いなりにそれを生成していたので、
この記事はなかなかに刺激的だった。(まあfinalなフィールドが好きなのでsetterの方はあまり作らなかったが。)&lt;/p&gt;

&lt;p&gt;ただ、記事の本質としては、Getter/Setterパターン、つまり、
オブジェクトのフィールドをprivateにし、メソッドを介してアクセスさせるようにすることで、実装の詳細を隠蔽し、
APIと分離させることを図るデザインパターンの技術的役割や目的を否定しているわけではなく、
オブジェクト指向の哲学的な部分にも則り、Getter/Setterパターンを真のオブジェクト界に向けて昇華させましょうと言っているように読める。&lt;/p&gt;

&lt;p&gt;犬とボールのやり取りをするコードのビフォーアフターはsetBall/getBallがtake/giveになっただけで、
これだけ見れば処理が変わるわけでもないし、コンパイラに言わせればどっちでもいいだろとなる。
ただ、プログラマにボールを無下につっこまれるビフォーの犬よりも、
自ら能動的にボールを受け取り返してくれるアフターの犬の方が幸せそうで愛らしいのは確かだ。
真のオブジェクト界を垣間見た気がする。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Pcap4J container with runC</title>
          <link>https://www.kaitoy.xyz/2015/07/19/pcap4j-container-with-runc/</link>
          <pubDate>Sun, 19 Jul 2015 16:25:03 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/07/19/pcap4j-container-with-runc/</guid>
          <description>

&lt;p&gt;I tried to run a &lt;a href=&#34;https://registry.hub.docker.com/u/kaitoy/pcap4j/&#34;&gt;Pcap4J container&lt;/a&gt; with &lt;a href=&#34;https://runc.io/&#34;&gt;runC&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;what-is-pcap4j&#34;&gt;What is Pcap4J?&lt;/h2&gt;

&lt;p&gt;Pcap4J is a Java library for capturing, crafting, and sending packets.
It&amp;rsquo;s actually a Java wrapper for libpcap/WinPcap plus packet analyzer.
We can see the details in its &lt;a href=&#34;https://github.com/kaitoy/pcap4j&#34;&gt;README&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;what-is-runc&#34;&gt;What is runC?&lt;/h2&gt;

&lt;p&gt;runC is a container runtime developed by Docker and released on June 22, 2015.
With runC, we can start a container from a docker image without the docker service or the docker command.&lt;/p&gt;

&lt;p&gt;That said, as of now, runC cannot directory use docker images.
We need to create a container form a docker image and export its filesystem before executing runC.&lt;/p&gt;

&lt;p&gt;It seems currently it supports only Linux but Windows support is in the roadmap.&lt;/p&gt;

&lt;h2 id=&#34;what-i-did&#34;&gt;What I did&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Environment

&lt;ul&gt;
&lt;li&gt;OS: CentOS 7 (on VMware Player 7.1.0 on Windows 7)&lt;/li&gt;
&lt;li&gt;user: root&lt;/li&gt;
&lt;li&gt;runC version: 0.2&lt;/li&gt;
&lt;li&gt;Pcap4J version: 1.5.1-SNAPSHOT&lt;/li&gt;
&lt;li&gt;Docker version: 1.6.2&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Prerequisites:

&lt;ul&gt;
&lt;li&gt;Docker is installed and Docker service is started&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://golang.org/&#34;&gt;Go&lt;/a&gt; is installed&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Step by step&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Install runC&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@localhost ~]# mkdir -p $GOPATH/src/github.com/opencontainers
[root@localhost ~]# cd $GOPATH/src/github.com/opencontainers
[root@localhost opencontainers]# git clone https://github.com/opencontainers/runc
[root@localhost opencontainers]# cd runc
[root@localhost runc]# make &amp;amp;&amp;amp; make install
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Pull the Pcap4J docker image.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@localhost ~]# docker pull kaitoy/pcap4j
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Create a container from the image.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@localhost ~]# docker run -d --name pcap4j-tmp kaitoy/pcap4j:latest /bin/bash
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Export the container&amp;rsquo;s file system.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@localhost ~]# mkdir /tmp/pcap4j-test
[root@localhost pcap4j-test]# cd /tmp/pcap4j-test
[root@localhost pcap4j-test]# docker export pcap4j-tmp &amp;gt; pcap4j.tar
[root@localhost pcap4j-test]# tar xf pcap4j.tar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We are now free from Docker. We don&amp;rsquo;t need Docker service, Docker command, Docker images, nor Docker containers anymore.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Generate a container config file.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@localhost pcap4j-test]# runc spec | sed -e &#39;s/rootfs/\/root\/Desktop\/pcap4j-container/&#39; -e &#39;s/&amp;quot;readonly&amp;quot;: true/&amp;quot;readonly&amp;quot;: false/&#39; -e &#39;s/&amp;quot;NET_BIND_SERVICE&amp;quot;/&amp;quot;NET_BIND_SERVICE&amp;quot;,&amp;quot;NET_ADMIN&amp;quot;,&amp;quot;NET_RAW&amp;quot;/&#39; &amp;gt; config.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the above command, &lt;code&gt;runc spec&lt;/code&gt; generates a standard container config file and &lt;code&gt;sed&lt;/code&gt; modifies it for Pcap4J.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Run a container.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[root@localhost pcap4j-test]# runc
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;In the container, enable lo.&lt;/p&gt;

&lt;p&gt;As far as I saw, lo is the only interface we can use in a container.
So, I used it to capture packets.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sh-4.1# ifconfig lo up
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Generate a script to ping localhost and run it background.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sh-4.1# cd /usr/local/src/pcap4j/bin
sh-4.1# echo ping 127.0.0.1 \&amp;gt; /dev/null &amp;gt; pinger.sh
sh-4.1# chmod +x pinger.sh
sh-4.1# ./pinger.sh &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the next step, ICMP packets from this pinger.sh will be captured.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Generate a script to start capturing packets with Pcap4J and run it.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sh-4.1# cat runGetNextPacket.sh | sed -e &#39;s/eth0/lo/&#39; &amp;gt; foo.sh
sh-4.1# chmod +x foo.sh
sh-4.1# ./foo.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We will see the ICMP packets are dumped on the terminal. That&amp;rsquo;s it!&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>First Post</title>
          <link>https://www.kaitoy.xyz/2015/07/18/first-post/</link>
          <pubDate>Sat, 18 Jul 2015 13:10:37 -0600</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2015/07/18/first-post/</guid>
          <description>&lt;p&gt;初投稿。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;ブログを立ち上げようと思ったきっかけは、&lt;a href=&#34;http://www.teamed.io/&#34;&gt;Teamed.io&lt;/a&gt;というCaliforniaのソフトウェアアウトソーシング(?)をやってる会社のCTO、
Yegor Bugayenko (yegor256)のブログのエントリ、&lt;a href=&#34;http://www.yegor256.com/2014/10/29/how-much-do-you-cost.html&#34;&gt;How Much Do You Cost?&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;これは、Teamed.ioがエンジニアに払うfeeを決める際の指標についてのエントリで、その指標の一つとして &lt;em&gt;Talks and Publications&lt;/em&gt; を挙げている。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Both blog articles and conference presentations make you much more valuable as a specialist.
Mostly because these things demonstrate that some people already reviewed your work and your talent.
And it was not just a single employer, but a group of other programmers and engineers.
This means that we also can rely on your opinions.&lt;/p&gt;

&lt;div style=&#34;font-size: 0.5em; text-align: right;&#34;&gt;&lt;cite&gt;引用元: &lt;a href=&#34;http://www.yegor256.com/2014/10/29/how-much-do-you-cost.html#talks-and-publications&#34;&gt;http://www.yegor256.com/2014/10/29/how-much-do-you-cost.html#talks-and-publications&lt;/a&gt;&lt;/cite&gt;&lt;/div&gt;
&lt;/blockquote&gt;

&lt;p&gt;つまり、カンファレンスで発表したりブログで意見を発信すると、それらを見た様々な人たちによってレビューされフィードバックを受けることになるので、
そういった経験が多いエンジニアは、より洗練された考えや技術を持っているとみなせるということ。&lt;/p&gt;

&lt;p&gt;確かに、普段会社の同僚としか接しないので、自分の意見を広く発信してフィードバックを受けるのは刺激になりおもしろそうだしためになりそう。
ただそのためにはこのブログが広く読まれコメントをもらえるまでになる必要があるが、それはさておき、
文筆の練習として、また物事に対する理解を深めるためにも、書くということは有益であろう。備忘録にもなるし。&lt;/p&gt;

&lt;p&gt;因みに、Yegorはオブジェクト指向プログラミングの原理主義者で、ソフトウェア開発に対して非常に厳格で斬新な(異端な?)考え方を持っている。
それは例えば彼の以下のブログエントリに見られる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.yegor256.com/2015/01/08/morning-standup-meetings.html&#34;&gt;Daily Stand-Up Meetings Are a Good Tool for a Bad Manager&lt;/a&gt; (スタンドアップミーティングはダメマネージャーが好む手法)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.yegor256.com/2014/12/01/orm-offensive-anti-pattern.html&#34;&gt;ORM Is an Offensive Anti-Pattern&lt;/a&gt; (ORMはけしからんアンチパターン)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.yegor256.com/2014/09/16/getters-and-setters-are-evil.html&#34;&gt;Getters/Setters. Evil. Period.&lt;/a&gt; (GetterやSetterは悪だ。以上。)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下で働くと苦労しそうなタイプな気はするが、言っていることは面白いし説得力もあるので、いくつかのエントリを和訳しておいおいここで紹介していこうかと思う。&lt;/p&gt;
</description>
        </item>
      
    

  </channel>
</rss>
