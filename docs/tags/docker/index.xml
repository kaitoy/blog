<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>docker on To Be Decided</title>
    <link>https://www.kaitoy.xyz/tags/docker/</link>
    <description>Recent content in docker on To Be Decided</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>© 2015 Kaito Yamada</copyright>
    <lastBuildDate>Sun, 17 Jun 2018 23:22:33 +0900</lastBuildDate>
    
	<atom:link href="https://www.kaitoy.xyz/tags/docker/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Packer &#43; Ansible on Windows 10でKubernetes 1.10のクラスタ on VirtualBoxを全自動構築</title>
      <link>https://www.kaitoy.xyz/2018/06/17/packer-k8s/</link>
      <pubDate>Sun, 17 Jun 2018 23:22:33 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2018/06/17/packer-k8s/</guid>
      <description>「Kubernetes 1.10のクラスタを全手動で構築するのをAnsibleで全自動化した」の続きで、さらにPackerを組み合わせて、VM作成まで自動化した話。
AnsibleをWindows(MSYS2)で動かした話でもある。
書いたPackerテンプレートはGitHubに置いた。
   (adsbygoogle = window.adsbygoogle || []).push({});  Packerとは Packerは、様々な種類のVMを構築できるツール。 VagrantとかTerraformとかを開発しているHashiCorpが開発している。
テンプレートと呼ばれるビルド定義をJSONファイルに書いて、ビルド、プロビジョニング、ポストプロセスを実行して、アーティファクトと呼ばれるビルドの成果物を生成する。
ビルドのステップでは、VMを作成して、ハードウェア構成を設定したり、OSをインストールしたりする。
以下のような環境でVMを作れる。
 VirtualBox Hyper-V VMware Workstation VMware vSphere Hypervisor Docker AWS EC2  
プロビジョニングのステップでは、ビルドで作ったVMのOS上で指定された操作を実行し、ソフトウェアのインストールなどのセットアップ処理をする。
プロビジョニングには以下のようなツールを使える。
 Shell PowerShell Ansible Chef Puppet  プロビジョニングが終わるとアーティファクト(VMイメージファイルや、AWS EC2のAMI IDとか)が出力される。

ポストプロセスのステップでは、アーティファクトを入力として何らかの処理をして、最終的なアーティファクトを生成する。
ポストプロセスでは以下のような処理を実行できる。
 アーカイブ VagrantBox生成 AWS EC2へのインポート Docker push  
PackerはGoで書かれていてビルド済みのバイナリが配布されているので、ダウンロードページから落として PATHの通ったところに置くだけでインストールできる。

今回はPacker 1.2.4のWindows版をインストールした。
Packerのテンプレート概要 Packerのテンプレートにはビルド、プロビジョニング、ポストプロセスの定義を複数かけて、複数環境のVM生成を1ファイルで定義できる。
テンプレートには以下のプロパティを書く。
 builders: ビルドの定義のリスト。 description: テンプレートの説明。 min_packer_version: Packer の最低バージョン指定。 post-processors: ポストプロセスの定義のリスト。 provisioners: プロビジョニングの定義のリスト。 variables: テンプレート内で使う変数の定義。 _comment: コメントなどを書くためのプロパティ。実際はアンダースコアで始まればなんでもいい。JSON オブジェクトのルートレベルのみで使える。  これらのうち、必須なのはbuildersだけ。</description>
    </item>
    
    <item>
      <title>Kubernetes 1.10のクラスタを全手動で構築するのをAnsibleで全自動化した</title>
      <link>https://www.kaitoy.xyz/2018/06/03/build-k8s-cluster-by-ansible/</link>
      <pubDate>Sun, 03 Jun 2018 17:14:07 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2018/06/03/build-k8s-cluster-by-ansible/</guid>
      <description>「Kubernetes 1.10をスクラッチから全手動で構築」、「Kubernetes 1.10のクラスタにWeave Netをデプロイする」、「Kubernetes 1.10のkubeletの起動オプションをKubelet ConfigファイルとPodSecurityPolicyで置き換える」のまとめとして、Kubernetes 1.10のクラスタを構築するAnsible Playbookを書いた。
書いたものはGitHubに置いた。
   (adsbygoogle = window.adsbygoogle || []).push({});  Ansibleとは Ansibleは、Ansible社が開発したOSSのIT自動化ツール。 Ansible社は2015年10月にRedHatが買収したので、現在はRedHatが開発している。 似たようなツールにPuppetやChefがあるが、最近はAnsibleが最も支持されている気がする。
構成管理ツールと紹介されることが多い気がするが、2014年末位からはIT自動化ツールを自称していて、構成管理は実現するユースケースの一つという位置づけになっているので、そろそろ認識を改めてあげたい。
ユースケースは以下のようなもの。
 プロビジョニング (ベアメタル、VM、クラウドインスタンス) 構成管理 アプリケーションデプロイメント CI/CD セキュリティ・コンプライアンス管理 オーケストレーション  
以下のような特徴を持つ。
 Python(とPowerShell)で作られてる。  昔はPython 2じゃないと動かなかったけど、2.2からPython 3でも動くようになった。  YAMLで書いた定義(Playbook)に従って処理を実行する。 シンプルで簡便であることを売りにしている。  多数のモジュールがビルトインされていて、様々な操作を簡潔な定義で宣言的に実行できる。  エージェントレスで、SSH(等)で対象のサーバにつないで処理を実行する。 処理を冪等にできるような仕組みが備わっていて、特にビルトインモジュールを活用すると簡単に冪等性を持たせられる。  
Pythonで書かれているのでどこでも動くかと思いきや、fcntlとかgrpやらUnix特有のモジュールを使っているため、WindowsのPythonでは動かない。
MSYS2とかWSLでは動く模様。 (Git Bashでは動かない…)

今回使ったのは最新版の2.5.3。
Ansibleインストール AnsibleはYUMとかpipとかでインストールできる。
今回はOracle Linux 7.4で動かすため、以下のようにインストールした。
 AnsibleのYUMリポジトリ追加
以下の内容を/etc/yum.repos.d/の適当な.repoファイルに書く。
[ansible] name=Ansible baseurl=http://releases.ansible.com/ansible/rpm/release/epel-7-x86_64/ gpgcheck=0 enabled=1 依存するPythonパッケージのYUMリポジトリを有効化</description>
    </item>
    
    <item>
      <title>Kubernetes 1.10のkubeletの起動オプションをKubelet ConfigファイルとPodSecurityPolicyで置き換える</title>
      <link>https://www.kaitoy.xyz/2018/05/05/kubernetes-kubelet-config-and-pod-sec-policy/</link>
      <pubDate>Sat, 05 May 2018 21:54:30 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2018/05/05/kubernetes-kubelet-config-and-pod-sec-policy/</guid>
      <description>「Kubernetes 1.10をスクラッチから全手動で構築」、「Kubernetes 1.10のクラスタにWeave Netをデプロイする」の続き。
kubeletの起動オプションの代わりに、Kubelet ConfigファイルとPodSecurityPolicyを使うように変更した話。
ついでにkube-proxyとkube-schedulerもConfigファイルを使うようにした。
   (adsbygoogle = window.adsbygoogle || []).push({});  Kubelet Configファイル journalctl -u kubeletすると、以下の警告が出ている。
Apr 28 15:31:39 k8s-master kubelet[1370]: Flag --address has been deprecated, This parameter should be set via the config file specified by the Kubelet&amp;#39;s - -config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information. Apr 28 15:31:40 k8s-master kubelet[1370]: Flag --pod-manifest-path has been deprecated, This parameter should be set via the config file specified by the K ubelet&amp;#39;s --config flag.</description>
    </item>
    
    <item>
      <title>Kubernetes 1.10のクラスタにWeave Netをデプロイする</title>
      <link>https://www.kaitoy.xyz/2018/05/04/kubernetes-with-weave-net/</link>
      <pubDate>Fri, 04 May 2018 11:14:33 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2018/05/04/kubernetes-with-weave-net/</guid>
      <description>「Kubernetes 1.10をスクラッチから全手動で構築」で、Kubernetes 1.10のクラスタに、ネットワークプロバイダとしてflannelをデプロイしたけど、flannelはNetwork Policyをサポートしていないので、代わりにWeave Netをデプロイしてみた話。
   (adsbygoogle = window.adsbygoogle || []).push({});  Weave Netにした理由 Network Policyをサポートしているネットワークプロバイダには現時点で以下のものがある。
 Calico Cilium Kube-router Romana Weave Net  このなかで、よく名前を聞くのがCalicoとWeave Net。 GitHubのスター数が圧倒的に多いのがWeave Net。 性能が比較的いいのがWeave Net。
ということでWeave Netにした。
Weave Netデプロイ 以下を参考に設定してデプロイする。
 https://www.weave.works/docs/net/latest/kubernetes/kube-addon/ https://www.weave.works/docs/net/latest/install/installing-weave/ https://github.com/weaveworks/weave/blob/master/prog/weave-kube/launch.sh  Kubernetesマニフェスト Weave NetをKubernetesクラスタにデプロイするためのマニフェストは、GitHub Releasesかhttps://cloud.weave.worksからダウンロードできる。 今回は後者にする。
https://cloud.weave.worksを使う場合、Kubernetesのバージョンなどのパラメータはクエリストリングで指定できる。 主なパラメータは以下。
 k8s-version: Kubernetesのバージョン。指定しないとlatest。 password-secret: ノード間のWeave Net通信の暗号化に使うパスワードを保持するSecret名。指定しないと平文。(参考: https://www.weave.works/docs/net/latest/tasks/manage/security-untrusted-networks/) IPALLOC_RANGE: Podに割り当てるIPアドレスの範囲。指定しないと10.32.0.0/12。 CHECKPOINT_DISABLE: Weave Netのアップデートを定期的にチェックする機能の無効化オプション。 WEAVE_MTU: MTUを指定するオプション。デフォルトで1376バイト。  
WEAVE_MTUはとりあえずデフォルトにしておいて、IPALLOC_RANGEもデフォルトにして、通信暗号化して、CHECKPOINT_DISABLEをtrueにするとすると、マニフェストは以下のようにダウンロードできる。
# curl -fsSLo weave-daemonset.</description>
    </item>
    
    <item>
      <title>Kubernetes 1.10をスクラッチから全手動で構築</title>
      <link>https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/</link>
      <pubDate>Tue, 17 Apr 2018 00:31:48 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/</guid>
      <description>Oracle Linux 7.4.0のVMでKubernetes 1.10.0のクラスタをスクラッチから全手動で作った。 参考にしたのは主に以下。
 https://nixaid.com/deploying-kubernetes-cluster-from-scratch/ https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.10.md https://kubernetes.io/docs/getting-started-guides/scratch/ https://kubernetes.io/docs/reference/setup-tools/kubeadm/implementation-details/ https://ulam.io/blog/kubernetes-scratch/ https://docs.microsoft.com/en-us/virtualization/windowscontainers/kubernetes/creating-a-linux-master  (2019/1/17追記: クラスタ全手動構築手順はKubernetes 1.13になってもほとんど変わっていない。ユニットファイルに指定するオプションが多少減ったりしたくらい。 また、ホストがRHELでもほとんど変わらない。インストールするDockerがDocker-CE(もしくはRedhatのやつ)に変わるくらいで、あとはkubeletの--cgroup-driverをsystemdにしないといけなかったかも。)    (adsbygoogle = window.adsbygoogle || []).push({});  構成  マシン: Windows 10 Homeのラップトップの上のVMware PlayerのVM  CPU: 2コア メモリ: 4GB NIF: NATのを一つ  OS: Oracle Linux 7.4.0  Minimalインストール IPアドレス: 192.168.171.200、静的割り当て ホスト名: k8s-master (hostsで解決)  Docker: Oracle Container Runtime for Docker (docker-engine) 17.06.2 Kubernetes: バージョン1.10.0  単一ノード 全コンポーネント(kubelet、kube-proxy、kube-apiserver、kube-controller-manager、kube-scheduler、etcd)をsystemdで起動 (i.e. 非コンテナ)  kubeletとkube-proxy以外は非rootユーザ kubeletは現時点でrootで動かす必要がある kube-proxyはiptableいじったりする都合上rootで動かす必要があるっぽい。  コンポーネント間通信とkubectlの通信をTLSで暗号化  TLS 1.</description>
    </item>
    
    <item>
      <title>Skaffoldを触ってみた</title>
      <link>https://www.kaitoy.xyz/2018/04/01/hello-skaffold/</link>
      <pubDate>Sun, 01 Apr 2018 09:59:43 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2018/04/01/hello-skaffold/</guid>
      <description>Skaffoldを試してみた話。
   (adsbygoogle = window.adsbygoogle || []).push({});  Skaffoldとは Googleが開発している、Kubernetesアプリケーションを快適に開発するためのツール。 アプリケーションのソースを監視し、変更が入ると、自動的にコンテナイメージをビルドしてKubernetesクラスタにデプロイしてくれる。
2018/3/16に発表された新しいツールで、触った感じではまだこれからといった感じだった。
Goで書かれていて、Linux、OS X、Windows用のバイナリが提供されている。
似たツールにはMicrosoftのDraftがある。
また、Gitのコミットを自動デプロイしてくれるものに、Gitkube、Jenkins X (エックス)がある。
Windows版を試す 自PCがWindowsなのでWindows版を試す。 会社で使ってるのもWindowsだし。
Skaffoldを使うには、Skaffoldの実行バイナリ、Kubernetesクラスタ、そのクラスタをコンテクストに設定したkubectl、Dockerが必要。
まずWindows版Skaffoldをインストールする。 GitHubのリリースページからWindowsバイナリをダウンロードして、skaffold.exeにリネームしてPATHの通ったところに置くだけ。 Skaffoldのバージョンは0.3.0。

Kubernetesクラスタは、Windows 10 Home上にminikube 0.22.2で作ったKubernetes 1.7.0のクラスタ。 minikubeは以前インストールしたものを使う。
minikubeを起動。
&amp;gt; minikube start --kubernetes-version v1.7.0 kubectlもminikubeと一緒にインストール済み。

Dockerについては、デーモンはminikube上のを使えばいいとして、クライアント(Docker Client)はskaffoldコマンドから実行するのでWindows上にないとだめはなず。
WindowsでDockerと言えば今ならDocker for Windowsだけど、これはWindows 10 Proじゃないと使えなかったはずなので、Docker Toolboxでクライアントをいれた。
このクライアントはデフォルトではローカルのデーモンを見てるので、minikubeのデーモンを見させる。 そのための設定はminikubeのコマンドで分かるようになっている。
&amp;gt; minikube docker-env SET DOCKER_TLS_VERIFY=1 SET DOCKER_HOST=tcp://192.168.99.100:2376 SET DOCKER_CERT_PATH=C:\Users\kaitoy\.minikube\certs SET DOCKER_API_VERSION=1.23 REM Run this command to configure your shell: REM @FOR /f &amp;#34;tokens=*&amp;#34; %i IN (&amp;#39;minikube docker-env&amp;#39;) DO @%i これに従って以下のコマンドを実行するとクライアントの設定完了。</description>
    </item>
    
    <item>
      <title>Kubernetes 1.8のアクセス制御について。あとDashboard。</title>
      <link>https://www.kaitoy.xyz/2017/10/31/retry-dashboard-on-k8s-cluster-by-kubeadm/</link>
      <pubDate>Tue, 31 Oct 2017 16:57:04 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2017/10/31/retry-dashboard-on-k8s-cluster-by-kubeadm/</guid>
      <description>「Kubernetes1.8のクラスタを構築する。kubeadmで。」で、Dashboardがうまく動かない問題が発生したんだけど、それを解決した話。
   (adsbygoogle = window.adsbygoogle || []).push({});  問題の現象 kubeadmでKubernetesクラスタを組んで、自前のアプリ(Goslings)のデプロイまではうまくできたんだけど、Dashboardをデプロイしたら動かず、Web UIにkubectl proxy経由でつないでもタイムアウトしてしまった。
対策 なんとなく、クラスタ内部での名前解決にはkube-dnsによるDNSサービスが使われているっぽいので、/etc/hostsに余計な事書いたのがいけなかったと思った。
ので、/etc/hostsからk8s-masterとk8s-nodeのエントリを削除してから、kubeadm initからやり直してみた。
結果 したらちゃんと動いた。
VMのホストでkubectl proxyして、
C:\Users\kaitoy\Desktop&amp;gt;kubectl proxy Starting to serve on 127.0.0.1:8001 http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/にブラウザでつないだらサインイン画面が表示された。

Dashboardのサインイン処理はKubernetes(というかkube-apiserver)のそれに移譲している。 Dashboardはそこで認証されたユーザでクラスタのリソースにアクセスし、情報を取得して表示する。多分。
Dashboardへのサインイン方法はいくつかあるが、それらを理解するにはKubernetesのアクセス制御について学ぶことを推奨とあったのでちょっとKubernetesのドキュメントを読んだ。
Kubernetesのアクセス制御 Kubernetesクラスタのエンドポイントはkube-apiserverであり、クラスタのリソースへのアクセス制御もkube-apiserverがやる。 クライアントとkube-apiserverとのTLSセッションが確立した後、HTTP層のデータを見てアクセス制御をするんだけど、その処理はAuthentication(認証)、Authorization(認可)、Admission(許可)の三段階からなる。
Authentication 第一段階がAuthentication。 ここでは、kube-apiserverに仕込まれたAuthenticatorモジュールがユーザ認証をする。
Kubernetesが認証するユーザには、Kubernetesが管理するService Accountと、クラスタ外部で管理される通常ユーザの二通りがある。 Service AccountはPodがkube-apiserverと話すためのユーザで、通常ユーザは主に人がkubectlとかでkube-apiserverと話すためのユーザ。(匿名で話すこともできる。) 前者はServiceAccountオブジェクトで定義されるけど、後者用のオブジェクトはない。
ServiceAccountはNamespaceと関連付き(つまりnamespace毎にユニーク)、Secretに紐づく。 Secretオブジェクトはクレデンシャルのセットを定義し、Podにマウントされる。 ServiceAccountとSecretは、ふつうは自動で作られ、Podに割り当てられる。
kube-apiserverには一つ以上のAuthenticatorモジュールを設定できて、どれかで認証できれば次の段階に進める。 認証失敗するとHTTPステータスコード401が返る。
Authenticatorモジュールには以下のようなものがある。
 クライアント証明書: X.509のディジタル証明書を使うモジュール。kube-apiserver起動時に--client-ca-fileオプションで証明書ファイルを渡してやると有効になる。証明書のCommon Nameがユーザ名になり、Organizationがグループになる。クライアント側は、その証明書と対応する秘密鍵をクレデンシャルとして指定する。 Bearer Token: 無記名トークンを使うモジュール。kube-apiserver起動時に--token-auth-fileオプションでトークン情報を渡してやると有効になる。トークン情報はCSVで、「token,user,uid,&amp;quot;group1,group2,group3&amp;quot;」という形式で書く。クライアント側は、トークン文字列をクレデンシャルとして指定する。 ベーシック認証: ユーザ名とパスワードで認証するモジュール。kube-apiserver起動時に--basic-auth-fileオプションでユーザ名とパスワードのリストを渡してやると有効になる。このリストはCSVで、「password,user,uid,&amp;quot;group1,group2,group3&amp;quot;」という形式で書く。クライアント側は、ユーザ名とパスワードをクレデンシャルとして指定する。HTTPクライアントの時はAuthorizationヘッダが使える。 Service Account Token: Service Accountを署名付きBearer Tokenで認証するモジュール。デフォルトで有効になる。  このあたり、Qiitaの「kubernetesがサポートする認証方法の全パターンを動かす」という記事をみると理解が深まる。
Authorization Authenticationをパスすると、クライアントのユーザ(とグループ)が認証され、第二段階のAuthorizationモジュールの処理に移る。 ここでは、リクエストの内容(操作対象、操作種別(メソッド)等)を見て、それがユーザに許されたものなら認可する。 何を許すかは事前にクラスタにポリシーを定義しておく。</description>
    </item>
    
    <item>
      <title>Kubernetes1.8のクラスタを構築する。kubeadmで。</title>
      <link>https://www.kaitoy.xyz/2017/10/21/build-kubernetes-cluster-by-kubeadm/</link>
      <pubDate>Sat, 21 Oct 2017 10:42:46 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2017/10/21/build-kubernetes-cluster-by-kubeadm/</guid>
      <description>「Kubernetes 1.8が出たので、Minikubeを触ってみる」でMinikubeをやったんだけど、もう一歩ステップアップすべく、kubeadmでKubernetesクラスタを組んでみた話。
   (adsbygoogle = window.adsbygoogle || []).push({});  kubeadmとは kubeadm(キューブアダム)はKubernetesに含まれるコマンドで、Kubernetesクラスタを簡単に構築するツール。 Kubernetes 1.4で追加され、Kubernetes 1.8の時点でまだベータで、本番環境には使わないでとなっている。 Qiitaの「kubeadmが何をやっているのかみてみた」という記事が、中でどんな動作をしてるかを解説していて参考になる。
コマンドの使用感からすると、DockerのSwarmモードでのクラスタ構築の容易さをKubernetesに取り込むことを目指して開発されている気がした。
ネットで見かけた評判だと、確かに簡単にクラスタ構築できて素晴らしいけど、TLSの証明書生成など、細かく制御できなくて困るところがあって、やはり本番に使えるレベルではないとのこと。
まあとにかく試してみる価値はあろう。
kubeadmインストール Kubernetesのドキュメントに従ってkubeadmをインストールする。 バージョンは最新版の1.8.1。
VM作成 kubeadmのサポートOSは、Ubuntu 16.04+、Debian 9、CentOS 7、RHEL 7、Fedora 25/26、HypriotOS v1.0.1+となっている。 慣れているCentOS 7を使うことにする。 (HypriotOSってなんだろう?)
自前のノートPCのWindows 10 x64 Home Edition上のVMware Player 12のVMにCentOS 7を入れた。 メモリは1GB以上が要件なので、味を付けて1.4GBで。 VM間で通信できることって要件があったけど、インターネット接続も必要なはずなので、NICはNATのやつで。
このVMはMasterになる。
OS設定 Kubernetesが使うポートをいろいろ開けなければいけないんだけど、めんどいのでfirewalldを無効にする。
# systemctl stop firewalld # systemctl disable firewalld Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service. Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service. 
なんとなくIPアドレスをDHCPから静的割り当てに。(192.168.171.200)
# nmcli c modify ens33 ipv4.method manual # nmcli c modify ens33 ipv4.</description>
    </item>
    
    <item>
      <title>Kubernetesのチュートリアルをやる</title>
      <link>https://www.kaitoy.xyz/2017/10/11/goslings-on-kubernetes-cont/</link>
      <pubDate>Wed, 11 Oct 2017 23:48:40 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2017/10/11/goslings-on-kubernetes-cont/</guid>
      <description>「Kubernetes 1.8が出たので、Minikubeを触ってみる」の続き。 Minikubeのセットアップまではできたので、Kubernetes Basicsというチュートリアルをやりながら、Goslingsをデプロイする。
   (adsbygoogle = window.adsbygoogle || []).push({});  Kubernetes Basics - 概要 Kubernetes Basicsは、公式のチュートリアルで、Kubernetesクラスタのオーケストレーションの基本を学ぶことができるもの。 以下の6つのモジュールからなる。
 Kubernetesクラスタを作る アプリをデプロイする アプリを調査する アプリを公開する アプリをスケールする アプリをアップデートする  チュートリアルで使うのはMinikubeだけど、自分でセットアップする必要はない。 Katacodaという、ブラウザ上でIT技術を学べるプラットフォームがあり、Kubernetes Basicsはそれを利用して、ブラウザ上のターミナルからホステッドMinikubeを操作できるようにしている。
が、前回の記事で自PC上にMinikubeをセットアップしたので、そちらを使うことにする。

Kubernetes Basics - モジュール 1: Kubernetesクラスタを作る Minikubeを起動してkubectlでクラスタの状態をみるだけのモジュール。
これは前回の記事でカバーしている。
Kubernetes Basics - モジュール 2: アプリをデプロイする アプリ(i.e. コンテナ)をデプロイするにはDeploymentオブジェクトを作る。 MasterはDeploymentのspecに従って各ノードにアプリのインスタンスをスケジューリングする。 Deploymentは、アプリが落ちたら再起動してくれる、つまりself-healingも実現する。
Deploymentオブジェクトを作るコマンドはkubectl run &amp;lt;オブジェクト名&amp;gt; --image=&amp;lt;Dockerイメージ名&amp;gt;。 Goslingsをこれでデプロイする。
Goslingsコンテナは3つの引数を受け取り、指定したポートでWebサーバを起動する。 --portオプションでそのポートをexposeするようにして、--の後にコンテナに渡す引数を記述する。
C:\Users\kaitoy&amp;gt;kubectl run goslings --image=kaitoy/goslings:latest --port 8080 -- 8080 /tmp https://github.com/kaitoy/ deployment &amp;#34;goslings&amp;#34; created C:\Users\kaitoy&amp;gt;kubectl get deployment NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE goslings 1 1 1 1 27s デプロイできた。 裏でPodも作られていて、アプリが起動されている。</description>
    </item>
    
    <item>
      <title>Kubernetes 1.8が出たので、Minikubeを触ってみる</title>
      <link>https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/</link>
      <pubDate>Tue, 10 Oct 2017 00:10:59 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/</guid>
      <description>Kubernetes1.8のリリースが話題になっていたので、ちょっと触って見たという話。 (1.8を触ったとは言っていない。)
具体的には、Kubernetes Basicsというチュートリアルをやりながら、MinikubeにGoslingsをデプロイしたんだけど、この記事ではMinikubeをセットアップしたところまで。
   (adsbygoogle = window.adsbygoogle || []).push({});  Kubernetesとは KubernetesはOSSのコンテナオーケストレーションツール。 英語だとクーバネティスみたいに発音する。 Googleが自身のコンテナ技術であるBorgの運用で培ったノウハウを活かして開発したもの。 2014年ころに開発が始まり、2015年夏にv1がリリースされたということで、かなり新しいツール。 よく比べられるものにはDockerのSwarmモードやApache Mesosがあるが、何が違うのかは調べてないので知らない。 ただ、Dockerコンテナ管理ツールとしてはKubernetesが一番勢いがある雰囲気を感じる。
(2017/10/18追記: DockerがKubernetesとの統合を発表した。KubernetesはDockerネイティブなツールになり、Dockerとともにインストールされ、Docker ComposeのConposeファイルでデプロイできるようになったりする。Kubernetesの大勝利っぽい。)
Kubernetesを使うと、複数の物理マシンからなるHAクラスタ(Kubernetesクラスタ)を構成し、その上にコンテナをデプロイして管理できる。 Kubernetesクラスタは、一組のMasterコンポーネント群(a.k.a. Kubernetes Control Plane、または単にMaster)と一つ以上のNode(昔はMinionと呼ばれてたもの)で構成される。 Nodeは、Masterの管理下でコンテナを実行する機能を備えた、一台のVMや物理マシン。 MasterはNode上で動き、クラスタを管理し、コンテナのスケジューリング、状態管理、スケーリング、アップデートなどを担う。
Kubernetesのアーキテクチャを図にすると以下の感じ。 矢印の向きとかはちょっと間違ってるかも。
ごちゃごちゃするので省いたけど、図の下部のNode内のコンポーネントは、他のNode内でも動いている。

Masterにはkube-apiserverが含まれていて、Kubernetes APIというREST APIを公開する。 このAPIを通してKubernetesオブジェクトを定義したりすることで、宣言的にコンテナの管理ができる仕組み。 ユーザは普通、kubectl(キューブシーティーエル)というコマンドでkube-apiserverとやり取りする。
KubernetesオブジェクトはMasterのetcdによって分散キーバリューストアに永続化され、そのストアをkube-controller-managerとkube-schedulerが(kube-apiserver経由で)watchしてて、変更に応じた処理をする。
kube-controller-managerは、ノードの管理や、オブジェクトのライフサイクルの管理や、コンテナのスケーリングなど、クラスタレベルの機能を実行する。 (よくわからない。)
kube-schedulerは、コンテナを実行するホストを選出し、コンテナのスケジューリングをする。

一方、各Nodeでは、kubelet(キューブレット)というMasterのエージェントになるプロセスが動く。
kubeletはkube-apiserverからの指示で、コンテナイメージを取得してコンテナを起動したり監視したり止めたりする。
kubeletがコンテナを扱うためのコンテナランタイムは、普通はDockerだけど、rktとかcri-oとかfraktiとかも使える。runcやRailCarはどうなんだろう。
コンテナはデフォルトではクラスタ内のプライベートネットワークにつながるので、そこで動いているアプリにユーザからアクセスするには、何らかの形でトラフィックを中継してやる必要がある。 これをするのがkube-proxy。 ロードバランシングもしてくれる。
Kubernetesオブジェクトとは Kubernetesオブジェクトは、Kubernetesクラスタ上で機能する構成要素を表現するもの。 オブジェクトはspecとstatusを持ち、オブジェクトに期待する状態やふるまい(spec)を定義しておくと、Kubernetesが実際の状態(status)をそれに合わせてくれる。 宣言的。
オブジェクトには以下のようなものがある。
 Pod
デプロイの最小単位。 一つ(またはリソースを共有する複数)のコンテナと、ストレージ、ネットワークなどを内包する。 一つのPodには一つのIPアドレスが付く。
kubeletはPodの定義に従ってコンテナを起動する。
因みに、etcd以外のMasterコンポーネントもPodとしてデプロイされる。
 Service
Podの論理グループ。 PodのIPアドレスは外部に公開されないので、外とのやり取りをするためにServiceがある。 kube-proxyはこいつの定義に従って働く。
Serviceには複数のEndpoint(i.e. Pod等)が紐づき、外部からのトラフィックをラウンドロビンでルーティングするので、冗長化やロードバランサ的な働きもする。 ServiceはPodを抽象化するので、Podが死んだり入れ替わったりしても外に影響が見えにくくなる。</description>
    </item>
    
    <item>
      <title>WebdriverIOとChromeのヘッドレスモードで自動ブラウザテストするDockerイメージ: webdriverio-chrome</title>
      <link>https://www.kaitoy.xyz/2017/08/14/webdriverio-chrome/</link>
      <pubDate>Mon, 14 Aug 2017 10:53:17 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2017/08/14/webdriverio-chrome/</guid>
      <description>「2017年夏、ブラウザテストフレームワーク」の続き。 ServiceNowアプリケーションのブラウザテストをしたくて色々調べている。 前回は、フレームワークにWebdriverIOを使うと決めたところまで書いた。
今回、最終的に、WebdriverIO、WDIO、selenium-standalone、Jasmineと、Chromeのヘッドレスモードを使って、Dockerコンテナ(Alpine Linux)上でテストスクリプトを実行して、ServiceNowのログイン画面のスクリーンショットが取れるところまでできた。
そのコンテナイメージのDockerfileはGitHubに置いた。
   (adsbygoogle = window.adsbygoogle || []).push({});  とりあえずAlpine Linux テスト環境の作成は自宅でやってるけど、DockerイメージにしてDocker Hubとかに上げておけば、社内でダウンロードしてそのまま再現できる。 ダウンロードに係る社内手続きも、Dockerイメージだけに対してやればいいので、中に何を詰め込んでも、後でライブラリとか追加しても、一回こっきりで済む。
というわけでWebdriverIO環境をDockerコンテナとしてつくることにする。 とりあえず、自PC(Windows 10 Home x64)に入ってるVMware Workstation Player 12.5.5でCentOS 7 x64のVMを作り、そこにDockerをインストールした。
次に、そのDockerを使って、WebdriverIO環境のベースにするAlpine Linuxをpullする。
$ docker pull alpine:edge 
Alpine LinuxはBusyBoxとmusl libcで構成された軽量な Linuxディストリビューション。 2016年2月にすべてのオフィシャルDockerイメージがAlpine Linuxベースになるというアナウンスがあったし、他にそれっぽいものもなかったので、これをベースに環境を作ることにした。 glibcじゃないのがちょっと気になるけど、まあ問題ないか。
現在、Chrome 59のAlpine Linuxパッケージはedgeブランチ(i.e. 開発ブランチ)でしか作られていない。 pullするタグをedgeにしたのはそのため。 (因みに現時点でAlpine Linuxのlatestは3.6。)
で、起動。
$ docker run -it alpine:edge sh Chrome(Chromium)インストール まずはChrome(がAlpine Linuxパッケージにはないので、実際にはChromium)と、ついでにChromeDriverをインストールする。 Alpine Linux独自のパッケージマネージャーであるapkを使う。
コンテナ内:
# apk add --update chromium chromium-chromedriver # chromium-browser -version Chromium 59.</description>
    </item>
    
    <item>
      <title>Pcap4J on Nano Server on Hyper-V Containers on Windows 10 on VMware Playerにトライ</title>
      <link>https://www.kaitoy.xyz/2016/09/15/pcap4j-on-hyper-v-container-on-win10/</link>
      <pubDate>Thu, 15 Sep 2016 13:56:35 -0600</pubDate>
      
      <guid>https://www.kaitoy.xyz/2016/09/15/pcap4j-on-hyper-v-container-on-win10/</guid>
      <description>Pcap4Jが動くHyper-VコンテナをWindows 10上でビルドしようとしたけど3合目あたりで息絶えた話。

   (adsbygoogle = window.adsbygoogle || []).push({});  Hyper-V Containersとは Hyper-V Containersは、MicrosoftによるWindowsネイティブなコンテナ技術であるWindows Containersの一種で、これによるコンテナは、同じくWindows Containersの一種であるWindows Server Containersのものに比べて、より厳密に隔離されている分、起動コストが高い。
実体はDockerそのもので、コンテナイメージはDocker Hubからpullできるし、コンテナの操作や管理はdockerコマンドでやる。(昔はコンテナ操作用PowerShellコマンドレットもあったが、不評だったので廃止したようだ。) ソースもLinuxとWindowsで一本化されている。
Windows 10のAnniversary Updateで正式にリリースされたが、なんだかあまり注目されていない気がする。
Docker for Windowsとは全く別物なので注意。
Hyper-V Containersのインストール (on VMware Player) 自前のPCが5年前に買ったdynabookでWindows 10をサポートしていないので、VMware PlayerのVM上のWindows 10にHyper-V Containersをインストールしてみる。
VMは、Windows 7に入れたVMware Workstation 11.1.0 build-2496824に付属の VMware Player 7.1.0 build-2496824で作ったもの。 VMのバージョンは11.0。 2CPUでメモリは2.5GB。 ネットワークインターフェースはNAT。 このVMを、Hyper-Vが使えるように設定しておく。
この記事にしたがい、Windows 10の評価版をダウンロード。 今公開されている評価版はAnniversary Update適用済みのバージョン1607で、Hyper-V Containersをサポートしている。
これをさっき作ったVMにインストール。
Windows 10を起動し、以下、Windows Containers on Windows 10に従って進める。
 containers機能有効化
PowerShellプロンプトを管理者権限でひらき、以下のコマンドでcontainers機能を有効化。
Enable-WindowsOptionalFeature -Online -FeatureName containers -All 1分程度経つと再起動を促されるので再起動。</description>
    </item>
    
    <item>
      <title>Hyper-Vコンテナ(Nano Server)でunzipしたいならjarを使え</title>
      <link>https://www.kaitoy.xyz/2016/09/12/unzip-on-nanoserver/</link>
      <pubDate>Mon, 12 Sep 2016 16:46:54 -0600</pubDate>
      
      <guid>https://www.kaitoy.xyz/2016/09/12/unzip-on-nanoserver/</guid>
      <description>Nano Serverでunzipしたかっただけだったのに、妙に苦労した話。

   (adsbygoogle = window.adsbygoogle || []).push({});  Nano Serverとは Nano Serverは、Windows Server 2016で追加されるWindows Serverの新たなインストール形式で、Server Coreよりさらに機能を絞り、リモートで管理するクラウドホストやWebサーバ向けにに特化したもの。
Server Coreが数GBくらいなのに対し、Nano Serverは数百MBととても軽量で、それゆえ起動が速くセキュア。
unzipとは unzipとは、[zip](https://ja.wikipedia.org/wiki/ZIP_(%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%83%95%E3%82%A9%E3%83%BC%E3%83%9E%E3%83%83%E3%83%88)ファイルを解凍する、ただそれだけのこと。
ただそれだけのことで、基本的な機能だと思うのだが、Windowsはこれをコマンドラインで実行する方法をつい最近まで正式に提供していなかった。
Nano Serverでunzip Windows 10のHyper-V Containersの上でPcap4JのビルドとテストをするDockerイメージをビルドしたくて、そのための依存ライブラリなどをインストールする処理をDockerfileに書いていて、ADDでzipをダウンロードしたところまではいいんだけど、このzipどうやって解凍してやろうかとなった。 (Dockerホストに置いたものをコンテナにADDするのはなんか格好悪いから無しで。Dockerfile裸一貫で実現したい。)
Windows 10のHyper-V Containersは、現時点でNano Serverしかサポートしていないのが厳しい点。Server Coreだったら楽だったのに。

以下、いろいろ試したことを書く。
正攻法: Expand-Archive PowerShellの v5 で実装されたExpand-Archiveというコマンドレットでzipを解凍できる。 Nano ServerのPowerShellのバージョンを確認したら 5.1 だったのでこれでいけるかと思った。
C:\&amp;gt;powershell -command &amp;#34;$PSVersionTable.PSVersion&amp;#34; Major Minor Build Revision ----- ----- ----- -------- 5 1 14284 1000 
したらこのエラー。
Add-Type : Cannot find path &amp;#39;C:\System.</description>
    </item>
    
    <item>
      <title>Docker for Windowsがコレジャナかった</title>
      <link>https://www.kaitoy.xyz/2016/07/31/docker-for-windows/</link>
      <pubDate>Sun, 31 Jul 2016 14:34:16 -0600</pubDate>
      
      <guid>https://www.kaitoy.xyz/2016/07/31/docker-for-windows/</guid>
      <description>7/28にDocker for Winodws(とDocker for Mac)の正式版リリースのアナウンスがあったので試してみたけど、期待していたものと違ったしなんだか上手く動かなかった話。

   (adsbygoogle = window.adsbygoogle || []).push({});  Docker for Windowsとは Docker for WindowsはDocker Toolboxの後継製品。(多分。)
Docker ToolboxはWindowsやMacでDockerを使うための製品で、以下のコンポーネントからなる。
 Docker Engine
コンテナランタイム。
 Docker Compose
複数のコンテナを組み合わせたアプリケーション/サービスの構築/管理ツール。
 Docker Machine
Docker仮想ホストのプロビジョニング/管理ツール。
 Kitematic
Dockerコンテナを管理するGUIを提供する製品。 Docker Machineと連携してローカルマシンへのDocker仮想ホストのプロビジョニングもしてくれる。
  Docker Toolboxを使うと、VirtualBoxのLinux VMをWindows/Mac上にプロビジョニングして、そのVMにDockerをインストールして、Windows/Macから利用できる。
Docker for Windowsもだいたい同じで、Docker EngineとDocker ComposeとDocker MachineをWinodwsで利用するための製品。 ElectronベースでOracleのVirtualBox依存なKitematicの代わりに、ネイティブなインストーラがWindows内蔵のHyper-Vを使ってDockerをセットアップしてくれる。 Hyper-Vを使うため、VirtualBoxより速くて高信頼らしい。 KitematicはDocker for Windowsには付属しないが、別途ダウンロードすればコンテナ管理に使える。Docker for WindowsとDocker Toolboxとは共存はできない。
私は勝手にDocker for WindowsはHyper-V ContainersのデスクトップOS版のようなものかと勘違いしていて、Windowsのコンテナが使えるようになったのかと期待したが違った。 Docker for Windowsは単にDocker ToolboxのVirtualBoxがHyper-Vになっただけのもので、結局Linux VMの中でDockerを使うだけのものだということにセットアップ中に気付いた。</description>
    </item>
    
    <item>
      <title>Windows Server 2016 TP5でWindows Containersにリトライ</title>
      <link>https://www.kaitoy.xyz/2016/07/11/windows_containers_on_tp5/</link>
      <pubDate>Mon, 11 Jul 2016 00:30:33 -0600</pubDate>
      
      <guid>https://www.kaitoy.xyz/2016/07/11/windows_containers_on_tp5/</guid>
      <description>Windows Server 2016のTechnical Preview 5(TP5)が公開されていたので、 TP4でバグに阻まれて挫折した、Windows ContainersでPcap4Jを使ってパケットキャプチャする試みにリトライした話。

   (adsbygoogle = window.adsbygoogle || []).push({});  OSセットアップ TP4のときと同じ環境。
以降はWindows Server Containersのクイックスタートガイドに沿ってセットアップを進める。 TP4からは大分変わっていて、単一のPowershellスクリプトを実行する形式から、Powershellのコマンドレットを逐次手動実行する形式になっている。 面倒だけど何やってるかわかりやすくて好き。
コンテナ機能のインストール  管理者権限のパワーシェルウィンドウを開く
コマンドプロンプトから以下のコマンドを実行。
powershell start-process powershell -Verb runas コンテナ機能のインストール
開いた青いパワーシェルウィンドウで以下のコマンドを実行するとコンテナ機能がインストールされる。
Install-WindowsFeature containers 数分で終わる。
インストールされたのはHyper-V ContainersじゃなくてWindows Server Containersの方。 クイックスタートガイドをみると、前者がWindows 10向け、後者がWindows Server向けというように住み分けされているっぽい。TP4では両方ともWindows Serverで使えたんだけど。
 再起動
変更を有効にするために再起動が必要。
Restart-Computer -Force  Dockerインストール Dockerは、コンテナイメージの管理やコンテナの起動などもろもろの機能を提供するDockerデーモンと、その機能を利用するためのCLIを提供するDockerクライアントからなる。この節ではそれら両方をインストールする。
 Dockerインストールフォルダ作成
管理者権限のパワーシェルウィンドウを開いて、以下のコマンドでDockerインストールフォルダを作成。
New-Item -Type Directory -Path &amp;#39;C:\Program Files\docker\&amp;#39; Dockerデーモンインストール
まずはデーモンの方をインストール。
Invoke-WebRequest https://aka.ms/tp5/b/dockerd -OutFile $env:ProgramFiles\docker\dockerd.exe -UseBasicParsing 数分。</description>
    </item>
    
    <item>
      <title>Pcap4J Meets Windows Containers</title>
      <link>https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/</link>
      <pubDate>Fri, 22 Jan 2016 17:46:43 -0700</pubDate>
      
      <guid>https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/</guid>
      <description>Windows Containers で Pcap4J のコンテナをビルドしてみた話。

   (adsbygoogle = window.adsbygoogle || []).push({});  Windows Containersとは Windows Containersは、MicrosoftがDocker, Incと提携して開発しているコンテナ技術で、Windows版Dockerとも言われる機能。 今年リリースされる Windows Server 2016 に実装される予定で、その3つめのテクニカルプレビューである Windows Server 2016 Technical Preview 3 (2015/8/19公開)から評価できるようになった。
Windows Containersには次の二種類がある。
 Windows Server Containers
プロセスと名前空間の分離を実現する機能で、これによるコンテナはカーネルをホストと共有する。 つまり本家Dockerに近い形の機能。
 Hyper-V Containers
それぞれのコンテナを軽量化されたHyper-Vの仮想マシンっぽいものの上で動かす機能。 このコンテナの実行にはHyper-Vが必要。 Windows Server Containersよりコンテナ間の分離性が高く、カーネルの共有もしないが、そもそもそれってコンテナなの?
  どちらも同じようなインターフェースで操作でき、このインターフェースにはPowershellのコマンドレットとDockerコマンドの二種類がある。
より詳しくは、Microsoftによる解説や@ITのこの記事がわかりやすい。 また、Qiitaのこの記事がDockerとWindows Server Containersのアーキテクチャを詳細に説明していて面白い。
Windows Containersセットアップ まず、Windows 7 x64のノートPCにVMware Player 7.1.0を入れてWindows 10 x64用のVM(CPU2つとメモリ2.5GB)を作り、そこに2015/11/19に公開された Windows Server 2016 Technical Preview 4 をインストール。 コマンドでいろいろ設定するの慣れていないのでGUI(Desktop Experience)付きで。 (リモートデスクトップ使えばよかったのかもしれないけど。) ロケールは英語以外は問題が起きそうなので英語で。</description>
    </item>
    
    <item>
      <title>Another way to capture LAN packets with pcap4j container</title>
      <link>https://www.kaitoy.xyz/2015/07/27/another-way-to-capture-lan-packets-with-pcap4j-container/</link>
      <pubDate>Mon, 27 Jul 2015 23:41:49 -0600</pubDate>
      
      <guid>https://www.kaitoy.xyz/2015/07/27/another-way-to-capture-lan-packets-with-pcap4j-container/</guid>
      <description>2 days ago, I posted an article How to capture packets on a local network with Pcap4J container.
Today, I was reading Docker Docs and found another way to do it. I&amp;rsquo;m writing about it here.

   (adsbygoogle = window.adsbygoogle || []).push({});  &amp;ndash;net option for docker run When we start a docker container we use docker run command. It accepts some options. --net is one of them, which is to set a network mode for a container.</description>
    </item>
    
    <item>
      <title>How to capture packets on a local network with Pcap4J container</title>
      <link>https://www.kaitoy.xyz/2015/07/25/how-to-capture-packets-on-a-local-network-with-pcap4j-container/</link>
      <pubDate>Sat, 25 Jul 2015 19:05:06 -0600</pubDate>
      
      <guid>https://www.kaitoy.xyz/2015/07/25/how-to-capture-packets-on-a-local-network-with-pcap4j-container/</guid>
      <description>I&amp;rsquo;ll show how to capture packets on a local network with Pcap4J container.

   (adsbygoogle = window.adsbygoogle || []).push({});  Docker network By default, Docker containers are not connected to a local network. They are connected only to a virtual network Docker creates as like below:
  Refer to the Docker doc for more details.
What&amp;rsquo;s a challenge In order to let a Pcap4J container capture packets in a local (real) network, we need to directly connect the container to the local network, because docker0 forwards only packets the destinations of which are in the virtual network.</description>
    </item>
    
    <item>
      <title>Pcap4J container with runC</title>
      <link>https://www.kaitoy.xyz/2015/07/19/pcap4j-container-with-runc/</link>
      <pubDate>Sun, 19 Jul 2015 16:25:03 -0600</pubDate>
      
      <guid>https://www.kaitoy.xyz/2015/07/19/pcap4j-container-with-runc/</guid>
      <description>I tried to run a Pcap4J container with runC.

   (adsbygoogle = window.adsbygoogle || []).push({});  What is Pcap4J? Pcap4J is a Java library for capturing, crafting, and sending packets. It&amp;rsquo;s actually a Java wrapper for libpcap/WinPcap plus packet analyzer. We can see the details in its README.
What is runC? runC is a container runtime developed by Docker and released on June 22, 2015. With runC, we can start a container from a docker image without the docker service or the docker command.</description>
    </item>
    
  </channel>
</rss>