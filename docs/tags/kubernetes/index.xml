<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kubernetes on To Be Decided</title>
    <link>https://www.kaitoy.xyz/tags/kubernetes/</link>
    <description>Recent content in kubernetes on To Be Decided</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>© 2015 Kaito Yamada</copyright>
    <lastBuildDate>Fri, 08 Mar 2019 17:29:16 +0900</lastBuildDate>
    
	<atom:link href="https://www.kaitoy.xyz/tags/kubernetes/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ズンドコキヨシ with Kubernetes Operator - KubebuilderでKubernetes Operatorを作ってみた</title>
      <link>https://www.kaitoy.xyz/2019/03/08/k8s-zundoko-operator/</link>
      <pubDate>Fri, 08 Mar 2019 17:29:16 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2019/03/08/k8s-zundoko-operator/</guid>
      <description>Javaの講義、試験が「自作関数を作り記述しなさい」って問題だったから
「ズン」「ドコ」のいずれかをランダムで出力し続けて「ズン」「ズン」「ズン」「ズン」「ドコ」の配列が出たら「キ・ヨ・シ！」って出力した後終了って関数作ったら満点で単位貰ってた
&amp;mdash; てくも (@kumiromilk) 2016年3月9日 
久しぶりにズンドコしたくなったので、Kubebuilderを使って、KubernetesのOperatorとして動くZundoko Operatorを作ってみた。
   (adsbygoogle = window.adsbygoogle || []).push({});  Kubernetes Operatorとは KubernetesのOperatorというのはCoreOS社(現Red Hat)によって提唱された概念(実装パターン)で、KubernetesのAPIで登録されるKubernetesオブジェクトの内容に従って何らかの処理をするController (e.g. Deployment Controller)の一種。
Controllerが汎用的なのに対して、特定のアプリケーションに特化しているのが特徴。 アプリケーションごとの細かな設定をKubernetesオブジェクトで表現するために、KubernetesのAPIを拡張する。
APIを拡張するにはAPI Aggregationを使う方法とCustom Resource Definition (CRD)を使う方法がある。 API Aggregationは、Kubernetesオブジェクトをetcd以外で管理したり、WebSocketを使ったり、Kubernetesクラスタ外のAPIサーバを使う場合など、特殊な場合にも対応できる高度なやりかたで、大抵のユースケースではCRDで事足りる。 Operatorも普通はCRDを使う。(というかCRDを使うのがOperatorという人もいる。)
CRDとは KubernetesのAPIを簡単に拡張できる仕組みで、Kubernetesオブジェクト(リソース)を定義するKubernetesオブジェクト。
YAMLで、定義したいリソースの名前や型やバリデーションなんかを書いてkubectl applyすれば、そのリソースをKubernetesのREST APIとかkubectlで作成したり取得したりできるようになる。
Operatorの仕組み Operatorは、CRDで定義されたリソース(など)の作成、更新、削除を監視(watch)して、リソースの内容に応じた何らかの処理をするReconciliationループを回すPod。 普通、リソースはOperatorの管理対象のアプリケーションの状態を表す。 で、Operatorはリソースの内容とアプリケーションの状態が同じになるように、Reconciliationループ内でDeploymentを作ったりアプリケーションのAPIを叩いたりする。
ユーザとしては、アプリケーションの構成や設定をKubernetesのAPIで宣言的に統一的に管理できるようになって幸せになれる。
Operator作成ツール Operatorを作るツールとして以下がある。
   ツール Operator SDK Kubebuilder Metacontroller     開発元 Kubernetesコミュニティ製 CoreOS社製 GKEチーム製   GitHubスター数 1459 1009 506   開発言語 Go、Ansible、Helm Go 任意   特徴 プロジェクトテンプレート生成、ビルド、デプロイをするCLIツール。AnsibleでもOperatorを書けるのが面白い。Operator FrameworkとしてLifecycle Managerなどが提供されていたり、OperatorHub.</description>
    </item>
    
    <item>
      <title>Packer &#43; Ansible on Windows 10でKubernetes 1.10のクラスタ on VirtualBoxを全自動構築</title>
      <link>https://www.kaitoy.xyz/2018/06/17/packer-k8s/</link>
      <pubDate>Sun, 17 Jun 2018 23:22:33 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2018/06/17/packer-k8s/</guid>
      <description>「Kubernetes 1.10のクラスタを全手動で構築するのをAnsibleで全自動化した」の続きで、さらにPackerを組み合わせて、VM作成まで自動化した話。
AnsibleをWindows(MSYS2)で動かした話でもある。
書いたPackerテンプレートはGitHubに置いた。
   (adsbygoogle = window.adsbygoogle || []).push({});  Packerとは Packerは、様々な種類のVMを構築できるツール。 VagrantとかTerraformとかを開発しているHashiCorpが開発している。
テンプレートと呼ばれるビルド定義をJSONファイルに書いて、ビルド、プロビジョニング、ポストプロセスを実行して、アーティファクトと呼ばれるビルドの成果物を生成する。
ビルドのステップでは、VMを作成して、ハードウェア構成を設定したり、OSをインストールしたりする。
以下のような環境でVMを作れる。
 VirtualBox Hyper-V VMware Workstation VMware vSphere Hypervisor Docker AWS EC2  
プロビジョニングのステップでは、ビルドで作ったVMのOS上で指定された操作を実行し、ソフトウェアのインストールなどのセットアップ処理をする。
プロビジョニングには以下のようなツールを使える。
 Shell PowerShell Ansible Chef Puppet  プロビジョニングが終わるとアーティファクト(VMイメージファイルや、AWS EC2のAMI IDとか)が出力される。

ポストプロセスのステップでは、アーティファクトを入力として何らかの処理をして、最終的なアーティファクトを生成する。
ポストプロセスでは以下のような処理を実行できる。
 アーカイブ VagrantBox生成 AWS EC2へのインポート Docker push  
PackerはGoで書かれていてビルド済みのバイナリが配布されているので、ダウンロードページから落として PATHの通ったところに置くだけでインストールできる。

今回はPacker 1.2.4のWindows版をインストールした。
Packerのテンプレート概要 Packerのテンプレートにはビルド、プロビジョニング、ポストプロセスの定義を複数かけて、複数環境のVM生成を1ファイルで定義できる。
テンプレートには以下のプロパティを書く。
 builders: ビルドの定義のリスト。 description: テンプレートの説明。 min_packer_version: Packer の最低バージョン指定。 post-processors: ポストプロセスの定義のリスト。 provisioners: プロビジョニングの定義のリスト。 variables: テンプレート内で使う変数の定義。 _comment: コメントなどを書くためのプロパティ。実際はアンダースコアで始まればなんでもいい。JSON オブジェクトのルートレベルのみで使える。  これらのうち、必須なのはbuildersだけ。</description>
    </item>
    
    <item>
      <title>Kubernetes 1.10のクラスタを全手動で構築するのをAnsibleで全自動化した</title>
      <link>https://www.kaitoy.xyz/2018/06/03/build-k8s-cluster-by-ansible/</link>
      <pubDate>Sun, 03 Jun 2018 17:14:07 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2018/06/03/build-k8s-cluster-by-ansible/</guid>
      <description>「Kubernetes 1.10をスクラッチから全手動で構築」、「Kubernetes 1.10のクラスタにWeave Netをデプロイする」、「Kubernetes 1.10のkubeletの起動オプションをKubelet ConfigファイルとPodSecurityPolicyで置き換える」のまとめとして、Kubernetes 1.10のクラスタを構築するAnsible Playbookを書いた。
書いたものはGitHubに置いた。
   (adsbygoogle = window.adsbygoogle || []).push({});  Ansibleとは Ansibleは、Ansible社が開発したOSSのIT自動化ツール。 Ansible社は2015年10月にRedHatが買収したので、現在はRedHatが開発している。 似たようなツールにPuppetやChefがあるが、最近はAnsibleが最も支持されている気がする。
構成管理ツールと紹介されることが多い気がするが、2014年末位からはIT自動化ツールを自称していて、構成管理は実現するユースケースの一つという位置づけになっているので、そろそろ認識を改めてあげたい。
ユースケースは以下のようなもの。
 プロビジョニング (ベアメタル、VM、クラウドインスタンス) 構成管理 アプリケーションデプロイメント CI/CD セキュリティ・コンプライアンス管理 オーケストレーション  
以下のような特徴を持つ。
 Python(とPowerShell)で作られてる。  昔はPython 2じゃないと動かなかったけど、2.2からPython 3でも動くようになった。  YAMLで書いた定義(Playbook)に従って処理を実行する。 シンプルで簡便であることを売りにしている。  多数のモジュールがビルトインされていて、様々な操作を簡潔な定義で宣言的に実行できる。  エージェントレスで、SSH(等)で対象のサーバにつないで処理を実行する。 処理を冪等にできるような仕組みが備わっていて、特にビルトインモジュールを活用すると簡単に冪等性を持たせられる。  
Pythonで書かれているのでどこでも動くかと思いきや、fcntlとかgrpやらUnix特有のモジュールを使っているため、WindowsのPythonでは動かない。
MSYS2とかWSLでは動く模様。 (Git Bashでは動かない…)

今回使ったのは最新版の2.5.3。
Ansibleインストール AnsibleはYUMとかpipとかでインストールできる。
今回はOracle Linux 7.4で動かすため、以下のようにインストールした。
 AnsibleのYUMリポジトリ追加
以下の内容を/etc/yum.repos.d/の適当な.repoファイルに書く。
[ansible] name=Ansible baseurl=http://releases.ansible.com/ansible/rpm/release/epel-7-x86_64/ gpgcheck=0 enabled=1 依存するPythonパッケージのYUMリポジトリを有効化</description>
    </item>
    
    <item>
      <title>Kubernetes 1.10のkubeletの起動オプションをKubelet ConfigファイルとPodSecurityPolicyで置き換える</title>
      <link>https://www.kaitoy.xyz/2018/05/05/kubernetes-kubelet-config-and-pod-sec-policy/</link>
      <pubDate>Sat, 05 May 2018 21:54:30 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2018/05/05/kubernetes-kubelet-config-and-pod-sec-policy/</guid>
      <description>「Kubernetes 1.10をスクラッチから全手動で構築」、「Kubernetes 1.10のクラスタにWeave Netをデプロイする」の続き。
kubeletの起動オプションの代わりに、Kubelet ConfigファイルとPodSecurityPolicyを使うように変更した話。
ついでにkube-proxyとkube-schedulerもConfigファイルを使うようにした。
   (adsbygoogle = window.adsbygoogle || []).push({});  Kubelet Configファイル journalctl -u kubeletすると、以下の警告が出ている。
Apr 28 15:31:39 k8s-master kubelet[1370]: Flag --address has been deprecated, This parameter should be set via the config file specified by the Kubelet&amp;#39;s - -config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information. Apr 28 15:31:40 k8s-master kubelet[1370]: Flag --pod-manifest-path has been deprecated, This parameter should be set via the config file specified by the K ubelet&amp;#39;s --config flag.</description>
    </item>
    
    <item>
      <title>Kubernetes 1.10のクラスタにWeave Netをデプロイする</title>
      <link>https://www.kaitoy.xyz/2018/05/04/kubernetes-with-weave-net/</link>
      <pubDate>Fri, 04 May 2018 11:14:33 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2018/05/04/kubernetes-with-weave-net/</guid>
      <description>「Kubernetes 1.10をスクラッチから全手動で構築」で、Kubernetes 1.10のクラスタに、ネットワークプロバイダとしてflannelをデプロイしたけど、flannelはNetwork Policyをサポートしていないので、代わりにWeave Netをデプロイしてみた話。
   (adsbygoogle = window.adsbygoogle || []).push({});  Weave Netにした理由 Network Policyをサポートしているネットワークプロバイダには現時点で以下のものがある。
 Calico Cilium Kube-router Romana Weave Net  このなかで、よく名前を聞くのがCalicoとWeave Net。 GitHubのスター数が圧倒的に多いのがWeave Net。 性能が比較的いいのがWeave Net。
ということでWeave Netにした。
Weave Netデプロイ 以下を参考に設定してデプロイする。
 https://www.weave.works/docs/net/latest/kubernetes/kube-addon/ https://www.weave.works/docs/net/latest/install/installing-weave/ https://github.com/weaveworks/weave/blob/master/prog/weave-kube/launch.sh  Kubernetesマニフェスト Weave NetをKubernetesクラスタにデプロイするためのマニフェストは、GitHub Releasesかhttps://cloud.weave.worksからダウンロードできる。 今回は後者にする。
https://cloud.weave.worksを使う場合、Kubernetesのバージョンなどのパラメータはクエリストリングで指定できる。 主なパラメータは以下。
 k8s-version: Kubernetesのバージョン。指定しないとlatest。 password-secret: ノード間のWeave Net通信の暗号化に使うパスワードを保持するSecret名。指定しないと平文。(参考: https://www.weave.works/docs/net/latest/tasks/manage/security-untrusted-networks/) IPALLOC_RANGE: Podに割り当てるIPアドレスの範囲。指定しないと10.32.0.0/12。 CHECKPOINT_DISABLE: Weave Netのアップデートを定期的にチェックする機能の無効化オプション。 WEAVE_MTU: MTUを指定するオプション。デフォルトで1376バイト。  
WEAVE_MTUはとりあえずデフォルトにしておいて、IPALLOC_RANGEもデフォルトにして、通信暗号化して、CHECKPOINT_DISABLEをtrueにするとすると、マニフェストは以下のようにダウンロードできる。
# curl -fsSLo weave-daemonset.</description>
    </item>
    
    <item>
      <title>Kubernetes 1.10をスクラッチから全手動で構築</title>
      <link>https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/</link>
      <pubDate>Tue, 17 Apr 2018 00:31:48 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/</guid>
      <description>Oracle Linux 7.4.0のVMでKubernetes 1.10.0のクラスタをスクラッチから全手動で作った。 参考にしたのは主に以下。
 https://nixaid.com/deploying-kubernetes-cluster-from-scratch/ https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.10.md https://kubernetes.io/docs/getting-started-guides/scratch/ https://kubernetes.io/docs/reference/setup-tools/kubeadm/implementation-details/ https://ulam.io/blog/kubernetes-scratch/ https://docs.microsoft.com/en-us/virtualization/windowscontainers/kubernetes/creating-a-linux-master  (2019/1/17追記: クラスタ全手動構築手順はKubernetes 1.13になってもほとんど変わっていない。ユニットファイルに指定するオプションが多少減ったりしたくらい。 また、ホストがRHELでもほとんど変わらない。インストールするDockerがDocker-CE(もしくはRedhatのやつ)に変わるくらいで、あとはkubeletの--cgroup-driverをsystemdにしないといけなかったかも。)    (adsbygoogle = window.adsbygoogle || []).push({});  構成  マシン: Windows 10 Homeのラップトップの上のVMware PlayerのVM  CPU: 2コア メモリ: 4GB NIF: NATのを一つ  OS: Oracle Linux 7.4.0  Minimalインストール IPアドレス: 192.168.171.200、静的割り当て ホスト名: k8s-master (hostsで解決)  Docker: Oracle Container Runtime for Docker (docker-engine) 17.06.2 Kubernetes: バージョン1.10.0  単一ノード 全コンポーネント(kubelet、kube-proxy、kube-apiserver、kube-controller-manager、kube-scheduler、etcd)をsystemdで起動 (i.e. 非コンテナ)  kubeletとkube-proxy以外は非rootユーザ kubeletは現時点でrootで動かす必要がある kube-proxyはiptableいじったりする都合上rootで動かす必要があるっぽい。  コンポーネント間通信とkubectlの通信をTLSで暗号化  TLS 1.</description>
    </item>
    
    <item>
      <title>Skaffoldを触ってみた</title>
      <link>https://www.kaitoy.xyz/2018/04/01/hello-skaffold/</link>
      <pubDate>Sun, 01 Apr 2018 09:59:43 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2018/04/01/hello-skaffold/</guid>
      <description>Skaffoldを試してみた話。
   (adsbygoogle = window.adsbygoogle || []).push({});  Skaffoldとは Googleが開発している、Kubernetesアプリケーションを快適に開発するためのツール。 アプリケーションのソースを監視し、変更が入ると、自動的にコンテナイメージをビルドしてKubernetesクラスタにデプロイしてくれる。
2018/3/16に発表された新しいツールで、触った感じではまだこれからといった感じだった。
Goで書かれていて、Linux、OS X、Windows用のバイナリが提供されている。
似たツールにはMicrosoftのDraftがある。
また、Gitのコミットを自動デプロイしてくれるものに、Gitkube、Jenkins X (エックス)がある。
Windows版を試す 自PCがWindowsなのでWindows版を試す。 会社で使ってるのもWindowsだし。
Skaffoldを使うには、Skaffoldの実行バイナリ、Kubernetesクラスタ、そのクラスタをコンテクストに設定したkubectl、Dockerが必要。
まずWindows版Skaffoldをインストールする。 GitHubのリリースページからWindowsバイナリをダウンロードして、skaffold.exeにリネームしてPATHの通ったところに置くだけ。 Skaffoldのバージョンは0.3.0。

Kubernetesクラスタは、Windows 10 Home上にminikube 0.22.2で作ったKubernetes 1.7.0のクラスタ。 minikubeは以前インストールしたものを使う。
minikubeを起動。
&amp;gt; minikube start --kubernetes-version v1.7.0 kubectlもminikubeと一緒にインストール済み。

Dockerについては、デーモンはminikube上のを使えばいいとして、クライアント(Docker Client)はskaffoldコマンドから実行するのでWindows上にないとだめはなず。
WindowsでDockerと言えば今ならDocker for Windowsだけど、これはWindows 10 Proじゃないと使えなかったはずなので、Docker Toolboxでクライアントをいれた。
このクライアントはデフォルトではローカルのデーモンを見てるので、minikubeのデーモンを見させる。 そのための設定はminikubeのコマンドで分かるようになっている。
&amp;gt; minikube docker-env SET DOCKER_TLS_VERIFY=1 SET DOCKER_HOST=tcp://192.168.99.100:2376 SET DOCKER_CERT_PATH=C:\Users\kaitoy\.minikube\certs SET DOCKER_API_VERSION=1.23 REM Run this command to configure your shell: REM @FOR /f &amp;#34;tokens=*&amp;#34; %i IN (&amp;#39;minikube docker-env&amp;#39;) DO @%i これに従って以下のコマンドを実行するとクライアントの設定完了。</description>
    </item>
    
    <item>
      <title>Kubernetes 1.8のアクセス制御について。あとDashboard。</title>
      <link>https://www.kaitoy.xyz/2017/10/31/retry-dashboard-on-k8s-cluster-by-kubeadm/</link>
      <pubDate>Tue, 31 Oct 2017 16:57:04 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2017/10/31/retry-dashboard-on-k8s-cluster-by-kubeadm/</guid>
      <description>「Kubernetes1.8のクラスタを構築する。kubeadmで。」で、Dashboardがうまく動かない問題が発生したんだけど、それを解決した話。
   (adsbygoogle = window.adsbygoogle || []).push({});  問題の現象 kubeadmでKubernetesクラスタを組んで、自前のアプリ(Goslings)のデプロイまではうまくできたんだけど、Dashboardをデプロイしたら動かず、Web UIにkubectl proxy経由でつないでもタイムアウトしてしまった。
対策 なんとなく、クラスタ内部での名前解決にはkube-dnsによるDNSサービスが使われているっぽいので、/etc/hostsに余計な事書いたのがいけなかったと思った。
ので、/etc/hostsからk8s-masterとk8s-nodeのエントリを削除してから、kubeadm initからやり直してみた。
結果 したらちゃんと動いた。
VMのホストでkubectl proxyして、
C:\Users\kaitoy\Desktop&amp;gt;kubectl proxy Starting to serve on 127.0.0.1:8001 http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/にブラウザでつないだらサインイン画面が表示された。

Dashboardのサインイン処理はKubernetes(というかkube-apiserver)のそれに移譲している。 Dashboardはそこで認証されたユーザでクラスタのリソースにアクセスし、情報を取得して表示する。多分。
Dashboardへのサインイン方法はいくつかあるが、それらを理解するにはKubernetesのアクセス制御について学ぶことを推奨とあったのでちょっとKubernetesのドキュメントを読んだ。
Kubernetesのアクセス制御 Kubernetesクラスタのエンドポイントはkube-apiserverであり、クラスタのリソースへのアクセス制御もkube-apiserverがやる。 クライアントとkube-apiserverとのTLSセッションが確立した後、HTTP層のデータを見てアクセス制御をするんだけど、その処理はAuthentication(認証)、Authorization(認可)、Admission(許可)の三段階からなる。
Authentication 第一段階がAuthentication。 ここでは、kube-apiserverに仕込まれたAuthenticatorモジュールがユーザ認証をする。
Kubernetesが認証するユーザには、Kubernetesが管理するService Accountと、クラスタ外部で管理される通常ユーザの二通りがある。 Service AccountはPodがkube-apiserverと話すためのユーザで、通常ユーザは主に人がkubectlとかでkube-apiserverと話すためのユーザ。(匿名で話すこともできる。) 前者はServiceAccountオブジェクトで定義されるけど、後者用のオブジェクトはない。
ServiceAccountはNamespaceと関連付き(つまりnamespace毎にユニーク)、Secretに紐づく。 Secretオブジェクトはクレデンシャルのセットを定義し、Podにマウントされる。 ServiceAccountとSecretは、ふつうは自動で作られ、Podに割り当てられる。
kube-apiserverには一つ以上のAuthenticatorモジュールを設定できて、どれかで認証できれば次の段階に進める。 認証失敗するとHTTPステータスコード401が返る。
Authenticatorモジュールには以下のようなものがある。
 クライアント証明書: X.509のディジタル証明書を使うモジュール。kube-apiserver起動時に--client-ca-fileオプションで証明書ファイルを渡してやると有効になる。証明書のCommon Nameがユーザ名になり、Organizationがグループになる。クライアント側は、その証明書と対応する秘密鍵をクレデンシャルとして指定する。 Bearer Token: 無記名トークンを使うモジュール。kube-apiserver起動時に--token-auth-fileオプションでトークン情報を渡してやると有効になる。トークン情報はCSVで、「token,user,uid,&amp;quot;group1,group2,group3&amp;quot;」という形式で書く。クライアント側は、トークン文字列をクレデンシャルとして指定する。 ベーシック認証: ユーザ名とパスワードで認証するモジュール。kube-apiserver起動時に--basic-auth-fileオプションでユーザ名とパスワードのリストを渡してやると有効になる。このリストはCSVで、「password,user,uid,&amp;quot;group1,group2,group3&amp;quot;」という形式で書く。クライアント側は、ユーザ名とパスワードをクレデンシャルとして指定する。HTTPクライアントの時はAuthorizationヘッダが使える。 Service Account Token: Service Accountを署名付きBearer Tokenで認証するモジュール。デフォルトで有効になる。  このあたり、Qiitaの「kubernetesがサポートする認証方法の全パターンを動かす」という記事をみると理解が深まる。
Authorization Authenticationをパスすると、クライアントのユーザ(とグループ)が認証され、第二段階のAuthorizationモジュールの処理に移る。 ここでは、リクエストの内容(操作対象、操作種別(メソッド)等)を見て、それがユーザに許されたものなら認可する。 何を許すかは事前にクラスタにポリシーを定義しておく。</description>
    </item>
    
    <item>
      <title>Kubernetes1.8のクラスタを構築する。kubeadmで。</title>
      <link>https://www.kaitoy.xyz/2017/10/21/build-kubernetes-cluster-by-kubeadm/</link>
      <pubDate>Sat, 21 Oct 2017 10:42:46 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2017/10/21/build-kubernetes-cluster-by-kubeadm/</guid>
      <description>「Kubernetes 1.8が出たので、Minikubeを触ってみる」でMinikubeをやったんだけど、もう一歩ステップアップすべく、kubeadmでKubernetesクラスタを組んでみた話。
   (adsbygoogle = window.adsbygoogle || []).push({});  kubeadmとは kubeadm(キューブアダム)はKubernetesに含まれるコマンドで、Kubernetesクラスタを簡単に構築するツール。 Kubernetes 1.4で追加され、Kubernetes 1.8の時点でまだベータで、本番環境には使わないでとなっている。 Qiitaの「kubeadmが何をやっているのかみてみた」という記事が、中でどんな動作をしてるかを解説していて参考になる。
コマンドの使用感からすると、DockerのSwarmモードでのクラスタ構築の容易さをKubernetesに取り込むことを目指して開発されている気がした。
ネットで見かけた評判だと、確かに簡単にクラスタ構築できて素晴らしいけど、TLSの証明書生成など、細かく制御できなくて困るところがあって、やはり本番に使えるレベルではないとのこと。
まあとにかく試してみる価値はあろう。
kubeadmインストール Kubernetesのドキュメントに従ってkubeadmをインストールする。 バージョンは最新版の1.8.1。
VM作成 kubeadmのサポートOSは、Ubuntu 16.04+、Debian 9、CentOS 7、RHEL 7、Fedora 25/26、HypriotOS v1.0.1+となっている。 慣れているCentOS 7を使うことにする。 (HypriotOSってなんだろう?)
自前のノートPCのWindows 10 x64 Home Edition上のVMware Player 12のVMにCentOS 7を入れた。 メモリは1GB以上が要件なので、味を付けて1.4GBで。 VM間で通信できることって要件があったけど、インターネット接続も必要なはずなので、NICはNATのやつで。
このVMはMasterになる。
OS設定 Kubernetesが使うポートをいろいろ開けなければいけないんだけど、めんどいのでfirewalldを無効にする。
# systemctl stop firewalld # systemctl disable firewalld Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service. Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service. 
なんとなくIPアドレスをDHCPから静的割り当てに。(192.168.171.200)
# nmcli c modify ens33 ipv4.method manual # nmcli c modify ens33 ipv4.</description>
    </item>
    
    <item>
      <title>Kubernetesのチュートリアルをやる</title>
      <link>https://www.kaitoy.xyz/2017/10/11/goslings-on-kubernetes-cont/</link>
      <pubDate>Wed, 11 Oct 2017 23:48:40 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2017/10/11/goslings-on-kubernetes-cont/</guid>
      <description>「Kubernetes 1.8が出たので、Minikubeを触ってみる」の続き。 Minikubeのセットアップまではできたので、Kubernetes Basicsというチュートリアルをやりながら、Goslingsをデプロイする。
   (adsbygoogle = window.adsbygoogle || []).push({});  Kubernetes Basics - 概要 Kubernetes Basicsは、公式のチュートリアルで、Kubernetesクラスタのオーケストレーションの基本を学ぶことができるもの。 以下の6つのモジュールからなる。
 Kubernetesクラスタを作る アプリをデプロイする アプリを調査する アプリを公開する アプリをスケールする アプリをアップデートする  チュートリアルで使うのはMinikubeだけど、自分でセットアップする必要はない。 Katacodaという、ブラウザ上でIT技術を学べるプラットフォームがあり、Kubernetes Basicsはそれを利用して、ブラウザ上のターミナルからホステッドMinikubeを操作できるようにしている。
が、前回の記事で自PC上にMinikubeをセットアップしたので、そちらを使うことにする。

Kubernetes Basics - モジュール 1: Kubernetesクラスタを作る Minikubeを起動してkubectlでクラスタの状態をみるだけのモジュール。
これは前回の記事でカバーしている。
Kubernetes Basics - モジュール 2: アプリをデプロイする アプリ(i.e. コンテナ)をデプロイするにはDeploymentオブジェクトを作る。 MasterはDeploymentのspecに従って各ノードにアプリのインスタンスをスケジューリングする。 Deploymentは、アプリが落ちたら再起動してくれる、つまりself-healingも実現する。
Deploymentオブジェクトを作るコマンドはkubectl run &amp;lt;オブジェクト名&amp;gt; --image=&amp;lt;Dockerイメージ名&amp;gt;。 Goslingsをこれでデプロイする。
Goslingsコンテナは3つの引数を受け取り、指定したポートでWebサーバを起動する。 --portオプションでそのポートをexposeするようにして、--の後にコンテナに渡す引数を記述する。
C:\Users\kaitoy&amp;gt;kubectl run goslings --image=kaitoy/goslings:latest --port 8080 -- 8080 /tmp https://github.com/kaitoy/ deployment &amp;#34;goslings&amp;#34; created C:\Users\kaitoy&amp;gt;kubectl get deployment NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE goslings 1 1 1 1 27s デプロイできた。 裏でPodも作られていて、アプリが起動されている。</description>
    </item>
    
    <item>
      <title>Kubernetes 1.8が出たので、Minikubeを触ってみる</title>
      <link>https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/</link>
      <pubDate>Tue, 10 Oct 2017 00:10:59 +0900</pubDate>
      
      <guid>https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/</guid>
      <description>Kubernetes1.8のリリースが話題になっていたので、ちょっと触って見たという話。 (1.8を触ったとは言っていない。)
具体的には、Kubernetes Basicsというチュートリアルをやりながら、MinikubeにGoslingsをデプロイしたんだけど、この記事ではMinikubeをセットアップしたところまで。
   (adsbygoogle = window.adsbygoogle || []).push({});  Kubernetesとは KubernetesはOSSのコンテナオーケストレーションツール。 英語だとクーバネティスみたいに発音する。 Googleが自身のコンテナ技術であるBorgの運用で培ったノウハウを活かして開発したもの。 2014年ころに開発が始まり、2015年夏にv1がリリースされたということで、かなり新しいツール。 よく比べられるものにはDockerのSwarmモードやApache Mesosがあるが、何が違うのかは調べてないので知らない。 ただ、Dockerコンテナ管理ツールとしてはKubernetesが一番勢いがある雰囲気を感じる。
(2017/10/18追記: DockerがKubernetesとの統合を発表した。KubernetesはDockerネイティブなツールになり、Dockerとともにインストールされ、Docker ComposeのConposeファイルでデプロイできるようになったりする。Kubernetesの大勝利っぽい。)
Kubernetesを使うと、複数の物理マシンからなるHAクラスタ(Kubernetesクラスタ)を構成し、その上にコンテナをデプロイして管理できる。 Kubernetesクラスタは、一組のMasterコンポーネント群(a.k.a. Kubernetes Control Plane、または単にMaster)と一つ以上のNode(昔はMinionと呼ばれてたもの)で構成される。 Nodeは、Masterの管理下でコンテナを実行する機能を備えた、一台のVMや物理マシン。 MasterはNode上で動き、クラスタを管理し、コンテナのスケジューリング、状態管理、スケーリング、アップデートなどを担う。
Kubernetesのアーキテクチャを図にすると以下の感じ。 矢印の向きとかはちょっと間違ってるかも。
ごちゃごちゃするので省いたけど、図の下部のNode内のコンポーネントは、他のNode内でも動いている。

Masterにはkube-apiserverが含まれていて、Kubernetes APIというREST APIを公開する。 このAPIを通してKubernetesオブジェクトを定義したりすることで、宣言的にコンテナの管理ができる仕組み。 ユーザは普通、kubectl(キューブシーティーエル)というコマンドでkube-apiserverとやり取りする。
KubernetesオブジェクトはMasterのetcdによって分散キーバリューストアに永続化され、そのストアをkube-controller-managerとkube-schedulerが(kube-apiserver経由で)watchしてて、変更に応じた処理をする。
kube-controller-managerは、ノードの管理や、オブジェクトのライフサイクルの管理や、コンテナのスケーリングなど、クラスタレベルの機能を実行する。 (よくわからない。)
kube-schedulerは、コンテナを実行するホストを選出し、コンテナのスケジューリングをする。

一方、各Nodeでは、kubelet(キューブレット)というMasterのエージェントになるプロセスが動く。
kubeletはkube-apiserverからの指示で、コンテナイメージを取得してコンテナを起動したり監視したり止めたりする。
kubeletがコンテナを扱うためのコンテナランタイムは、普通はDockerだけど、rktとかcri-oとかfraktiとかも使える。runcやRailCarはどうなんだろう。
コンテナはデフォルトではクラスタ内のプライベートネットワークにつながるので、そこで動いているアプリにユーザからアクセスするには、何らかの形でトラフィックを中継してやる必要がある。 これをするのがkube-proxy。 ロードバランシングもしてくれる。
Kubernetesオブジェクトとは Kubernetesオブジェクトは、Kubernetesクラスタ上で機能する構成要素を表現するもの。 オブジェクトはspecとstatusを持ち、オブジェクトに期待する状態やふるまい(spec)を定義しておくと、Kubernetesが実際の状態(status)をそれに合わせてくれる。 宣言的。
オブジェクトには以下のようなものがある。
 Pod
デプロイの最小単位。 一つ(またはリソースを共有する複数)のコンテナと、ストレージ、ネットワークなどを内包する。 一つのPodには一つのIPアドレスが付く。
kubeletはPodの定義に従ってコンテナを起動する。
因みに、etcd以外のMasterコンポーネントもPodとしてデプロイされる。
 Service
Podの論理グループ。 PodのIPアドレスは外部に公開されないので、外とのやり取りをするためにServiceがある。 kube-proxyはこいつの定義に従って働く。
Serviceには複数のEndpoint(i.e. Pod等)が紐づき、外部からのトラフィックをラウンドロビンでルーティングするので、冗長化やロードバランサ的な働きもする。 ServiceはPodを抽象化するので、Podが死んだり入れ替わったりしても外に影響が見えにくくなる。</description>
    </item>
    
  </channel>
</rss>