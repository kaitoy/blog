<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta name="google-site-verification" content="9qs7VjxtSrYMqw5OElxCdKv_gnssSRi6acB2iYlZnGA" />

    
    
    <meta property="og:title" content="To Be Decided">
    <meta property="og:url" content="https://www.kaitoy.xyz">
    <link rel="canonical" href="https://www.kaitoy.xyz">
    
    <meta property="og:site_name" content="To Be Decided">

    <title>
      
      coursera | To Be Decided
      
    </title>

    
    <link rel="shortcut icon" href="https://www.kaitoy.xyz/assets/favicon.ico">

    
    <link rel="alternate" type="application/rss+xml" title="RSS" href="https://www.kaitoy.xyz/index.xml">

    <link href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css" rel="stylesheet">
    <link href="//fonts.googleapis.com/css?family=Marcellus+SC" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=PT+Sans" rel="stylesheet" type="text/css">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">
    <link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.5.0/styles/zenburn.min.css" rel="stylesheet">
    <link href="https://www.kaitoy.xyz/css/styles.css" rel="stylesheet">
    <link href="https://www.kaitoy.xyz/css/custom.css" rel="stylesheet">
    <link href="https://www.kaitoy.xyz/css/table.css" rel="stylesheet">
    <link href="https://www.kaitoy.xyz/css/jquery.bxslider.css" rel="stylesheet" />

    
    

    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-6244473643910448",
        enable_page_level_ads: true
      });
    </script>

    
  </head>
  <body>

    <header id="site-header">
      <div class="container">
        <h1 class="text-center">
          <a href="https://www.kaitoy.xyz" class="font-logo">To Be Decided</a>
        </h1>
      </div>
    </header>

    <main id="site-body">
      <div class="container">


<div class="row">
  <div class="col-md-9">
    <div id="posts">
      <div class="row">
        
        
        
        <div class="col-sm-6">
          <article>
            <a href="https://www.kaitoy.xyz/2018/02/06/coursera-deep-learning-convolutional-neural-networks/" class="post post-topix">
              <header class="eyecatch text-center">
                <img src="/images/deeplearning.ai.png" alt="eyecatch">
              </header>
              <div class="date text-center">
                <span>Tue, Feb 6, 2018</span>
              </div>
              <h2 class="title">CourseraのDeep Learning SpecializationのConvolutional Neural Networksコースを修了した</h2>
              <div class="summary">
                CourseraのDeep Learning SpecializationのStructuring Machine Learning Projectsコースを修了したのに続き、Convolutional Neural Networksコースを修了した。 (adsbygoogle = window.adsbygoogle || []).push({}); このコースは、CNNの原理、代表的なアーキテクチャ、応用などについて学べる4週間のコース。 動画は今のところ全部英語。 プログラミング課題は初のKeras。 このコースは結構難しくて、特に3週目と4週目は理解に苦しんだ。 というか理解しきれなかったような。 けどNST面白かった。 2018/1/16に始めて、2/6に完了。 22日間かかった。 修了したらまたCertifacateもらえた。 以下、4週分の内容をメモ程度に書いておく。 1週目 畳み込みニューラルネットワーク(CNN: Convolutional neural network)の基本。 動画 畳み込み計算 画像認識でよく使われるNNのアーキテクチャ。 低層ではエッジを検出し、層が進むにつれて複雑な特徴を学習する。 画像を特定の行列(普通は奇数の正方行列。3×3が多い。)で畳み込むことで、特定の方向のエッジを検出できる。 この行列をフィルタ(filter)という。カーネルと呼ばれることもある。 例えば縦なら以下。 [[1, 0, -1], [1, 0, -1], [1, 0, -1]] 縦でもいろいろフィルタはあって、以下はSobelフィルタというもの。 [[1, 0, -1], [2, 0, -2], [1, 0, -1]] 以下はScharrフィルタ。 [[ 3, 0, -3], [10, 0, -10], [ 3, 0, -3]] 縦のフィルタを90度回転すると横のフィルタになる。 深層学習では、フィルタもパラメータとして学習させる。 パディング(Padding) n×nの行列をf×fのフィルタで畳み込むとn-f+1×n-f+1の行列になる。 つまり畳み込めば畳み込むほど画像が小さくなってしまう。 また、画像の端のほうはフィルタにかかる割合が小さいので、情報量が小さくなってしまう。 これらを解決するテクニックがパディング(Padding)。 行列の周囲を0でパディングして、サイズを大きくしてから畳み込む。 パディングがないのをValidな畳み込み、出力が入力と同じサイズになるようにパディングするのをSameな畳み込みという。 Strided畳み込み 畳み込むときにフィルタをずらす幅を1より大きくする。 パディングサイズがpでストライドがsのとき、n×nの行列をf×fのフィルタで畳み込むと(n+2p-f)/s+1×(n+2p-f)/s+1の行列になる。 3次元(カラー画像)の畳み込み カラー画像は3次元の行列、つまりn×n×cの行列で、それを畳み込むのはf×f×cのフィルタで、出力はn-f+1×n-f+1の行列になる。 チャネルごとにフィルタを設定して、色ごとにエッジ検出できる。 フィルタごとの出力は全部スタックして、最終的な出力は3次元になる。 畳み込み層はフィルタの要素数がパラメータ数になる。 入力画像の大きさに依存しないので、パラメータ数が少なくて済み、過学習しにくい。 入力を複数の畳み込み層に通したら、最終的に3次元の出力をなべてベクトルにして、後ろの層に渡す。 プーリング層(Pooling layer) 計算量を減らすため、また特徴の抽出のために、畳み込み層のあとに使われる層。 基本Max poolingが使われるけど、Average poolingというのもある。 Max pooling: フィルタをかけた部分を畳み込む代わりに、最大値を出力とする。大きな値が特徴が大きく出ているところだから、特徴を凝縮するイメージだけど、経験的にこれで上手くいくことが分かっているだけで、なぜ上手くいくかは判明していない。この層はパラメータを持たない。 Average pooling: フィルタをかけた部分を畳み込む代わりに、平均を出力とする。 プーリング層のフィルタは大抵、サイズが2×2でパディングが0でストライドは2。 普通、畳み込み層とプーリング層とセットで1層と数える。 全結合層(Fully connected layer) 全ノードがメッシュ状につながった普通の層。 畳み込み層とプーリング層のセットがいくつかあって、その出力をベクトルになべて、全結合層につなぐ。 一般的なCNN 畳み込み層は、普通nhとnwを縮め、ncを増やす。 また、全体として、層が浅くなるほど出力が減るのが多い。 CNNはハイパーパラメータが多すぎるので、アーキテクチャは自分で考えるんではなく、論文呼んで自分の問題に合いそうなのを探すべし。 畳み込み層は全結合層に比べてパラメータ数がかなり少なくて済むのがいいところ。 これはパラメーター共有(Parameter sharing)という、画像のある個所で上手く動いたフィルタ(e.g.
              </div>
            </a>
          </article>
        </div>
        
        
        
        
        
        <div class="col-sm-6">
          <article>
            <a href="https://www.kaitoy.xyz/2018/01/16/coursera-deep-learning-ml-strategy/" class="post post-topix">
              <header class="eyecatch text-center">
                <img src="/images/deeplearning.ai.png" alt="eyecatch">
              </header>
              <div class="date text-center">
                <span>Tue, Jan 16, 2018</span>
              </div>
              <h2 class="title">CourseraのDeep Learning SpecializationのStructuring Machine Learning Projectsコースを修了した</h2>
              <div class="summary">
                CourseraのDeep Learning SpecializationのImproving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimizationコースを修了したのに続き、Structuring Machine Learning Projectsコースを修了した。 (adsbygoogle = window.adsbygoogle || []).push({}); このコースは、深層学習プロジェクトの進め方のコツや問題への対処方法などについて学べる2週間のコース。 今回はプログラミング課題がない。 動画は今のところ全部英語。 ちょっと動画編集ミスが多かった。 同じことを二回言ったり、無音無絵の時間があったり、マイクテストしてたり。 2018/1/13に始めて、1/15に完了。 3日間かかった。 修了したらまたCertifacateもらえた。 以下、2週分の内容をメモ程度に書いておく。 1週目 モデルの改善をするのに、データを増やしたりハイパーパラメータを変えたり色々な手法がある。 一つを試すのに下手すると数か月とかかかるので、効率よく手法の取捨選択し、モデルを改善していくための戦略について学ぶ。 動画 直交化(Orthogonalization) 一つの要素で複数の制御をしようとすると難しいので、一つの制御だけするようにする。 具体的には、以下のことを別々に扱う。 訓練データに目標の精度までフィットさせる。 devデータに目標の精度までフィットさせる。 テストデータに目標の精度までフィットさせる。 現実のデータでうまく動くようにする。 それぞれの目的について、チューニングすべき要素は別々になる。 早期終了は直行化の原則に反しているので、ほかの方法があるならそっちをやったほうがいい。 指標(Goal)の設定 モデルの改善はイテレーティブなプロセスなので、サイクルを速く回したい。 そのため、モデルを評価する単一の数値があるといい。 F1スコアとか。平均とか 単一の指標にまとめるのがむずいときもある。 精度と速さとか。 そんなときは一つ以外の指標を足切りだけに使う。 ある閾値以上の速さが出てるもののなかで精度をくらべるなど。 データの分け方 devデータとテストデータの分布(と評価指標)は同じ感じにしないといけない。 そのために、いったん全データをシャッフルしてから分割する。 訓練データの分布は異なってても問題ない。 訓練:テスト = 70:30とか、訓練:dev:テスト = 60:20:20とかいう比率は、1万くらいのデータなら適当。 けど100万くらいなら、98:1:1くらいが妥当。 テストデータはモデルの最終評価をするためのものなので、どれだけ評価したいかによってサイズを変える。 0もありがちだけど、非推奨。 猫の画像のなかにエロ画像が混じっちゃうようなモデルはだめ。 猫判定率が多少下がっても、エロ画像が含まれないほうがまし。 こういう場合は評価指標を変える必要がある。 エロ画像を猫と判定した場合にペナルティを大きくするなど。 直行化の観点で言うと、指標を決めるのと、その指標に従って最適化するのは、別のタスクとして扱うべき。 人並性能(Human-level performance)との比較 人並性能とは、人が手動で達成できる精度。そのエラー率、つまり人並誤差(Human-level error)はベイズ誤差(Bayes
              </div>
            </a>
          </article>
        </div>
        
        
        
        
        
        <div class="col-sm-6">
          <article>
            <a href="https://www.kaitoy.xyz/2018/01/12/coursera-deep-learning-improving-deep-neural-networks/" class="post post-topix">
              <header class="eyecatch text-center">
                <img src="/images/deeplearning.ai.png" alt="eyecatch">
              </header>
              <div class="date text-center">
                <span>Fri, Jan 12, 2018</span>
              </div>
              <h2 class="title">CourseraのDeep Learning SpecializationのImproving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimizationコースを修了した</h2>
              <div class="summary">
                CourseraのDeep Learning SpecializationのNeural Networks and Deep Learningコースを修了したのに続き、Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimizationコースを修了した。 (adsbygoogle = window.adsbygoogle || []).push({}); このコースは、ディープニューラルネットワークのチューニングなどについて学べる3週間のコース。 今のところ全部英語。 2018/1/5に始めて、1/12に完了。 8日間かかった。 修了したらまたCertifacateもらえた。 以下、3週分の内容をメモ程度に書いておく。 1週目 OverfittingやUnderfittingを防ぐテクニックについて。 動画 データ分割 深層学習のモデル構築は、検討(Idea)、実装(Code)、検証(Experiment)というサイクルの繰り返し(Iterative process)。 取り組む課題、課題のドメイン、データ量、マシンの構成などにより、ハイパーパラメータは変わるので、経験をもって事前に予測することは無理なので、サイクルをどれだけ速く回せるかが鍵。 データは、訓練データ(Training set)、Devデータ(Development set))(a.k.a. Cross-validation set)、テストデータ(Test set)に分割する。 訓練データで学習し、Devデータでハイパーパラメータを評価し、テストデータで最終的な評価と性能見積をする。 テストデータは無くてもいい。 サンプル数が1万くらいだった時代は、6:2:2くらいで分割してたけど、近年は数百万とかのデータを扱い、交差検証データやテストデータの割合はもっと小さくするのがトレンド。 98:1:1など。 Devデータとテストデータは同じようなものを使うべき。 訓練データは必ずしも同様でなくてもいい。訓練データは沢山要るので、別のデータソースからとることもある。 バイアス vs バリアンス でかいネットワークで正則化して大量データで学習させるのが吉。 正則化 過学習(Overfitting)を防ぐため、コスト関数を正則化(Regularization)すべし。 ロジスティック回帰ではL2ノルム(L2 norm)を使ったL2正則化が一般的。 L1正則化はあまり使われない。 L1正則化をすると、wがスパース行列になってモデルを圧縮できると言われることがあるが、経験上その効果はほとんどない。 正則化パラメータλはハイパーパラメータで、Devデータで評価する。 ニューラルネットワークでは正則化項にフロベニウスノルム(Frobenius norm)を使う。 Dropout(Inverted Dropout) ランダムにノードを無効化しながら学習することで過学習を防ぐ。 画像処理の分野では、特徴量の数が多く学習データが少ない傾向があるので、ほぼ常に使われる。 コスト関数が計算できなくなるのが欠点。 計算する必要があるときにはDropoutを無効化する。 データ拡張(Data augmentation) データを加工して増やせば、高バリアンス対策になる。 早期終了(Early stopping) 過学習するまえに学習を止めるテクニック。 訓練データとDevデータについてコストをプロットして、Devデータのものが上がる前に止める。 これは、直交化(Orthogonalization)の原則、つまり一度に一つのことを考慮すべきという原則に反していて、コストを最小化するという問題と、過学習を避けるという問題に同時に対処することになるので微妙。 普通は代わりにL2正則化使えばいいけど、λを最適化する手間を省きたいときには選択肢になりうる、というか実現場ではちょくちょく選択肢になる。 訓練データの正規化(Normalization) 訓練データの各特徴量について平均を0にして分散を1にすると学習が速くなる。 訓練データを正規化したらテストデータも正規化する。 その際、正規化パラメータは訓練データのものを使う。 勾配消失(Vanishing gradient)、勾配爆発(Exploding gradient) ニューラルネットワークの層が深くなると、層の出力や勾配が指数関数的に大きくなったり小さくなったりして、学習が難しくなる問題。 長年ディープニューラルネットワークの発展を妨げてきた問題。 パラメータのランダム初期化をすると防げる。 ガウス分布で作ったパラメータに特定の値を掛けてを分散が1/n(ReLUの時は2/n)になるように調整して、活性化関数に入力する値を約1に抑える。 掛ける値は活性化関数ごとにだいたい決まっていて((e.g.
              </div>
            </a>
          </article>
        </div>
        
        
        
        
        
        <div class="col-sm-6">
          <article>
            <a href="https://www.kaitoy.xyz/2018/01/05/coursera-deep-learning-neural-networks-and-deep-learning/" class="post post-topix">
              <header class="eyecatch text-center">
                <img src="/images/deeplearning.ai.png" alt="eyecatch">
              </header>
              <div class="date text-center">
                <span>Fri, Jan 5, 2018</span>
              </div>
              <h2 class="title">CourseraのDeep Learning SpecializationのNeural Networks and Deep Learningコースを修了した</h2>
              <div class="summary">
                CourseraのMachine Learningコースに続いて、同じくAndrew先生によるDeep Learning Specializationを受講中。 これは深層学習の基本を学べるもので、以下の5つのコースからなる。 Neural Networks and Deep Learning Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization Structuring Machine Learning Projects Convolutional Neural Networks Sequence Models この内、最初のNeural Networks and Deep Learningを修了したので、記念にブログしておく。 (adsbygoogle = window.adsbygoogle || []).push({}); Deep Learning Specializationとは Deep Learning SpecializationはCoursera Specializationのひとつ。 Coursera Specializationはサブスクリプションモデルで、つまりあるSpecializationのサブスクリプションを購入すると、受講完了するまで毎月定額の料金を支払うことになる。 Deep Learning Specializationは月$49で、5コース合わせて13週+α分の内容。 (Sequence Modelsが2018年1月に公開予定となっていて、現時点でまだ公開されていないので内容が不明。) 最初の7日間はトライアルで無料なので、この間に全部終わらせられればタダ。 無理だけど。 Deep Learning Specializationでは、PythonとTensorFlowでディープニューラルネットワーク、CNN、RNN、LSTM、Adam、Dropout、バッチ正規化、Xavier/He initializationなどを学べる。 Machine Learningコースと同じく、5分～15分くらいの動画による講義と、小テストと、プログラミング課題から構成されている。 プログラミング課題は、coursera hubという、ホステッドJupyter Notebookで解いて提出できるので楽。 Neural Networks and Deep Learningコースとは ディープニューラルネットワークの仕組みを学んで実装する4週間のコース。 また、深層学習の偉い人へのインタビューを見れる。
              </div>
            </a>
          </article>
        </div>
        
        
        
        
        
        <div class="col-md-3 col-sm-4 col-xs-6">
          <article>
            <a href="https://www.kaitoy.xyz/2017/12/22/coursera-machine-learning/" class="post">
              <header class="eyecatch text-center">
                <img src="/images/cml.png" alt="eyecatch">
              </header>
              <div class="date text-center">
                <span>Fri, Dec 22, 2017</span>
              </div>
              <h3 class="title">CourseraのMachine Learningコースを修了した</h3>
            </a>
          </article>
        </div>
        
        
        
      </div>
    </div>
  </div>
  <div class="col-md-3">
    <aside id="site-sidebar">
      <div class="row">
        <div class="col-md-12 col-sm-6 col-xs-12">
  <div class="text-center custom-partial">
    
  </div>
  <section class="sidebar-bordered">
    
    <div id="profile">
      <div class="text-center">
        <img id="profile-photo" src="/images/nopicture.png" alt="profile">
      </div>
      <div class="data">
        <h4 id="profile-username" class="post-title"></h4>
        
        <span id="profile-birth">DOB: Dec 14, 1983</span>
        
        <div id="social-links">
          
          <a href="https://www.facebook.com/yamada.kaito.90" target="_blank"><i class="fa fa-facebook-square"></i></a>
          
          
          
          <a href="https://github.com/Kaitoy" target="_blank"><i class="fa fa-github-square"></i></a>
          
        </div>
        <div id="profile-description"></div>
        <ul id="profile-urls" class="post-tags"></ul>
      </div>
    </div>
    
  </section>
</div>

<div class="col-md-12 col-sm-6 col-xs-12">
  <section>
    <h3>Tags</h3>
    
    <div id="tag-cloud" class="text-center">
      
      
      
      <a href="https://www.kaitoy.xyz/tags/atom">atom</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/aws">aws</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/aws-ecs">aws-ecs</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/blog">blog</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/bow">bow</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/cdn">cdn</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/ci">ci</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/cnn">cnn</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/coursera">coursera</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/deep-learning">deep-learning</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/disturb-me">disturb-me</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/docker">docker</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/elasticsearch">elasticsearch</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/filebeat">filebeat</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/firedrop">firedrop</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/git">git</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/github">github</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/goslings">goslings</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/groovy">groovy</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/headless-browser">headless-browser</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/hibernate">hibernate</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/hugo">hugo</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/impress.js">impress.js</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/japanese-word-selection">japanese-word-selection</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/javascript">javascript</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/jekyll">jekyll</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/jgit">jgit</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/jvm-language">jvm-language</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/kotlin">kotlin</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/kubeadm">kubeadm</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/kubernetes">kubernetes</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/license">license</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/logstash">logstash</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/machine-learning">machine-learning</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/management">management</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/minikube">minikube</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/nanoserver">nanoserver</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/neural-network">neural-network</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/oop">oop</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/orm">orm</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/pcap4j">pcap4j</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/react">react</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/runc">runc</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/selenium">selenium</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/seo">seo</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/servicenow">servicenow</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/spring">spring</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/spring-boot">spring-boot</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/subversion">subversion</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/tensorflow">tensorflow</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/test-framework">test-framework</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/vcs">vcs</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/webdriverio">webdriverio</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/windows">windows</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/yegor256">yegor256</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/zundoko">zundoko</a>
      
    </div>
    
  </section>
</div>





<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
    style="display:block"
    data-ad-client="ca-pub-6244473643910448"
    data-ad-slot="1845600530"
    data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>

<div class="col-md-12 col-sm-6 col-xs-12">
  <div class="text-center custom-partial">
    
  </div>
</div>

      </div>
    </aside>
  </div>
</div>

        <div class="text-center custom-partial">
          
        </div>
      </div>
    </main>

    <footer id="site-footer" class="text-center font-logo">
      <p>&copy;  2015 -  2018  Kaito Yamada </p>
      <p>Powered by <a href="http://gohugo.io" target="_blank">Hugo</a></p>
      <p>
        Theme: <a target="_blank" href="https://github.com/dim0627/hugo_theme_robust">Robust</a>
        designed by <a target="_blank" href="http://yet.unresolved.xyz">Daisuke Tsuji</a>
      </p>
    </footer>

    <script src="//code.jquery.com/jquery-2.1.3.min.js"></script>
    <script src="https://www.kaitoy.xyz/js/jquery.bxslider.min.js"></script>
    
    <script>
      $(document).ready(function(){
        $('.bxslider').bxSlider({
          speed: 1,
          preloadImages: 'all'
        });
      });
    </script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
    <script src="https://www.kaitoy.xyz/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-65248565-1', 'auto');
    ga('send', 'pageview');

    </script>

    <script>
    $(function() {
      var url = "https://ja.gravatar.com/5fbe47b2a4b3637dd26dfc9a49381895.json?callback=?";
      $.getJSON(url)
        .done(function(data) {
          var entry = data.entry[0];
          $("#profile-photo").attr("src", entry.photos[0].value);
          $("#profile-username").html(entry.name.familyName + " " + entry.name.givenName);
          $("#profile-description").html(entry.aboutMe);
          entry.urls.forEach(function(el){
            $("#profile-urls").append($("<li><a href='" + el.value + "'>" + el.title + "</a></li>"));
          });
          $("#profile").show();
        });
    });
    </script>
  </body>
</html>

