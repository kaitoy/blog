<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>To Be Decided </title>
    <link>https://www.kaitoy.xyz/tags/coursera/</link>
    <language>en-us</language>
    <author>Kaito Yamada</author>
    <rights>(C) 2018</rights>
    <updated>2018-01-16 07:56:43 &#43;0900 JST</updated>

    
      
        <item>
          <title>CourseraのDeep Learning SpecializationのStructuring Machine Learning Projectsコースを修了した</title>
          <link>https://www.kaitoy.xyz/2018/01/16/coursera-deep-learning-ml-strategy/</link>
          <pubDate>Tue, 16 Jan 2018 07:56:43 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/01/16/coursera-deep-learning-ml-strategy/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/01/12/coursera-deep-learning-improving-deep-neural-networks/&#34;&gt;CourseraのDeep Learning SpecializationのImproving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimizationコースを修了した&lt;/a&gt;のに続き、&lt;a href=&#34;https://www.coursera.org/learn/machine-learning-projects&#34;&gt;Structuring Machine Learning Projectsコース&lt;/a&gt;を修了した。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;このコースは、深層学習プロジェクトの進め方のコツや問題への対処方法などについて学べる2週間のコース。
今回はプログラミング課題がない。
動画は今のところ全部英語。&lt;/p&gt;

&lt;p&gt;ちょっと動画編集ミスが多かった。
同じことを二回言ったり、無音無絵の時間があったり、マイクテストしてたり。&lt;/p&gt;

&lt;p&gt;2018/1/13に始めて、1/15に完了。
3日間かかった。
修了したらまた&lt;a href=&#34;https://www.coursera.org/account/accomplishments/certificate/7MHFMLHP67C4&#34;&gt;Certifacate&lt;/a&gt;もらえた。&lt;/p&gt;

&lt;p&gt;以下、2週分の内容をメモ程度に書いておく。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;p&gt;モデルの改善をするのに、データを増やしたりハイパーパラメータを変えたり色々な手法がある。
一つを試すのに下手すると数か月とかかかるので、効率よく手法の取捨選択し、モデルを改善していくための戦略について学ぶ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;直交化(Orthogonalization)&lt;/p&gt;

&lt;p&gt;一つの要素で複数の制御をしようとすると難しいので、一つの制御だけするようにする。
具体的には、以下のことを別々に扱う。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;訓練データに目標の精度までフィットさせる。&lt;/li&gt;
&lt;li&gt;devデータに目標の精度までフィットさせる。&lt;/li&gt;
&lt;li&gt;テストデータに目標の精度までフィットさせる。&lt;/li&gt;
&lt;li&gt;現実のデータでうまく動くようにする。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;それぞれの目的について、チューニングすべき要素は別々になる。&lt;/p&gt;

&lt;p&gt;早期終了は直行化の原則に反しているので、ほかの方法があるならそっちをやったほうがいい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;指標(Goal)の設定&lt;/p&gt;

&lt;p&gt;モデルの改善はイテレーティブなプロセスなので、サイクルを速く回したい。
そのため、モデルを評価する単一の数値があるといい。
F1スコアとか。平均とか&lt;/p&gt;

&lt;p&gt;単一の指標にまとめるのがむずいときもある。
精度と速さとか。
そんなときは一つ以外の指標を足切りだけに使う。
ある閾値以上の速さが出てるもののなかで精度をくらべるなど。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;データの分け方&lt;/p&gt;

&lt;p&gt;devデータとテストデータの分布(と評価指標)は同じ感じにしないといけない。
そのために、いったん全データをシャッフルしてから分割する。
訓練データの分布は異なってても問題ない。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;訓練:テスト = 70:30&lt;/code&gt;とか、&lt;code&gt;訓練:dev:テスト = 60:20:20&lt;/code&gt;とかいう比率は、1万くらいのデータなら適当。
けど100万くらいなら、98:1:1くらいが妥当。&lt;/p&gt;

&lt;p&gt;テストデータはモデルの最終評価をするためのものなので、どれだけ評価したいかによってサイズを変える。
0もありがちだけど、非推奨。&lt;/p&gt;

&lt;p&gt;猫の画像のなかにエロ画像が混じっちゃうようなモデルはだめ。
猫判定率が多少下がっても、エロ画像が含まれないほうがまし。
こういう場合は評価指標を変える必要がある。
エロ画像を猫と判定した場合にペナルティを大きくするなど。&lt;/p&gt;

&lt;p&gt;直行化の観点で言うと、指標を決めるのと、その指標に従って最適化するのは、別のタスクとして扱うべき。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;人並性能(Human-level performance)との比較&lt;/p&gt;

&lt;p&gt;人並性能とは、人が手動で達成できる精度。そのエラー率、つまり人並誤差(Human-level error)はベイズ誤差(Bayes optimal error)に近い。&lt;/p&gt;

&lt;p&gt;モデルを改良していくと、人並性能を超え、その後改善速度は鈍化し、人並誤差はベイズ誤差に漸近していく。
鈍化する理由は、人並性能がベイズ誤差に近いのと、人以上の精度に人がチューニングするのが無理があるから。
人手でラベル付きデータを作れないし、エラー分析もできなくなるので。&lt;/p&gt;

&lt;p&gt;人並誤差より訓練データでのエラー率が結構高いなら、高バイアス対策をする。
人並誤差と訓練データでのエラー率が近くて、devデータでのエラー率が結構高いなら、高バリアンス対策をする。
人並誤差と訓練データでのエラー率との差ををAndrew先生は可避バイアス(Avoidable bias)と名付けた。&lt;/p&gt;

&lt;p&gt;人並誤差はベイズ誤差の近似として使える。
人並誤差は、ある判別問題に関して、その道のエキスパート達が議論して解を出すみたいな、人類が全力を尽くしたうえでの誤差とする。
人並誤差が分かれば、訓練データとdevデータのエラー率を見て、高バイアスか高バリアンス化を判別できる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;モデルの性能改善手順&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;訓練データにフィットさせ、可避バイアスを最小化する。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;モデルを大きくする。&lt;/li&gt;
&lt;li&gt;最適化アルゴリズムを高度なものにするか、長く訓練する。&lt;/li&gt;
&lt;li&gt;NNのレイヤを深くしたり隠れ層のノードを増やしたり、CNNとかRNNとかの高度なアーキテクチャにする。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;dev・テストデータで評価し、バリアンスを下げる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;データを増やす。&lt;/li&gt;
&lt;li&gt;正則化する。&lt;/li&gt;
&lt;li&gt;ハイパーパラメータをいじる。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Andrej Karpathyへのインタビュー&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;エラー分析&lt;/p&gt;

&lt;p&gt;エラー率が高いときに、エラーが起きたdevデータのサンプルを見て原因を分析する。
天井分析(Ceiling analysis)も併せてやる。
例えば、猫判定器で、犬を猫と判定したサンプルがあったとして、犬の問題に取り組むかどうかは、全体のエラーサンプル数に対する犬のエラーサンプル数の割合を見て、その取り組みで最大どれだけの効果を得るかを分析する。&lt;/p&gt;

&lt;p&gt;天井分析を複数の問題点に対してやれば、どれに時間をかける価値があるかの指標を得られる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ラベリングミスへの対処&lt;/p&gt;

&lt;p&gt;ディープラーニングは、ランダムエラーに対して堅牢で、訓練データに多少のラベリングミスがあっても問題なく動く。&lt;/p&gt;

&lt;p&gt;devデータにミスがあった場合、エラー分析の際にそれも数えておいて、対処すべきかどうかを判断する。
他の問題によるエラーの割合と比べて、ラベリングミスによるものの割合が大きければ対処すればいいし、そうでなければほっておく。
また、エラー全体に対するラベリングミスの割合が大きくなると、モデルの性能比較に支障が出てくるので、そうなったらラベリングミスに対処する必要が高まってくる。&lt;/p&gt;

&lt;p&gt;devデータのラベリングミスを直すときは、テストデータも同時に直し、分布に違いが出ないようにする。
また、エラーなサンプルだけじゃなく、正答したサンプルも見直すべし。
けど、訓練データは直さなくてもいい。数も多いし、devデータと分布が違っていても問題ないし。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;新しいディープラーニングシステムを作るときのガイドライン&lt;/p&gt;

&lt;p&gt;あまり経験のない分野のシステムを新たに作るなら、早く立ち上げてイテレーションを回すべし。
具体的には、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;dev・テストデータと、指標を用意する。&lt;/li&gt;
&lt;li&gt;さっさとシステムを実装する。&lt;/li&gt;
&lt;li&gt;バイアス/バリアンス分析やエラー分析をして、次のアクションを決める。&lt;/li&gt;
&lt;li&gt;システムを改善する。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;というのを速く回す。
経験が深かったり、確かな研究結果がすでにあったりするなら、最初から凝ったシステムにしてもいい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;訓練データとdev・テストデータの分布のミスマッチ&lt;/p&gt;

&lt;p&gt;ディープラーニングでは訓練データは大抵不足するから、現実的に、訓練データはいろんなデータのかき集めで、dev・テストデータとは分布が異なってくる。&lt;/p&gt;

&lt;p&gt;例えば、実際のデータが10000個で、かき集めのが200000個あったら、全部合わせてシャッフルしてデータ分割するのは、dev・テストデータの質が悪くなるのでダメ。
dev・テストデータには実際のデータだけ使って、かき集めのは全部訓練データに使うべし。&lt;/p&gt;

&lt;p&gt;分布がミスマッチになると、バイアス/バリアンス分析がむずくなる。
devデータでエラーが増えても、単にdevデータのほうが判別が難しいデータなのかもしれない。&lt;/p&gt;

&lt;p&gt;分析をしやすくするため、訓練devデータを作る。
これは、訓練データと同じ分布のデータで訓練に使わないデータ。訓練データのサブセット。&lt;/p&gt;

&lt;p&gt;訓練データと訓練devデータのエラー率の差が大きければオーバーフィット。
訓練データと訓練devデータのエラー率の差が小さくて、devデータのエラー率が高いなら、データミスマッチ問題(Data missmatch problem)。&lt;/p&gt;

&lt;p&gt;あんまり発生しないけど、devデータよりテストデータのエラー率が結構大きいなら、devデータにオーバーフィットしてるので、devデータサイズを増やしたりする必要がある。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;データミスマッチ問題への対応&lt;/p&gt;

&lt;p&gt;データミスマッチ問題が発覚したら、訓練データをdevデータに近づけたり、devデータに近いものを訓練データに加えたりすることを考える。
例えば、車内の音声認識のためのモデルを開発していて、devデータに車の雑音が入っていることが分かったら、訓練データにそういう雑音を合成してやるなど。
ただし、その場合、同じ雑音をすべての訓練データに適用すると、その雑音にモデルがオーバーフィットするリスクがあるので注意。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;転移学習(Transfer learning)&lt;/p&gt;

&lt;p&gt;ある問題に対して作ったモデルを、別の問題に再利用する。
(但し入力は同種のデータ。画像なら画像、音声なら音声。)
その際、NNの、出力層だけのパラメータをランダム初期化したり、層を足したりして、あたらしい訓練データで学習させる。
新たな訓練データが少ない場合は、後ろの1,2層だけを再学習させ、データがたくさんあったら全体を再学習させる。&lt;/p&gt;

&lt;p&gt;最初の学習を事前学習(Pre-training)、新たなデータでの学習をファインチューニング(Fine tuning)という。
画像認識の分野でよく使われる。NNの浅い層のほうが、汎用的な特徴(エッジ検出など)を学習するので再利用できると考えられているが、詳しい原理は判明していない。&lt;/p&gt;

&lt;p&gt;事前学習するデータより、ファインチューニングに使えるデータが少ないときに効果的。
データ量が同じくらいだったり、後者のほうが多い場合は、最初から目的のデータで学習させたほうがいい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;マルチタスク学習(Multi-task learning)&lt;/p&gt;

&lt;p&gt;一度に複数の判別をさせるモデルをつくる。
ソフトマックス層つかった多クラス分類に似てるけど、一つのサンプルから複数のクラスを検出する。
例えば車と歩行者と標識など。
物体検知によく使われる。&lt;/p&gt;

&lt;p&gt;一つ一つのクラスのデータが少なくても低層が学んだ共通特徴を活用できるので、一つのタスクをするNNを複数訓練するより性能が良くなることがある。&lt;/p&gt;

&lt;p&gt;ラベルが歯抜けでも学習できる。&lt;/p&gt;

&lt;p&gt;複数タスクをこなすため、大き目なネットワークにする必要がある。&lt;/p&gt;

&lt;p&gt;それぞれのクラスのデータが十分あるときはあまり使われない手法。
目的のクラスのデータが少ないとき、転移学習のほうがよく使われる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;End-to-end学習&lt;/p&gt;

&lt;p&gt;従来、ある入力から解となる出力を得るのに、パイプラインで複数の処理をしていたが、これを全部一つのNNで処理する手法。
データ量が多いと上手くいく。&lt;/p&gt;

&lt;p&gt;例えば、人の認識をするときパイプラインでは、顔検出して、拡大してクロップしてからNNにかける。
こっちのほうが個々のタスクがシンプルで、それぞれのデータも手に入りやすいので性能を出しやすい。
けどもし、end-to-endのラベル付きデータが十分にあればend-to-end学習でもいける。&lt;/p&gt;

&lt;p&gt;翻訳タスクの場合、現実的に大量のデータが手に入るので、end-to-endで上手くいく。&lt;/p&gt;

&lt;p&gt;データさえたくさんあれば、パイプラインのコンポーネント的なところも勝手に学んでくれるので、ヒトが考え付くよりもいい特徴を学んでくれるかもしれない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Ruslan Salakhutdinovへのインタビュー&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CourseraのDeep Learning SpecializationのImproving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimizationコースを修了した</title>
          <link>https://www.kaitoy.xyz/2018/01/12/coursera-deep-learning-improving-deep-neural-networks/</link>
          <pubDate>Fri, 12 Jan 2018 23:41:57 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/01/12/coursera-deep-learning-improving-deep-neural-networks/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2018/01/05/coursera-deep-learning-neural-networks-and-deep-learning/&#34;&gt;CourseraのDeep Learning SpecializationのNeural Networks and Deep Learningコースを修了した&lt;/a&gt;のに続き、&lt;a href=&#34;https://www.coursera.org/learn/deep-neural-network&#34;&gt;Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimizationコース&lt;/a&gt;を修了した。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;このコースは、ディープニューラルネットワークのチューニングなどについて学べる3週間のコース。
今のところ全部英語。&lt;/p&gt;

&lt;p&gt;2018/1/5に始めて、1/12に完了。
8日間かかった。
修了したらまた&lt;a href=&#34;https://www.coursera.org/account/accomplishments/certificate/5VS9EJJ6TJ3A&#34;&gt;Certifacate&lt;/a&gt;もらえた。&lt;/p&gt;

&lt;p&gt;以下、3週分の内容をメモ程度に書いておく。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;p&gt;OverfittingやUnderfittingを防ぐテクニックについて。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;データ分割&lt;/p&gt;

&lt;p&gt;深層学習のモデル構築は、検討(Idea)、実装(Code)、検証(Experiment)というサイクルの繰り返し(Iterative process)。
取り組む課題、課題のドメイン、データ量、マシンの構成などにより、ハイパーパラメータは変わるので、経験をもって事前に予測することは無理なので、サイクルをどれだけ速く回せるかが鍵。&lt;/p&gt;

&lt;p&gt;データは、訓練データ(Training set)、Devデータ(Development set))(a.k.a. Cross-validation set)、テストデータ(Test set)に分割する。
訓練データで学習し、Devデータでハイパーパラメータを評価し、テストデータで最終的な評価と性能見積をする。
テストデータは無くてもいい。&lt;/p&gt;

&lt;p&gt;サンプル数が1万くらいだった時代は、6:2:2くらいで分割してたけど、近年は数百万とかのデータを扱い、交差検証データやテストデータの割合はもっと小さくするのがトレンド。
98:1:1など。&lt;/p&gt;

&lt;p&gt;Devデータとテストデータは同じようなものを使うべき。
訓練データは必ずしも同様でなくてもいい。訓練データは沢山要るので、別のデータソースからとることもある。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;バイアス vs バリアンス&lt;/p&gt;

&lt;p&gt;でかいネットワークで正則化して大量データで学習させるのが吉。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;正則化&lt;/p&gt;

&lt;p&gt;過学習(Overfitting)を防ぐため、コスト関数を正則化(Regularization)すべし。&lt;/p&gt;

&lt;p&gt;ロジスティック回帰ではL2ノルム(L2 norm)を使ったL2正則化が一般的。
L1正則化はあまり使われない。
L1正則化をすると、wがスパース行列になってモデルを圧縮できると言われることがあるが、経験上その効果はほとんどない。&lt;/p&gt;

&lt;p&gt;正則化パラメータλはハイパーパラメータで、Devデータで評価する。&lt;/p&gt;

&lt;p&gt;ニューラルネットワークでは正則化項にフロベニウスノルム(Frobenius norm)を使う。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dropout(Inverted Dropout)&lt;/p&gt;

&lt;p&gt;ランダムにノードを無効化しながら学習することで過学習を防ぐ。
画像処理の分野では、特徴量の数が多く学習データが少ない傾向があるので、ほぼ常に使われる。&lt;/p&gt;

&lt;p&gt;コスト関数が計算できなくなるのが欠点。
計算する必要があるときにはDropoutを無効化する。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;データ拡張(Data augmentation)&lt;/p&gt;

&lt;p&gt;データを加工して増やせば、高バリアンス対策になる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;早期終了(Early stopping)&lt;/p&gt;

&lt;p&gt;過学習するまえに学習を止めるテクニック。
訓練データとDevデータについてコストをプロットして、Devデータのものが上がる前に止める。&lt;/p&gt;

&lt;p&gt;これは、直交化(Orthogonalization)の原則、つまり一度に一つのことを考慮すべきという原則に反していて、コストを最小化するという問題と、過学習を避けるという問題に同時に対処することになるので微妙。&lt;/p&gt;

&lt;p&gt;普通は代わりにL2正則化使えばいいけど、λを最適化する手間を省きたいときには選択肢になりうる、というか実現場ではちょくちょく選択肢になる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;訓練データの正規化(Normalization)&lt;/p&gt;

&lt;p&gt;訓練データの各特徴量について平均を0にして分散を1にすると学習が速くなる。&lt;/p&gt;

&lt;p&gt;訓練データを正規化したらテストデータも正規化する。
その際、正規化パラメータは訓練データのものを使う。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;勾配消失(Vanishing gradient)、勾配爆発(Exploding gradient)&lt;/p&gt;

&lt;p&gt;ニューラルネットワークの層が深くなると、層の出力や勾配が指数関数的に大きくなったり小さくなったりして、学習が難しくなる問題。
長年ディープニューラルネットワークの発展を妨げてきた問題。&lt;/p&gt;

&lt;p&gt;パラメータのランダム初期化をすると防げる。
ガウス分布で作ったパラメータに特定の値を掛けてを分散が1/n(ReLUの時は2/n)になるように調整して、活性化関数に入力する値を約1に抑える。
掛ける値は活性化関数ごとにだいたい決まっていて((e.g. Xavier Initialization)、その値をハイパーパラメータとして調整するのはそれほど優先度は高くない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Gradient checking&lt;/p&gt;

&lt;p&gt;順伝播・逆伝播が正確に実装できているかを、数値計算手法で概算した勾配と逆伝播で出した勾配を比べてチェックするテクニック。
計算コストが高くなるので、デバッグ時にのみ使う。&lt;/p&gt;

&lt;p&gt;Dropoutしてるときには使えない。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;初期化&lt;/p&gt;

&lt;p&gt;ゼロ初期化、大きい値でのランダム初期化、He初期化(Xavier初期化っぽいやつ)を実装して性能を比べる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;正則化&lt;/p&gt;

&lt;p&gt;正則化無し、L2正則化、Dropoutの実装と比較。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Gradient checking&lt;/p&gt;

&lt;p&gt;Gradient checkingの実装と、その結果を利用した逆伝播のデバッグ。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Yoshua Bengioへのインタビュー&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;p&gt;学習を速くするテクニックについて。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ミニバッチ勾配降下法(Mini-batch gradient descent)&lt;/p&gt;

&lt;p&gt;普通の勾配降下法(i.e. バッチ勾配降下法)よりかなり速いので、大規模データでよく使われるテクニック。
学習回数に対するコストのプロットはノイジーになる。&lt;/p&gt;

&lt;p&gt;ミニバッチサイズというハイパーパラメータが増える。
ミニバッチサイズがmならバッチ勾配降下法、1なら確率的勾配降下法(Stochastic gradient descent)になる。&lt;/p&gt;

&lt;p&gt;ミニバッチ勾配降下法と確率的勾配降下法は収束しない。&lt;/p&gt;

&lt;p&gt;バッチ勾配降下法は遅すぎる。
確率的勾配降下法はベクトル化の恩恵がなくなるという欠点がある。
ので、適当なミニバッチサイズにするのがよく、それが一番速い。&lt;/p&gt;

&lt;p&gt;2000個くらいのデータならバッチ勾配降下法。
それより多ければ、64～512位のミニバッチサイズがいい。
メモリ効率を考えると2の累乗数がいいし、CPU/GPUメモリサイズに乗るサイズにすべし。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;指数加重移動平均 (EWMA: Exponentially Weighted Moving Average)&lt;/p&gt;

&lt;p&gt;ノイズのあるデータから、よりスムーズなプロットを書く手法。
過去数日の平均をもとにプロットする。&lt;/p&gt;

&lt;p&gt;この手法だと、最初の方のデータが不当に小さくなってしまう。
これが問題になるなら、バイアス補正(Bias correction)をかける。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;モーメンタム(Momentum)付き勾配降下法&lt;/p&gt;

&lt;p&gt;パラメータを更新するときに、勾配そのままではなく、勾配の指数加重移動平均を使う手法。
勾配降下を滑らかに速くできる。
慣性(勢い)をつけて走り抜ける感じ。&lt;/p&gt;

&lt;p&gt;指数加重移動平均を計算するときのβが新たなハイパーパラメータになる。
普通0.9。この場合バイアス補正はそんなに効果ないので普通かけない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;RMSprop&lt;/p&gt;

&lt;p&gt;パラメータを更新するときに、勾配そのままではなく、勾配の二乗平均平方根(RMS: Root Mean Square)を使う手法。
学習率を上げつつ、勾配降下を滑らかに速くできる。&lt;/p&gt;

&lt;p&gt;二乗平均平方根を計算するときのβと、ゼロ除算を防ぐためのεが新たなハイパーパラメータになる。
提唱者は、&lt;code&gt;β=0.999&lt;/code&gt;、&lt;code&gt;ε=10^-8&lt;/code&gt;を推奨しているし、これらをチューニングすることはあまりない。&lt;/p&gt;

&lt;p&gt;Couseraが広めたことで、よく使われるようになった。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Adam(Adaptive Moment Estimation)&lt;/p&gt;

&lt;p&gt;モーメンタムとRMSpropとバイアス補正を組み合わせた最適化アルゴリズム。
これをミニバッチ勾配降下法と一緒に使えばだいたい上手くいく。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;学習率減衰(Learning rate decay)&lt;/p&gt;

&lt;p&gt;ミニバッチ勾配降下を収束させるために、学習率を徐々に小さくする手法。
エポックごとに学習率を下げる。&lt;/p&gt;

&lt;p&gt;学習率αが、α0と 減衰率(Decay rate)とエポック番号から計算されるようになるので、α0と減衰率がハイパーパラメータ。&lt;/p&gt;

&lt;p&gt;学習率の計算方法にはいくつかある。
指数関数的に下げたり、階段状に下げたり。&lt;/p&gt;

&lt;p&gt;Andrew先生はあまり使わない手法。
学習率をよくチューニングすれば十分。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;局所最適解(Local optima)&lt;/p&gt;

&lt;p&gt;かつて、勾配が0になる点は、コストの谷、つまり局所最適解だと考えられていて、そこに嵌ることが問題だった。&lt;/p&gt;

&lt;p&gt;けど、ディープニューラルネットワークでは多くは尾根的なもの。
鞍の上みたいな部分なので鞍点(Saddle point)と呼ばれる。
特徴量が沢山あるので、ちょっと動かすとどれかの勾配は負になる。&lt;/p&gt;

&lt;p&gt;よって局所最適解はあまり恐れなくていい。
代わりに、鞍点の台地みたいな部分では勾配が小さいので学習効率が悪くなる。
ここを勢いよく抜けたいので、モーメンタムやRMSpropやAdamが有効になる。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ミニバッチ勾配降下法実装&lt;/p&gt;

&lt;p&gt;訓練データをシャッフルして、ミニバッチサイズに分割して(余りは余りでミニバッチにする)、forループで回す。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;モーメンタムとAdam実装&lt;/p&gt;

&lt;p&gt;単なるミニバッチ勾配降下法とモーメンタム付きとAdamを比較。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Yuanqing Linへのインタビュー&lt;/p&gt;

&lt;p&gt;中国の国立深層学習研究所のトップ。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;p&gt;ハイパーパラメータのチューニング方法、バッチ正規化、ソフトマックス回帰、TensorFlow。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;動画&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ハイパーパラメータのチューニング&lt;/p&gt;

&lt;p&gt;一番重要なのは学習率。
次はモーメンタムのβとかミニバッチサイズとか隠れ層のノード数。
その次がレイヤ数とか学習率減衰率。&lt;/p&gt;

&lt;p&gt;チューニングの際は、かつてはグリッドサーチ(Grid search)がよく使われたけど、これはハイパーパラメータが多くなるとつらい。
ランダムサーチ(Randomized search)がより効率的。&lt;/p&gt;

&lt;p&gt;グリッドサーチだとあるパラメータを固定して別のパラメータを変化させるけど、変化させたパラメータがどうでもいいものだった場合、その試行がほとんど無駄になるので。&lt;/p&gt;

&lt;p&gt;粗くランダムサーチして当たりをつけ、範囲を絞って細かいランダムサーチする。&lt;/p&gt;

&lt;p&gt;ランダムといってもいろいろあって、ユニット数なんかは一様にランダムでいいけど、学習率なんかはlogスケールの上でランダムにしたほうがいい。&lt;/p&gt;

&lt;p&gt;実運用では、計算リソースが少ない場合に採るパンダアプローチと、潤沢なリソースで複数のモデルを同時に訓練するキャビアアプローチがある。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;バッチ正規化(Batch normalization)&lt;/p&gt;

&lt;p&gt;深層学習の実用化において最も重要なアルゴリズムの一つ。
ハイパーパラメータの選定を簡単にして、ディープニューラルネットワークの訓練を簡単にする。&lt;/p&gt;

&lt;p&gt;バッチ正規化では、各層の入力を正規化する。
ミニバッチごとに平均を0、分散を1に正規化した後、βとγというパラメータでそれぞれを調整する。
aよりz(i.e. 活性化関数適用前)を正規化するのが普通。&lt;/p&gt;

&lt;p&gt;(ハイパーではない)パラメータとしてβとγが層ごとに増える。
これらもWとともに学習する。
βがbの役割をするので、bはいらなくなる。&lt;/p&gt;

&lt;p&gt;バッチ正規化は共変量シフト(Covariate shift)という問題に対応するもの。
共変量シフトは、訓練した後で入力の分散が変わると、また訓練しなおさないといけないという問題。
ニューラルネットワークの内部では、前のほうの層のWが学習を進めるたびに変わり、その層の出力が変わる。
つまり後のほうの層への入力が変わるので、後のほうの層の学習が進みにくい。
バッチ正規化は、この後のほうの層への入力の分散を一定範囲に抑えることで、後のほうの層の学習を効率化する。&lt;/p&gt;

&lt;p&gt;Dropoutと同様な論理(ノードへの依存が分散される)で正則化の効果もややある。&lt;/p&gt;

&lt;p&gt;訓練が終わったら、最後のミニバッチの平均μと分散σ^2を保存しておいて、予測時に使う。
μとσ^2は訓練データ全体から再計算してもよさそうだけど、普通はやらない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ソフトマックス回帰(Softmax regression)&lt;/p&gt;

&lt;p&gt;ニューラルネットワークで多値分類(Multi-class classification)するアルゴリズム。
出力層(ソフトマックス層)のノード数をクラス数にして、活性化関数にソフトマックス関数を使う。
出力層の各ノードは、サンプルが各クラスに属する確率を出力する。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;TensorFlow&lt;/p&gt;

&lt;p&gt;ディープラーニングフレームワークはいろいろある: Caffe/Caffe2、CNTK、DL2J、Keras、Lasagne、mxnet、PaddlePaddle、TensorFlow、Theano、Torch。
プログラミングしやすいこと、訓練性能がいいこと、オープンであることが重要。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;TensorFlowの基本&lt;/p&gt;

&lt;p&gt;TensorFlowでのプログラムはだいたい以下のような手順で書く。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;テンソル(tensor)をつくる。これはまだ評価されない。&lt;/li&gt;
&lt;li&gt;テンソル間の計算式(計算グラフ)を書く。&lt;/li&gt;
&lt;li&gt;テンソルを初期化する。&lt;/li&gt;
&lt;li&gt;セッションを作る。&lt;/li&gt;
&lt;li&gt;セッションを実行する。ここで計算が実行される。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;後で(セッション実行時に)値を入れたい場合はプレースホルダ(placeholder)を使う。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;TensorFlowでのニューラルネットワーク実装&lt;/p&gt;

&lt;p&gt;画像を読み込んで多クラス分類するNNを作る。
以下、今回使った関数の一部。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;シグモイド関数: &lt;code&gt;tf.sigmoid(x)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;エントロピーコスト: &lt;code&gt;tf.nn.sigmoid_cross_entropy_with_logits(logits, labels)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;One-hotエンコーディング: &lt;code&gt;tf.one_hot(labels, depth, axis)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;最急降下法: &lt;code&gt;tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CourseraのDeep Learning SpecializationのNeural Networks and Deep Learningコースを修了した</title>
          <link>https://www.kaitoy.xyz/2018/01/05/coursera-deep-learning-neural-networks-and-deep-learning/</link>
          <pubDate>Fri, 05 Jan 2018 15:20:23 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2018/01/05/coursera-deep-learning-neural-networks-and-deep-learning/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;https://www.kaitoy.xyz/2017/12/22/coursera-machine-learning/&#34;&gt;CourseraのMachine Learningコース&lt;/a&gt;に続いて、同じくAndrew先生による&lt;a href=&#34;https://www.coursera.org/specializations/deep-learning&#34;&gt;Deep Learning Specialization&lt;/a&gt;を受講中。&lt;/p&gt;

&lt;p&gt;これは深層学習の基本を学べるもので、以下の5つのコースからなる。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Neural Networks and Deep Learning&lt;/li&gt;
&lt;li&gt;Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization&lt;/li&gt;
&lt;li&gt;Structuring Machine Learning Projects&lt;/li&gt;
&lt;li&gt;Convolutional Neural Networks&lt;/li&gt;
&lt;li&gt;Sequence Models&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;この内、最初のNeural Networks and Deep Learningを修了したので、記念にブログしておく。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h1 id=&#34;deep-learning-specializationとは&#34;&gt;Deep Learning Specializationとは&lt;/h1&gt;

&lt;p&gt;Deep Learning Specializationは&lt;a href=&#34;https://learner.coursera.help/hc/en-us/articles/208280296&#34;&gt;Coursera Specialization&lt;/a&gt;のひとつ。
Coursera Specializationはサブスクリプションモデルで、つまりあるSpecializationのサブスクリプションを購入すると、受講完了するまで毎月定額の料金を支払うことになる。&lt;/p&gt;

&lt;p&gt;Deep Learning Specializationは月$49で、5コース合わせて13週+α分の内容。
(Sequence Modelsが2018年1月に公開予定となっていて、現時点でまだ公開されていないので内容が不明。)
最初の7日間はトライアルで無料なので、この間に全部終わらせられればタダ。
無理だけど。&lt;/p&gt;

&lt;p&gt;Deep Learning Specializationでは、PythonとTensorFlowでディープニューラルネットワーク、CNN、RNN、LSTM、Adam、Dropout、バッチ正規化、Xavier/He initializationなどを学べる。
Machine Learningコースと同じく、5分～15分くらいの動画による講義と、小テストと、プログラミング課題から構成されている。&lt;/p&gt;

&lt;p&gt;プログラミング課題は、coursera hubという、ホステッドJupyter Notebookで解いて提出できるので楽。&lt;/p&gt;

&lt;h1 id=&#34;neural-networks-and-deep-learningコースとは&#34;&gt;Neural Networks and Deep Learningコースとは&lt;/h1&gt;

&lt;p&gt;ディープニューラルネットワークの仕組みを学んで実装する4週間のコース。
また、深層学習の偉い人へのインタビューを見れる。
Machine Learningコースと被っている内容が少なくなく、かなり楽だったが、結構ペースが速いので、Machine Learningコースをやっていなかったら辛かったと思う。&lt;/p&gt;

&lt;p&gt;動画は大抵日本語字幕が付いている。
日本語字幕が付いていない奴は、英語字幕が機械生成したっぽいもので見辛い。&lt;/p&gt;

&lt;p&gt;2018/1/1に始めて、1/5に完了。
5日間かかった。
修了したら&lt;a href=&#34;https://www.coursera.org/account/accomplishments/certificate/G77XMU9TNEKX&#34;&gt;Certifacate&lt;/a&gt;もらえた。&lt;/p&gt;

&lt;p&gt;以下、4週分の内容をキーワードレベルで書いておく。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;深層学習(Deep Learning)概要&lt;/p&gt;

&lt;p&gt;AIは次世代の電気。産業革命を起こす。
AIで今一番熱い分野が深層学習。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ニューラルネットワーク(Neural Network)。&lt;/li&gt;
&lt;li&gt;畳み込みニューラルネットワーク(CNN: Convolutional Neural Network)。&lt;/li&gt;
&lt;li&gt;再帰型ニューラルネットワーク(RNN: Recurrent Neural Network)。&lt;/li&gt;
&lt;li&gt;深層学習の適用分野・例。&lt;/li&gt;
&lt;li&gt;深層学習が実用化した背景。&lt;/li&gt;
&lt;li&gt;シグモイド関数(Sigmoid function) vs ReLU(Rectified Linear Unit)関数。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;深層学習のゴッドファーザー、Geoffrey Hintonへのインタビュー。&lt;/p&gt;

&lt;p&gt;ニューラルネットワークの黎明期を支え、ReLU関数の有効性を証明したりボルツマンマシンを発明したりした人。
自身が歩んできた深層学習の歴史や今取り組んでいる・注目している理論について、
高尚な話をしていたようだったが、高尚すぎてよくわからなかった。&lt;/p&gt;

&lt;p&gt;今日成果を出しているのは教師あり学習だけど、教師無し学習のほうが重要と考えているとのこと。&lt;/p&gt;

&lt;p&gt;これから機械学習に取り組む人へ、以下のアドバイスをしていた。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;文献を読みすぎるな。&lt;/li&gt;
&lt;li&gt;文献を読んで、間違っていると感じるところをみつけて、それに取り組め。&lt;/li&gt;
&lt;li&gt;人から何を言われても気にせず、自分の信念に従って研究しろ。&lt;/li&gt;
&lt;li&gt;誰かに無意味なことをしていると指摘されたら、むしろ価値のあることをしていると思え。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ニューラルネットワークプログラミングの基礎&lt;/p&gt;

&lt;p&gt;ロジスティック回帰は小さい(1層1ノード)ニューラルネットワーク。
ロジスティック回帰の微分を逆伝播で計算する。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;二値分類(Binary classification)、ロジスティック回帰(Logistic regression)。&lt;/li&gt;
&lt;li&gt;損失関数(Loss function)、交差エントロピー(Cross entropy)、目的関数(Cost function)。&lt;/li&gt;
&lt;li&gt;最急降下法(Gradient descent)。&lt;/li&gt;
&lt;li&gt;微分(Derivatives)。&lt;/li&gt;
&lt;li&gt;逆伝播(Backpropagation)、計算グラフ(Computation graph)、連鎖律(Chain rule)。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Pythonとベクトル化(Vectorization)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;forループ vs ベクトル化。&lt;/li&gt;
&lt;li&gt;Jupyter Notebook、NumPy、ブロードキャスト(Broadcasting)。&lt;/li&gt;
&lt;li&gt;ロジスティック回帰のベクトル化。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ロジスティック回帰で猫の画像の判別。&lt;/li&gt;
&lt;li&gt;NumPy、h5py、Matplotlib、PIL、SciPy。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;深層学習とロボットの研究者、Pieter Abbeelへのインタビュー&lt;/p&gt;

&lt;p&gt;深層強化学習の有名な研究者。DQN。&lt;/p&gt;

&lt;p&gt;かつて、機械学習で成果を出すためには、取り組んでいる課題特有の分野の知識が必要だったが、2012年にGeoffreyが発表したAlexNetがそれを覆した。
Pieterはそのアイデアを深層強化学習に適用し発展させた。&lt;/p&gt;

&lt;p&gt;強化学習は、どこからデータ収集するのか、報酬の分配はどうするかといったところに課題がある。
また、安全性にも課題。学習の過程で失敗を繰り返すので、自動運転などをどう学習させるか、またどう学び続けさせるか。
ネガティブデータを集めるのがむずい。&lt;/p&gt;

&lt;p&gt;短時間の実験でうまくいっても、長時間の稼働でうまくいくとも限らない。&lt;/p&gt;

&lt;p&gt;強化学習は複雑すぎるので、アルゴリズム自体を学習できるようにしたい。
プログラムを自動で変更しながら学習するなど。&lt;/p&gt;

&lt;p&gt;強化学習は、アルゴリズムを変更しなくても様々なことを学べる。
けど、ゼロから学ぶと時間がかかるので、以前学んだことを活かして次の課題に取り組めるようにするのが最先端の研究。&lt;/p&gt;

&lt;p&gt;まずは教師あり学習で人の代わりができるようになり、その後目的を与えて、強化学習で改善していく、っていう感じのことができるとうれしい。&lt;/p&gt;

&lt;p&gt;これから機械学習に取り組む人へ、以下のアドバイスをしていた。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;需要が高まっているので、AIを始めるにはよい時期。&lt;/li&gt;
&lt;li&gt;オンライン講座がたくさんあるので、学びやすい。自分で試したり再現したりしてみることが重要。&lt;/li&gt;
&lt;li&gt;TensorFlow、Chainer、Theano、PyTorchなど、手軽に試せるツールが色々ある。&lt;/li&gt;
&lt;li&gt;専門的な教育を受けなくても、自己学習でトップクラスになれる。&lt;/li&gt;
&lt;li&gt;機械学習を学ぶのに、大学で研究すべきか大企業で仕事を得るべきかについては、どれくらいの指導を受けれるかによる。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;3週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;浅いニューラルネットワーク&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ロジスティック回帰を多重にして2層のニューラルネットワーク化。&lt;/li&gt;
&lt;li&gt;ニューラルネットワークアルゴリズムのベクトル化。&lt;/li&gt;
&lt;li&gt;活性化関数(Activation function)の選択: シグモイド vs tanh vs ReLU vs Leaky ReLU vs 線形活性化関数(Linear activation function)。&lt;/li&gt;
&lt;li&gt;順伝播(Forward propagation)、逆伝播(Backpropagation)。&lt;/li&gt;
&lt;li&gt;ランダム初期化(Random initialization)。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;二値分類するニューラルネットワークを実装。&lt;/li&gt;
&lt;li&gt;scikit-learn。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;GAN(Generative Adversarial Network)の発明者、Ian Goodfellowへのインタビュー&lt;/p&gt;

&lt;p&gt;GANは生成モデル(学習したデータに似たデータを生成するモデル)。
バーで飲んでいるときに思いつき、一晩で実装した。&lt;/p&gt;

&lt;p&gt;GANは今は繊細過ぎるのが課題で、安定性の向上に今取り組んでいる。&lt;/p&gt;

&lt;p&gt;機械学習のセキュリティにも興味がある。モデルをだまして想定外の動作をさせるような攻撃への対策など。&lt;/p&gt;

&lt;p&gt;これから機械学習に取り組む人へ、以下のアドバイスをしていた。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;機械学習のアルゴリズムよりも、線形代数や確率といった数学の基礎を習得することが重要。&lt;/li&gt;
&lt;li&gt;AIの道を進むのに、近年では博士号は必ずしも要らない。コードを書いてGitHubに上げろ。自身も実際に、オープンソース活動をしているひとの貢献を見て興味をもって採用したことがある。&lt;/li&gt;
&lt;li&gt;論文を公開するとよりいいけど、コードのほうが楽。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;4週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;深いニューラルネットワーク&lt;/p&gt;

&lt;p&gt;3層以上のニューラルネットワーク。その実装方法と有効性について。
ハイパーパラメータ(Hyperparameters): 学習率(Learning rate)、学習回数、レイヤ数、ノード数、活性化関数、等。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;プログラミング課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ディープニューラルネットワークの実装。&lt;/li&gt;
&lt;li&gt;再度猫画像の判別。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CourseraのMachine Learningコースを修了した</title>
          <link>https://www.kaitoy.xyz/2017/12/22/coursera-machine-learning/</link>
          <pubDate>Fri, 22 Dec 2017 10:20:44 JST</pubDate>
          <author>Kaito Yamada</author>
          <guid>https://www.kaitoy.xyz/2017/12/22/coursera-machine-learning/</guid>
          <description>

&lt;p&gt;機械学習の入門教材として有名な&lt;a href=&#34;https://www.coursera.org/learn/machine-learning&#34;&gt;CourseraのMachine Learningコース&lt;/a&gt;を修了した記念日記。&lt;/p&gt;

&lt;p&gt;



&lt;script async src=&#34;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;
&lt;ins class=&#34;adsbygoogle&#34;
     style=&#34;display:block&#34;
     data-ad-client=&#34;ca-pub-6244473643910448&#34;
     data-ad-slot=&#34;1845600530&#34;
     data-ad-format=&#34;auto&#34;&gt;&lt;/ins&gt;
&lt;script&gt;
(adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;courseraとは&#34;&gt;Courseraとは&lt;/h2&gt;

&lt;p&gt;Courseraは、2012年にスタンフォード大学のコンピュータ工学科の2人の教授によって設立されたサービスで、世界トップクラスの大学の講座をオンラインで受けることができるもの。
東京大学とも提携している。&lt;/p&gt;

&lt;p&gt;講座の一部は無料で受けることができる。&lt;/p&gt;

&lt;h2 id=&#34;courseraのmachine-learningコースとは&#34;&gt;CourseraのMachine Learningコースとは&lt;/h2&gt;

&lt;p&gt;Machine Learningコースは、Courseraの設立者の一人であるAndrew Ngによる、機械学習の基礎から実践まで浅く広く(?)学べる世界的に有名な講座。
Andrew先生は一時期Googleで働き、&lt;a href=&#34;https://en.wikipedia.org/wiki/Google_Brain&#34;&gt;Google Brain&lt;/a&gt;というDeep Learningのプロジェクトをリードしていたこともある機械学習のエキスパートで、さらにスタンフォードの教授だっただけあって教え方が非常にうまくてわかりやすい。&lt;/p&gt;

&lt;p&gt;この講座は主に、5分～15分くらいの動画による講義と、小テストと、プログラミング課題から構成されている。
1週間分の内容が、1.5時間分くらいの動画と、15分くらいでできる小テストと、2、3時間で終わるプログラミング課題で、全体で11週間分やれば修了できる。
1、10、11週目はプログラミング課題が無くてすぐ終わる一方、3～5週目辺りは結構ハード。&lt;/p&gt;

&lt;p&gt;私は2017/10/30に始めて、2017/12/19に完了したので、ちょうど50日かかったことになる。&lt;/p&gt;

&lt;p&gt;動画は当然英語だが、有志により英語や日本語の字幕が付けられてるので聞き取れなくても問題はあまりない。
ただ、1～4週目くらいまでは、日本語の字幕がずれている動画が少なくなく、それらは英語の字幕でみる必要がある。
1つだけ英語の字幕もダメなものがあって、それだけは字幕なしで見た。&lt;/p&gt;

&lt;p&gt;プログラミング課題は、&lt;a href=&#34;https://www.gnu.org/software/octave/&#34;&gt;Octave&lt;/a&gt;というオープンソースの数値解析言語で解く。
聞いたことない言語だったが、&lt;a href=&#34;https://jp.mathworks.com/programs/trials/trial_request.html?ref=ggl&amp;amp;s_eid=ppc_30300738322&amp;amp;q=matlab&#34;&gt;MATLAB&lt;/a&gt;との互換性維持を重視して開発されている言語なので、まあ覚えておいて損はない。
Octaveグラフ描画APIは、MATLABのグラフ描画APIをまねていて、MATLABのグラフ描画APIは、Pythonでよく使われるグラフ描画ライブラリである&lt;a href=&#34;https://matplotlib.org/&#34;&gt;Matplotlib&lt;/a&gt;がまねていて、つまりOctaveやってるとMatplotlibの勉強にもなる。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;以下、11週間分の内容を、キーワードレベルで書いておく。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;機械学習の概要&lt;/p&gt;

&lt;p&gt;背景、歴史、活用例。
教師あり学習(Supervised learning) vs 教師なし(Unsupervised learning)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;線形単回帰(Linear regression with one variable)&lt;/p&gt;

&lt;p&gt;仮説関数(Hypothesis)、目的関数(Cost function)、平均二乗誤差(Mean squared error)、最小二乗法(Least squares method)、最急降下法(Gradient descent)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;行列&lt;/p&gt;

&lt;p&gt;行列(Matrix)とベクトル(Vector)。
行列演算。
逆行列(Inverse)、転置行列(Transpose)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;線形重回帰(Linear regression with multiple variables)&lt;/p&gt;

&lt;p&gt;特徴量のスケーリング(Feature scaling)、平均正則化(Mean normalization)。
学習率(Learning rate)。
多項式回帰(Polynomial regression)。
正規方程式(Normal equation)、特異行列(singular matrix)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Octaveチュートリアル&lt;/p&gt;

&lt;p&gt;基本操作、データロード・セーブ、データ計算、描画、制御構文、ベクトル化。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;3週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ロジスティック回帰(Logistic regression)&lt;/p&gt;

&lt;p&gt;二値分類(Binary classification)。
シグモイド関数(Sigmoid function)。
決定境界(Decision boundary)。
共役勾配法(Conjugate gradient)、BFGS、L-BFGS。
多値分類(Multi-class classification)、1対その他(One-vs-all)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;過学習(Overfitting)&lt;/p&gt;

&lt;p&gt;正則化(Regularization)、未学習(Underfitting)。
バイアス(Bias)、バリアンス(Variance)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;4週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ニューラルネットワーク(Neural Network)&lt;/p&gt;

&lt;p&gt;入力層(Input layer)、隠れ層(Hidden layer)、出力層(Output layer)。
ユニット(Unit)、バイアスユニット(Bias unit)、重み(Weight)。
活性化関数(Activation function)。
順伝播(Forward propagation)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;5週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ニューラルネットワーク続き&lt;/p&gt;

&lt;p&gt;逆伝播(Backpropagation)。
Gradient checking。
対称性破壊(Symmetry breaking)、ランダム初期化(Random initialization)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;6週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;機械学習へのアドバイス&lt;/p&gt;

&lt;p&gt;訓練データ(Training set)、テストデータ(Test set)、交差検証データ(Cross-validation set)。
一般化エラー(Generalization error)。
高バイアス(High bias)、高バリアンス(High variance)。
学習曲線(Learning curve)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;機械学習システムの設計&lt;/p&gt;

&lt;p&gt;実装の優先度付け。
スパム分類器(Spam classifier)。
エラー分析(Error analysis)。
歪んだクラス(Skewed classes)。
真陽性(True positive)、偽陽性(False positive)、真陰性(True negative)、偽陰性(False negative)。
適合率(Precision)、再現率(Recall)、F値(F1 score)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;7週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;サポートベクタマシン(SVM: Support Vector Machine)&lt;/p&gt;

&lt;p&gt;マージン(Margin)。
線形カーネル(Linear kernel)、ガウスカーネル(Gaussian kernel)、多項式カーネル(Polynomial kernel)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;8週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;K平均法(K-means algorithm)&lt;/p&gt;

&lt;p&gt;クラスタリング(Clustering)。
ランダム初期化(Random initialization)、局所最適解(Local optima)。
エルボー法(Elbow method)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;主成分分析(PCA: Principal Component Analysis)&lt;/p&gt;

&lt;p&gt;データ圧縮(Data compression)、データ可視化(Data visualization)、次元削減(Dimensionality Reduction)、データ復元(Reconstruction from compressed representation)。
投影誤差(Projection error)、分散(Variance)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;9週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;異常検知(Anomaly detection)&lt;/p&gt;

&lt;p&gt;密度推定(Density estimation)。
ガウス分布(Gaussian distribution)、正規分布(Normal distribution)。
異常検知 vs 教師あり学習。
多変量ガウス分布(Multivariate gaussian distribution)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;レコメンダシステム(Recommender system)&lt;/p&gt;

&lt;p&gt;映画レーティング(Movie rating)。
コンテンツベース(Content-­based recommendation)、協調フィルタリング(Collaborative filtering)。
低ランク行列因子分解(Low-rank matrix factorization)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;10週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;大規模機械学習&lt;/p&gt;

&lt;p&gt;バッチ勾配降下法(Batch gradient descent)、確率的勾配降下法(Stochastic gradient descent)、ミニバッチ勾配降下法(Mini-batch gradient descent)。
オンライン学習(Online learning)。
Map­‐reduce、データ並列性(Data parallelism)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;11週目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;写真OCR(Photo OCR)&lt;/p&gt;

&lt;p&gt;写真OCRパイプライン(Photo OCR pipeline)、テキスト検出(Text detection)、文字分割(character segmentation)、文字認識(character recognition)。
スライディングウィンドウ(Sliding window)。
人工データ合成(Artificial data synthesis)、歪曲収差(Distortion)。
天井分析(Ceiling analysis)。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;次は&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873117584/&#34;&gt;ゼロから作るDeep Learning&lt;/a&gt;かな。&lt;/p&gt;
</description>
        </item>
      
    

  </channel>
</rss>
