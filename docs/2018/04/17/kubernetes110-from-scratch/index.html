<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta name="google-site-verification" content="9qs7VjxtSrYMqw5OElxCdKv_gnssSRi6acB2iYlZnGA" />

    
    
    <meta property="og:type" content="article">
    <meta property="og:title" content="Kubernetes 1.10をスクラッチから全手動で構築 | To Be Decided">
    <meta property="og:url" content="https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/">
    <link rel="canonical" href="https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/">
    <meta property="og:description" content="Oracle Linux 7.4.0のVMでKubernetes1.10.0のクラスタをスクラッチから全手動で作った。 参考にしたのは主に以下。 https://nixaid.com/deploying-kubernetes-cluster-from-scratch/ https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.10.md https://kubernetes.io/docs/getting-started-guides/scratch/ https://kubernetes.io/docs/reference/setup-tools/kubeadm/implementation-details/ https://ulam.io/blog/kubernetes-scratch/ https://docs.microsoft.com/en-us/virtualization/windowscontainers/kubernetes/creating-a-linux-master (adsbygoogle = window.adsbygoogle || []).push({}); 構成 マシン: Windows 10 Homeのラップトップの上のVMware PlayerのVM CPU: 2コア メモリ: 4GB NIF: NATのを一つ OS: Oracle Linux 7.4.0 Minimalインストール IPアドレス: 192.168.171.200、静的割り当て ホスト名: k8s-master (hostsで解決) Docker: Oracle Container Runtime for Docker (docker-engine) 17.06.2 Kubernetes: バージョン1.10.0 単一ノード 全コンポーネント(kubelet、kube-proxy、kube-apiserver、kube-controller-manager、kube-scheduler、etcd)をsystemdで起動 (i.e. 非コンテナ) kubeletとkube-proxy以外は非rootユーザ kubeletは現時点でrootで動かす必要がある kube-proxyはiptableいじったりする都合上rootで動かす必要があるっぽい。 コンポーネント間通信とkubectlの通信をTLSで暗号化 TLS 1.2 セキュアなCipher Suites コンポーネント間通信とkubectlの通信の認証はx509クライアント証明書 TLS Bootstrapping Bootstrap token使用 CSR自動承認 Certificate Rotation有効 etcd 3.1.12 flannel 0.10.0 CoreDNS 1.1.1 SERVICE_CLUSTER_IP_RANGE (Serviceに割り当てるIPの範囲) は10.0.0.0/16 kube-apiserverのIPはこの範囲の最初のIP(i.e.">
    
    <meta property="og:image" content="https://www.kaitoy.xyz/images/kubernetes.png">
    
    
    <meta property="og:site_name" content="To Be Decided">

    <title>
      
      Kubernetes 1.10をスクラッチから全手動で構築 | To Be Decided
      
    </title>

    
    <link rel="shortcut icon" href="https://www.kaitoy.xyz/assets/favicon.ico">

    
    <link rel="alternate" type="application/rss+xml" title="RSS" href="https://www.kaitoy.xyz/index.xml">

    <link href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css" rel="stylesheet">
    <link href="//fonts.googleapis.com/css?family=Marcellus+SC" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=PT+Sans" rel="stylesheet" type="text/css">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">
    <link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/styles/zenburn.min.css" rel="stylesheet">
    <link href="https://www.kaitoy.xyz/css/styles.css" rel="stylesheet">
    <link href="https://www.kaitoy.xyz/css/custom.css" rel="stylesheet">
    <link href="https://www.kaitoy.xyz/css/table.css" rel="stylesheet">
    <link href="https://www.kaitoy.xyz/css/jquery.bxslider.css" rel="stylesheet" />

    
    

    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-6244473643910448",
        enable_page_level_ads: true
      });
    </script>

    
  </head>
  <body>

    <header id="site-header">
      <div class="container">
        <h1 class="text-center">
          <a href="https://www.kaitoy.xyz" class="font-logo">To Be Decided</a>
        </h1>
      </div>
    </header>

    <main id="site-body">
      <div class="container">

<div class="row">
  <div class="col-md-9">
    <article id="post">
      <span class="date">Tue, Apr 17, 2018</span>
      <h2 class="title">Kubernetes 1.10をスクラッチから全手動で構築</h2>

      <div class="eyecatch text-center">
        
        <img src="https://www.kaitoy.xyz/images/kubernetes.png" alt="Kubernetes 1.10をスクラッチから全手動で構築">
        
      </div>

      <div class="content">
        

<p>Oracle Linux 7.4.0のVMでKubernetes1.10.0のクラスタをスクラッチから全手動で作った。
参考にしたのは主に以下。</p>

<ul>
<li><a href="https://nixaid.com/deploying-kubernetes-cluster-from-scratch/">https://nixaid.com/deploying-kubernetes-cluster-from-scratch/</a></li>
<li><a href="https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.10.md">https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.10.md</a></li>
<li><a href="https://kubernetes.io/docs/getting-started-guides/scratch/">https://kubernetes.io/docs/getting-started-guides/scratch/</a></li>
<li><a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/implementation-details/">https://kubernetes.io/docs/reference/setup-tools/kubeadm/implementation-details/</a></li>
<li><a href="https://ulam.io/blog/kubernetes-scratch/">https://ulam.io/blog/kubernetes-scratch/</a></li>
<li><a href="https://docs.microsoft.com/en-us/virtualization/windowscontainers/kubernetes/creating-a-linux-master">https://docs.microsoft.com/en-us/virtualization/windowscontainers/kubernetes/creating-a-linux-master</a></li>
</ul>

<p>



<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-6244473643910448"
     data-ad-slot="1845600530"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
</p>

<h2 id="構成">構成</h2>

<ul>
<li>マシン: Windows 10 Homeのラップトップの上のVMware PlayerのVM

<ul>
<li>CPU: 2コア</li>
<li>メモリ: 4GB</li>
<li>NIF: NATのを一つ</li>
</ul></li>
<li>OS: Oracle Linux 7.4.0

<ul>
<li>Minimalインストール</li>
<li>IPアドレス: 192.168.171.200、静的割り当て</li>
<li>ホスト名: k8s-master (hostsで解決)</li>
</ul></li>
<li>Docker: Oracle Container Runtime for Docker (docker-engine) 17.06.2</li>
<li>Kubernetes: バージョン1.10.0

<ul>
<li>単一ノード</li>
<li>全コンポーネント(kubelet、kube-proxy、kube-apiserver、kube-controller-manager、kube-scheduler、etcd)をsystemdで起動 (i.e. 非コンテナ)

<ul>
<li>kubeletとkube-proxy以外は非rootユーザ</li>
<li>kubeletは<a href="https://github.com/kubernetes/kubernetes/blob/v1.10.2/cmd/kubelet/app/server.go#L388">現時点でrootで動かす必要がある</a></li>
<li>kube-proxyはiptableいじったりする都合上rootで動かす必要があるっぽい。</li>
</ul></li>
<li>コンポーネント間通信とkubectlの通信をTLSで暗号化

<ul>
<li>TLS 1.2</li>
<li>セキュアなCipher Suites</li>
</ul></li>
<li>コンポーネント間通信とkubectlの通信の認証は<a href="https://kubernetes.io/docs/admin/authentication/#x509-client-certs">x509クライアント証明書</a></li>
<li>TLS Bootstrapping

<ul>
<li>Bootstrap token使用</li>
<li>CSR自動承認</li>
</ul></li>
<li><a href="https://kubernetes.io/docs/tasks/tls/certificate-rotation/">Certificate Rotation</a>有効</li>
<li>etcd 3.1.12</li>
<li><a href="https://github.com/coreos/flannel">flannel</a> 0.10.0</li>
<li><a href="https://github.com/coredns/coredns">CoreDNS</a> 1.1.1</li>
<li>SERVICE_CLUSTER_IP_RANGE (Serviceに割り当てるIPの範囲) は10.0.0.0/16

<ul>
<li>kube-apiserverのIPはこの範囲の最初のIP(i.e. 10.0.0.1)になる。</li>
<li>ホストネットワークや、CLUSTER_CIDRと範囲が被らないようにする必要がある。</li>
</ul></li>
<li>CLUSTER_CIDR (Podに割り当てるIPの範囲) は10.244.0.0/16

<ul>
<li>flannelの要件に合わせている。</li>
<li>ホストネットワークや、SERVICE_CLUSTER_IP_RANGEと範囲が被らないようにする必要がある。</li>
</ul></li>
</ul></li>
</ul>

<p><br></p>

<p>kubeletの動作条件にあるので、swapをoffにする。
Oracle Linuxにログインして、<code>/etc/fstab</code>のswapの行を削除して、以下のコマンドを実行。</p>

<pre><code class="language-sh"># swapoff -a
</code></pre>

<p><br></p>

<p>SELinuxはちゃんと設定すればKubernetes動かせるはずだけど、面倒なのでとりあえず無効にする。</p>

<p><code>/etc/selinux/config</code>を編集して、<code>SELINUX</code>を<code>permissive</code>にして、以下のコマンドを実行。</p>

<pre><code class="language-sh"># setenforce 0
</code></pre>

<p><br></p>

<p>ファイアウォールもちゃんと設定すればいいんだけど面倒なのでとりあえず無効にする。</p>

<pre><code class="language-sh"># systemctl stop firewalld
# systemctl disable firewalld
</code></pre>

<p><br></p>

<p>これで準備完了。</p>

<h2 id="クラスタ構築手順">クラスタ構築手順</h2>

<p>おおむね、k8sコンポーネント間の通信の暗号化に使う鍵と証明書の生成、各コンポーネント用kubeconfigの生成、etcdのデプロイ、k8sコンポーネントのデプロイ、fannelデプロイ、CoreDNSデプロイ、という流れ。
ついでに最後に<a href="https://github.com/weaveworks/scope">Weave Scope</a>をデプロイしてみる。</p>

<ol>
<li><p>Bridge netfilterとIP forwardingを設定</p>

<p>まず、Bridge netfilterモジュールをロードする。</p>

<pre><code class="language-sh"># modprobe br_netfilter
# echo &quot;br_netfilter&quot; &gt; /etc/modules-load.d/br_netfilter.conf
</code></pre>

<p>Bridge netfilterとIP forwardingを有効化する。</p>

<pre><code class="language-sh"># cat &gt; /etc/sysctl.d/kubernetes.conf &lt;&lt; EOF
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward = 1
EOF
# sysctl -p /etc/sysctl.d/kubernetes.conf
</code></pre>

<p><br></p>

<p>設定確認。</p>

<pre><code class="language-sh"># lsmod |grep br_netfilter
# sysctl -a | grep -E &quot;net.bridge.bridge-nf-call-|net.ipv4.ip_forward&quot;
</code></pre></li>

<li><p>x509証明書生成</p>

<ol>
<li><p>opensslの設定作成</p>

<pre><code class="language-sh"># mkdir -p /etc/kubernetes/pki
# HOSTNAME=k8s-master
# K8S_SERVICE_IP=10.0.0.1
# MASTER_IP=192.168.171.200
# cat &gt; /etc/kubernetes/pki/openssl.cnf &lt;&lt; EOF
[ req ]
distinguished_name = req_distinguished_name
[req_distinguished_name]
[ v3_ca ]
basicConstraints = critical, CA:TRUE
keyUsage = critical, digitalSignature, keyEncipherment, keyCertSign
[ v3_req_client ]
basicConstraints = CA:FALSE
keyUsage = critical, digitalSignature, keyEncipherment
extendedKeyUsage = clientAuth
[ v3_req_apiserver ]
basicConstraints = CA:FALSE
keyUsage = critical, digitalSignature, keyEncipherment
extendedKeyUsage = serverAuth
subjectAltName = @alt_names_cluster
[ v3_req_etcd ]
basicConstraints = CA:FALSE
keyUsage = critical, digitalSignature, keyEncipherment
extendedKeyUsage = serverAuth
subjectAltName = @alt_names_etcd
[ alt_names_cluster ]
DNS.1 = kubernetes
DNS.2 = kubernetes.default
DNS.3 = kubernetes.default.svc
DNS.4 = kubernetes.default.svc.cluster.local
DNS.5 = ${HOSTNAME}
IP.1 = ${MASTER_IP}
IP.2 = ${K8S_SERVICE_IP}
[ alt_names_etcd ]
DNS.1 = ${HOSTNAME}
IP.1 = ${MASTER_IP}
EOF
</code></pre></li>

<li><p>Kubernetes CA証明書生成</p>

<p>以降で生成する証明書に署名するための証明書。
後述のTLS Bootstrappingでの証明書生成にも使う。</p>

<pre><code class="language-sh"># groupadd -r kubernetes
# adduser -r -g kubernetes -M -s /sbin/nologin kubernetes
# CA_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/ca.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/ca.key
# chmod 0600 /etc/kubernetes/pki/ca.key
# openssl req -x509 -new -sha256 -nodes -key /etc/kubernetes/pki/ca.key -days $CA_DAYS -out /etc/kubernetes/pki/ca.crt -subj &quot;/CN=kubernetes-ca&quot;  -extensions v3_ca -config /etc/kubernetes/pki/openssl.cnf
</code></pre></li>

<li><p>kube-apiserver証明書生成</p>

<p>kube-apiserverのサーバ証明書。</p>

<pre><code class="language-sh"># APISERVER_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/kube-apiserver.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/kube-apiserver.key
# chmod 0600 /etc/kubernetes/pki/kube-apiserver.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/kube-apiserver.key -subj &quot;/CN=kube-apiserver&quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/kube-apiserver.crt -days $APISERVER_DAYS -extensions v3_req_apiserver -extfile /etc/kubernetes/pki/openssl.cnf
</code></pre></li>

<li><p>kube-apiserver-kubelet証明書生成</p>

<p>kube-apiserverが<a href="https://kubernetes.io/docs/concepts/architecture/master-node-communication/#apiserver-kubelet">kubeletのAPIにアクセス</a>するときのクライアント証明書。</p>

<pre><code class="language-sh"># APISERVER_KUBELET_CLIENT_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/apiserver-kubelet-client.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/apiserver-kubelet-client.key
# chmod 0600 /etc/kubernetes/pki/apiserver-kubelet-client.key
# openssl req -new -key /etc/kubernetes/pki/apiserver-kubelet-client.key -subj &quot;/CN=kube-apiserver-kubelet-client/O=system:masters&quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/apiserver-kubelet-client.crt -days $APISERVER_KUBELET_CLIENT_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
</code></pre></li>

<li><p>adminクライアント証明書生成</p>

<p>kubectlがkube-apiserverのAPIにアクセスするときのクライアント証明書。</p>

<pre><code class="language-sh"># groupadd -r kube-admin
# adduser -r -g kube-admin -M -s /sbin/nologin kube-admin
# ADMIN_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/admin.key
# chown kube-admin:kube-admin /etc/kubernetes/pki/admin.key
# chmod 0600 /etc/kubernetes/pki/admin.key
# openssl req -new -key /etc/kubernetes/pki/admin.key -subj &quot;/CN=kubernetes-admin/O=system:masters&quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/admin.crt -days $ADMIN_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
</code></pre></li>

<li><p>kube-controller-managerのクライアント証明書生成</p>

<p>kube-controller-managerがkube-apiserverに接続するときのクライアント証明書。
この証明書に対応する秘密鍵と公開鍵はそれぞれ、kube-controller-managerがService Accountトークンに署名するとき、kube-apiserverがトークンの署名を確認するときにも使う。</p>

<pre><code class="language-sh"># CONTROLLER_MANAGER_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/kube-controller-manager.key
# openssl ec -in /etc/kubernetes/pki/kube-controller-manager.key -outform PEM -pubout -out /etc/kubernetes/pki/kube-controller-manager.pub
# chown kubernetes:kubernetes /etc/kubernetes/pki/kube-controller-manager.key
# chmod 0600 /etc/kubernetes/pki/kube-controller-manager.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/kube-controller-manager.key -subj &quot;/CN=system:kube-controller-manager&quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/kube-controller-manager.crt -days $CONTROLLER_MANAGER_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
</code></pre></li>

<li><p>kube-schedulerクライアント証明書生成</p>

<p>kube-schedulerがkube-apiserverにリクエストするときに使うクライアント証明書。</p>

<pre><code class="language-sh"># SCHEDULER_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/kube-scheduler.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/kube-scheduler.key
# chmod 0600 /etc/kubernetes/pki/kube-scheduler.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/kube-scheduler.key -subj &quot;/CN=system:kube-scheduler&quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/kube-scheduler.crt -days $SCHEDULER_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
</code></pre></li>

<li><p>kube-proxyクライアント証明書生成</p>

<p>kube-proxyがkube-apiserverにリクエストするときに使うクライアント証明書。</p>

<pre><code class="language-sh"># PROXY_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/kube-proxy.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/kube-proxy.key
# chmod 0600 /etc/kubernetes/pki/kube-proxy.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/kube-proxy.key -subj &quot;/CN=system:kube-proxy&quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/kube-proxy.crt -days $PROXY_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
</code></pre></li>

<li><p>front proxy CA証明書生成</p>

<p>front proxyの証明書に署名するのにつかう証明書。
front proxyは<a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/api-machinery/aggregated-api-servers.md">API Aggregation</a>のためのもの。
API Aggregationは、kube-apiserverを変更することなく、別途作られた<a href="https://kubernetes.io/docs/tasks/access-kubernetes-api/setup-extension-api-server/">Extension API Server</a>でKubernetesのAPIを拡張できるようにする機能。
API Aggregationは現時点では<a href="https://kubernetes.io/docs/concepts/api-extension/apiserver-aggregation/#overview">kube-apiserverの一機能として実装されていて</a>、将来的には<a href="https://github.com/kubernetes/kube-aggregator">kubernetes-aggregator</a>という別のコンポーネントで実現される。</p>

<p>API AggregationしないならこのCA証明書と次のクライアント証明書はいらないはず。
今回はしないけど、とりあえず作って設定したおく。</p>

<pre><code class="language-sh"># FRONT_PROXY_CA_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/front-proxy-ca.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/front-proxy-ca.key
# chmod 0600 /etc/kubernetes/pki/front-proxy-ca.key
# openssl req -x509 -new -sha256 -nodes -key /etc/kubernetes/pki/front-proxy-ca.key -days $FRONT_PROXY_CA_DAYS -out /etc/kubernetes/pki/front-proxy-ca.crt -subj &quot;/CN=front-proxy-ca&quot; -extensions v3_ca -config /etc/kubernetes/pki/openssl.cnf
</code></pre></li>

<li><p>front proxyクライアント証明書</p>

<p>Extension API ServerのAPIへのリクエストは、いったんkube-apiserverが受け取ってExtension API Serverに転送される。(多分。)
この転送の暗号化と認証にTLSが使われていて、ここではそのクライアント証明書を生成する。</p>

<pre><code class="language-sh"># FRONT_PROXY_CLIENT_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/front-proxy-client.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/front-proxy-client.key
# chmod 0600 /etc/kubernetes/pki/front-proxy-client.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/front-proxy-client.key -subj &quot;/CN=front-proxy-client&quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/front-proxy-ca.crt -CAkey /etc/kubernetes/pki/front-proxy-ca.key -CAcreateserial -out /etc/kubernetes/pki/front-proxy-client.crt -days $FRONT_PROXY_CLIENT_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
</code></pre></li>

<li><p>etcd CA証明書</p>

<p>以降で生成するetcdの証明書に署名するための証明書。</p>

<pre><code class="language-sh"># groupadd -r etcd
# adduser -r -g etcd -M -s /sbin/nologin etcd
# ETCD_CA_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/etcd-ca.key
# chown etcd:etcd /etc/kubernetes/pki/etcd-ca.key
# chmod 0600 /etc/kubernetes/pki/etcd-ca.key
# openssl req -x509 -new -sha256 -nodes -key /etc/kubernetes/pki/etcd-ca.key -days $ETCD_CA_DAYS -out /etc/kubernetes/pki/etcd-ca.crt -subj &quot;/CN=etcd-ca&quot; -extensions v3_ca -config /etc/kubernetes/pki/openssl.cnf
</code></pre></li>

<li><p>etcd証明書</p>

<p>etcdのサーバ証明書。</p>

<pre><code class="language-sh"># ETCD_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/etcd.key
# chown etcd:etcd /etc/kubernetes/pki/etcd.key
# chmod 0600 /etc/kubernetes/pki/etcd.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/etcd.key -subj &quot;/CN=etcd&quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/etcd-ca.crt -CAkey /etc/kubernetes/pki/etcd-ca.key -CAcreateserial -out /etc/kubernetes/pki/etcd.crt -days $ETCD_DAYS -extensions v3_req_etcd -extfile /etc/kubernetes/pki/openssl.cnf
</code></pre></li>

<li><p>etcdクライアント証明書</p>

<p>etcdのクライアント証明書。
kube-apiserverだけがetcdと話すので、kube-apiserverだけが使う。</p>

<pre><code class="language-sh"># ETCD_CLIENT_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/etcd-client.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/etcd-client.key
# chmod 0600 /etc/kubernetes/pki/etcd-client.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/etcd-client.key -subj &quot;/CN=kube-apiserver&quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/etcd-ca.crt -CAkey /etc/kubernetes/pki/etcd-ca.key -CAcreateserial -out /etc/kubernetes/pki/etcd-client.crt -days $ETCD_CLIENT_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf
</code></pre></li>

<li><p>etcd peer証明書</p>

<p>etcdサーバが冗長構成のとき、サーバ間の通信の暗号化に使う証明書。
マスタが一つなら要らないはずだけど、今回とりあえず作って設定しておく。</p>

<pre><code class="language-sh"># ETCD_PEER_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/etcd-peer.key
# chown etcd:etcd /etc/kubernetes/pki/etcd-peer.key
# chmod 0600 /etc/kubernetes/pki/etcd-peer.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/etcd-peer.key -subj &quot;/CN=etcd-peer&quot; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/etcd-ca.crt -CAkey /etc/kubernetes/pki/etcd-ca.key -CAcreateserial -out /etc/kubernetes/pki/etcd-peer.crt -days $ETCD_PEER_DAYS -extensions v3_req_etcd -extfile /etc/kubernetes/pki/openssl.cnf
</code></pre></li>

<li><p>確認</p>

<p>以上で生成した証明書の内容を確認する。</p>

<pre><code class="language-sh"># for i in /etc/kubernetes/pki/*crt; do
  echo $i:;
  openssl x509 -subject -issuer -noout -in $i;
  echo;
done
</code></pre></li>
</ol></li>

<li><p>Kubernetesバイナリインストール</p>

<p><a href="https://kubernetes.io/docs/getting-started-guides/scratch/#selecting-images">公式ドキュメント</a>によると、Docker、kubelet、kube-proxyはコンテナ外で動かして、etcd、kube-apiserver、kube-controller-manager、kube-schedulerはコンテナで動かすのが推奨されている。
けど、とりあえずは簡単に全部コンテナ外でやる。</p>

<p>(Oracle Linux用には、各コンポのコンテナイメージ詰め合わせがOracle Container Services for use with Kubernetesという名前で配布されているけど、現時点で1.9までしかないので使わない。)</p>

<p>バイナリは以下URLからダウンロードできる。</p>

<ul>
<li>全部入り: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/kubernetes-server-linux-amd64.tar.gz">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/kubernetes-server-linux-amd64.tar.gz</a></li>
<li>kube-apiserver

<ul>
<li>バイナリ: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-apiserver">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-apiserver</a></li>
<li>コンテナ: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-apiserver.tar">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-apiserver.tar</a></li>
</ul></li>
<li>kube-controller-manager

<ul>
<li>バイナリ: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-controller-manager">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-controller-manager</a></li>
<li>コンテナ: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-controller-manager.tar">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-controller-manager.tar</a></li>
</ul></li>
<li>kube-scheduler

<ul>
<li>バイナリ: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-scheduler">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-scheduler</a></li>
<li>コンテナ: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-scheduler.tar">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-scheduler.tar</a></li>
</ul></li>
<li>kube-proxy

<ul>
<li>バイナリ: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-proxy">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-proxy</a></li>
<li>コンテナ: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-proxy.tar">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-proxy.tar</a></li>
</ul></li>
<li>kubelet: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubelet">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubelet</a></li>
<li>kubectl: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubectl">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubectl</a></li>
<li>kubeadm: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubeadm">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubeadm</a></li>
<li>hyperkube: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/hyperkube">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/hyperkube</a></li>
</ul>

<p>最後のhyperkubeは、各種Kubernetesバイナリのごった煮。
ファイル名によって動作が変わる。
簡単のためこれを使うけど、個別のバイナリ使ったほうがメモリ使用量などで有利そう。</p>

<p>hyperkubeとkubeadmのバイナリを<code>/usr/bin/</code>において、以下のコマンドを実行。</p>

<pre><code class="language-sh"># ln -s /usr/bin/hyperkube /usr/bin/kube-apiserver
# ln -s /usr/bin/hyperkube /usr/bin/kube-controller-manager
# ln -s /usr/bin/hyperkube /usr/bin/kube-scheduler
# ln -s /usr/bin/hyperkube /usr/bin/kube-proxy
# ln -s /usr/bin/hyperkube /usr/bin/kubelet
# ln -s /usr/bin/hyperkube /usr/bin/kubectl
# chmod +x /usr/bin/kube*
# mkdir -p /var/lib/{kubelet,kube-proxy}
</code></pre></li>

<li><p>kubeconfigファイル生成</p>

<p>kubectlとマスタコンポーネントがkube-apiserverと話すときに使うkubeconfigファイルを生成する。</p>

<ol>
<li><p>kube-controller-managerのkubeconfig</p>

<pre><code class="language-sh"># MASTER_IP=192.168.171.200
# KUBERNETES_PUBLIC_ADDRESS=$MASTER_IP
# CLUSTER_NAME=&quot;k8s&quot;
# KCONFIG=/etc/kubernetes/kube-controller-manager.kubeconfig
# KUSER=&quot;system:kube-controller-manager&quot;
# kubectl config set-cluster ${CLUSTER_NAME} --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 --kubeconfig=${KCONFIG}
# kubectl config set-credentials ${KUSER} --client-certificate=/etc/kubernetes/pki/kube-controller-manager.crt --client-key=/etc/kubernetes/pki/kube-controller-manager.key --embed-certs=true --kubeconfig=${KCONFIG}
# kubectl config set-context ${KUSER}@${CLUSTER_NAME} --cluster=${CLUSTER_NAME} --user=${KUSER} --kubeconfig=${KCONFIG}
# kubectl config use-context ${KUSER}@${CLUSTER_NAME} --kubeconfig=${KCONFIG}
# chown kubernetes:kubernetes ${KCONFIG}
# chmod 0600 ${KCONFIG}
</code></pre>

<p>設定確認。</p>

<pre><code class="language-sh"># kubectl config view --kubeconfig=${KCONFIG}
</code></pre></li>

<li><p>kube-schedulerのkubeconfig</p>

<pre><code class="language-sh"># MASTER_IP=192.168.171.200
# KUBERNETES_PUBLIC_ADDRESS=$MASTER_IP
# CLUSTER_NAME=&quot;k8s&quot;
# KCONFIG=/etc/kubernetes/kube-scheduler.kubeconfig
# KUSER=&quot;system:kube-scheduler&quot;
# kubectl config set-cluster ${CLUSTER_NAME} --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 --kubeconfig=${KCONFIG}
# kubectl config set-credentials ${KUSER} --client-certificate=/etc/kubernetes/pki/kube-scheduler.crt --client-key=/etc/kubernetes/pki/kube-scheduler.key --embed-certs=true --kubeconfig=${KCONFIG}
# kubectl config set-context ${KUSER}@${CLUSTER_NAME} --cluster=${CLUSTER_NAME} --user=${KUSER} --kubeconfig=${KCONFIG}
# kubectl config use-context ${KUSER}@${CLUSTER_NAME} --kubeconfig=${KCONFIG}
# chown kubernetes:kubernetes ${KCONFIG}
# chmod 0600 ${KCONFIG}
</code></pre>

<p>設定確認。</p>

<pre><code class="language-sh"># kubectl config view --kubeconfig=${KCONFIG}
</code></pre></li>

<li><p>adminのkubeconfig</p>

<p>kubectl用。</p>

<pre><code class="language-sh"># MASTER_IP=192.168.171.200
# KUBERNETES_PUBLIC_ADDRESS=$MASTER_IP
# CLUSTER_NAME=&quot;k8s&quot;
# KCONFIG=/etc/kubernetes/admin.kubeconfig
# KUSER=&quot;kubernetes-admin&quot;
# kubectl config set-cluster ${CLUSTER_NAME} --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 --kubeconfig=${KCONFIG}
# kubectl config set-credentials ${KUSER} --client-certificate=/etc/kubernetes/pki/admin.crt --client-key=/etc/kubernetes/pki/admin.key --embed-certs=true --kubeconfig=${KCONFIG}
# kubectl config set-context ${KUSER}@${CLUSTER_NAME} --cluster=${CLUSTER_NAME} --user=${KUSER} --kubeconfig=${KCONFIG}
# kubectl config use-context ${KUSER}@${CLUSTER_NAME} --kubeconfig=${KCONFIG}
# chown kube-admin:kube-admin ${KCONFIG}
# chmod 0600 ${KCONFIG}
# ln -s ${KCONFIG} ~/.kube/config
</code></pre>

<p>設定確認。</p>

<pre><code class="language-sh"># kubectl config view --kubeconfig=${KCONFIG}
</code></pre></li>
</ol></li>

<li><p>etcdデプロイ</p>

<p><a href="https://github.com/coreos/etcd/releases/download/v3.1.12/etcd-v3.1.12-linux-amd64.tar.gz">https://github.com/coreos/etcd/releases/download/v3.1.12/etcd-v3.1.12-linux-amd64.tar.gz</a>
からアーカイブをダウンロードして、中のetcdとetcdctlを<code>/usr/bin/</code>にいれて、以下のコマンドを実行。</p>

<pre><code class="language-sh"># chown root:root /usr/bin/etcd*
# chmod 0755 /usr/bin/etcd*
# mkdir -p /var/lib/etcd
# chown etcd:etcd /var/lib/etcd
</code></pre>

<p>で、systemdのユニットファイルを書いてサービス化。</p>

<p>(参考: <a href="https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/">Kubernetesドキュメント</a>、<a href="https://github.com/coreos/etcd/blob/master/Documentation/op-guide/security.md">etcdドキュメント</a>)</p>

<pre><code class="language-sh"># MASTER_IP=192.168.171.200
# ETCD_MEMBER_NAME=etcd1
# CLUSTER_NAME=&quot;k8s&quot;
# ETCD_TOKEN=$(openssl rand -hex 5)
# ETCD_CLUSTER_TOKEN=$CLUSTER_NAME-$ETCD_TOKEN
# cat &gt; /etc/systemd/system/etcd.service &lt;&lt; EOF
[Unit]
Description=etcd
Documentation=https://coreos.com/etcd/docs/latest/
After=network.target


[Service]
Type=notify
NotifyAccess=all
User=etcd
Group=etcd
ExecStart=/usr/bin/etcd \\
  --name ${ETCD_MEMBER_NAME} \\
  --listen-client-urls https://${MASTER_IP}:2379 \\
  --advertise-client-urls https://${MASTER_IP}:2379 \\
  --data-dir=/var/lib/etcd \\
  --cert-file=/etc/kubernetes/pki/etcd.crt \\
  --key-file=/etc/kubernetes/pki/etcd.key \\
  --peer-cert-file=/etc/kubernetes/pki/etcd-peer.crt \\
  --peer-key-file=/etc/kubernetes/pki/etcd-peer.key \\
  --trusted-ca-file=/etc/kubernetes/pki/etcd-ca.crt \\
  --peer-trusted-ca-file=/etc/kubernetes/pki/etcd-ca.crt \\
  --peer-client-cert-auth \\
  --client-cert-auth \\
  --initial-advertise-peer-urls https://${MASTER_IP}:2380 \\
  --listen-peer-urls https://${MASTER_IP}:2380 \\
  --initial-cluster-token ${ETCD_CLUSTER_TOKEN} \\
  --initial-cluster ${ETCD_MEMBER_NAME}=https://${MASTER_IP}:2380 \\
  --initial-cluster-state new
Restart=always
RestartSec=10s


[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable etcd
# systemctl start etcd
</code></pre>

<p>確認。</p>

<pre><code class="language-sh"># systemctl status etcd -l
# MASTER_IP=192.168.171.200
# etcdctl --endpoints https://${MASTER_IP}:2379 --ca-file=/etc/kubernetes/pki/etcd-ca.crt --cert-file=/etc/kubernetes/pki/etcd-client.crt --key-file=/etc/kubernetes/pki/etcd-client.key cluster-health
# etcdctl --endpoints https://${MASTER_IP}:2379 --ca-file=/etc/kubernetes/pki/etcd-ca.crt --cert-file=/etc/kubernetes/pki/etcd-client.crt --key-file=/etc/kubernetes/pki/etcd-client.key member list
</code></pre></li>

<li><p>マスタコンポーネントデプロイ。</p>

<ol>
<li><p>kube-apiserver</p>

<p>systemdのユニットファイルを書いてサービス化。</p>

<ul>
<li>d</li>
</ul>

<pre><code class="language-sh"># mkdir -p /var/log/kubernetes
# chown kubernetes:kubernetes /var/log/kubernetes
# chmod 0700 /var/log/kubernetes
# MASTER_IP=192.168.171.200
# SERVICE_CLUSTER_IP_RANGE=&quot;10.0.0.0/16&quot;
# SECRET_ENC_KEY=$(echo -n 'your_32_bytes_secure_private_key' | base64)
# cat &gt; /etc/kubernetes/encryption.conf &lt;&lt; EOF
kind: EncryptionConfig
apiVersion: v1
resources:
  - resources:
    - secrets
    providers:
    - aescbc:
        keys:
        - name: key1
          secret: ${SECRET_ENC_KEY}
    - identity: {}
EOF
# cat &gt; /etc/kubernetes/audit-policy.conf &lt;&lt; EOF
apiVersion: audit.k8s.io/v1beta1
kind: Policy
# Don't generate audit events for all requests in RequestReceived stage.
omitStages:
  - &quot;RequestReceived&quot;
rules:
  # Log pod changes at RequestResponse level
  - level: RequestResponse
    resources:
    - group: &quot;&quot;
      # Resource &quot;pods&quot; doesn't match requests to any subresource of pods,
      # which is consistent with the RBAC policy.
      resources: [&quot;pods&quot;]
  # Log &quot;pods/log&quot;, &quot;pods/status&quot; at Metadata level
  - level: Metadata
    resources:
    - group: &quot;&quot;
      resources: [&quot;pods/log&quot;, &quot;pods/status&quot;]


  # Don't log requests to a configmap called &quot;controller-leader&quot;
  - level: None
    resources:
    - group: &quot;&quot;
      resources: [&quot;configmaps&quot;]
      resourceNames: [&quot;controller-leader&quot;]


  # Don't log watch requests by the &quot;system:kube-proxy&quot; on endpoints or services
  - level: None
    users: [&quot;system:kube-proxy&quot;]
    verbs: [&quot;watch&quot;]
    resources:
    - group: &quot;&quot; # core API group
      resources: [&quot;endpoints&quot;, &quot;services&quot;]


  # Don't log authenticated requests to certain non-resource URL paths.
  - level: None
    userGroups: [&quot;system:authenticated&quot;]
    nonResourceURLs:
    - &quot;/api*&quot; # Wildcard matching.
    - &quot;/version&quot;


  # Log the request body of configmap changes in kube-system.
  - level: Request
    resources:
    - group: &quot;&quot; # core API group
      resources: [&quot;configmaps&quot;]
    # This rule only applies to resources in the &quot;kube-system&quot; namespace.
    # The empty string &quot;&quot; can be used to select non-namespaced resources.
    namespaces: [&quot;kube-system&quot;]


  # Log configmap and secret changes in all other namespaces at the Metadata level.
  - level: Metadata
    resources:
    - group: &quot;&quot; # core API group
      resources: [&quot;secrets&quot;, &quot;configmaps&quot;]


  # Log all other resources in core and extensions at the Request level.
  - level: Request
    resources:
    - group: &quot;&quot; # core API group
    - group: &quot;extensions&quot; # Version of group should NOT be included.


  # A catch-all rule to log all other requests at the Metadata level.
  - level: Metadata
    # Long-running requests like watches that fall under this rule will not
    # generate an audit event in RequestReceived.
    omitStages:
      - &quot;RequestReceived&quot;
EOF
# cat &gt; /etc/systemd/system/kube-apiserver.service &lt;&lt; EOF
[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/kubernetes/kubernetes
After=network.target


[Service]
User=kubernetes
Group=kubernetes
ExecStart=/usr/bin/kube-apiserver \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --apiserver-count=1 \\
  --allow-privileged=true \\
  --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,NodeRestriction,DenyEscalatingExec,StorageObjectInUseProtection \\
  --authorization-mode=Node,RBAC \\
  --bind-address=0.0.0.0 \\
  --advertise-address=${MASTER_IP} \\
  --client-ca-file=/etc/kubernetes/pki/ca.crt \\
  --etcd-cafile=/etc/kubernetes/pki/etcd-ca.crt \\
  --etcd-certfile=/etc/kubernetes/pki/etcd-client.crt \\
  --etcd-keyfile=/etc/kubernetes/pki/etcd-client.key \\
  --etcd-servers=https://${MASTER_IP}:2379 \\
  --service-account-key-file=/etc/kubernetes/pki/kube-controller-manager.pub \\
  --service-cluster-ip-range=${SERVICE_CLUSTER_IP_RANGE} \\
  --tls-cert-file=/etc/kubernetes/pki/kube-apiserver.crt \\
  --tls-private-key-file=/etc/kubernetes/pki/kube-apiserver.key \\
  --kubelet-certificate-authority=/etc/kubernetes/pki/ca.crt \\
  --enable-bootstrap-token-auth=true \\
  --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt \\
  --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key \\
  --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname \\
  --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt \\
  --requestheader-username-headers=X-Remote-User \\
  --requestheader-group-headers=X-Remote-Group \\
  --requestheader-allowed-names=front-proxy-client \\
  --requestheader-extra-headers-prefix=X-Remote-Extra- \\
  --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt \\
  --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key \\
  --experimental-encryption-provider-config=/etc/kubernetes/encryption.conf \\
  --v=2 \\
  --tls-min-version=VersionTLS12 \\
  --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 \\
  --anonymous-auth=false \\
  --audit-log-format=json \\
  --audit-log-maxage=30 \\
  --audit-log-maxbackup=3 \\
  --audit-log-maxsize=100 \\
  --audit-log-path=/var/log/kubernetes/kube-audit.log \\
  --audit-policy-file=/etc/kubernetes/audit-policy.conf
Restart=always
RestartSec=10s


[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable kube-apiserver
# systemctl start kube-apiserver
</code></pre>

<p><code>--allow-privileged</code>はflannelなどに必要。</p>

<p><code>--enable-admission-plugins</code>には<a href="https://kubernetes.io/docs/admin/admission-controllers/#is-there-a-recommended-set-of-admission-controllers-to-use">公式推奨のプラグイン</a>に加えて、後述のTLS BootstrappingのためのNodeRestrictionを指定。
また、<code>--allow-privileged</code>の効果を軽減するため、DenyEscalatingExecも追加で指定。
また、使われているPersistent VolumeやPersistent Volume Claimが誤って消されることを防ぐ<a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/#storage-object-in-use-protection">StorageObjectInUseProtection</a>も追加で指定。
因みに、プラグインを指定する順番はKubernetes 1.10からは気にしなくてよくなった。</p>

<p><code>--authorization-mode</code>にはRBACを指定するのが標準。
後述のTLS Bootstrappingをするなら、Nodeも要る。</p>

<p><code>--experimental-encryption-provider-config</code>は<a href="https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/">Secretを暗号化する</a>ための設定。
暗号化のキーをローテーションすることもできるけど、それはやってない。</p>

<p><code>--tls-min-version</code>と<code>--tls-cipher-suites</code>は<a href="https://www.lambdanote.com/blogs/news/openssl-cookbook">OpenSSLクックブック</a>と<a href="https://golang.org/pkg/crypto/tls/#pkg-constants">Goのtlsパッケージドキュメント</a>を参考に設定。
RSA鍵交換はNG、RC4と3DESもNG、AESの鍵長は128ビット以上、SHA1はNG。</p>

<p>また、(&ndash;tls-min-versionをVersionTLS12にする場合?)TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256が必須で、CBCモードがNG。(参照: <a href="https://github.com/golang/go/blob/release-branch.go1.9/src/net/http/h2_bundle.go">https://github.com/golang/go/blob/release-branch.go1.9/src/net/http/h2_bundle.go</a>)</p>

<p><code>--anonymous-auth=false</code>はセキュリティのため設定。</p>

<p><code>--requestheader-*</code>と<code>--proxy-client-*</code>は上記API Aggregationのための設定。</p>

<p><code>--audit-*</code>は監査ログ設定。
100MB3面のログを30日間保持する。
ログポリシーは<a href="https://kubernetes.io/docs/tasks/debug-application-cluster/audit/">公式のサンプル</a>そのまま。</p>

<p><code>--feature-gates</code>でRotateKubeletServerCertificateを有効にして、kubeletのサーバ証明書を自動更新するようにしている。
因みに、クライアント証明書を自動更新するRotateKubeletClientCertificateはデフォルトで有効。
これらがCertificate Rotationと呼ばれる機能。</p>

<p><code>--feature-gates</code>は全Kubernetesコンポーネントで同じ値を指定するのがよさそう。</p>

<p>確認。</p>

<pre><code class="language-sh"># systemctl status kube-apiserver -l
# journalctl -u kube-apiserver
</code></pre></li>

<li><p>kube-controller-manager</p>

<p>systemdのユニットファイルを書いてサービス化。</p>

<pre><code class="language-sh"># CLUSTER_CIDR=&quot;10.244.0.0/16&quot;
# SERVICE_CLUSTER_IP_RANGE=&quot;10.0.0.0/16&quot;
# CLUSTER_NAME=&quot;k8s&quot;
# cat &gt; /etc/systemd/system/kube-controller-manager.service &lt;&lt; EOF
[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/kubernetes/kubernetes
After=network.target


[Service]
User=kubernetes
Group=kubernetes
ExecStart=/usr/bin/kube-controller-manager \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig \\
  --bind-address=0.0.0.0 \\
  --controllers=*,bootstrapsigner,tokencleaner \\
  --service-account-private-key-file=/etc/kubernetes/pki/kube-controller-manager.key \\
  --allocate-node-cidrs=true \\
  --cluster-cidr=${CLUSTER_CIDR} \\
  --node-cidr-mask-size=24 \\
  --cluster-name=${CLUSTER_NAME} \\
  --service-cluster-ip-range=${SERVICE_CLUSTER_IP_RANGE} \\
  --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt \\
  --cluster-signing-key-file=/etc/kubernetes/pki/ca.key \\
  --root-ca-file=/etc/kubernetes/pki/ca.crt \\
  --use-service-account-credentials=true \\
  --v=2 \\
  --experimental-cluster-signing-duration=8760h0m0s
Restart=always
RestartSec=10s


[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable kube-controller-manager
# systemctl start kube-controller-manager
</code></pre>

<p>期限の切れたBootstrap token(後述)を消すためにtokencleanerを有効にしている。</p>

<p>bootstrapsignerは後述のcluster-infoにBootstrap tokenで署名するためのコントローラ。</p>

<p><a href="https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/#approval-controller">csrapproving</a>というコントローラがデフォルトで有効になっていて、後述のTLS BootstrapppingやCertificate Rotationの時に作られるCSRを自動で承認する。</p>

<p><code>--cluster-cidr</code>で指定するネットワークは、後述のネットワークプロバイダの設定と合っている必要がある。
<code>--allocate-node-cidrs</code>は<code>--cluster-cidr</code>の前提。</p>

<p><code>--node-cidr-mask-size</code>は、ノードに使うネットワークのサイズを指定するオプションで、<code>--cluster-cidr</code>で指定したネットワークの一部になるようにする。
<code>--cluster-cidr</code>で<code>/16</code>を指定した場合、半分の<code>/24</code>にするのが普通。
つまり256ノードまで作れて、それぞれ254個のPodをホストできるような構成。</p>

<p><code>--experimental-cluster-signing-duration</code>は、Certificate Rotationのための設定で、自動発行する証明書の期限を1年に指定している。</p>

<p><code>--use-service-account-credentials</code>をつけると、<a href="https://kubernetes.io/docs/admin/authorization/rbac/#controller-roles">各コントローラが別々のService Accountで動く</a>。</p>

<p><code>--secure-port</code>や<code>--tls-*</code>は、ヘルスチェックAPIをHTTPSにするだけで意味が無いし、設定すると<code>kubectl get componentstatuses</code>でエラーが出るようになるので、設定しないほうがいい。</p>

<p>確認。</p>

<pre><code class="language-sh"># systemctl status kube-controller-manager -l
</code></pre></li>

<li><p>kube-scheduler</p>

<p>systemdのユニットファイルを書いてサービス化。</p>

<pre><code class="language-sh"># cat &gt; /etc/systemd/system/kube-scheduler.service &lt;&lt; EOF
[Unit]
Description=Kubernetes Scheduler
Documentation=https://github.com/kubernetes/kubernetes
After=network.target


[Service]
User=kubernetes
Group=kubernetes
ExecStart=/usr/bin/kube-scheduler \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --kubeconfig=/etc/kubernetes/kube-scheduler.kubeconfig \\
  --address=0.0.0.0 \\
  --v=2
Restart=always
RestartSec=10s


[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable kube-scheduler
# systemctl start kube-scheduler
</code></pre>

<p>確認。</p>

<pre><code class="language-sh"># systemctl status kube-scheduler -l
</code></pre></li>

<li><p>マスタコンポーネント状態確認</p>

<pre><code class="language-sh"># kubectl version
# kubectl get componentstatuses
</code></pre></li>
</ol></li>

<li><p><a href="https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/">TLS Bootstrapping</a>の設定</p>

<p>TLS Bootstrappingは、Kubernetesクラスタのコンポーネント間の通信がTLSで暗号化されている環境で、ノードが新たにクラスタに参加するとき、自動的にセキュアに<a href="https://ja.wikipedia.org/wiki/%E8%A8%BC%E6%98%8E%E6%9B%B8%E7%BD%B2%E5%90%8D%E8%A6%81%E6%B1%82">CSR</a>を処理する仕組み。</p>

<p>TLS Bootstrappingでは、kubeletは起動時にBootstrap kubeconfigを読んで、kubeletとノード用のCSRを生成し、それらがkube-controller-managerに承認されると、kubelet用のクライアント証明書と秘密鍵を生成する。
その証明書と鍵を使ってkubeconfigを生成し、以降のクラスタへの接続に使う。</p>

<p>Bootstrap時の認証には<a href="https://kubernetes.io/docs/admin/bootstrap-tokens/">Bootstrap Tokens</a>か<a href="https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/#token-authentication-file">Token authentication file</a>を使うことが推奨されていて、今回は前者を使う。</p>

<p>(後者については<a href="https://medium.com/@toddrosner/kubernetes-tls-bootstrapping-cf203776abc7">この記事</a>に詳しい。)</p>

<ol>
<li><p>Bootstrap TokenのSecret生成</p>

<p>以下のように生成できる。</p>

<pre><code class="language-sh"># TOKEN_PUB=$(openssl rand -hex 3)
# TOKEN_SECRET=$(openssl rand -hex 8)
# BOOTSTRAP_TOKEN=&quot;${TOKEN_PUB}.${TOKEN_SECRET}&quot;
# kubectl -n kube-system create secret generic bootstrap-token-${TOKEN_PUB} --type 'bootstrap.kubernetes.io/token' --from-literal description=&quot;cluster bootstrap token&quot; --from-literal token-id=${TOKEN_PUB} --from-literal token-secret=${TOKEN_SECRET} --from-literal usage-bootstrap-authentication=true --from-literal usage-bootstrap-signing=true --from-literal auth-extra-groups=system:bootstrappers:worker,system:bootstrappers:ingress
</code></pre>

<p>けど、<a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-token/#cmd-token-generate">kubeadm</a>でも生成出来てこっちのほうが楽なので、それで。</p>

<pre><code class="language-sh"># BOOTSTRAP_TOKEN=$(kubeadm token create --kubeconfig /etc/kubernetes/admin.kubeconfig)
</code></pre>

<p>BOOTSTRAP_TOKENの値はあとで使う。</p>

<p>expirationは指定できなくて、1日で期限切れになっちゃうけど、クラスタにノードを追加するときに有効であればいいのでまあいい。</p>

<p>確認。</p>

<pre><code class="language-sh"># TOKEN_PUB=$(echo $BOOTSTRAP_TOKEN | sed -e s/\\..*//)
# kubectl -n kube-system get secret/bootstrap-token-${TOKEN_PUB} -o yaml
</code></pre></li>

<li><p>Bootstrap kubeconfig作成</p>

<p>Bootstrap時は<code>kubelet-bootstrap</code>というユーザでkube-apiserverに接続する。
<code>kubelet-bootstrap</code>は<code>system:node-bootstrapper</code>ロールを持って<code>system:bootstrappers</code>に属しているユーザとして認証される必要がある。</p>

<pre><code class="language-sh"># mkdir -p /etc/kubernetes/manifests
# MASTER_IP=192.168.171.200
# KUBERNETES_PUBLIC_ADDRESS=$MASTER_IP
# CLUSTER_NAME=&quot;k8s&quot;
# KCONFIG=&quot;/etc/kubernetes/bootstrap.kubeconfig&quot;
# KUSER=&quot;kubelet-bootstrap&quot;
# kubectl config set-cluster ${CLUSTER_NAME} --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 --kubeconfig=${KCONFIG}
# kubectl config set-context ${KUSER}@${CLUSTER_NAME} --cluster=${CLUSTER_NAME} --user=${KUSER} --kubeconfig=${KCONFIG}
# kubectl config use-context ${KUSER}@${CLUSTER_NAME} --kubeconfig=${KCONFIG}
# chown kubernetes:kubernetes ${KCONFIG}
# chmod 0600 ${KCONFIG}
</code></pre>

<p>確認。</p>

<pre><code class="language-sh"># kubectl config view --kubeconfig=${KCONFIG}
</code></pre></li>

<li><p>CA証明書とbootstrap kubeconfigをConfigMap(cluster-info)で公開</p>

<p>kubeletはこのConfigMapを見てクラスタに参加する。</p>

<pre><code class="language-sh"># kubectl -n kube-public create configmap cluster-info --from-file /etc/kubernetes/pki/ca.crt --from-file /etc/kubernetes/bootstrap.kubeconfig
</code></pre>

<p>anonymousユーザにcluster-infoへのアクセスを許可する。</p>

<pre><code class="language-sh"># kubectl -n kube-public create role system:bootstrap-signer-clusterinfo --verb get --resource configmaps
# kubectl -n kube-public create rolebinding kubeadm:bootstrap-signer-clusterinfo --role system:bootstrap-signer-clusterinfo --user system:anonymous
</code></pre>

<p>system:bootstrappersグループにsystem:node-bootstrapperロールを紐づける。</p>

<pre><code class="language-sh"># kubectl create clusterrolebinding kubeadm:kubelet-bootstrap --clusterrole system:node-bootstrapper --group system:bootstrappers
</code></pre></li>

<li><p>bootstrap.kubeconfigにトークンを追記</p>

<pre><code class="language-sh"># kubectl config set-credentials kubelet-bootstrap --token=${BOOTSTRAP_TOKEN} --kubeconfig=/etc/kubernetes/bootstrap.kubeconfig
</code></pre></li>
</ol></li>

<li><p>Docker、CNI、kubeletインストール</p>

<ol>
<li><p>Docker</p>

<p><a href="https://docs.docker.com/install/linux/docker-ce/centos/#set-up-the-repository">https://docs.docker.com/install/linux/docker-ce/centos/#set-up-the-repository</a>
に従ってDocker CEをインストール。
ストレージドライバにはoverlay2をつかうので、device-mapper-persistent-dataとlvm2は入れない。</p>

<pre><code class="language-sh"># yum install -y yum-utils
# yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
# yum install -y docker-ce
</code></pre>

<p>18.03.0-ceが入った。</p>

<p>が、よくみたらDocker CEはOracle Linuxをサポートしていないので、Docker CEはアンインストールして、代わりに<a href="https://docs.oracle.com/cd/E77565_01/E87205/html/section_install_upgrade_yum_docker.html">Oracle Container Runtime for Docker</a> (aka docker-engine)を入れる。</p>

<p><code>/etc/yum.repos.d/public-yum-ol7.repo</code>の<code>ol7_addons</code>の<code>enabled</code>を1にして、以下のコマンドでdocker-engineをインストール。</p>

<pre><code class="language-sh"># yum install -y docker-engine
</code></pre>

<p>docker-engine 17.06.2が入った。</p>

<p><code>/etc/sysconfig/docker</code>に以下を追記して、 Dockerがオープンできる最大ファイル数を増やす。</p>

<pre><code>DOCKER_NOFILE=1000000
</code></pre>

<p>Kubernetes環境ではiptablesはkube-proxyが操作するので、Dockerには操作させないようにするため、<code>/etc/sysconfig/docker</code>の<code>OPTIONS</code>に<code>--iptables=false</code>を追加。
(これをすると、<code>--icc=false</code>は設定できなくなる(不要になる)。)</p>

<pre><code class="language-sh"># systemctl daemon-reload
# systemctl enable docker
# systemctl start docker
</code></pre>

<p>確認。</p>

<pre><code class="language-sh"># cat /proc/$(pidof dockerd)/environ
# systemctl status docker -l
# docker version
</code></pre></li>

<li><p>CNI</p>

<pre><code class="language-sh"># mkdir -p /etc/cni/net.d /opt/cni/bin/
# cd /tmp
# curl -OL https://github.com/containernetworking/cni/releases/download/v0.6.0/cni-amd64-v0.6.0.tgz
# curl -OL https://github.com/containernetworking/plugins/releases/download/v0.7.1/cni-plugins-amd64-v0.7.1.tgz
# cd /opt/cni/bin
# tar zxf /tmp/cni-amd64-v0.6.0.tgz
# tar zxf /tmp/cni-plugins-amd64-v0.7.1.tgz
# chmod +x /opt/cni/bin/*
# cat &gt;/etc/cni/net.d/99-loopback.conf &lt;&lt;EOF
{
  &quot;type&quot;: &quot;loopback&quot;
}
EOF
</code></pre></li>

<li><p>kubelet</p>

<p>前提コマンド(conntrack)インストール。</p>

<pre><code class="language-sh"># yum -y install conntrack-tools
</code></pre>

<p>systemdのユニットファイルを書いてサービス化。</p>

<pre><code class="language-sh"># DNS_SERVER_IP=10.0.0.10
# PAUSE_IMAGE=k8s.gcr.io/pause-amd64:3.1
# DNS_DOMAIN=&quot;cluster.local&quot;
# cat &gt; /etc/systemd/system/kubelet.service &lt;&lt; EOF
[Unit]
Description=Kubernetes Kubelet
Documentation=https://github.com/kubernetes/kubernetes
After=docker.service
Requires=docker.service


[Service]
User=root
Group=root
ExecStart=/usr/bin/kubelet \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --address=0.0.0.0 \\
  --bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \\
  --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \\
  --pod-manifest-path=/etc/kubernetes/manifests \\
  --network-plugin=cni \\
  --cni-conf-dir=/etc/cni/net.d \\
  --cni-bin-dir=/opt/cni/bin \\
  --cluster-dns=${DNS_SERVER_IP} \\
  --cluster-domain=${DNS_DOMAIN} \\
  --authorization-mode=Webhook \\
  --client-ca-file=/etc/kubernetes/pki/ca.crt \\
  --cert-dir=/etc/kubernetes/pki \\
  --rotate-certificates=true \\
  --v=2 \\
  --cgroup-driver=cgroupfs \\
  --pod-infra-container-image=${PAUSE_IMAGE} \\
  --tls-min-version=VersionTLS12 \\
  --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 \\
  --allow-privileged=true \\
  --anonymous-auth=false
Restart=always
RestartSec=10s


[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable kubelet
# systemctl start kubelet
</code></pre>

<p>(実際は、systemctl start kubeletするまえに、後述のNode CSR自動承認設定をすべし。)</p>

<p><code>--allow-privileged</code>はflannelなどに必要。</p>

<p><code>--pod-infra-container-image</code>では<a href="https://github.com/kubernetes/kubernetes/tree/master/build/pause">pause</a>コンテナイメージを指定する。
このコンテナはPod毎に起動され、Podネットワークの名前空間を保持するために使われるらしい。
今回使った<code>k8s.gcr.io/pause-amd64:3.1</code>はKubernetesチームが配布しているものだけど、Oracleが配布しているものもあり、そちらを使うには、Oracle Linux 7.4のダウンロード媒体リストに含まれるOracle Container Services for use with Kubernetes 1.1.9.1に入っているpause-amd64.tarを<code>docker load</code>しておいて、そのイメージ名を<code>--pod-infra-container-image</code>に渡せばいい。</p>

<p><code>--bootstrap-kubeconfig</code>で指定したkubeconfigでTLS Bootstrapして、<code>--cert-dir</code>で指定したディレクトリに証明書と鍵を生成して、<code>--kubeconfig</code>で指定したパスに以降使うkubeconfigを生成する。
この証明書を自動更新(i.e. Certificate Rotation)するオプションが<code>--rotate-certificates</code>。</p>

<p><code>--pod-manifest-path</code>で指定したディレクトリはkubeletに定期的にスキャンされ、そこに置いたKubernetesマニフェスト(ドットで始まるもの以外)が読まれる。
(参照: <a href="https://kubernetes.io/docs/tasks/administer-cluster/static-pod/">Static Pods</a>)</p>

<p><code>--pod-cidr</code>は指定しない。
これはkube-controller-managerに渡した<code>--cluster-cidr</code>と<code>--node-cidr-mask-size</code>から計算されるので。</p>

<p><code>--anonymous-auth=false</code>は<a href="https://kubernetes.io/docs/admin/kubelet-authentication-authorization/">セキュリティのために推奨されたオプション</a>。</p>

<p><code>--authorization-mode=Webhook</code>も<a href="https://kubernetes.io/docs/admin/kubelet-authentication-authorization/">セキュリティのために推奨されたオプション</a>で、認可処理をkube-apiserverに移譲する設定。</p>

<p>本当は<a href="https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/">Kubelet Configファイル</a>を使ったほうがいいみたいなので、いずれそれに対応する。
(対応した: 「<a href="https://www.kaitoy.xyz/2018/05/05/kubernetes-kubelet-config-and-pod-sec-policy/">Kubernetes 1.10のkubeletの起動オプションをKubelet ConfigファイルとPodSecurityPolicyで置き換える</a>」)</p>

<p>起動確認。</p>

<pre><code class="language-sh"># systemctl status kubelet -l
</code></pre></li>

<li><p>Node CSR手動承認</p>

<p>TLS Bootstrappingで生成されたCSRを手動で承認する。</p>

<p>CSRは以下のコマンドで見れる。</p>

<pre><code class="language-sh"># kubectl get csr
NAME                                                   AGE       REQUESTOR                 CONDITION
csr-cf9hm                                              24m       system:node:k8s-master  Pending
node-csr-Vcw_4HioW1CI96eDH29RMKPrOchEN133053wm6DCXUk   24m       system:bootstrap:itacbw   Pending
</code></pre>

<p><code>node-csr-…</code>がクライアント証明書のためのCSRで、<code>csr-…</code>がサーバ証明書の。
これらを承認する。</p>

<pre><code class="language-sh"># kubectl certificate approve node-csr-Vcw_4HioW1CI96eDH29RMKPrOchEN133053wm6DCXUk
# kubectl certificate approve csr-cf9hm
</code></pre>

<p>(因みに否認するときは<code>kubectl certificate deny</code>)</p>

<p>これでクラスタにノードが追加されたはず。
確認。</p>

<pre><code class="language-sh"># kubectl get node
NAME         STATUS    ROLES     AGE       VERSION
k8s-master   Ready     &lt;none&gt;    36s       v1.10.0
</code></pre></li>

<li><p>Node CSR自動承認設定</p>

<p>前節でやった手動承認はcsrapprovingが自動でやってくれる。</p>

<p>新規ノード参加時のCSRを承認するClusterRoleとして<code>system:certificates.k8s.io:certificatesigningrequests:nodeclient</code>が自動生成されているので、これを<code>system:bootstrappers</code>グループにバインドしてやると、自動承認が有効になる。</p>

<ul>
<li>s</li>
</ul>

<pre><code class="language-sh"># cat &lt;&lt;EOF | kubectl create -f -
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: auto-approve-csrs-for-group
subjects:
- kind: Group
  name: system:bootstrappers
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: system:certificates.k8s.io:certificatesigningrequests:nodeclient
  apiGroup: rbac.authorization.k8s.io
EOF
</code></pre>

<p>また、kubeletのクライアント証明書を自動更新(i.e. RotateKubeletClientCertificate)するときのCSRを承認するClusterRoleとして<code>system:certificates.k8s.io:certificatesigningrequests:selfnodeclient</code>が自動生成されていて、これをノード毎のユーザにバインドしてやると、自動承認が有効になる。</p>

<pre><code class="language-sh"># HOSTNAME=k8s-master
# cat &lt;&lt;EOF | kubectl create -f -
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: ${HOSTNAME}-node-client-cert-renewal
subjects:
- kind: User
  name: system:node:${HOSTNAME}
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient
  apiGroup: rbac.authorization.k8s.io
EOF
</code></pre>

<p>kubeletのサーバ証明書を自動更新(i.e. RotateKubeletServerCertificate)するときのCSRを承認するClusterRoleは現時点で自動生成されないので、自分で作ってノード毎のユーザにバインドして、自動承認を有効にする。</p>

<pre><code class="language-sh"># cat &lt;&lt;EOF | kubectl create -f -
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: approve-node-server-renewal-csr
rules:
- apiGroups: [&quot;certificates.k8s.io&quot;]
  resources: [&quot;certificatesigningrequests/selfnodeserver&quot;]
  verbs: [&quot;create&quot;]
EOF
# HOSTNAME=k8s-master
# cat &lt;&lt;EOF | kubectl create -f -
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: ${HOSTNAME}-server-client-cert-renewal
subjects:
- kind: User
  name: system:node:${HOSTNAME}
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: approve-node-server-renewal-csr
  apiGroup: rbac.authorization.k8s.io
EOF
</code></pre></li>
</ol></li>

<li><p>kube-proxy、オーバレイネットワーク、DNSのデプロイ</p>

<ol>
<li><p>kube-proxy</p>

<p>kube-proxyのkubeconfigを作成。</p>

<pre><code class="language-sh"># MASTER_IP=192.168.171.200
# KUBERNETES_PUBLIC_ADDRESS=$MASTER_IP
# CLUSTER_NAME=&quot;k8s&quot;
# KCONFIG=&quot;/etc/kubernetes/kube-proxy.kubeconfig&quot;
# KUSER=&quot;system:kube-proxy&quot;
# kubectl config set-cluster ${CLUSTER_NAME} --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 --kubeconfig=${KCONFIG}
# kubectl config set-credentials ${KUSER} --client-certificate=/etc/kubernetes/pki/kube-proxy.crt --client-key=/etc/kubernetes/pki/kube-proxy.key --embed-certs=true --kubeconfig=${KCONFIG}
# kubectl config set-context ${KUSER}@${CLUSTER_NAME} --cluster=${CLUSTER_NAME} --user=${KUSER} --kubeconfig=${KCONFIG}
# kubectl config use-context ${KUSER}@${CLUSTER_NAME} --kubeconfig=${KCONFIG}
# chown kubernetes:kubernetes ${KCONFIG}
# chmod 0600 ${KCONFIG}
</code></pre>

<p>確認。</p>

<pre><code class="language-sh"># kubectl config view --kubeconfig=${KCONFIG}
</code></pre>

<p>Service Accountのkube-proxyに<code>system:node-proxier</code>というClusterRoleを付ける。</p>

<pre><code class="language-sh"># kubectl create clusterrolebinding kubeadm:node-proxier --clusterrole system:node-proxier --serviceaccount kube-system:kube-proxy
</code></pre>

<p>systemdのユニットファイルを書いてサービス化。</p>

<pre><code class="language-sh"># CLUSTER_CIDR=&quot;10.244.0.0/16&quot;
# cat &gt; /etc/systemd/system/kube-proxy.service &lt;&lt; EOF
[Unit]
Description=Kubernetes Kube Proxy
Documentation=https://github.com/kubernetes/kubernetes
After=network.target


[Service]
User=root
Group=root
ExecStart=/usr/bin/kube-proxy \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --bind-address 0.0.0.0 \\
  --cluster-cidr=${CLUSTER_CIDR} \\
  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig \\
  --v=2
Restart=always
RestartSec=10s


[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable kube-proxy
# systemctl start kube-proxy
</code></pre>

<p>確認。</p>

<pre><code class="language-sh"># systemctl status kube-proxy -l
</code></pre></li>

<li><p>ネットワークプロバイダ (flannel)</p>

<p><a href="https://github.com/coreos/flannel/blob/master/Documentation/kubernetes.md">flannelのドキュメント</a>を参考に。</p>

<p>flannelをデプロイするには、kube-apiserverとkube-controller-managerの起動オプションに<code>--allow-privileged</code>を付ける必要がある。</p>

<p>また、公式が配布しているKubernetesマニフェストを使う場合、kube-controller-managerの起動オプションの<code>--cluster-cidr</code>で<code>10.244.0.0/16</code>を指定する必要がある。</p>

<p>デプロイ自体は以下のコマンドを実行するだけ。</p>

<pre><code class="language-sh"># kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</code></pre>

<p>このKubernetesマニフェストでは、quay.ioから<code>quay.io/coreos/flannel:v0.10.0-amd64</code>というコンテナイメージがpullされる。</p>

<p>Oracleもflannelのコンテナイメージを配布していて、そちらを使うには、Oracle Linux 7.4のダウンロード媒体リストに含まれるOracle Container Services for use with Kubernetes 1.1.9.1に入っているflannel.tarを<code>docker load</code>しておいて、そのイメージを使うようにマニフェストを書きかえればいい。</p>

<p>起動確認。</p>

<pre><code class="language-sh"># kubectl -n kube-system get po
NAME                    READY     STATUS    RESTARTS   AGE
kube-flannel-ds-gkcqd   1/1       Running   0          1m
</code></pre>

<p>flannelは<a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/">Network Policy</a>をサポートしていないので、<a href="https://www.projectcalico.org/">Calico</a>か<a href="https://www.weave.works/oss/net/">Weave Net</a>あたりにすればよかったかも。
(やった: 「<a href="https://www.kaitoy.xyz/2018/05/04/kubernetes-with-weave-net/">Kubernetes 1.10のクラスタにWeave Netをデプロイする</a>」)</p></li>

<li><p>CoreDNS</p>

<p>Kubernetes 1.10からは、サービスディスカバリに(kube-dnsの代わりに)CoreDNSを使うのが標準になった。</p>

<p>以下を参考にCoreDNSをデプロイする:</p>

<ul>
<li><a href="https://kubernetes.io/docs/tasks/administer-cluster/coredns/">https://kubernetes.io/docs/tasks/administer-cluster/coredns/</a></li>
<li><a href="https://coredns.io/2018/01/29/deploying-kubernetes-with-coredns-using-kubeadm/">https://coredns.io/2018/01/29/deploying-kubernetes-with-coredns-using-kubeadm/</a></li>
<li><a href="https://github.com/coredns/deployment/tree/master/kubernetes">https://github.com/coredns/deployment/tree/master/kubernetes</a></li>
</ul>

<pre><code class="language-sh"># cd /tmp
# curl -LO https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/coredns.yaml.sed
# curl -LO https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/deploy.sh
# chmod +x deploy.sh
# DNS_SERVER_IP=&quot;10.0.0.10&quot;
# SERVICE_CLUSTER_IP_RANGE=&quot;10.0.0.0/16&quot;
# DNS_DOMAIN=&quot;cluster.local&quot;
# ./deploy.sh -r $SERVICE_CLUSTER_IP_RANGE -i $DNS_SERVER_IP -d $DNS_DOMAIN &gt; coredns.yaml
# kubectl apply -f coredns.yaml
</code></pre>

<p>このKubernetesマニフェストではDocker Hubから<code>coredns/coredns:1.1.1</code>というイメージがpullされる。</p>

<p>起動確認。</p>

<pre><code class="language-sh"># kubectl -n kube-system get pods -o wide | grep coredns
coredns-8459d9f654-b585f   1/1       Running   0          48s       10.244.0.3        k8s-master
coredns-8459d9f654-x7drc   1/1       Running   0          48s       10.244.0.2        k8s-master
</code></pre>

<p>起動確認時にCoreDNSのIPアドレスを確認して、動作確認。</p>

<pre><code class="language-sh"># dig @10.244.0.3 kubernetes.default.svc.cluster.local +noall +answer


; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-61.el7 &lt;&lt;&gt;&gt; @10.244.0.3 kubernetes.default.svc.cluster.local +noall +answer
; (1 server found)
;; global options: +cmd
kubernetes.default.svc.cluster.local. 5 IN A    10.0.0.1
</code></pre></li>
</ol></li>

<li><p>Kubernetesアプリデプロイ</p>

<p>前節まででKubernetesクラスタの構築は完了。
試しにKubernetesアプリをひとつデプロイしてみる。</p>

<ol>
<li><p><a href="https://github.com/weaveworks/scope">Weave Scope</a></p>

<p><a href="https://www.weave.works/docs/scope/latest/installing/#k8s">ドキュメント</a>を参考に。</p>

<pre><code class="language-sh"># cd /tmp
# curl -sSL -o scope.yaml https://cloud.weave.works/k8s/scope.yaml?k8s-service-type=NodePort
# kubectl apply -f scope.yaml
</code></pre>

<p>このKubernetesマニフェストではDocker Hubから<code>weaveworks/scope:1.8.0</code>というイメージがpullされる。</p>

<p><code>kubectl -n weave get svc/weave-scope-app</code>でポート調べて、<code>http://k8s-master:&lt;ポート&gt;/</code>をブラウザ開くとWeave ScopeのGUIが見れる。</p></li>
</ol></li>
</ol>

      </div>

      <div class="text-center custom-partial">
        
      </div>

      <aside>
        
        

        
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
             style="display:block"
             data-ad-client="ca-pub-6244473643910448"
             data-ad-slot="1845600530"
             data-ad-format="auto"></ins>
        <script>
        (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      </aside>

      <aside>
        <div class="row">
          <div class="col-sm-5">
            <section id="share">
              <h3>Share</h3>
              <a id="share-fb" href="http://www.facebook.com/sharer.php?src=bm&u=https%3a%2f%2fwww.kaitoy.xyz%2f2018%2f04%2f17%2fkubernetes110-from-scratch%2f&t=Kubernetes%201.10%e3%82%92%e3%82%b9%e3%82%af%e3%83%a9%e3%83%83%e3%83%81%e3%81%8b%e3%82%89%e5%85%a8%e6%89%8b%e5%8b%95%e3%81%a7%e6%a7%8b%e7%af%89" onclick="window.open(this.href, 'PCwindow', 'width=550, height=350, menubar=no, toolbar=no, scrollbars=yes'); return false;"><img src="https://www.kaitoy.xyz/images/sharebutton/facebook.png" alt="Facebook"/></a>
              <a id="share-twitter" href="http://twitter.com/intent/tweet?url=https%3a%2f%2fwww.kaitoy.xyz%2f2018%2f04%2f17%2fkubernetes110-from-scratch%2f&text=Kubernetes%201.10%e3%82%92%e3%82%b9%e3%82%af%e3%83%a9%e3%83%83%e3%83%81%e3%81%8b%e3%82%89%e5%85%a8%e6%89%8b%e5%8b%95%e3%81%a7%e6%a7%8b%e7%af%89&tw_p=tweetbutton" onclick="window.open(this.href, 'PCwindow', 'width=550, height=350, menubar=no, toolbar=no, scrollbars=yes'); return false;"><img src="https://www.kaitoy.xyz/images/sharebutton/twitter.png" alt="Twitter"/></a>
              <a id="share-googleplus" href="https://plus.google.com/share?url=https%3a%2f%2fwww.kaitoy.xyz%2f2018%2f04%2f17%2fkubernetes110-from-scratch%2f" onclick="window.open(this.href, 'PCwindow', 'width=550, height=350, menubar=no, toolbar=no, scrollbars=yes'); return false;"><img src="https://www.kaitoy.xyz/images/sharebutton/googleplus.png" alt="Google+"/></a>
              <a id="share-hatena" href="http://b.hatena.ne.jp/add?mode=confirm&url=https%3a%2f%2fwww.kaitoy.xyz%2f2018%2f04%2f17%2fkubernetes110-from-scratch%2f" onclick="window.open(this.href, 'PCwindow', 'width=550, height=350, menubar=no, toolbar=no, scrollbars=yes'); return false;"><img src="https://www.kaitoy.xyz/images/sharebutton/hatena.png" alt="Hatena"/></a>
              <a id="share-pocket" href="http://getpocket.com/edit?url=https%3a%2f%2fwww.kaitoy.xyz%2f2018%2f04%2f17%2fkubernetes110-from-scratch%2f&title=Kubernetes%201.10%e3%82%92%e3%82%b9%e3%82%af%e3%83%a9%e3%83%83%e3%83%81%e3%81%8b%e3%82%89%e5%85%a8%e6%89%8b%e5%8b%95%e3%81%a7%e6%a7%8b%e7%af%89" onclick="window.open(this.href, 'PCwindow', 'width=550, height=350, menubar=no, toolbar=no, scrollbars=yes'); return false;"><img src="https://www.kaitoy.xyz/images/sharebutton/pocket.png" alt="Pocket"/></a>
            </section>
          </div>

          <div class="col-sm-7">
            
            

            
            <section id="related">
              <h3>Related Post</h3>
              <div id="tags">
                
                <a href="https://www.kaitoy.xyz/tags/kubernetes"><i class="fa fa-tags"></i> kubernetes </a>
                
                <a href="https://www.kaitoy.xyz/tags/docker"><i class="fa fa-tags"></i> docker </a>
                
              </div>

              <ul id="related-posts">
                
                
                
                
                
                
                <li><a href="https://www.kaitoy.xyz/2018/05/05/kubernetes-kubelet-config-and-pod-sec-policy/">Kubernetes 1.10のkubeletの起動オプションをKubelet ConfigファイルとPodSecurityPolicyで置き換える</a></li>
                
                
                
                
                
                <li><a href="https://www.kaitoy.xyz/2018/05/04/kubernetes-with-weave-net/">Kubernetes 1.10のクラスタにWeave Netをデプロイする</a></li>
                
                
                
                
                
                
                
                
                
                <li><a href="https://www.kaitoy.xyz/2018/04/01/hello-skaffold/">Skaffoldを触ってみた</a></li>
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                <li><a href="https://www.kaitoy.xyz/2017/10/31/retry-dashboard-on-k8s-cluster-by-kubeadm/">Kubernetes 1.8のアクセス制御について。あとDashboard。</a></li>
                
                
                
                
                
                <li><a href="https://www.kaitoy.xyz/2017/10/21/build-kubernetes-cluster-by-kubeadm/">Kubernetes1.8のクラスタを構築する。kubeadmで。</a></li>
                
                
                
                
                
                <li><a href="https://www.kaitoy.xyz/2017/10/11/goslings-on-kubernetes-cont/">Kubernetesのチュートリアルをやる</a></li>
                
                
                
                
                
                <li><a href="https://www.kaitoy.xyz/2017/10/10/goslings-on-kubernetes/">Kubernetes 1.8が出たので、Minikubeを触ってみる</a></li>
                
                
                
                
                
                
                
                
                
                <li><a href="https://www.kaitoy.xyz/2017/08/14/webdriverio-chrome/">WebdriverIOとChromeのヘッドレスモードで自動ブラウザテストするDockerイメージ: webdriverio-chrome</a></li>
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                <li><a href="https://www.kaitoy.xyz/2016/09/15/pcap4j-on-hyper-v-container-on-win10/">Pcap4J on Nano Server on Hyper-V Containers on Windows 10 on VMware Playerにトライ</a></li>
                
                
                
                
                
                <li><a href="https://www.kaitoy.xyz/2016/09/12/unzip-on-nanoserver/">Hyper-Vコンテナ(Nano Server)でunzipしたいならjarを使え</a></li>
                
                
                
                
                
                
                
                
                
                
                
                
                
                <li><a href="https://www.kaitoy.xyz/2016/07/31/docker-for-windows/">Docker for Windowsがコレジャナかった</a></li>
                
                
                
                
                
                <li><a href="https://www.kaitoy.xyz/2016/07/11/windows_containers_on_tp5/">Windows Server 2016 TP5でWindows Containersにリトライ</a></li>
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                <li><a href="https://www.kaitoy.xyz/2016/01/22/pcap4j-meets-windows-containers/">Pcap4J Meets Windows Containers</a></li>
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                <li><a href="https://www.kaitoy.xyz/2015/07/27/another-way-to-capture-lan-packets-with-pcap4j-container/">Another way to capture LAN packets with pcap4j container</a></li>
                
                
                
                
                
                
                
                
                
                <li><a href="https://www.kaitoy.xyz/2015/07/25/how-to-capture-packets-on-a-local-network-with-pcap4j-container/">How to capture packets on a local network with Pcap4J container</a></li>
                
                
                
                
                
                
                
                
                
                <li><a href="https://www.kaitoy.xyz/2015/07/19/pcap4j-container-with-runc/">Pcap4J container with runC</a></li>
                
                
                
                
                
                
              </ul>
            </section>
            
          </div>
        </div>
      </aside>

      
      <footer>
        <section id="pagination">
          <div class="row">
            <div class="col-sm-6">
              <div class="prev">
                
                <a href="https://www.kaitoy.xyz/2018/05/04/kubernetes-with-weave-net/">
                  <i class="fa fa-chevron-left"></i>
                  Kubernetes 1.10のクラスタにWeave Netをデプロイする
                </a>
                
              </div>
            </div>
            <div class="col-sm-6">
              <div class="next text-right">
                
                <a href="https://www.kaitoy.xyz/2018/04/01/hello-skaffold/">
                  Skaffoldを触ってみた
                  <i class="fa fa-chevron-right"></i>
                </a>
                
              </div>
            </div>
          </div>
        </section>

        
        <div id="disqus_thread"></div>
<script type="text/javascript">

(function() {
    
    
    if (window.location.hostname == "localhost")
        return;

    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    var disqus_shortname = 'kaitoy-tobedecided';
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

        
      </footer>

    </article>
  </div>

  <div class="col-md-3">
    <aside id="site-sidebar">
      <div class="row">
        <div class="col-md-12 col-sm-6 col-xs-12">
  <div class="text-center custom-partial">
    
  </div>
  <section class="sidebar-bordered">
    
    <div id="profile">
      <div class="text-center">
        <img id="profile-photo" src="/images/nopicture.png" alt="profile">
      </div>
      <div class="data">
        <h4 id="profile-username" class="post-title"></h4>
        
        <span id="profile-birth">DOB: Dec 14, 1983</span>
        
        <div id="social-links">
          
          <a href="https://www.facebook.com/yamada.kaito.90" target="_blank"><i class="fa fa-facebook-square"></i></a>
          
          
          
          <a href="https://github.com/Kaitoy" target="_blank"><i class="fa fa-github-square"></i></a>
          
        </div>
        <div id="profile-description"></div>
        <ul id="profile-urls" class="post-tags"></ul>
      </div>
    </div>
    
  </section>
</div>

<div class="col-md-12 col-sm-6 col-xs-12">
  <section>
    <h3>Tags</h3>
    
    <div id="tag-cloud" class="text-center">
      
      
      
      <a href="https://www.kaitoy.xyz/tags/atom">atom</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/aws">aws</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/aws-ecs">aws-ecs</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/blog">blog</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/bow">bow</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/cdn">cdn</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/ci">ci</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/cnn">cnn</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/coursera">coursera</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/deep-learning">deep-learning</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/disturb-me">disturb-me</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/docker">docker</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/elasticsearch">elasticsearch</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/filebeat">filebeat</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/firedrop">firedrop</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/git">git</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/github">github</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/goslings">goslings</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/groovy">groovy</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/headless-browser">headless-browser</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/hibernate">hibernate</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/hugo">hugo</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/impress.js">impress.js</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/japanese-word-selection">japanese-word-selection</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/javascript">javascript</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/jekyll">jekyll</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/jgit">jgit</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/jvm-language">jvm-language</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/keras">keras</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/kotlin">kotlin</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/kubeadm">kubeadm</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/kubernetes">kubernetes</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/license">license</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/logstash">logstash</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/machine-learning">machine-learning</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/management">management</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/minikube">minikube</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/nanoserver">nanoserver</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/neural-network">neural-network</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/nlp">nlp</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/oop">oop</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/orm">orm</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/pcap4j">pcap4j</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/react">react</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/rnn">rnn</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/runc">runc</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/selenium">selenium</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/seo">seo</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/servicenow">servicenow</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/skaffold">skaffold</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/spring">spring</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/spring-boot">spring-boot</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/subversion">subversion</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/tensorflow">tensorflow</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/test-framework">test-framework</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/vcs">vcs</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/webdriverio">webdriverio</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/windows">windows</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/yegor256">yegor256</a>
      
      
      <a href="https://www.kaitoy.xyz/tags/zundoko">zundoko</a>
      
    </div>
    
  </section>
</div>





<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
    style="display:block"
    data-ad-client="ca-pub-6244473643910448"
    data-ad-slot="1845600530"
    data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>

<div class="col-md-12 col-sm-6 col-xs-12">
  <div class="text-center custom-partial">
    
  </div>
</div>

      </div>
    </aside>
  </div>
</div>

        <div class="text-center custom-partial">
          
        </div>
      </div>
    </main>

    <footer id="site-footer" class="text-center font-logo">
      <p>&copy;  2015 -  2018  Kaito Yamada </p>
      <p>Powered by <a href="http://gohugo.io" target="_blank">Hugo</a></p>
      <p>
        Theme: <a target="_blank" href="https://github.com/dim0627/hugo_theme_robust">Robust</a>
        designed by <a target="_blank" href="http://yet.unresolved.xyz">Daisuke Tsuji</a>
      </p>
    </footer>

    <script src="//code.jquery.com/jquery-2.1.3.min.js"></script>
    <script src="https://www.kaitoy.xyz/js/jquery.bxslider.min.js"></script>
    
    <script>
      $(document).ready(function(){
        $('.bxslider').bxSlider({
          speed: 1,
          preloadImages: 'all'
        });
      });
    </script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/highlight.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/languages/dos.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/languages/yaml.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/languages/dockerfile.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-65248565-1', 'auto');
    ga('send', 'pageview');

    </script>

    <script>
    $(function() {
      var url = "https://ja.gravatar.com/5fbe47b2a4b3637dd26dfc9a49381895.json?callback=?";
      $.getJSON(url)
        .done(function(data) {
          var entry = data.entry[0];
          $("#profile-photo").attr("src", entry.photos[0].value);
          $("#profile-username").html(entry.name.familyName + " " + entry.name.givenName);
          $("#profile-description").html(entry.aboutMe);
          entry.urls.forEach(function(el){
            $("#profile-urls").append($("<li><a href='" + el.value + "'>" + el.title + "</a></li>"));
          });
          $("#profile").show();
        });
    });
    </script>
  </body>
</html>

