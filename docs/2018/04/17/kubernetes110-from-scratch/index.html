<!DOCTYPE html>
<html lang="en-us">
    <head>
        <script data-ad-client="ca-pub-6244473643910448" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<meta name="google-site-verification" content="9qs7VjxtSrYMqw5OElxCdKv_gnssSRi6acB2iYlZnGA" />
<meta property="og:url" content="https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/">
<meta property="og:site_name" content="To Be Decided">
<meta name="twitter:card" content="summary"></meta>
<link rel="canonical" href="https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/">



  <meta property="og:type" content="article">
  <meta property="og:title" content="Kubernetes 1.10をスクラッチから全手動で構築 | To Be Decided">
  <title>Kubernetes 1.10をスクラッチから全手動で構築 | To Be Decided</title>
  <meta property="og:description" content="Oracle Linux 7.4.0のVMでKubernetes 1.10.0のクラスタをスクラッチから全手動で作った。">
  <meta name="description" content="Oracle Linux 7.4.0のVMでKubernetes 1.10.0のクラスタをスクラッチから全手動で作った。">
  <meta property="og:image" content="https://www.kaitoy.xyz/images/kubernetes.png">



        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        
        <style>

    html body {
        font-family: 'Noto Sans JP', sans-serif;
        background-color: #fefefe;
    }

    :root {
        --accent: #fa1e44;
        --border-width:  5px ;
    }

</style>


<link rel="stylesheet" href="https://www.kaitoy.xyz/css/main.css">






<script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js"></script>
<script>
  var webFontConfig = {
    google: {
      families: ['Noto Sans JP:400,700:japanese'],
      active: function() {
        sessionStorage.fonts = true;
      }
    },
    timeout: 3000
  };
  WebFont.load(webFontConfig);
</script>


 <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/monokai.min.css"> 


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
 


    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js"></script>

    

    <script>hljs.initHighlightingOnLoad();</script>







<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>


<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>








<script>$(document).on('click', function() { $('.collapse').collapse('hide'); })</script>
 <meta name="generator" content="Hugo 0.55.1" />
        
        
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-65248565-1"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments)};
          gtag('js', new Date());

          gtag('config', 'UA-65248565-1');
        </script>
        
    </head>

    

    <body>
         
<div id="fb-root"></div>
<script async defer crossorigin="anonymous" src="https://connect.facebook.net/ja_JP/sdk.js#xfbml=1&version=v9.0" nonce="WjvU2Pqv"></script>

        <nav class="navbar navbar-default navbar-fixed-top">

            <div class="container">

                <div class="navbar-header">

                    <a class="navbar-brand visible-xs" href="#">Kubernetes 1.10をスクラッチから全手動で構築</a>

                    <button class="navbar-toggle" data-target=".navbar-collapse" data-toggle="collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>

                </div>

                <div class="collapse navbar-collapse">

                    
                        <ul class="nav navbar-nav">
                            
                                <li><a href="/">Home</a></li>
                            
                                <li><a href="/post/">Posts</a></li>
                            
                                <li><a href="/tags/">Tags</a></li>
                            
                                <li><a href="/about/">About</a></li>
                            
                        </ul>
                    

                    
                        <ul class="nav navbar-nav navbar-right">
                            
                                <li class="navbar-icon"><a href="mailto:kaitoy@pcap4j.org"><i class="fa fa-envelope-o"></i></a></li>
                            
                                <li class="navbar-icon"><a href="https://github.com/kaitoy"><i class="fa fa-github"></i></a></li>
                            
                                <li class="navbar-icon"><a href="https://www.linkedin.com/in/kaito-yamada-8558b913a"><i class="fa fa-linkedin"></i></a></li>
                            
                                <li class="navbar-icon"><a href="https://www.facebook.com/yamada.kaito.90"><i class="fa fa-facebook-square"></i></a></li>
                            
                        </ul>
                    

                </div>

            </div>

        </nav>


<main>

    <div class="single-post">
        <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2018/04/17/kubernetes110-from-scratch/">Kubernetes 1.10をスクラッチから全手動で構築</a></h4>
    <h5>Tue, Apr 17, 2018</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    

</div>


        <div class="cover">
            <a href="/2018/04/17/kubernetes110-from-scratch/">
                <img src="https://www.kaitoy.xyz/images/kubernetes.png" alt="Kubernetes 1.10をスクラッチから全手動で構築">
            </a>
        </div>

        
        <h4 class="page-header">Table of Contents</h4>
        <aside>
            <nav id="TableOfContents">
<ul>
<li><a href="#構成">構成</a></li>
<li><a href="#クラスタ構築手順">クラスタ構築手順</a>
<ul>
<li><a href="#1-bridge-netfilterとip-forwardingを設定">1. Bridge netfilterとIP forwardingを設定</a></li>
<li><a href="#2-x509証明書生成">2. x509証明書生成</a></li>
<li><a href="#3-kubernetesバイナリインストール">3. Kubernetesバイナリインストール</a></li>
<li><a href="#4-kubeconfigファイル生成">4. kubeconfigファイル生成</a></li>
<li><a href="#5-etcdデプロイ">5. etcdデプロイ</a></li>
<li><a href="#6-マスタコンポーネントデプロイ">6. マスタコンポーネントデプロイ。</a></li>
<li><a href="#7-tls-bootstrappingの設定">7. TLS Bootstrappingの設定</a></li>
<li><a href="#8-docker-cni-kubeletインストール">8. Docker、CNI、kubeletインストール</a></li>
<li><a href="#9-kube-proxy-オーバレイネットワーク-dnsのデプロイ">9. kube-proxy、オーバレイネットワーク、DNSのデプロイ</a></li>
<li><a href="#10-kubernetesアプリデプロイ">10. Kubernetesアプリデプロイ</a></li>
</ul></li>
</ul>
</nav>
        </aside>
        <hr>
        

        <br> <div class="text-justify"><p>Oracle Linux 7.4.0のVMでKubernetes 1.10.0のクラスタをスクラッチから全手動で作った。</p>

<p>参考にしたのは主に以下。</p>

<ul>
<li><a href="https://nixaid.com/deploying-kubernetes-cluster-from-scratch/">https://nixaid.com/deploying-kubernetes-cluster-from-scratch/</a></li>
<li><a href="https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.10.md">https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.10.md</a></li>
<li><a href="https://kubernetes.io/docs/getting-started-guides/scratch/">https://kubernetes.io/docs/getting-started-guides/scratch/</a></li>
<li><a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/implementation-details/">https://kubernetes.io/docs/reference/setup-tools/kubeadm/implementation-details/</a></li>
<li><a href="https://ulam.io/blog/kubernetes-scratch/">https://ulam.io/blog/kubernetes-scratch/</a></li>
<li><a href="https://docs.microsoft.com/en-us/virtualization/windowscontainers/kubernetes/creating-a-linux-master">https://docs.microsoft.com/en-us/virtualization/windowscontainers/kubernetes/creating-a-linux-master</a></li>
</ul>

<p>(2019/1/17追記: クラスタ全手動構築手順はKubernetes 1.13になってもほとんど変わっていない。ユニットファイルに指定するオプションが多少減ったりしたくらい。
また、ホストがRHELでもほとんど変わらない。インストールするDockerがDocker-CE(もしくはRedhatのやつ)に変わるくらいで、あとはkubeletの<code>--cgroup-driver</code>を<code>systemd</code>にしないといけなかったかも。)</p>

<p>(2020/3/2更新。)</p>

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-6244473643910448"
     data-ad-slot="1845600530"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h1 id="構成">構成</h1>

<ul>
<li>マシン: Windows 10 Homeのラップトップの上のVMware PlayerのVM

<ul>
<li>CPU: 2コア</li>
<li>メモリ: 4GB</li>
<li>NIF: NATのを一つ</li>
</ul></li>
<li>OS: Oracle Linux 7.4.0

<ul>
<li>Minimalインストール</li>
<li>IPアドレス: 192.168.171.200、静的割り当て</li>
<li>ホスト名: k8s-master (hostsで解決)</li>
</ul></li>
<li>Docker: Oracle Container Runtime for Docker (docker-engine) 17.06.2</li>
<li>Kubernetes: バージョン1.10.0

<ul>
<li>単一ノード</li>
<li>全コンポーネント(kubelet、kube-proxy、kube-apiserver、kube-controller-manager、kube-scheduler、etcd)をsystemdで起動 (i.e. 非コンテナ)

<ul>
<li>kubeletとkube-proxy以外は非rootユーザ</li>
<li>kubeletは<a href="https://github.com/kubernetes/kubernetes/blob/v1.10.2/cmd/kubelet/app/server.go#L388">現時点でrootで動かす必要がある</a></li>
<li>kube-proxyはiptableいじったりする都合上rootで動かす必要があるっぽい。</li>
</ul></li>
<li>コンポーネント間通信とkubectlの通信をTLSで暗号化

<ul>
<li>TLS 1.2</li>
<li>セキュアなCipher Suites</li>
</ul></li>
<li>コンポーネント間通信とkubectlの通信の認証は<a href="https://kubernetes.io/docs/admin/authentication/#x509-client-certs">x509クライアント証明書</a></li>
<li>TLS Bootstrapping

<ul>
<li>Bootstrap token使用</li>
<li>CSR自動承認</li>
</ul></li>
<li><a href="https://kubernetes.io/docs/tasks/tls/certificate-rotation/">Certificate Rotation</a>有効</li>
<li>etcd 3.1.12</li>
<li><a href="https://github.com/coreos/flannel">flannel</a> 0.10.0</li>
<li><a href="https://github.com/coredns/coredns">CoreDNS</a> 1.1.1</li>
<li>SERVICE_CLUSTER_IP_RANGE (Serviceに割り当てるIPの範囲) は10.0.0.0/16

<ul>
<li>kube-apiserverのIPはこの範囲の最初のIP(i.e. 10.0.0.1)になる。</li>
<li>ホストネットワークや、CLUSTER_CIDRと範囲が被らないようにする必要がある。</li>
</ul></li>
<li>CLUSTER_CIDR (Podに割り当てるIPの範囲) は10.244.0.0/16

<ul>
<li>flannelの要件に合わせている。</li>
<li>ホストネットワークや、SERVICE_CLUSTER_IP_RANGEと範囲が被らないようにする必要がある。</li>
</ul></li>
<li><a href="https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies">Proxyモード</a>はiptables。

<ul>
<li>ipvsのほうが速いけど、flannelとかがサポートしているかよくわからないので。</li>
</ul></li>
</ul></li>
</ul>

<p><br></p>

<p>kubeletの動作条件にあるので、swapをoffにする。
Oracle Linuxにログインして、<code>/etc/fstab</code>のswapの行を削除して、以下のコマンドを実行。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># swapoff -a
# cd /tmp</code></pre></div>
<p><br></p>

<p>SELinuxはちゃんと設定すればKubernetes動かせるはずだけど、面倒なのでとりあえず無効にする。</p>

<p><code>/etc/selinux/config</code>を編集して、<code>SELINUX</code>を<code>permissive</code>にして、以下のコマンドを実行。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># setenforce 0</code></pre></div>
<p><br></p>

<p>ファイアウォールもちゃんと設定すればいいんだけど面倒なのでとりあえず無効にする。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># systemctl stop firewalld
# systemctl disable firewalld</code></pre></div>
<p><br></p>

<p>これで準備完了。</p>

<h1 id="クラスタ構築手順">クラスタ構築手順</h1>

<p>おおむね、k8sコンポーネント間の通信の暗号化に使う鍵と証明書の生成、各コンポーネント用kubeconfigの生成、etcdのデプロイ、k8sコンポーネントのデプロイ、fannelデプロイ、CoreDNSデプロイ、という流れ。
ついでに最後に<a href="https://github.com/weaveworks/scope">Weave Scope</a>をデプロイしてみる。</p>

<h2 id="1-bridge-netfilterとip-forwardingを設定">1. Bridge netfilterとIP forwardingを設定</h2>

<p>まず、Bridge netfilterモジュールとoverlayモジュールをロードする。
(kube-proxyをipvsモードで動かすなら、さらにip_vs、ip_vs_rr、ip_vs_wrr、ip_vs_sh、nf_conntrack_ipv4が要る。)</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># modprobe br_netfilter
# echo &#34;br_netfilter&#34; &gt; /etc/modules-load.d/99-k8s.conf
# modprobe overlay
# echo &#34;overlay&#34; &gt;&gt; /etc/modules-load.d/99-k8s.conf</code></pre></div>
<p>Bridge netfilterとIP forwardingを有効化する。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># cat &gt; /etc/sysctl.d/kubernetes.conf &lt;&lt; EOF
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward = 1
EOF
# sysctl -p /etc/sysctl.d/kubernetes.conf</code></pre></div>
<p><br></p>

<p>設定確認。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># lsmod |grep br_netfilter
# sysctl -a | grep -E &#34;net.bridge.bridge-nf-call-|net.ipv4.ip_forward&#34;</code></pre></div>
<h2 id="2-x509証明書生成">2. x509証明書生成</h2>

<ol>
<li><p>opensslの設定作成</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># mkdir -p /etc/kubernetes/pki
# HOSTNAME=k8s-master
# K8S_SERVICE_IP=10.0.0.1
# MASTER_IP=192.168.171.200
# cat &gt; /etc/kubernetes/pki/openssl.cnf &lt;&lt; EOF
[ req ]
distinguished_name = req_distinguished_name
[req_distinguished_name]
[ v3_ca ]
basicConstraints = critical, CA:TRUE
keyUsage = critical, digitalSignature, keyEncipherment, keyCertSign
[ v3_req_client ]
basicConstraints = CA:FALSE
keyUsage = critical, digitalSignature, keyEncipherment
extendedKeyUsage = clientAuth
[ v3_req_apiserver ]
basicConstraints = CA:FALSE
keyUsage = critical, digitalSignature, keyEncipherment
extendedKeyUsage = serverAuth
subjectAltName = @alt_names_cluster
[ v3_req_etcd ]
basicConstraints = CA:FALSE
keyUsage = critical, digitalSignature, keyEncipherment
extendedKeyUsage = serverAuth
subjectAltName = @alt_names_etcd
[ alt_names_cluster ]
DNS.1 = kubernetes
DNS.2 = kubernetes.default
DNS.3 = kubernetes.default.svc
DNS.4 = kubernetes.default.svc.cluster.local
DNS.5 = ${HOSTNAME}
IP.1 = ${MASTER_IP}
IP.2 = ${K8S_SERVICE_IP}
[ alt_names_etcd ]
DNS.1 = ${HOSTNAME}
IP.1 = ${MASTER_IP}
EOF</code></pre></div></li>

<li><p>Kubernetes CA証明書生成</p>

<p>以降で生成する証明書に署名するための証明書。
後述のTLS Bootstrappingでの証明書生成にも使う。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># groupadd -r kubernetes
# adduser -r -g kubernetes -M -s /sbin/nologin kubernetes
# CA_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/ca.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/ca.key
# chmod 0600 /etc/kubernetes/pki/ca.key
# openssl req -x509 -new -sha256 -nodes -key /etc/kubernetes/pki/ca.key -days $CA_DAYS -out /etc/kubernetes/pki/ca.crt -subj &#34;/CN=kubernetes-ca&#34;  -extensions v3_ca -config /etc/kubernetes/pki/openssl.cnf</code></pre></div></li>

<li><p>kube-apiserver証明書生成</p>

<p>kube-apiserverのサーバ証明書。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># APISERVER_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/kube-apiserver.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/kube-apiserver.key
# chmod 0600 /etc/kubernetes/pki/kube-apiserver.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/kube-apiserver.key -subj &#34;/CN=kube-apiserver&#34; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/kube-apiserver.crt -days $APISERVER_DAYS -extensions v3_req_apiserver -extfile /etc/kubernetes/pki/openssl.cnf</code></pre></div></li>

<li><p>kube-apiserver-kubelet証明書生成</p>

<p>kube-apiserverが<a href="https://kubernetes.io/docs/concepts/architecture/master-node-communication/#apiserver-kubelet">kubeletのAPIにアクセス</a>するときのクライアント証明書。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># APISERVER_KUBELET_CLIENT_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/apiserver-kubelet-client.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/apiserver-kubelet-client.key
# chmod 0600 /etc/kubernetes/pki/apiserver-kubelet-client.key
# openssl req -new -key /etc/kubernetes/pki/apiserver-kubelet-client.key -subj &#34;/CN=kube-apiserver-kubelet-client/O=system:masters&#34; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/apiserver-kubelet-client.crt -days $APISERVER_KUBELET_CLIENT_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf</code></pre></div></li>

<li><p>adminクライアント証明書生成</p>

<p>kubectlがkube-apiserverのAPIにアクセスするときのクライアント証明書。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># groupadd -r kube-admin
# adduser -r -g kube-admin -M -s /sbin/nologin kube-admin
# ADMIN_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/admin.key
# chown kube-admin:kube-admin /etc/kubernetes/pki/admin.key
# chmod 0600 /etc/kubernetes/pki/admin.key
# openssl req -new -key /etc/kubernetes/pki/admin.key -subj &#34;/CN=kubernetes-admin/O=system:masters&#34; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/admin.crt -days $ADMIN_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf</code></pre></div></li>

<li><p>kube-controller-managerのクライアント証明書生成</p>

<p>kube-controller-managerがkube-apiserverに接続するときのクライアント証明書。
この証明書に対応する秘密鍵と公開鍵はそれぞれ、kube-controller-managerがService Accountトークンに署名するとき、kube-apiserverがトークンの署名を確認するときにも使う。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># CONTROLLER_MANAGER_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/kube-controller-manager.key
# openssl ec -in /etc/kubernetes/pki/kube-controller-manager.key -outform PEM -pubout -out /etc/kubernetes/pki/kube-controller-manager.pub
# chown kubernetes:kubernetes /etc/kubernetes/pki/kube-controller-manager.key
# chmod 0600 /etc/kubernetes/pki/kube-controller-manager.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/kube-controller-manager.key -subj &#34;/CN=system:kube-controller-manager&#34; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/kube-controller-manager.crt -days $CONTROLLER_MANAGER_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf</code></pre></div></li>

<li><p>kube-schedulerクライアント証明書生成</p>

<p>kube-schedulerがkube-apiserverにリクエストするときに使うクライアント証明書。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># SCHEDULER_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/kube-scheduler.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/kube-scheduler.key
# chmod 0600 /etc/kubernetes/pki/kube-scheduler.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/kube-scheduler.key -subj &#34;/CN=system:kube-scheduler&#34; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/kube-scheduler.crt -days $SCHEDULER_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf</code></pre></div></li>

<li><p>kube-proxyクライアント証明書生成</p>

<p>kube-proxyがkube-apiserverにリクエストするときに使うクライアント証明書。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># PROXY_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/kube-proxy.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/kube-proxy.key
# chmod 0600 /etc/kubernetes/pki/kube-proxy.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/kube-proxy.key -subj &#34;/CN=system:kube-proxy/O=system:node-proxier&#34; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /etc/kubernetes/pki/kube-proxy.crt -days $PROXY_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf</code></pre></div></li>

<li><p>front proxy CA証明書生成</p>

<p>front proxyの証明書に署名するのにつかう証明書。
front proxyは<a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/api-machinery/aggregated-api-servers.md">API Aggregation</a>のためのもの。
API Aggregationは、kube-apiserverを変更することなく、別途作られた<a href="https://kubernetes.io/docs/tasks/access-kubernetes-api/setup-extension-api-server/">Extension API Server</a>でKubernetesのAPIを拡張できるようにする機能。
API Aggregationは現時点では<a href="https://kubernetes.io/docs/concepts/api-extension/apiserver-aggregation/#overview">kube-apiserverの一機能として実装されていて</a>、将来的には<a href="https://github.com/kubernetes/kube-aggregator">kubernetes-aggregator</a>という別のコンポーネントで実現される。</p>

<p>API AggregationしないならこのCA証明書と次のクライアント証明書はいらないはず。
今回はしないけど、とりあえず作って設定したおく。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># FRONT_PROXY_CA_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/front-proxy-ca.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/front-proxy-ca.key
# chmod 0600 /etc/kubernetes/pki/front-proxy-ca.key
# openssl req -x509 -new -sha256 -nodes -key /etc/kubernetes/pki/front-proxy-ca.key -days $FRONT_PROXY_CA_DAYS -out /etc/kubernetes/pki/front-proxy-ca.crt -subj &#34;/CN=front-proxy-ca&#34; -extensions v3_ca -config /etc/kubernetes/pki/openssl.cnf</code></pre></div></li>

<li><p>front proxyクライアント証明書</p>

<p>Extension API ServerのAPIへのリクエストは、いったんkube-apiserverが受け取ってExtension API Serverに転送される。(多分。)
この転送の暗号化と認証にTLSが使われていて、ここではそのクライアント証明書を生成する。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># FRONT_PROXY_CLIENT_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/front-proxy-client.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/front-proxy-client.key
# chmod 0600 /etc/kubernetes/pki/front-proxy-client.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/front-proxy-client.key -subj &#34;/CN=front-proxy-client&#34; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/front-proxy-ca.crt -CAkey /etc/kubernetes/pki/front-proxy-ca.key -CAcreateserial -out /etc/kubernetes/pki/front-proxy-client.crt -days $FRONT_PROXY_CLIENT_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf</code></pre></div></li>

<li><p>etcd CA証明書</p>

<p>以降で生成するetcdの証明書に署名するための証明書。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># groupadd -r etcd
# adduser -r -g etcd -M -s /sbin/nologin etcd
# ETCD_CA_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/etcd-ca.key
# chown etcd:etcd /etc/kubernetes/pki/etcd-ca.key
# chmod 0600 /etc/kubernetes/pki/etcd-ca.key
# openssl req -x509 -new -sha256 -nodes -key /etc/kubernetes/pki/etcd-ca.key -days $ETCD_CA_DAYS -out /etc/kubernetes/pki/etcd-ca.crt -subj &#34;/CN=etcd-ca&#34; -extensions v3_ca -config /etc/kubernetes/pki/openssl.cnf</code></pre></div></li>

<li><p>etcd証明書</p>

<p>etcdのサーバ証明書。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># ETCD_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/etcd.key
# chown etcd:etcd /etc/kubernetes/pki/etcd.key
# chmod 0600 /etc/kubernetes/pki/etcd.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/etcd.key -subj &#34;/CN=etcd&#34; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/etcd-ca.crt -CAkey /etc/kubernetes/pki/etcd-ca.key -CAcreateserial -out /etc/kubernetes/pki/etcd.crt -days $ETCD_DAYS -extensions v3_req_etcd -extfile /etc/kubernetes/pki/openssl.cnf</code></pre></div></li>

<li><p>etcdクライアント証明書</p>

<p>etcdのクライアント証明書。
kube-apiserverだけがetcdと話すので、kube-apiserverだけが使う。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># ETCD_CLIENT_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/etcd-client.key
# chown kubernetes:kubernetes /etc/kubernetes/pki/etcd-client.key
# chmod 0600 /etc/kubernetes/pki/etcd-client.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/etcd-client.key -subj &#34;/CN=kube-apiserver&#34; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/etcd-ca.crt -CAkey /etc/kubernetes/pki/etcd-ca.key -CAcreateserial -out /etc/kubernetes/pki/etcd-client.crt -days $ETCD_CLIENT_DAYS -extensions v3_req_client -extfile /etc/kubernetes/pki/openssl.cnf</code></pre></div></li>

<li><p>etcd peer証明書</p>

<p>etcdサーバが冗長構成のとき、サーバ間の通信の暗号化に使う証明書。
マスタが一つなら要らないはずだけど、今回とりあえず作って設定しておく。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># ETCD_PEER_DAYS=5475
# openssl ecparam -name secp521r1 -genkey -noout -out /etc/kubernetes/pki/etcd-peer.key
# chown etcd:etcd /etc/kubernetes/pki/etcd-peer.key
# chmod 0600 /etc/kubernetes/pki/etcd-peer.key
# openssl req -new -sha256 -key /etc/kubernetes/pki/etcd-peer.key -subj &#34;/CN=etcd-peer&#34; | openssl x509 -req -sha256 -CA /etc/kubernetes/pki/etcd-ca.crt -CAkey /etc/kubernetes/pki/etcd-ca.key -CAcreateserial -out /etc/kubernetes/pki/etcd-peer.crt -days $ETCD_PEER_DAYS -extensions v3_req_etcd -extfile /etc/kubernetes/pki/openssl.cnf</code></pre></div></li>

<li><p>確認</p>

<p>以上で生成した証明書の内容を確認する。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># for i in /etc/kubernetes/pki/*crt; do
  echo $i:;
  openssl x509 -subject -issuer -noout -in $i;
  echo;
done</code></pre></div></li>
</ol>

<h2 id="3-kubernetesバイナリインストール">3. Kubernetesバイナリインストール</h2>

<p><a href="https://kubernetes.io/docs/getting-started-guides/scratch/#selecting-images">公式ドキュメント</a>によると、Docker、kubelet、kube-proxyはコンテナ外で動かして、etcd、kube-apiserver、kube-controller-manager、kube-schedulerはコンテナで動かすのが推奨されている。
けど、とりあえずは簡単に全部コンテナ外でやる。</p>

<p>(Oracle Linux用には、各コンポのコンテナイメージ詰め合わせがOracle Container Services for use with Kubernetesという名前で配布されているけど、現時点で1.9までしかないので使わない。)</p>

<p>バイナリは以下URLからダウンロードできる。</p>

<ul>
<li>全部入り: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/kubernetes-server-linux-amd64.tar.gz">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/kubernetes-server-linux-amd64.tar.gz</a></li>
<li>kube-apiserver

<ul>
<li>バイナリ: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-apiserver">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-apiserver</a></li>
<li>コンテナ: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-apiserver.tar">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-apiserver.tar</a></li>
</ul></li>
<li>kube-controller-manager

<ul>
<li>バイナリ: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-controller-manager">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-controller-manager</a></li>
<li>コンテナ: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-controller-manager.tar">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-controller-manager.tar</a></li>
</ul></li>
<li>kube-scheduler

<ul>
<li>バイナリ: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-scheduler">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-scheduler</a></li>
<li>コンテナ: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-scheduler.tar">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-scheduler.tar</a></li>
</ul></li>
<li>kube-proxy

<ul>
<li>バイナリ: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-proxy">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-proxy</a></li>
<li>コンテナ: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-proxy.tar">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kube-proxy.tar</a></li>
</ul></li>
<li>kubelet: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubelet">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubelet</a></li>
<li>kubectl: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubectl">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubectl</a></li>
<li>kubeadm: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubeadm">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubeadm</a></li>
<li>hyperkube: <a href="https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/hyperkube">https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/hyperkube</a></li>
</ul>

<p>最後のhyperkubeは、各種Kubernetesバイナリのごった煮。
ファイル名によって動作が変わる。
簡単のためこれを使うけど、個別のバイナリ使ったほうがメモリ使用量などで有利そう。</p>

<p>hyperkubeとkubeadmのバイナリを<code>/usr/bin/</code>において、以下のコマンドを実行。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># ln -s /usr/bin/hyperkube /usr/bin/kube-apiserver
# ln -s /usr/bin/hyperkube /usr/bin/kube-controller-manager
# ln -s /usr/bin/hyperkube /usr/bin/kube-scheduler
# ln -s /usr/bin/hyperkube /usr/bin/kube-proxy
# ln -s /usr/bin/hyperkube /usr/bin/kubelet
# ln -s /usr/bin/hyperkube /usr/bin/kubectl
# chmod +x /usr/bin/kube*
# mkdir -p /var/lib/{kubelet,kube-proxy}</code></pre></div>
<h2 id="4-kubeconfigファイル生成">4. kubeconfigファイル生成</h2>

<p>kubectlとマスタコンポーネントがkube-apiserverと話すときに使うkubeconfigファイルを生成する。</p>

<ol>
<li><p>kube-controller-managerのkubeconfig</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># MASTER_IP=192.168.171.200
# KUBERNETES_PUBLIC_ADDRESS=$MASTER_IP
# CLUSTER_NAME=&#34;k8s&#34;
# KCONFIG=/etc/kubernetes/kube-controller-manager.kubeconfig
# KUSER=&#34;system:kube-controller-manager&#34;
# kubectl config set-cluster ${CLUSTER_NAME} --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 --kubeconfig=${KCONFIG}
# kubectl config set-credentials ${KUSER} --client-certificate=/etc/kubernetes/pki/kube-controller-manager.crt --client-key=/etc/kubernetes/pki/kube-controller-manager.key --embed-certs=true --kubeconfig=${KCONFIG}
# kubectl config set-context ${KUSER}@${CLUSTER_NAME} --cluster=${CLUSTER_NAME} --user=${KUSER} --kubeconfig=${KCONFIG}
# kubectl config use-context ${KUSER}@${CLUSTER_NAME} --kubeconfig=${KCONFIG}
# chown kubernetes:kubernetes ${KCONFIG}
# chmod 0600 ${KCONFIG}</code></pre></div>
<p>設定確認。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># kubectl config view --kubeconfig=${KCONFIG}</code></pre></div></li>

<li><p>kube-schedulerのkubeconfig</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># MASTER_IP=192.168.171.200
# KUBERNETES_PUBLIC_ADDRESS=$MASTER_IP
# CLUSTER_NAME=&#34;k8s&#34;
# KCONFIG=/etc/kubernetes/kube-scheduler.kubeconfig
# KUSER=&#34;system:kube-scheduler&#34;
# kubectl config set-cluster ${CLUSTER_NAME} --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 --kubeconfig=${KCONFIG}
# kubectl config set-credentials ${KUSER} --client-certificate=/etc/kubernetes/pki/kube-scheduler.crt --client-key=/etc/kubernetes/pki/kube-scheduler.key --embed-certs=true --kubeconfig=${KCONFIG}
# kubectl config set-context ${KUSER}@${CLUSTER_NAME} --cluster=${CLUSTER_NAME} --user=${KUSER} --kubeconfig=${KCONFIG}
# kubectl config use-context ${KUSER}@${CLUSTER_NAME} --kubeconfig=${KCONFIG}
# chown kubernetes:kubernetes ${KCONFIG}
# chmod 0600 ${KCONFIG}</code></pre></div>
<p>設定確認。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># kubectl config view --kubeconfig=${KCONFIG}</code></pre></div></li>

<li><p>adminのkubeconfig</p>

<p>kubectl用。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># MASTER_IP=192.168.171.200
# KUBERNETES_PUBLIC_ADDRESS=$MASTER_IP
# CLUSTER_NAME=&#34;k8s&#34;
# KCONFIG=/etc/kubernetes/admin.kubeconfig
# KUSER=&#34;kubernetes-admin&#34;
# kubectl config set-cluster ${CLUSTER_NAME} --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 --kubeconfig=${KCONFIG}
# kubectl config set-credentials ${KUSER} --client-certificate=/etc/kubernetes/pki/admin.crt --client-key=/etc/kubernetes/pki/admin.key --embed-certs=true --kubeconfig=${KCONFIG}
# kubectl config set-context ${KUSER}@${CLUSTER_NAME} --cluster=${CLUSTER_NAME} --user=${KUSER} --kubeconfig=${KCONFIG}
# kubectl config use-context ${KUSER}@${CLUSTER_NAME} --kubeconfig=${KCONFIG}
# chown kube-admin:kube-admin ${KCONFIG}
# chmod 0600 ${KCONFIG}
# ln -s ${KCONFIG} ~/.kube/config</code></pre></div>
<p>設定確認。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># kubectl config view --kubeconfig=${KCONFIG}</code></pre></div></li>
</ol>

<h2 id="5-etcdデプロイ">5. etcdデプロイ</h2>

<p><a href="https://github.com/coreos/etcd/releases/download/v3.1.12/etcd-v3.1.12-linux-amd64.tar.gz">https://github.com/coreos/etcd/releases/download/v3.1.12/etcd-v3.1.12-linux-amd64.tar.gz</a>
からアーカイブをダウンロードして、中のetcdとetcdctlを<code>/usr/bin/</code>にいれて、以下のコマンドを実行。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># chown root:root /usr/bin/etcd*
# chmod 0755 /usr/bin/etcd*
# mkdir -p /var/lib/etcd
# chown etcd:etcd /var/lib/etcd</code></pre></div>
<p>で、systemdのユニットファイルを書いてサービス化。</p>

<p>(参考: <a href="https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/">Kubernetesドキュメント</a>、<a href="https://github.com/coreos/etcd/blob/master/Documentation/op-guide/security.md">etcdドキュメント</a>)</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># MASTER_IP=192.168.171.200
# ETCD_MEMBER_NAME=etcd1
# CLUSTER_NAME=&#34;k8s&#34;
# ETCD_TOKEN=$(openssl rand -hex 5)
# ETCD_CLUSTER_TOKEN=$CLUSTER_NAME-$ETCD_TOKEN
# cat &gt; /etc/systemd/system/etcd.service &lt;&lt; EOF
[Unit]
Description=etcd
Documentation=https://coreos.com/etcd/docs/latest/
After=network.target

[Service]
Type=notify
NotifyAccess=all
User=etcd
Group=etcd
ExecStart=/usr/bin/etcd \\
  --name ${ETCD_MEMBER_NAME} \\
  --listen-client-urls https://${MASTER_IP}:2379 \\
  --advertise-client-urls https://${MASTER_IP}:2379 \\
  --data-dir=/var/lib/etcd \\
  --cert-file=/etc/kubernetes/pki/etcd.crt \\
  --key-file=/etc/kubernetes/pki/etcd.key \\
  --peer-cert-file=/etc/kubernetes/pki/etcd-peer.crt \\
  --peer-key-file=/etc/kubernetes/pki/etcd-peer.key \\
  --trusted-ca-file=/etc/kubernetes/pki/etcd-ca.crt \\
  --peer-trusted-ca-file=/etc/kubernetes/pki/etcd-ca.crt \\
  --peer-client-cert-auth \\
  --client-cert-auth \\
  --initial-advertise-peer-urls https://${MASTER_IP}:2380 \\
  --listen-peer-urls https://${MASTER_IP}:2380 \\
  --initial-cluster-token ${ETCD_CLUSTER_TOKEN} \\
  --initial-cluster ${ETCD_MEMBER_NAME}=https://${MASTER_IP}:2380 \\
  --initial-cluster-state new
Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable etcd
# systemctl start etcd</code></pre></div>
<p>確認。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># systemctl status etcd -l
# MASTER_IP=192.168.171.200
# etcdctl --endpoints https://${MASTER_IP}:2379 --ca-file=/etc/kubernetes/pki/etcd-ca.crt --cert-file=/etc/kubernetes/pki/etcd-client.crt --key-file=/etc/kubernetes/pki/etcd-client.key cluster-health
# etcdctl --endpoints https://${MASTER_IP}:2379 --ca-file=/etc/kubernetes/pki/etcd-ca.crt --cert-file=/etc/kubernetes/pki/etcd-client.crt --key-file=/etc/kubernetes/pki/etcd-client.key member list</code></pre></div>
<h2 id="6-マスタコンポーネントデプロイ">6. マスタコンポーネントデプロイ。</h2>

<ol>
<li><p>kube-apiserver</p>

<p>systemdのユニットファイルを書いてサービス化。</p>

<ul>
<li>d</li>
</ul>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># mkdir -p /var/log/kubernetes
# chown kubernetes:kubernetes /var/log/kubernetes
# chmod 0700 /var/log/kubernetes
# MASTER_IP=192.168.171.200
# SERVICE_CLUSTER_IP_RANGE=&#34;10.0.0.0/16&#34;
# SECRET_ENC_KEY=$(echo -n &#39;your_32_bytes_secure_private_key&#39; | base64)
# cat &gt; /etc/kubernetes/encryption.conf &lt;&lt; EOF
kind: EncryptionConfig
apiVersion: v1
resources:
  - resources:
    - secrets
    providers:
    - aescbc:
        keys:
        - name: key1
          secret: ${SECRET_ENC_KEY}
    - identity: {}
EOF
# cat &gt; /etc/kubernetes/audit-policy.conf &lt;&lt; EOF
apiVersion: audit.k8s.io/v1beta1
kind: Policy
# Don&#39;t generate audit events for all requests in RequestReceived stage.
omitStages:
  - &#34;RequestReceived&#34;
rules:
  # Log pod changes at RequestResponse level
  - level: RequestResponse
    resources:
    - group: &#34;&#34;
      # Resource &#34;pods&#34; doesn&#39;t match requests to any subresource of pods,
      # which is consistent with the RBAC policy.
      resources: [&#34;pods&#34;]
  # Log &#34;pods/log&#34;, &#34;pods/status&#34; at Metadata level
  - level: Metadata
    resources:
    - group: &#34;&#34;
      resources: [&#34;pods/log&#34;, &#34;pods/status&#34;]

  # Don&#39;t log requests to a configmap called &#34;controller-leader&#34;
  - level: None
    resources:
    - group: &#34;&#34;
      resources: [&#34;configmaps&#34;]
      resourceNames: [&#34;controller-leader&#34;]

  # Don&#39;t log watch requests by the &#34;system:kube-proxy&#34; on endpoints or services
  - level: None
    users: [&#34;system:kube-proxy&#34;]
    verbs: [&#34;watch&#34;]
    resources:
    - group: &#34;&#34; # core API group
      resources: [&#34;endpoints&#34;, &#34;services&#34;]

  # Don&#39;t log authenticated requests to certain non-resource URL paths.
  - level: None
    userGroups: [&#34;system:authenticated&#34;]
    nonResourceURLs:
    - &#34;/api*&#34; # Wildcard matching.
    - &#34;/version&#34;

  # Log the request body of configmap changes in kube-system.
  - level: Request
    resources:
    - group: &#34;&#34; # core API group
      resources: [&#34;configmaps&#34;]
    # This rule only applies to resources in the &#34;kube-system&#34; namespace.
    # The empty string &#34;&#34; can be used to select non-namespaced resources.
    namespaces: [&#34;kube-system&#34;]

  # Log configmap and secret changes in all other namespaces at the Metadata level.
  - level: Metadata
    resources:
    - group: &#34;&#34; # core API group
      resources: [&#34;secrets&#34;, &#34;configmaps&#34;]

  # Log all other resources in core and extensions at the Request level.
  - level: Request
    resources:
    - group: &#34;&#34; # core API group
    - group: &#34;extensions&#34; # Version of group should NOT be included.

  # A catch-all rule to log all other requests at the Metadata level.
  - level: Metadata
    # Long-running requests like watches that fall under this rule will not
    # generate an audit event in RequestReceived.
    omitStages:
      - &#34;RequestReceived&#34;
EOF
# cat &gt; /etc/systemd/system/kube-apiserver.service &lt;&lt; EOF
[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/kubernetes/kubernetes
After=network.target

[Service]
User=kubernetes
Group=kubernetes
ExecStart=/usr/bin/kube-apiserver \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --apiserver-count=1 \\
  --allow-privileged=true \\
  --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,NodeRestriction,DenyEscalatingExec,StorageObjectInUseProtection \\
  --authorization-mode=Node,RBAC \\
  --bind-address=0.0.0.0 \\
  --advertise-address=${MASTER_IP} \\
  --client-ca-file=/etc/kubernetes/pki/ca.crt \\
  --etcd-cafile=/etc/kubernetes/pki/etcd-ca.crt \\
  --etcd-certfile=/etc/kubernetes/pki/etcd-client.crt \\
  --etcd-keyfile=/etc/kubernetes/pki/etcd-client.key \\
  --etcd-servers=https://${MASTER_IP}:2379 \\
  --service-account-key-file=/etc/kubernetes/pki/kube-controller-manager.pub \\
  --service-cluster-ip-range=${SERVICE_CLUSTER_IP_RANGE} \\
  --tls-cert-file=/etc/kubernetes/pki/kube-apiserver.crt \\
  --tls-private-key-file=/etc/kubernetes/pki/kube-apiserver.key \\
  --kubelet-certificate-authority=/etc/kubernetes/pki/ca.crt \\
  --enable-bootstrap-token-auth=true \\
  --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt \\
  --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key \\
  --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname \\
  --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt \\
  --requestheader-username-headers=X-Remote-User \\
  --requestheader-group-headers=X-Remote-Group \\
  --requestheader-allowed-names=front-proxy-client \\
  --requestheader-extra-headers-prefix=X-Remote-Extra- \\
  --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt \\
  --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key \\
  --experimental-encryption-provider-config=/etc/kubernetes/encryption.conf \\
  --v=2 \\
  --tls-min-version=VersionTLS12 \\
  --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 \\
  --anonymous-auth=false \\
  --audit-log-format=json \\
  --audit-log-maxage=30 \\
  --audit-log-maxbackup=3 \\
  --audit-log-maxsize=100 \\
  --audit-log-path=/var/log/kubernetes/kube-audit.log \\
  --audit-policy-file=/etc/kubernetes/audit-policy.conf
Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable kube-apiserver
# systemctl start kube-apiserver</code></pre></div>
<p>(k8s 1.13から<code>EncryptionConfig</code>が<code>EncryptionConfiguration</code>に変わり、そのapiVersionも<code>v1</code>から<code>apiserver.config.k8s.io/v1</code>に変わった。)</p>

<p>(audit-policy.confに書くapiVersionもk8s 1.13から<code>audit.k8s.io/v1</code>になった。)</p>

<p><code>--allow-privileged</code>はflannelなどに必要。</p>

<p><code>--enable-admission-plugins</code>には<a href="https://kubernetes.io/docs/admin/admission-controllers/#is-there-a-recommended-set-of-admission-controllers-to-use">公式推奨のプラグイン</a>に加えて、後述のTLS BootstrappingのためのNodeRestrictionを指定。
また、<code>--allow-privileged</code>の効果を軽減するため、DenyEscalatingExecも追加で指定。
また、使われているPersistent VolumeやPersistent Volume Claimが誤って消されることを防ぐ<a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/#storage-object-in-use-protection">StorageObjectInUseProtection</a>も追加で指定。
因みに、プラグインを指定する順番はKubernetes 1.10からは気にしなくてよくなった。</p>

<p><code>--authorization-mode</code>にはRBACを指定するのが標準。
後述のTLS Bootstrappingをするなら、Nodeも要る。</p>

<p><code>--experimental-encryption-provider-config</code>は<a href="https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/">Secretを暗号化する</a>ための設定。(k8s 1.13でexperimentalじゃなくなった。)
暗号化のキーをローテーションすることもできるけど、それはやってない。</p>

<p><code>--tls-min-version</code>と<code>--tls-cipher-suites</code>は<a href="https://www.lambdanote.com/blogs/news/openssl-cookbook">OpenSSLクックブック</a>と<a href="https://golang.org/pkg/crypto/tls/#pkg-constants">Goのtlsパッケージドキュメント</a>を参考に設定。
RSA鍵交換はNG、RC4と3DESもNG、AESの鍵長は128ビット以上、SHA1はNG。</p>

<p>また、(&ndash;tls-min-versionをVersionTLS12にする場合?)TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256が必須で、CBCモードがNG。(参照: <a href="https://github.com/golang/go/blob/release-branch.go1.9/src/net/http/h2_bundle.go">https://github.com/golang/go/blob/release-branch.go1.9/src/net/http/h2_bundle.go</a>)</p>

<p><code>--anonymous-auth=false</code>はセキュリティのため設定。</p>

<p><code>--requestheader-*</code>と<code>--proxy-client-*</code>は上記API Aggregationのための設定。</p>

<p><code>--audit-*</code>は監査ログ設定。
100MB3面のログを30日間保持する。
ログポリシーは<a href="https://kubernetes.io/docs/tasks/debug-application-cluster/audit/">公式のサンプル</a>そのまま。
(ログポリシーのAPIバージョンはk8s 1.12で<code>audit.k8s.io/v1</code>になった。)</p>

<p><code>--feature-gates</code>でRotateKubeletServerCertificateを有効にして、kubeletのサーバ証明書を自動更新するようにしている。
因みに、クライアント証明書を自動更新するRotateKubeletClientCertificateはデフォルトで有効。
これらがCertificate Rotationと呼ばれる機能。
(セキュリティの問題から、<code>RotateKubeletServerCertificate</code>のサーバ証明書自動更新はk8s 1.11以降<a href="https://github.com/kubernetes/kubernetes/pull/62471">使えなくなった</a>。)</p>

<p><code>--feature-gates</code>は全Kubernetesコンポーネントで同じ値を指定するのがよさそう。</p>

<p>確認。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># systemctl status kube-apiserver -l
# journalctl -u kube-apiserver</code></pre></div></li>

<li><p>kube-controller-manager</p>

<p>systemdのユニットファイルを書いてサービス化。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># CLUSTER_CIDR=&#34;10.244.0.0/16&#34;
# SERVICE_CLUSTER_IP_RANGE=&#34;10.0.0.0/16&#34;
# CLUSTER_NAME=&#34;k8s&#34;
# cat &gt; /etc/systemd/system/kube-controller-manager.service &lt;&lt; EOF
[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/kubernetes/kubernetes
After=network.target

[Service]
User=kubernetes
Group=kubernetes
ExecStart=/usr/bin/kube-controller-manager \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig \\
  --bind-address=0.0.0.0 \\
  --controllers=*,bootstrapsigner,tokencleaner \\
  --service-account-private-key-file=/etc/kubernetes/pki/kube-controller-manager.key \\
  --allocate-node-cidrs=true \\
  --cluster-cidr=${CLUSTER_CIDR} \\
  --node-cidr-mask-size=24 \\
  --cluster-name=${CLUSTER_NAME} \\
  --service-cluster-ip-range=${SERVICE_CLUSTER_IP_RANGE} \\
  --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt \\
  --cluster-signing-key-file=/etc/kubernetes/pki/ca.key \\
  --root-ca-file=/etc/kubernetes/pki/ca.crt \\
  --use-service-account-credentials=true \\
  --v=2 \\
  --experimental-cluster-signing-duration=8760h0m0s
Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable kube-controller-manager
# systemctl start kube-controller-manager</code></pre></div>
<p>期限の切れたBootstrap token(後述)を消すためにtokencleanerを有効にしている。</p>

<p>bootstrapsignerは後述のcluster-infoにBootstrap tokenで署名するためのコントローラ。</p>

<p><a href="https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/#approval-controller">csrapproving</a>というコントローラがデフォルトで有効になっていて、後述のTLS BootstrapppingやCertificate Rotationの時に作られるCSRを自動で承認する。</p>

<p><code>--cluster-cidr</code>で指定するネットワークは、後述のネットワークプロバイダの設定と合っている必要がある。
<code>--allocate-node-cidrs</code>は<code>--cluster-cidr</code>の前提。</p>

<p><code>--node-cidr-mask-size</code>は、ノードに使うネットワークのサイズを指定するオプションで、<code>--cluster-cidr</code>で指定したネットワークの一部になるようにする。
<code>--cluster-cidr</code>で<code>/16</code>を指定した場合、半分の<code>/24</code>にするのが普通。
つまり256ノードまで作れて、それぞれ254個のPodをホストできるような構成。</p>

<p><code>--experimental-cluster-signing-duration</code>は、Certificate Rotationのための設定で、自動発行する証明書の期限を1年に指定している。</p>

<p><code>--use-service-account-credentials</code>をつけると、<a href="https://kubernetes.io/docs/admin/authorization/rbac/#controller-roles">各コントローラが別々のService Accountで動く</a>。</p>

<p><code>--secure-port</code>や<code>--tls-*</code>は、ヘルスチェックAPIをHTTPSにするだけで意味が無いし、設定すると<code>kubectl get componentstatuses</code>でエラーが出るようになるので、設定しないほうがいい。
(k8s 1.12からは設定できるようになった。)</p>

<p>確認。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># systemctl status kube-controller-manager -l</code></pre></div></li>

<li><p>kube-scheduler</p>

<p>systemdのユニットファイルを書いてサービス化。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># cat &gt; /etc/systemd/system/kube-scheduler.service &lt;&lt; EOF
[Unit]
Description=Kubernetes Scheduler
Documentation=https://github.com/kubernetes/kubernetes
After=network.target

[Service]
User=kubernetes
Group=kubernetes
ExecStart=/usr/bin/kube-scheduler \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --kubeconfig=/etc/kubernetes/kube-scheduler.kubeconfig \\
  --address=0.0.0.0 \\
  --v=2
Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable kube-scheduler
# systemctl start kube-scheduler</code></pre></div>
<p>確認。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># systemctl status kube-scheduler -l</code></pre></div></li>

<li><p>マスタコンポーネント状態確認</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># kubectl version
# kubectl get componentstatuses</code></pre></div></li>
</ol>

<h2 id="7-tls-bootstrappingの設定">7. TLS Bootstrappingの設定</h2>

<p><a href="https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/">TLS Bootstrapping</a>は、Kubernetesクラスタのコンポーネント間の通信がTLSで暗号化されている環境で、ノードが新たにクラスタに参加するとき、自動的にセキュアに<a href="https://ja.wikipedia.org/wiki/%E8%A8%BC%E6%98%8E%E6%9B%B8%E7%BD%B2%E5%90%8D%E8%A6%81%E6%B1%82">CSR</a>を処理する仕組み。</p>

<p>TLS Bootstrappingでは、kubeletは起動時にBootstrap kubeconfigを読んで、kubeletとノード用のCSRを生成し、それらがkube-controller-managerに承認されると、kubelet用のクライアント証明書と秘密鍵を生成する。
その証明書と鍵を使ってkubeconfigを生成し、以降のクラスタへの接続に使う。</p>

<p>Bootstrap時の認証には<a href="https://kubernetes.io/docs/admin/bootstrap-tokens/">Bootstrap Tokens</a>か<a href="https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/#token-authentication-file">Token authentication file</a>を使うことが推奨されていて、今回は前者を使う。</p>

<p>(後者については<a href="https://medium.com/@toddrosner/kubernetes-tls-bootstrapping-cf203776abc7">この記事</a>に詳しい。)</p>

<ol>
<li><p>Bootstrap TokenのSecret生成</p>

<p>以下のように生成できる。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># TOKEN_PUB=$(openssl rand -hex 3)
# TOKEN_SECRET=$(openssl rand -hex 8)
# BOOTSTRAP_TOKEN=&#34;${TOKEN_PUB}.${TOKEN_SECRET}&#34;
# kubectl -n kube-system create secret generic bootstrap-token-${TOKEN_PUB} --type &#39;bootstrap.kubernetes.io/token&#39; --from-literal description=&#34;cluster bootstrap token&#34; --from-literal token-id=${TOKEN_PUB} --from-literal token-secret=${TOKEN_SECRET} --from-literal usage-bootstrap-authentication=true --from-literal usage-bootstrap-signing=true --from-literal auth-extra-groups=system:bootstrappers:worker,system:bootstrappers:ingress</code></pre></div>
<p>けど、<a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-token/#cmd-token-generate">kubeadm</a>でも生成出来てこっちのほうが楽なので、それで。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># BOOTSTRAP_TOKEN=$(kubeadm token create --kubeconfig /etc/kubernetes/admin.kubeconfig)</code></pre></div>
<p>BOOTSTRAP_TOKENの値はあとで使う。</p>

<p>expirationは指定できなくて、1日で期限切れになっちゃうけど、クラスタにノードを追加するときに有効であればいいのでまあいい。</p>

<p>確認。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># TOKEN_PUB=$(echo $BOOTSTRAP_TOKEN | sed -e s/\\..*//)
# kubectl -n kube-system get secret/bootstrap-token-${TOKEN_PUB} -o yaml</code></pre></div></li>

<li><p>Bootstrap kubeconfig作成</p>

<p>Bootstrap時は<code>kubelet-bootstrap</code>というユーザでkube-apiserverに接続する。
<code>kubelet-bootstrap</code>は<code>system:node-bootstrapper</code>ロールを持って<code>system:bootstrappers</code>に属しているユーザとして認証される必要がある。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># mkdir -p /etc/kubernetes/manifests
# MASTER_IP=192.168.171.200
# KUBERNETES_PUBLIC_ADDRESS=$MASTER_IP
# CLUSTER_NAME=&#34;k8s&#34;
# KCONFIG=&#34;/etc/kubernetes/bootstrap.kubeconfig&#34;
# KUSER=&#34;kubelet-bootstrap&#34;
# kubectl config set-cluster ${CLUSTER_NAME} --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 --kubeconfig=${KCONFIG}
# kubectl config set-context ${KUSER}@${CLUSTER_NAME} --cluster=${CLUSTER_NAME} --user=${KUSER} --kubeconfig=${KCONFIG}
# kubectl config use-context ${KUSER}@${CLUSTER_NAME} --kubeconfig=${KCONFIG}
# chown kubernetes:kubernetes ${KCONFIG}
# chmod 0600 ${KCONFIG}</code></pre></div>
<p>確認。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># kubectl config view --kubeconfig=${KCONFIG}</code></pre></div></li>

<li><p>bootstrap.kubeconfigにトークンを追記</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># kubectl config set-credentials kubelet-bootstrap --token=${BOOTSTRAP_TOKEN} --kubeconfig=/etc/kubernetes/bootstrap.kubeconfig</code></pre></div></li>
</ol>

<h2 id="8-docker-cni-kubeletインストール">8. Docker、CNI、kubeletインストール</h2>

<ol>
<li><p>Docker</p>

<p><a href="https://docs.docker.com/install/linux/docker-ce/centos/#set-up-the-repository">https://docs.docker.com/install/linux/docker-ce/centos/#set-up-the-repository</a>
に従ってDocker CEをインストール。
ストレージドライバにはoverlay2をつかうので、device-mapper-persistent-dataとlvm2は入れない。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># yum install -y yum-utils
# yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
# yum install -y docker-ce</code></pre></div>
<p>18.03.0-ceが入った。</p>

<p>が、よくみたらDocker CEはOracle Linuxをサポートしていないので、Docker CEはアンインストールして、代わりに<a href="https://docs.oracle.com/cd/E77565_01/E87205/html/section_install_upgrade_yum_docker.html">Oracle Container Runtime for Docker</a> (aka docker-engine)を入れる。</p>

<p><code>/etc/yum.repos.d/public-yum-ol7.repo</code>の<code>ol7_addons</code>の<code>enabled</code>を1にして、以下のコマンドでdocker-engineをインストール。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># yum install -y docker-engine</code></pre></div>
<p>docker-engine 17.06.2が入った。</p>

<p><code>/etc/sysconfig/docker</code>に以下を追記して、 Dockerがオープンできる最大ファイル数を増やす。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-plain" data-lang="plain">DOCKER_NOFILE=1000000</code></pre></div>
<p>Kubernetes環境ではiptablesはkube-proxyが操作するので、Dockerには操作させないようにするため、<code>/etc/sysconfig/docker</code>の<code>OPTIONS</code>に<code>--iptables=false</code>を追加。
(これをすると、<code>--icc=false</code>は設定できなくなる(不要になる)。)</p>

<p>また、Podの<a href="https://kubernetes.io/docs/tasks/configure-pod-container/security-context/">allowPrivilegeEscalation</a>をfalseにできない<a href="https://github.com/coreos/bugs/issues/1796">問題</a>に対処するため、<code>/etc/sysconfig/docker</code>の<code>OPTIONS</code>から<code>--selinux-enabled</code>を消す。</p>

<p>で、起動。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># systemctl daemon-reload
# systemctl enable docker
# systemctl start docker</code></pre></div>
<p>確認。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># cat /proc/$(pidof dockerd)/environ
# systemctl status docker -l
# docker version</code></pre></div></li>

<li><p>CNI</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># mkdir -p /etc/cni/net.d /opt/cni/bin/
# cd /tmp
# curl -OL https://github.com/containernetworking/plugins/releases/download/v0.7.1/cni-plugins-amd64-v0.7.1.tgz
# cd /opt/cni/bin
# tar zxf /tmp/cni-plugins-amd64-v0.7.1.tgz
# chmod +x /opt/cni/bin/*
# cat &gt;/etc/cni/net.d/99-loopback.conf &lt;&lt;EOF
{
  &#34;cniVersion&#34;: &#34;0.3.1&#34;,
  &#34;name&#34;: &#34;lo&#34;,
  &#34;type&#34;: &#34;loopback&#34;
}
EOF</code></pre></div></li>

<li><p>kubelet</p>

<p>systemdのユニットファイルを書いてサービス化。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># DNS_SERVER_IP=10.0.0.10
# PAUSE_IMAGE=k8s.gcr.io/pause-amd64:3.1
# DNS_DOMAIN=&#34;cluster.local&#34;
# cat &gt; /etc/systemd/system/kubelet.service &lt;&lt; EOF
[Unit]
Description=Kubernetes Kubelet
Documentation=https://github.com/kubernetes/kubernetes
After=docker.service
Requires=docker.service

[Service]
CPUAccounting=true
MemoryAccounting=true
User=root
Group=root
ExecStart=/usr/bin/kubelet \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --address=0.0.0.0 \\
  --bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \\
  --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \\
  --pod-manifest-path=/etc/kubernetes/manifests \\
  --network-plugin=cni \\
  --cni-conf-dir=/etc/cni/net.d \\
  --cni-bin-dir=/opt/cni/bin \\
  --cluster-dns=${DNS_SERVER_IP} \\
  --cluster-domain=${DNS_DOMAIN} \\
  --authorization-mode=Webhook \\
  --client-ca-file=/etc/kubernetes/pki/ca.crt \\
  --cert-dir=/etc/kubernetes/pki \\
  --rotate-certificates=true \\
  --v=2 \\
  --cgroup-driver=cgroupfs \\
  --pod-infra-container-image=${PAUSE_IMAGE} \\
  --tls-min-version=VersionTLS12 \\
  --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 \\
  --allow-privileged=true \\
  --anonymous-auth=false
Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable kubelet
# systemctl start kubelet</code></pre></div>
<p>(実際は、systemctl start kubeletするまえに、後述のNode CSR自動承認設定をすべし。)</p>

<p><code>CPUAccounting=true</code>と<code>MemoryAccounting=true</code>は、Redhat系Linuxで<a href="https://github.com/kontena/pharos-cluster/issues/440">kubeletとdockerプロセスのメモリとCPUのcgroupが妙になる問題</a>の対応。</p>

<p><code>--allow-privileged</code>はflannelなどに必要。(k8s 1.11以降は指定不要になった。)</p>

<p><code>--pod-infra-container-image</code>では<a href="https://github.com/kubernetes/kubernetes/tree/master/build/pause">pause</a>コンテナイメージを指定する。
このコンテナはPod毎に起動され、Podネットワークの名前空間を保持するために使われるらしい。
今回使った<code>k8s.gcr.io/pause-amd64:3.1</code>はKubernetesチームが配布しているものだけど、Oracleが配布しているものもあり、そちらを使うには、Oracle Linux 7.4のダウンロード媒体リストに含まれるOracle Container Services for use with Kubernetes 1.1.9.1に入っているpause-amd64.tarを<code>docker load</code>しておいて、そのイメージ名を<code>--pod-infra-container-image</code>に渡せばいい。</p>

<p><code>--bootstrap-kubeconfig</code>で指定したkubeconfigでTLS Bootstrapして、<code>--cert-dir</code>で指定したディレクトリに証明書と鍵を生成して、<code>--kubeconfig</code>で指定したパスに以降使うkubeconfigを生成する。
この証明書を自動更新(i.e. Certificate Rotation)するオプションが<code>--rotate-certificates</code>。</p>

<p><code>--pod-manifest-path</code>で指定したディレクトリはkubeletに定期的にスキャンされ、そこに置いたKubernetesマニフェスト(ドットで始まるもの以外)が読まれる。
(参照: <a href="https://kubernetes.io/docs/tasks/administer-cluster/static-pod/">Static Pods</a>)</p>

<p><code>--pod-cidr</code>は指定しない。
これはkube-controller-managerに渡した<code>--cluster-cidr</code>と<code>--node-cidr-mask-size</code>から計算されるので。</p>

<p><code>--anonymous-auth=false</code>は<a href="https://kubernetes.io/docs/admin/kubelet-authentication-authorization/">セキュリティのために推奨されたオプション</a>。</p>

<p><code>--authorization-mode=Webhook</code>も<a href="https://kubernetes.io/docs/admin/kubelet-authentication-authorization/">セキュリティのために推奨されたオプション</a>で、認可処理をkube-apiserverに移譲する設定。</p>

<p>本当は<a href="https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/">Kubelet Configファイル</a>を使ったほうがいいみたいなので、いずれそれに対応する。
(対応した: 「<a href="https://www.kaitoy.xyz/2018/05/05/kubernetes-kubelet-config-and-pod-sec-policy/">Kubernetes 1.10のkubeletの起動オプションをKubelet ConfigファイルとPodSecurityPolicyで置き換える</a>」)</p>

<p>起動確認。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># systemctl status kubelet -l</code></pre></div></li>

<li><p>Node CSR手動承認</p>

<p>TLS Bootstrappingで生成されたCSRを手動で承認する。</p>

<p>CSRは以下のコマンドで見れる。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># kubectl get csr
NAME                                                   AGE       REQUESTOR                 CONDITION
csr-cf9hm                                              24m       system:node:k8s-master  Pending
node-csr-Vcw_4HioW1CI96eDH29RMKPrOchEN133053wm6DCXUk   24m       system:bootstrap:itacbw   Pending</code></pre></div>
<p><code>node-csr-…</code>がクライアント証明書のためのCSRで、<code>csr-…</code>がサーバ証明書の。
これらを承認する。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># kubectl certificate approve node-csr-Vcw_4HioW1CI96eDH29RMKPrOchEN133053wm6DCXUk
# kubectl certificate approve csr-cf9hm</code></pre></div>
<p>(因みに否認するときは<code>kubectl certificate deny</code>)</p>

<p>これでクラスタにノードが追加されたはず。
確認。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># kubectl get node
NAME         STATUS    ROLES     AGE       VERSION
k8s-master   Ready     &lt;none&gt;    36s       v1.10.0</code></pre></div></li>

<li><p>Node CSR自動承認設定</p>

<p>前節でやった手動承認はcsrapprovingが自動でやってくれる。</p>

<p>新規ノード参加時のCSRを承認するClusterRoleとして<code>system:certificates.k8s.io:certificatesigningrequests:nodeclient</code>が自動生成されているので、これを<code>system:bootstrappers</code>グループにバインドしてやると、自動承認が有効になる。</p>

<ul>
<li>s</li>
</ul>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># cat &lt;&lt;EOF | kubectl create -f -
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: auto-approve-csrs-for-group
subjects:
- kind: Group
  name: system:bootstrappers
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: system:certificates.k8s.io:certificatesigningrequests:nodeclient
  apiGroup: rbac.authorization.k8s.io
EOF</code></pre></div>
<p>また、kubeletのクライアント証明書を自動更新(i.e. RotateKubeletClientCertificate)するときのCSRを承認するClusterRoleとして<code>system:certificates.k8s.io:certificatesigningrequests:selfnodeclient</code>が自動生成されていて、これをsystem:nodesグループにバインドしてやると、自動承認が有効になる。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># HOSTNAME=k8s-master
# cat &lt;&lt;EOF | kubectl create -f -
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: auto-approve-renewals-for-nodes
subjects:
- kind: Group
  name: system:nodes
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient
  apiGroup: rbac.authorization.k8s.io
EOF</code></pre></div></li>
</ol>

<h2 id="9-kube-proxy-オーバレイネットワーク-dnsのデプロイ">9. kube-proxy、オーバレイネットワーク、DNSのデプロイ</h2>

<ol>
<li><p>kube-proxy</p>

<p>前提コマンド(conntrack)インストール。
(kube-proxyをipvsモードで動かす場合にはさらにipsetも入れる必要がある。)</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># yum -y install conntrack-tools</code></pre></div>
<p>kube-proxyのkubeconfigを作成。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># MASTER_IP=192.168.171.200
# KUBERNETES_PUBLIC_ADDRESS=$MASTER_IP
# CLUSTER_NAME=&#34;k8s&#34;
# KCONFIG=&#34;/etc/kubernetes/kube-proxy.kubeconfig&#34;
# KUSER=&#34;system:kube-proxy&#34;
# kubectl config set-cluster ${CLUSTER_NAME} --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 --kubeconfig=${KCONFIG}
# kubectl config set-credentials ${KUSER} --client-certificate=/etc/kubernetes/pki/kube-proxy.crt --client-key=/etc/kubernetes/pki/kube-proxy.key --embed-certs=true --kubeconfig=${KCONFIG}
# kubectl config set-context ${KUSER}@${CLUSTER_NAME} --cluster=${CLUSTER_NAME} --user=${KUSER} --kubeconfig=${KCONFIG}
# kubectl config use-context ${KUSER}@${CLUSTER_NAME} --kubeconfig=${KCONFIG}
# chown kubernetes:kubernetes ${KCONFIG}
# chmod 0600 ${KCONFIG}</code></pre></div>
<p>確認。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># kubectl config view --kubeconfig=${KCONFIG}</code></pre></div>
<p>systemdのユニットファイルを書いてサービス化。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># CLUSTER_CIDR=&#34;10.244.0.0/16&#34;
# cat &gt; /etc/systemd/system/kube-proxy.service &lt;&lt; EOF
[Unit]
Description=Kubernetes Kube Proxy
Documentation=https://github.com/kubernetes/kubernetes
After=network.target

[Service]
User=root
Group=root
ExecStart=/usr/bin/kube-proxy \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --bind-address 0.0.0.0 \\
  --cluster-cidr=${CLUSTER_CIDR} \\
  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig \\
  --v=2
Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
# systemctl daemon-reload
# systemctl enable kube-proxy
# systemctl start kube-proxy</code></pre></div>
<p>確認。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># systemctl status kube-proxy -l</code></pre></div></li>

<li><p>ネットワークプロバイダ (flannel)</p>

<p><a href="https://github.com/coreos/flannel/blob/master/Documentation/kubernetes.md">flannelのドキュメント</a>を参考に。</p>

<p>flannelをデプロイするには、kube-apiserverとkube-controller-managerの起動オプションに<code>--allow-privileged</code>を付ける必要がある。</p>

<p>また、公式が配布しているKubernetesマニフェストを使う場合、kube-controller-managerの起動オプションの<code>--cluster-cidr</code>で<code>10.244.0.0/16</code>を指定する必要がある。</p>

<p>デプロイ自体は以下のコマンドを実行するだけ。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</code></pre></div>
<p>このKubernetesマニフェストでは、quay.ioから<code>quay.io/coreos/flannel:v0.10.0-amd64</code>というコンテナイメージがpullされる。</p>

<p>Oracleもflannelのコンテナイメージを配布していて、そちらを使うには、Oracle Linux 7.4のダウンロード媒体リストに含まれるOracle Container Services for use with Kubernetes 1.1.9.1に入っているflannel.tarを<code>docker load</code>しておいて、そのイメージを使うようにマニフェストを書きかえればいい。</p>

<p>起動確認。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># kubectl -n kube-system get po
NAME                    READY     STATUS    RESTARTS   AGE
kube-flannel-ds-gkcqd   1/1       Running   0          1m</code></pre></div>
<p>flannelは<a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/">Network Policy</a>をサポートしていないので、<a href="https://www.projectcalico.org/">Calico</a>か<a href="https://www.weave.works/oss/net/">Weave Net</a>あたりにすればよかったかも。
(やった: 「<a href="https://www.kaitoy.xyz/2018/05/04/kubernetes-with-weave-net/">Kubernetes 1.10のクラスタにWeave Netをデプロイする</a>」)</p></li>

<li><p>CoreDNS</p>

<p>Kubernetes 1.10からは、サービスディスカバリに(kube-dnsの代わりに)CoreDNSを使うのが標準になった。</p>

<p>以下を参考にCoreDNSをデプロイする:</p>

<ul>
<li><a href="https://kubernetes.io/docs/tasks/administer-cluster/coredns/">https://kubernetes.io/docs/tasks/administer-cluster/coredns/</a></li>
<li><a href="https://coredns.io/2018/01/29/deploying-kubernetes-with-coredns-using-kubeadm/">https://coredns.io/2018/01/29/deploying-kubernetes-with-coredns-using-kubeadm/</a></li>
<li><a href="https://github.com/coredns/deployment/tree/master/kubernetes">https://github.com/coredns/deployment/tree/master/kubernetes</a></li>
</ul>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># cd /tmp
# curl -LO https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/coredns.yaml.sed
# curl -LO https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/deploy.sh
# chmod +x deploy.sh
# DNS_SERVER_IP=&#34;10.0.0.10&#34;
# SERVICE_CLUSTER_IP_RANGE=&#34;10.0.0.0/16&#34;
# DNS_DOMAIN=&#34;cluster.local&#34;
# ./deploy.sh -r $SERVICE_CLUSTER_IP_RANGE -i $DNS_SERVER_IP -d $DNS_DOMAIN &gt; coredns.yaml
# kubectl apply -f coredns.yaml</code></pre></div>
<p>このKubernetesマニフェストではDocker Hubから<code>coredns/coredns:1.1.1</code>というイメージがpullされる。</p>

<p>起動確認。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># kubectl -n kube-system get pods -o wide | grep coredns
coredns-8459d9f654-b585f   1/1       Running   0          48s       10.244.0.3        k8s-master
coredns-8459d9f654-x7drc   1/1       Running   0          48s       10.244.0.2        k8s-master</code></pre></div>
<p>起動確認時にCoreDNSのIPアドレスを確認して、動作確認。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># dig @10.244.0.3 kubernetes.default.svc.cluster.local +noall +answer

; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-61.el7 &lt;&lt;&gt;&gt; @10.244.0.3 kubernetes.default.svc.cluster.local +noall +answer
; (1 server found)
;; global options: +cmd
kubernetes.default.svc.cluster.local. 5 IN A    10.0.0.1</code></pre></div></li>
</ol>

<h2 id="10-kubernetesアプリデプロイ">10. Kubernetesアプリデプロイ</h2>

<p>前節まででKubernetesクラスタの構築は完了。
試しにKubernetesアプリをひとつデプロイしてみる。</p>

<ol>
<li><p><a href="https://github.com/weaveworks/scope">Weave Scope</a></p>

<p><a href="https://www.weave.works/docs/scope/latest/installing/#k8s">ドキュメント</a>を参考に。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># cd /tmp
# curl -sSL -o scope.yaml https://cloud.weave.works/k8s/scope.yaml?k8s-service-type=NodePort
# kubectl apply -f scope.yaml</code></pre></div>
<p>このKubernetesマニフェストではDocker Hubから<code>weaveworks/scope:1.8.0</code>というイメージがpullされる。</p>

<p><code>kubectl -n weave get svc/weave-scope-app</code>でポート調べて、<code>http://k8s-master:&lt;ポート&gt;/</code>をブラウザ開くとWeave ScopeのGUIが見れる。</p></li>
</ol></div>

        <section class="share-buttons">
          <div class="fb-share-button share-button" data-href="https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/" data-layout="button_count" data-size="small"><a target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fdevelopers.facebook.com%2Fdocs%2Fplugins%2F&amp;src=sdkpreparse" class="fb-xfbml-parse-ignore">シェア</a></div>
          <div class="share-button">
            <a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" data-text="Kubernetes 1.10をスクラッチから全手動で構築" data-url="https://www.kaitoy.xyz/2018/04/17/kubernetes110-from-scratch/" data-show-count="true" data-count="horizontal">Tweet</a>
          </div>
          <div class="share-button">
            <a href="https://b.hatena.ne.jp/entry/" class="hatena-bookmark-button" data-hatena-bookmark-layout="basic-label-counter" data-hatena-bookmark-lang="ja" title="このエントリーをはてなブックマークに追加"><img src="https://b.st-hatena.com/images/v4/public/entry-button/button-only@2x.png" alt="このエントリーをはてなブックマークに追加" width="20" height="20" style="border: none;" /></a><script type="text/javascript" src="https://b.st-hatena.com/js/bookmark_button.js" charset="utf-8" async="async"></script>
          </div>
          <div class="share-button">
            <a data-pocket-label="pocket" data-pocket-count="horizontal" class="pocket-btn" data-lang="en"></a>
            <script type="text/javascript">!function(d,i){if(!d.getElementById(i)){var j=d.createElement("script");j.id=i;j.src="https://widgets.getpocket.com/v1/j/btn.js?v=1";var w=d.getElementById(i);d.body.appendChild(j);}}(document,"pocket-btn-js");</script>
          </div>
        </section>
    </div>

    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <ins class="adsbygoogle"
         style="display:block"
         data-ad-client="ca-pub-6244473643910448"
         data-ad-slot="1845600530"
         data-ad-format="auto"></ins>
    <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
    </script>

    <section class="tbd-pagination">
      <div class="row">
        <div class="col-sm-6">
          <div class="prev">
            
            <a href="https://www.kaitoy.xyz/2018/04/01/hello-skaffold/">
              <i class="fa fa-angle-left"></i>
              Skaffoldを触ってみた
            </a>
            
          </div>
        </div>
        <div class="col-sm-6">
          <div class="next text-right">
            
            <a href="https://www.kaitoy.xyz/2018/05/04/kubernetes-with-weave-net/">
              Kubernetes 1.10のクラスタにWeave Netをデプロイする
              <i class="fa fa-angle-right"></i>
            </a>
            
          </div>
        </div>
      </div>
    </section>

    
    

    

        <h4 class="page-header">Related</h4>

        <div class="related-links">
           <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2022/09/04/irsa-emu/">EKSの外でIAM Roles for Service Accountsっぽいことを実現するMutating Admission Webhookを作った</a></h4>
    <h5>Sun, Sep 4, 2022</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/eks"><kbd class="item-tag">eks</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/irsa-emu"><kbd class="item-tag">irsa-emu</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/localstack"><kbd class="item-tag">localstack</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/vault"><kbd class="item-tag">vault</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2021/12/09/virtual-kubelet-liqo/">Liqoのvirtual-kubeletでKubernetesクラスタからk3sにPodをオフロードする</a></h4>
    <h5>Thu, Dec 9, 2021</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/k3s"><kbd class="item-tag">k3s</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/virtual-kubelet"><kbd class="item-tag">virtual-kubelet</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/liqo"><kbd class="item-tag">liqo</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2021/12/09/virtual-kubelet-admiralty/">Admiraltyのvirtual-kubeletでKubernetesクラスタからk3sにPodをオフロードする</a></h4>
    <h5>Thu, Dec 9, 2021</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/k3s"><kbd class="item-tag">k3s</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/virtual-kubelet"><kbd class="item-tag">virtual-kubelet</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/admiralty"><kbd class="item-tag">admiralty</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2021/08/16/k3s-on-eks/">EKSとオンプレVMとの間でk3sクラスタを組む</a></h4>
    <h5>Mon, Aug 16, 2021</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/k3s"><kbd class="item-tag">k3s</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/aws"><kbd class="item-tag">aws</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/eks"><kbd class="item-tag">eks</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2021/08/15/k3s-on-on-premises-k8s/">k3sをオンプレの手製Kubernetesクラスタで動かす</a></h4>
    <h5>Sun, Aug 15, 2021</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/k3s"><kbd class="item-tag">k3s</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2021/04/06/k8s-on-alma-linux-8/">Kubernetes 1.20 のクラスタを AlmaLinux 8で構築する</a></h4>
    <h5>Tue, Apr 6, 2021</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/alma-linux"><kbd class="item-tag">alma-linux</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2020/12/20/k8s-zundoko-ansible-operator/">ズンドコキヨシ with Kubernetes Ansible Operator - Operator SDKのAnsible Operatorを使ってみた</a></h4>
    <h5>Sun, Dec 20, 2020</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/operator-sdk"><kbd class="item-tag">operator-sdk</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/zundoko"><kbd class="item-tag">zundoko</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/ansible"><kbd class="item-tag">ansible</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2020/12/06/cri-dockerd/">Kubernetesでdockershimが廃止されても、KubernetesでDockerが使えなくなるわけじゃないよ</a></h4>
    <h5>Sun, Dec 6, 2020</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2020/10/31/metallb/">MetalLB入門 ― オンプレKubernetesクラスタでLoadBalancerタイプのServiceを使う</a></h4>
    <h5>Sat, Oct 31, 2020</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/metallb"><kbd class="item-tag">metallb</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2020/10/11/rook-ceph/">Rook/CephでCephFSを試す</a></h4>
    <h5>Sun, Oct 11, 2020</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/rook"><kbd class="item-tag">rook</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/ceph"><kbd class="item-tag">ceph</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2019/12/11/kong-ingress-controller/">Kong Ingress ControllerでKongの設定を管理する</a></h4>
    <h5>Wed, Dec 11, 2019</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/kong"><kbd class="item-tag">kong</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2019/12/05/k8s-on-centos8-with-containerd/">Kubernetes 1.16 のクラスタを CentOS 8 と containerd で構築する</a></h4>
    <h5>Thu, Dec 5, 2019</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/containerd"><kbd class="item-tag">containerd</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2019/09/23/k8s-ecosystem-misc/">Kubernetesのエコシステム ー その他雑多</a></h4>
    <h5>Mon, Sep 23, 2019</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2019/08/14/k8s-ecosystem-k8s-variations-and-container-host-oses/">Kubernetesのエコシステム ー KubernetesバリエーションとコンテナホストOS編</a></h4>
    <h5>Wed, Aug 14, 2019</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2019/07/27/introduction-to-k8s/">Kubernetes入門</a></h4>
    <h5>Sat, Jul 27, 2019</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/microservices"><kbd class="item-tag">microservices</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2019/07/26/k8s-meetup-tokyo-21/">Kubernetes Meetup Tokyo #21 - Cloud Native CI/CD に行ってきた</a></h4>
    <h5>Fri, Jul 26, 2019</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/argo"><kbd class="item-tag">argo</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/gitops"><kbd class="item-tag">gitops</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/spinnaker"><kbd class="item-tag">spinnaker</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/argo"><kbd class="item-tag">argo</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2019/06/23/k8s-ecosystem-preparing-k8s-cluster/">Kubernetesのエコシステム ー Kubernetesクラスタ構築編</a></h4>
    <h5>Sun, Jun 23, 2019</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2019/06/15/k8s-ecosystem-container-runtimes/">Kubernetesのエコシステム ー コンテナランタイム編</a></h4>
    <h5>Sat, Jun 15, 2019</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/containerd"><kbd class="item-tag">containerd</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2019/03/08/k8s-zundoko-operator/">ズンドコキヨシ with Kubernetes Operator - KubebuilderでKubernetes Operatorを作ってみた</a></h4>
    <h5>Fri, Mar 8, 2019</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/kubebuilder"><kbd class="item-tag">kubebuilder</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/zundoko"><kbd class="item-tag">zundoko</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/golang"><kbd class="item-tag">golang</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2018/06/17/packer-k8s/">Packer &#43; Ansible on Windows 10でKubernetes 1.10のクラスタ on VirtualBoxを全自動構築</a></h4>
    <h5>Sun, Jun 17, 2018</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/ansible"><kbd class="item-tag">ansible</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/packer"><kbd class="item-tag">packer</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/msys2"><kbd class="item-tag">msys2</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2018/06/03/build-k8s-cluster-by-ansible/">Kubernetes 1.10のクラスタを全手動で構築するのをAnsibleで全自動化した</a></h4>
    <h5>Sun, Jun 3, 2018</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/ansible"><kbd class="item-tag">ansible</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2018/05/05/kubernetes-kubelet-config-and-pod-sec-policy/">Kubernetes 1.10のkubeletの起動オプションをKubelet ConfigファイルとPodSecurityPolicyで置き換える</a></h4>
    <h5>Sat, May 5, 2018</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2018/05/04/kubernetes-with-weave-net/">Kubernetes 1.10のクラスタにWeave Netをデプロイする</a></h4>
    <h5>Fri, May 4, 2018</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2018/04/01/hello-skaffold/">Skaffoldを触ってみた</a></h4>
    <h5>Sun, Apr 1, 2018</h5>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/skaffold"><kbd class="item-tag">skaffold</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/minikube"><kbd class="item-tag">minikube</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2017/10/31/retry-dashboard-on-k8s-cluster-by-kubeadm/">Kubernetes 1.8のアクセス制御について。あとDashboard。</a></h4>
    <h5>Tue, Oct 31, 2017</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2017/10/21/build-kubernetes-cluster-by-kubeadm/">Kubernetes1.8のクラスタを構築する。kubeadmで。</a></h4>
    <h5>Sat, Oct 21, 2017</h5>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/kubeadm"><kbd class="item-tag">kubeadm</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2017/10/11/goslings-on-kubernetes-cont/">Kubernetesのチュートリアルをやる</a></h4>
    <h5>Wed, Oct 11, 2017</h5>
    
    <a href="https://www.kaitoy.xyz/tags/goslings"><kbd class="item-tag">goslings</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/minikube"><kbd class="item-tag">minikube</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2017/10/10/goslings-on-kubernetes/">Kubernetes 1.8が出たので、Minikubeを触ってみる</a></h4>
    <h5>Tue, Oct 10, 2017</h5>
    
    <a href="https://www.kaitoy.xyz/tags/goslings"><kbd class="item-tag">goslings</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/kubernetes"><kbd class="item-tag">kubernetes</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/minikube"><kbd class="item-tag">minikube</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2017/08/14/webdriverio-chrome/">WebdriverIOとChromeのヘッドレスモードで自動ブラウザテストするDockerイメージ: webdriverio-chrome</a></h4>
    <h5>Mon, Aug 14, 2017</h5>
    
    <a href="https://www.kaitoy.xyz/tags/servicenow"><kbd class="item-tag">servicenow</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/selenium"><kbd class="item-tag">selenium</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/webdriverio"><kbd class="item-tag">webdriverio</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2016/09/15/pcap4j-on-hyper-v-container-on-win10/">Pcap4J on Nano Server on Hyper-V Containers on Windows 10 on VMware Playerにトライ</a></h4>
    <h5>Thu, Sep 15, 2016</h5>
    
    <a href="https://www.kaitoy.xyz/tags/windows"><kbd class="item-tag">windows</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/nanoserver"><kbd class="item-tag">nanoserver</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/pcap4j"><kbd class="item-tag">pcap4j</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2016/09/12/unzip-on-nanoserver/">Hyper-Vコンテナ(Nano Server)でunzipしたいならjarを使え</a></h4>
    <h5>Mon, Sep 12, 2016</h5>
    
    <a href="https://www.kaitoy.xyz/tags/windows"><kbd class="item-tag">windows</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/nanoserver"><kbd class="item-tag">nanoserver</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2016/07/31/docker-for-windows/">Docker for Windowsがコレジャナかった</a></h4>
    <h5>Sun, Jul 31, 2016</h5>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/windows"><kbd class="item-tag"> windows</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2016/07/11/windows_containers_on_tp5/">Windows Server 2016 TP5でWindows Containersにリトライ</a></h4>
    <h5>Mon, Jul 11, 2016</h5>
    
    <a href="https://www.kaitoy.xyz/tags/pcap4j"><kbd class="item-tag">pcap4j</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/windows"><kbd class="item-tag">windows</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2016/01/22/pcap4j-meets-windows-containers/">Pcap4J Meets Windows Containers</a></h4>
    <h5>Fri, Jan 22, 2016</h5>
    
    <a href="https://www.kaitoy.xyz/tags/pcap4j"><kbd class="item-tag">pcap4j</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/windows"><kbd class="item-tag">windows</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2015/07/27/another-way-to-capture-lan-packets-with-pcap4j-container/">Another way to capture LAN packets with pcap4j container</a></h4>
    <h5>Mon, Jul 27, 2015</h5>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/pcap4j"><kbd class="item-tag">pcap4j</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2015/07/25/how-to-capture-packets-on-a-local-network-with-pcap4j-container/">How to capture packets on a local network with Pcap4J container</a></h4>
    <h5>Sat, Jul 25, 2015</h5>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/pcap4j"><kbd class="item-tag">pcap4j</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2015/07/19/pcap4j-container-with-runc/">Pcap4J container with runC</a></h4>
    <h5>Sun, Jul 19, 2015</h5>
    
    <a href="https://www.kaitoy.xyz/tags/pcap4j"><kbd class="item-tag">pcap4j</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/runc"><kbd class="item-tag">runc</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/docker"><kbd class="item-tag">docker</kbd></a>
    

</div>
 
        </div>
    

    

        <h4 class="page-header">Comments</h4>

        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "kaitoy-tobedecided" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    

</main>

        <footer>

            <p class="copyright text-muted">&copy; 2015 Kaito Yamada. Powered by <a href="https://gohugo.io">Hugo</a> and <a href="https://github.com/calintat/minimal">Minimal</a></p>

        </footer>

        <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

    </body>

</html>

