<!DOCTYPE html>
<html lang="en-us">
    <head>
         

<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-6244473643910448",
    enable_page_level_ads: true
  });
</script>

<meta name="google-site-verification" content="9qs7VjxtSrYMqw5OElxCdKv_gnssSRi6acB2iYlZnGA" />
<meta property="og:url" content="https://www.kaitoy.xyz/2018/03/25/hello-world-to-ml-with-keras/">
<meta property="og:site_name" content="To Be Decided">
<meta name="twitter:card" content="summary"></meta>
<link rel="canonical" href="https://www.kaitoy.xyz/2018/03/25/hello-world-to-ml-with-keras/">



  <meta property="og:type" content="article">
  <meta property="og:title" content="[To Be Decided ~]$ cat /post/&quot;機械学習のHello World: MNISTの分類モデルをKerasで作ってみた&quot;">
  <title>[To Be Decided ~]$ cat /post/&quot;機械学習のHello World: MNISTの分類モデルをKerasで作ってみた&quot;</title>
  <meta property="og:description" content="機械学習のHello WorldとしてよくやられるMNISTの分類モデルをKeras on TensorFlowで作ってみた話。
   (adsbygoogle = window.adsbygoogle || []).push({});  MNISTとは 手書き数字画像のラベル付きデータセット。 6万個の訓練データと1万個のテストデータからなる。 CC BY-SA 3.0で配布されているっぽい。
一つの画像は28×28ピクセルの白黒画像で、0から9のアラビア数字が書かれている。
画像とラベルがそれぞれ独特な形式でアーカイブされていて、画像一つ、ラベル一つ取り出すのも一苦労する。
Kerasとは Pythonのニューラルネットワークライブラリ。 バックエンドとしてTensorFlowかCNTKかTheanoを使う。 今回はTensorFlowを使った。
やったこと KerasのMNISTのAPIとかコードサンプルとかがあけどこれらはスルー。
MNISTのサイトにあるデータセットをダウンロードしてきて、サイトに書いてあるデータ形式の説明を見ながらサンプルを取り出すコードを書いた。 で、KerasでVGGっぽいCNNを書いて、学習させてモデルをダンプして、ダンプしたモデルをロードしてテストデータで評価するコードを書いた。 コードはGitHubに。
ネットワークアーキテクチャ 入力画像のサイズに合わせてVGGを小さくした感じのCNNを作った。
VGGは2014年に発表されたアーキテクチャで、各層に同じフィルタを使い、フィルタ数を線形増加させるシンプルな構造でありながら、性能がよく、今でもよく使われるっぽい。
VGGを図にすると以下の構造。
実際はバッチ正規化とかDropoutもやるのかも。 プーリング層は数えないで16層なので、VGG-16とも呼ばれる。 パラメータ数は1億3800万個くらいで、結構深めなアーキテクチャ。

VGG-16は244×244×3の画像を入力して1000クラスに分類するのに対し、MNISTは28×28×1を入れて10クラスに分類するので、以下のような7層版を作った。
これでパラメータ数は27万個くらい。 訓練データのサンプル数が6万個なので、パラメータ数が大分多い感じではある。
コードは以下。
inputs: Tensor = Input(shape=(IMAGE_NUM_ROWS, IMAGE_NUM_COLS, 1)) x: Tensor = Conv2D(filters=8, kernel_size=(2, 2), padding=&#39;same&#39;, activation=&#39;relu&#39;)(inputs) x = Conv2D(filters=8, kernel_size=(2, 2), padding=&#39;same&#39;, activation=&#39;relu&#39;)(x) x = MaxPooling2D(pool_size=(2, 2))(x) x = Conv2D(filters=16, kernel_size=(2, 2), padding=&#39;same&#39;, activation=&#39;relu&#39;)(x) x = Conv2D(filters=16, kernel_size=(2, 2), padding=&#39;same&#39;, activation=&#39;relu&#39;)(x) x = Conv2D(filters=16, kernel_size=(2, 2), padding=&#39;same&#39;, activation=&#39;relu&#39;)(x) x = MaxPooling2D(pool_size=(2, 2))(x) x = Flatten()(x) x = Dense(units=256, activation=&#39;relu&#39;)(x) x = Dense(units=256, activation=&#39;relu&#39;)(x) predictions: Tensor = Dense(NUM_CLASSES, activation=&#39;softmax&#39;)(x) model: Model = Model(inputs=inputs, outputs=predictions) model.">
  <meta property="og:image" content="https://www.kaitoy.xyz/images/keras.png">



        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        
        <style>

    html body {
        font-family: 'Noto Sans JP', sans-serif;
        background-color: #fefefe;
    }

    :root {
        --accent: #fa1e44;
        --border-width:  5px ;
    }

</style>


<link rel="stylesheet" href="https://www.kaitoy.xyz/css/main.css">





<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans+JP:400,700&amp;subset=japanese">





<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
 






<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>


<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>








<script>$(document).on('click', function() { $('.collapse').collapse('hide'); })</script>
 <meta name="generator" content="Hugo 0.55.1" />
        
        
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-65248565-1"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments)};
          gtag('js', new Date());

          gtag('config', 'UA-65248565-1');
        </script>
        
    </head>

    

    <body>
         
<div id="fb-root"></div>
<script async defer crossorigin="anonymous" src="https://connect.facebook.net/ja_JP/sdk.js#xfbml=1&version=v3.2"></script>

        <nav class="navbar navbar-default navbar-fixed-top">

            <div class="container">

                <div class="navbar-header">

                    <a class="navbar-brand visible-xs" href="#">機械学習のHello World: MNISTの分類モデルをKerasで作ってみた</a>

                    <button class="navbar-toggle" data-target=".navbar-collapse" data-toggle="collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>

                </div>

                <div class="collapse navbar-collapse">

                    
                        <ul class="nav navbar-nav">
                            
                                <li><a href="/">Home</a></li>
                            
                                <li><a href="/post/">Posts</a></li>
                            
                                <li><a href="/tags/">Tags</a></li>
                            
                                <li><a href="/about/">About</a></li>
                            
                        </ul>
                    

                    
                        <ul class="nav navbar-nav navbar-right">
                            
                                <li class="navbar-icon"><a href="mailto:kaitoy@pcap4j.org"><i class="fa fa-envelope-o"></i></a></li>
                            
                                <li class="navbar-icon"><a href="https://github.com/kaitoy"><i class="fa fa-github"></i></a></li>
                            
                                <li class="navbar-icon"><a href="https://www.linkedin.com/in/kaito-yamada-8558b913a"><i class="fa fa-linkedin"></i></a></li>
                            
                                <li class="navbar-icon"><a href="https://www.facebook.com/yamada.kaito.90"><i class="fa fa-facebook-square"></i></a></li>
                            
                        </ul>
                    

                </div>

            </div>

        </nav>


<main>

    <div class="single-post">
        <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2018/03/25/hello-world-to-ml-with-keras/">機械学習のHello World: MNISTの分類モデルをKerasで作ってみた</a></h4>
    <h5>Sun, Mar 25, 2018</h5>
    
    <a href="https://www.kaitoy.xyz/tags/machine-learning"><kbd class="item-tag">machine learning</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/deep-learning"><kbd class="item-tag">deep learning</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/neural-network"><kbd class="item-tag">neural network</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/tensorflow"><kbd class="item-tag">tensorflow</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/keras"><kbd class="item-tag">keras</kbd></a>
    

</div>


        <div class="cover">
            <a href="/2018/03/25/hello-world-to-ml-with-keras/">
                <img src="https://www.kaitoy.xyz/images/keras.png" alt="機械学習のHello World: MNISTの分類モデルをKerasで作ってみた">
            </a>
        </div>

        
        <h4 class="page-header">Table of Contents</h4>
        <aside>
            <nav id="TableOfContents">
<ul>
<li><a href="#mnistとは">MNISTとは</a></li>
<li><a href="#kerasとは">Kerasとは</a></li>
<li><a href="#やったこと">やったこと</a></li>
<li><a href="#ネットワークアーキテクチャ">ネットワークアーキテクチャ</a></li>
<li><a href="#訓練-評価">訓練・評価</a></li>
<li><a href="#モデル改善">モデル改善</a></li>
<li><a href="#エラー分析">エラー分析</a></li>
</ul>
</nav>
        </aside>
        <hr>
        

        <br> <div class="text-justify">

<p>機械学習のHello Worldとしてよくやられる<a href="http://yann.lecun.com/exdb/mnist/">MNIST</a>の分類モデルを<a href="https://keras.io/ja/">Keras</a> on <a href="https://www.tensorflow.org/">TensorFlow</a>で作ってみた話。</p>





<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-6244473643910448"
     data-ad-slot="1845600530"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h1 id="mnistとは">MNISTとは</h1>

<p>手書き数字画像のラベル付きデータセット。
6万個の訓練データと1万個のテストデータからなる。
<a href="https://creativecommons.org/licenses/by-sa/3.0/">CC BY-SA 3.0</a>で<a href="http://www.pymvpa.org/datadb/mnist.html">配布されているっぽい</a>。</p>

<p>一つの画像は28×28ピクセルの白黒画像で、0から9のアラビア数字が書かれている。</p>

<p>画像とラベルがそれぞれ独特な形式でアーカイブされていて、画像一つ、ラベル一つ取り出すのも一苦労する。</p>

<h1 id="kerasとは">Kerasとは</h1>

<p>Pythonのニューラルネットワークライブラリ。
バックエンドとしてTensorFlowかCNTKかTheanoを使う。
今回はTensorFlowを使った。</p>

<h1 id="やったこと">やったこと</h1>

<p>KerasのMNISTの<a href="https://keras.io/ja/datasets/#mnist">API</a>とか<a href="https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py">コードサンプル</a>とかがあけどこれらはスルー。</p>

<p>MNISTのサイトにあるデータセットをダウンロードしてきて、サイトに書いてあるデータ形式の説明を見ながらサンプルを取り出すコードを書いた。
で、KerasでVGGっぽいCNNを書いて、学習させてモデルをダンプして、ダンプしたモデルをロードしてテストデータで評価するコードを書いた。
コードは<a href="https://github.com/kaitoy/ml-mnist">GitHub</a>に。</p>

<h1 id="ネットワークアーキテクチャ">ネットワークアーキテクチャ</h1>

<p>入力画像のサイズに合わせてVGGを小さくした感じのCNNを作った。</p>

<p>VGGは2014年に発表されたアーキテクチャで、各層に同じフィルタを使い、フィルタ数を線形増加させるシンプルな構造でありながら、性能がよく、今でもよく使われるっぽい。</p>

<p>VGGを図にすると以下の構造。</p>

<p><img src="/images/hello-world-to-ml-with-keras/vgg16.png" alt="vgg16.png" /></p>

<p>実際はバッチ正規化とかDropoutもやるのかも。
プーリング層は数えないで16層なので、VGG-16とも呼ばれる。
パラメータ数は1億3800万個くらいで、結構深めなアーキテクチャ。</p>

<p><br></p>

<p>VGG-16は244×244×3の画像を入力して1000クラスに分類するのに対し、MNISTは28×28×1を入れて10クラスに分類するので、以下のような7層版を作った。</p>

<p><img src="/images/hello-world-to-ml-with-keras/vgg7.png" alt="vgg7.png" /></p>

<p>これでパラメータ数は27万個くらい。
訓練データのサンプル数が6万個なので、パラメータ数が大分多い感じではある。</p>

<p>コードは以下。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">inputs: Tensor = Input(shape=(IMAGE_NUM_ROWS, IMAGE_NUM_COLS, <span style="color:#3677a9">1</span>))

x: Tensor = Conv2D(filters=<span style="color:#3677a9">8</span>, kernel_size=(<span style="color:#3677a9">2</span>, <span style="color:#3677a9">2</span>), padding=<span style="color:#ed9d13">&#39;same&#39;</span>, activation=<span style="color:#ed9d13">&#39;relu&#39;</span>)(inputs)
x = Conv2D(filters=<span style="color:#3677a9">8</span>, kernel_size=(<span style="color:#3677a9">2</span>, <span style="color:#3677a9">2</span>), padding=<span style="color:#ed9d13">&#39;same&#39;</span>, activation=<span style="color:#ed9d13">&#39;relu&#39;</span>)(x)
x = MaxPooling2D(pool_size=(<span style="color:#3677a9">2</span>, <span style="color:#3677a9">2</span>))(x)

x = Conv2D(filters=<span style="color:#3677a9">16</span>, kernel_size=(<span style="color:#3677a9">2</span>, <span style="color:#3677a9">2</span>), padding=<span style="color:#ed9d13">&#39;same&#39;</span>, activation=<span style="color:#ed9d13">&#39;relu&#39;</span>)(x)
x = Conv2D(filters=<span style="color:#3677a9">16</span>, kernel_size=(<span style="color:#3677a9">2</span>, <span style="color:#3677a9">2</span>), padding=<span style="color:#ed9d13">&#39;same&#39;</span>, activation=<span style="color:#ed9d13">&#39;relu&#39;</span>)(x)
x = Conv2D(filters=<span style="color:#3677a9">16</span>, kernel_size=(<span style="color:#3677a9">2</span>, <span style="color:#3677a9">2</span>), padding=<span style="color:#ed9d13">&#39;same&#39;</span>, activation=<span style="color:#ed9d13">&#39;relu&#39;</span>)(x)
x = MaxPooling2D(pool_size=(<span style="color:#3677a9">2</span>, <span style="color:#3677a9">2</span>))(x)

x = Flatten()(x)
x = Dense(units=<span style="color:#3677a9">256</span>, activation=<span style="color:#ed9d13">&#39;relu&#39;</span>)(x)
x = Dense(units=<span style="color:#3677a9">256</span>, activation=<span style="color:#ed9d13">&#39;relu&#39;</span>)(x)
predictions: Tensor = Dense(NUM_CLASSES, activation=<span style="color:#ed9d13">&#39;softmax&#39;</span>)(x)

model: Model = Model(inputs=inputs, outputs=predictions)
model.<span style="color:#24909d">compile</span>(optimizer=<span style="color:#ed9d13">&#39;adam&#39;</span>, loss=<span style="color:#ed9d13">&#39;categorical_crossentropy&#39;</span>, metrics=[<span style="color:#ed9d13">&#39;accuracy&#39;</span>])</code></pre></div>
<h1 id="訓練-評価">訓練・評価</h1>

<p>上記モデルを6万個のサンプルでバッチサイズ512で一周(1エポック)学習させると、Intel Core i5-6300HQプロセッサー、メモリ16GBのノートPCで28秒前後かかる。</p>

<p>とりあえず3エポック学習させてみる。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cmd" data-lang="cmd">(ml-mnist) C:\workspace\ml-mnist<span style="color:#999;font-style:italic">&gt;python bin\ml_mnist.py train</span>
Using TensorFlow backend.
Epoch 1/3
60000/60000 [==============================] - 28s 465us/step - loss: 0.7813 - acc: 0.7702
Epoch 2/3
60000/60000 [==============================] - 27s 453us/step - loss: 0.1607 - acc: 0.9496
Epoch 3/3
60000/60000 [==============================] - 27s 448us/step - loss: 0.1041 - acc: 0.9681</code></pre></div>
<p>ロスが0.1041で正答率が96.81%という結果になった。</p>

<p>このモデルをテストデータで評価する。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cmd" data-lang="cmd">(ml-mnist) C:\workspace\ml-mnist<span style="color:#999;font-style:italic">&gt;python bin\ml_mnist.py eval</span>
Using TensorFlow backend.
10000/10000 [==============================] - 2s 165us/step
loss: 0.08780829641819, acc: 0.9717000002861023</code></pre></div>
<p>正答率97.17%。
そんなに良くないけど、過学習はしていない模様。</p>

<p><br></p>

<p>次に10エポック学習させて評価してみる。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cmd" data-lang="cmd">(ml-mnist) C:\workspace\ml-mnist<span style="color:#999;font-style:italic">&gt;python bin\ml_mnist.py train</span>
Using TensorFlow backend.
Epoch 1/10
60000/60000 [==============================] - 29s 486us/step - loss: 0.5814 - acc: 0.8297
Epoch 2/10
60000/60000 [==============================] - 28s 470us/step - loss: 0.1130 - acc: 0.9651
Epoch 3/10
60000/60000 [==============================] - 28s 469us/step - loss: 0.0711 - acc: 0.9777
Epoch 4/10
60000/60000 [==============================] - 28s 468us/step - loss: 0.0561 - acc: 0.9821
Epoch 5/10
60000/60000 [==============================] - 28s 469us/step - loss: 0.0476 - acc: 0.9852
Epoch 6/10
60000/60000 [==============================] - 28s 473us/step - loss: 0.0399 - acc: 0.9879
Epoch 7/10
60000/60000 [==============================] - 28s 467us/step - loss: 0.0338 - acc: 0.9892
Epoch 8/10
60000/60000 [==============================] - 28s 467us/step - loss: 0.0283 - acc: 0.9909
Epoch 9/10
60000/60000 [==============================] - 29s 490us/step - loss: 0.0230 - acc: 0.9925
Epoch 10/10
60000/60000 [==============================] - 28s 471us/step - loss: 0.0223 - acc: 0.9928

(ml-mnist) C:\workspace\ml-mnist<span style="color:#999;font-style:italic">&gt;python bin\ml_mnist.py eval</span>
Using TensorFlow backend.
10000/10000 [==============================] - 2s 171us/step
loss: 0.040611953073740006, acc: 0.9866999998092651</code></pre></div>
<p>テストデータでの正答率98.67%。
ちょっと改善した。</p>

<h1 id="モデル改善">モデル改善</h1>

<p>試しにバッチ正規化層を入れてみる。
ReLUの前に入れるべきという情報があったけど、それだとちょっと修正が面倒なので、単にプーリング層の後に入れてみた。</p>

<p>3エポックで学習・評価。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cmd" data-lang="cmd">(ml-mnist) C:\workspace\ml-mnist<span style="color:#999;font-style:italic">&gt;python bin\ml_mnist.py train</span>
Using TensorFlow backend.
Epoch 1/3
60000/60000 [==============================] - 45s 746us/step - loss: 0.2157 - acc: 0.9336
Epoch 2/3
60000/60000 [==============================] - 44s 737us/step - loss: 0.0513 - acc: 0.9838
Epoch 3/3
60000/60000 [==============================] - 47s 777us/step - loss: 0.0340 - acc: 0.9896

(ml-mnist) C:\workspace\ml-mnist<span style="color:#999;font-style:italic">&gt;python bin\ml_mnist.py eval</span>
Using TensorFlow backend.
10000/10000 [==============================] - 2s 246us/step
loss: 0.051704482543468475, acc: 0.9844999995231628</code></pre></div>
<p>98.45%。
1エポックの学習時間は45秒前後に伸びたけど、速く学習できるようにはなった。</p>

<p>10エポックではどうか。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cmd" data-lang="cmd">(ml-mnist) C:\workspace\ml-mnist<span style="color:#999;font-style:italic">&gt;python bin\ml_mnist.py train</span>
Using TensorFlow backend.
Epoch 1/10
60000/60000 [==============================] - 47s 776us/step - loss: 0.2318 - acc: 0.9265
Epoch 2/10
60000/60000 [==============================] - 47s 790us/step - loss: 0.0596 - acc: 0.9811
Epoch 3/10
60000/60000 [==============================] - 47s 778us/step - loss: 0.0370 - acc: 0.9884
Epoch 4/10
60000/60000 [==============================] - 48s 801us/step - loss: 0.0259 - acc: 0.9917
Epoch 5/10
60000/60000 [==============================] - 47s 785us/step - loss: 0.0182 - acc: 0.9942
Epoch 6/10
60000/60000 [==============================] - 48s 794us/step - loss: 0.0132 - acc: 0.9961
Epoch 7/10
60000/60000 [==============================] - 46s 765us/step - loss: 0.0108 - acc: 0.9965
Epoch 8/10
60000/60000 [==============================] - 45s 751us/step - loss: 0.0107 - acc: 0.9965
Epoch 9/10
60000/60000 [==============================] - 45s 749us/step - loss: 0.0055 - acc: 0.9984
Epoch 10/10
60000/60000 [==============================] - 45s 754us/step - loss: 0.0035 - acc: 0.9991

(ml-mnist) C:\workspace\ml-mnist<span style="color:#999;font-style:italic">&gt;python bin\ml_mnist.py eval</span>
Using TensorFlow backend.
10000/10000 [==============================] - 2s 243us/step
loss: 0.034382903814315795, acc: 0.9893999994277954</code></pre></div>
<p>98.94%。
バッチ正規化無し版よりも0.27%改善してるけど、誤差の範囲かも。</p>

<p><br></p>

<p>MNISTのサイトに載ってるので一番いいのが99.77%。
どうしたらそんなによくなるのか。</p>

<h1 id="エラー分析">エラー分析</h1>

<p>一番正答率が高かったモデルについて、エラー分析をしてみた。</p>

<p>まず、エラーが多かった数字を調べる。
数字をエラー数順に並べると、</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-plain" data-lang="plain">ラベル: エラー数
9: 18
7: 18
5: 15
4: 14
6: 14
3: 8
8: 8
2: 7
1: 2
0: 2</code></pre></div>
<p>9と7が一番分類むずくて、4、5、6がそれらに次いでむずいことがわかる。</p>

<p><br></p>

<p>次にエラーのパターンを見てみる。</p>
<div class="highlight"><pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-plain" data-lang="plain">(予測した数字, ラベル): 出現数
(9, 4): 10
(3, 5): 9
(1, 7): 7
(2, 7): 6
(7, 9): 6
(9, 7): 5
(7, 2): 4
(8, 5): 4
(1, 6): 4
(1, 9): 4
(0, 6): 4
(8, 9): 3
(9, 3): 3
(4, 9): 3
(8, 3): 2
(2, 4): 2
(2, 8): 2
(1, 2): 2
(8, 4): 2
(5, 3): 2
(5, 9): 2
(8, 6): 2
(2, 6): 2
(5, 6): 1
(1, 8): 1
(6, 8): 1
(0, 8): 1
(2, 3): 1
(4, 6): 1
(2, 1): 1
(3, 8): 1
(8, 1): 1
(7, 0): 1
(4, 8): 1
(6, 0): 1
(5, 8): 1
(6, 5): 1
(9, 2): 1
(0, 5): 1</code></pre></div>
<p>4を9と、5を3と、7を1か2と、9を7と間違えたパターンが多い。
特に4と7がむずい模様。</p>

<p><br></p>

<p>次に、実際に間違えた画像を見てみる。
多かったパターンについて見てみる。</p>

<p>4を9と間違えたパターン:</p>

<p><img src="/images/hello-world-to-ml-with-keras/9-4.png" alt="9-4.png" /></p>

<p>なんだこれは。
これはかなり9にも見える。
ちょっと角ばってるとこと、線が右にはみ出しているとこで判断するのか。</p>

<p><br></p>

<p>5を3と間違えたパターン:</p>

<p><img src="/images/hello-world-to-ml-with-keras/3-5.png" alt="3-5.png" /></p>

<p>これはもうちょっとモデルに頑張ってほしい。
これを3としてしまうのは残念。
なにがだめだったのかは分からないけど。</p>

<p><br></p>

<p>7を1と間違えたパターン:</p>

<p><img src="/images/hello-world-to-ml-with-keras/1-7.png" alt="1-7.png" /></p>

<p>これは1でもいいような…</p>

<p><br></p>

<p>7を2と間違えたパターン:</p>

<p><img src="/images/hello-world-to-ml-with-keras/2-7.png" alt="2-7.png" /></p>

<p>これはちょっと面白い。
7の真ん中に線をいれるパターンを訓練データに足せば対応できそう。</p>

<p><br></p>

<p>9を7と間違えたパターン:</p>

<p><img src="/images/hello-world-to-ml-with-keras/7-9.png" alt="7-9.png" /></p>

<p>これもモデルに頑張ってほしかったパターン。
左上のごみが悪さしたんだろうか。
ごみがあるパターンを訓練データに増やすと対応できるかも。</p>

<p><br></p>

<p>あと、ちょっと噴いたやつ:</p>

<p><img src="/images/hello-world-to-ml-with-keras/2-4.png" alt="2-4.png" /></p>

<p>これは4。
モデルは2と間違えた。
むずい。</p>

<p><img src="/images/hello-world-to-ml-with-keras/2-8.png" alt="2-8.png" /></p>

<p>これは8。
モデルは2と間違えた。
こんなのテストデータにいれないで…</p>
</div>

        <section class="share-buttons">
          <div class="share-button">
            <div class="fb-share-button" data-href="https://www.kaitoy.xyz/2018/03/25/hello-world-to-ml-with-keras/" data-layout="box_count" data-size="small"><a target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fwww.kaitoy.xyz%2f2018%2f03%2f25%2fhello-world-to-ml-with-keras%2f&amp;src=sdkpreparse" class="fb-xfbml-parse-ignore">Share</a></div>
          </div>
          <div class="share-button">
            <a class="twitter-share-button"
              href="https://twitter.com/intent/tweet?text=%e6%a9%9f%e6%a2%b0%e5%ad%a6%e7%bf%92%e3%81%aeHello%20World%3a%20MNIST%e3%81%ae%e5%88%86%e9%a1%9e%e3%83%a2%e3%83%87%e3%83%ab%e3%82%92Keras%e3%81%a7%e4%bd%9c%e3%81%a3%e3%81%a6%e3%81%bf%e3%81%9f&amp;url=https%3a%2f%2fwww.kaitoy.xyz%2f2018%2f03%2f25%2fhello-world-to-ml-with-keras%2f"
              data-size="large">
            Tweet</a>
          </div>
          <div class="share-button">
            <a href="http://b.hatena.ne.jp/entry/" class="hatena-bookmark-button" data-hatena-bookmark-layout="vertical-normal" data-hatena-bookmark-lang="ja" title="このエントリーをはてなブックマークに追加"><img src="https://b.st-hatena.com/images/v4/public/entry-button/button-only@2x.png" alt="このエントリーをはてなブックマークに追加" width="20" height="20" style="border: none;" /></a><script type="text/javascript" src="https://b.st-hatena.com/js/bookmark_button.js" charset="utf-8" async="async"></script>
          </div>
          <div class="share-button">
            <a data-pocket-label="pocket" data-pocket-count="vertical" class="pocket-btn" data-lang="en"></a>
            <script type="text/javascript">!function(d,i){if(!d.getElementById(i)){var j=d.createElement("script");j.id=i;j.src="https://widgets.getpocket.com/v1/j/btn.js?v=1";var w=d.getElementById(i);d.body.appendChild(j);}}(document,"pocket-btn-js");</script>
          </div>
        </section>
    </div>

    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <ins class="adsbygoogle"
         style="display:block"
         data-ad-client="ca-pub-6244473643910448"
         data-ad-slot="1845600530"
         data-ad-format="auto"></ins>
    <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
    </script>

    <section class="tbd-pagination">
      <div class="row">
        <div class="col-sm-6">
          <div class="prev">
            
            <a href="https://www.kaitoy.xyz/2018/03/04/open-data/">
              <i class="fa fa-angle-left"></i>
              オープンデータメモ
            </a>
            
          </div>
        </div>
        <div class="col-sm-6">
          <div class="next text-right">
            
            <a href="https://www.kaitoy.xyz/2018/04/01/hello-skaffold/">
              Skaffoldを触ってみた
              <i class="fa fa-angle-right"></i>
            </a>
            
          </div>
        </div>
      </div>
    </section>

    
    

    

        <h4 class="page-header">Related</h4>

        <div class="related-links">
           <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2018/03/04/open-data/">オープンデータメモ</a></h4>
    <h5>Sun, Mar 4, 2018</h5>
    
    <a href="https://www.kaitoy.xyz/tags/machine-learning"><kbd class="item-tag">machine learning</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/deep-learning"><kbd class="item-tag">deep learning</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2018/02/27/coursera-deep-learning-sequence-models/">CourseraのDeep Learning SpecializationのSequence Modelsコースを修了した</a></h4>
    <h5>Tue, Feb 27, 2018</h5>
    
    <a href="https://www.kaitoy.xyz/tags/coursera"><kbd class="item-tag">coursera</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/machine-learning"><kbd class="item-tag">machine learning</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/deep-learning"><kbd class="item-tag">deep learning</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/neural-network"><kbd class="item-tag">neural network</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/rnn"><kbd class="item-tag">rnn</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/nlp"><kbd class="item-tag">nlp</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2018/02/06/coursera-deep-learning-convolutional-neural-networks/">CourseraのDeep Learning SpecializationのConvolutional Neural Networksコースを修了した</a></h4>
    <h5>Tue, Feb 6, 2018</h5>
    
    <a href="https://www.kaitoy.xyz/tags/coursera"><kbd class="item-tag">coursera</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/machine-learning"><kbd class="item-tag">machine learning</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/deep-learning"><kbd class="item-tag">deep learning</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/neural-network"><kbd class="item-tag">neural network</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/cnn"><kbd class="item-tag">cnn</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2018/01/16/coursera-deep-learning-ml-strategy/">CourseraのDeep Learning SpecializationのStructuring Machine Learning Projectsコースを修了した</a></h4>
    <h5>Tue, Jan 16, 2018</h5>
    
    <a href="https://www.kaitoy.xyz/tags/coursera"><kbd class="item-tag">coursera</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/machine-learning"><kbd class="item-tag">machine learning</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/deep-learning"><kbd class="item-tag">deep learning</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/neural-network"><kbd class="item-tag">neural network</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2018/01/12/coursera-deep-learning-improving-deep-neural-networks/">CourseraのDeep Learning SpecializationのImproving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimizationコースを修了した</a></h4>
    <h5>Fri, Jan 12, 2018</h5>
    
    <a href="https://www.kaitoy.xyz/tags/coursera"><kbd class="item-tag">coursera</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/machine-learning"><kbd class="item-tag">machine learning</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/deep-learning"><kbd class="item-tag">deep learning</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/neural-network"><kbd class="item-tag">neural network</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/tensorflow"><kbd class="item-tag">tensorflow</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2018/01/05/coursera-deep-learning-neural-networks-and-deep-learning/">CourseraのDeep Learning SpecializationのNeural Networks and Deep Learningコースを修了した</a></h4>
    <h5>Fri, Jan 5, 2018</h5>
    
    <a href="https://www.kaitoy.xyz/tags/coursera"><kbd class="item-tag">coursera</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/machine-learning"><kbd class="item-tag">machine learning</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/deep-learning"><kbd class="item-tag">deep learning</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/neural-network"><kbd class="item-tag">neural network</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4 class="post-title"><a href="/2017/12/22/coursera-machine-learning/">CourseraのMachine Learningコースを修了した</a></h4>
    <h5>Fri, Dec 22, 2017</h5>
    
    <a href="https://www.kaitoy.xyz/tags/coursera"><kbd class="item-tag">coursera</kbd></a>
    
    <a href="https://www.kaitoy.xyz/tags/machine-learning"><kbd class="item-tag">machine learning</kbd></a>
    

</div>
 
        </div>
    

    

        <h4 class="page-header">Comments</h4>

        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "kaitoy-tobedecided" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    

</main>

        <footer>

            <p class="copyright text-muted">&copy; 2015 Kaito Yamada. Powered by <a href="https://gohugo.io">Hugo</a> and <a href="https://github.com/calintat/minimal">Minimal</a></p>

        </footer>

        <script>window.twttr = (function(d, s, id) {
          var js, fjs = d.getElementsByTagName(s)[0],
            t = window.twttr || {};
          if (d.getElementById(id)) return t;
          js = d.createElement(s);
          js.id = id;
          js.src = "https://platform.twitter.com/widgets.js";
          fjs.parentNode.insertBefore(js, fjs);

          t._e = [];
          t.ready = function(f) {
            t._e.push(f);
          };

          return t;
        }(document, "script", "twitter-wjs"));</script>

    </body>

</html>

